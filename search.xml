<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>项目规范</title>
    <url>/README/</url>
    <content><![CDATA[<h1 id="wiki-guadazi"><a href="#wiki-guadazi" class="headerlink" title="wiki.guadazi"></a>wiki.guadazi</h1><p>本工程是呱嗒子WIKI <a href="http://wiki.zhangzuofeng.cn/">http://wiki.zhangzuofeng.cn</a> 的建设项目。项目下的所有文件是WIKI文章的源码。文章以<a href="http://www.appinn.com/markdown/">markdown</a>格式书写。</p>
<p>2017-04-18</p>
<p>这一天是一生中需要牢记的一次机会，</p>
<h1 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h1><table>
<thead>
<tr>
<th>目录</th>
<th>备注</th>
<th align="center">文章catagory</th>
</tr>
</thead>
<tbody><tr>
<td>Java</td>
<td>Java通用的文章，如J2SE、Java通用的工具等</td>
<td align="center">Java</td>
</tr>
<tr>
<td>Java/IO</td>
<td>Java IO</td>
<td align="center">Java</td>
</tr>
<tr>
<td>Java/multithread</td>
<td>Java多线程</td>
<td align="center">Java</td>
</tr>
<tr>
<td>JavaWeb</td>
<td>J2EE相关的内容，包括J2EE通用标准和第三方框架，如JSP、Servlet、EJB、Struts2、Spring、Hibernate、MyBatis、Netty等</td>
<td align="center">JavaWeb</td>
</tr>
<tr>
<td>JavaWeb/JSP-Servlet</td>
<td>JSP与Servlet</td>
<td align="center">JavaWeb</td>
</tr>
<tr>
<td>JavaWeb/EJB</td>
<td>EJB</td>
<td align="center">JavaWeb</td>
</tr>
<tr>
<td>JavaWeb/Struts2</td>
<td>Struts2</td>
<td align="center">JavaWeb</td>
</tr>
<tr>
<td>JavaWeb/Spring</td>
<td>Spring相关的内容</td>
<td align="center">JavaWeb</td>
</tr>
<tr>
<td>JavaWeb/Hibernate</td>
<td></td>
<td align="center">JavaWeb</td>
</tr>
<tr>
<td>JavaWeb/MyBatis</td>
<td></td>
<td align="center">JavaWeb</td>
</tr>
<tr>
<td>JavaWeb/Netty</td>
<td></td>
<td align="center">JavaWeb</td>
</tr>
<tr>
<td>web</td>
<td>web前端相关，如Javascript、JQuery、EasyUI等</td>
<td align="center">web</td>
</tr>
<tr>
<td>data-struct</td>
<td>数据结构与算法</td>
<td align="center">DataStruct</td>
</tr>
<tr>
<td>network</td>
<td>计算机网络</td>
<td align="center">Network</td>
</tr>
<tr>
<td>database</td>
<td>数据库</td>
<td align="center">DataBase</td>
</tr>
<tr>
<td>database/MySQL</td>
<td>MySQL数据库</td>
<td align="center">DataBase</td>
</tr>
<tr>
<td>design-pattern</td>
<td>设计模式</td>
<td align="center">DesignPattern</td>
</tr>
<tr>
<td>bigdata</td>
<td>大数据</td>
<td align="center">BigData</td>
</tr>
<tr>
<td>nuecai</td>
<td>面试题与面试经验总结</td>
<td align="center">-</td>
</tr>
<tr>
<td>projects</td>
<td>项目案例分析与设计</td>
<td align="center">projects</td>
</tr>
<tr>
<td>software-engineering</td>
<td>软件工程与项目管理</td>
<td align="center">SoftwareEngineering</td>
</tr>
<tr>
<td>tools</td>
<td>开发工具与小软件的使用</td>
<td align="center">Tools</td>
</tr>
<tr>
<td>images</td>
<td>图片目录，文章引用的图片全部放在该目录下，子目录的结构与文章的目录结构相同</td>
<td align="center">-</td>
</tr>
<tr>
<td>temp</td>
<td>临时文件，默认不会发布到网络上，只是作为临时笔记或文件的备份,可以不遵循hexo规范</td>
<td align="center">-</td>
</tr>
</tbody></table>
<p>此外，两个文件<code>deploy_git.sh</code>和<code>server_deploy.sh</code>为用于部署的shell，**勿动!**不要在网页上编辑。</p>
<h1 id="文章撰写"><a href="#文章撰写" class="headerlink" title="文章撰写"></a>文章撰写</h1><p>所有的文章必须按照固定的规范，即hexo的文章规范。<br>快捷的方法—直接复制同类文件</p>
]]></content>
      <categories>
        <category>Growth</category>
      </categories>
  </entry>
  <entry>
    <title>GraalVM: run programs faster anywhere</title>
    <url>/Java/GraalVM/</url>
    <content><![CDATA[<h1 id="GraalVM-run-programs-faster-anywhere"><a href="#GraalVM-run-programs-faster-anywhere" class="headerlink" title="GraalVM: run programs faster anywhere"></a>GraalVM: run programs faster anywhere</h1><p>Yudi Zheng 郑雨迪</p>
<p>Graal Compiler Team， Oracle Labs</p>
<p>为什么快？</p>
<p>支持哪些程序</p>
<p>跑在哪里？</p>
<p>compiler optimization ， performace tuning， X64 backend</p>
<p>ahead-of-time<br>experimental java-based JIT Compiler</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>tool</tag>
        <tag>JDK</tag>
        <tag>GraalVM</tag>
      </tags>
  </entry>
  <entry>
    <title>HttpClient</title>
    <url>/Java/HttpClient/</url>
    <content><![CDATA[<h1 id="HttpClient-2-3-6中-使用-SSL-3"><a href="#HttpClient-2-3-6中-使用-SSL-3" class="headerlink" title="HttpClient 2.3.6中 使用 SSL 3"></a>HttpClient 2.3.6中 使用 SSL 3</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">httpPost</span><span class="params">(String strUrl, List&lt;NameValuePair&gt; params)</span> </span>&#123;</span><br><span class="line">    RequestConfig.Builder bld = RequestConfig.custom();</span><br><span class="line">    bld.setConnectTimeout(<span class="number">60000</span>);</span><br><span class="line">    bld.setConnectionRequestTimeout(<span class="number">60000</span>);</span><br><span class="line">    bld.setSocketTimeout(<span class="number">60000</span>);</span><br><span class="line"></span><br><span class="line">    RequestConfig config = bld.build();</span><br><span class="line">    CloseableHttpClient closeableHttpClient = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        SSLContext sslcontext = SSLContexts.custom()</span><br><span class="line">                .loadTrustMaterial(<span class="keyword">null</span>, <span class="keyword">new</span> TrustSelfSignedStrategy())</span><br><span class="line">                .loadKeyMaterial(<span class="keyword">null</span>, <span class="keyword">null</span>)</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        SSLConnectionSocketFactory sslsf = <span class="keyword">new</span> SSLConnectionSocketFactory(</span><br><span class="line">                sslcontext, <span class="keyword">new</span> String[]&#123;<span class="string">&quot;SSLv3&quot;</span>, <span class="string">&quot;TLSv1&quot;</span>&#125;, <span class="keyword">null</span>,</span><br><span class="line">                SSLConnectionSocketFactory.ALLOW_ALL_HOSTNAME_VERIFIER);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (closeableHttpClient == <span class="keyword">null</span>) &#123;</span><br><span class="line">            closeableHttpClient = HttpClients.custom()</span><br><span class="line">                    .setSSLSocketFactory(sslsf).build();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    String result = <span class="keyword">null</span>;</span><br><span class="line">    CloseableHttpResponse response = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        HttpPost post = <span class="keyword">new</span> HttpPost(strUrl);</span><br><span class="line">        post.setEntity(<span class="keyword">new</span> UrlEncodedFormEntity(params, <span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line">        response = closeableHttpClient.execute(post);</span><br><span class="line">        <span class="keyword">int</span> code = response.getStatusLine().getStatusCode();</span><br><span class="line">        System.out.println(<span class="string">&quot;请求返回结果: Code:&quot;</span> + code);</span><br><span class="line">        <span class="keyword">if</span> (code == <span class="number">200</span>) &#123;</span><br><span class="line">            result = EntityUtils.toString(response.getEntity(), <span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;请求返回值为:=&gt; &quot;</span> + result);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (closeableHttpClient != <span class="keyword">null</span>) &#123;</span><br><span class="line">                closeableHttpClient.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (response != <span class="keyword">null</span>) &#123;</span><br><span class="line">                response.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>Java编程tips</title>
    <url>/Java/Java-tips/</url>
    <content><![CDATA[<ol>
<li>Calendar<br>获取小时数 [2017-10-17 16:10:36 星期二]<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Calendar calendar = Calendar.getInstance();</span><br><span class="line"><span class="comment">// 获取12小时制的小时数</span></span><br><span class="line"><span class="keyword">int</span> hour12 = calendar.get(Calendar.HOUR);</span><br><span class="line"><span class="comment">// 获取24小时制的小时数</span></span><br><span class="line"><span class="keyword">int</span> hour24 = calendar.get(Calendar.HOUR_OF_DAY);</span><br></pre></td></tr></table></figure></li>
<li>读锁(共享锁)与写锁(独占锁)</li>
</ol>
<p>[2017-10-17 16:10:41 星期二]</p>
<p>虽然读锁可以允许多个线程读取，写锁会独占，但是当一个线程对资源加了读锁后，另一个线程要加独占锁也必须等待读锁释放。</p>
<ol start="3">
<li>Java web 获取 classes 目录</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String path = Thread.currentThread().getContextClassLoader().getResource(<span class="string">&quot;/&quot;</span>).toURI().getPath();</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Socket</title>
    <url>/Java/Socket/</url>
    <content><![CDATA[<h1 id="计算机网络的基本知识"><a href="#计算机网络的基本知识" class="headerlink" title="计算机网络的基本知识"></a>计算机网络的基本知识</h1><p>两台计算机设备通过网络进行通信需要满足一些必然的条件: 1. IP地址 2. 协议 3. 端口号</p>
<p>TCP/IP模型是目前应用最为广泛的网络模型.</p>
<p><img src="/images/java/socket/tcp_ip.png"></p>
<p>TCP/IP协议是传输层协议</p>
<p>常见的应用层协议有:</p>
<ul>
<li>DNS 域名系统(Domain Name System，DNS)：用于实现网络设备名字到IP地址映射的网络服务。</li>
<li>HTTP 超文本传输协议 用于实现WWW服务</li>
<li>FTP 文件传输协议</li>
<li>TELNET 远程登录协议</li>
<li>SMTP 简单邮件传输协议</li>
<li>简单网络管理协议(simple Network Management Protocol，SNMP)：用于管理与监视网络设备。</li>
</ul>
<p>端口</p>
<ol>
<li><p>用来区分不同的应用程序</p>
</li>
<li><p>端口号的范围为0<del>65535,其中0</del>1023是系统保留端口</p>
</li>
<li><p>一个应用可以绑定多个端口:</p>
<p><img src="/images/java/socket/port_of_qq.png"></p>
</li>
<li><p>IP地址和端口号组成了所谓的Socket, Socket是网络上运行的程序之间双向通信链路的终结点,是TCP和UDP的基础</p>
</li>
<li><p>常用的端口号有: http 80 ftp 21 telnet 23</p>
</li>
</ol>
<h1 id="Java对网路通信的支持"><a href="#Java对网路通信的支持" class="headerlink" title="Java对网路通信的支持"></a>Java对网路通信的支持</h1><ul>
<li>InetAddress<br>用于标示网络上的硬件资源,也就是IP地址</li>
<li>URL<br>统一资源定位符 通过URL可以直接读取或写入网络上的数据</li>
<li>Socket<br>使用TCP协议实现网络通信的Socket相关的类</li>
<li>Datagram<br>使用UDP协议,将数据保存在数据报中,通过网络进行通信.</li>
</ul>
<h2 id="InetAddress"><a href="#InetAddress" class="headerlink" title="InetAddress"></a>InetAddress</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取本机的InetAddress实例</span></span><br><span class="line">InetAddress address = InetAddress.getLocalHost();</span><br><span class="line">System.out.println(<span class="string">&quot;计算名：&quot;</span> + address.getHostName());</span><br><span class="line">System.out.println(<span class="string">&quot;IP地址：&quot;</span> + address.getHostAddress());</span><br><span class="line"><span class="keyword">byte</span>[] bytes = address.getAddress();<span class="comment">// 获取字节数组形式的IP地址</span></span><br><span class="line">System.out.println(<span class="string">&quot;字节数组形式的IP：&quot;</span> + Arrays.toString(bytes));</span><br><span class="line">System.out.println(address);<span class="comment">// 直接输出InetAddress对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据机器名获取InetAddress实例</span></span><br><span class="line"><span class="comment">// InetAddress address2=InetAddress.getByName(&quot;laurenyang&quot;);</span></span><br><span class="line">InetAddress address2 = InetAddress.getByName(<span class="string">&quot;1.1.1.10&quot;</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;计算名：&quot;</span> + address2.getHostName());</span><br><span class="line">System.out.println(<span class="string">&quot;IP地址：&quot;</span> + address2.getHostAddress());</span><br></pre></td></tr></table></figure>

<h2 id="Socket通信与Socket类"><a href="#Socket通信与Socket类" class="headerlink" title="Socket通信与Socket类"></a>Socket通信与Socket类</h2><p>TCP协议是面向连接 可靠的 有序的, 以字节流的方式发送数据</p>
<p>基于TCP协议实现网络通信的类</p>
<ul>
<li> 客户端的Socket类</li>
<li> 服务端的ServerSocket类</li>
</ul>
<p>Client.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	<span class="comment">//1.创建客户端Socket，指定服务器地址和端口</span></span><br><span class="line">	Socket socket=<span class="keyword">new</span> Socket(<span class="string">&quot;localhost&quot;</span>, <span class="number">8888</span>);</span><br><span class="line">	<span class="comment">//2.获取输出流，向服务器端发送信息</span></span><br><span class="line">	OutputStream os=socket.getOutputStream();<span class="comment">//字节输出流</span></span><br><span class="line">	PrintWriter pw=<span class="keyword">new</span> PrintWriter(os);<span class="comment">//将输出流包装为打印流</span></span><br><span class="line">	pw.write(<span class="string">&quot;用户名：alice;密码：789&quot;</span>);</span><br><span class="line">	pw.flush();</span><br><span class="line">	socket.shutdownOutput();<span class="comment">//关闭输出流</span></span><br><span class="line">	<span class="comment">//3.获取输入流，并读取服务器端的响应信息</span></span><br><span class="line">	InputStream is=socket.getInputStream();</span><br><span class="line">	BufferedReader br=<span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(is));</span><br><span class="line">	String info=<span class="keyword">null</span>;</span><br><span class="line">	<span class="keyword">while</span>((info=br.readLine())!=<span class="keyword">null</span>)&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;我是客户端，服务器说：&quot;</span>+info);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//4.关闭资源</span></span><br><span class="line">	br.close();</span><br><span class="line">	is.close();</span><br><span class="line">	pw.close();</span><br><span class="line">	os.close();</span><br><span class="line">	socket.close();</span><br><span class="line">&#125; <span class="keyword">catch</span> (UnknownHostException e) &#123;</span><br><span class="line">	e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">	e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Server.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 基于TCP协议的Socket通信，实现用户登陆</span></span><br><span class="line"><span class="comment"> * 服务器端</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	<span class="comment">//1.创建一个服务器端Socket，即ServerSocket，指定绑定的端口，并监听此端口</span></span><br><span class="line">	ServerSocket serverSocket=<span class="keyword">new</span> ServerSocket(<span class="number">8888</span>);</span><br><span class="line">	Socket socket=<span class="keyword">null</span>;</span><br><span class="line">	<span class="comment">//记录客户端的数量</span></span><br><span class="line">	<span class="keyword">int</span> count=<span class="number">0</span>;</span><br><span class="line">	System.out.println(<span class="string">&quot;***服务器即将启动，等待客户端的连接***&quot;</span>);</span><br><span class="line">	<span class="comment">//循环监听等待客户端的连接</span></span><br><span class="line">	<span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">		<span class="comment">//调用accept()方法开始监听，等待客户端的连接</span></span><br><span class="line">		socket=serverSocket.accept();</span><br><span class="line">		<span class="comment">//创建一个新的线程</span></span><br><span class="line">		ServerThread serverThread=<span class="keyword">new</span> ServerThread(socket);</span><br><span class="line">		<span class="comment">//启动线程</span></span><br><span class="line">		serverThread.start();</span><br><span class="line"></span><br><span class="line">		count++;<span class="comment">//统计客户端的数量</span></span><br><span class="line">		System.out.println(<span class="string">&quot;客户端的数量：&quot;</span>+count);</span><br><span class="line">		InetAddress address=socket.getInetAddress();</span><br><span class="line">		System.out.println(<span class="string">&quot;当前客户端的IP：&quot;</span>+address.getHostAddress());</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">	e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ServerThread.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 服务器线程处理类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ServerThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 和本线程相关的Socket</span></span><br><span class="line">	Socket socket = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">ServerThread</span><span class="params">(Socket socket)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.socket = socket;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//线程执行的操作，响应客户端的请求</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">		InputStream is=<span class="keyword">null</span>;</span><br><span class="line">		InputStreamReader isr=<span class="keyword">null</span>;</span><br><span class="line">		BufferedReader br=<span class="keyword">null</span>;</span><br><span class="line">		OutputStream os=<span class="keyword">null</span>;</span><br><span class="line">		PrintWriter pw=<span class="keyword">null</span>;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			<span class="comment">//获取输入流，并读取客户端信息</span></span><br><span class="line">			is = socket.getInputStream();</span><br><span class="line">			isr = <span class="keyword">new</span> InputStreamReader(is);</span><br><span class="line">			br = <span class="keyword">new</span> BufferedReader(isr);</span><br><span class="line">			String info=<span class="keyword">null</span>;</span><br><span class="line">			<span class="keyword">while</span>((info=br.readLine())!=<span class="keyword">null</span>)&#123;<span class="comment">//循环读取客户端的信息</span></span><br><span class="line">				System.out.println(<span class="string">&quot;我是服务器，客户端说：&quot;</span>+info);</span><br><span class="line">			&#125;</span><br><span class="line">			socket.shutdownInput();<span class="comment">//关闭输入流</span></span><br><span class="line">			<span class="comment">//获取输出流，响应客户端的请求</span></span><br><span class="line">			os = socket.getOutputStream();</span><br><span class="line">			pw = <span class="keyword">new</span> PrintWriter(os);</span><br><span class="line">			pw.write(<span class="string">&quot;欢迎您！&quot;</span>);</span><br><span class="line">			pw.flush();<span class="comment">//调用flush()方法将缓冲输出</span></span><br><span class="line">		&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">			<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">			<span class="comment">//关闭资源</span></span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				<span class="keyword">if</span>(pw!=<span class="keyword">null</span>)</span><br><span class="line">					pw.close();</span><br><span class="line">				<span class="keyword">if</span>(os!=<span class="keyword">null</span>)</span><br><span class="line">					os.close();</span><br><span class="line">				<span class="keyword">if</span>(br!=<span class="keyword">null</span>)</span><br><span class="line">					br.close();</span><br><span class="line">				<span class="keyword">if</span>(isr!=<span class="keyword">null</span>)</span><br><span class="line">					isr.close();</span><br><span class="line">				<span class="keyword">if</span>(is!=<span class="keyword">null</span>)</span><br><span class="line">					is.close();</span><br><span class="line">				<span class="keyword">if</span>(socket!=<span class="keyword">null</span>)</span><br><span class="line">					socket.close();</span><br><span class="line">			&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="多线程Socket通信优化"><a href="#多线程Socket通信优化" class="headerlink" title="多线程Socket通信优化"></a>多线程Socket通信优化</h2><ol>
<li><p>完成新客户端的绑定,启动多线程时, 设置优先级, 为设置优先级可能会导致运行时速度非常慢, 可降低优先级</p>
</li>
<li><p>对于同一个Socket, 如果关闭了输出流,则与该输出流关联的Socket也会被关闭,所以一般不用关闭流, 直接关闭socket即可.</p>
</li>
<li><p>使用TCP通信传输对象</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//使用ObjectOutputStream 对象序列化流,传递对象</span></span><br><span class="line">OutputStream os=socket.getOutputStream();</span><br><span class="line">ObjectOutputStream oos=<span class="keyword">new</span> ObjectOutputStream(os);</span><br><span class="line">User user=<span class="keyword">new</span> User();</span><br><span class="line">oos.writeObject(user);</span><br><span class="line">socket.shutdownOutput();</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
<li><p>使用TCP通信传输文件</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BufferedOutputStream fos=<span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(file));</span><br><span class="line"><span class="keyword">byte</span>[] buf =<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">int</span> len;</span><br><span class="line"><span class="keyword">while</span>((len=clientInputStream.read(buf))!=-<span class="number">1</span>)&#123;</span><br><span class="line">  fos.write(buf,<span class="number">0</span>,len);</span><br><span class="line">  fos.flush();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="UDP协议与Datagram"><a href="#UDP协议与Datagram" class="headerlink" title="UDP协议与Datagram"></a>UDP协议与Datagram</h2></li>
</ol>
<p>UDP协议(用户数据报协议)是无连接 不可靠 无序的. UDP协议以数据报作为数据传输的载体.<br>进行数据传输时,首先要将传输的数据定义成数据报(Datagram),在数据报中指明数据所要达到的Socket(主机地址和端口号),然后再讲数据报发送出去.</p>
<ul>
<li>DatagramPacket: 表示数据报包</li>
<li>DatagramSocket: 进行端对端通信的类</li>
</ul>
<p>UDPClient.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* 向服务器端发送数据</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">//1.定义服务器的地址、端口号、数据</span></span><br><span class="line">InetAddress address=InetAddress.getByName(<span class="string">&quot;localhost&quot;</span>);</span><br><span class="line"><span class="keyword">int</span> port=<span class="number">8800</span>;</span><br><span class="line"><span class="keyword">byte</span>[] data=<span class="string">&quot;用户名：admin;密码：123&quot;</span>.getBytes();</span><br><span class="line"><span class="comment">//2.创建数据报，包含发送的数据信息</span></span><br><span class="line">DatagramPacket packet=<span class="keyword">new</span> DatagramPacket(data, data.length, address, port);</span><br><span class="line"><span class="comment">//3.创建DatagramSocket对象</span></span><br><span class="line">DatagramSocket socket=<span class="keyword">new</span> DatagramSocket();</span><br><span class="line"><span class="comment">//4.向服务器端发送数据报</span></span><br><span class="line">socket.send(packet);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* 接收服务器端响应的数据</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">//1.创建数据报，用于接收服务器端响应的数据</span></span><br><span class="line"><span class="keyword">byte</span>[] data2=<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">DatagramPacket packet2=<span class="keyword">new</span> DatagramPacket(data2, data2.length);</span><br><span class="line"><span class="comment">//2.接收服务器响应的数据</span></span><br><span class="line">socket.receive(packet2);</span><br><span class="line"><span class="comment">//3.读取数据</span></span><br><span class="line">String reply=<span class="keyword">new</span> String(data2, <span class="number">0</span>, packet2.getLength());</span><br><span class="line">System.out.println(<span class="string">&quot;我是客户端，服务器说：&quot;</span>+reply);</span><br><span class="line"><span class="comment">//4.关闭资源</span></span><br><span class="line">socket.close();</span><br></pre></td></tr></table></figure>
<p>UDPServer.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 接收客户端发送的数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//1.创建服务器端DatagramSocket，指定端口</span></span><br><span class="line">DatagramSocket socket=<span class="keyword">new</span> DatagramSocket(<span class="number">8800</span>);</span><br><span class="line"><span class="comment">//2.创建数据报，用于接收客户端发送的数据</span></span><br><span class="line"><span class="keyword">byte</span>[] data =<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];<span class="comment">//创建字节数组，指定接收的数据包的大小</span></span><br><span class="line">DatagramPacket packet=<span class="keyword">new</span> DatagramPacket(data, data.length);</span><br><span class="line"><span class="comment">//3.接收客户端发送的数据</span></span><br><span class="line">System.out.println(<span class="string">&quot;****服务器端已经启动，等待客户端发送数据&quot;</span>);</span><br><span class="line">socket.receive(packet);<span class="comment">//此方法在接收到数据报之前会一直阻塞</span></span><br><span class="line"><span class="comment">//4.读取数据</span></span><br><span class="line">String info=<span class="keyword">new</span> String(data, <span class="number">0</span>, packet.getLength());</span><br><span class="line">System.out.println(<span class="string">&quot;我是服务器，客户端说：&quot;</span>+info);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 向客户端响应数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//1.定义客户端的地址、端口号、数据</span></span><br><span class="line">InetAddress address=packet.getAddress();</span><br><span class="line"><span class="keyword">int</span> port=packet.getPort();</span><br><span class="line"><span class="keyword">byte</span>[] data2=<span class="string">&quot;欢迎您!&quot;</span>.getBytes();</span><br><span class="line"><span class="comment">//2.创建数据报，包含响应的数据信息</span></span><br><span class="line">DatagramPacket packet2=<span class="keyword">new</span> DatagramPacket(data2, data2.length, address, port);</span><br><span class="line"><span class="comment">//3.响应客户端</span></span><br><span class="line">socket.send(packet2);</span><br><span class="line"><span class="comment">//4.关闭资源</span></span><br><span class="line">socket.close();</span><br></pre></td></tr></table></figure>
<h2 id="URL"><a href="#URL" class="headerlink" title="URL"></a>URL</h2><p><a href="/android-network/">参见 Android 网路编程</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * URL常用方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">//创建一个URL实例</span></span><br><span class="line">  URL imooc=<span class="keyword">new</span> URL(<span class="string">&quot;http://www.imooc.com&quot;</span>);</span><br><span class="line">  <span class="comment">//?后面表示参数，#后面表示锚点</span></span><br><span class="line">  URL url=<span class="keyword">new</span> URL(imooc, <span class="string">&quot;/index.html?username=tom#test&quot;</span>);</span><br><span class="line">  System.out.println(<span class="string">&quot;协议：&quot;</span>+url.getProtocol());</span><br><span class="line">  System.out.println(<span class="string">&quot;主机：&quot;</span>+url.getHost());</span><br><span class="line">  <span class="comment">//如果未指定端口号，则使用默认的端口号，此时getPort()方法返回值为-1</span></span><br><span class="line">  System.out.println(<span class="string">&quot;端口：&quot;</span>+url.getPort());</span><br><span class="line">  System.out.println(<span class="string">&quot;文件路径：&quot;</span>+url.getPath());</span><br><span class="line">  System.out.println(<span class="string">&quot;文件名：&quot;</span>+url.getFile());</span><br><span class="line">  System.out.println(<span class="string">&quot;相对路径：&quot;</span>+url.getRef());</span><br><span class="line">  System.out.println(<span class="string">&quot;查询字符串：&quot;</span>+url.getQuery());</span><br><span class="line">&#125; <span class="keyword">catch</span> (MalformedURLException e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 使用URL读取网页内容</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"> <span class="comment">//创建一个URL实例</span></span><br><span class="line"> URL url = <span class="keyword">new</span> URL(<span class="string">&quot;http://www.baidu.com&quot;</span>);</span><br><span class="line"> <span class="comment">//通过URL的openStream方法获取URL对象所表示的资源的字节输入流</span></span><br><span class="line"> InputStream is = url.openStream();</span><br><span class="line"> <span class="comment">//将字节输入流转换为字符输入流</span></span><br><span class="line"> InputStreamReader isr = <span class="keyword">new</span> InputStreamReader(is, <span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line"> <span class="comment">//为字符输入流添加缓冲</span></span><br><span class="line"> BufferedReader br = <span class="keyword">new</span> BufferedReader(isr);</span><br><span class="line"> String data = br.readLine();<span class="comment">//读取数据</span></span><br><span class="line"> <span class="keyword">while</span> (data != <span class="keyword">null</span>) &#123;<span class="comment">//循环读取数据</span></span><br><span class="line">   System.out.println(data);<span class="comment">//输出数据</span></span><br><span class="line">   data = br.readLine();</span><br><span class="line"> &#125;</span><br><span class="line"> br.close();</span><br><span class="line"> isr.close();</span><br><span class="line"> is.close();</span><br><span class="line">&#125; <span class="keyword">catch</span> (MalformedURLException e) &#123;</span><br><span class="line"> e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line"> e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="HttpURLConnection"><a href="#HttpURLConnection" class="headerlink" title="HttpURLConnection"></a>HttpURLConnection</h2><p><a href="/android-network/">参见 Android 网路编程</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title>Quartz应用与原理</title>
    <url>/Java/Quartz/</url>
    <content><![CDATA[<p>使用</p>
<p>配置</p>
<p>集群</p>
<p>原理</p>
<p>Quartz是一个大名鼎鼎的Java版开源定时调度器，功能强悍，使用方便。</p>
<h1 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h1><p>Quartz的原理不是很复杂，只要搞明白几个概念，然后知道如何去启动和关闭一个调度程序即可。</p>
<ol>
<li><p>Job</p>
<p>表示一个工作，要执行的具体内容。此接口中只有一个方法<br>void execute(JobExecutionContext context)</p>
</li>
<li><p>JobDetail</p>
<p>JobDetail表示一个具体的可执行的调度程序，Job是这个可执行程调度程序所要执行的内容，另外JobDetail还包含了这个任务调度的方案和策略。</p>
</li>
<li><p>Trigger代表一个调度参数的配置，什么时候去调。</p>
</li>
<li><p>Scheduler代表一个调度容器，一个调度容器中可以注册多个JobDetail和Trigger。当Trigger与JobDetail组合，就可以被Scheduler容器调度了。</p>
</li>
</ol>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleQuartzJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SimpleQuartzJob</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;In SimpleQuartzJob - executing its JOB at &quot;</span></span><br><span class="line">                + <span class="keyword">new</span> Date() + <span class="string">&quot; by &quot;</span> + context.getTrigger().getDescription());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="普通"><a href="#普通" class="headerlink" title="普通"></a>普通</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.quartz.*;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.StdSchedulerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* quartz定时器测试</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext jobExecutionContext)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">                System.out.println(<span class="keyword">new</span> Date() + <span class="string">&quot;: doing something...&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用的代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、创建JobDetial对象</span></span><br><span class="line">JobDetail jobDetail = <span class="keyword">new</span> JobDetail();</span><br><span class="line"><span class="comment">//设置工作项</span></span><br><span class="line">jobDetail.setJobClass(MyJob.class);</span><br><span class="line">jobDetail.setName(<span class="string">&quot;MyJob_1&quot;</span>);</span><br><span class="line">jobDetail.setGroup(<span class="string">&quot;JobGroup_1&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//2、创建Trigger对象</span></span><br><span class="line">SimpleTrigger strigger = <span class="keyword">new</span> SimpleTrigger();</span><br><span class="line">strigger.setName(<span class="string">&quot;Trigger_1&quot;</span>);</span><br><span class="line">strigger.setGroup(<span class="string">&quot;Trigger_Group_1&quot;</span>);</span><br><span class="line">strigger.setStartTime(<span class="keyword">new</span> Date());</span><br><span class="line"><span class="comment">//设置重复停止时间，并销毁该Trigger对象</span></span><br><span class="line">java.util.Calendar c = java.util.Calendar.getInstance();</span><br><span class="line">c.setTimeInMillis(System.currentTimeMillis() + <span class="number">1000</span> * <span class="number">1L</span>);</span><br><span class="line">strigger.setEndTime(c.getTime());</span><br><span class="line">strigger.setFireInstanceId(<span class="string">&quot;Trigger_1_id_001&quot;</span>);</span><br><span class="line"><span class="comment">//设置重复间隔时间</span></span><br><span class="line">strigger.setRepeatInterval(<span class="number">1000</span> * <span class="number">1L</span>);</span><br><span class="line"><span class="comment">//设置重复执行次数</span></span><br><span class="line">strigger.setRepeatCount(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//3、创建Scheduler对象，并配置JobDetail和Trigger对象</span></span><br><span class="line">SchedulerFactory sf = <span class="keyword">new</span> StdSchedulerFactory();</span><br><span class="line">Scheduler scheduler = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">        scheduler = sf.getScheduler();</span><br><span class="line">        scheduler.scheduleJob(jobDetail, strigger);</span><br><span class="line">        <span class="comment">//4、并执行启动、关闭等操作</span></span><br><span class="line">        scheduler.start();</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (SchedulerException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// try &#123;</span></span><br><span class="line"><span class="comment">//   //关闭调度器</span></span><br><span class="line"><span class="comment">//   scheduler.shutdown(true);</span></span><br><span class="line"><span class="comment">// &#125; catch (SchedulerException e) &#123;</span></span><br><span class="line"><span class="comment">//    e.printStackTrace();</span></span><br><span class="line"><span class="comment">// &#125;</span></span><br></pre></td></tr></table></figure>
<p>另外一种创建的方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">// 创建调度器</span></span><br><span class="line">  Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line">  <span class="comment">// Create a JobDetail for the Job</span></span><br><span class="line">  JobDetail jobDetail = newJob(SimpleQuartzJob.class).withIdentity(<span class="string">&quot;myJob&quot;</span>, <span class="string">&quot;group1&quot;</span>).build();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Date runTime = evenMinuteDate(new Date());</span></span><br><span class="line"></span><br><span class="line">  Trigger trigger = newTrigger().withIdentity(<span class="string">&quot;myTrigger&quot;</span>, <span class="string">&quot;group1&quot;</span>).startNow()</span><br><span class="line">    .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(<span class="number">5</span>).withRepeatCount(<span class="number">10</span>)).build();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Trigger trigger = newTrigger().withIdentity(&quot;myTrigger&quot;,&quot;group1&quot;).startAt(RunTime).build();</span></span><br><span class="line"></span><br><span class="line">  scheduler.scheduleJob(jobDetail, trigger);</span><br><span class="line"></span><br><span class="line">  scheduler.start();</span><br><span class="line"></span><br><span class="line">  <span class="comment">//            Thread.sleep(60000);</span></span><br><span class="line">  System.out.println(<span class="string">&quot;goto shutdown&quot;</span>);</span><br><span class="line">  scheduler.shutdown(<span class="keyword">true</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (SchedulerException e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">  <span class="comment">//        &#125; catch (InterruptedException e) &#123;</span></span><br><span class="line">  e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="Crontab"><a href="#Crontab" class="headerlink" title="Crontab"></a>Crontab</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建调度器</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line">  JobDetail jobDetail = newJob(SimpleQuartzJob.class).withIdentity(<span class="string">&quot;myJob2&quot;</span>, <span class="string">&quot;group1&quot;</span>).build();</span><br><span class="line"></span><br><span class="line">  Trigger trigger = newTrigger().withIdentity(<span class="string">&quot;myTrigger3&quot;</span>, <span class="string">&quot;group1&quot;</span>).withSchedule(CronScheduleBuilder.cronSchedule(<span class="string">&quot;0/1 * * * * ?&quot;</span>)).build();</span><br><span class="line"></span><br><span class="line">  scheduler.scheduleJob(jobDetail, trigger);</span><br><span class="line">  <span class="keyword">if</span> (scheduler.isStarted()) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;has started!&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  scheduler.start();</span><br><span class="line">  Thread.sleep(<span class="number">60000</span>);</span><br><span class="line">  scheduler.shutdown();</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (SchedulerException e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




<h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><h2 id="与Spring结合"><a href="#与Spring结合" class="headerlink" title="与Spring结合"></a>与Spring结合</h2><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p> </p>
<p>通过研读Quartz的源代码，和本实例，终于悟出了Quartz的工作原理。</p>
<p> 1. scheduler是一个计划调度器容器（总部），容器里面可以盛放众多的JobDetail和trigger，当容器启动后，里面的每个JobDetail都会根据trigger按部就班自动去执行。 <br> 2. JobDetail是一个可执行的工作，它本身可能是有状态的。 <br> 3. Trigger代表一个调度参数的配置，什么时候去调。 <br> 4. 当JobDetail和Trigger在scheduler容器上注册后，形成了装配好的作业（JobDetail和Trigger所组成的一对儿），就可以伴随容器启动而调度执行了。 <br> 5. scheduler是个容器，容器中有一个线程池，用来并行调度执行每个作业，这样可以提高容器效率。<br> 6. 将上述的结构用一个图来表示，如下：</p>
<p><img src="/images/java/quartz-central.png"></p>
<hr>
<p>[参考文献]:</p>
<ol>
<li><a href="http://lavasoft.blog.51cto.com/62575/181907/">深入解读Quartz的原理</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java异常</title>
    <url>/Java/Throwable/</url>
    <content><![CDATA[<p>请参考<a href="http://blog.csdn.net/hguisu/article/details/6155636" title="深入理解java异常处理机制">深入理解java异常处理机制</a></p>
<p>异常是指当程序中某些地方出错时创建的一种特殊的运行时错误对象。Java创建异常对象后，就发送给Java程序，即抛出异常(throwing an exception)。程序捕捉到这个异常后，可以编写相应的异常处理代码进行处理。使用异常处理可以使得程序更加健壮，有助于调试和后期维护。</p>
<h1 id="Throwable的继承体系"><a href="#Throwable的继承体系" class="headerlink" title="Throwable的继承体系"></a>Throwable的继承体系</h1><p>Throwable类派生了两个类：Exception类和Error类，其中Error类系统保留，而Exception类供应用程序使用，它下面又派生出几个具体的异常类，都对应着一项具体的运行错误</p>
<p><img src="/images/java/Throwable/inherit.png"></p>
<h1 id="异常的工作原理"><a href="#异常的工作原理" class="headerlink" title="异常的工作原理"></a>异常的工作原理</h1><p>抛出异常：当一个方法出现错误引发异常时，方法创建异常对象并交付运行时系统，异常对象中包含了异常类型和异常出现时的程序状态等异常信息。运行时系统负责寻找处置异常的代码并执行。</p>
<p>捕获异常：在方法抛出异常之后，运行时系统将转为寻找合适的异常处理器（exception handler）。潜在的异常处理器是异常发生时依次存留在调用栈中的方法的集合。当异常处理器所能处理的异常类型与方法抛出的异常类型相符时，即为合适 的异常处理器。运行时系统从发生异常的方法开始，依次回查调用栈中的方法，直至找到含有合适异常处理器的方法并执行。当运行时系统遍历调用栈而未找到合适 的异常处理器，则运行时系统终止。同时，意味着Java程序的终止。</p>
<h1 id="常见的受检异常"><a href="#常见的受检异常" class="headerlink" title="常见的受检异常"></a>常见的受检异常</h1><p> 除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。</p>
<p>IOException：操作输入流和输出流时可能出现的异常。</p>
<p>EOFException   文件已结束异常</p>
<p>FileNotFoundException   文件未找到异常</p>
<h1 id="常见的非受检异常"><a href="#常见的非受检异常" class="headerlink" title="常见的非受检异常"></a>常见的非受检异常</h1><p>运行时异常：都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。</p>
<p>ArithmeticException</p>
<p>ArrayIndexOutOfBoundsException<br>1、 java.lang.ArrayIndexOutOfBoundsException<br> 数组索引越界异常。当对数组的索引值为负数或大于等于数组大小时抛出。<br> 2、java.lang.ArithmeticException<br> 算术条件异常。譬如：整数除零等。<br> 3、java.lang.NullPointerException<br> 空指针异常。当应用试图在要求使用对象的地方使用了null时，抛出该异常。譬如：调用null对象的实例方法、访问null对象的属性、计算null对象的长度、使用throw语句抛出null等等<br> 4、java.lang.ClassNotFoundException<br> 找不到类异常。当应用试图根据字符串形式的类名构造类，而在遍历CLASSPAH之后找不到对应名称的class文件时，抛出该异常。</p>
<p>5、java.lang.NegativeArraySizeException  数组长度为负异常</p>
<p>6、java.lang.ArrayStoreException 数组中包含不兼容的值抛出的异常</p>
<p>7、java.lang.SecurityException 安全性异常</p>
<p>8、java.lang.IllegalArgumentException 非法参数异常</p>
<p>综合实例:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestException</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TestException</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">testEx</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> ret = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            ret = testEx1();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;testEx, catch exception&quot;</span>);</span><br><span class="line">            ret = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;testEx, finally; return value=&quot;</span> + ret);</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">testEx1</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> ret = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            ret = testEx2();</span><br><span class="line">            <span class="keyword">if</span> (!ret) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;testEx1, at the end of try&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;testEx1, catch exception&quot;</span>);</span><br><span class="line">            ret = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;testEx1, finally; return value=&quot;</span> + ret);</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">testEx2</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> ret = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> b = <span class="number">12</span>;</span><br><span class="line">            <span class="keyword">int</span> c;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &gt;= -<span class="number">2</span>; i--) &#123;</span><br><span class="line">                c = b / i;</span><br><span class="line">                System.out.println(<span class="string">&quot;i=&quot;</span> + i);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;testEx2, catch exception&quot;</span>);</span><br><span class="line">            ret = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;testEx2, finally; return value=&quot;</span> + ret);</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        TestException testException1 = <span class="keyword">new</span> TestException();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            testException1.testEx();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出结果:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">i&#x3D;2</span><br><span class="line">i&#x3D;1</span><br><span class="line">testEx2, catch exception</span><br><span class="line">testEx2, finally; return value&#x3D;false</span><br><span class="line">testEx1, finally; return value&#x3D;false</span><br><span class="line">testEx, finally; return value&#x3D;false</span><br></pre></td></tr></table></figure>
<hr>
<p>[参考文献]:</p>
<ol>
<li>Think in Java</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/6155636" title="深入理解java异常处理机制">深入理解java异常处理机制</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Throwable</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/Java/String.split/</url>
    <content><![CDATA[<h1 id="String-split"><a href="#String-split" class="headerlink" title="String.split"></a>String.split</h1><h2 id="正则表达式分割字符串"><a href="#正则表达式分割字符串" class="headerlink" title="正则表达式分割字符串"></a>正则表达式分割字符串</h2><h3 id="保留末尾空格与空字符串情形"><a href="#保留末尾空格与空字符串情形" class="headerlink" title="保留末尾空格与空字符串情形"></a>保留末尾空格与空字符串情形</h3><p><code>split(delimiter)</code> 默认会从结果数组中去掉空字符串. 要关闭这个机制，将重载方法 <code>split(delimiter, limit)</code> 的 <code>limit</code> 设置为负值，如</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] split = data.split(<span class="string">&quot;\\|&quot;</span>, -<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>更详细的介绍:</p>
<p><code>split(regex)</code> 内部是调用<code>split(regex, 0)</code>的返回结果，参考官方文档 <a href="http://docs.oracle.com/javase/8/docs/api/java/lang/String.html#split-java.lang.String-int-">documentation</a> 有这个方法的详细介绍</p>
<blockquote>
<p><code>limit</code>参数控制应用pattern的次数，因此会影响所得数组的长度。<br>如果限制<code>n</code><strong>大于零</strong>，则将最多应用<code>n-1</code>次该pattern，该数组的长度将不大于n，并且该数组的最后一个条目将包含除最后一个匹配的定界符之外的所有输入。<br>如果<code>n</code>为<strong>非正数</strong>，则该pattern将被尽可能多地应用，并且数组可以具有任何长度。<br>如果<code>n</code>为<strong>零</strong>，则该pattern将被尽可能多地应用，该数组可以具有任何长度，并且<strong>尾随的空字符串将被丢弃</strong>。</p>
</blockquote>
<p><strong>Exception</strong>:</p>
<p><strong>空字符串分拆的情况</strong></p>
<p>值得一提的是，只有在拆分机制创建了空字符串，删除尾随的空字符串才有意义。 因此，对于空字符串的分拆<code>&quot;&quot;.split(任何东西)</code>，因为我们无法进一步拆分<code>&quot;&quot;</code>，所以我们将得到结果<code>[&quot;&quot;]</code>数组。发生这种情况是因为此处未发生拆分，因此尽管存在空白，但<code>&quot;&quot;</code>还是尾随表示原始字符串，而不是拆分过程创建的空字符串。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> ~ jshell</span><br><span class="line">|  欢迎使用 JShell -- 版本 <span class="number">15</span></span><br><span class="line">|  要大致了解该版本, 请键入: /help intro</span><br><span class="line"></span><br><span class="line">jshell&gt; String demo=<span class="string">&quot;&quot;</span>;</span><br><span class="line">demo ==&gt; <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">jshell&gt; String[] demoSplit = demo.split(<span class="string">&quot;[,;]&quot;</span>);</span><br><span class="line">demoSplit ==&gt; String[<span class="number">1</span>] &#123; <span class="string">&quot;&quot;</span> &#125;</span><br></pre></td></tr></table></figure>

<h3 id="踢掉空格"><a href="#踢掉空格" class="headerlink" title="踢掉空格"></a>踢掉空格</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; list = Splitter.on(pattern).omitEmptyStrings().splitToList(<span class="string">&quot;&quot;</span>);</span><br><span class="line">System.out.println(list.size());  <span class="comment">// 0</span></span><br></pre></td></tr></table></figure>
<h3 id="StringUtils-split"><a href="#StringUtils-split" class="headerlink" title="StringUtils.split"></a>StringUtils.split</h3><figure class="highlight"><table><tr><td class="code"><pre><span class="line">org.apache.commons.lang.StringUtils#splitByWholeSeparator(java.lang.String, java.lang.String, int)</span><br></pre></td></tr></table></figure>
<p>分割字符串，正则表达式作为普通字符串</p>
]]></content>
  </entry>
  <entry>
    <title>Java8 Time API</title>
    <url>/Java/TimeApiInJava8/</url>
    <content><![CDATA[<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.time.*;</span><br><span class="line"><span class="keyword">import</span> java.time.temporal.TemporalAdjusters;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeApiInJava8</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dateToLocalDate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Date date = <span class="keyword">new</span> Date();</span><br><span class="line">        <span class="keyword">final</span> Instant instant = date.toInstant();</span><br><span class="line">        System.out.println(instant);</span><br><span class="line">        <span class="keyword">final</span> ZoneId defaultZoneId = ZoneId.systemDefault();</span><br><span class="line">        ZonedDateTime atZone = instant.atZone(defaultZoneId);</span><br><span class="line">        <span class="keyword">final</span> LocalDate localDate = atZone.toLocalDate();</span><br><span class="line">        System.out.println(localDate);</span><br><span class="line">        LocalDateTime localDateTime = atZone.toLocalDateTime();</span><br><span class="line">        System.out.println(localDateTime);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dateToLocalDateTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Date date = <span class="keyword">new</span> Date();</span><br><span class="line">        Instant instant = date.toInstant();</span><br><span class="line">        ZoneId systemDefault = ZoneId.systemDefault();</span><br><span class="line">        LocalDateTime.ofInstant(instant, systemDefault);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LocalDateTime <span class="title">longToLocalDateTime</span><span class="params">(Long time)</span> </span>&#123;</span><br><span class="line">        ZoneId systemDefault = ZoneId.systemDefault();</span><br><span class="line">        Instant instant = Instant.ofEpochMilli(time);</span><br><span class="line">        LocalDateTime localDateTime = instant.atZone(systemDefault).toLocalDateTime();</span><br><span class="line">        <span class="keyword">return</span> localDateTime;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">localDateNow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LocalDate now = LocalDate.now();</span><br><span class="line">        System.out.println(<span class="string">&quot;localDateNow: &quot;</span> + now);</span><br><span class="line">        System.out.println(<span class="string">&quot;year: &quot;</span> + now.getYear());</span><br><span class="line">        System.out.println(<span class="string">&quot;month: &quot;</span> + now.getMonthValue());</span><br><span class="line">        System.out.println(<span class="string">&quot;day: &quot;</span> + now.getDayOfMonth());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">localDateDiff</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LocalDate nowLocalDate = LocalDate.of(<span class="number">2019</span>, <span class="number">12</span>, <span class="number">15</span>);</span><br><span class="line">        LocalDate birthLocalDate = LocalDate.of(<span class="number">1986</span>, <span class="number">2</span>, <span class="number">14</span>);</span><br><span class="line">        <span class="keyword">long</span> l = nowLocalDate.toEpochDay() - birthLocalDate.toEpochDay();</span><br><span class="line">        System.out.println(<span class="string">&quot;date diff: &quot;</span> + l);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">firstLastDay</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LocalDate now = LocalDate.now();</span><br><span class="line">        LocalDate firstDayOfMonth = now.with(TemporalAdjusters.firstDayOfMonth());</span><br><span class="line">        LocalDate lastDayOfMonth = now.with(TemporalAdjusters.lastDayOfMonth());</span><br><span class="line">        LocalDate firstDayOfNextYear = now.with(TemporalAdjusters.firstDayOfNextYear());</span><br><span class="line">        LocalDate lastDayOfYear = now.with(TemporalAdjusters.lastDayOfYear());</span><br><span class="line">        LocalDate firstDayOfYear = now.with(TemporalAdjusters.firstDayOfYear());</span><br><span class="line">        System.out.println(<span class="string">&quot;firstDayOfMonth: &quot;</span> + firstDayOfMonth);</span><br><span class="line">        System.out.println(<span class="string">&quot;lastDayOfMonth: &quot;</span> + lastDayOfMonth);</span><br><span class="line">        System.out.println(<span class="string">&quot;firstDayOfNextYear: &quot;</span> + firstDayOfNextYear);</span><br><span class="line">        System.out.println(<span class="string">&quot;lastDayOfYear: &quot;</span> + lastDayOfYear);</span><br><span class="line">        System.out.println(<span class="string">&quot;firstDayOfYear: &quot;</span> + firstDayOfYear);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getDayOfMonth</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LocalDate localDate = LocalDate.of(<span class="number">2019</span>, <span class="number">2</span>, <span class="number">14</span>);</span><br><span class="line">        LocalDate lastDay = localDate.with(TemporalAdjusters.lastDayOfMonth());</span><br><span class="line">        <span class="keyword">int</span> dayOfMonth = lastDay.getDayOfMonth();</span><br><span class="line">        System.out.println(<span class="string">&quot;day of month: &quot;</span> + dayOfMonth);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">localDateCompareTo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LocalDate date1 = LocalDate.of(<span class="number">2018</span>, <span class="number">9</span>, <span class="number">20</span>);</span><br><span class="line">        LocalDate date2 = LocalDate.of(<span class="number">2018</span>, <span class="number">9</span>, <span class="number">21</span>);</span><br><span class="line">        System.out.println(date1 + <span class="string">&quot;.compareTo(&quot;</span> + date2 + <span class="string">&quot;): &quot;</span> + date1.compareTo(date2));</span><br><span class="line">        System.out.println(date1 + <span class="string">&quot;.compareTo(&quot;</span> + date1 + <span class="string">&quot;): &quot;</span> + date1.compareTo(date1));</span><br><span class="line">        System.out.println(date2 + <span class="string">&quot;.compareTo(&quot;</span> + date1 + <span class="string">&quot;): &quot;</span> + date2.compareTo(date1));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextMonth</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        LocalDate localDate = LocalDate.of(<span class="number">2018</span>, <span class="number">2</span>, <span class="number">12</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 下一周的该星期</span></span><br><span class="line">        LocalDate nextWeeks1 = localDate.minusWeeks(-<span class="number">1</span>);</span><br><span class="line">        System.out.println(nextWeeks1);</span><br><span class="line">        <span class="comment">// 2018-02-19</span></span><br><span class="line">        LocalDate nextWeeks2 = localDate.plusWeeks(<span class="number">1</span>);</span><br><span class="line">        System.out.println(nextWeeks2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取下个月的这天</span></span><br><span class="line">        LocalDate nextMonth1 = localDate.minusMonths(-<span class="number">1</span>);</span><br><span class="line">        System.out.println(nextMonth1);</span><br><span class="line">        <span class="comment">// 2018-03-12</span></span><br><span class="line">        LocalDate nextMonth2 = localDate.plusMonths(<span class="number">1</span>);</span><br><span class="line">        System.out.println(nextMonth2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 下个月的1号</span></span><br><span class="line">        LocalDate localDate3 = LocalDate.of(localDate.getYear(), localDate.getMonthValue() + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">        System.out.println(localDate3);</span><br><span class="line">        <span class="comment">// 2018-03-01</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">localDatePeriod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LocalDate date1 = LocalDate.of(<span class="number">2018</span>, <span class="number">10</span>, <span class="number">9</span>);</span><br><span class="line">        LocalDate date2 = LocalDate.of(<span class="number">2019</span>, <span class="number">4</span>, <span class="number">1</span>);</span><br><span class="line">        Period period = Period.between(date1, date2);</span><br><span class="line">        <span class="keyword">int</span> years = period.getYears();</span><br><span class="line">        <span class="keyword">int</span> months = period.getMonths();</span><br><span class="line">        <span class="keyword">int</span> days = period.getDays();</span><br><span class="line">        System.out.println(<span class="string">&quot;years:&quot;</span> + years + <span class="string">&quot;, months:&quot;</span> + months + <span class="string">&quot;, days:&quot;</span> + days);</span><br><span class="line">        <span class="comment">// years:0, months:5, days:23</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ofEpochSecond</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Instant now = Instant.now();</span><br><span class="line">        System.out.println(now);</span><br><span class="line">        <span class="comment">// 2019-03-13T06:41:32.865Z</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 去除毫秒</span></span><br><span class="line">        <span class="keyword">long</span> l = now.toEpochMilli() / <span class="number">1000</span>;</span><br><span class="line">        <span class="comment">// 通过秒构建Instant对象</span></span><br><span class="line">        Instant instant = Instant.ofEpochSecond(l);</span><br><span class="line">        System.out.println(instant);</span><br><span class="line">        <span class="comment">// 2019-03-13T06:41:32Z</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stringToLocalDate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> String string = <span class="string">&quot;2018-12-07&quot;</span>;</span><br><span class="line">        LocalDate parse = LocalDate.parse(string);</span><br><span class="line">        System.out.println(parse.toString());</span><br><span class="line">        <span class="comment">// 结果是2018-12-07</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">localDateTimeToZonedDateTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> String string = <span class="string">&quot;2018-12-07T09:33:38&quot;</span>;</span><br><span class="line">        LocalDateTime parse = LocalDateTime.parse(string);</span><br><span class="line">        ZonedDateTime z1 = ZonedDateTime.of(parse, ZoneId.of(<span class="string">&quot;Asia/Shanghai&quot;</span>));</span><br><span class="line">        System.out.println(z1.toString());</span><br><span class="line">        <span class="comment">// 2018-12-07T09:33:38+08:00[Asia/Shanghai]</span></span><br><span class="line"></span><br><span class="line">        ZonedDateTime z2 = ZonedDateTime.of(parse, ZoneId.of(<span class="string">&quot;Z&quot;</span>));</span><br><span class="line">        System.out.println(z2.toString());</span><br><span class="line">        <span class="comment">// 2018-12-07T09:33:38Z</span></span><br><span class="line"></span><br><span class="line">        ZonedDateTime z3 = ZonedDateTime.of(parse, ZoneId.of(<span class="string">&quot;UTC&quot;</span>));</span><br><span class="line">        System.out.println(z3.toString());</span><br><span class="line">        <span class="comment">// 2018-12-07T09:33:38Z[UTC]</span></span><br><span class="line"></span><br><span class="line">        ZonedDateTime z4 = ZonedDateTime.of(parse, ZoneId.of(<span class="string">&quot;UTC+08:00&quot;</span>));</span><br><span class="line">        System.out.println(z4.toString());</span><br><span class="line">        <span class="comment">// 2018-12-07T09:33:38+08:00[UTC+08:00]</span></span><br><span class="line"></span><br><span class="line">        ZonedDateTime z5 = ZonedDateTime.of(parse, ZoneId.of(<span class="string">&quot;+08:00&quot;</span>));</span><br><span class="line">        System.out.println(z5.toString());</span><br><span class="line">        <span class="comment">// 2018-12-07T09:33:38+08:00</span></span><br><span class="line"></span><br><span class="line">        ZonedDateTime z6 = ZonedDateTime.of(parse, ZoneId.of(<span class="string">&quot;+00:00&quot;</span>));</span><br><span class="line">        System.out.println(z6.toString());</span><br><span class="line">        <span class="comment">// 2018-12-07T09:33:38Z</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(<span class="keyword">final</span> String[] args)</span> </span>&#123;</span><br><span class="line">        TimeApiInJava8 timeApi = <span class="keyword">new</span> TimeApiInJava8();</span><br><span class="line">        timeApi.dateToLocalDate();</span><br><span class="line">        timeApi.dateToLocalDateTime();</span><br><span class="line">        System.out.println(<span class="string">&quot;long to localDateTime: &quot;</span> + timeApi.longToLocalDateTime(System.currentTimeMillis()));</span><br><span class="line">        timeApi.localDateNow();</span><br><span class="line">        timeApi.localDateDiff();</span><br><span class="line">        timeApi.firstLastDay();</span><br><span class="line">        timeApi.getDayOfMonth();</span><br><span class="line">        timeApi.localDateCompareTo();</span><br><span class="line">        timeApi.nextMonth();</span><br><span class="line">        timeApi.localDatePeriod();</span><br><span class="line">        timeApi.ofEpochSecond();</span><br><span class="line">        timeApi.stringToLocalDate();</span><br><span class="line">        timeApi.localDateTimeToZonedDateTime();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Throwable</tag>
      </tags>
  </entry>
  <entry>
    <title>Android网络编程</title>
    <url>/Java/android-network/</url>
    <content><![CDATA[<p>Android 网络开发</p>
<p>网络功能是 Android 的最基本的功能之一, 本文将详细介绍 Android 网络开发.</p>
<ol>
<li>Android网络编程专题之二:搭建测试服务器 目的是为了测试 Android 网络代码</li>
<li>Android网络编程专题之三:模拟简单的网络应用</li>
</ol>
<ul>
<li>下载并显示图片</li>
<li>HttpURLConnection GET和POST请求</li>
<li>HttpClient: apache-commons-httpclient GET和POST请求</li>
<li>WebView</li>
</ul>
<ol start="3">
<li>Android网络编程专题之四:第三方框架</li>
</ol>
<ul>
<li>AsyncHttpClient<ul>
<li>post</li>
<li>get</li>
<li>文件上传</li>
</ul>
</li>
<li>SmartImage</li>
</ul>
<ol start="4">
<li>Android网络编程专题之五:多线程断点下载</li>
</ol>
<h1 id="Android配置"><a href="#Android配置" class="headerlink" title="Android配置"></a>Android配置</h1><p>网络连接需要声明网络服务权限:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">uses-permission</span> <span class="attr">android:name</span>=<span class="string">&quot;android.permission.INTERNET&quot;</span>/&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="简单的服务器端"><a href="#简单的服务器端" class="headerlink" title="简单的服务器端"></a>简单的服务器端</h2><h3 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h3><p>为了支持Android的网络测试，搭建一个服务器端工程，满足如下几个要求：</p>
<ol>
<li>并支持Session和Cookie</li>
<li>支持文件上传</li>
<li>图片查看</li>
</ol>
<p>访问<code>/SimpleServer</code>进入登陆界面</p>
<p><img src="/images/android/network/android-network-SimpleServer-index.png"></p>
<p>登陆成功，显示相关的信息</p>
<p><img src="/images/android/network/android-network-SimpleServer-loginSuccess.png"></p>
<p>登陆失败，显示失败信息</p>
<p><img src="/images/android/network/android-network-SimpleServer-loginFailure.png"></p>
<p>下载图片地址</p>
<p><code>/SimpleServer/gyy.jpg</code></p>
<p><img src="/images/android/network/android-network-SimpleServer-image.png"></p>
<p>文件上传</p>
<p><code>/SimpleServer/uploadFile.jsp</code></p>
<p><img src="/images/android/network/android-network-SimpleServer-uploadServer1.png"></p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>Eclipse工程目录如下</p>
<p><img src="/images/android/network/android-network-SimpleServer-project.png"></p>
<ol>
<li>创建打开<code>/SimpleServer/</code>的默认页面<code>login.jsp</code></li>
</ol>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot;</span><br><span class="line">	pageEncoding=&quot;UTF-8&quot;%&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;Content-Type&quot;</span> <span class="attr">content</span>=<span class="string">&quot;text/html; charset=UTF-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>登陆<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;login&quot;</span> <span class="attr">method</span>=<span class="string">&quot;get&quot;</span>&gt;</span></span><br><span class="line">		姓名:<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;name&quot;</span> &gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">		密码:<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> &gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;get 提交&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">hr</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;login&quot;</span> <span class="attr">method</span>=<span class="string">&quot;post&quot;</span>&gt;</span></span><br><span class="line">		姓名:<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;name&quot;</span> &gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">		密码:<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> &gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;post 提交&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>上面有两个表单，分别用于使用<code>get</code>方法和<code>post</code>方法请求，发送请求到action–<code>login</code></p>
<ol start="2">
<li>在<code>web.xml</code>中注册</li>
</ol>
<p>在<code>web-app</code>节点下创建<code>welcome-file-list</code>子节点<br>添加页面</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">web-app</span> <span class="attr">...</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">welcome-file-list</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">welcome-file</span>&gt;</span>login.jsp<span class="tag">&lt;/<span class="name">welcome-file</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">welcome-file-list</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><code>welcome-file</code>是默认的欢迎页面，在不指定子页面的情况下，按照<code>welcome-file-list</code>的顺序寻找页面，直到找到页面。<br>如果所有的页面都找不到，则只能显示404了</p>
<ol start="3">
<li>在<code>web.xml</code>中注册login action</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>login<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>club.guadazi.ss.LoginAction<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>login<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/login<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol start="4">
<li>LoginAction</li>
</ol>
<p>页面登陆，登陆成功后将用户名记录到Session中，如果Session中用户名不为null则代表已经登陆。<br>如果登陆失败，输出错误信息。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> club.guadazi.ss;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginAction</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">LoginAction</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doPost</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span></span></span><br><span class="line"><span class="function">   <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">		HttpSession session = req.getSession();</span><br><span class="line">		Object pwdAttribute = req.getParameter(<span class="string">&quot;password&quot;</span>);</span><br><span class="line">		Object nameAttribute = req.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">		<span class="keyword">if</span> (pwdAttribute != <span class="keyword">null</span> &amp;&amp; <span class="string">&quot;abc.123&quot;</span>.equals((String) pwdAttribute)</span><br><span class="line">    &amp;&amp; nameAttribute != <span class="keyword">null</span>) &#123;</span><br><span class="line">			String name = (String) nameAttribute;</span><br><span class="line">			session.setAttribute(<span class="string">&quot;name&quot;</span>, name);</span><br><span class="line">			resp.setContentType(<span class="string">&quot;text/html;charset=utf-8&quot;</span>);</span><br><span class="line">			resp.sendRedirect(<span class="string">&quot;info.jsp&quot;</span>);</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			resp.setContentType(<span class="string">&quot;text/html;charset=utf-8&quot;</span>);</span><br><span class="line">			PrintWriter writer = resp.getWriter();</span><br><span class="line">			writer.print(<span class="string">&quot;&lt;html&gt;&lt;head&gt;&quot;</span>);</span><br><span class="line">			writer.print(<span class="string">&quot;&lt;title&gt;&quot;</span> + <span class="string">&quot;欢迎 post&quot;</span> + <span class="string">&quot;&lt;/title&gt;&quot;</span>);</span><br><span class="line">			writer.print(<span class="string">&quot;&lt;/head&gt;&quot;</span>);</span><br><span class="line">			writer.print(<span class="string">&quot;&lt;center&gt;登陆失败!&lt;/center&gt;&quot;</span>);</span><br><span class="line">			writer.flush();</span><br><span class="line">			writer.close();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span></span></span><br><span class="line"><span class="function">   <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">		doPost(req, resp);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Servlet实现的过程，继承HttpServlet，HttpServlet类含有处理post和get请求的方法，重写相应的方法即可。<br>Session用于保存一次会话的所有信息，Session以键值对的形式保存信息。常常用于记录登陆信息，当登陆成功后记录用户信息到Session，<br>在其他的页面上可以判断是否登陆，如果未登陆，则显示登陆页面。<br><code>HttpServletRequest.getParameter</code>可以获取页面表单在发请求时携带的参数。<br><code>resp.sendRedirect(&quot;info.jsp&quot;);</code>页面重定向</p>
<ol start="5">
<li>info.jsp 登陆成功后显示的页面</li>
</ol>
<p>需要在头部增加Session中用户名判断信息</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&lt;%</span><br><span class="line">	HttpSession session2 = request.getSession();</span><br><span class="line">	Object nameObject = session2.getAttribute(&quot;name&quot;);</span><br><span class="line">	if (nameObject == null) &#123;</span><br><span class="line">		/* 		response.sendRedirect(&quot;/SimpleServer&quot;); */</span><br><span class="line">%&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">center</span>&gt;</span></span><br><span class="line">	未登录 <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/SimpleServer&quot;</span>&gt;</span>点击登陆<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">center</span>&gt;</span></span><br><span class="line">&lt;%</span><br><span class="line">	return;</span><br><span class="line">	&#125;</span><br><span class="line">%&gt;</span><br></pre></td></tr></table></figure>
<p>当为登陆时不再显示下面的信息直接return</p>
<ol start="6">
<li>上传文件页面</li>
</ol>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;uploadFileAction&quot;</span> <span class="attr">enctype</span>=<span class="string">&quot;multipart/form-data&quot;</span></span></span><br><span class="line"><span class="tag">  <span class="attr">method</span>=<span class="string">&quot;post&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;file&quot;</span> <span class="attr">name</span>=<span class="string">&quot;filename&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">value</span>=<span class="string">&quot;Press&quot;</span>&gt;</span> to upload the file!</span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><code>enctype</code>必须指定为<code>multipart/form-data</code></p>
<ol start="7">
<li>上传文件Action</li>
</ol>
<p>使用Apache的commons-fileupload工具包在doPost方法中实现上传文件<br>commons-fileupload依赖commons-io包</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DiskFileItemFactory factory = <span class="keyword">new</span> DiskFileItemFactory();</span><br><span class="line">ServletFileUpload fileUpload = <span class="keyword">new</span> ServletFileUpload(factory);</span><br><span class="line"><span class="keyword">if</span> (!ServletFileUpload.isMultipartContent(req)) &#123;</span><br><span class="line">  PrintWriter writer = resp.getWriter();</span><br><span class="line">  writer.println(<span class="string">&quot;is not multipart content!&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  List&lt;FileItem&gt; list = fileUpload.parseRequest(req);</span><br><span class="line">  <span class="keyword">for</span> (FileItem fileItem : list) &#123;</span><br><span class="line">    <span class="keyword">if</span> (fileItem.isFormField()) &#123;</span><br><span class="line">      String name = fileItem.getName();</span><br><span class="line">      String value = fileItem.getString();</span><br><span class="line">      ServletOutputStream outputStream = resp.getOutputStream();</span><br><span class="line">      outputStream.write((name + <span class="string">&quot;:&quot;</span> + value).getBytes());</span><br><span class="line">      outputStream.close();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      String fileName = fileItem.getName();</span><br><span class="line">      String realPath = <span class="comment">/* this.getServletContext().getRealPath */</span>(<span class="string">&quot;/Users/Mariaaron/upload/&quot;</span>);</span><br><span class="line">      System.out.println(realPath);</span><br><span class="line">      FileOutputStream out = <span class="keyword">new</span> FileOutputStream(realPath + fileName);</span><br><span class="line">      InputStream in = fileItem.getInputStream();</span><br><span class="line">      <span class="keyword">byte</span> buffer[] = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">      <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">while</span> ((len = in.read(buffer)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        out.write(buffer, <span class="number">0</span>, len);</span><br><span class="line">      &#125;</span><br><span class="line">      out.close();</span><br><span class="line">      in.close();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (FileUploadException e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>源文件与war包的<a href="http://pan.baidu.com/s/1qW89zyc" title="SimpleServer源码与war包下载">下载地址</a></p>
<h1 id="简单网络操作"><a href="#简单网络操作" class="headerlink" title="简单网络操作"></a>简单网络操作</h1><p>Android 网络</p>
<h2 id="Android-网络连接线程"><a href="#Android-网络连接线程" class="headerlink" title="Android 网络连接线程"></a>Android 网络连接线程</h2><ol>
<li>在 Android 中, 主线程负责更新 UI, 因此,主线程也称为 UI 线程.</li>
<li>除了ProcessBar等几个少数的控件外, 几乎所有的 UI 控件必须在主线程更新.</li>
<li>为了防止 UI 载入和更新出现卡顿, 网络连接/大图片载入以及一些大型的计算必须在子线程进行.</li>
<li>网络操作必须放在子线程, 在子线程使用 Handler 更新 UI.<br>异步框架<code>AsyncHttpClient</code>就是基于这个原理实现的.</li>
</ol>
<p>Android提供了在子线程更新 UI 的 API:<br><code>Activity.runOnUiThread(Thread thread)</code> 方法,将 Runnable 中的任务放到UI 线程执行:<br/><br>// 如果当前线程就是UI 线程立即执行,否者将把 Runnable 线程 join 到UI 线程中执行.</p>
<h2 id="Java-Socket"><a href="#Java-Socket" class="headerlink" title="Java Socket"></a>Java Socket</h2><blockquote>
<p>android简单聊天工具</p>
</blockquote>
<h2 id="URL"><a href="#URL" class="headerlink" title="URL"></a>URL</h2><p>类 URL 代表一个统一资源定位符，它是指向互联网“资源”的指针。</p>
<p>创建一个到 URL 的连接需要几个步骤：</p>
<p>  openConnection() ———— 时间 —————-&gt;    connect()<br>对影响到远程资源连接的参数进行操作 ———— 时间 —————-&gt; 与资源交互；查询头字段和内容。</p>
<ol>
<li>通过在 URL 上调用 openConnection 方法创建连接对象。</li>
<li>处理设置参数和一般请求属性。</li>
<li>使用 connect 方法建立到远程对象的实际连接。</li>
<li>远程对象变为可用。远程对象的头字段和内容变为可访问。</li>
</ol>
<p>使用以下方法修改设置参数：</p>
<p>   setAllowUserInteraction<br>   setDoInput<br>   setDoOutput<br>   setIfModifiedSince<br>   setUseCaches</p>
<p>使用以下方法修改一般请求属性：</p>
<p>   setRequestProperty</p>
<p>使用 setDefaultAllowUserInteraction 和 setDefaultUseCaches 可设置 AllowUserInteraction 和 UseCaches 参数的默认值。</p>
<p>上面每个 set 方法都有一个用于获取参数值或一般请求属性值的对应 get 方法。适用的具体参数和一般请求属性取决于协议。</p>
<p>在建立到远程对象的连接后，以下方法用于访问头字段和内容：</p>
<p>   getContent<br>   getHeaderField<br>   getInputStream<br>   getOutputStream</p>
<p>某些头字段需要经常访问。以下方法：</p>
<p>   getContentEncoding<br>   getContentLength<br>   getContentType<br>   getDate<br>   getExpiration<br>   getLastModifed</p>
<p>提供对这些字段的便捷访问。getContent 方法使用 getContentType 方法以确定远程对象类型；子类重写 getContentType 方法很容易。</p>
<p>一般情况下，所有的预连接参数和一般请求属性都可忽略：预连接参数和一般请求属性默认为敏感值。对于此接口的大多数客户端而言，只有两个需要的方法：getInputStream 和 getContent，它们通过便捷方法镜像到 URL 类中。</p>
<h2 id="URLConnection"><a href="#URLConnection" class="headerlink" title="URLConnection"></a>URLConnection</h2><p>例子: 布局文件中的Button被调用时，调用loadImage方法</p>
<p>在loadImage方法中</p>
<ol>
<li>判断收入的图片地址是否为空</li>
<li>启动新的子线程，在子线程中</li>
</ol>
<p>`URLConnection urlConnection = url.openConnection();’<br>返回一个 URLConnection 对象，它表示到 URL 所引用的远程对象的连接。<br>每次调用此 URL 的协议处理程序的 openConnection 方法都打开一个新的连接。</p>
<p>如果 URL 的协议（例如，HTTP 或 JAR）存在属于以下包或其子包之一的公共、专用 URLConnection 子类：java.lang、java.io、java.util、java.net，<br>返回的连接将为该子类的类型。例如，对于 HTTP，将返回 HttpURLConnection，对于 JAR，将返回 JarURLConnection。</p>
<p>‘InputStream inputStream = urlConnection.getInputStream();’<br>从打开的连接读取输入流</p>
<blockquote>
<p>‘InputStream inputStream = urlConnection.openStream();’<br>是<code>openConnection().getInputStream()</code>的缩写形式。</p>
</blockquote>
<p>‘Bitmap bitmap = BitmapFactory.decodeStream(inputStream);`<br>把输入流解码成位图对象</p>
<ol start="3">
<li><p>创建Message，将位图对象作为<code>Message.obj</code>, 向Handler发送消息</p>
</li>
<li><p>Handler执行，更新UI</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> ImageView imageView;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">loadImage</span><span class="params">(View view)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">final</span> String imageUrl = imageUrlEdit.getText().toString().trim();</span><br><span class="line">   <span class="keyword">if</span> (TextUtils.isEmpty(imageUrl)) &#123;</span><br><span class="line">       <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               URL url = <span class="keyword">new</span> URL(imageUrl);</span><br><span class="line">               HttpURLConnection urlConnection = (HttpURLConnection) url.openConnection();</span><br><span class="line">               urlConnection.setRequestMethod(<span class="string">&quot;GET&quot;</span>);</span><br><span class="line">               <span class="keyword">if</span> (urlConnection.getResponseCode() == <span class="number">200</span>) &#123;</span><br><span class="line">                   InputStream inputStream = urlConnection.getInputStream();</span><br><span class="line">                   Bitmap bitmap;</span><br><span class="line">                   bitmap = BitmapFactory.decodeStream(inputStream);</span><br><span class="line">                   Message message = <span class="keyword">new</span> Message();</span><br><span class="line">                   message.what = SHOW_IMAGE_BY_URL;</span><br><span class="line">                   message.obj = bitmap;</span><br><span class="line">                   handler.sendMessage(message);</span><br><span class="line">               &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                   Toast.makeText(MainActivity.<span class="keyword">this</span>, <span class="string">&quot;请求失败!&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">               &#125;</span><br><span class="line">           &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">               e.printStackTrace();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;.start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">loadImage2</span><span class="params">(View view)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">final</span> String imageUrl = imageUrlEdit.getText().toString().trim();</span><br><span class="line">   <span class="keyword">if</span> (TextUtils.isEmpty(imageUrl)) &#123;</span><br><span class="line">       <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               URL url = <span class="keyword">new</span> URL(imageUrl);</span><br><span class="line">               HttpURLConnection urlConnection = (HttpURLConnection) url.openConnection();</span><br><span class="line">               urlConnection.setRequestMethod(<span class="string">&quot;GET&quot;</span>);</span><br><span class="line">               <span class="keyword">if</span> (urlConnection.getResponseCode() == <span class="number">200</span>) &#123;</span><br><span class="line">                   InputStream inputStream = urlConnection.getInputStream();</span><br><span class="line">                   <span class="keyword">final</span> Bitmap bitmap = BitmapFactory.decodeStream(inputStream);</span><br><span class="line">                   <span class="comment">/**</span></span><br><span class="line"><span class="comment">                    * runOnUiThread 方法,将 Runnable 中的任务放到UI 线程执行:&lt;br/&gt;</span></span><br><span class="line"><span class="comment">                    * 如果当前线程就是UI 线程立即执行,否者将把 Runnable 线程 join 到UI 线程中执行.</span></span><br><span class="line"><span class="comment">                    */</span></span><br><span class="line">                   runOnUiThread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                       <span class="meta">@Override</span></span><br><span class="line">                       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                           imageView.setImageBitmap(bitmap);</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125;);</span><br><span class="line">               &#125;</span><br><span class="line">           &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">               e.printStackTrace();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;.start();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> Handler handler = <span class="keyword">new</span> Handler() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleMessage</span><span class="params">(Message msg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">switch</span> (msg.what) &#123;</span><br><span class="line">            <span class="keyword">case</span> showImageByUrl:</span><br><span class="line">                Bitmap bitmap = (Bitmap) msg.obj;</span><br><span class="line">                imageView.setImageBitmap(bitmap);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onCreate(savedInstanceState);</span><br><span class="line">    setContentView(R.layout.activity_main);</span><br><span class="line">    imageView = (ImageView) findViewById(R.id.iv);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="HttpURLConnection"><a href="#HttpURLConnection" class="headerlink" title="HttpURLConnection"></a>HttpURLConnection</h2><p>对于上面的例子，URL的scheme是HTTP类型的，<code>URL.openConnection</code>返回的对象就是<code>HttpURLConnection</code>对象。</p>
<p>get和post方式发送登录请求的代码和纯Java环境是一模一样的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loginUrlGet</span><span class="params">(<span class="keyword">final</span> String name, <span class="keyword">final</span> String password)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        String path = loginPath + <span class="string">&quot;?name=&quot;</span> + name + <span class="string">&quot;&amp;password=&quot;</span> + password;</span><br><span class="line">        URL url = <span class="keyword">new</span> URL(path);</span><br><span class="line">        HttpURLConnection urlConnection = (HttpURLConnection) url.openConnection();</span><br><span class="line">        urlConnection.setRequestMethod(<span class="string">&quot;GET&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (urlConnection.getResponseCode() == <span class="number">200</span>) &#123;</span><br><span class="line">            InputStream inputStream = urlConnection.getInputStream();</span><br><span class="line">            String content = readAsString(inputStream);</span><br><span class="line">            showResponseOnWebView(content);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            Toast.makeText(MainActivity.<span class="keyword">this</span>, <span class="string">&quot;请求失败!&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loginUrlPost</span><span class="params">(<span class="keyword">final</span> String name, <span class="keyword">final</span> String password)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Map&lt;String, String&gt; requestParams = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">        requestParams.put(<span class="string">&quot;name&quot;</span>, name);</span><br><span class="line">        requestParams.put(<span class="string">&quot;password&quot;</span>, password);</span><br><span class="line">        StringBuilder params = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry : requestParams.entrySet()) &#123;</span><br><span class="line">            params.append(entry.getKey());</span><br><span class="line">            params.append(<span class="string">&quot;=&quot;</span>);</span><br><span class="line">            params.append(URLEncoder.encode(entry.getValue(), <span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line">            params.append(<span class="string">&quot;&amp;&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (params.length() &gt; <span class="number">0</span>) params.deleteCharAt(params.length() - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">byte</span>[] data = params.toString().getBytes();</span><br><span class="line">        URL url = <span class="keyword">new</span> URL(loginPath);</span><br><span class="line">        HttpURLConnection conn = (HttpURLConnection) url.openConnection();</span><br><span class="line">        conn.setRequestMethod(<span class="string">&quot;POST&quot;</span>);<span class="comment">//必须大写</span></span><br><span class="line">        conn.setDoOutput(<span class="keyword">true</span>);</span><br><span class="line">        conn.setRequestProperty(<span class="string">&quot;Connection&quot;</span>, <span class="string">&quot;Keep-Alive&quot;</span>);<span class="comment">//维持长连接</span></span><br><span class="line">        conn.setRequestProperty(<span class="string">&quot;Charset&quot;</span>, <span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line">        conn.setRequestProperty(<span class="string">&quot;Content-Length&quot;</span>, String.valueOf(data.length));</span><br><span class="line">        conn.setRequestProperty(<span class="string">&quot;Content-Type&quot;</span>, <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>);</span><br><span class="line">        DataOutputStream outStream = <span class="keyword">new</span> DataOutputStream(conn.getOutputStream());</span><br><span class="line">        outStream.write(data);</span><br><span class="line">        outStream.flush();</span><br><span class="line">        <span class="keyword">if</span> (conn.getResponseCode() == <span class="number">200</span>) &#123;</span><br><span class="line">            String result = readAsString(conn.getInputStream());</span><br><span class="line">            outStream.close();</span><br><span class="line">            showResponseOnWebView(result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (MalformedURLException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的例子只是实现了登录，如果当服务器端使用了Session时，再访问其他页面登录信息是无法联系起来的。<br>而HttpClient可以</p>
<h3 id="多线程下载"><a href="#多线程下载" class="headerlink" title="多线程下载"></a>多线程下载</h3><p>见 <a href="#nulti_download">下文</a></p>
<h2 id="HttpClient-apache-commons-httpclient"><a href="#HttpClient-apache-commons-httpclient" class="headerlink" title="HttpClient: apache-commons-httpclient"></a>HttpClient: apache-commons-httpclient</h2><p>HttpClient类似于Http的客户端，也就是浏览器。<br>它会保存会话，记录登录信息，Cookie等</p>
<p>看登录并访问的例子</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loginHttpClientPost</span><span class="params">(String name, String password)</span> </span>&#123;</span><br><span class="line">    HttpClient httpClient = <span class="keyword">new</span> DefaultHttpClient();</span><br><span class="line">    HashMap&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">    map.put(<span class="string">&quot;name&quot;</span>, name);</span><br><span class="line">    map.put(<span class="string">&quot;password&quot;</span>, password);</span><br><span class="line">    String path = loginPath;</span><br><span class="line">    path += <span class="string">&quot;?&quot;</span>;</span><br><span class="line">    Set&lt;Map.Entry&lt;String, String&gt;&gt; entries = map.entrySet();</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry : entries) &#123;</span><br><span class="line">        String key = entry.getKey();</span><br><span class="line">        String value = entry.getValue();</span><br><span class="line">        path += key + <span class="string">&quot;=&quot;</span> + value;</span><br><span class="line">        path += <span class="string">&quot;&amp;&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    path = path.substring(<span class="number">0</span>, path.length() - <span class="number">1</span>);</span><br><span class="line">    HttpPost httpPost = <span class="keyword">new</span> HttpPost(path);</span><br><span class="line">    String responseString = <span class="string">&quot;&quot;</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        HttpResponse response = httpClient.execute(httpPost);</span><br><span class="line">        <span class="keyword">if</span> (response.getStatusLine().getStatusCode() == <span class="number">200</span>) &#123;</span><br><span class="line">            responseString = EntityUtils.toString(response.getEntity());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            responseString = <span class="string">&quot;Error Response: &quot;</span></span><br><span class="line">                    + response.getStatusLine().toString();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    showResponseOnWebView(responseString);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loginHttpClientGet</span><span class="params">(<span class="keyword">final</span> String name, <span class="keyword">final</span> String password)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建 HttpParams 以用来设置 HTTP 参数（这一部分不是必需的）</span></span><br><span class="line">    BasicHttpParams httpParams = <span class="keyword">new</span> BasicHttpParams();</span><br><span class="line">    <span class="comment">// 设置连接超时和 Socket 超时，以及 Socket 缓存大小</span></span><br><span class="line">    HttpConnectionParams.setConnectionTimeout(httpParams, <span class="number">20</span> * <span class="number">1000</span>);</span><br><span class="line">    HttpConnectionParams.setSoTimeout(httpParams, <span class="number">20</span> * <span class="number">1000</span>);</span><br><span class="line">    HttpConnectionParams.setSocketBufferSize(httpParams, <span class="number">8192</span>);</span><br><span class="line">    <span class="comment">// 设置重定向，缺省为 true</span></span><br><span class="line">    HttpClientParams.setRedirecting(httpParams, <span class="keyword">true</span>);</span><br><span class="line">    <span class="comment">// 设置 user agent</span></span><br><span class="line">    String userAgent = <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.2) Gecko/20100115 Firefox/3.6&quot;</span>;</span><br><span class="line">    HttpProtocolParams.setUserAgent(httpParams, userAgent);</span><br><span class="line">    <span class="comment">// 创建一个 HttpClient 实例</span></span><br><span class="line">    <span class="comment">// 注意 HttpClient httpClient = new HttpClient(); 是Commons HttpClient</span></span><br><span class="line">    <span class="comment">// 中的用法，在 Android 1.5 中我们需要使用 Apache 的缺省实现 DefaultHttpClient</span></span><br><span class="line">    HttpClient httpClient = <span class="keyword">new</span> DefaultHttpClient(httpParams);</span><br><span class="line">    Map params2 = <span class="keyword">new</span> HashMap();</span><br><span class="line">    params2.put(<span class="string">&quot;name&quot;</span>, name);</span><br><span class="line">    params2.put(<span class="string">&quot;password&quot;</span>, password);</span><br><span class="line">    String url = loginPath;</span><br><span class="line">     <span class="comment">/* 建立HTTPGet对象 */</span></span><br><span class="line">    String paramStr = <span class="string">&quot;&quot;</span>;</span><br><span class="line">    Iterator iter = params2.entrySet().iterator();</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        Map.Entry entry = (Map.Entry) iter.next();</span><br><span class="line">        Object key = entry.getKey();</span><br><span class="line">        Object val = entry.getValue();</span><br><span class="line">        paramStr += paramStr = <span class="string">&quot;&amp;&quot;</span> + key + <span class="string">&quot;=&quot;</span> + val;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!paramStr.equals(<span class="string">&quot;&quot;</span>)) &#123;</span><br><span class="line">        paramStr = paramStr.replaceFirst(<span class="string">&quot;&amp;&quot;</span>, <span class="string">&quot;?&quot;</span>);</span><br><span class="line">        url += paramStr;</span><br><span class="line">    &#125;</span><br><span class="line">    HttpGet httpGet = <span class="keyword">new</span> HttpGet(url);</span><br><span class="line">    String strResult = <span class="string">&quot;doGetError&quot;</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">/* 发送请求并等待响应 */</span></span><br><span class="line">        HttpResponse httpResponse = httpClient.execute(httpGet);</span><br><span class="line">        <span class="comment">/* 若状态码为200 ok */</span></span><br><span class="line">        <span class="keyword">if</span> (httpResponse.getStatusLine().getStatusCode() == <span class="number">200</span>) &#123;</span><br><span class="line">            <span class="comment">/* 读返回数据 */</span></span><br><span class="line">            strResult = EntityUtils.toString(httpResponse.getEntity());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            strResult = <span class="string">&quot;Error Response: &quot;</span></span><br><span class="line">                    + httpResponse.getStatusLine().toString();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ClientProtocolException e) &#123;</span><br><span class="line">        strResult = e.getMessage().toString();</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        strResult = e.getMessage().toString();</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        strResult = e.getMessage().toString();</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    showResponseOnWebView(strResult);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<a href="3">示例工程</a>中, 服务器端在登录成功后会跳转到info.jsp页面，详见第一节</p>
<p>使用URLConnection是无法实现的。而HttpClient可以实现跳转并显示登录信息。</p>
<h2 id="WebView"><a href="#WebView" class="headerlink" title="WebView"></a>WebView</h2><p>WebView是Android内置的WebKit内核网页显示控件，使用WebView可以显示本地和网站页面。so powerful!<br>默认使用UTF-8编码</p>
<h3 id="显示本地页面中文乱码"><a href="#显示本地页面中文乱码" class="headerlink" title="显示本地页面中文乱码"></a>显示本地页面中文乱码</h3><p>显示本地页面可以使用的API有：loadData 和loadDataWithBaseURL</p>
<p>WebView.loadData(content, “text/html”, “UTF-8”);出现中文乱码了，<br>改成 loadData(data, “text/html; charset=UTF-8”, null);就不会乱码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">WebView.loadDataWithBaseURL(basePath, content, <span class="string">&quot;text/html&quot;</span>, <span class="string">&quot;utf-8&quot;</span>, <span class="keyword">null</span>);<span class="comment">// 可以正常显示</span></span><br><span class="line">WebView.loadDataWithBaseURL(<span class="keyword">null</span>, content, <span class="string">&quot;text/html&quot;</span>, <span class="string">&quot;utf-8&quot;</span>, <span class="keyword">null</span>);<span class="comment">// 无乱码 但无法显示图片</span></span><br></pre></td></tr></table></figure>
<p>使用loadDataWithBaseURL时,如果不传入URL时,刷新会造成白屏,因为刷新时调用的的是reload方法,<br>reload是根据传入的URL进行一次重新加载即再次loadUrl(url),不传入URL时,默认的的URL是about:blank</p>
<p>使用loadData,刷新只是从缓存里面取，但是在4.0以上的,如果按照API里所写的loadData(data, “UTF-8”, null);时会乱码,<br>如果写成<code>loadData(data, &quot;text/html; charset=UTF-8&quot;, null);</code><br>loadData最终的机制是会把传入的三个参数拼接在一起,<br>然后再进行loadUrl操作,参数就是data, “text/html; charset=UTF-8”, null这三个进行拼装,加入text/html; charset=UTF-8就相当于限定了页面的字符</p>
<p>loadData(detail,”text/html;charset=UTF-8”, null); 在小米 One S上仍然存在中文乱码的情况，<br>改成 WebView.loadDataWithBaseURL(null, detail, “text/html”, “UTF-8”, null); 就没问题。<br>在小米手机上设置<code>settings.setDefaultTextEncodingName(&quot;utf-8&quot;)</code><br>在 webview 的 settings 属性里指定 utf-8 就可以了</p>
<h1 id="第三方框架"><a href="#第三方框架" class="headerlink" title="第三方框架"></a>第三方框架</h1><h2 id="AsyncHttpClient"><a href="#AsyncHttpClient" class="headerlink" title="AsyncHttpClient"></a>AsyncHttpClient</h2><p><a href="https://github.com/loopj/android-async-http">Github的地址</a></p>
<h3 id="get"><a href="#get" class="headerlink" title="get"></a>get</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">loginASyncHttpGet</span><span class="params">(String name, String password)</span> </span>&#123;</span><br><span class="line">    AsyncHttpClient asyncHttpClient = <span class="keyword">new</span> AsyncHttpClient();</span><br><span class="line">    RequestParams requestParams = <span class="keyword">new</span> RequestParams();</span><br><span class="line">    requestParams.put(<span class="string">&quot;name&quot;</span>, name);</span><br><span class="line">    requestParams.put(<span class="string">&quot;password&quot;</span>, password);</span><br><span class="line">    asyncHttpClient.get(loginPath, requestParams, <span class="keyword">new</span> AsyncHttpResponseHandler() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> s;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="post"><a href="#post" class="headerlink" title="post"></a>post</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">loginASyncHttpPost</span><span class="params">(String name, String password)</span> </span>&#123;</span><br><span class="line">    AsyncHttpClient asyncHttpClient = <span class="keyword">new</span> AsyncHttpClient();</span><br><span class="line">    RequestParams requestParams = <span class="keyword">new</span> RequestParams();</span><br><span class="line">    requestParams.put(<span class="string">&quot;name&quot;</span>, name);</span><br><span class="line">    requestParams.put(<span class="string">&quot;password&quot;</span>, password);</span><br><span class="line">    asyncHttpClient.post(loginPath, requestParams, <span class="keyword">new</span> AsyncHttpResponseHandler() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> s;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">uploadFileAsyncHttpClient</span><span class="params">(String  selectFilePath)</span> </span>&#123;</span><br><span class="line">    File file = <span class="keyword">new</span> File(selectFilePath);</span><br><span class="line">    <span class="keyword">if</span> (file.exists() &amp;&amp; file.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        AsyncHttpClient client = <span class="keyword">new</span> AsyncHttpClient();</span><br><span class="line">        RequestParams params = <span class="keyword">new</span> RequestParams();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            params.put(<span class="string">&quot;profile_picture&quot;</span>, file);</span><br><span class="line"></span><br><span class="line">            client.post(uploadUrlEditTex.getText().toString(), params, <span class="keyword">new</span> AsyncHttpResponseHandler() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">                    Toast.makeText(MainActivity.<span class="keyword">this</span>, <span class="string">&quot;文件上传成功!&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Throwable throwable, String s)</span> </span>&#123;</span><br><span class="line">                    Toast.makeText(MainActivity.<span class="keyword">this</span>, <span class="string">&quot;文件上传失败!&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Toast.makeText(<span class="keyword">this</span>, <span class="string">&quot;文件不存在&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SmartImage"><a href="#SmartImage" class="headerlink" title="SmartImage"></a>SmartImage</h2><p><a href="https://github.com/loopj/android-smart-image-view">Github地址</a></p>
<p><a href="http://loopj.com/android-smart-image-view/">官网</a></p>
<h1 id="多线程断点下载"><a href="#多线程断点下载" class="headerlink" title="多线程断点下载"></a>多线程断点下载</h1><p><a href="http://pan.baidu.com/s/1pJDvG6Z" title="多线程下载">示例代码下载地址</a></p>
<h2 id="多线程下载-1"><a href="#多线程下载-1" class="headerlink" title="多线程下载"></a>多线程下载</h2><p><a name="nulti_download">多线程下载</a>即将一个文件分割成若干部分，交给多个线程同时去下载，每个线程下载文件的一部分。以达到提速的目的。</p>
<p>为了实现多线程下载，需要如下几个步骤：</p>
<ol>
<li>为每个线程分配要下载的文件的位置</li>
<li>在本地创建同等大小的文件区域</li>
<li>从服务器下载文件的某一段数据</li>
<li>每个线程下载指定位置的数据并写入文件对应的位置</li>
</ol>
<h3 id="为每个线程分配要下载的文件的位置"><a href="#为每个线程分配要下载的文件的位置" class="headerlink" title="为每个线程分配要下载的文件的位置"></a>为每个线程分配要下载的文件的位置</h3><p><img src="/images/android/network/android-network-multidownload-dispatcher.png"></p>
<h3 id="在本地创建同等大小的文件区域"><a href="#在本地创建同等大小的文件区域" class="headerlink" title="在本地创建同等大小的文件区域"></a>在本地创建同等大小的文件区域</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 创建文件，大小与待下载的文件大小一致</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> objPath 创建文件文件名，包含完整路径</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> fileLength 文件的长度</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">createFile</span><span class="params">(String  objPath,<span class="keyword">long</span> fileLength)</span> </span>&#123;</span><br><span class="line">	RandomAccessFile raf = <span class="keyword">null</span>;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		raf = <span class="keyword">new</span> RandomAccessFile(objPath, <span class="string">&quot;rwd&quot;</span>);</span><br><span class="line">		raf.setLength(fileLength);</span><br><span class="line">		raf.close();</span><br><span class="line">	&#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">		e.printStackTrace();</span><br><span class="line">	&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">		e.printStackTrace();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="从服务器下载文件的某一段数据"><a href="#从服务器下载文件的某一段数据" class="headerlink" title="从服务器下载文件的某一段数据"></a>从服务器下载文件的某一段数据</h3><p>在HTTP协议中， RequestProperty <code>Range</code>用于指定下载文件片段的范围<br>格式为<code>&quot;bytes=&lt;开始位置&gt;-&lt;结束位置&gt;&quot;</code><br>一旦设定了Range属性，服务器会返回 206，表示支持部分下载。<br>不设定Range属性，服务器返回 200，表示连接正常, 可以下载。</p>
<p>因此发送请求的格式为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//downloadUrl为下载文件的网址</span></span><br><span class="line">URL url = <span class="keyword">new</span> URL(downloadUrl);</span><br><span class="line"><span class="comment">//打开远程连接</span></span><br><span class="line">HttpURLConnection conn = (HttpURLConnection) url.openConnection();</span><br><span class="line">conn.setRequestMethod(<span class="string">&quot;GET&quot;</span>);</span><br><span class="line"><span class="comment">//设置下载的位置</span></span><br><span class="line">conn.setRequestProperty(<span class="string">&quot;Range&quot;</span>, <span class="string">&quot;bytes=&quot;</span> + startPosition + <span class="string">&quot;-&quot;</span> + endPosition);</span><br><span class="line"><span class="keyword">if</span> (<span class="number">206</span> == conn.getResponseCode())</span><br><span class="line"><span class="comment">// DO SOMETHING</span></span><br></pre></td></tr></table></figure>
<h3 id="每个线程下载指定位置的数据并写入文件对应的位置"><a href="#每个线程下载指定位置的数据并写入文件对应的位置" class="headerlink" title="每个线程下载指定位置的数据并写入文件对应的位置"></a>每个线程下载指定位置的数据并写入文件对应的位置</h3><p>衔接上一段程序</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 从打开的连接读入输入流</span></span><br><span class="line">InputStream inputStream = conn.getInputStream();</span><br><span class="line"><span class="comment">// 创建写入文件的RandomAccessFile对象</span></span><br><span class="line">RandomAccessFile raf = <span class="keyword">new</span> RandomAccessFile(objPath, <span class="string">&quot;rwd&quot;</span>);</span><br><span class="line"><span class="comment">//随机写文件，跳到相应的位置</span></span><br><span class="line">raf.seek(startPosition);</span><br><span class="line"><span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> lenCount = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">while</span> ((len = inputStream.read(buffer)) != -<span class="number">1</span>) &#123;</span><br><span class="line">	lenCount += len;</span><br><span class="line">	raf.write(buffer, <span class="number">0</span>, len);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//最后记得关闭掉输入流</span></span><br><span class="line">raf.close();</span><br><span class="line">inputStream.close();</span><br></pre></td></tr></table></figure>


<h3 id="RandomAccessFile"><a href="#RandomAccessFile" class="headerlink" title="RandomAccessFile"></a>RandomAccessFile</h3><p>RandomAccessFile是一个强大的随机文件读写API，创建该对象时的参数设置为<code>&quot;rwd&quot;</code>表示立即写入硬盘</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RandomAccessFile</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">RandomAccessFile</span><span class="params">(File file,</span></span></span><br><span class="line"><span class="function"><span class="params">                        String mode)</span></span></span><br><span class="line"><span class="function">                 <span class="keyword">throws</span> FileNotFoundException</span></span><br><span class="line"><span class="function">创建从中读取和向其中写入（可选）的随机访问文件流，该文件由 File 参数指定。将创建一个新的 FileDescriptor 对象来表示此文件的连接。</span></span><br><span class="line"><span class="function">mode 参数指定用以打开文件的访问模式。允许的值及其含意为：</span></span><br><span class="line"><span class="function">值含意</span></span><br><span class="line"><span class="function">&quot;r&quot;	以只读方式打开。调用结果对象的任何 write 方法都将导致抛出 IOException。</span></span><br><span class="line"><span class="function">&quot;rw&quot;	打开以便读取和写入。如果该文件尚不存在，则尝试创建该文件。</span></span><br><span class="line"><span class="function">&quot;rws&quot;	打开以便读取和写入，对于 &quot;rw&quot;，还要求对文件的内容或元数据的每个更新都同步写入到底层存储设备。</span></span><br><span class="line"><span class="function">&quot;rwd&quot;  	打开以便读取和写入，对于 &quot;rw&quot;，还要求对文件内容的每个更新都同步写入到底层存储设备。 &quot;rws&quot; 和 &quot;rwd&quot; 模式的工作方式极其类似 FileChannel 类的 <span class="title">force</span><span class="params">(<span class="keyword">boolean</span>)</span> 方法，分别传递 <span class="keyword">true</span> 和 <span class="keyword">false</span> 参数，除非它们始终应用于每个 I/O 操作，并因此通常更为高效。如果该文件位于本地存储设备上，那么当返回此类的一个方法的调用时，可以保证由该调用对此文件所做的所有更改均被写入该设备。这对确保在系统崩溃时不会丢失重要信息特别有用。如果该文件不在本地设备上，则无法提供这样的保证。</span></span><br><span class="line"><span class="function">&quot;rwd&quot; 模式可用于减少执行的 I/O 操作数量。使用 &quot;rwd&quot; 仅要求更新要写入存储的文件的内容；使用 &quot;rws&quot; 要求更新要写入的文件内容及其元数据，这通常要求至少一个以上的低级别 I/O 操作。</span></span><br><span class="line"><span class="function">如果存在安全管理器，则使用 file 参数的路径名作为其参数调用它的 checkRead 方法，以查看是否允许对该文件进行读取访问。如果该模式允许写入，那么还使用该路径参数调用该安全管理器的 checkWrite 方法，以查看是否允许对该文件进行写入访问。</span></span><br><span class="line"><span class="function">参数：</span></span><br><span class="line"><span class="function">file - 该文件对象</span></span><br><span class="line"><span class="function">mode - 访问模式，如 上所述</span></span><br><span class="line"><span class="function">抛出：</span></span><br><span class="line"><span class="function">IllegalArgumentException - 如果此模式参数与 &quot;r&quot;、 &quot;rw&quot;、 &quot;rws&quot; 或 &quot;rwd&quot; 的其中一个不相等</span></span><br><span class="line"><span class="function">FileNotFoundException - 如果该模式为 &quot;r&quot;，但给定的文件对象不表示一个现有的常规文件，或者该模式以 &quot;rw&quot; 开头，但给定的文件对象不表示一个现有的可写常规文件，而且无法创建具有该名称的新常规文件，或者在打开或创建该文件时发生一些其他错误</span></span><br><span class="line"><span class="function">SecurityException - 如果存在安全管理器，并且其 checkRead 方法拒绝对该文件的读取访问，或者该模式为 &quot;rw&quot;，并且该安全管理器的 checkWrite 方法拒绝对该文件的写入访问</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">seek</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">seek</span><span class="params">(<span class="keyword">long</span> pos)</span></span></span><br><span class="line"><span class="function">          <span class="keyword">throws</span> IOException</span></span><br></pre></td></tr></table></figure>
<p>seek是个牛逼的，像一个游标，跳到指定的位置写数据</p>
<h2 id="断点下载"><a href="#断点下载" class="headerlink" title="断点下载"></a>断点下载</h2><p>当下载大文件时，异常下载中断或暂停下载， 为了防止造成下载资源浪费，为每一个线程提供一个记录，用于记住已经下载文件的位置。当再次启动下载时，读取记录，从中断位置继续下载。</p>
<p>为了兼容不同设备(PC和Android)存储记录文件，本文定义一个接口为不同的存储提供不同的对象，类似于适配器模式.</p>
<ul>
<li>SameDirFileBreakPointManager： 在目标文件同目录下建立记录文件(PC和Android)</li>
<li>SqliteBreakPointManager： 使用Sqlite记录(Android)</li>
<li>PropertyFileBreakPointManager：使用SharedPerferences记录(Android)</li>
</ul>
<p><img src="/images/android/network/android-network-multidownload-breakpointmanager-uml.png"></p>
<p>工程的调用关系</p>
<p><img src="/images/android/network/android-network-multidownload-uml.png"></p>
<pre><code>参考文献</code></pre>
<ol>
<li><a href="http://pan.baidu.com/s/1sjOMIgl" title="Android network 项目工程">itheima的教程</a> (密码: yfqk)</li>
</ol>
<p><img src="/images/android/network/android-network-multidownload-itheima.png"></p>
<ol start="2">
<li><a href="http://pan.baidu.com/s/1qW89zyc">SimpleServer源码</a></li>
</ol>
]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>Java数组</title>
    <url>/Java/array/</url>
    <content><![CDATA[<h1 id="1-声明一个数组"><a href="#1-声明一个数组" class="headerlink" title="1.  声明一个数组"></a>1.  声明一个数组</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] aArray = <span class="keyword">new</span> String[<span class="number">5</span>];  </span><br><span class="line">String[] bArray = &#123;<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>, <span class="string">&quot;e&quot;</span>&#125;;  </span><br><span class="line">String[] cArray = <span class="keyword">new</span> String[]&#123;<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span>,<span class="string">&quot;d&quot;</span>,<span class="string">&quot;e&quot;</span>&#125;;  </span><br></pre></td></tr></table></figure>
<h1 id="2-输出一个数组"><a href="#2-输出一个数组" class="headerlink" title="2.  输出一个数组"></a>2.  输出一个数组</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] intArray = &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span> &#125;;  </span><br><span class="line">String intArrayString = Arrays.toString(intArray);  </span><br><span class="line"><span class="comment">// print directly will print reference value  </span></span><br><span class="line">System.out.println(intArray);  </span><br><span class="line"><span class="comment">// [I@7150bd4d  </span></span><br><span class="line">System.out.println(intArrayString);  </span><br><span class="line"><span class="comment">// [1, 2, 3, 4, 5]  </span></span><br></pre></td></tr></table></figure>
<h1 id="3-从一个数组创建数组列表"><a href="#3-从一个数组创建数组列表" class="headerlink" title="3.  从一个数组创建数组列表"></a>3.  从一个数组创建数组列表</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] stringArray = &#123; <span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>, <span class="string">&quot;e&quot;</span> &#125;;  </span><br><span class="line">ArrayList&lt;String&gt; arrayList = <span class="keyword">new</span> ArrayList&lt;String&gt;(Arrays.asList(stringArray));  </span><br><span class="line">System.out.println(arrayList);  </span><br><span class="line"><span class="comment">// [a, b, c, d, e]  </span></span><br></pre></td></tr></table></figure>
<h1 id="4-检查一个数组是否包含某个值"><a href="#4-检查一个数组是否包含某个值" class="headerlink" title="4.  检查一个数组是否包含某个值"></a>4.  检查一个数组是否包含某个值</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] stringArray = &#123; <span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>, <span class="string">&quot;e&quot;</span> &#125;;  </span><br><span class="line"><span class="keyword">boolean</span> b = Arrays.asList(stringArray).contains(<span class="string">&quot;a&quot;</span>);  </span><br><span class="line">System.out.println(b);  </span><br><span class="line"><span class="comment">// true  </span></span><br></pre></td></tr></table></figure>
<h1 id="5-连接两个数组"><a href="#5-连接两个数组" class="headerlink" title="5.  连接两个数组"></a>5.  连接两个数组</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] intArray = &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span> &#125;;  </span><br><span class="line"><span class="keyword">int</span>[] intArray2 = &#123; <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span> &#125;;  </span><br><span class="line"><span class="comment">// Apache Commons Lang library  </span></span><br><span class="line"><span class="keyword">int</span>[] combinedIntArray = ArrayUtils.addAll(intArray, intArray2);  </span><br></pre></td></tr></table></figure>
<h1 id="6-声明一个内联数组（Array-inline）"><a href="#6-声明一个内联数组（Array-inline）" class="headerlink" title="6.  声明一个内联数组（Array inline）"></a>6.  声明一个内联数组（Array inline）</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">method(<span class="keyword">new</span> String[]&#123;<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>, <span class="string">&quot;e&quot;</span>&#125;);  </span><br></pre></td></tr></table></figure>
<h1 id="7-把提供的数组元素放入一个字符串"><a href="#7-把提供的数组元素放入一个字符串" class="headerlink" title="7.  把提供的数组元素放入一个字符串"></a>7.  把提供的数组元素放入一个字符串</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// containing the provided list of elements  </span></span><br><span class="line"><span class="comment">// Apache common lang  </span></span><br><span class="line">String j = StringUtils.join(<span class="keyword">new</span> String[] &#123; <span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span> &#125;, <span class="string">&quot;, &quot;</span>);  </span><br><span class="line">System.out.println(j);  </span><br><span class="line"><span class="comment">// a, b, c  </span></span><br></pre></td></tr></table></figure>
<h1 id="8-将一个数组列表转换为数组"><a href="#8-将一个数组列表转换为数组" class="headerlink" title="8.  将一个数组列表转换为数组"></a>8.  将一个数组列表转换为数组</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] stringArray = &#123; <span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>, <span class="string">&quot;e&quot;</span> &#125;;  </span><br><span class="line">ArrayList&lt;String&gt; arrayList = <span class="keyword">new</span> ArrayList&lt;String&gt;(Arrays.asList(stringArray));  </span><br><span class="line">String[] stringArr = <span class="keyword">new</span> String[arrayList.size()];  </span><br><span class="line">arrayList.toArray(stringArr);  </span><br><span class="line"><span class="keyword">for</span> (String s : stringArr)  </span><br><span class="line">    System.out.println(s);  </span><br></pre></td></tr></table></figure>
<h1 id="9-将一个数组转换为集（set）"><a href="#9-将一个数组转换为集（set）" class="headerlink" title="9.  将一个数组转换为集（set）"></a>9.  将一个数组转换为集（set）</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Set&lt;String&gt; set = <span class="keyword">new</span> HashSet&lt;String&gt;(Arrays.asList(stringArray));  </span><br><span class="line">System.out.println(set);  </span><br><span class="line"><span class="comment">//[d, e, b, c, a]  </span></span><br></pre></td></tr></table></figure>
<h1 id="10-逆向一个数组"><a href="#10-逆向一个数组" class="headerlink" title="10.  逆向一个数组"></a>10.  逆向一个数组</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] intArray = &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span> &#125;;  </span><br><span class="line">ArrayUtils.reverse(intArray);  </span><br><span class="line">System.out.println(Arrays.toString(intArray));  </span><br><span class="line"><span class="comment">//[5, 4, 3, 2, 1]  </span></span><br></pre></td></tr></table></figure>
<h1 id="11-移除数组中的元素"><a href="#11-移除数组中的元素" class="headerlink" title="11.  移除数组中的元素"></a>11.  移除数组中的元素</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] intArray = &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span> &#125;;  </span><br><span class="line"><span class="keyword">int</span>[] removed = ArrayUtils.removeElement(intArray, <span class="number">3</span>);<span class="comment">//create a new array  </span></span><br><span class="line">System.out.println(Arrays.toString(removed));  </span><br></pre></td></tr></table></figure>
<h1 id="12-将整数转换为字节数组"><a href="#12-将整数转换为字节数组" class="headerlink" title="12.  将整数转换为字节数组"></a>12.  将整数转换为字节数组</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">byte</span>[] bytes = ByteBuffer.allocate(<span class="number">4</span>).putInt(<span class="number">8</span>).array();  </span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">byte</span> t : bytes) &#123;  </span><br><span class="line">   System.out.format(<span class="string">&quot;0x%x &quot;</span>, t);  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>





]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基础之泛型</title>
    <url>/Java/generic/</url>
    <content><![CDATA[<h1 id="普通泛型"><a href="#普通泛型" class="headerlink" title="普通泛型"></a>普通泛型</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span>&lt;<span class="title">T</span>&gt;</span>&#123;       <span class="comment">// 此处可以随便写标识符号，T是type的名称参数</span></span><br><span class="line">   <span class="keyword">private</span> T <span class="keyword">var</span> ; <span class="comment">// var的类型由T指定，即：由外部指定</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;  <span class="comment">// 返回值的类型由外部决定</span></span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">var</span> ;</span><br><span class="line">   &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;  <span class="comment">// 设置的类型也由外部决定</span></span><br><span class="line">       <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo06</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">       Point&lt;String&gt; p = <span class="keyword">new</span> Point&lt;String&gt;() ; <span class="comment">// 里面的var类型为String类型</span></span><br><span class="line">       p.setVar(<span class="string">&quot;it&quot;</span>) ;        <span class="comment">// 设置字符串</span></span><br><span class="line">       System.out.println(p.getVar().length()) ;   <span class="comment">// 取得字符串的长度</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;;</span><br><span class="line"> ----------------------------------------------------------</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Notepad</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;</span>&#123;       <span class="comment">// 此处指定了两个泛型类型</span></span><br><span class="line">     <span class="keyword">private</span> K key ;     <span class="comment">// 此变量的类型由外部决定</span></span><br><span class="line">     <span class="keyword">private</span> V value ;   <span class="comment">// 此变量的类型由外部决定</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> K <span class="title">getKey</span><span class="params">()</span></span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">this</span>.key ;</span><br><span class="line">     &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> V <span class="title">getValue</span><span class="params">()</span></span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">this</span>.value ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setKey</span><span class="params">(K key)</span></span>&#123;</span><br><span class="line">         <span class="keyword">this</span>.key = key ;</span><br><span class="line">    &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setValue</span><span class="params">(V value)</span></span>&#123;</span><br><span class="line">         <span class="keyword">this</span>.value = value ;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo09</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">         Notepad&lt;String,Integer&gt; t = <span class="keyword">null</span> ;        <span class="comment">// 定义两个泛型类型的对象</span></span><br><span class="line">         t = <span class="keyword">new</span> Notepad&lt;String,Integer&gt;() ;       <span class="comment">// 里面的key为String，value为Integer</span></span><br><span class="line">        t.setKey(<span class="string">&quot;汤姆&quot;</span>) ;        <span class="comment">// 设置第一个内容</span></span><br><span class="line">         t.setValue(<span class="number">20</span>) ;            <span class="comment">// 设置第二个内容</span></span><br><span class="line">         System.out.print(<span class="string">&quot;姓名；&quot;</span> + t.getKey()) ;      <span class="comment">// 取得信息</span></span><br><span class="line">         System.out.print(<span class="string">&quot;，年龄；&quot;</span> + t.getValue()) ;       <span class="comment">// 取得信息</span></span><br><span class="line"></span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure>
<h1 id="通配符"><a href="#通配符" class="headerlink" title="通配符"></a>通配符</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Info</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> T <span class="keyword">var</span> ;     <span class="comment">// 定义泛型变量</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;   <span class="comment">// 直接打印</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span>.toString() ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo14</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Info&lt;String&gt; i = <span class="keyword">new</span> Info&lt;String&gt;() ;       <span class="comment">// 使用String为泛型类型</span></span><br><span class="line">        i.setVar(<span class="string">&quot;it&quot;</span>) ;                            <span class="comment">// 设置内容</span></span><br><span class="line">        fun(i) ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">fun</span><span class="params">(Info&lt;?&gt; temp)</span></span>&#123;     <span class="comment">// 可以接收任意的泛型对象</span></span><br><span class="line">        System.out.println(<span class="string">&quot;内容：&quot;</span> + temp) ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="受限泛型"><a href="#受限泛型" class="headerlink" title="受限泛型"></a>受限泛型</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">Info</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">     <span class="keyword">private</span> T <span class="keyword">var</span> ;     <span class="comment">// 定义泛型变量</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">         <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;   <span class="comment">// 直接打印</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span>.toString() ;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo17</span></span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Info&lt;Integer&gt; i1 = <span class="keyword">new</span> Info&lt;Integer&gt;() ;        <span class="comment">// 声明Integer的泛型对象</span></span><br><span class="line">         Info&lt;Float&gt; i2 = <span class="keyword">new</span> Info&lt;Float&gt;() ;            <span class="comment">// 声明Float的泛型对象</span></span><br><span class="line">         i1.setVar(<span class="number">30</span>) ;                                 <span class="comment">// 设置整数，自动装箱</span></span><br><span class="line">         i2.setVar(<span class="number">30.1f</span>) ;                              <span class="comment">// 设置小数，自动装箱</span></span><br><span class="line">         fun(i1) ;</span><br><span class="line">        fun(i2) ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">fun</span><span class="params">(Info&lt;? extends Number&gt; temp)</span></span>&#123;  <span class="comment">// 只能接收Number及其Number的子类</span></span><br><span class="line">         System.out.print(temp + <span class="string">&quot;、&quot;</span>) ;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br><span class="line">-----------------------------------------------------------</span><br><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">Info</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">     <span class="keyword">private</span> T <span class="keyword">var</span> ;     <span class="comment">// 定义泛型变量</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">         <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;   <span class="comment">// 直接打印</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span>.toString() ;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo21</span></span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Info&lt;String&gt; i1 = <span class="keyword">new</span> Info&lt;String&gt;() ;      <span class="comment">// 声明String的泛型对象</span></span><br><span class="line">         Info&lt;Object&gt; i2 = <span class="keyword">new</span> Info&lt;Object&gt;() ;      <span class="comment">// 声明Object的泛型对象</span></span><br><span class="line">         i1.setVar(<span class="string">&quot;hello&quot;</span>) ;</span><br><span class="line">         i2.setVar(<span class="keyword">new</span> Object()) ;</span><br><span class="line">         fun(i1) ;</span><br><span class="line">        fun(i2) ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">fun</span><span class="params">(Info&lt;? <span class="keyword">super</span> String&gt; temp)</span></span>&#123;    <span class="comment">// 只能接收String或Object类型的泛型</span></span><br><span class="line">         System.out.print(temp + <span class="string">&quot;、&quot;</span>) ;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure>
<h1 id="泛型无法向上转型"><a href="#泛型无法向上转型" class="headerlink" title="泛型无法向上转型"></a>泛型无法向上转型</h1> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">Info</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">     <span class="keyword">private</span> T <span class="keyword">var</span> ;     <span class="comment">// 定义泛型变量</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">         <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">     &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;   <span class="comment">// 直接打印</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span>.toString() ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo23</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Info&lt;String&gt; i1 = <span class="keyword">new</span> Info&lt;String&gt;() ;      <span class="comment">// 泛型类型为String</span></span><br><span class="line">        Info&lt;Object&gt; i2 = <span class="keyword">null</span> ;</span><br><span class="line">        i2 = i1 ;                               <span class="comment">//这句会出错 incompatible types</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="泛型接口"><a href="#泛型接口" class="headerlink" title="泛型接口"></a>泛型接口</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">interface</span> <span class="title">Info</span>&lt;<span class="title">T</span>&gt;</span>&#123;        <span class="comment">// 在接口上定义泛型</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span> </span>; <span class="comment">// 定义抽象方法，抽象方法的返回值就是泛型类型</span></span><br><span class="line"> &#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InfoImpl</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">Info</span>&lt;<span class="title">T</span>&gt;</span>&#123;   <span class="comment">// 定义泛型接口的子类</span></span><br><span class="line">   <span class="keyword">private</span> T <span class="keyword">var</span> ;             <span class="comment">// 定义属性</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">InfoImpl</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;     <span class="comment">// 通过构造方法设置属性内容</span></span><br><span class="line">       <span class="keyword">this</span>.setVar(<span class="keyword">var</span>) ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">         <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo24</span></span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String arsg[])</span></span>&#123;</span><br><span class="line">         Info&lt;String&gt; i = <span class="keyword">null</span>;        <span class="comment">// 声明接口对象</span></span><br><span class="line">         i = <span class="keyword">new</span> InfoImpl&lt;String&gt;(<span class="string">&quot;汤姆&quot;</span>) ;  <span class="comment">// 通过子类实例化对象</span></span><br><span class="line">         System.out.println(<span class="string">&quot;内容：&quot;</span> + i.getVar()) ;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> ----------------------------------------------------------</span><br><span class="line"> <span class="class"><span class="keyword">interface</span> <span class="title">Info</span>&lt;<span class="title">T</span>&gt;</span>&#123;        <span class="comment">// 在接口上定义泛型</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span> </span>; <span class="comment">// 定义抽象方法，抽象方法的返回值就是泛型类型</span></span><br><span class="line"> &#125;</span><br><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">InfoImpl</span> <span class="keyword">implements</span> <span class="title">Info</span>&lt;<span class="title">String</span>&gt;</span>&#123;   <span class="comment">// 定义泛型接口的子类</span></span><br><span class="line">     <span class="keyword">private</span> String <span class="keyword">var</span> ;                <span class="comment">// 定义属性</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="title">InfoImpl</span><span class="params">(String <span class="keyword">var</span>)</span></span>&#123;        <span class="comment">// 通过构造方法设置属性内容</span></span><br><span class="line">         <span class="keyword">this</span>.setVar(<span class="keyword">var</span>) ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(String <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">         <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo25</span></span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String arsg[])</span></span>&#123;</span><br><span class="line">         Info i = <span class="keyword">null</span>;      <span class="comment">// 声明接口对象</span></span><br><span class="line">         i = <span class="keyword">new</span> InfoImpl(<span class="string">&quot;汤姆&quot;</span>) ;    <span class="comment">// 通过子类实例化对象</span></span><br><span class="line">         System.out.println(<span class="string">&quot;内容：&quot;</span> + i.getVar()) ;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure>
<h1 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demo</span></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">fun</span><span class="params">(T t)</span></span>&#123;            <span class="comment">// 可以接收任意类型的数据</span></span><br><span class="line">        <span class="keyword">return</span> t ;                  <span class="comment">// 直接把参数返回</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo26</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Demo d = <span class="keyword">new</span> Demo() ;   <span class="comment">// 实例化Demo对象</span></span><br><span class="line">        String str = d.fun(<span class="string">&quot;汤姆&quot;</span>) ; <span class="comment">//   传递字符串</span></span><br><span class="line">        <span class="keyword">int</span> i = d.fun(<span class="number">30</span>) ;     <span class="comment">// 传递数字，自动装箱</span></span><br><span class="line">        System.out.println(str) ;   <span class="comment">// 输出内容</span></span><br><span class="line">        System.out.println(i) ;     <span class="comment">// 输出内容</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="通过泛型方法返回泛型类型实例"><a href="#通过泛型方法返回泛型类型实例" class="headerlink" title="通过泛型方法返回泛型类型实例"></a>通过泛型方法返回泛型类型实例</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Info</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Number</span>&gt;</span>&#123; <span class="comment">// 指定上限，只能是数字类型</span></span><br><span class="line">    <span class="keyword">private</span> T <span class="keyword">var</span> ;     <span class="comment">// 此类型由外部决定</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">  &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;       <span class="comment">// 覆写Object类中的toString()方法</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span>.toString() ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo27</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Info&lt;Integer&gt; i = fun(<span class="number">30</span>) ;</span><br><span class="line">        System.out.println(i.getVar()) ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T extends Number&gt; <span class="function">Info&lt;T&gt; <span class="title">fun</span><span class="params">(T param)</span></span>&#123;<span class="comment">//方法中传入或返回的泛型类型由调用方法时所设置的参数类型决定</span></span><br><span class="line">        Info&lt;T&gt; temp = <span class="keyword">new</span> Info&lt;T&gt;() ;      <span class="comment">// 根据传入的数据类型实例化Info</span></span><br><span class="line">        temp.setVar(param) ;        <span class="comment">// 将传递的内容设置到Info对象的var属性之中</span></span><br><span class="line">        <span class="keyword">return</span> temp ;   <span class="comment">// 返回实例化对象</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="使用泛型统一传入的参数类型"><a href="#使用泛型统一传入的参数类型" class="headerlink" title="使用泛型统一传入的参数类型"></a>使用泛型统一传入的参数类型</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Info</span>&lt;<span class="title">T</span>&gt;</span>&#123;    <span class="comment">// 指定上限，只能是数字类型</span></span><br><span class="line">    <span class="keyword">private</span> T <span class="keyword">var</span> ;     <span class="comment">// 此类型由外部决定</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;       <span class="comment">// 覆写Object类中的toString()方法</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span>.toString() ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo28</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Info&lt;String&gt; i1 = <span class="keyword">new</span> Info&lt;String&gt;() ;</span><br><span class="line">        Info&lt;String&gt; i2 = <span class="keyword">new</span> Info&lt;String&gt;() ;</span><br><span class="line">        i1.setVar(<span class="string">&quot;HELLO&quot;</span>) ;        <span class="comment">// 设置内容</span></span><br><span class="line">        i2.setVar(<span class="string">&quot;汤姆&quot;</span>) ;       <span class="comment">// 设置内容</span></span><br><span class="line">        add(i1,i2) ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(Info&lt;T&gt; i1,Info&lt;T&gt; i2)</span></span>&#123;</span><br><span class="line">        System.out.println(i1.getVar() + <span class="string">&quot; &quot;</span> + i2.getVar()) ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="泛型数组"><a href="#泛型数组" class="headerlink" title="泛型数组"></a>泛型数组</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo30</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Integer i[] = fun1(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>) ;   <span class="comment">// 返回泛型数组</span></span><br><span class="line">        fun2(i) ;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; T[] fun1(T...arg)&#123;  <span class="comment">// 接收可变参数</span></span><br><span class="line">      <span class="keyword">return</span> arg ;            <span class="comment">// 返回泛型数组</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">fun2</span><span class="params">(T param[])</span></span>&#123;   <span class="comment">// 输出</span></span><br><span class="line">      System.out.print(<span class="string">&quot;接收泛型数组：&quot;</span>) ;</span><br><span class="line">        <span class="keyword">for</span>(T t:param)&#123;</span><br><span class="line">            System.out.print(t + <span class="string">&quot;、&quot;</span>) ;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="泛型的嵌套设置"><a href="#泛型的嵌套设置" class="headerlink" title="泛型的嵌套设置"></a>泛型的嵌套设置</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Info</span>&lt;<span class="title">T</span>,<span class="title">V</span>&gt;</span>&#123;      <span class="comment">// 接收两个泛型类型</span></span><br><span class="line">    <span class="keyword">private</span> T <span class="keyword">var</span> ;</span><br><span class="line">    <span class="keyword">private</span> V value ;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Info</span><span class="params">(T <span class="keyword">var</span>,V value)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setVar(<span class="keyword">var</span>) ;</span><br><span class="line">        <span class="keyword">this</span>.setValue(value) ;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(T <span class="keyword">var</span>)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setValue</span><span class="params">(V value)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.value = value ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">getVar</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.<span class="keyword">var</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">getValue</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.value ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demo</span>&lt;<span class="title">S</span>&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> S info ;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Demo</span><span class="params">(S info)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setInfo(info) ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setInfo</span><span class="params">(S info)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.info = info ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> S <span class="title">getInfo</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.info ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericsDemo31</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Demo&lt;Info&lt;String,Integer&gt;&gt; d = <span class="keyword">null</span> ;       <span class="comment">// 将Info作为Demo的泛型类型</span></span><br><span class="line">        Info&lt;String,Integer&gt; i = <span class="keyword">null</span> ;   <span class="comment">// Info指定两个泛型类型</span></span><br><span class="line">        i = <span class="keyword">new</span> Info&lt;String,Integer&gt;(<span class="string">&quot;汤姆&quot;</span>,<span class="number">30</span>) ;    <span class="comment">// 实例化Info对象</span></span><br><span class="line">        d = <span class="keyword">new</span> Demo&lt;Info&lt;String,Integer&gt;&gt;(i) ; <span class="comment">// 在Demo类中设置Info类的对象</span></span><br><span class="line">        System.out.println(<span class="string">&quot;内容一：&quot;</span> + d.getInfo().getVar()) ;</span><br><span class="line">        System.out.println(<span class="string">&quot;内容二：&quot;</span> + d.getInfo().getValue()) ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p> 泛型方法不一定要通过参数来确定泛型准确类型，可以只通过返回值，比如：<br> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;E&gt; <span class="function">ArrayList&lt;E&gt; <span class="title">newArrayList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">new</span> ArrayList&lt;E&gt;();</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> List&lt;PrepaidHistory&gt; <span class="title">queryHistories</span><span class="params">(Long skyid,PrepaidHistoryType type, Date from, Date end)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">　　　　。。。</span><br><span class="line">            <span class="keyword">return</span> Lists.newArrayList();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><br>这样<code>Lists.newArrayList()</code>;<br>智能的知道返回类型为<code>PrepaidHistory</code></p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>//TODO 继承泛型</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TextFile</span> <span class="keyword">extends</span> <span class="title">ArrayList</span>&lt;<span class="title">String</span>&gt;</span>&#123;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Generic</tag>
      </tags>
  </entry>
  <entry>
    <title>Java内部类</title>
    <url>/Java/innerClass/</url>
    <content><![CDATA[<h1 id="什么是内部类？分为哪几种？"><a href="#什么是内部类？分为哪几种？" class="headerlink" title="什么是内部类？分为哪几种？"></a>什么是内部类？分为哪几种？</h1><p>内部类是指在一个外部类的内部再定义一个类。内部类作为外部类的一个成员，并且依附于外部类而存在的。内部类可为静态，可用protected和private修饰（而外部类只能使用public和缺省的包访问权限）。<br>内部类主要有以下几类：成员内部类、局部内部类、静态内部类、匿名内部类。</p>
<h1 id="为什么需要内部类？"><a href="#为什么需要内部类？" class="headerlink" title="为什么需要内部类？"></a>为什么需要内部类？</h1><p>典型的情况是，内部类继承自某个类或实现某个接口，内部类的代码操作创建其的外围类的对象。所以你可以认为内部类提供了某种进入其外围类的窗口。<br>使用内部类最吸引人的原因是：每个内部类都能独立地继承自一个（接口的）实现，所以无论外围类是否已经继承了某个（接口的）实现，对于内部类都没有影响。如果没有内部类提供的可以继承多个具体的或抽象的类的能力，一些设计与编程问题就很难解决。从这个角度看，内部类使得多重继承的解决方案变得完整。接口解决了部分问题，而内部类有效地实现了“多重继承”。</p>
<h1 id="内部类可以引用它的包含类的成员吗？有没有什么限制？"><a href="#内部类可以引用它的包含类的成员吗？有没有什么限制？" class="headerlink" title="内部类可以引用它的包含类的成员吗？有没有什么限制？"></a>内部类可以引用它的包含类的成员吗？有没有什么限制？</h1><p>完全可以。如果不是静态内部类，那没有什么限制！<br>如果你把静态嵌套类当作内部类的一种特例，那在这种情况下不可以访问外部类的普通成员变量，而只能访问外部类中的静态成员，例如，下面的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">int</span> x;</span><br><span class="line">	<span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Inner</span></span></span><br><span class="line"><span class="class">	</span>&#123;</span><br><span class="line">		<span class="function"><span class="keyword">void</span> <span class="title">test</span><span class="params">()</span></span></span><br><span class="line"><span class="function">		</span>&#123;</span><br><span class="line">			syso(x);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>答题时，也要能察言观色，揣摩提问者的心思，显然人家希望你说的是静态内部类不能访问外部类的成员，但你一上来就顶牛，这不好，要先顺着人家，让人家满意，然后再说特殊情况，让人家吃惊。</p>
<h1 id="Anonymous-Inner-Class-匿名内部类-是否可以extends-继承-其它类，是否可以implements-实现-interface-接口"><a href="#Anonymous-Inner-Class-匿名内部类-是否可以extends-继承-其它类，是否可以implements-实现-interface-接口" class="headerlink" title="Anonymous Inner Class (匿名内部类) 是否可以extends(继承)其它类，是否可以implements(实现)interface(接口)?"></a>Anonymous Inner Class (匿名内部类) 是否可以extends(继承)其它类，是否可以implements(实现)interface(接口)?</h1><p>可以继承其他类或实现其他接口。不仅是可以，而是必须!</p>
<h1 id="如何调用内部类？"><a href="#如何调用内部类？" class="headerlink" title="如何调用内部类？"></a>如何调用内部类？</h1><hr>
<p>参考文献</p>
<ol>
<li><a href="http://www.codeceo.com/article/java-memory-model-volatile.html" title="Java内存模型与volatile关键字">Java内存模型与volatile关键字</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>inner class</tag>
      </tags>
  </entry>
  <entry>
    <title>JDBC(占坑)</title>
    <url>/Java/jdbc/</url>
    <content><![CDATA[<h1 id="JDBC的使用步骤"><a href="#JDBC的使用步骤" class="headerlink" title="JDBC的使用步骤"></a>JDBC的使用步骤</h1><h2 id="注册驱动-只做一次"><a href="#注册驱动-只做一次" class="headerlink" title="注册驱动 只做一次"></a>注册驱动 只做一次</h2><p><strong>方式一</strong>：</p>
<p><code>Class.forName(&quot;com.MySQL.jdbc.Driver&quot;);</code></p>
<p>推荐这种方式，不会对具体的驱动类产生依赖。</p>
<p><strong>方式二</strong>：</p>
<p><code>DriverManager.registerDriver(&quot;com.MySQL.jdbc.Driver&quot;);</code></p>
<p>会造成DriverManager中产生两个一样的驱动，并会对具体的驱动类产生依赖。</p>
<p><strong>方式三</strong>：</p>
<p><code>System.setProperty(“jdbc.drivers”, “driver1:driver2”);</code></p>
<p>虽然不会对具体的驱动类产生依赖；但注册不太方便，所以很少使用。 </p>
<p>Jar包地址:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>




<h2 id="建立连接Connection"><a href="#建立连接Connection" class="headerlink" title="建立连接Connection"></a>建立连接Connection</h2><p><code>Connection conn = DriverManager.getConnection(url, user, password);  </code></p>
<p><strong>url格式：</strong><br><code>JDBC:子协议:子名称//主机名:端口/数据库名？属性名=属性值&amp;…</code><br>User,password可以用“属性名=属性值”方式告诉数据库；<br>其他参数如：<code>useUnicode=true&amp;characterEncoding=GBK</code>。</p>
<h2 id="创建执行SQL的语句Statement"><a href="#创建执行SQL的语句Statement" class="headerlink" title="创建执行SQL的语句Statement"></a>创建执行SQL的语句Statement</h2><p>Statement</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Statement st = conn.createStatement();  </span><br><span class="line">st.executeQuery(sql);  </span><br></pre></td></tr></table></figure>
<p>PreparedStatement</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String sql = “select * from table_name where col_name=?”;  </span><br><span class="line">PreparedStatement ps = conn.preparedStatement(sql);  </span><br><span class="line">ps.setString(<span class="number">1</span>, “col_value”);  </span><br><span class="line">ps.executeQuery(); </span><br></pre></td></tr></table></figure>


<h2 id="处理执行结果ResultSet"><a href="#处理执行结果ResultSet" class="headerlink" title="处理执行结果ResultSet"></a>处理执行结果ResultSet</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ResultSet rs = statement.executeQuery(sql);  </span><br><span class="line">While(rs.next())&#123;  </span><br><span class="line">rs.getString(“col_name”);  </span><br><span class="line">rs.getInt(“col_name”);  </span><br><span class="line"><span class="comment">//…  </span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>


<h2 id="释放资源"><a href="#释放资源" class="headerlink" title="释放资源"></a>释放资源</h2><p>释放ResultSet, Statement,Connection.</p>
<p>数据库连接（Connection）是非常稀有的资源，用完后必须马上释放，如果Connection不能及时正确的关闭将导致系统宕机。Connection的使用原则是尽量晚创建，尽量早的释放。</p>
<h1 id="使用JDBC来实现CRUD的操作"><a href="#使用JDBC来实现CRUD的操作" class="headerlink" title="使用JDBC来实现CRUD的操作"></a>使用JDBC来实现CRUD的操作</h1><h2 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h2><p>在这里定义了一个用户信息表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `tb_user_info` (</span><br><span class="line">  `user_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT COMMENT <span class="string">&#x27;主键&#x27;</span>,</span><br><span class="line">  `name` <span class="type">varchar</span>(<span class="number">10</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;姓名&#x27;</span>,</span><br><span class="line">  `gender` enum(<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;女&#x27;</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;性别&#x27;</span>,</span><br><span class="line">  `birthday` <span class="type">timestamp</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="built_in">CURRENT_TIMESTAMP</span> COMMENT <span class="string">&#x27;生日&#x27;</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (`user_id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB AUTO_INCREMENT<span class="operator">=</span><span class="number">10000</span> <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8 COMMENT<span class="operator">=</span><span class="string">&#x27;用户信息表&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="Entity"><a href="#Entity" class="headerlink" title="Entity"></a>Entity</h2><p>与该表对应的Entity为:</p>
<p><img src="/images/java/jdbc/sample-01-uml.png"></p>
<h2 id="JDBC的CRUD"><a href="#JDBC的CRUD" class="headerlink" title="JDBC的CRUD"></a>JDBC的CRUD</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JDBCDemo</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * database connection</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Connection connection;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Connection <span class="title">connection</span><span class="params">(<span class="keyword">final</span> String url, <span class="keyword">final</span> String name, <span class="keyword">final</span> String password)</span> <span class="keyword">throws</span> ClassNotFoundException, SQLException </span>&#123;</span><br><span class="line">        Class.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>);</span><br><span class="line">        Connection connection = DriverManager.getConnection(url, name, password);</span><br><span class="line">        <span class="keyword">this</span>.connection = connection;</span><br><span class="line">        <span class="keyword">return</span> connection;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;UserInfo&gt; <span class="title">list</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> ps)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> start = p * ps;</span><br><span class="line">        PreparedStatement preparedStatement = connection.prepareStatement(<span class="string">&quot;select * from tb_user_info limit &quot;</span> + start + <span class="string">&quot;,&quot;</span> + ps);</span><br><span class="line">        ResultSet resultSet = preparedStatement.executeQuery();</span><br><span class="line">        ArrayList&lt;UserInfo&gt; list = <span class="keyword">new</span> ArrayList&lt;UserInfo&gt;();</span><br><span class="line">        <span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">            <span class="keyword">int</span> userId = resultSet.getInt(<span class="string">&quot;user_id&quot;</span>);</span><br><span class="line">            String name = resultSet.getString(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">            Timestamp birthday = resultSet.getTimestamp(<span class="string">&quot;birthday&quot;</span>);</span><br><span class="line">            String gender = resultSet.getString(<span class="string">&quot;gender&quot;</span>);</span><br><span class="line">            UserInfo userInfo = <span class="keyword">new</span> UserInfo(userId, name, gender, birthday);</span><br><span class="line">            list.add(userInfo);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;UserInfo&gt; <span class="title">findByName</span><span class="params">(String name)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        PreparedStatement preparedStatement = connection.prepareStatement(<span class="string">&quot;select * from tb_user_info where name = ?&quot;</span>);</span><br><span class="line">        preparedStatement.setString(<span class="number">1</span>, name);</span><br><span class="line">        ResultSet resultSet = preparedStatement.executeQuery();</span><br><span class="line">        ArrayList&lt;UserInfo&gt; list = <span class="keyword">new</span> ArrayList&lt;UserInfo&gt;();</span><br><span class="line">        <span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">            <span class="keyword">int</span> userId = resultSet.getInt(<span class="string">&quot;user_id&quot;</span>);</span><br><span class="line">            Timestamp birthday = resultSet.getTimestamp(<span class="string">&quot;birthday&quot;</span>);</span><br><span class="line">            String gender = resultSet.getString(<span class="string">&quot;gender&quot;</span>);</span><br><span class="line">            UserInfo userInfo = <span class="keyword">new</span> UserInfo(userId, name, gender, birthday);</span><br><span class="line">            list.add(userInfo);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">addUser</span><span class="params">(UserInfo userInfo)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        PreparedStatement preparedStatement = connection.prepareStatement(<span class="string">&quot;insert into tb_user_info values(default,?,?,?)&quot;</span>);</span><br><span class="line">        preparedStatement.setString(<span class="number">1</span>, userInfo.getName());</span><br><span class="line">        preparedStatement.setString(<span class="number">2</span>, userInfo.getGender());</span><br><span class="line">        preparedStatement.setTimestamp(<span class="number">3</span>, userInfo.getBirthday());</span><br><span class="line">        <span class="keyword">int</span> influenceLines = preparedStatement.executeUpdate();</span><br><span class="line">        <span class="keyword">return</span> influenceLines;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">delete</span><span class="params">(<span class="keyword">int</span> userId)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        PreparedStatement preparedStatement = connection.prepareStatement(<span class="string">&quot;delete from tb_user_info where user_id = ?&quot;</span>);</span><br><span class="line">        preparedStatement.setInt(<span class="number">1</span>, userId);</span><br><span class="line">        <span class="keyword">int</span> influenceLines = preparedStatement.executeUpdate();</span><br><span class="line">        <span class="keyword">return</span> influenceLines;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(UserInfo userInfo)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        PreparedStatement preparedStatement = connection.prepareStatement(<span class="string">&quot;update tb_user_info set name=? , gender = ? , birthday = ? where user_id = ?&quot;</span>);</span><br><span class="line">        preparedStatement.setString(<span class="number">1</span>, userInfo.getName());</span><br><span class="line">        preparedStatement.setString(<span class="number">2</span>, userInfo.getGender());</span><br><span class="line">        preparedStatement.setTimestamp(<span class="number">3</span>, userInfo.getBirthday());</span><br><span class="line">        preparedStatement.setInt(<span class="number">4</span>, userInfo.getUserId());</span><br><span class="line">        <span class="keyword">int</span> influenceLines = preparedStatement.executeUpdate();</span><br><span class="line">        <span class="keyword">return</span> influenceLines;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试样例: </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JDBCDemo jdbcDemo = <span class="keyword">new</span> JDBCDemo();</span><br><span class="line">jdbcDemo.connection(<span class="string">&quot;jdbc:mysql://127.0.0.1:3306/test?autoReconnect=true&amp;autoReconnectForPools=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>,</span><br><span class="line">        <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>);</span><br><span class="line">UserInfo obama = <span class="keyword">new</span> UserInfo(<span class="number">0</span>, <span class="string">&quot;奥巴马&quot;</span>, <span class="string">&quot;男&quot;</span>, <span class="keyword">new</span> Timestamp(System.currentTimeMillis()));</span><br><span class="line">UserInfo cirali = <span class="keyword">new</span> UserInfo(<span class="number">0</span>, <span class="string">&quot;希拉里&quot;</span>, <span class="string">&quot;女&quot;</span>, <span class="keyword">new</span> Timestamp(System.currentTimeMillis()));</span><br><span class="line">UserInfo trappes = <span class="keyword">new</span> UserInfo(<span class="number">0</span>, <span class="string">&quot;特朗普&quot;</span>, <span class="string">&quot;女&quot;</span>, <span class="keyword">new</span> Timestamp(System.currentTimeMillis()));</span><br><span class="line">System.out.println(<span class="string">&quot;[添加 奥巴马]&quot;</span>);</span><br><span class="line">jdbcDemo.addUser(obama);</span><br><span class="line">System.out.println(<span class="string">&quot;[添加 希拉里]&quot;</span>);</span><br><span class="line"></span><br><span class="line">jdbcDemo.addUser(cirali);</span><br><span class="line">System.out.println(<span class="string">&quot;[添加 特朗普]&quot;</span>);</span><br><span class="line">jdbcDemo.addUser(trappes);</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">&quot;\n 输出 所有用户信息：&quot;</span>);</span><br><span class="line">List&lt;UserInfo&gt; list = jdbcDemo.list(<span class="number">0</span>, <span class="number">10</span>);</span><br><span class="line"><span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (UserInfo userInfo : list) &#123;</span><br><span class="line">        System.out.println(userInfo);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">&quot;根据姓名查询用户信息&quot;</span>);</span><br><span class="line">UserInfo tUserIndo = <span class="keyword">null</span>;</span><br><span class="line">List&lt;UserInfo&gt; resultList = jdbcDemo.findByName(<span class="string">&quot;特朗普&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (resultList != <span class="keyword">null</span>) &#123;</span><br><span class="line">    tUserIndo = resultList.get(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(tUserIndo);</span><br><span class="line"></span><br><span class="line">tUserIndo.setGender(<span class="string">&quot;男&quot;</span>);</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">&quot;[更新]&quot;</span>);</span><br><span class="line">jdbcDemo.update(tUserIndo);</span><br><span class="line"></span><br><span class="line">System.out.println(tUserIndo);</span><br><span class="line">System.out.println(<span class="string">&quot;\n 输出 所有用户信息：&quot;</span>);</span><br><span class="line">list = jdbcDemo.list(<span class="number">0</span>, <span class="number">10</span>);</span><br><span class="line"><span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (UserInfo userInfo : list) &#123;</span><br><span class="line">        System.out.println(userInfo);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 释放资源 </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> rs </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> st </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">free</span><span class="params">(ResultSet rs,Statement st,Connection conn)</span></span>&#123;  </span><br><span class="line">  <span class="keyword">try</span>&#123;  </span><br><span class="line">    <span class="keyword">if</span>(rs != <span class="keyword">null</span>)&#123;  </span><br><span class="line">      rs.close();  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;<span class="keyword">catch</span>(SQLException e)&#123;  </span><br><span class="line">    e.printStackTrace();  </span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;  </span><br><span class="line">    <span class="keyword">try</span>&#123;  </span><br><span class="line">      <span class="keyword">if</span>(st != <span class="keyword">null</span>)&#123;  </span><br><span class="line">        st.close();  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;<span class="keyword">catch</span>(SQLException e)&#123;  </span><br><span class="line">      e.printStackTrace();  </span><br><span class="line">    &#125;<span class="keyword">finally</span>&#123;  </span><br><span class="line">      <span class="keyword">try</span>&#123;  </span><br><span class="line">        <span class="keyword">if</span>(conn != <span class="keyword">null</span>)&#123;  </span><br><span class="line">          conn.close();  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;<span class="keyword">catch</span>(SQLException e)&#123;  </span><br><span class="line">        e.printStackTrace();  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line"></span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>


<p>输出结果为:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[添加 奥巴马]</span><br><span class="line">[添加 希拉里]</span><br><span class="line">[添加 特朗普]</span><br><span class="line"></span><br><span class="line"> 输出 所有用户信息：</span><br><span class="line">UserInfo&#123;userId&#x3D;10009, name&#x3D;&#39;奥巴马&#39;, gender&#x3D;男, birthday&#x3D;2016-11-27 10:03:00.0&#125;</span><br><span class="line">UserInfo&#123;userId&#x3D;10010, name&#x3D;&#39;希拉里&#39;, gender&#x3D;女, birthday&#x3D;2016-11-27 10:03:00.0&#125;</span><br><span class="line">UserInfo&#123;userId&#x3D;10011, name&#x3D;&#39;特朗普&#39;, gender&#x3D;女, birthday&#x3D;2016-11-27 10:03:00.0&#125;</span><br><span class="line">根据姓名查询用户信息</span><br><span class="line">UserInfo&#123;userId&#x3D;10011, name&#x3D;&#39;特朗普&#39;, gender&#x3D;女, birthday&#x3D;2016-11-27 10:03:00.0&#125;</span><br><span class="line">[更新]</span><br><span class="line">UserInfo&#123;userId&#x3D;10011, name&#x3D;&#39;特朗普&#39;, gender&#x3D;男, birthday&#x3D;2016-11-27 10:03:00.0&#125;</span><br><span class="line"></span><br><span class="line"> 输出 所有用户信息：</span><br><span class="line">UserInfo&#123;userId&#x3D;10009, name&#x3D;&#39;奥巴马&#39;, gender&#x3D;男, birthday&#x3D;2016-11-27 10:03:00.0&#125;</span><br><span class="line">UserInfo&#123;userId&#x3D;10010, name&#x3D;&#39;希拉里&#39;, gender&#x3D;女, birthday&#x3D;2016-11-27 10:03:00.0&#125;</span><br><span class="line">UserInfo&#123;userId&#x3D;10011, name&#x3D;&#39;特朗普&#39;, gender&#x3D;男, birthday&#x3D;2016-11-27 10:03:00.0&#125;</span><br></pre></td></tr></table></figure>


<p><strong>注意</strong></p>
<ol>
<li>使用prepareStatement预处理执行SQL语句时，<code>?</code>的索引是从<code>1</code>开始的</li>
</ol>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h1 id="JDBC中特殊数据类型的操作问题"><a href="#JDBC中特殊数据类型的操作问题" class="headerlink" title="JDBC中特殊数据类型的操作问题"></a>JDBC中特殊数据类型的操作问题</h1><h2 id="第一个是日期问题"><a href="#第一个是日期问题" class="headerlink" title="第一个是日期问题"></a>第一个是日期问题</h2><p>JDBC接收的时间类型是sql下的类型，与Java中的类型不同，通常需要转化。</p>
<p>如 java.sql.Date &lt;—&gt; java.util.Date</p>
<h2 id="第二个问题就是大文本数据的问题"><a href="#第二个问题就是大文本数据的问题" class="headerlink" title="第二个问题就是大文本数据的问题"></a>第二个问题就是大文本数据的问题</h2><p>读写大文本数据:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">         * 插入大文本 </span></span><br><span class="line"><span class="comment">         */</span>  </span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">()</span></span>&#123;  </span><br><span class="line">  Connection conn = <span class="keyword">null</span>;  </span><br><span class="line">  PreparedStatement ps = <span class="keyword">null</span>;  </span><br><span class="line">  ResultSet rs = <span class="keyword">null</span>;  </span><br><span class="line">  <span class="keyword">try</span>&#123;  </span><br><span class="line">    conn = JdbcUtils.getConnection();  </span><br><span class="line">    String sql = <span class="string">&quot;insert into clob_test(bit_text) values(?)&quot;</span>;  </span><br><span class="line">    ps = conn.prepareStatement(sql);  </span><br><span class="line">    File file = <span class="keyword">new</span> File(<span class="string">&quot;src/com/weijia/type/ClubDemo.java&quot;</span>);  </span><br><span class="line">    Reader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(file));  </span><br><span class="line">    <span class="comment">//ps.setAsciiStream(1, new FileInputStream(file), (int)file.length());//英文的文档  </span></span><br><span class="line">    ps.setCharacterStream(<span class="number">1</span>, reader, (<span class="keyword">int</span>)file.length());  </span><br><span class="line">    ps.executeUpdate();  </span><br><span class="line">    reader.close();  </span><br><span class="line">  &#125;<span class="keyword">catch</span>(Exception e)&#123;  </span><br><span class="line">    e.printStackTrace();  </span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;  </span><br><span class="line">    JdbcUtils.free(rs,ps,conn);  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Clob clob = rs.getClob(<span class="number">1</span>);  </span><br><span class="line">InputStream is = clob.getAsciiStream();  </span><br></pre></td></tr></table></figure>


<h1 id="JDBC中事务的概念"><a href="#JDBC中事务的概念" class="headerlink" title="JDBC中事务的概念"></a>JDBC中事务的概念</h1><h1 id="JDBC中调用存储过程"><a href="#JDBC中调用存储过程" class="headerlink" title="JDBC中调用存储过程"></a>JDBC中调用存储过程</h1><h1 id="JDBC来实现批处理功能"><a href="#JDBC来实现批处理功能" class="headerlink" title="JDBC来实现批处理功能"></a>JDBC来实现批处理功能</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createBatch</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;  </span><br><span class="line">  <span class="comment">//建立一个连接的是很耗时间的  </span></span><br><span class="line">  <span class="comment">//执行一个sql语句也是很耗时间的  </span></span><br><span class="line">  <span class="comment">//优化的措施：批处理  </span></span><br><span class="line">  Connection conn = <span class="keyword">null</span>;  </span><br><span class="line">  PreparedStatement ps = <span class="keyword">null</span>;  </span><br><span class="line">  ResultSet rs = <span class="keyword">null</span>;  </span><br><span class="line">  <span class="keyword">try</span>&#123;  </span><br><span class="line">    conn = JdbcUtils.getConnection();  </span><br><span class="line">    String sql = <span class="string">&quot;insert user(name,birthday,money) values(?,?,?)&quot;</span>;  </span><br><span class="line">    ps = conn.prepareStatement(sql,Statement.RETURN_GENERATED_KEYS);  </span><br><span class="line"></span><br><span class="line">    <span class="comment">//打包的话容量也不是越大越好，因为可能会内存溢出的，同时网络传输的过程中也是会进行拆包传输的，这个包的大小是不一定的  </span></span><br><span class="line">    <span class="comment">//有时候打包的效率不一定就会高，这个和数据库的类型，版本都有关系的，所以我们在实践的过程中需要检验的  </span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">100</span>;i++)&#123;  </span><br><span class="line">      ps.setString(<span class="number">1</span>,<span class="string">&quot;jiangwei&quot;</span>);  </span><br><span class="line">      ps.setDate(<span class="number">2</span>,<span class="keyword">new</span> Date(System.currentTimeMillis()));  </span><br><span class="line">      ps.setFloat(<span class="number">3</span>,<span class="number">400</span>);  </span><br><span class="line">      <span class="comment">//ps.addBatch(sql);  </span></span><br><span class="line">      ps.addBatch();  </span><br><span class="line">    &#125;  </span><br><span class="line">    ps.executeBatch();  </span><br><span class="line">  &#125;<span class="keyword">catch</span>(Exception e)&#123;  </span><br><span class="line">    e.printStackTrace();  </span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;  </span><br><span class="line">    JdbcUtils.free(rs, ps, conn);  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>


<h1 id="JDBC中的滚动结果集和分页技术"><a href="#JDBC中的滚动结果集和分页技术" class="headerlink" title="JDBC中的滚动结果集和分页技术"></a>JDBC中的滚动结果集和分页技术</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;  </span><br><span class="line">  Connection conn = <span class="keyword">null</span>;  </span><br><span class="line">  Statement st = <span class="keyword">null</span>;  </span><br><span class="line">  ResultSet rs = <span class="keyword">null</span>;  </span><br><span class="line">  <span class="keyword">try</span>&#123;  </span><br><span class="line">    conn = JdbcUtils.getConnection();  </span><br><span class="line">    <span class="comment">//结果集可滚动的  </span></span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">             * 参数的含义： </span></span><br><span class="line"><span class="comment">             *  ResultSet.RTYPE_FORWORD_ONLY：这是缺省值，只可向前滚动；  </span></span><br><span class="line"><span class="comment">                ResultSet.TYPE_SCROLL_INSENSITIVE：双向滚动，但不及时更新，就是如果数据库里的数据修改过，并不在ResultSet中反应出来。  </span></span><br><span class="line"><span class="comment">                ResultSet.TYPE_SCROLL_SENSITIVE：双向滚动，并及时跟踪数据库的更新,以便更改ResultSet中的数据。 </span></span><br><span class="line"><span class="comment">                ResultSet.CONCUR_READ_ONLY：这是缺省值，指定不可以更新 ResultSet  </span></span><br><span class="line"><span class="comment">                ResultSet.CONCUR_UPDATABLE：指定可以更新 ResultSet </span></span><br><span class="line"><span class="comment">             */</span>  </span><br><span class="line">    st = conn.createStatement(ResultSet.TYPE_SCROLL_SENSITIVE,ResultSet.CONCUR_READ_ONLY);  </span><br><span class="line">    rs = st.executeQuery(<span class="string">&quot;select id,name,money,birthday from user&quot;</span>);  </span><br><span class="line">    <span class="comment">//开始的时候这个游标的位置是第一条记录之前的一个位置  </span></span><br><span class="line">    <span class="comment">//当执行rs.next的时候这个游标的位置就到第一条记录了  </span></span><br><span class="line">    <span class="comment">/*while(rs.next())&#123; </span></span><br><span class="line"><span class="comment">                //print result </span></span><br><span class="line"><span class="comment">            &#125;*/</span>  </span><br><span class="line">    <span class="comment">//上面的代码执行之后，这个游标就到最后一条记录的下一个位置了  </span></span><br><span class="line">    <span class="comment">//所以这里在调用previous方法之后，这个游标就回到了最后一条记录中，所以打印了最后一条记录的值  </span></span><br><span class="line">    <span class="comment">/*if(rs.previous())&#123; </span></span><br><span class="line"><span class="comment">                System.out.println(&quot;id=&quot;+rs.getInt(&quot;id&quot;)+&quot;\tname=&quot;+rs.getString(&quot;name&quot;)+&quot;\tbirthday=&quot;+rs.getDate(&quot;birthday&quot;)+&quot;\tmoney=&quot;+rs.getFloat(&quot;money&quot;)); </span></span><br><span class="line"><span class="comment">            &#125;*/</span>  </span><br><span class="line"></span><br><span class="line">    <span class="comment">//绝对定位到第几行结果集  </span></span><br><span class="line">    <span class="comment">//这里传递的参数的下标是从1开始的，比如这里查询出来的记录有3条，那么这里的参数的范围是:1-3,如果传递的参数不在这个范围内就会报告异常的  </span></span><br><span class="line">    rs.absolute(<span class="number">2</span>);  </span><br><span class="line">    System.out.println(<span class="string">&quot;id=&quot;</span>+rs.getInt(<span class="string">&quot;id&quot;</span>)+<span class="string">&quot;\tname=&quot;</span>+rs.getString(<span class="string">&quot;name&quot;</span>)+<span class="string">&quot;\tbirthday=&quot;</span>+rs.getDate(<span class="string">&quot;birthday&quot;</span>)+<span class="string">&quot;\tmoney=&quot;</span>+rs.getFloat(<span class="string">&quot;money&quot;</span>));  </span><br><span class="line"></span><br><span class="line">    <span class="comment">//滚到到第一行的前面(默认的就是这种情况)  </span></span><br><span class="line">    rs.beforeFirst();  </span><br><span class="line"></span><br><span class="line">    <span class="comment">//滚动到最后一行的后面  </span></span><br><span class="line">    rs.afterLast();  </span><br><span class="line"></span><br><span class="line">    rs.isFirst();<span class="comment">//判断是不是在第一行记录  </span></span><br><span class="line">    rs.isLast();<span class="comment">//判断是不是在最后一行记录  </span></span><br><span class="line">    rs.isAfterLast();<span class="comment">//判断是不是第一行前面的位置  </span></span><br><span class="line">    rs.isBeforeFirst();<span class="comment">//判断是不是最后一行的后面的位置  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//以上的api可以实现翻页的效果(这个效率很低的，因为是先把数据都查询到内存中，然后再进行分页显示的)  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//效率高的话是直接使用数据库中的分页查询语句：  </span></span><br><span class="line">    <span class="comment">//select * from user limit 150,10;  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//以上的api实现的分页功能是针对于那些本身不支持分页查询功能的数据库的，如果一个数据库支持分页功能，上面的代码就不能使用的，因为效率是很低的  </span></span><br><span class="line">  &#125;<span class="keyword">catch</span>(Exception e)&#123;  </span><br><span class="line">    e.printStackTrace();  </span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;  </span><br><span class="line">    JdbcUtils.free(rs,st,conn);  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>


<h1 id="JDBC中的可更新以及对更新敏感的结果集操作"><a href="#JDBC中的可更新以及对更新敏感的结果集操作" class="headerlink" title="JDBC中的可更新以及对更新敏感的结果集操作"></a>JDBC中的可更新以及对更新敏感的结果集操作</h1><h1 id="元数据的相关知识"><a href="#元数据的相关知识" class="headerlink" title="元数据的相关知识"></a>元数据的相关知识</h1><h2 id="数据库的元数据信息"><a href="#数据库的元数据信息" class="headerlink" title="数据库的元数据信息"></a>数据库的元数据信息</h2><h2 id="查询参数的元数据信息"><a href="#查询参数的元数据信息" class="headerlink" title="查询参数的元数据信息"></a>查询参数的元数据信息</h2><h2 id="结果集中元数据信息"><a href="#结果集中元数据信息" class="headerlink" title="结果集中元数据信息"></a>结果集中元数据信息</h2><h1 id="JDBC中的数据源"><a href="#JDBC中的数据源" class="headerlink" title="JDBC中的数据源"></a>JDBC中的数据源</h1><h1 id="JDBC中CRUD的模板模式"><a href="#JDBC中CRUD的模板模式" class="headerlink" title="JDBC中CRUD的模板模式"></a>JDBC中CRUD的模板模式</h1><h1 id="Spring框架中的JdbcTemplate"><a href="#Spring框架中的JdbcTemplate" class="headerlink" title="Spring框架中的JdbcTemplate"></a>Spring框架中的JdbcTemplate</h1><h2 id="加强版的JdbcTemplate"><a href="#加强版的JdbcTemplate" class="headerlink" title="加强版的JdbcTemplate"></a>加强版的JdbcTemplate</h2><h3 id="NamedParameterJdbcTemplate"><a href="#NamedParameterJdbcTemplate" class="headerlink" title="NamedParameterJdbcTemplate"></a>NamedParameterJdbcTemplate</h3><h3 id="SimpleJdbcTemplate"><a href="#SimpleJdbcTemplate" class="headerlink" title="SimpleJdbcTemplate"></a>SimpleJdbcTemplate</h3><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h1 id="批量"><a href="#批量" class="headerlink" title="批量"></a>批量</h1><h1 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h1><ul>
<li><code>java.sql.SQLException: Incorrect string value: &#39;\xE3\x80\x90\xE9\x80\x9A...&#39; for column &#39;msg&#39; at row 1</code><br>编码问题： 检查数据库编码，数据表编码，列编码以及连接数据库使用的<code>characterEncoding</code></li>
</ul>
<h1 id="链接数据库"><a href="#链接数据库" class="headerlink" title="链接数据库"></a>链接数据库</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.seecen.stream;</span><br><span class="line"><span class="keyword">import</span> java.sql.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestJDBC</span> </span>&#123;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 1、实例话驱动类</span></span><br><span class="line"><span class="comment">	 * 2、建立到数据库的连接</span></span><br><span class="line"><span class="comment">	 * 3、将数据发送到数据库中</span></span><br><span class="line"><span class="comment">	 * 4、执行语句（select语句）</span></span><br><span class="line"><span class="comment">	 * 5、关闭</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		  ResultSet rs = <span class="keyword">null</span>;  </span><br><span class="line">		  Statement stmt = <span class="keyword">null</span>;  </span><br><span class="line">		  Connection conn = <span class="keyword">null</span>;  </span><br><span class="line">		  <span class="keyword">try</span> &#123;  </span><br><span class="line">		   Class.forName(<span class="string">&quot;oracle.jdbc.driver.OracleDriver&quot;</span>);  </span><br><span class="line">	conn = DriverManager.getConnection(<span class="string">&quot;jdbc:oracle:thin:@192.168.0.1:1521:yuewei&quot;</span>, <span class="string">&quot;scott&quot;</span>, <span class="string">&quot;tiger&quot;</span>);  </span><br><span class="line">		   stmt = conn.createStatement();  </span><br><span class="line">		   rs = stmt.executeQuery(<span class="string">&quot;select * from dept&quot;</span>);  </span><br><span class="line">		   <span class="keyword">while</span>(rs.next()) &#123;  </span><br><span class="line">		    System.out.println(rs.getString(<span class="string">&quot;deptno&quot;</span>));  </span><br><span class="line">		   &#125;  </span><br><span class="line">		  &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;  </span><br><span class="line">		   e.printStackTrace();  </span><br><span class="line">		  &#125; <span class="keyword">catch</span> (SQLException e) &#123;  </span><br><span class="line">		   e.printStackTrace();  </span><br><span class="line">		  &#125; <span class="keyword">finally</span> &#123;  </span><br><span class="line">		   <span class="keyword">try</span> &#123;  </span><br><span class="line">		    <span class="keyword">if</span>(rs != <span class="keyword">null</span>) &#123;  </span><br><span class="line">		     rs.close();  </span><br><span class="line">		     rs = <span class="keyword">null</span>;  </span><br><span class="line">		    &#125;  </span><br><span class="line">		    <span class="keyword">if</span>(stmt != <span class="keyword">null</span>) &#123;  </span><br><span class="line">		     stmt.close();  </span><br><span class="line">		     stmt = <span class="keyword">null</span>;  </span><br><span class="line">		    &#125;  </span><br><span class="line">		    <span class="keyword">if</span>(conn != <span class="keyword">null</span>) &#123;  </span><br><span class="line">		     conn.close();  </span><br><span class="line">		     conn = <span class="keyword">null</span>;  </span><br><span class="line">		    &#125;  </span><br><span class="line">		   &#125; <span class="keyword">catch</span> (SQLException e) &#123;  </span><br><span class="line">		    e.printStackTrace();  </span><br><span class="line">		   &#125;  </span><br><span class="line">		  &#125;  </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="调用存储过程"><a href="#调用存储过程" class="headerlink" title="调用存储过程"></a>调用存储过程</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.huawei.interview.lym;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.CallableStatement;</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"><span class="keyword">import</span> java.sql.Types;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JdbcTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">		Connection cn = <span class="keyword">null</span>;</span><br><span class="line">		CallableStatement cstmt = <span class="keyword">null</span>;		</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			<span class="comment">//这里最好不要这么干，因为驱动名写死在程序中了</span></span><br><span class="line">			Class.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>);</span><br><span class="line">			<span class="comment">//实际项目中，这里应用DataSource数据，如果用框架，</span></span><br><span class="line">			<span class="comment">//这个数据源不需要我们编码创建，我们只需Datasource ds = context.lookup()</span></span><br><span class="line">			<span class="comment">//cn = ds.getConnection();			</span></span><br><span class="line">			cn = DriverManager.getConnection(<span class="string">&quot;jdbc:mysql:///test&quot;</span>,<span class="string">&quot;root&quot;</span>,<span class="string">&quot;root&quot;</span>);</span><br><span class="line">			cstmt = cn.prepareCall(<span class="string">&quot;&#123;call insert_Student(?,?,?)&#125;&quot;</span>);</span><br><span class="line">			cstmt.registerOutParameter(<span class="number">3</span>,Types.INTEGER);</span><br><span class="line">			cstmt.setString(<span class="number">1</span>, <span class="string">&quot;wangwu&quot;</span>);</span><br><span class="line">			cstmt.setInt(<span class="number">2</span>, <span class="number">25</span>);</span><br><span class="line">			cstmt.execute();</span><br><span class="line">			<span class="comment">//get第几个，不同的数据库不一样，建议不写</span></span><br><span class="line">			System.out.println(cstmt.getString(<span class="number">3</span>));</span><br><span class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">			<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">finally</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">/*try&#123;cstmt.close();&#125;catch(Exception e)&#123;&#125;</span></span><br><span class="line"><span class="comment">			try&#123;cn.close();&#125;catch(Exception e)&#123;&#125;*/</span></span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				<span class="keyword">if</span>(cstmt != <span class="keyword">null</span>)</span><br><span class="line">					cstmt.close();</span><br><span class="line">				<span class="keyword">if</span>(cn != <span class="keyword">null</span>)				</span><br><span class="line">					cn.close();</span><br><span class="line">			&#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">				<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h1 id="JDBC中的PreparedStatement相比Statement的好处"><a href="#JDBC中的PreparedStatement相比Statement的好处" class="headerlink" title="JDBC中的PreparedStatement相比Statement的好处"></a>JDBC中的PreparedStatement相比Statement的好处</h1><p>1）提高性能：在使用preparedStatement对象执行sql时候，命令被数据库编译和解析，然后被放到命令缓冲区，然后每当执行同一个preparedStatement时候，他就被再解析一次，但不会在编译，在缓冲区中可以发现预编译的命令，并且可以重新使用。<br>如果你要写Insert update delete 最好使用preparedStatement，在有大量用户的企业级应用软件中，经常会执行相同的sql,使用preparedStatement会增加整体的性能。<br>2）安全性：PreparedStatement 可以防止sql注入。</p>
<h1 id="JDBC原理"><a href="#JDBC原理" class="headerlink" title="JDBC原理"></a>JDBC原理</h1><p>调用Class.forName(“com.mysql.jdbc.Driver”);   加载mysql的驱动类进内存，那么就会在DriverManager中注册自己，注册的意思简单来说就是DriverManager中保持一个Driver引用指向了自己，但是具体的实现可能不同。</p>
<p>然后嗲用DriverManager.getConnection方法得到连接对象，  这里运用到了简单工厂方法，即根据传进去得参数来具体实例化哪个驱动类。</p>
<p>可能是mysql的驱动类， 也可能是Oracle的驱动类， 具体的由传进去的参数来决定。</p>
<p>当得到Connection对象后就没DriverManager和Driver类什么事了。</p>
<p>Connection一个接口，但是它指向了具体的Connection子类对象。</p>
<p>通过Connection中定义的接口，就能够访问数据库了。</p>
<p>所以总得来说，如果要改变当前使用的数据库，那么只需要改变两个地方，</p>
<p>Class.forName(具体的参数)</p>
<p>DriverManager.getConnection(具体的参数)</p>
<p>所以我们可以在配置文件中配置这两个参数，那么我们就可以在程序运行的时候动态地改变所使用的数据库，只需要更改配置文件就行了。</p>
<p>当然了，程序肯定要有数据库第三方jar包。</p>
<hr>
<p>参考文献：</p>
<ol>
<li>[J2EE学习篇之–JDBC详解 ][<a href="http://blog.csdn.net/jiangwei0910410003/article/details/26164629]">http://blog.csdn.net/jiangwei0910410003/article/details/26164629]</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDBC</tag>
      </tags>
  </entry>
  <entry>
    <title>JNI：Java native interface</title>
    <url>/Java/jni/</url>
    <content><![CDATA[<h2 id="JNI-–-Java-Native-Interface"><a href="#JNI-–-Java-Native-Interface" class="headerlink" title="JNI – Java Native Interface"></a>JNI – Java Native Interface</h2><p>JNI 是 Java 与本地代码通信的桥梁，因此，也是 Java 调用操作系统 API 的接口。<br>因为 jvm 也是采用 C 实现的，通过JNI，可以达到调用 jvm 的目的。</p>
<h2 id="JNI调用过程"><a href="#JNI调用过程" class="headerlink" title="JNI调用过程"></a>JNI调用过程</h2><ol>
<li>当加载 Java 类时，运行静态代码段。 在静态代码段中，调用<code>System.loadLibrary(&quot;&lt;jni_lib_name&gt;&quot;)</code>方法，加载动态库。</li>
<li>Java 自动在库中查找<code>JNI_OnLoad()</code>函数。 <code>JNI_OnLoad()</code>函数主要有两个作用：</li>
</ol>
<ul>
<li>判断 JNI 版本</li>
<li>初始化，如注册函数</li>
</ul>
<ol>
<li>当调用 native 方法时，Java 将去查找注册的函数。有两种注册函数的方法，静态注册和动态注册。</li>
</ol>
<ul>
<li><p>静态注册是指在 C 里面以JNI默认的函数名定义与 java 中对对应的函数</p>
</li>
<li><p>而动态注册是指在调用<code>JNI_OnLoad()</code>函数时，调用<code>(*env)-&gt;RegisterNatives()</code>函数，将方法注册。</p>
<p>当Java去查找注册函数，首先判断是不是存在动态注册函数，如果不存在再查找静态注册函数。<br>如果查找不到，将报出异常。</p>
</li>
</ul>
<ol>
<li>执行C 函数，Java接收返回结果。</li>
</ol>
<h3 id="动态注册"><a href="#动态注册" class="headerlink" title="动态注册"></a>动态注册</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">  System.loadLibrary(<span class="string">&quot;native_native&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">callNativeMethod</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">double</span> y)</span></span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> JNINativeMethod gMethods[] = &#123;          </span><br><span class="line">  &#123;<span class="string">&quot;callNativeMethod&quot;</span>, <span class="string">&quot;(ID)Ljava/lang/String;&quot;</span>,  (<span class="keyword">void</span> *)abc&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//真正的实现方法</span></span><br><span class="line"><span class="function">JNIExport jstring <span class="title">abc</span><span class="params">(JNIEnv *env, jobject obj,jint x,jdouble y)</span></span>&#123;</span><br><span class="line"><span class="comment">//TODO 实现</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">jint <span class="title">JNI_OnLoad</span><span class="params">(JavaVM* vm, <span class="keyword">void</span>* reserved)</span> </span>&#123;</span><br><span class="line"> JNIEnv* env = <span class="literal">NULL</span>;</span><br><span class="line"> jint result = <span class="number">-1</span>;</span><br><span class="line">  <span class="comment">//获取JNI环境对象</span></span><br><span class="line"> <span class="comment">//  if(vm-&gt;GetEnv((void**)&amp;env,JNI_VERSION_1_4)!=JNI_OK)&#123; //C++</span></span><br><span class="line"> <span class="keyword">if</span> ((*vm)-&gt;GetEnv(vm,(<span class="keyword">void</span>**) &amp;env, JNI_VERSION_1_4) != JNI_OK) &#123;<span class="comment">//C</span></span><br><span class="line">     <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">//如果要注册, 只需要两步骤, 首先FindClass, 然后RegisterNatives就可以了</span></span><br><span class="line"> <span class="comment">//注册本地方法.Load 目标类</span></span><br><span class="line"> <span class="keyword">char</span> className[<span class="number">20</span>] = &#123;<span class="string">&quot;club/guadazi/wiki/MyFirstActivity&quot;</span>&#125;;</span><br><span class="line"> <span class="comment">// jclass clazz = (env)-&gt;FindClass( (const char*)className);// C++</span></span><br><span class="line"> jclass clazz = (*env)-&gt;FindClass(env,(<span class="keyword">const</span> <span class="keyword">char</span> *)className);<span class="comment">//C</span></span><br><span class="line"> <span class="comment">//注册本地native方法</span></span><br><span class="line"> <span class="keyword">if</span>((*env)-&gt;RegisterNatives(env,clazz, gMethods, <span class="number">1</span>)&lt; <span class="number">0</span>)</span><br><span class="line"> &#123;</span><br><span class="line">     <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">//一定要返回版本号, 否则会出错.</span></span><br><span class="line"> result = JNI_VERSION_1_4;</span><br><span class="line"> <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="静态注册"><a href="#静态注册" class="headerlink" title="静态注册"></a>静态注册</h3><p>在生成的头文件中会含有静态注册函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JNIExport jstring</span><br><span class="line"> Java_club_guadazi_wiki_MyFirstActivity_callNativeMethod(</span><br><span class="line">   JNIEnv *env, jobject obj,jint x,jdouble y);</span><br></pre></td></tr></table></figure>
<p>写法是Java+Android工程的包名+Android工程的Activity名+方法名,点号用下划线表示，这个写法很严格。 包名：com_conowen_helloworld， Activity名：HelloWorldActivity， 方法名：helloWorldFromJNI</p>
<p>函数名称可以通过<code>javah</code>生成:</p>
<ul>
<li> 编译该java文件成class文件</li>
<li> 利用命令生成h头文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">javah MyFirstActivity</span><br></pre></td></tr></table></figure>

<h2 id="java-调用-c"><a href="#java-调用-c" class="headerlink" title="java 调用 c"></a>java 调用 c</h2><p>上面的实现即为 java 调用 C</p>
<h2 id="c-调用-java"><a href="#c-调用-java" class="headerlink" title="c 调用 java"></a>c 调用 java</h2><h3 id="普通函数"><a href="#普通函数" class="headerlink" title="普通函数"></a>普通函数</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestJNIInstanceVariable</span> </span>&#123;</span><br><span class="line">   <span class="keyword">static</span> &#123;</span><br><span class="line">      System.loadLibrary(<span class="string">&quot;myjni&quot;</span>);</span><br><span class="line">      <span class="comment">// myjni.dll (Windows) or libmyjni.so (Unixes)</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// Instance variables</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> number = <span class="number">88</span>;</span><br><span class="line">   <span class="keyword">private</span> String message = <span class="string">&quot;Hello from Java&quot;</span>;</span><br><span class="line">   <span class="comment">// Native method that modifies the instance variables</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">modifyInstanceVariable</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">      TestJNIInstanceVariable test = <span class="keyword">new</span> TestJNIInstanceVariable();</span><br><span class="line">      test.modifyInstanceVariable();</span><br><span class="line">      System.out.println(<span class="string">&quot;In Java, int is &quot;</span> + test.number);</span><br><span class="line">      System.out.println(<span class="string">&quot;In Java, String is &quot;</span> + test.message);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;TestJNIInstanceVariable.h&quot;</span></span></span><br><span class="line"><span class="comment">// jni方法的静态实现</span></span><br><span class="line">JNIEXPORT <span class="keyword">void</span> JNICALL</span><br><span class="line"> Java_TestJNIInstanceVariable_modifyInstanceVariable</span><br><span class="line">          (JNIEnv *env, jobject thisObj) &#123;</span><br><span class="line">   <span class="comment">// Get a reference to this object&#x27;s class</span></span><br><span class="line">   jclass thisClass = (*env)-&gt;GetObjectClass(env, thisObj);</span><br><span class="line">   <span class="comment">// int</span></span><br><span class="line">   <span class="comment">// Get the Field ID of the instance variables &quot;number&quot;</span></span><br><span class="line">   jfieldID fidNumber = (*env)-&gt;GetFieldID(env, thisClass, <span class="string">&quot;number&quot;</span>, <span class="string">&quot;I&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == fidNumber) <span class="keyword">return</span>;</span><br><span class="line">   <span class="comment">// Get the int given the Field ID</span></span><br><span class="line">   jint number = (*env)-&gt;GetIntField(env, thisObj, fidNumber);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, the int is %d\n&quot;</span>, number);</span><br><span class="line">   <span class="comment">// Change the variable</span></span><br><span class="line">   number = <span class="number">99</span>;</span><br><span class="line">   (*env)-&gt;SetIntField(env, thisObj, fidNumber, number);</span><br><span class="line">   <span class="comment">// Get the Field ID of the instance variables &quot;message&quot;</span></span><br><span class="line">   jfieldID fidMessage = (*env)-&gt;GetFieldID(env, thisClass, <span class="string">&quot;message&quot;</span>, <span class="string">&quot;Ljava/lang/String;&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == fidMessage) <span class="keyword">return</span>;</span><br><span class="line">   <span class="comment">// String</span></span><br><span class="line">   <span class="comment">// Get the object given the Field ID</span></span><br><span class="line">   jstring message = (*env)-&gt;GetObjectField(env, thisObj, fidMessage);</span><br><span class="line">   <span class="comment">// Create a C-string with the JNI String</span></span><br><span class="line">   <span class="keyword">const</span> <span class="keyword">char</span> *cStr = (*env)-&gt;GetStringUTFChars(env, message, <span class="literal">NULL</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == cStr) <span class="keyword">return</span>;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, the string is %s\n&quot;</span>, cStr);</span><br><span class="line">   (*env)-&gt;ReleaseStringUTFChars(env, message, cStr);</span><br><span class="line">   <span class="comment">// Create a new C-string and assign to the JNI string</span></span><br><span class="line">   message = (*env)-&gt;NewStringUTF(env, <span class="string">&quot;Hello from C&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == message) <span class="keyword">return</span>;</span><br><span class="line">   <span class="comment">// modify the instance variables</span></span><br><span class="line">   (*env)-&gt;SetObjectField(env, thisObj, fidMessage, message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意：</p>
<ol>
<li>c 调用 java 的方法，类似于反射。 首先，需要获得类对象，然后再获取函数 id。<br>再调用get 和 set 函数，操作数据。</li>
<li>如果建立了局部对象， 需要释放空间， 以防数据泄露。</li>
</ol>
<h3 id="访问静态变量和静态函数"><a href="#访问静态变量和静态函数" class="headerlink" title="访问静态变量和静态函数"></a>访问静态变量和静态函数</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestJNIStaticVariable</span> </span>&#123;</span><br><span class="line">   <span class="keyword">static</span> &#123;</span><br><span class="line">      System.loadLibrary(<span class="string">&quot;myjni&quot;</span>); <span class="comment">// nyjni.dll (Windows) or libmyjni.so (Unixes)</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// Static variables</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">double</span> number = <span class="number">55.66</span>;</span><br><span class="line">   <span class="comment">// Native method that modifies the instance variables</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">modifyStaticVariable</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">      TestJNIStaticVariable test = <span class="keyword">new</span> TestJNIStaticVariable();</span><br><span class="line">      test.modifyStaticVariable();</span><br><span class="line">      System.out.println(<span class="string">&quot;In Java, the double is &quot;</span> + number);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;TestJNIStaticVariable.h&quot;</span></span></span><br><span class="line">JNIEXPORT <span class="keyword">void</span> JNICALL Java_TestJNIStaticVariable_modifyStaticVariable</span><br><span class="line">          (JNIEnv *env, jobject thisObj) &#123;</span><br><span class="line">   <span class="comment">// Get a reference to this object&#x27;s class</span></span><br><span class="line">   jclass cls = (*env)-&gt;GetObjectClass(env, thisObj);</span><br><span class="line">   <span class="comment">// Read the int static variable and modify its value</span></span><br><span class="line">   jfieldID fidNumber = (*env)-&gt;GetStaticFieldID(env, cls, <span class="string">&quot;number&quot;</span>, <span class="string">&quot;D&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == fidNumber) <span class="keyword">return</span>;</span><br><span class="line">   jdouble number = (*env)-&gt;GetStaticDoubleField(env, thisObj, fidNumber);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, the double is %f\n&quot;</span>, number);</span><br><span class="line">   number = <span class="number">77.88</span>;</span><br><span class="line">   (*env)-&gt;SetStaticDoubleField(env, thisObj, fidNumber, number);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="调用实例方法和静态方法"><a href="#调用实例方法和静态方法" class="headerlink" title="调用实例方法和静态方法"></a>调用实例方法和静态方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestJNICallBackMethod</span> </span>&#123;</span><br><span class="line">   <span class="keyword">static</span> &#123;</span><br><span class="line">      System.loadLibrary(<span class="string">&quot;myjni&quot;</span>);</span><br><span class="line">      <span class="comment">// myjni.dll (Windows) or libmyjni.so (Unixes)</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// Native method that calls back the Java methods below</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">nativeMethod</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="comment">// To be called back by the native code</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">callback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;In Java&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">callback</span><span class="params">(String message)</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;In Java with &quot;</span> + message);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">double</span> <span class="title">callbackAverage</span><span class="params">(<span class="keyword">int</span> n1, <span class="keyword">int</span> n2)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> ((<span class="keyword">double</span>)n1 + n2) / <span class="number">2.0</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// Static method to be called back</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> String <span class="title">callbackStatic</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;From static Java method&quot;</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">      <span class="keyword">new</span> TestJNICallBackMethod().nativeMethod();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;TestJNICallBackMethod.h&quot;</span></span></span><br><span class="line">JNIEXPORT <span class="keyword">void</span> JNICALL Java_TestJNICallBackMethod_nativeMethod</span><br><span class="line">          (JNIEnv *env, jobject thisObj) &#123;</span><br><span class="line">   <span class="comment">// Get a class reference for this object</span></span><br><span class="line">   jclass thisClass = (*env)-&gt;GetObjectClass(env, thisObj);</span><br><span class="line">   <span class="comment">// Get the Method ID for method &quot;callback&quot;, which takes no arg and return void</span></span><br><span class="line">   jmethodID midCallBack = (*env)-&gt;GetMethodID(env, thisClass, <span class="string">&quot;callback&quot;</span>, <span class="string">&quot;()V&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midCallBack) <span class="keyword">return</span>;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, call back Java&#x27;s callback()\n&quot;</span>);</span><br><span class="line">   <span class="comment">// Call back the method (which returns void), baed on the Method ID</span></span><br><span class="line">   (*env)-&gt;CallVoidMethod(env, thisObj, midCallBack);</span><br><span class="line">   jmethodID midCallBackStr = (*env)-&gt;GetMethodID(env, thisClass,</span><br><span class="line">                               <span class="string">&quot;callback&quot;</span>, <span class="string">&quot;(Ljava/lang/String;)V&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midCallBackStr) <span class="keyword">return</span>;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, call back Java&#x27;s called(String)\n&quot;</span>);</span><br><span class="line">   jstring message = (*env)-&gt;NewStringUTF(env, <span class="string">&quot;Hello from C&quot;</span>);</span><br><span class="line">   (*env)-&gt;CallVoidMethod(env, thisObj, midCallBackStr, message);</span><br><span class="line">   jmethodID midCallBackAverage = (*env)-&gt;GetMethodID(env, thisClass,</span><br><span class="line">                                  <span class="string">&quot;callbackAverage&quot;</span>, <span class="string">&quot;(II)D&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midCallBackAverage) <span class="keyword">return</span>;</span><br><span class="line">   jdouble average = (*env)-&gt;CallDoubleMethod(env, thisObj, midCallBackAverage, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, the average is %f\n&quot;</span>, average);</span><br><span class="line">   jmethodID midCallBackStatic = (*env)-&gt;GetStaticMethodID(env, thisClass,</span><br><span class="line">                                 <span class="string">&quot;callbackStatic&quot;</span>, <span class="string">&quot;()Ljava/lang/String;&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midCallBackStatic) <span class="keyword">return</span>;</span><br><span class="line">   jstring resultJNIStr = (*env)-&gt;CallStaticObjectMethod(env, thisObj, midCallBackStatic);</span><br><span class="line">   <span class="keyword">const</span> <span class="keyword">char</span> *resultCStr = (*env)-&gt;GetStringUTFChars(env, resultJNIStr, <span class="literal">NULL</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == resultCStr) <span class="keyword">return</span>;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, the returned string is %s\n&quot;</span>, resultCStr);</span><br><span class="line">   (*env)-&gt;ReleaseStringUTFChars(env, resultJNIStr, resultCStr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="回调覆盖的父类的实例方法"><a href="#回调覆盖的父类的实例方法" class="headerlink" title="回调覆盖的父类的实例方法"></a>回调覆盖的父类的实例方法</h3><p>//TODO</p>
<h2 id="jni-数据类型"><a href="#jni-数据类型" class="headerlink" title="jni 数据类型"></a>jni 数据类型</h2><p>jni在本地系统中定义了与java总的基本数据类型相对应的数据类型。</p>
<ol>
<li><p>基本类型: <code>jint</code> <code>jbyte</code> <code>jshort</code> <code>jlong</code> <code>jdouble</code> <code>jchar</code> <code>jboolean</code>与java中的<code>int</code> <code>byte</code> <code>short</code> <code>long</code> <code>double</code> <code>char</code> <code>boolean</code>对应。</p>
</li>
<li><p>引用类型: <code>jobject</code>与<code>java.lang.Object</code>也定义了如下的子类型:</p>
</li>
</ol>
<ul>
<li><code>jclass</code>与<code>java.lang.Class</code></li>
<li><code>jstring</code>与<code>java.lang.String</code></li>
<li><code>jthrowable</code>与<code>java.lang.Throwable</code></li>
<li><code>jarray</code>对应java数组。 java数组是包括8种基本类型数组与Object数组的应用类型。因此， 存在8个基本类型的数组: <code>jintArray</code>, <code>jbyteArray</code>, <code>jshortArray</code>, <code>jlongArray</code>, <code>jfloatArray</code>, <code>jdoubleArray</code>, <code>jcharArray</code>和<code>jbooleanArray</code>,以及<code>jobjectArray</code>.</li>
</ul>
<p>本地函数接收到上述的JNI类型的参数，返回JNI类型的数据。在本地函数处理自己的本地类型数据时，需要JNI类型与本地类型的转换。</p>
<h2 id="参数传递与数据类型转换"><a href="#参数传递与数据类型转换" class="headerlink" title="参数传递与数据类型转换"></a>参数传递与数据类型转换</h2><h3 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h3><p>Java基本数据类型可以直接传递。在本地系统中定义的<code>jXXX</code>类型, 如<code>jint</code>,<code>jbyte</code>,<code>jshort</code>,<code>jlong</code>,<code>jfloat</code>,<code>jdouble</code>,<code>jchar</code>和<code>jboolean</code>与java中基本数据类型<code>int</code>,<code>byte</code>,<code>short</code>,<code>long</code>,<code>float</code>,<code>double</code>,<code>char</code>和<code>boolean</code>对应.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// In &quot;win\jni_mh.h&quot; - machine header which is machine dependent</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span>            jint;</span><br><span class="line"><span class="keyword">typedef</span> __int64         jlong;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">signed</span> <span class="keyword">char</span>     jbyte;</span><br><span class="line"><span class="comment">// In &quot;jni.h&quot;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">char</span>   jboolean;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">short</span>  jchar;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">short</span>           jshort;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">float</span>           jfloat;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">double</span>          jdouble;</span><br><span class="line"><span class="keyword">typedef</span> jint            jsize;</span><br></pre></td></tr></table></figure>
<h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestJNIString</span> </span>&#123;</span><br><span class="line">   <span class="keyword">static</span> &#123;</span><br><span class="line">      System.loadLibrary(<span class="string">&quot;myjni&quot;</span>);</span><br><span class="line">      <span class="comment">// myjni.dll (Windows) or libmyjni.so (Unixes)</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// Native method that receives a Java String and return a Java String</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">native</span> String <span class="title">sayHello</span><span class="params">(String msg)</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">      String result = <span class="keyword">new</span> TestJNIString().sayHello(<span class="string">&quot;Hello from Java&quot;</span>);</span><br><span class="line">      System.out.println(<span class="string">&quot;In Java, the returned string is: &quot;</span> + result);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JNIEXPORT jstring JNICALL Java_TestJNIString_sayHello(JNIEnv *, jobject, jstring);</span><br></pre></td></tr></table></figure>
<p>Java的String是一个对象，而C里面的String是一个以 null 结束的字符数组(字符指针 char*)。JNI环境提供了转换用的函数:</p>
<ol>
<li><p>JNI String(jstring)转换为C String(char *): <code>const char* GetStringUTFChars(JNIEnv*, jstring, jboolean*)</code></p>
</li>
<li><p>C-String(char *)转换为JNI String(jstring): <code>jstring NewStringUTF(JNIEnv*, char*)</code></p>
<p> 注意: 当调用上面的函数产生了新的内存时，需要调用<code>(*env)-&gt;ReleaseStringUTFChars(env, &lt;&gt;, &lt;&gt;);</code></p>
</li>
</ol>
<h4 id="JNI本地字符串函数"><a href="#JNI本地字符串函数" class="headerlink" title="JNI本地字符串函数"></a>JNI本地字符串函数</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// UTF-8 String (encoded to 1-3 byte, backward compatible with 7-bit ASCII)</span></span><br><span class="line"><span class="comment">// Can be mapped to null-terminated char-array C-string</span></span><br><span class="line"><span class="function"><span class="keyword">const</span> <span class="keyword">char</span> * <span class="title">GetStringUTFChars</span><span class="params">(JNIEnv *env, jstring <span class="built_in">string</span>, jboolean *isCopy)</span></span>;</span><br><span class="line"><span class="comment">// Returns a pointer to an array of bytes representing the string in modified UTF-8 encoding.</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ReleaseStringUTFChars</span><span class="params">(JNIEnv *env, jstring <span class="built_in">string</span>, <span class="keyword">const</span> <span class="keyword">char</span> *utf)</span></span>;</span><br><span class="line"><span class="comment">// Informs the VM that the native code no longer needs access to utf.</span></span><br><span class="line"><span class="function">jstring <span class="title">NewStringUTF</span><span class="params">(JNIEnv *env, <span class="keyword">const</span> <span class="keyword">char</span> *bytes)</span></span>;</span><br><span class="line"><span class="comment">// Constructs a new java.lang.String object from an array of characters in modified UTF-8 encoding.</span></span><br><span class="line"><span class="function">jsize <span class="title">GetStringUTFLength</span><span class="params">(JNIEnv *env, jstring <span class="built_in">string</span>)</span></span>;</span><br><span class="line"><span class="comment">// Returns the length in bytes of the modified UTF-8 representation of a string.</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">GetStringUTFRegion</span><span class="params">(JNIEnv *env, jstring str, jsize start, jsize length, <span class="keyword">char</span> *buf)</span></span>;</span><br><span class="line"><span class="comment">// Translates len number of Unicode characters beginning at offset start into modified UTF-8 encoding</span></span><br><span class="line"><span class="comment">// and place the result in the given buffer buf.</span></span><br><span class="line"><span class="comment">// Unicode Strings (16-bit character)</span></span><br><span class="line"><span class="function"><span class="keyword">const</span> jchar * <span class="title">GetStringChars</span><span class="params">(JNIEnv *env, jstring <span class="built_in">string</span>, jboolean *isCopy)</span></span>;</span><br><span class="line"><span class="comment">// Returns a pointer to the array of Unicode characters</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ReleaseStringChars</span><span class="params">(JNIEnv *env, jstring <span class="built_in">string</span>, <span class="keyword">const</span> jchar *chars)</span></span>;</span><br><span class="line"><span class="comment">// Informs the VM that the native code no longer needs access to chars.</span></span><br><span class="line"><span class="function">jstring <span class="title">NewString</span><span class="params">(JNIEnv *env, <span class="keyword">const</span> jchar *unicodeChars, jsize length)</span></span>;</span><br><span class="line"><span class="comment">// Constructs a new java.lang.String object from an array of Unicode characters.</span></span><br><span class="line"><span class="function">jsize <span class="title">GetStringLength</span><span class="params">(JNIEnv *env, jstring <span class="built_in">string</span>)</span></span>;</span><br><span class="line"><span class="comment">// Returns the length (the count of Unicode characters) of a Java string.</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">GetStringRegion</span><span class="params">(JNIEnv *env, jstring str, jsize start, jsize length, jchar *buf)</span></span>;</span><br><span class="line"><span class="comment">// Copies len number of Unicode characters beginning at offset start to the given buffer buf</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">native</span> <span class="keyword">double</span>[] sumAndAverage(<span class="keyword">int</span>[] numbers);</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span>[] numbers = &#123;<span class="number">22</span>, <span class="number">33</span>, <span class="number">33</span>&#125;;</span><br><span class="line"><span class="keyword">double</span>[] results = <span class="keyword">new</span> TestJNIPrimitiveArray().sumAndAverage(numbers);</span><br><span class="line">System.out.println(<span class="string">&quot;In Java, the sum is &quot;</span> + results[<span class="number">0</span>]);</span><br><span class="line">System.out.println(<span class="string">&quot;In Java, the average is &quot;</span> + results[<span class="number">1</span>]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;jni.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &quot;TestJNIPrimitiveArray.h&quot;</span><br><span class="line">JNIEXPORT jdoubleArray JNICALL Java_TestJNIPrimitiveArray_sumAndAverage</span><br><span class="line">          (JNIEnv *env, jobject thisObj, jintArray inJNIArray) &#123;</span><br><span class="line">   &#x2F;&#x2F; Step 1: Convert the incoming JNI jintarray to C&#39;s jint[]</span><br><span class="line">   jint *inCArray &#x3D; (*env)-&gt;GetIntArrayElements(env, inJNIArray, NULL);</span><br><span class="line">   if (NULL &#x3D;&#x3D; inCArray) return NULL;</span><br><span class="line">   jsize length &#x3D; (*env)-&gt;GetArrayLength(env, inJNIArray);</span><br><span class="line">   &#x2F;&#x2F; Step 2: Perform its intended operations</span><br><span class="line">   jint sum &#x3D; 0;</span><br><span class="line">   int i;</span><br><span class="line">   for (i &#x3D; 0; i &lt; length; i++) &#123;</span><br><span class="line">      sum +&#x3D; inCArray[i];</span><br><span class="line">   &#125;</span><br><span class="line">   jdouble average &#x3D; (jdouble)sum &#x2F; length;</span><br><span class="line">   (*env)-&gt;ReleaseIntArrayElements(env, inJNIArray, inCArray, 0); &#x2F;&#x2F; release resources</span><br><span class="line">   jdouble outCArray[] &#x3D; &#123;sum, average&#125;;</span><br><span class="line">   &#x2F;&#x2F; Step 3: Convert the C&#39;s Native jdouble[] to JNI jdoublearray, and return</span><br><span class="line">   jdoubleArray outJNIArray &#x3D; (*env)-&gt;NewDoubleArray(env, 2);  &#x2F;&#x2F; allocate</span><br><span class="line">   if (NULL &#x3D;&#x3D; outJNIArray) return NULL;</span><br><span class="line">   (*env)-&gt;SetDoubleArrayRegion(env, outJNIArray, 0 , 2, outCArray);  &#x2F;&#x2F; copy</span><br><span class="line">   return outJNIArray;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>JNI基本类型数组函数</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ArrayType: jintArray, jbyteArray, jshortArray, jlongArray, jfloatArray, jdoubleArray, jcharArray, jbooleanArray</span></span><br><span class="line"><span class="comment">// PrimitiveType: int, byte, short, long, float, double, char, boolean</span></span><br><span class="line"><span class="comment">// NativeType: jint, jbyte, jshort, jlong, jfloat, jdouble, jchar, jboolean</span></span><br><span class="line">NativeType * Get&lt;PrimitiveType&gt;ArrayElements(JNIEnv *env, ArrayType <span class="built_in">array</span>, jboolean *isCopy);</span><br><span class="line"><span class="keyword">void</span> Release&lt;PrimitiveType&gt;ArrayElements(JNIEnv *env, ArrayType <span class="built_in">array</span>, NativeType *elems, jint mode);</span><br><span class="line"><span class="keyword">void</span> Get&lt;PrimitiveType&gt;ArrayRegion(JNIEnv *env, ArrayType <span class="built_in">array</span>, jsize start, jsize length, NativeType *buffer);</span><br><span class="line"><span class="keyword">void</span> Set&lt;PrimitiveType&gt;ArrayRegion(JNIEnv *env, ArrayType <span class="built_in">array</span>, jsize start, jsize length, <span class="keyword">const</span> NativeType *buffer);</span><br><span class="line">ArrayType New&lt;PrimitiveType&gt;Array(JNIEnv *env, jsize length);</span><br><span class="line"><span class="function"><span class="keyword">void</span> * <span class="title">GetPrimitiveArrayCritical</span><span class="params">(JNIEnv *env, jarray <span class="built_in">array</span>, jboolean *isCopy)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ReleasePrimitiveArrayCritical</span><span class="params">(JNIEnv *env, jarray <span class="built_in">array</span>, <span class="keyword">void</span> *carray, jint mode)</span></span>;</span><br></pre></td></tr></table></figure>

<h2 id="函数签名"><a href="#函数签名" class="headerlink" title="函数签名"></a>函数签名</h2><h2 id="创建对象与对象数组"><a href="#创建对象与对象数组" class="headerlink" title="创建对象与对象数组"></a>创建对象与对象数组</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;TestJNIConstructor.h&quot;</span></span></span><br><span class="line">JNIEXPORT jobject JNICALL Java_TestJNIConstructor_getIntegerObject</span><br><span class="line">          (JNIEnv *env, jobject thisObj, jint number) &#123;</span><br><span class="line">   <span class="comment">// Get a class reference for java.lang.Integer</span></span><br><span class="line">   jclass cls = (*env)-&gt;FindClass(env, <span class="string">&quot;java/lang/Integer&quot;</span>);</span><br><span class="line">   <span class="comment">// Get the Method ID of the constructor which takes an int</span></span><br><span class="line">   jmethodID midInit = (*env)-&gt;GetMethodID(env, cls, <span class="string">&quot;&lt;init&gt;&quot;</span>, <span class="string">&quot;(I)V&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midInit) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">   <span class="comment">// Call back constructor to allocate a new instance, with an int argument</span></span><br><span class="line">   jobject newObj = (*env)-&gt;NewObject(env, cls, midInit, number);</span><br><span class="line">   <span class="comment">// Try runnning the toString() on this newly create object</span></span><br><span class="line">   jmethodID midToString = (*env)-&gt;GetMethodID(env, cls, <span class="string">&quot;toString&quot;</span>, <span class="string">&quot;()Ljava/lang/String;&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midToString) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">   jstring resultStr = (*env)-&gt;CallObjectMethod(env, newObj, midToString);</span><br><span class="line">   <span class="keyword">const</span> <span class="keyword">char</span> *resultCStr = (*env)-&gt;GetStringUTFChars(env, resultStr, <span class="literal">NULL</span>);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C: the number is %s\n&quot;</span>, resultCStr);</span><br><span class="line">   <span class="keyword">return</span> newObj;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对象函数</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">jclass <span class="title">FindClass</span><span class="params">(JNIEnv *env, <span class="keyword">const</span> <span class="keyword">char</span> *name)</span></span>;</span><br><span class="line"><span class="function">jobject <span class="title">NewObject</span><span class="params">(JNIEnv *env, jclass cls, jmethodID methodID, ...)</span></span>;</span><br><span class="line"><span class="function">jobject <span class="title">NewObjectA</span><span class="params">(JNIEnv *env, jclass cls, jmethodID methodID, <span class="keyword">const</span> jvalue *args)</span></span>;</span><br><span class="line"><span class="function">jobject <span class="title">NewObjectV</span><span class="params">(JNIEnv *env, jclass cls, jmethodID methodID, va_list args)</span></span>;</span><br><span class="line"><span class="comment">//Constructs a new Java object.The method ID indicates which constructor method to invoke</span></span><br><span class="line"><span class="function">jobject <span class="title">AllocObject</span><span class="params">(JNIEnv *env, jclass cls)</span></span>;</span><br><span class="line"><span class="comment">//Allocates a new Java object without invoking any of the constructors for the object.</span></span><br></pre></td></tr></table></figure>
<p>对象数组</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;TestJNIObjectArray.h&quot;</span></span></span><br><span class="line">JNIEXPORT jobjectArray JNICALL Java_TestJNIObjectArray_sumAndAverage</span><br><span class="line">          (JNIEnv *env, jobject thisObj, jobjectArray inJNIArray) &#123;</span><br><span class="line">   <span class="comment">// Get a class reference for java.lang.Integer</span></span><br><span class="line">   jclass classInteger = (*env)-&gt;FindClass(env, <span class="string">&quot;java/lang/Integer&quot;</span>);</span><br><span class="line">   <span class="comment">// Use Integer.intValue() to retrieve the int</span></span><br><span class="line">   jmethodID midIntValue = (*env)-&gt;GetMethodID(env, classInteger, <span class="string">&quot;intValue&quot;</span>, <span class="string">&quot;()I&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midIntValue) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">   <span class="comment">// Get the value of each Integer object in the array</span></span><br><span class="line">   jsize length = (*env)-&gt;GetArrayLength(env, inJNIArray);</span><br><span class="line">   jint sum = <span class="number">0</span>;</span><br><span class="line">   <span class="keyword">int</span> i;</span><br><span class="line">   <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">      jobject objInteger = (*env)-&gt;GetObjectArrayElement(env, inJNIArray, i);</span><br><span class="line">      <span class="keyword">if</span> (<span class="literal">NULL</span> == objInteger) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">      jint value = (*env)-&gt;CallIntMethod(env, objInteger, midIntValue);</span><br><span class="line">      sum += value;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">double</span> average = (<span class="keyword">double</span>)sum / length;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, the sum is %d\n&quot;</span>, sum);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, the average is %f\n&quot;</span>, average);</span><br><span class="line">   <span class="comment">// Get a class reference for java.lang.Double</span></span><br><span class="line">   jclass classDouble = (*env)-&gt;FindClass(env, <span class="string">&quot;java/lang/Double&quot;</span>);</span><br><span class="line">   <span class="comment">// Allocate a jobjectArray of 2 java.lang.Double</span></span><br><span class="line">   jobjectArray outJNIArray = (*env)-&gt;NewObjectArray(env, <span class="number">2</span>, classDouble, <span class="literal">NULL</span>);</span><br><span class="line">   <span class="comment">// Construct 2 Double objects by calling the constructor</span></span><br><span class="line">   jmethodID midDoubleInit = (*env)-&gt;GetMethodID(env, classDouble, <span class="string">&quot;&lt;init&gt;&quot;</span>, <span class="string">&quot;(D)V&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midDoubleInit) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">   jobject objSum = (*env)-&gt;NewObject(env, classDouble, midDoubleInit, (<span class="keyword">double</span>)sum);</span><br><span class="line">   jobject objAve = (*env)-&gt;NewObject(env, classDouble, midDoubleInit, average);</span><br><span class="line">   <span class="comment">// Set to the jobjectArray</span></span><br><span class="line">   (*env)-&gt;SetObjectArrayElement(env, outJNIArray, <span class="number">0</span>, objSum);</span><br><span class="line">   (*env)-&gt;SetObjectArrayElement(env, outJNIArray, <span class="number">1</span>, objAve);</span><br><span class="line">   <span class="keyword">return</span> outJNIArray;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>局部变量</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestJNIReference</span> </span>&#123;</span><br><span class="line">   <span class="keyword">static</span> &#123;</span><br><span class="line">      System.loadLibrary(<span class="string">&quot;myjni&quot;</span>); <span class="comment">// myjni.dll (Windows) or libmyjni.so (Unixes)</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// A native method that returns a java.lang.Integer with the given int.</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">native</span> Integer <span class="title">getIntegerObject</span><span class="params">(<span class="keyword">int</span> number)</span></span>;</span><br><span class="line">   <span class="comment">// Another native method that also returns a java.lang.Integer with the given int.</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">native</span> Integer <span class="title">anotherGetIntegerObject</span><span class="params">(<span class="keyword">int</span> number)</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">      TestJNIReference test = <span class="keyword">new</span> TestJNIReference();</span><br><span class="line">      System.out.println(test.getIntegerObject(<span class="number">1</span>));</span><br><span class="line">      System.out.println(test.getIntegerObject(<span class="number">2</span>));</span><br><span class="line">      System.out.println(test.anotherGetIntegerObject(<span class="number">11</span>));</span><br><span class="line">      System.out.println(test.anotherGetIntegerObject(<span class="number">12</span>));</span><br><span class="line">      System.out.println(test.getIntegerObject(<span class="number">3</span>));</span><br><span class="line">      System.out.println(test.anotherGetIntegerObject(<span class="number">13</span>));</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;TestJNIReference.h&quot;</span></span></span><br><span class="line"><span class="comment">// Global Reference to the Java class &quot;java.lang.Integer&quot;</span></span><br><span class="line"><span class="keyword">static</span> jclass classInteger;</span><br><span class="line"><span class="keyword">static</span> jmethodID midIntegerInit;</span><br><span class="line"><span class="function">jobject <span class="title">getInteger</span><span class="params">(JNIEnv *env, jobject thisObj, jint number)</span> </span>&#123;</span><br><span class="line">   <span class="comment">// Get a class reference for java.lang.Integer if missing</span></span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == classInteger) &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;Find java.lang.Integer\n&quot;</span>);</span><br><span class="line">      classInteger = (*env)-&gt;FindClass(env, <span class="string">&quot;java/lang/Integer&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == classInteger) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">   <span class="comment">// Get the Method ID of the Integer&#x27;s constructor if missing</span></span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midIntegerInit) &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;Get Method ID for java.lang.Integer&#x27;s constructor\n&quot;</span>);</span><br><span class="line">      midIntegerInit = (*env)-&gt;GetMethodID(env, classInteger, <span class="string">&quot;&lt;init&gt;&quot;</span>, <span class="string">&quot;(I)V&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">NULL</span> == midIntegerInit) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">   <span class="comment">// Call back constructor to allocate a new instance, with an int argument</span></span><br><span class="line">   jobject newObj = (*env)-&gt;NewObject(env, classInteger, midIntegerInit, number);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;In C, constructed java.lang.Integer with number %d\n&quot;</span>, number);</span><br><span class="line">   <span class="keyword">return</span> newObj;</span><br><span class="line">&#125;</span><br><span class="line">JNIEXPORT jobject JNICALL Java_TestJNIReference_getIntegerObject</span><br><span class="line">          (JNIEnv *env, jobject thisObj, jint number) &#123;</span><br><span class="line">   <span class="keyword">return</span> getInteger(env, thisObj, number);</span><br><span class="line">&#125;</span><br><span class="line">JNIEXPORT jobject JNICALL Java_TestJNIReference_anotherGetIntegerObject</span><br><span class="line">          (JNIEnv *env, jobject thisObj, jint number) &#123;</span><br><span class="line">   <span class="keyword">return</span> getInteger(env, thisObj, number);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; Get a class reference for java.lang.Integer if missing</span><br><span class="line">if (NULL &#x3D;&#x3D; classInteger) &#123;</span><br><span class="line">   printf(&quot;Find java.lang.Integer\n&quot;);</span><br><span class="line">   &#x2F;&#x2F; FindClass returns a local reference</span><br><span class="line">   jclass classIntegerLocal &#x3D; (*env)-&gt;FindClass(env, &quot;java&#x2F;lang&#x2F;Integer&quot;);</span><br><span class="line">   &#x2F;&#x2F; Create a global reference from the local reference</span><br><span class="line">   classInteger &#x3D; (*env)-&gt;NewGlobalRef(env, classIntegerLocal);</span><br><span class="line">   &#x2F;&#x2F; No longer need the local reference, free it!</span><br><span class="line">   (*env)-&gt;DeleteLocalRef(env, classIntegerLocal);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h1><h2 id="如何避免内存泄露"><a href="#如何避免内存泄露" class="headerlink" title="如何避免内存泄露"></a>如何避免内存泄露</h2>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JNI</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基本语法与小错误</title>
    <url>/Java/lang/</url>
    <content><![CDATA[<h1 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h1><h1 id="常见的小错误"><a href="#常见的小错误" class="headerlink" title="常见的小错误"></a>常见的小错误</h1><h2 id="装箱类型为null时与基本类型比较"><a href="#装箱类型为null时与基本类型比较" class="headerlink" title="装箱类型为null时与基本类型比较"></a>装箱类型为<code>null</code>时与基本类型比较</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">if</span> (i == <span class="number">1</span>) &#123;</span><br><span class="line">	System.out.println(<span class="string">&quot;success!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当装箱类型遇到比较运算符的时候，会首先调用相应的方法将装箱类型转换为基本类型，如果装箱类型变量为null，运行将会抛出<code>java.lang.NullPointerException</code>异常；而对于非装箱类型如<code>String</code>则没有这种情况。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String string = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">if</span> (string == <span class="string">&quot;&quot;</span>) &#123;</span><br><span class="line">  	System.out.println(<span class="string">&quot;success!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="String-split"><a href="#String-split" class="headerlink" title="String.split"></a>String.split</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> String[] split(String regex,</span><br><span class="line">                      <span class="keyword">int</span> limit)</span><br><span class="line"><span class="comment">// The limit parameter controls the number of times the pattern is applied and therefore affects the length of the resulting array. If the limit n is greater than zero then the pattern will be applied at most n - 1 times, the array&#x27;s length will be no greater than n, and the array&#x27;s last entry will contain all input beyond the last matched delimiter. If n is non-positive then the pattern will be applied as many times as possible and the array can have any length. If n is zero then the pattern will be applied as many times as possible, the array can have any length, and trailing empty strings will be discarded.</span></span><br><span class="line"><span class="comment">// 1. -1 pattern将应用尽可能多的次数</span></span><br><span class="line"><span class="comment">// 2. 0 pattern将应用尽可能多的次数，默认的空字符串将忽略</span></span><br><span class="line"><span class="comment">// 3. n&gt;0 pattern将应用n-1次，最后一个元素会包含所有分隔符后的输入</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java内存管理</title>
    <url>/Java/memory/</url>
    <content><![CDATA[<h1 id="Java内存管理原理"><a href="#Java内存管理原理" class="headerlink" title="Java内存管理原理"></a>Java内存管理原理</h1><p>在Java运行体系结构中，存在Java程序、虚拟机和操作系统三个层次，Java程序与虚拟机交互(即<a href="/java-jni/" title="JNI：Java native interface ">JNI</a>)，虚拟机与操作系统间交互！这就保证了Java程序的平台无关性。</p>
<p>程序运行前，JVM向操作系统申请一定的内存空间，称为初始内存空间。</p>
<p>程序运行过程中，Java程序一直向Java虚拟机申请内存，当超过初始内存空间时，Java虚拟机再次向操作系统申请。当虚拟机已申请的内存超过规定的最大内存空间再申请时，将会出现内存溢出错误。</p>
<h1 id="内存的分配"><a href="#内存的分配" class="headerlink" title="内存的分配"></a>内存的分配</h1><p>Java内存可以分为方法区、heap(堆)和stack(栈)。</p>
<ul>
<li>方法区，默认64M，Java虚拟机会将加载的类存入，保存类的结构，静态成员等。</li>
<li>heap(堆)，默认64M，存放对象持有的数据，<strong>保持对原类的引用</strong> 。对象的属性值保存在堆中，对象调用的方法保存在方法区。通过<code>new</code>创建的对象都在堆中。方法中的局部变量使用final修饰后，放在堆中。</li>
<li>stack(栈), 默认为1M。</li>
<li>基础类型保存在栈中</li>
<li>局部变量保存在栈中<br>程序进入一个方法时，会为这个方法单独分配一块私属存储空间，用于存储这个方法内部的局部变量，当这个方法结束时，分配给这个方法的栈会释放，这个栈中的变量也将随之释放。</li>
</ul>
<h2 id="在堆上分配内存与赋值异步性"><a href="#在堆上分配内存与赋值异步性" class="headerlink" title="在堆上分配内存与赋值异步性"></a>在堆上分配内存与赋值异步性</h2><p>在Java的指令中，创建对象和赋值操作是分开进行的，如<code>instance=new Singleton();</code>语句是分为两步进行的，但是JVM并不保证这两个操作的先后顺序，也就是有可能JVM会为Singleton实例分配空间， 然后直接赋值给 <code>instance</code>成员，然后再去初始化这个Singleton实例。这样就可能出错了，我们以A、B两个线程为例：</p>
<ol>
<li>A、B线程同时进入了第一个if判断</li>
<li>A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton();</li>
<li>由于JVM内部的优化机制，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。</li>
<li>B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。</li>
<li>此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。</li>
</ol>
<h2 id="基础类型"><a href="#基础类型" class="headerlink" title="基础类型"></a>基础类型</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a=<span class="number">3</span>;</span><br><span class="line"><span class="keyword">int</span> b=<span class="number">3</span>;</span><br><span class="line">a=<span class="number">4</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>编译器先处理<code>int a=3;</code>:<br>首先，在栈中创建一个变量为a的引用，然后查找有没有字面量为3的地址。没有，则开辟一个存放3这个字面量的地址，然后将a指向这个地址。</p>
</li>
<li><p>再处理<code>int b=3;</code>:<br>首先创建一个变量为b的引用，然后查找发现已经存在字面量为3的地址，将b指向这个地址。</p>
</li>
<li><p>如果此时，再<code>a=4;</code>:<br>那么，虚拟机存在是否存在4这个字面量，如果存在，直接将a指向这个地址；否则，创建4这个字面量，将a指向这个字面量的地址。</p>
</li>
</ul>
<p>因此改变了a的值，只是a重新指向别的地方，不会影响b的值。</p>
<h2 id="对象存储"><a href="#对象存储" class="headerlink" title="对象存储"></a>对象存储</h2><blockquote>
<p>方法的存储</p>
</blockquote>
<p>定义如下类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BoxSet</span></span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> width=<span class="number">100</span>;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> hight=<span class="number">200</span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">BoxSet</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> y)</span></span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.width=x;</span><br><span class="line">    <span class="keyword">this</span>.hight=y;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BoxSet boxSet; <span class="comment">// (1)</span></span><br><span class="line">boxSet=<span class="keyword">new</span> BoxSet(<span class="number">50</span>,<span class="number">50</span>); <span class="comment">// (2)</span></span><br></pre></td></tr></table></figure>
<p>两条语句:</p>
<ol>
<li>声明变量boxSet：</li>
</ol>
<ul>
<li>在栈内存中，为对象的引用变量<code>boxSet</code>分配内存空间。但是<code>boxSet</code>的值为空，称<code>boxSet</code>为一个空对象。空对象不能使用，因为它没有引用任何“实体”。</li>
</ul>
<ol start="2">
<li>会做两件事：</li>
</ol>
<ul>
<li>在堆内存中，为类的成员变量<code>width</code>和<code>hight</code>分配内存，并赋值为各数据类型的默认值。</li>
<li>显式初始化: 类定义时的初始化值，即<code>width</code>赋值为100，<code>hight</code>赋值为200</li>
<li>调用构造方法: 为<code>width</code>和<code>hight</code>分别赋值为50和50</li>
<li>返回堆内存中对象的引用给引用变量<code>boxSet</code></li>
</ul>
<h2 id="方法存储"><a href="#方法存储" class="headerlink" title="方法存储"></a>方法存储</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Dog</span> </span>&#123;</span><br><span class="line">  Collar c;</span><br><span class="line">  String name;</span><br><span class="line"><span class="comment">//1. main()方法位于栈上</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">//2. 在栈上创建引用变量d,但Dog对象尚未存在</span></span><br><span class="line">    Dog d;</span><br><span class="line"><span class="comment">//3. 在堆上创建新的Dog对象，并将其赋予d引用变量</span></span><br><span class="line">    d = <span class="keyword">new</span> Dog();</span><br><span class="line"><span class="comment">//4. 将引用变量的一个副本传递给go()方法</span></span><br><span class="line">    d.go(d);</span><br><span class="line">  &#125;</span><br><span class="line"><span class="comment">//5. 将go()方法置于栈上，并将dog参数作为局部变量(局部变量位于栈上)</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">go</span><span class="params">(Dog dog)</span></span>&#123;</span><br><span class="line"><span class="comment">//6. 在堆上创建新的Collar对象，并将其赋予Dog的实例变量</span></span><br><span class="line">    c =<span class="keyword">new</span> Collar();</span><br><span class="line">  &#125;</span><br><span class="line"><span class="comment">//7.将setName()添加到栈上，并将dogName参数作为其局部变量</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">setName</span><span class="params">(String dogName)</span></span>&#123;</span><br><span class="line"><span class="comment">//8. name的实例对象也引用String对象</span></span><br><span class="line">    name=dogName;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="comment">//9. 程序执行完成后，setName()将会完成并从栈中清除，</span></span><br><span class="line"><span class="comment">//此时，局部变量dogName也会消失，尽管它所引用的String仍在堆上</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="包装类"><a href="#包装类" class="headerlink" title="包装类"></a>包装类</h2><blockquote>
<p>2.String StringBuffered 与 StringBuilder 区别</p>
</blockquote>
<p>Java中的基本变量都存在包装类，如下表：</p>
<table>
<thead>
<tr>
<th>0</th>
<th>基本变量</th>
<th>包装类</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>int</td>
<td>Integer</td>
</tr>
<tr>
<td>2</td>
<td>long</td>
<td>Long</td>
</tr>
<tr>
<td>3</td>
<td>short</td>
<td>Short</td>
</tr>
<tr>
<td>4</td>
<td>float</td>
<td>Float</td>
</tr>
<tr>
<td>5</td>
<td>double</td>
<td>Double</td>
</tr>
<tr>
<td>6</td>
<td>boolean</td>
<td>Boolean</td>
</tr>
<tr>
<td>7</td>
<td>byte</td>
<td>Byte</td>
</tr>
<tr>
<td>8</td>
<td>char</td>
<td>Character</td>
</tr>
</tbody></table>
<h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s=<span class="string">&quot;abc&quot;</span>;</span><br></pre></td></tr></table></figure>
<ol>
<li>在栈内存中为对象的引用变量<code>s</code>分配内存</li>
<li>查找字面量<code>&quot;abc&quot;</code>，如果存在则将该地址赋值给s; 否则，新建字面量<code>&quot;abc&quot;</code>并将赋值给s。</li>
</ol>
<p>继续看下面的例子:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s=<span class="keyword">new</span> String(<span class="string">&quot;abc&quot;</span>); <span class="comment">//(2)</span></span><br></pre></td></tr></table></figure>
<p>方式2:</p>
<ol>
<li>在栈内存中为对象的引用变量<code>s</code>分配内存</li>
<li>在堆中新建String对象，并将地址赋值给栈中的s</li>
<li>在栈内存中，查找字面量”abc”, 如果存在则将字面量地址作为参数传递给赋值给栈中s指向的String对象；否则，新建字面量”abc”.<br>因此，在这个过程中共产生了两个对象。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str1 = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">String str2 = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">System.out.println(str1==str2);   <span class="comment">//true</span></span><br></pre></td></tr></table></figure>
<p>　　注意，我们这里并不用<code>str1.equals(str2)；</code>的方式，因为这将比较两个字符串的值是否相等。<code>==</code>号，根据JDK的说明，只有在两个引用都指向了同一个对象时才返回真值。而我们在这里要看的是，str1与str2是否都指向了同一个对象。<br>结果说明，JVM创建了两个引用str1和str2，但只创建了一个对象，而且两个引用都指向了这个对象。</p>
<p>String可以用<code>String str = new String(&quot;abc&quot;);</code>的形式来创建，也可以用<code>String str = &quot;abc&quot;；</code>的形式来创建，这种表达式是可以的！前者是规范的类的创建过程，即在Java中，一切都是对象，而对象是类的实例，全部通过new()的形式来创建。那为什么在<code>String str = &quot;abc&quot;；</code>中，并没有通过<code>new()</code>来创建实例，是不是违反了上述原则？其实没有。</p>
<p>我们再来更进一步，将以上代码改成：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str1 = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">String str2 = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">str1 = <span class="string">&quot;bcd&quot;</span>;</span><br><span class="line">System.out.println(str1==str2);   <span class="comment">//false</span></span><br><span class="line">System.out.println(str1 + <span class="string">&quot;,&quot;</span> + str2);   <span class="comment">//bcd, abc</span></span><br></pre></td></tr></table></figure>
<p>　　这就是说，赋值的变化导致了类对象引用的变化，str1指向了另外一个新对象！而str2仍旧指向原来的对象。上例中，当我们将str1的值改为”bcd”时，JVM发现在栈中没有存放该值的地址，便开辟了这个地址，并创建了一个新的对象，其字符串的值指向这个地址。<br>　　事实上，String类被设计成为不可改变(immutable)的类。如果你要改变其值，可以，但JVM在运行时根据新值悄悄创建了一个新对象，然后将这个对象的地址返回给原来类的引用。这个创建过程虽说是完全自动进行的，但它毕竟占用了更多的时间。在对时间要求比较敏感的环境中，会带有一定的不良影响。</p>
<p>　　再修改原来代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">　　String str1 = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">　　String str2 = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line"></span><br><span class="line">　　str1 = <span class="string">&quot;bcd&quot;</span>;</span><br><span class="line"></span><br><span class="line">　　String str3 = str1;</span><br><span class="line">　　System.out.println(str3);   <span class="comment">//bcd</span></span><br><span class="line"></span><br><span class="line">　　String str4 = <span class="string">&quot;bcd&quot;</span>;</span><br><span class="line">　　System.out.println(str1 == str4);   <span class="comment">//true</span></span><br></pre></td></tr></table></figure>
<p>　　str3 这个对象的引用直接指向str1所指向的对象(注意，str3并没有创建新对象)。当str1改完其值后，再创建一个String的引用str4，并指向因str1修改值而创建的新的对象。可以发现，这回str4也没有创建新的对象，从而再次实现栈中数据的共享。</p>
<p>　　我们再接着看以下的代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">　　String str1 = <span class="keyword">new</span> String(<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">　　String str2 = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">　　System.out.println(str1==str2);   <span class="comment">//false</span></span><br></pre></td></tr></table></figure>
<p>　　创建了两个引用。创建了两个对象。两个引用分别指向不同的两个对象。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">　　String str1 = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">　　String str2 = <span class="keyword">new</span> String(<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">　　System.out.println(str1==str2);   <span class="comment">//false</span></span><br></pre></td></tr></table></figure>
<p>　　创建了两个引用。创建了两个对象。两个引用分别指向不同的两个对象。</p>
<p>　　以上两段代码说明，<strong>只要是用new()来新建对象的，都会在堆中创建，而且其字符串是单独存值的，即使与栈中的数据相同，也不会与栈中的数据共享。</strong></p>
<p>　　6). <strong>数据类型包装类的值不可修改</strong>。不仅仅是String类的值不可修改，所有的数据类型包装类都不能更改其内部的值。</p>
<h2 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h2><p>Volatile修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。</p>
<p>首先, 应该明白计算机内部都做什么了。比如做了一个i++操作，计算机内部做了三次处理：读取－修改－写入。<br>同样，对于一个long型数据，做了个赋值操作，在32系统下需要经过两步才能完成，先修改低32位，然后修改高32位。<br>假想一下，当将以上的操作放到一个多线程环境下操作时候，有可能出现的问题，是这些步骤执行了一部分，而另外一个线程就已经引用了变量值，这样就导致了读取脏数据的问题。<br>通过这个设想，就不难理解volatile关键字了。</p>
<p>volatile可以用在任何变量前面，但不能用于final变量前面，因为final型的变量是禁止修改的。也不存在线程安全的问题。</p>
<h1 id="内存释放"><a href="#内存释放" class="headerlink" title="内存释放"></a>内存释放</h1><h2 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h2><p>垃圾回收是一种动态存储管理技术，它自动地释放不再被程序引用的对象，按照特定的垃圾收集算法来实现资源自动回收的功能。当一个对象不再被引用的时候，内存回收它占领的空间，以便空间被后来的新对象使用，以免造成内存泄露。</p>
<p>一般是在CPU空闲或空间不足时自动进行垃圾回收，而程序员无法精确控制垃圾回收的时机和顺序等。<br>当没有任何获得线程能访问一个对象时，该对象就符合垃圾回收条件。<br> 垃圾回收器如发现一个对象不能被任何活线程访问时，他将认为该对象符合删除条件，就将其加入回收队列，但不是立即销毁对象，何时销毁并释放内存是无法预知的。垃圾回收不能强制执行，然而Java提供了一些方法（如：System.gc()方法），允许你请求JVM执行垃圾回收，而不是要求，虚拟机会尽其所能满足请求，但是不能保证JVM从内存中删除所有不用的对象。</p>
<h3 id="符合垃圾回收的条件"><a href="#符合垃圾回收的条件" class="headerlink" title="符合垃圾回收的条件"></a>符合垃圾回收的条件</h3><ol>
<li>空引用</li>
<li>重新为引用变量赋值：可以通过设置引用变量引用另一个对象来解除该引用变量与一个对象间的引用关系。</li>
<li>方法内创建的对象：所创建的局部变量仅在该方法的作用期间内存在。一旦该方法返回，在这个方法内创建的对象就符合垃圾收集条件。有一种明显的例外情况，就是方法的返回对象。</li>
<li>隔离引用：这种情况中，被回收的对象仍具有引用，这种情况称作隔离岛。若存在这两个实例，他们互相引用，并且这两个对象的所有其他引用都删除，其他任何线程无法访问这两个对象中的任意一个。也可以符合垃圾回收条件。</li>
</ol>
<h3 id="强制垃圾回收"><a href="#强制垃圾回收" class="headerlink" title="强制垃圾回收"></a>强制垃圾回收</h3><h3 id="finalize"><a href="#finalize" class="headerlink" title="finalize()"></a>finalize()</h3><p>java提供了一种机制，使你能够在对象刚要被垃圾回收之前运行一些代码。这段代码位于名为finalize()的方法内，所有类从Object类继承这个方法。由于不能保证垃圾回收器会删除某个对象。因此放在finalize()中的代码无法保证运行。因此建议不要重写finalize();</p>
<h2 id="内存泄露"><a href="#内存泄露" class="headerlink" title="内存泄露"></a>内存泄露</h2><p>内存泄漏就是存在一些被分配的对象，这些对象有下面两个特点:<br>首先，这些对象是有被引用的，即在有向树形图中，存在树枝通路可以与其相连；<br>其次，这些对象是无用的，即程序以后不会再使用这些对象。<br>如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Vector v = <span class="keyword">new</span> Vector(<span class="number">10</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">100</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">Object o = <span class="keyword">new</span> Object();  </span><br><span class="line">v.add(o);  </span><br><span class="line">o = <span class="keyword">null</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>//此时，所有的Object对象都没有被释放，因为变量v引用这些对象。   实际上无用，而还被引用的对象，GC就无能为力了(事实上GC认为它还有用)，这一点是导致内存泄漏最重要的原因。</p>
<h1 id="优化编程"><a href="#优化编程" class="headerlink" title="优化编程"></a>优化编程</h1><h2 id="1-不要显式调用System-gc"><a href="#1-不要显式调用System-gc" class="headerlink" title="(1)不要显式调用System.gc()"></a>(1)不要显式调用System.gc()</h2><p>　　此函数建议JVM进行主GC,虽然只是建议而非一定,但很多情况下它会触发主GC,从而增加主GC的频率,也即增加了间歇性停顿的次数。</p>
<h2 id="2-尽量减少临时对象的使用"><a href="#2-尽量减少临时对象的使用" class="headerlink" title="(2)尽量减少临时对象的使用"></a>(2)尽量减少临时对象的使用</h2><p>　　临时对象在跳出函数调用后,会成为垃圾,少用临时变量就相当于减少了垃圾的产生,从而延长了出现上述第二个触发条件出现的时间,减少了主GC的机会。</p>
<h2 id="3-对象不用时最好显式置为Null"><a href="#3-对象不用时最好显式置为Null" class="headerlink" title="(3)对象不用时最好显式置为Null"></a>(3)对象不用时最好显式置为Null</h2><p>　　一般而言,为Null的对象都会被作为垃圾处理,所以将不用的对象显式地设为Null,有利于GC收集器判定垃圾,从而提高了GC的效率。</p>
<h2 id="4-尽量使用StringBuffer-而不用String来累加字符串"><a href="#4-尽量使用StringBuffer-而不用String来累加字符串" class="headerlink" title="(4)尽量使用StringBuffer,而不用String来累加字符串"></a>(4)尽量使用StringBuffer,而不用String来累加字符串</h2><p>   由于String是固定长的字符串对象,累加String对象时,并非在一个String对象中扩增,而是重新创建新的String对象,如Str5=Str1+Str2+Str3+Str4,这条语句执行过程中会产生多个垃圾对象,因为对次作“+”操作时都必须创建新的String对象,但这些过渡对象对系统来说是没有实际意义的,只会增加更多的垃圾。避免这种情况可以改用StringBuffer来累加字符串,因StringBuffer是可变长的,它在原有基础上进行扩增,不会产生中间对象。</p>
<h2 id="5-能用基本类型如Int-Long-就不用Integer-Long对象"><a href="#5-能用基本类型如Int-Long-就不用Integer-Long对象" class="headerlink" title="(5)能用基本类型如Int,Long,就不用Integer,Long对象"></a>(5)能用基本类型如Int,Long,就不用Integer,Long对象</h2><p>　　基本类型变量占用的内存资源比相应对象占用的少得多,如果没有必要,最好使用基本变量。</p>
<h2 id="6-尽量少用静态对象变量"><a href="#6-尽量少用静态对象变量" class="headerlink" title="(6)尽量少用静态对象变量"></a>(6)尽量少用静态对象变量</h2><p>　　静态变量属于全局变量,不会被GC回收,它们会一直占用内存。</p>
<h2 id="7-分散对象创建或删除的时间"><a href="#7-分散对象创建或删除的时间" class="headerlink" title="(7)分散对象创建或删除的时间"></a>(7)分散对象创建或删除的时间</h2><p>　集中在短时间内大量创建新对象,特别是大对象,会导致突然需要大量内存,JVM在面临这种情况时,只能进行主GC,以回收内存或整合内存碎片,从而增加主GC的频率。集中删除对象,道理也是一样的。它使得突然出现了大量的垃圾对象,空闲空间必然减少,从而大大增加了下一次创建新对象时强制主GC的机会。</p>
<hr>
<p>参考文献</p>
<ol>
<li><a href="http://www.codeceo.com/article/java-memory-model-volatile.html" title="Java内存模型与volatile关键字">Java内存模型与volatile关键字</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>memory</tag>
        <tag>heap</tag>
        <tag>stack</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title>正则表达式</title>
    <url>/Java/regular-expression/</url>
    <content><![CDATA[<h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><h2 id="元字符"><a href="#元字符" class="headerlink" title="元字符"></a>元字符</h2><ol>
<li><code>\w</code> 匹配一个字符，可以是数字、下划线、字母或者汉字</li>
<li><code>\b</code> 匹配的是位置，它的前一个字符和后一个字符不全是(一个是, 一个不是或不存在) <code>\w</code></li>
</ol>
<ul>
<li><code>\bhi\b</code> 匹配hi单词， 对于history和him都不匹配</li>
<li><code>\bhi\b.*\blucy\b</code> hi单词后面若干字符之后是lucy</li>
</ul>
<ol>
<li><code>.</code> 匹配除了换行符之外的任一字符<br><code>\bhi.lucy\b</code>在hi和lucy中存在一个除了换行符之外的任一字符</li>
<li><code>*</code> 匹配的是数量 0~若干个<br><code>\bhi\b.*\blucy\b</code> hi单词后面若干个除换行符以外的字符之后是lucy</li>
<li><code>\s</code> 匹配任意的空白符</li>
<li><code>\d</code> 匹配数字<br><code>0\d&#123;2&#125;-\d&#123;8&#125;</code> 匹配以0开头，紧接着是2位数字，接着是-，最后是8位数字<br><code>\d+</code> 匹配多于一个数字</li>
<li><code>[0123456789]</code>或者<code>[0-9]</code> 匹配数字与<code>\d</code>的意义完全相同</li>
<li><code>^</code> 匹配字符串的开始</li>
<li><code>$</code> 匹配字符串的结束<br><code>^\b&#123;5,12&#125;$</code> 匹配5到12位的数字</li>
</ol>
<h2 id="字符转义"><a href="#字符转义" class="headerlink" title="字符转义"></a>字符转义</h2><p>使用斜杠<code>\</code>对特殊字符转义，转换为普通字符</p>
<h2 id="重复"><a href="#重复" class="headerlink" title="重复"></a>重复</h2><table>
<thead>
<tr>
<th>代码/语法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>*</code></td>
<td>重复零次或更多次</td>
</tr>
<tr>
<td><code>+</code></td>
<td>重复一次或者更多次</td>
</tr>
<tr>
<td><code>?</code></td>
<td>重复零次或一次</td>
</tr>
<tr>
<td><code>&#123;n&#125;</code></td>
<td>重复n次</td>
</tr>
<tr>
<td><code>&#123;n,&#125;</code></td>
<td>重复n次或更多次</td>
</tr>
<tr>
<td><code>&#123;n,m&#125;</code></td>
<td>重复n到m次</td>
</tr>
</tbody></table>
<p><code>windows\d+</code> windows后面紧跟着多于一个数字<br><code>^\w+</code> 以多于一个字符开头</p>
<h2 id="字符类"><a href="#字符类" class="headerlink" title="字符类"></a>字符类</h2><ol>
<li><p><code>[aeiou]</code> aeiou中的一个字符</p>
</li>
<li><p><code>[0-9]</code> 从0到9</p>
</li>
<li><p><code>[0-9A-Za-z]</code> 完全等同于 <code>\w</code>(如果不考虑中文字符)</p>
</li>
<li><p><code>[) -]</code> 从右括号、空格和减号中选择一个</p>
<p> <code>\(?0\d&#123;2&#125;[) -]?\d&#123;8&#125;</code> 首先是一个转义字符<code>\(</code>， 它可能出现0次或1次(?)， 然后是一个0， 后面跟着2个数字<code>\d&#123;2&#125;</code>，然后是)或-或空格中的一个，它出现1此或不出现(?), 最后是8个数字(\d{8}).</p>
</li>
</ol>
<h2 id="分枝条件"><a href="#分枝条件" class="headerlink" title="分枝条件"></a>分枝条件</h2><p>分枝条件: 满足若干条件中的一个就能匹配. 要注意优先级和各条件顺序问题.</p>
<p>** 例1 匹配电话号码<br>要匹配两种电话号码形式:  (0755)12345678 或者 0755-12345678 以及 0751-1234567</p>
<p><code>\(\d&#123;3,4&#125;\)\d&#123;7,8&#125;|\d&#123;3,4&#125;-\d&#123;7,8&#125;</code></p>
<p>** 例2: 注意分枝条件各条件的顺序<br>美国的邮编是有两种形式的: 5位数字 或者用连字号间隔的9位数字, 如12345和12345-1234两种形式.</p>
<p>应该使用<code>\d&#123;5&#125;-\d&#123;4&#125;|\d&#123;5&#125;</code>, 而不能使用<code>\d&#123;5&#125;|\d&#123;5&#125;-\d&#123;4&#125;</code><br>也就是说, 如果<code>\d&#123;5&#125;</code>提前匹配了<code>12345</code>之后会返回而丢弃掉后面的四位.</p>
<h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><p>分组可以实现子表达式重复出现.</p>
<p><code>(\d&#123;1,3&#125;\.)&#123;3&#125;\d&#123;1,3&#125;</code> 匹配以点号分割的四组数字, 每组数字是1到3位,如 <code>999.999.999.999</code> 或<code>1.1.0.0</code></p>
<p>** IP地址的匹配 **<br>IP地址分为4段, 每段的数字范围为: 0~255<br>正则表达式只能匹配字符串的格式, 不支持数值比较, 因此需要用尽可能精简的方式准确列出所有的可能性</p>
<p><code>((2[0-4]\d|25[0-5]|[0-1]?\d\d?)\.)&#123;3&#125;(2[0-4]\d|25[0-5]|[0-1]?\d\d?)</code></p>
<p>解释:</p>
<ol>
<li><code>2[0-4]\d</code> 首位是2,第二位可以为0到4,第三位是任意数字</li>
<li><code>25[0-5]</code> 前两位是25,第三位必须是0到5, 因为最大是255</li>
<li><code>[0-1]?\d\d?</code> 首位是0或1, 也可以首位不存在, 第二位为任何数字, 第三位是任意数字, 也可以不存在, 不存在这种情况下, 就只有前两位.<br> 为什么不是<code>[0-1]?\d?\d</code>?</li>
</ol>
<h2 id="反义"><a href="#反义" class="headerlink" title="反义"></a>反义</h2><p>对字符类进行反义, 只需要将上面<a href="">字符类</a>一节的所有的字符转为大写</p>
<table>
<thead>
<tr>
<th>代码/语法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>\W</code></td>
<td>匹配任意不是字母，数字，下划线，汉字的字符</td>
</tr>
<tr>
<td><code>\S</code></td>
<td>匹配任意不是空白符的字符</td>
</tr>
<tr>
<td><code>\D</code></td>
<td>匹配任意非数字的字符</td>
</tr>
<tr>
<td><code>\B</code></td>
<td>匹配不是单词开头或结束的位置</td>
</tr>
<tr>
<td><code>[^x]</code></td>
<td>匹配除了x以外的任意字符</td>
</tr>
<tr>
<td><code>[^aeiou]</code></td>
<td>匹配除了aeiou这几个字母以外的任意字符</td>
</tr>
</tbody></table>
<h2 id="后向引用"><a href="#后向引用" class="headerlink" title="后向引用"></a>后向引用</h2><p>用于引用上文中匹配到的字符- 给上文中出现的表达式添加组号, 在下文中引用这个组号</p>
<table>
<thead>
<tr>
<th>代码/语法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>(exp)</code></td>
<td>匹配exp,并捕获文本到自动命名的组里</td>
</tr>
<tr>
<td><code>(?&lt;name&gt;exp)</code></td>
<td>匹配exp,并捕获文本到名称为name的组里，也可以写成(?’name’exp)</td>
</tr>
<tr>
<td><code>(?:exp)</code></td>
<td>匹配exp,不捕获匹配的文本，也不给此分组分配组号</td>
</tr>
</tbody></table>
<p>分组命名规则为:</p>
<ul>
<li>  分组0对应整个正则表达式</li>
<li>  实际上组号分配过程是要从左向右扫描两遍的：第一遍只给未命名组分配，第二遍只给命名组分配－－因此所有命名组的组号都大于未命名的组号</li>
<li>  你可以使用(?:exp)这样的语法来剥夺一个分组对组号分配的参与权．</li>
</ul>
<p>例1 <strong>自动命名</strong><br><code>\b(\w+)\b\s+\1\b</code> 首先匹配一个单词(<code>\w+</code>)并放到分组1中, 在下文中通过<code>\1</code>引用上文中分组1匹配到的字符.<br>该表达式用于匹配重复单词. 如 <code>hello hello</code></p>
<p>例2 <strong>手动命名</strong><br><code>\b(?&lt;name&gt;\w+)\b\s+\k&lt;name&gt;\b</code> 首先匹配一个单词(<code>\w+</code>) 并将这个单词放入name组中, 在下文中引用name分组, 看后面是否再出现<br>注意反向引用时的格式: <code>\k&lt;name&gt;</code></p>
<p>例3 <strong>不捕获</strong><br>    <code>\b(?:\w+)\b\s+</code> 不捕获</p>
<h2 id="零宽断言"><a href="#零宽断言" class="headerlink" title="零宽断言"></a>零宽断言</h2><p>零宽断言和负向零宽断言用于指示位置, 零宽断言分为两种, 分别指示匹配表达式的前面和后面.</p>
<h3 id="零宽度正预测先行断言"><a href="#零宽度正预测先行断言" class="headerlink" title="零宽度正预测先行断言"></a>零宽度正预测先行断言</h3><p>用于指示匹配表达式的字符串的上一个字符位置</p>
<p><code>\b\w+(?=ing\b)</code> 匹配以ing结尾的单词的前面部分(除了ing以外的部分).<br>如果查找 <code> I&#39;m singing while you&#39;re dancing.</code>时, 它会匹配sing和danc.</p>
<h3 id="零宽度正回顾后发断言"><a href="#零宽度正回顾后发断言" class="headerlink" title="零宽度正回顾后发断言"></a>零宽度正回顾后发断言</h3><p>用于指示匹配表达式的字符串的下一个字符位置</p>
<p><code>(?&lt;=\bre)\w+\b</code> 匹配以re开头的单词的后半部分</p>
<p><code>((?&lt;=\d)\d&#123;3&#125;+\b)</code>匹配一个数字后面是若干的三个数字的后面部分.<br>对1234567890进行查找时结果是234567890</p>
<h2 id="负向零宽断言"><a href="#负向零宽断言" class="headerlink" title="负向零宽断言"></a>负向零宽断言</h2><p>负向零宽断言, 与上一节中的正向零宽断言相对, 用于匹配不是某个字符或不在某些字符类里的方法</p>
<p>确保某个字符没有出现, 但并不想去匹配它, 就可以使用<code>负向零宽断言</code></p>
<h3 id="零宽度负预测先行断言-exp"><a href="#零宽度负预测先行断言-exp" class="headerlink" title="零宽度负预测先行断言(?!exp)"></a>零宽度负预测先行断言(?!exp)</h3><p>断言此位置的后面不能匹配表达式exp。<br>例如：\d{3}(?!\d)匹配三位数字，而且这三位数字的后面不能是数字；<br>\b((?!abc)\w)+\b匹配不包含连续字符串abc的单词。</p>
<h3 id="零宽度负回顾后发断言"><a href="#零宽度负回顾后发断言" class="headerlink" title="零宽度负回顾后发断言"></a>零宽度负回顾后发断言</h3><p>同理，可以用(<code>?&lt;!exp</code>),零宽度负回顾后发断言来断言此位置的前面不能匹配表达式exp：<br><code>(?&lt;![a-z])\d&#123;7&#125;</code> 匹配前面不是小写字母的七位数字。</p>
<p>请详细分析表达式<code>(?&lt;=&lt;(\w+)&gt;).*(?=&lt;\/\1&gt;)</code>，这个表达式最能表现零宽断言的真正用途。</p>
<p>一个更复杂的例子：<br><code>(?&lt;=&lt;(\w+)&gt;).*(?=&lt;\/\1&gt;)</code>匹配不包含属性的简单HTML标签内里的内容。<br><code>(?&lt;=&lt;(\w+)&gt;)</code>指定了这样的前缀：被尖括号括起来的单词(比如可能是<b>)，<br>然后是.<code>*(任意的字符串)</code>,最后是一个后缀(?=&lt;/\1&gt;)。注意后缀里的/，<br>它用到了前面提过的字符转义；\1则是一个反向引用，引用的正是捕获的第一组，<br>前面的(\w+)匹配的内容，这样如果前缀实际上是<b>的话，后缀就是</b>了。<br>整个表达式匹配的是<b>和</b>之间的内容(再次提醒，不包括前缀和后缀本身)。</p>
<h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p>通过语法<code>(?#comment)</code>来包含注释</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(?&lt;&#x3D;    # 断言要匹配的文本的前缀</span><br><span class="line"> &lt;(\w+)&gt; # 查找尖括号括起来的字母或数字(即HTML&#x2F;XML标签)</span><br><span class="line">)       # 前缀结束</span><br><span class="line">.*      # 匹配任意文本</span><br><span class="line">(?&#x3D;     # 断言要匹配的文本的后缀</span><br><span class="line"> &lt;\&#x2F;\1&gt;  # 查找尖括号括起来的内容：前面是一个&quot;&#x2F;&quot;，后面是先前捕获的标签</span><br><span class="line">)       # 后缀结束</span><br></pre></td></tr></table></figure>

<h2 id="贪婪与懒惰"><a href="#贪婪与懒惰" class="headerlink" title="贪婪与懒惰"></a>贪婪与懒惰</h2><table>
<thead>
<tr>
<th>代码/语法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>*?</code></td>
<td>重复任意次，但尽可能少重复</td>
</tr>
<tr>
<td><code>+?</code></td>
<td>重复1次或更多次，但尽可能少重复</td>
</tr>
<tr>
<td><code>??</code></td>
<td>重复0次或1次，但尽可能少重复</td>
</tr>
<tr>
<td><code>&#123;n,m&#125;?</code></td>
<td>重复n到m次，但尽可能少重复</td>
</tr>
<tr>
<td><code>&#123;n,&#125;?</code></td>
<td>重复n次以上，但尽可能少重复</td>
</tr>
</tbody></table>
<h2 id="处理选项"><a href="#处理选项" class="headerlink" title="处理选项"></a>处理选项</h2><table>
<thead>
<tr>
<th>名称</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>IgnoreCase</code>(忽略大小写)</td>
<td>匹配时不区分大小写。</td>
</tr>
<tr>
<td><code>Multiline</code>(多行模式)</td>
<td>更改^和$的含义，使它们分别在任意一行的行首和行尾匹配，而不仅仅在整个字符串的开头和结尾匹配。(在此模式下,$的精确含意是:匹配\n之前的位置以及字符串结束前的位置.)</td>
</tr>
<tr>
<td><code>Singleline</code>(单行模式)</td>
<td>更改.的含义，使它与每一个字符匹配（包括换行符\n）。</td>
</tr>
<tr>
<td><code>IgnorePatternWhitespace</code>(忽略空白)</td>
<td>忽略表达式中的非转义空白并启用由#标记的注释。</td>
</tr>
<tr>
<td><code>ExplicitCapture</code>(显式捕获)</td>
<td>仅捕获已被显式命名的组。</td>
</tr>
</tbody></table>
<h2 id="平衡组-递归匹配"><a href="#平衡组-递归匹配" class="headerlink" title="平衡组/递归匹配"></a>平衡组/递归匹配</h2><p>用于在嵌套的层次结构中, 判断是否嵌套.</p>
<ul>
<li>   <code>(?&#39;group&#39;)</code> 把捕获的内容命名为group,并压入堆栈(Stack)</li>
<li>   <code>(?&#39;-group&#39;)</code> 从堆栈上弹出最后压入堆栈的名为group的捕获内容，如果堆栈本来为空，则本分组的匹配失败</li>
<li>   <code>(?(group)yes|no)</code> 如果堆栈上存在以名为group的捕获内容的话，继续匹配yes部分的表达式，否则继续匹配no部分</li>
<li>   <code>(?!)</code> 零宽负向先行断言，由于没有后缀表达式，试图匹配总是失败</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;                         #最外层的左括号</span><br><span class="line">[^&lt;&gt;]*                #最外层的左括号后面的不是括号的内容</span><br><span class="line">(</span><br><span class="line"> (</span><br><span class="line">  (?&#39;Open&#39;&lt;)    #碰到了左括号，在黑板上写一个&quot;Open&quot;</span><br><span class="line">  [^&lt;&gt;]*       #匹配左括号后面的不是括号的内容</span><br><span class="line"> )+</span><br><span class="line"> (</span><br><span class="line">  (?&#39;-Open&#39;&gt;)   #碰到了右括号，擦掉一个&quot;Open&quot;</span><br><span class="line">  [^&lt;&gt;]*        #匹配右括号后面不是括号的内容</span><br><span class="line"> )+</span><br><span class="line">)*</span><br><span class="line">(?(Open)(?!))         #在遇到最外层的右括号前面，判断黑板上还有没有没擦掉的&quot;Open&quot;；如果还有，则匹配失败</span><br><span class="line"></span><br><span class="line">&gt;                         #最外层的右括号</span><br></pre></td></tr></table></figure>
<p>我们需要做的是每碰到了左括号，就在压入一个”Open”,每碰到一个右括号，就弹出一个，到了最后就看看堆栈是否为空－－如果不为空那就证明左括号比右括号多，那匹配就应该失败。正则表达式引擎会进行回溯(放弃最前面或最后面的一些字符)，尽量使整个表达式得到匹配。</p>
<h2 id="其他语法"><a href="#其他语法" class="headerlink" title="其他语法"></a>其他语法</h2><table>
<thead>
<tr>
<th>代码/语法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>\a</td>
<td>报警字符(打印它的效果是电脑嘀一声)</td>
</tr>
<tr>
<td>\b</td>
<td>通常是单词分界位置，但如果在字符类里使用代表退格</td>
</tr>
<tr>
<td>\t</td>
<td>制表符，Tab</td>
</tr>
<tr>
<td>\r</td>
<td>回车</td>
</tr>
<tr>
<td>\v</td>
<td>竖向制表符</td>
</tr>
<tr>
<td>\f</td>
<td>换页符</td>
</tr>
<tr>
<td>\n</td>
<td>换行符</td>
</tr>
<tr>
<td>\e</td>
<td>Escape</td>
</tr>
<tr>
<td>\0nn</td>
<td>ASCII代码中八进制代码为nn的字符</td>
</tr>
<tr>
<td>\xnn</td>
<td>ASCII代码中十六进制代码为nn的字符</td>
</tr>
<tr>
<td>\unnnn</td>
<td>Unicode代码中十六进制代码为nnnn的字符</td>
</tr>
<tr>
<td>\cN</td>
<td>ASCII控制字符。比如\cC代表Ctrl+C</td>
</tr>
<tr>
<td>\A</td>
<td>字符串开头(类似^，但不受处理多行选项的影响)</td>
</tr>
<tr>
<td>\Z</td>
<td>字符串结尾或行尾(不受处理多行选项的影响)</td>
</tr>
<tr>
<td>\z</td>
<td>字符串结尾(类似$，但不受处理多行选项的影响)</td>
</tr>
<tr>
<td>\G</td>
<td>当前搜索的开头</td>
</tr>
<tr>
<td>\p{name}</td>
<td>Unicode中命名为name的字符类，例如\p{IsGreek}</td>
</tr>
<tr>
<td>(?&gt;exp)</td>
<td>贪婪子表达式</td>
</tr>
<tr>
<td>(?<x>-<y>exp)</td>
<td>平衡组</td>
</tr>
<tr>
<td>(?im-nsx:exp)</td>
<td>在子表达式exp中改变处理选项</td>
</tr>
<tr>
<td>(?im-nsx)</td>
<td>为表达式后面的部分改变处理选项</td>
</tr>
<tr>
<td>(?(exp)yes</td>
<td>no)</td>
</tr>
<tr>
<td>(?(exp)yes)</td>
<td>同上，只是使用空表达式作为no</td>
</tr>
<tr>
<td>(?(name)yes</td>
<td>no)</td>
</tr>
<tr>
<td>(?(name)yes)</td>
<td>同上，只是使用空表达式作为no</td>
</tr>
</tbody></table>
<h1 id="常用的正则表达式"><a href="#常用的正则表达式" class="headerlink" title="常用的正则表达式"></a>常用的正则表达式</h1><h2 id="电子邮箱Email"><a href="#电子邮箱Email" class="headerlink" title="电子邮箱Email"></a>电子邮箱Email</h2><p><code>\w+([-+.]\w+)*@\w+([-.]\w)*\.\w+([-.]\w+)*</code><br>Email地址是以@分割, <code>@</code>前面的部分为用户名, 后面为域名.<br>用户名部分可以包含字母/数字/下划线/-/+/., 但是只能字母/数字/下划线开头.<br>不能出现+-.连续<br>而域名部分可以包含字母/数字/下划线/-以及. 也是只能字母/数字/下划线开头.</p>
<p>用户名部分<code>\w+([-+.]\w+)*</code> , 必须是至少一个<code>\w</code>开头,</p>
<h2 id="手机号码"><a href="#手机号码" class="headerlink" title="手机号码"></a>手机号码</h2><p><code>[1-9][3,4,5,7,8]/d&#123;9&#125;</code></p>
<h2 id="汉字"><a href="#汉字" class="headerlink" title="汉字"></a>汉字</h2><p><code>[\u4e00-\u9fa5]</code></p>
<h2 id="QQ号码"><a href="#QQ号码" class="headerlink" title="QQ号码"></a>QQ号码</h2><p><code>[1-9]\d&#123;4,&#125;</code></p>
<h2 id="邮编"><a href="#邮编" class="headerlink" title="邮编"></a>邮编</h2><p><code>[1-9]\d&#123;5&#125;</code></p>
<h2 id="不含abc的单词"><a href="#不含abc的单词" class="headerlink" title="不含abc的单词"></a>不含abc的单词</h2><p><code>\b((?!abc)\w)+\b</code></p>
<h2 id="时间-小时-分钟-24小时制"><a href="#时间-小时-分钟-24小时制" class="headerlink" title="时间(小时:分钟, 24小时制)"></a>时间(小时:分钟, 24小时制)</h2><p>((1|0?)[0-9]|2[0-3]):([0-5][0-9])</p>
<h2 id="姓名"><a href="#姓名" class="headerlink" title="姓名"></a>姓名</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String regex=<span class="string">&quot;^([(?&lt;cc&gt;a-zA-Z\\u4e00-\\u9fa5)]+)|([a-zA-Z\\u4e00-\\u9fa5]+[a-zA-Z\\u4e00-\\u9fa5. _·]*)$&quot;</span>;</span><br><span class="line">String [] tem=&#123;</span><br><span class="line">  <span class="string">&quot;张大千&quot;</span>,</span><br><span class="line">    <span class="string">&quot;张.大千&quot;</span>,</span><br><span class="line">    <span class="string">&quot;zhangdaqian&quot;</span>,</span><br><span class="line">    <span class="string">&quot;zhang.daqian&quot;</span>,</span><br><span class="line">    <span class="string">&quot;张大千Quene&quot;</span>,</span><br><span class="line">    <span class="string">&quot;zhang daqian&quot;</span>,</span><br><span class="line">    <span class="string">&quot;zhang_daqian&quot;</span>,</span><br><span class="line">    <span class="string">&quot; 张大千&quot;</span>,</span><br><span class="line">    <span class="string">&quot;.张大千&quot;</span>,</span><br><span class="line">    <span class="string">&quot;_张大千&quot;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">for</span> (String s : tem) &#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> matches = Pattern.matches(regex, s);</span><br><span class="line">  System.out.println(s+<span class="string">&quot;:\t&quot;</span>+(matches?<span class="string">&quot;√&quot;</span>:<span class="string">&quot;×&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">张大千:	√</span><br><span class="line">张.大千:	√</span><br><span class="line">zhangdaqian:	√</span><br><span class="line">zhang.daqian:	√</span><br><span class="line">张大千Quene:	√</span><br><span class="line">zhang daqian:	√</span><br><span class="line">zhang_daqian:	√</span><br><span class="line"> 张大千:	×</span><br><span class="line">.张大千:	×</span><br><span class="line">_张大千:	×</span><br></pre></td></tr></table></figure>


<h1 id="Java中运用"><a href="#Java中运用" class="headerlink" title="Java中运用"></a>Java中运用</h1><p>java.util.regex 包主要由三个类所组成：Pattern、Matcher 和 PatternSyntaxException。</p>
<ul>
<li>Pattern 对象表示一个已编译的正则表达式。Pattern 类没有提供公共的构造方法。要构建一个模式，首先必须调用公共的静态 <code>compile</code> 方法，它将返回一个 Pattern 对象。这个方法接受正则表达式作为第一个参数。</li>
<li>Matcher 是一个靠着输入的字符串来解析这个模式和完成匹配操作的对象。与 Pattern 相似，Matcher 也没有定义公共的构造方法，需要通过调用 Pattern 对象的 matcher 方法来获得一个 Matcher 对象。</li>
<li>PatternSyntaxException 对象是一个未检查异常，指示了正则表达式中的一个语法错误。</li>
</ul>
<h2 id="Pattern"><a href="#Pattern" class="headerlink" title="Pattern"></a>Pattern</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String message=<span class="string">&quot;&quot;</span>;</span><br><span class="line"><span class="comment">// 大小写不敏感</span></span><br><span class="line">Pattern pattern = Pattern.compile(message, Pattern.CASE_INSENSITIVE );</span><br><span class="line"><span class="comment">// 大小写不敏感且使用Unix的行结束符</span></span><br><span class="line">pattern = Pattern.compile(<span class="string">&quot;[az]$&quot;</span>, Pattern.MULTILINE | Pattern.UNIX_LINES);</span><br><span class="line"><span class="comment">// 使用int变量， 启用Unicode折叠感知和大小写不敏感</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> flags = Pattern.CASE_INSENSITIVE | Pattern.UNICODE_CASE;</span><br><span class="line">Pattern pattern = Pattern.compile(<span class="string">&quot;aa&quot;</span>, flags);</span><br></pre></td></tr></table></figure>
<p>** matches(String, CharSequence) 方法 **</p>
<p>Pattern 类定义了一个方便的 matches 方法，用于快速地检查模式是否表示给定的输入字符串。与使用所有的公共静态方法一样，应该通过它的类名来调用 matches 方法，诸如 Pattern.matches(“\d”,”1”);。这个例子中，方法返回 true，这是由于数字“1”匹配了正则表达式\d。</p>
<p>** split(String) 方法 **</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String REGEX = <span class="string">&quot;:&quot;</span>;</span><br><span class="line">String INPUT = <span class="string">&quot;one:two:three:four:five&quot;</span>;</span><br><span class="line">Pattern p = Pattern.compile(REGEX);</span><br><span class="line">String[] items = p.split(INPUT);</span><br><span class="line"><span class="keyword">for</span>(String s : items) &#123;</span><br><span class="line">    System.out.println(s);</span><br><span class="line">&#125;</span><br><span class="line">REGEX=<span class="string">&quot;//d&quot;</span>;</span><br><span class="line">INPUT=<span class="string">&quot;one9two4three7four1five&quot;</span>;</span><br><span class="line">Pattern p = Pattern.compile(REGEX);</span><br><span class="line">String[] items = p.split(INPUT);</span><br><span class="line"><span class="keyword">for</span>(String s : items) &#123;</span><br><span class="line">  System.out.println(s);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出结果 one two three four five</span></span><br></pre></td></tr></table></figure>
<p>** public static String quote(String s)** ：返回指定字符串字面模式的字符串。此方法会产生一个字符串，能被用于构建一个与字符串 s 匹配的 Pattern，好像它是一个字面上的模式。输入序列中的元字符和转义序列将没有特殊的意义了。<br>**　　public String toString() ** ：返回这个模式的字符串表现形式。这是一个编译过的模式中的正则表达式。</p>
<p>** java.lang.String中等价的方法 **</p>
<p><code>java.lang.String</code> 通过模拟 <code>java.util.regex.Pattern</code> 行为的几个方法，也可以支持正则表达式。方便起见，下面主要摘录了出现在 API 关键的方法。</p>
<ul>
<li><code>public boolean matches(String regex)</code>：告知字符串是否匹配给定的正则表达式。调用 <code>str.matches(regex)</code>方法所产生的结果与作为表达式的 <code>Pattern.matches(regex, str)</code>的结果是完全一致。</li>
<li><code>public String[] split(String regex, int limit)</code>：依照匹配给定的正则表达式来拆分字符串。调用 <code>str.split(regex, n)</code>方法所产生的结果与作为表达式的 <code>Pattern.compile(regex).split(str, n)</code> 的结果完全一致。</li>
<li><code>public String[] split(String regex)</code>：依照匹配给定的正则表达式来拆分字符串。这个方法与调用两个参数的 split 方法是相同的，第一个参数使用给定的表达式，第二个参数限制为 0。在结果数组中不包括尾部的空字符串。</li>
<li>还有一个替换方法，把一个 <code>CharSequence</code> 替换成另外一个：<br><code>public String replace(CharSequence target,CharSequence replacement)</code>：将字符串中每一个匹配替换匹配字面目标序列的子字符串，替换成指定的字面替换序列。这个替换从字符串的开始处理直至结束，例如，把字符串“aaa”中的“aa”替换成“b”，结果是“ba”，而不是“ab”。</li>
</ul>
<h2 id="Matcher"><a href="#Matcher" class="headerlink" title="Matcher"></a>Matcher</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">索引方法</span><br><span class="line"></span><br><span class="line">　　索引方法（index methods）提供了一些正好在输入字符串中发现匹配的索引值：</span><br><span class="line">　　<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">start</span><span class="params">()</span>：返回之前匹配的开始索引。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> <span class="keyword">int</span> <span class="title">start</span><span class="params">(<span class="keyword">int</span> group)</span>：返回之前匹配操作中通过给定组所捕获序列的开始索引。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> <span class="keyword">int</span> <span class="title">end</span><span class="params">()</span>: 返回最后匹配字符后的偏移量。</span></span><br><span class="line"><span class="function">   <span class="keyword">public</span> <span class="keyword">int</span> <span class="title">end</span><span class="params">(<span class="keyword">int</span> group)</span>: 返回之前匹配操作中通过给定组所捕获序列的最后字符之后的偏移量。</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">研究方法</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">　　研究方法（study methods）回顾输入的字符串，并且返回一个用于指示是否找到模式的布尔值。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">lookingAt</span><span class="params">()</span>: 尝试从区域开头处开始，输入序列与该模式匹配。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">find</span><span class="params">()</span>: 尝试地寻找输入序列中，匹配模式的下一个子序列。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> start)</span>: 重置匹配器，然后从指定的索引处开始，尝试地寻找输入序列中，匹配模式的下一个子序列。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">matches</span><span class="params">()</span>: 尝试将整个区域与模式进行匹配</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">替换方法</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">　　替换方法（replacement methods）用于在输入的字符串中替换文本有用处的方法。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> Matcher <span class="title">appendReplacement</span><span class="params">(StringBuffer sb, String replacement)</span>：实现非结尾处的增加和替换操作。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> StringBuffer <span class="title">appendTail</span><span class="params">(StringBuffer sb)</span>：实现结尾处的增加和替换操作。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> String <span class="title">replaceAll</span><span class="params">(String replacement)</span>：使用给定的替换字符串来替换输入序列中匹配模式的每一个子序列。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> String <span class="title">replaceFirst</span><span class="params">(String replacement)</span>：使用给定的替换字符串来替换输入序列中匹配模式的第一个子序列。</span></span><br><span class="line"><span class="function">　　<span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">quoteReplacement</span><span class="params">(String s)</span>：返回指定字符串的字面值来替换字符串。这个方法会生成一个字符串，用作 Matcher 的 appendReplacement 方法中的字面值替换 s。所产生的字符串将与作为字面值序列的 s 中的字符序列匹配。斜线（\）和美元符号（$）将不再有特殊意义了。</span></span><br></pre></td></tr></table></figure>
<p>** 使用 start 和 end 方法 **</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String REGEX = <span class="string">&quot;\\bdog\\b&quot;</span>;</span><br><span class="line">String INPUT = <span class="string">&quot;dog dog dog doggie dogg&quot;</span>;</span><br><span class="line">Pattern p = Pattern.compile(REGEX);</span><br><span class="line">Matcher m = p.matcher(INPUT);        <span class="comment">// 获得匹配器对象</span></span><br><span class="line"><span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (m.find()) &#123;</span><br><span class="line"> count++;</span><br><span class="line"> System.out.println(<span class="string">&quot;Match number &quot;</span> + count);</span><br><span class="line"> System.out.println(<span class="string">&quot;start(): &quot;</span> + m.start());</span><br><span class="line"> System.out.println(<span class="string">&quot;end(): &quot;</span> + m.end());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>** 使用 matches 和 lookingAt 方法 **</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String REGEX = <span class="string">&quot;foo&quot;</span>;</span><br><span class="line">String INPUT = <span class="string">&quot;fooooooooooooooooo&quot;</span>;</span><br><span class="line">Pattern pattern;</span><br><span class="line">Matcher matcher;</span><br><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">pattern = Pattern.compile(REGEX);</span><br><span class="line">matcher = pattern.matcher(INPUT);</span><br><span class="line">System.out.println(<span class="string">&quot;Current REGEX is: &quot;</span> + REGEX);</span><br><span class="line">System.out.println(<span class="string">&quot;Current INPUT is: &quot;</span> + INPUT);</span><br><span class="line">System.out.println(<span class="string">&quot;lookingAt(): &quot;</span> + matcher.lookingAt());</span><br><span class="line">System.out.println(<span class="string">&quot;matches(): &quot;</span> + matcher.matches());</span><br></pre></td></tr></table></figure>
<p>** 使用 replaceFirst(String) 和 replaceAll(String) 方法 **</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String REGEX = <span class="string">&quot;dog&quot;</span>;</span><br><span class="line">String INPUT = <span class="string">&quot;The dog says meow. All dogs say meow.&quot;</span>;</span><br><span class="line">String REPLACE = <span class="string">&quot;cat&quot;</span>;</span><br><span class="line"></span><br><span class="line">Pattern p = Pattern.compile(REGEX);</span><br><span class="line">Matcher m = p.matcher(INPUT);       <span class="comment">// 获得匹配器对象</span></span><br><span class="line">INPUT = m.replaceAll(REPLACE);</span><br><span class="line">System.out.println(INPUT);</span><br></pre></td></tr></table></figure>
<p>** 使用 appendReplacement(StringBuffer, String) 和<br>　     appendTail(StringBuffer) 方法 **</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String REGEX = <span class="string">&quot;a*b&quot;</span>;</span><br><span class="line"><span class="keyword">static</span> String INPUT = <span class="string">&quot;aabfooaabfooabfoob&quot;</span>;</span><br><span class="line"><span class="keyword">static</span> String REPLACE = <span class="string">&quot;-&quot;</span>;</span><br><span class="line">Pattern p = Pattern.compile(REGEX);</span><br><span class="line">Matcher m = p.matcher(INPUT);       <span class="comment">// 获得匹配器对象</span></span><br><span class="line">StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line"><span class="keyword">while</span> (m.find()) &#123;</span><br><span class="line">    m.appendReplacement(sb, REPLACE);</span><br><span class="line">&#125;</span><br><span class="line">m.appendTail(sb);</span><br><span class="line">System.out.println(sb.toString());</span><br></pre></td></tr></table></figure>

<p>** 在 java.lang.String 中等价的 Matcher 方法 **</p>
<p>为了使用方便，String 类看上去还不错地模仿了 Matcher 的两个方法：</p>
<p><code>public String replaceFirst(String regex, String replacement)</code>：使用给定的替换字符串替换该字符串中匹配了给定正则表达式的第一个子字符串。调用 str.replaceFirst(regex, repl)方法与使用 Pattern.compile(regex).matcher(str).replaceFirst(repl)产生的结果是完全相同的。</p>
<p><code>public String replaceAll(String regex, String replacement)</code>：使用给定的替换字符串替换该字符串中匹配了给定正则表达式的每一个子字符串。调用 str.replaceAll(regex, repl)方法与使用 Pattern.compile(regex).matcher(str).replaceAll(repl)产生的结果是完全相同的。</p>
<h2 id="PatternSyntaxException"><a href="#PatternSyntaxException" class="headerlink" title="PatternSyntaxException"></a>PatternSyntaxException</h2><p>PatternSyntaxException 是未检查异常，指示正则表达式模式中的语法错误。PatternSyntaxException 类提供了下面的一些方法，用于确定在什么地方发生了错误：</p>
<ul>
<li>public String getDescription()：获得错误描述。</li>
<li>public int getIndex()：获得错误索引。</li>
<li>public String getPattern()：获得字符串形式的错误正则表达式。</li>
<li>public String getMessage()：获得一个多行的字符串，包括语法错误和错误的索引、错误的正则表达式模式，以及模式内可视化的索引指示。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern pattern = <span class="keyword">null</span>;</span><br><span class="line">Matcher matcher = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">Console console = System.console();</span><br><span class="line"><span class="keyword">if</span> (console == <span class="keyword">null</span>) &#123;</span><br><span class="line">    System.err.println(<span class="string">&quot;No console.&quot;</span>);</span><br><span class="line">    System.exit(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        pattern = Pattern.compile(console.readLine(<span class="string">&quot;%nEnter your regex: &quot;</span>));</span><br><span class="line">        matcher = pattern.matcher(console.readLine(<span class="string">&quot;Enter input string to search: &quot;</span>));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (PatternSyntaxException pse)&#123;</span><br><span class="line">        console.format(<span class="string">&quot;There is a problem with the regular expression!%n&quot;</span>);</span><br><span class="line">        console.format(<span class="string">&quot;The pattern in question is: %s%n&quot;</span>, pse.getPattern());</span><br><span class="line">        console.format(<span class="string">&quot;The description is: %s%n&quot;</span>, pse.getDescription());</span><br><span class="line">        console.format(<span class="string">&quot;The message is: %s%n&quot;</span>, pse.getMessage());</span><br><span class="line">        console.format(<span class="string">&quot;The index is: %s%n&quot;</span>, pse.getIndex());</span><br><span class="line">        System.exit(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">boolean</span> found = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">while</span> (matcher.find()) &#123;</span><br><span class="line">        console.format(<span class="string">&quot;I found the text \&quot;%s\&quot; starting at &quot;</span> +</span><br><span class="line">                <span class="string">&quot;index %d and ending at index %d.%n&quot;</span>,</span><br><span class="line">                matcher.group(), matcher.start(), matcher.end()</span><br><span class="line">                );</span><br><span class="line">        found = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!found)&#123;</span><br><span class="line">        console.format(<span class="string">&quot;No match found.%n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Enter your regex: ?i)</span><br><span class="line">There is a problem with the regular expression!</span><br><span class="line">The pattern in question is: ?i)</span><br><span class="line">The description is: Dangling meta character &#39;?&#39;</span><br><span class="line">The message is: Dangling meta character &#39;?&#39; near index 0</span><br><span class="line">?i)</span><br><span class="line">^</span><br><span class="line">The index is: 0</span><br></pre></td></tr></table></figure>
<h2 id="问题与练习"><a href="#问题与练习" class="headerlink" title="问题与练习"></a>问题与练习</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">〖问题〗</span><br><span class="line"></span><br><span class="line">1. 在 java.util.regex 包中有哪三个公共的类？描述一下它们的作用。</span><br><span class="line">2. 考虑一下字符串“foo”，它的开始索引是多少？结束索引是多少？解释一下这些编号的意思。</span><br><span class="line">3. 普通字符和元字符有什么不同？各给出它们的一个例子。</span><br><span class="line">4. 如何把元字符表现成像普通字符那样？</span><br><span class="line">5. 附有方括号的字符集称为什么？它有什么作用？</span><br><span class="line">6. 这里是三个预定义的字符类：\d、\s和\w。描述一下它们各表示什么？并使用方括号的形式将它们重写。</span><br><span class="line">7. 对于\d、\s和\w，写出两个简单的表达式，匹配它们相反的字符集。</span><br><span class="line">8. 思考正则表达式(dog)&#123;3&#125;，识别一下其中的两个子表达式。这个表达式会匹配什么字符串？</span><br><span class="line"></span><br><span class="line">〖练习〗</span><br><span class="line"></span><br><span class="line">1. 使用反向引用写一个表达式，用于匹配一个人的名字，假设这个人的 first 名字与 last 名字是相同的。</span><br><span class="line"></span><br><span class="line">【问题答案】</span><br><span class="line"></span><br><span class="line">1. 问：在 java.util.regex 包中有哪三个公共的类？描述一下它们的作用。</span><br><span class="line">答：</span><br><span class="line"></span><br><span class="line">编译后的 Pattern 实例表示正则表达式。</span><br><span class="line">Matcher 实例是解析模式和靠着输入的字符串完成匹配操作的引擎。</span><br><span class="line">PatternSyntaxException 定义一个未检查异常，指示正则表达式中的语法错误。</span><br><span class="line"></span><br><span class="line">2. 问：考虑一下字符串“foo”，它的开始索引是多少？结束索引是多少？解释一下这些编号的意思。</span><br><span class="line"></span><br><span class="line">答：字符串中的每一个字符位于其自身的单元格中。索引位置在两个单元格之间。字符串“foo”开始于索引 0，结束于索引 3，即便是这些字符仅占用了 0、1 和 2 号单元格。</span><br><span class="line"></span><br><span class="line">3. 问：普通字符和元字符有什么不同？各给出它们的一个例子。</span><br><span class="line"></span><br><span class="line">答：正则表达式中的普通字符匹配其本身。元字符是一个特殊的字符，会影响被匹配模式的方式。字母A是一个普通字符。标点符号.是一个元字符，其匹配任意的单字符。</span><br><span class="line"></span><br><span class="line">4. 问：如何把元字符表现成像普通字符那样？答：有两种方法：</span><br><span class="line"></span><br><span class="line">在元字符前加上反斜线（\）；</span><br><span class="line">把元字符置于\Q（开始）\E（结束）的引用表达式中。</span><br><span class="line"></span><br><span class="line">5. 问：附有方括号的字符集称为什么？它有什么作用？</span><br><span class="line"></span><br><span class="line">答：是一个字符类。通过方括号间的表达式，匹配指定字符类中的任意一个字符。</span><br><span class="line"></span><br><span class="line">6. 问：这里是三个预定义的字符类：\d、\s和\w。描述一下它们各表示什么？并使用方括号的形式将它们重写。</span><br><span class="line"></span><br><span class="line">答：\d 匹配任意数字[0-9]</span><br><span class="line">　　\s 匹配任意空白字符[ \t\n-x0B\f\r ]</span><br><span class="line">　　\w 匹配任意单词字符[a-zA-Z_0-9]</span><br><span class="line"></span><br><span class="line">7. 问：对于\d、\s和\w，写出两个简单的表达式，匹配它们相反的字符集。</span><br><span class="line"></span><br><span class="line">答：\d \D [^\d]</span><br><span class="line">　　\s \S [^\s]</span><br><span class="line">　　\w \W [^\w]</span><br><span class="line"></span><br><span class="line">8. 问：思考正则表达式(dog)&#123;3&#125;，识别一下其中的两个子表达式。这个表达式会匹配什么字符串？</span><br><span class="line"></span><br><span class="line">答：表达式由捕获组(dog)和接着的贪婪量词&#123;3&#125;所组成。它匹配字符串“dogdogdog”。</span><br><span class="line"></span><br><span class="line">【练习答案】</span><br><span class="line"></span><br><span class="line">1. 练习：使用反向引用写一个表达式，用于匹配一个人的名字，假设这个人的 first 名字与 last 名字是相同的。</span><br><span class="line"></span><br><span class="line">解答：([A-Z][a-zA-Z]*)\s\1</span><br></pre></td></tr></table></figure>
<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>替换字符串中的字符串</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String regularExpressionString=...;</span><br><span class="line">Matcher m = Pattern.compile(regularExpressionString, Pattern.CASE_INSENSITIVE).matcher(source); </span><br><span class="line">String result=m.replaceAll(newstring); </span><br><span class="line">System.out.println(<span class="string">&quot;使用正则表达式不区分大小写的替换结果&quot;</span>+result);</span><br><span class="line"></span><br><span class="line">Matcher m1 = Pattern.compile(regularExpressionString, Pattern.CANON_EQ).matcher(source); </span><br><span class="line">String result1=m1.replaceAll(newstring); </span><br><span class="line">System.out.println(<span class="string">&quot;使用正则表达式区分大小写的替换结果&quot;</span>+result1); </span><br></pre></td></tr></table></figure>
<hr>
<p>参考文献:</p>
<ol>
<li><a href="http://www.jb51.net/tools/zhengze.html">正则表达式30分钟入门教程</a></li>
<li><a href="www.zuidaima.com/share/1835085544524800.htm">java正则表达式语法详解及其使用代码实例</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>RegularExpression</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 反射</title>
    <url>/Java/reflection/</url>
    <content><![CDATA[<h2 id="在多级类继承中-如何找到方法是在哪个类实现的"><a href="#在多级类继承中-如何找到方法是在哪个类实现的" class="headerlink" title="在多级类继承中, 如何找到方法是在哪个类实现的?"></a>在多级类继承中, 如何找到方法是在哪个类实现的?</h2><p>currentObject 是ContextWrapper 的子类的对象, <code>mBase</code>是定义在 <code>currentObject</code>某一个父类的字段,<br><code>mBase</code>中的某个方法<code>getSharedPerences()</code>是定义在某个父类中的抽象方法,<br>如何确定该方法是在哪个父类中实现的?</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  Field field = ContextWrapper.class.getDeclaredField(<span class="string">&quot;mBase&quot;</span>);</span><br><span class="line">  field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">  Object object = field.get(currentObject);</span><br><span class="line">  Log.i(TAG,<span class="string">&quot;the real implement class is &quot;</span> + filed.getClass().getName());</span><br><span class="line">&#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>getSharedPerences()</code>方法一定定义在<code>mBase</code>类中. 妙哉!<br>获得<code>mBase</code>对象的类名就是该方法的实现类.</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>reflection</tag>
      </tags>
  </entry>
  <entry>
    <title>Java软件工程师知识结构</title>
    <url>/Java/step-book/</url>
    <content><![CDATA[<h1 id="1-Java基础"><a href="#1-Java基础" class="headerlink" title="1 Java基础"></a>1 Java基础</h1><h2 id="1-1-Collection和Map"><a href="#1-1-Collection和Map" class="headerlink" title="1.1 Collection和Map"></a>1.1 Collection和Map</h2><ol>
<li>掌握Collection和Map的继承体系。<a href="/Java/collection/collection-map.html" title="Java Collection与Map">Java Collection与map</a></li>
<li>掌握ArrayList、LinkedList、Vector、Stack、PriorityQueue、HashSet、LinkedHashSet、TreeSet、HashMap、LinkedHashMap、TreeMap、WeakHashMap、EnumMap、TreeMap(红黑树)、HashTable的特点和实现原理。</li>
<li>掌握CopyOnWriteArrayList、CopyOnWriteArraySet、<a href="/Java/collection/ConcurrentHashMap.html">ConcurrentHashMap</a>的实现原理和适用场景。</li>
<li>Java并发容器</li>
</ol>
<h2 id="1-2-IO"><a href="#1-2-IO" class="headerlink" title="1.2 IO"></a>1.2 IO</h2><ol>
<li>掌握InputStream、OutputStream、Reader、Writer的继承体系。 <a href="/Java/io/BIO.html" title="Java IO">Java IO</a> , <a href="/Java/io/java-zip.html">Java 压缩</a> , <a href="/Java/io/java-XML-JSON.html">Java XML与JSON</a>, <a href="/Java/io/object-serialization.html">Java序列化</a></li>
<li>掌握字节流(FileInputStream、DataInputStream、BufferedInputStream、FileOutputSteam、DataOutputStream、BufferedOutputStream)和 字符流(BufferedReader、InputStreamReader、FileReader、BufferedWriter、OutputStreamWriter、PrintWriter、FileWriter)，并熟练运用。</li>
<li>掌握NIO实现原理及使用方法。 <a href="/Java/io/IO-Model.html">IO模式</a> <a href="/Java/io/NIO.html">Java NIO</a></li>
<li>Netty原理 <a href="/JavaWeb/Netty/Netty-theory.html">这可能是目前最透彻的Netty原理架构解析</a></li>
<li>IO理论 <a href="/Java/io/high-performance-network-programming.html">高性能网络编程</a></li>
</ol>
<h2 id="1-3-异常"><a href="#1-3-异常" class="headerlink" title="1.3 异常"></a>1.3 异常</h2><ol>
<li>掌握Throwable继承体系。<a href="http://blog.csdn.net/hguisu/article/details/6155636" title="深入理解java异常处理机制">深入理解java异常处理机制</a></li>
<li>掌握异常工作原理。</li>
<li>了解常见受检异常(比如FileNotFoundException)、非受检异常(比如NullPointerException)和错误(比如IOError)。</li>
</ol>
<h2 id="1-4-多线程"><a href="#1-4-多线程" class="headerlink" title="1.4 多线程"></a>1.4 多线程</h2><ol>
<li><p><a href="/Java/multithread/05.ThreadPool.html">线程池的实现原理、参数配置、平滑关机</a> 了解Executors可以创建的三种 (JAVA8增加了一种，共四种)线程池的特点及适用范围。 <a href="/Java/multithread/05.ThreadPool.html">Java多线程5: 线程池</a></p>
</li>
<li><p>掌握多线程同步机制，并熟练运用。</p>
</li>
</ol>
<ul>
<li>CPU、操作系统锁机制与Java编译优化(指令重排与内存栅栏)</li>
<li><a href="/Java/multithread/01.thread-lifecycle.html">线程生命周期</a></li>
<li><a href="/Java/multithread/03.volatile.html">volatile</a>、内存屏障、缓存行</li>
<li><a href="/Java/multithread/01.1.monitor-synchronized.html">monitor与Synchronized: 实现原理、偏向锁-轻型锁-重型锁</a></li>
<li><a href="http://www.cnblogs.com/waterystone/p/4920797.html">AQS</a></li>
<li>CAS</li>
<li><a href="https://blog.csdn.net/fuyuwei2015/article/details/83719444">RetreentLock</a>、ReadAndWriteLook</li>
<li>CountDownLatch、Atomic、Semaphore</li>
<li>Fork/Join</li>
<li><a href="/Java/multithread/06.BlockingQueue.html">阻塞队列</a></li>
<li>Disruptor队列</li>
<li>生产者消费者模式</li>
<li><a href="/Java/multithread/02.Lock-Semaphore-Atomic.html">Java多线程2: Lock、信号量、原子量与队列</a></li>
<li><a href="/Java/multithread/04.thread-synchronization.html">Java多线程4: 同步锁与Java线程同步方法比较</a></li>
<li><a href="/Java/multithread/06.BlockingQueue.html">Java多线程6: Java阻塞队列与生产者消费者模式</a></li>
<li><a href="1">Java多线程7: 分段锁</a></li>
<li><a href="https://www.jianshu.com/p/b3c4dd85901e">CompletableFuture</a> 、<a href="https://blog.csdn.net/CoderBruis/article/details/103181520">深入解读CompletableFuture源码与原理</a></li>
<li>Quartz定时任务内部实现</li>
<li>Guava并发包</li>
</ul>
<ol start="3">
<li>并发包</li>
</ol>
<h2 id="1-5-Socket"><a href="#1-5-Socket" class="headerlink" title="1.5 Socket"></a>1.5 Socket</h2><ol>
<li>掌握Socket通信原理。<a href="/Java/Socket.html">Java Socket</a></li>
<li>熟练使用多线程结合Socket进行编程。</li>
</ol>
<h2 id="1-6-Stream-API"><a href="#1-6-Stream-API" class="headerlink" title="1.6 Stream API"></a>1.6 Stream API</h2><ol>
<li>Lambda 实现原理</li>
<li>懒加载实现原理</li>
</ol>
<h1 id="2-Java虚拟机"><a href="#2-Java虚拟机" class="headerlink" title="2 Java虚拟机"></a>2 Java虚拟机</h1><h2 id="2-1-JVM内存区域划分"><a href="#2-1-JVM内存区域划分" class="headerlink" title="2.1 JVM内存区域划分"></a>2.1 JVM内存区域划分</h2><p><a href="/Java/JVM.html">深入理解JVM(Java虚拟机)</a><br><a href="/Java/metric/01_tuner.html">Java性能专题</a></p>
<ol>
<li>掌握JMM分区: 程序计数器、堆、虚拟机栈、本地方法栈、方法区（JAVA8已移除）、元空间（JAVA8新增）的作用及基本原理。</li>
<li>掌握堆的划分：新生代（Eden、Survivor1、Survivor2）和老年代的作用及工作原理。</li>
<li>垃圾回收：常见算法与策略、<a href="/Java/metric/02_CMS_GC.html">CMS GC</a>、G1</li>
<li>[重点] 掌握JVM内存参数设置及调优<ul>
<li>Eden与Survivor分配</li>
<li><a href="/Java/metric/jstack.html">JStack</a>、Jstat、vmstat、jmap、jutil</li>
<li>线上排查</li>
</ul>
</li>
</ol>
<h2 id="2-2-类加载"><a href="#2-2-类加载" class="headerlink" title="2.2 类加载"></a>2.2 类加载</h2><ol>
<li>掌握类的加载阶段：加载、链接（验证、准备、解析）、初始化、使用、卸载。</li>
<li>掌握类加载器分类及其应用：启动类加载器、扩展类加载器、应用程序类加载器、自定义加载器。</li>
<li>双亲委派</li>
<li>动态加载</li>
<li>CodeGen</li>
</ol>
<h1 id="3-J2EE"><a href="#3-J2EE" class="headerlink" title="3 J2EE"></a>3 J2EE</h1><ol>
<li>掌握JSP内置对象、动作及相关特点和工作原理。<a href="/JavaWeb/JSP.html">JSP</a></li>
<li>掌握Servlet的特点和工作原理。 <a href="/JavaWeb/Servlet.html">Servlet</a></li>
<li>Spring: IOC和AOP实现原理（控制反转和动态代理）。 <a href="/JavaWeb/Spring/base.html">Spring</a></li>
<li>MVC框架（Spring MVC，Struts等）的工作原理，并熟练运用。 <a href="/JavaWeb/Struts2-basic">Struts2</a> <a href="1">Spring MVC</a>工作原理、事务</li>
<li>Spring MVC: 线程安全、请求原理、事务与传递、异步</li>
<li>ORM框架(Hibernate，MyBatis等)的工作原理，并熟练运用。 <a href="/JavaWeb/Hibernate/concept">Hibernate基本概念</a> <a href="/JavaWeb/Hibernate/Association-Relationship.html">Hibernate关联关系XML实现</a> <a href="/JavaWeb/Hibernate/Annotation.html">Hibernate注解</a> <a href="1">MyBatis原理与缓存</a></li>
</ol>
<h1 id="4-数据结构与算法"><a href="#4-数据结构与算法" class="headerlink" title="4 数据结构与算法"></a>4 数据结构与算法</h1><ol>
<li>掌握<a href="http://www.docin.com/p-1532910757.html">线性表</a>和<a href="http://www.docin.com/p-682548027.html">树</a>的特点并熟练运用: B-Tree节点结构</li>
<li>掌握<a href="/data-struct/SortAndSearchAlgrithom.html">常用排序和查找算法</a>：插入排序(直接插入排序、希尔排序)、选择排序(直接选择排序、堆排序)、交换排序(冒泡排序、快速排序)、归并排序，顺序查找、二分查找、二叉查找树、哈希查找。广度优先搜索(队列实现)</li>
<li>熟练运用常见排序和查找算法思想解决编程问题: Top K问题、大数组查找TopN、数组去重、跳台阶问题、不定长字符串转定长字符串</li>
<li>了解<a href="/data-struct/BasicAlgrithom.html">几大基本算法</a>：贪心算法、分治策略、动态规划、蓄水池抽样</li>
</ol>
<h1 id="5-计算机网络"><a href="#5-计算机网络" class="headerlink" title="5 计算机网络"></a>5 计算机网络</h1><ol>
<li>掌握网络的分层结构，及每层的功能特点。<a href="/network/base.html">计算机网络基础知识</a></li>
<li>Http报文、状态码</li>
<li>掌握TCP/IP的通信原理(三次握手、四次挥手)</li>
<li><a href="/network/security/HTTPS-SSL.html" title="HTTPS与SSL">HTTPS</a>,<a href="/network/security/encrypt-decrypt-signature-certificate.html">加密、验签与证书</a></li>
</ol>
<h1 id="6-数据库"><a href="#6-数据库" class="headerlink" title="6 数据库"></a>6 数据库</h1><ol>
<li>掌握复杂的SQL语句编写。<a href="/database/MySQL/base.html">MySQL</a>   <a href="/database/concept.html">数据库设计</a></li>
<li>掌握数据库的优化（SQL层面和表设计层面）。<a href="http://www.jb51.net/article/24392.htm">MySQL 性能优化的最佳20多条经验</a></li>
<li><a href="/database/MySQL/base.html">MySQL</a><ul>
<li>InnoDB数据结构、索引</li>
<li>InnoDB与MyASIM区别</li>
<li>行级锁与表级锁</li>
</ul>
</li>
<li>MySQL集群<ul>
<li>集群</li>
<li>读写分离与实现</li>
<li>双写</li>
</ul>
</li>
<li>熟悉高并发、大数据情况下的数据库开发。</li>
</ol>
<h1 id="7-Web技术"><a href="#7-Web技术" class="headerlink" title="7 Web技术"></a>7 Web技术</h1><ol>
<li>掌握<a href="/web/AJAX.html">AJAX</a>的工作原理。</li>
<li>至少熟悉一款JS框架(比如JQuery)。<a href="/web/JQuery.html">JQuery</a></li>
</ol>
<h1 id="8-设计模式"><a href="#8-设计模式" class="headerlink" title="8 设计模式"></a>8 设计模式</h1><ol>
<li>熟悉常见的<a href="/design-pattern/base.html">设计模式</a>。</li>
<li>会将设计模式理论应用到实际开发中。</li>
</ol>
<h1 id="9-Linux"><a href="#9-Linux" class="headerlink" title="9 Linux"></a>9 Linux</h1><ol>
<li>熟练运用Linux常见命令。</li>
<li>熟悉Linux操作系统基本概念及特点。</li>
<li>熟悉<a href="http://www.codeceo.com/article/shell-learn-30-mins.html">Shell脚本</a>。</li>
</ol>
<h1 id="10-操作系统"><a href="#10-操作系统" class="headerlink" title="10 操作系统"></a>10 操作系统</h1><ol>
<li>掌握操作系统的进程管理。</li>
<li>了解操作系统的I/O。</li>
<li>Linux系统调优: 命令与方法</li>
</ol>
<h1 id="11-正则表达式"><a href="#11-正则表达式" class="headerlink" title="11 正则表达式"></a>11 正则表达式</h1><ol>
<li>掌握常见正则表达式符号。</li>
<li>熟练运用正则表达式解决实际问题(比如匹配电话号码、邮箱、域名等)。<a href="/Java/regular-expression.html">常用的正则表达式与Java中的运用</a></li>
</ol>
<h1 id="12-安全"><a href="#12-安全" class="headerlink" title="12 安全"></a>12 安全</h1><ol>
<li><a href="/web/XSS.html">XSS</a></li>
<li><a href="/web/JSONP.html">CROS</a></li>
<li>RTFS</li>
<li>加密解密与验签</li>
<li>HTTPS</li>
<li>跨域请求的方法</li>
</ol>
<h1 id="13-分布式"><a href="#13-分布式" class="headerlink" title="13 分布式"></a>13 分布式</h1><ol>
<li>分布式事务<ul>
<li>分布式锁：基于DB事务、基于Redis、基于ZooKeeper</li>
<li>ACID</li>
<li>CAP、BASE</li>
<li>TCC</li>
</ul>
</li>
<li>微服务</li>
<li>Nginx: 原理、负载均衡算法、动态切换</li>
<li>消息中间件 Kafka、ActiveMQ</li>
<li>分布式缓存及其集群: 雪崩、穿透、Master选举切换</li>
<li><a href="/database/Redis/base.html">Redis</a>：集群、并发竞争问题、事务与CAS操作、持久化、订阅、缓存失败策略</li>
<li><a href="/database/memcached/base.html">Memcached</a>: 数据结构</li>
<li>ZooKeeper: 数据结构、集群、Master选举切换</li>
<li><a href="/distributed/RPC.html">RPC</a>：<a href="/">WebService: SOAP、UUDI、WSDL</a>等</li>
<li>服务治理SOA框架的使用与原理<ul>
<li><a href="1">Dubbo</a>: 架构、雪崩、服务异常与逻辑异常追踪、服务降级、服务发现</li>
</ul>
</li>
<li>分库分表<ul>
<li>常见分库分表方案：水平分表与垂直分表的业务设计</li>
<li>扩容与迁移</li>
<li>MyCat</li>
<li>Sharding-JDBC</li>
</ul>
</li>
<li>唯一主键生成器</li>
<li>算法: 一致性hash、轮询、Paxos、fast leader、raft</li>
<li>系统设计<ul>
<li>高可用</li>
<li>可扩展</li>
<li>限流(滑动窗口、漏桶、令牌桶)</li>
<li>幂等</li>
</ul>
</li>
<li>常见场景<ul>
<li>电商</li>
</ul>
</li>
<li>Docker</li>
</ol>
<h1 id="14-大数据"><a href="#14-大数据" class="headerlink" title="14 大数据"></a>14 大数据</h1><ol>
<li>实时计算: 基数算法</li>
<li>Storm 原理</li>
<li>Flink 原理</li>
<li>Hadoop<ul>
<li>NameNode动态切换</li>
<li>MapReduce与shuffle、数据倾斜问题</li>
</ul>
</li>
<li>Yarn</li>
<li>HBase</li>
<li>Kylin</li>
<li>Hive</li>
<li>Lucene、solar、ElasticSearch</li>
<li>爬虫</li>
<li>推荐算法：协同过滤</li>
<li>画像系统原理</li>
</ol>
<h1 id="15-机器学习"><a href="#15-机器学习" class="headerlink" title="15. 机器学习"></a>15. 机器学习</h1><h1 id="16-其他"><a href="#16-其他" class="headerlink" title="16 其他"></a>16 其他</h1><ol>
<li>Quartz 原理：调度与分布式</li>
<li>缓存: Ehcache、Spring Data cache、Guava-cache<ul>
<li>LRUCache</li>
<li>FastLRUCache</li>
</ul>
</li>
<li>连接池：Druid</li>
<li><a href="/interview.html">虐菜</a></li>
<li><a href="/software-engineering/base.html">软件工程基本知识</a></li>
<li>CORBAR</li>
<li>WebSocket</li>
<li>Tomcat实现原理</li>
</ol>
<h1 id="17-2018-中期计划"><a href="#17-2018-中期计划" class="headerlink" title="17. 2018 中期计划"></a>17. 2018 中期计划</h1><ol>
<li><a href="/distributed/tomcat/principle.html">apache Tomcat 源码分析</a></li>
<li><a href="/distributed/storm/principle.html">apache Storm 源码分析</a></li>
<li><a href="/Java/multithread/disruptor_principle.html">disruptor源码分析</a></li>
<li>分布式服务架构：原理、设计与实战</li>
<li>HBase</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Job</tag>
      </tags>
  </entry>
  <entry>
    <title>Java软件工程师知识结构</title>
    <url>/Java/step/</url>
    <content><![CDATA[<h1 id="1-Java基础"><a href="#1-Java基础" class="headerlink" title="1 Java基础"></a>1 Java基础</h1><h2 id="1-1-Collection和Map"><a href="#1-1-Collection和Map" class="headerlink" title="1.1 Collection和Map"></a>1.1 Collection和Map</h2><ol>
<li>掌握Collection和Map的继承体系。<a href="/Java/collection/collection-map/" title="Java Collection与Map">Java Collection与map</a></li>
<li>掌握ArrayList、LinkedList、Vector、Stack、PriorityQueue、HashSet、LinkedHashSet、TreeSet、HashMap、LinkedHashMap、TreeMap、WeakHashMap、EnumMap、TreeMap(红黑树)、HashTable的特点和实现原理。</li>
<li>掌握CopyOnWriteArrayList、CopyOnWriteArraySet、<a href="/Java/collection/ConcurrentHashMap/">ConcurrentHashMap</a>的实现原理和适用场景。</li>
<li>Java并发容器</li>
</ol>
<h2 id="1-2-IO"><a href="#1-2-IO" class="headerlink" title="1.2 IO"></a>1.2 IO</h2><ol>
<li>掌握InputStream、OutputStream、Reader、Writer的继承体系。 <a href="/Java/io/BIO/" title="Java IO">Java IO</a> , <a href="/Java/io/java-zip/">Java 压缩</a> , <a href="/Java/io/java-XML-JSON/">Java XML与JSON</a>, <a href="/Java/io/object-serialization/">Java序列化</a></li>
<li>掌握字节流(FileInputStream、DataInputStream、BufferedInputStream、FileOutputSteam、DataOutputStream、BufferedOutputStream)和 字符流(BufferedReader、InputStreamReader、FileReader、BufferedWriter、OutputStreamWriter、PrintWriter、FileWriter)，并熟练运用。</li>
<li>掌握NIO实现原理及使用方法。 <a href="/Java/io/IO-Model/">IO模式</a> <a href="/Java/io/NIO/">Java NIO</a></li>
<li>Netty原理 <a href="/JavaWeb/Netty/Netty-theory/">这可能是目前最透彻的Netty原理架构解析</a></li>
<li>IO理论 <a href="/Java/io/high-performance-network-programming/">高性能网络编程</a></li>
</ol>
<h2 id="1-3-异常"><a href="#1-3-异常" class="headerlink" title="1.3 异常"></a>1.3 异常</h2><ol>
<li>掌握Throwable继承体系。<a href="http://blog.csdn.net/hguisu/article/details/6155636" title="深入理解java异常处理机制">深入理解java异常处理机制</a></li>
<li>掌握异常工作原理。</li>
<li>了解常见受检异常(比如FileNotFoundException)、非受检异常(比如NullPointerException)和错误(比如IOError)。</li>
</ol>
<h2 id="1-4-多线程"><a href="#1-4-多线程" class="headerlink" title="1.4 多线程"></a>1.4 多线程</h2><ol>
<li><p><a href="/Java/multithread/05.ThreadPool/">线程池的实现原理、参数配置、平滑关机</a> 了解Executors可以创建的三种 (JAVA8增加了一种，共四种)线程池的特点及适用范围。 <a href="/Java/multithread/05.ThreadPool/">Java多线程5: 线程池</a></p>
</li>
<li><p>掌握多线程同步机制，并熟练运用。</p>
</li>
</ol>
<ul>
<li>CPU、操作系统锁机制与Java编译优化(指令重排与内存栅栏)</li>
<li><a href="/Java/multithread/01.thread-lifecycle/">线程生命周期</a></li>
<li><a href="/Java/multithread/03.volatile/">volatile</a></li>
<li><a href="/Java/multithread/01.1.monitor-synchronized/">monitor与Synchronized: 实现原理、偏向锁-轻型锁-重型锁</a></li>
<li><a href="http://www.cnblogs.com/waterystone/p/4920797.html">AQS</a></li>
<li>CAS</li>
<li><a href="https://blog.csdn.net/fuyuwei2015/article/details/83719444">RetreentLock</a>、ReadAndWriteLook</li>
<li>CountDownLatch、Atomic、Semaphore</li>
<li>Fork/Join</li>
<li><a href="/Java/multithread/06.BlockingQueue/">阻塞队列</a></li>
<li>Disruptor队列</li>
<li>生产者消费者模式</li>
<li><a href="/Java/multithread/02.Lock-Semaphore-Atomic/">Java多线程2: Lock、信号量、原子量与队列</a></li>
<li><a href="/Java/multithread/04.thread-synchronization/">Java多线程4: 同步锁与Java线程同步方法比较</a></li>
<li><a href="/Java/multithread/06.BlockingQueue/">Java多线程6: Java阻塞队列与生产者消费者模式</a></li>
<li><a href="1">Java多线程7: 分段锁</a></li>
<li><a href="https://www.jianshu.com/p/b3c4dd85901e">CompletableFuture</a> 、<a href="https://blog.csdn.net/CoderBruis/article/details/103181520">深入解读CompletableFuture源码与原理</a></li>
<li>Quartz定时任务内部实现</li>
<li>Guava并发包</li>
</ul>
<ol start="3">
<li>并发包</li>
</ol>
<h2 id="1-5-Socket"><a href="#1-5-Socket" class="headerlink" title="1.5 Socket"></a>1.5 Socket</h2><ol>
<li>掌握Socket通信原理。<a href="/Java/Socket/">Java Socket</a></li>
<li>熟练使用多线程结合Socket进行编程。</li>
</ol>
<h2 id="1-6-Stream-API"><a href="#1-6-Stream-API" class="headerlink" title="1.6 Stream API"></a>1.6 Stream API</h2><ol>
<li>Lambda 实现原理</li>
<li>懒加载实现原理</li>
</ol>
<h1 id="2-Java虚拟机"><a href="#2-Java虚拟机" class="headerlink" title="2 Java虚拟机"></a>2 Java虚拟机</h1><h2 id="2-1-JVM内存区域划分"><a href="#2-1-JVM内存区域划分" class="headerlink" title="2.1 JVM内存区域划分"></a>2.1 JVM内存区域划分</h2><p><a href="/Java/JVM/">深入理解JVM(Java虚拟机)</a><br><a href="/Java/metric/01_tuner">Java性能专题</a></p>
<ol>
<li>掌握JMM分区: 程序计数器、堆、虚拟机栈、本地方法栈、方法区（JAVA8已移除）、元空间（JAVA8新增）的作用及基本原理。</li>
<li>掌握堆的划分：新生代（Eden、Survivor1、Survivor2）和老年代的作用及工作原理。</li>
<li>垃圾回收：常见算法与策略、<a href="/Java/metric/02_CMS_GC/">CMS GC</a>、G1</li>
<li>[重点] 掌握JVM内存参数设置及调优<ul>
<li>Eden与Survivor分配</li>
<li><a href="/Java/metric/jstack/">JStack</a>、Jstat、vmstat、jmap、jutil</li>
<li>线上排查</li>
</ul>
</li>
</ol>
<h2 id="2-2-类加载"><a href="#2-2-类加载" class="headerlink" title="2.2 类加载"></a>2.2 类加载</h2><ol>
<li>掌握类的加载阶段：加载、链接（验证、准备、解析）、初始化、使用、卸载。</li>
<li>掌握类加载器分类及其应用：启动类加载器、扩展类加载器、应用程序类加载器、自定义加载器。</li>
<li>双亲委派</li>
<li>动态加载</li>
<li>CodeGen</li>
</ol>
<h1 id="3-J2EE"><a href="#3-J2EE" class="headerlink" title="3 J2EE"></a>3 J2EE</h1><ol>
<li>掌握JSP内置对象、动作及相关特点和工作原理。<a href="/JavaWeb/JSP/">JSP</a></li>
<li>掌握Servlet的特点和工作原理。 <a href="/JavaWeb/Servlet/">Servlet</a></li>
<li>Spring: IOC和AOP实现原理（控制反转和动态代理）。 <a href="/JavaWeb/Spring/base/">Spring</a></li>
<li>MVC框架（Spring MVC，Struts等）的工作原理，并熟练运用。 <a href="/JavaWeb/Struts2-basic">Struts2</a> <a href="1">Spring MVC</a>工作原理、事务</li>
<li>Spring MVC: 线程安全、请求原理、事务与传递、异步</li>
<li>ORM框架(Hibernate，MyBatis等)的工作原理，并熟练运用。 <a href="/JavaWeb/Hibernate/concept">Hibernate基本概念</a> <a href="/JavaWeb/Hibernate/Association-Relationship/">Hibernate关联关系XML实现</a> <a href="/JavaWeb/Hibernate/Annotation/">Hibernate注解</a> <a href="1">MyBatis原理与缓存</a></li>
</ol>
<h1 id="4-数据结构与算法"><a href="#4-数据结构与算法" class="headerlink" title="4 数据结构与算法"></a>4 数据结构与算法</h1><ol>
<li>掌握<a href="http://www.docin.com/p-1532910757.html">线性表</a>和<a href="http://www.docin.com/p-682548027.html">树</a>的特点并熟练运用: B-Tree节点结构</li>
<li>掌握<a href="/data-struct/SortAndSearchAlgrithom/">常用排序和查找算法</a>：插入排序(直接插入排序、希尔排序)、选择排序(直接选择排序、堆排序)、交换排序(冒泡排序、快速排序)、归并排序，顺序查找、二分查找、二叉查找树、哈希查找。广度优先搜索(队列实现)</li>
<li>熟练运用常见排序和查找算法思想解决编程问题: Top K问题、大数组查找TopN、数组去重、跳台阶问题、不定长字符串转定长字符串</li>
<li>了解<a href="/data-struct/BasicAlgrithom/">几大基本算法</a>：贪心算法、分治策略、动态规划、蓄水池抽样</li>
</ol>
<h1 id="5-计算机网络"><a href="#5-计算机网络" class="headerlink" title="5 计算机网络"></a>5 计算机网络</h1><ol>
<li>掌握网络的分层结构，及每层的功能特点。<a href="/network/base/">计算机网络基础知识</a></li>
<li>Http报文、状态码</li>
<li>掌握TCP/IP的通信原理(三次握手、四次挥手)</li>
<li><a href="/network/security/HTTPS-SSL/" title="HTTPS与SSL">HTTPS</a>,<a href="/network/security/encrypt-decrypt-signature-certificate/">加密、验签与证书</a></li>
</ol>
<h1 id="6-数据库"><a href="#6-数据库" class="headerlink" title="6 数据库"></a>6 数据库</h1><ol>
<li>掌握复杂的SQL语句编写。<a href="/database/MySQL/base/">MySQL</a>   <a href="/database/concept/">数据库设计</a></li>
<li>掌握数据库的优化（SQL层面和表设计层面）。<a href="http://www.jb51.net/article/24392.htm">MySQL 性能优化的最佳20多条经验</a></li>
<li><a href="/database/MySQL/base">MySQL</a><ul>
<li>InnoDB数据结构、索引</li>
<li>InnoDB与MyASIM区别</li>
<li>行级锁与表级锁</li>
</ul>
</li>
<li>MySQL集群<ul>
<li>集群</li>
<li>读写分离与实现</li>
<li>双写</li>
</ul>
</li>
<li>熟悉高并发、大数据情况下的数据库开发。</li>
</ol>
<h1 id="7-Web技术"><a href="#7-Web技术" class="headerlink" title="7 Web技术"></a>7 Web技术</h1><ol>
<li>掌握<a href="/web/AJAX/">AJAX</a>的工作原理。</li>
<li>至少熟悉一款JS框架(比如JQuery)。<a href="/web/JQuery/">JQuery</a></li>
</ol>
<h1 id="8-设计模式"><a href="#8-设计模式" class="headerlink" title="8 设计模式"></a>8 设计模式</h1><ol>
<li>熟悉常见的<a href="/design-pattern/base/">设计模式</a>。</li>
<li>会将设计模式理论应用到实际开发中。</li>
</ol>
<h1 id="9-Linux"><a href="#9-Linux" class="headerlink" title="9 Linux"></a>9 Linux</h1><ol>
<li>熟练运用Linux常见命令。</li>
<li>熟悉Linux操作系统基本概念及特点。</li>
<li>熟悉<a href="http://www.codeceo.com/article/shell-learn-30-mins.html">Shell脚本</a>。</li>
</ol>
<h1 id="10-操作系统"><a href="#10-操作系统" class="headerlink" title="10 操作系统"></a>10 操作系统</h1><ol>
<li>掌握操作系统的进程管理。</li>
<li>了解操作系统的I/O。</li>
<li>Linux系统调优: 命令与方法</li>
</ol>
<h1 id="11-正则表达式"><a href="#11-正则表达式" class="headerlink" title="11 正则表达式"></a>11 正则表达式</h1><ol>
<li>掌握常见正则表达式符号。</li>
<li>熟练运用正则表达式解决实际问题(比如匹配电话号码、邮箱、域名等)。<a href="/Java/regular-expression/">常用的正则表达式与Java中的运用</a></li>
</ol>
<h1 id="12-安全"><a href="#12-安全" class="headerlink" title="12 安全"></a>12 安全</h1><ol>
<li><a href="/web/XSS">XSS</a></li>
<li><a href="/web/JSONP/">CROS</a></li>
<li>RTFS</li>
<li>加密解密与验签</li>
<li>HTTPS</li>
<li>跨域请求的方法</li>
</ol>
<h1 id="13-分布式"><a href="#13-分布式" class="headerlink" title="13 分布式"></a>13 分布式</h1><ol>
<li>分布式事务<ul>
<li>分布式锁：基于DB事务、基于Redis、基于ZooKeeper</li>
<li>ACID</li>
<li>CAP、BASE</li>
<li>TCC</li>
</ul>
</li>
<li>微服务</li>
<li>Nginx: 原理、负载均衡算法、动态切换</li>
<li>消息中间件 Kafka、ActiveMQ</li>
<li>分布式缓存及其集群: 雪崩、穿透、Master选举切换</li>
<li><a href="/database/Redis/base/">Redis</a>：集群、并发竞争问题、事务与CAS操作、持久化、订阅、缓存失败策略</li>
<li><a href="/database/memcached/base/">Memcached</a>: 数据结构</li>
<li>ZooKeeper: 数据结构、集群、Master选举切换</li>
<li><a href="/distributed/RPC/">RPC</a>：<a href="/">WebService: SOAP、UUDI、WSDL</a>等</li>
<li>服务治理SOA框架的使用与原理<ul>
<li><a href="1">Dubbo</a>: 架构、雪崩、服务异常与逻辑异常追踪、服务降级、服务发现</li>
</ul>
</li>
<li>分库分表<ul>
<li>常见分库分表方案：水平分表与垂直分表的业务设计</li>
<li>扩容与迁移</li>
<li>MyCat</li>
<li>Sharding-JDBC</li>
</ul>
</li>
<li>唯一主键生成器</li>
<li>算法: 一致性hash、轮询、Paxos、fast leader、raft</li>
<li>系统设计<ul>
<li>高可用</li>
<li>可扩展</li>
<li>限流(滑动窗口、漏桶、令牌桶)</li>
<li>幂等</li>
</ul>
</li>
<li>常见场景<ul>
<li>电商</li>
</ul>
</li>
<li>Docker</li>
</ol>
<h1 id="14-大数据"><a href="#14-大数据" class="headerlink" title="14 大数据"></a>14 大数据</h1><ol>
<li>实时计算: 基数算法</li>
<li>Storm 原理</li>
<li>Flink 原理</li>
<li>Hadoop<ul>
<li>NameNode动态切换</li>
<li>MapReduce与shuffle、数据倾斜问题</li>
</ul>
</li>
<li>Yarn</li>
<li>HBase</li>
<li>Kylin</li>
<li>Hive</li>
<li>Lucene、solar、ElasticSearch</li>
<li>爬虫</li>
<li>推荐算法：协同过滤</li>
<li>画像系统原理</li>
</ol>
<h1 id="15-机器学习"><a href="#15-机器学习" class="headerlink" title="15. 机器学习"></a>15. 机器学习</h1><h1 id="16-其他"><a href="#16-其他" class="headerlink" title="16 其他"></a>16 其他</h1><ol>
<li>Quartz 原理：调度与分布式</li>
<li>缓存: Ehcache、Spring Data cache、Guava-cache<ul>
<li>LRUCache</li>
<li>FastLRUCache</li>
</ul>
</li>
<li>连接池：Druid</li>
<li><a href="/interview/">虐菜</a></li>
<li><a href="/software-engineering/base/">软件工程基本知识</a></li>
<li>CORBAR</li>
<li>WebSocket</li>
<li>Tomcat实现原理</li>
</ol>
<h1 id="17-2018-中期计划"><a href="#17-2018-中期计划" class="headerlink" title="17. 2018 中期计划"></a>17. 2018 中期计划</h1><ol>
<li><a href="/distributed/tomcat/principle/">apache Tomcat 源码分析</a></li>
<li><a href="/distributed/storm/principle/">apache Storm 源码分析</a></li>
<li><a href="/Java/multithread/disruptor_principle/">disruptor源码分析</a></li>
<li>分布式服务架构：原理、设计与实战</li>
<li>HBase</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Job</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/distributed/02.%E9%99%90%E6%B5%81/</url>
    <content><![CDATA[<h1 id="02-限流"><a href="#02-限流" class="headerlink" title="02.限流"></a>02.限流</h1>]]></content>
  </entry>
  <entry>
    <title>分布式理论：隔离机制【转载】</title>
    <url>/distributed/03.%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>转载自 <a href="https://segmentfault.com/a/1190000020791119">微服务容错 - 隔离熔断限流</a></p>
<p>在高并发访问下，系统所依赖的服务的稳定性对系统的影响非常大，依赖有很多不可控的因素，比如网络连接变慢，资源突然繁忙，暂时不可用，服务脱机等。我们要构建稳定、可靠的分布式系统，就必须要有这样一套容错机制。常用的的容错技术如：隔离，降级，熔断，限流等策略，本文将详细的介绍微服务中的容错机制。</p>
<h2 id="隔离机制"><a href="#隔离机制" class="headerlink" title="隔离机制"></a>隔离机制</h2><p>为什么要隔离? 比如我们现在某个接口所在的服务A需要调用服务B，而服务B同时需要调用C服务，此时服务C突然宕机同时此时流量暴涨，调用全部打到服务B上，此时B服务调用C超时大量的线程资源被该接口所占全部hang住，慢慢服务B中的线程数量则会持续增加直致CPU资源耗尽到100%，整个服务对外不可用渐渐蔓延到B服务集群中的其他节点，导致服务级联故障。</p>
<p><img src="_v_images/20191130225057895_2045824433" alt="1570592685522.png" title="1570592685522.png"></p>
<p>此时我们就需要对服务出现异常的情况进行隔离，防止级联故障效应，常用的隔离策略有线程池隔离和信号量隔离</p>
<h3 id="线程池隔离"><a href="#线程池隔离" class="headerlink" title="线程池隔离"></a>线程池隔离</h3><p>线程池隔离顾名思义就是通过Java的线程池进行隔离，B服务调用C服务给予固定的线程数量比如10个线程，如果此时C服务宕机了就算大量的请求过来，调用C服务的接口只会占用10个线程不会占用其他工作线程资源，因此B服务就不会出现级联故障</p>
<p><img src="_v_images/20191130225057490_1596748749" alt="1570593867373.png" title="1570593867373.png"></p>
<h3 id="信号量隔离"><a href="#信号量隔离" class="headerlink" title="信号量隔离"></a>信号量隔离</h3><p>另一种隔离信号量隔离是使用<code>JUC</code>下的Semaphore来实现的，当拿不到信号量的时候直接拒接因此不会出现超时占用其他工作线程的情况。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Semaphore semaphore &#x3D; new Semaphore(10,true);</span><br><span class="line">&#x2F;&#x2F;获取信号量</span><br><span class="line">semaphore.acquire();</span><br><span class="line">&#x2F;&#x2F;do something here</span><br><span class="line">&#x2F;&#x2F;释放信号量</span><br><span class="line">semaphore.release();</span><br></pre></td></tr></table></figure>
<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>​线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。而信号量隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。</p>
<table>
<thead>
<tr>
<th>比较项</th>
<th>线程池隔离</th>
<th>信号量隔离</th>
</tr>
</thead>
<tbody><tr>
<td>线程</td>
<td>与调用线程不同，使用的是线程池创建的线程</td>
<td>与调用线程相同</td>
</tr>
<tr>
<td>开销</td>
<td>排队，切换，调度等开销</td>
<td>无线程切换性能更高</td>
</tr>
<tr>
<td>是否支持异步</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>是否支持超时</td>
<td>支持超时</td>
<td><strong>支持超时(<a href="https://www.codercto.com/a/77154.html">新版本支持</a>)</strong></td>
</tr>
<tr>
<td>并发支持</td>
<td>支持通过线程池大小控制</td>
<td>支持通过最大信号量控制</td>
</tr>
</tbody></table>
<h2 id="降级熔断机制"><a href="#降级熔断机制" class="headerlink" title="降级熔断机制"></a>降级熔断机制</h2><p>​ 什么是降级和熔断？降级和熔断有什么区别？虽然很多人把降级熔断当着一个词来说的，但是降级和熔断是完全不同的概念的，看看下面几种场景：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">场景一：比如我们每天上班坐公交，1路和2路公交都能到公司，但是2路公交需要下车走点路，所以平时都是坐1路公交，</span><br><span class="line">突然有一天等了1路公交好久都没来，于是就坐了2路公交作为替代方案总不能迟到吧！下次再等1路车。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">场景二：第二天，第三天 ... 已经一个星期了都没看到1路公交，心里觉得可能是1路公交改路线了，</span><br><span class="line">于是直接坐2路公交了，在接下来的日子里都是直接忽略1路车直接坐2路车</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">场景三：突然有一天在等2路车的时候看到了1路车，是不是1路车现在恢复了，于是天天开心的坐着1路车上班去了，领导再也不担心我迟到了</span><br></pre></td></tr></table></figure>
<p>场景一 在1路车没等到的情况下采取降级方案坐2路车，这就是降级策略，<br>场景二 如果多次都没有等到1路车就直接不等了下次直接坐2路车，这就是熔断策略，<br>场景三 如果过段时间1路车恢复了就使用2路车，这就是熔断恢复！</p>
<h3 id="降级机制"><a href="#降级机制" class="headerlink" title="降级机制"></a>降级机制</h3><p>常用的降级策略如：熔断器降级，限流降级，超时降级，异常降级，平均响应时间降级等</p>
<p><img src="_v_images/20191130225057086_638012610" alt="1570591437265.png" title="1570591437265.png"></p>
<ul>
<li><strong>熔断器降级：</strong>即熔断器开启的时间直接熔断走降级的策略</li>
<li><strong>限流降级：</strong>对流量进行限制达到降级的效果，如：<code>Hystrix</code>中的线程池，信号量都能达到限流的效果</li>
<li><strong>超时降级：</strong>课时设置对应的超时时间如果服务调用超时了就执行降级策略，如：<code>Hystrix</code>中默认为1s</li>
<li><strong>异常降级：</strong>异常降级很简单就是服务出现异常了执行降级策略</li>
<li><strong>平均响应时间降级：</strong>服务响应时间持续飙高的时候实现降级策略，如Sentinel中默认的RT 上限是 4900 ms</li>
</ul>
<h3 id="熔断机制"><a href="#熔断机制" class="headerlink" title="熔断机制"></a>熔断机制</h3><p>​ 熔断其实是一个框架级的处理，那么这套熔断机制的设计，基本上业内用的是<code>Martin Fowler</code>提出的断路器模式，断路器的基本原理非常简单。<br>您将受保护的函数调用包装在断路器对象中，该对象将监视故障。一旦故障达到某个阈值，断路器将跳闸，并且所有进一步的断路器调用都会返回错误，而根本不会进行受保护的调用。常见的断路器模式有基本模式和扩展模式。</p>
<p><strong>基本模式：</strong></p>
<ul>
<li>如果断路器状态为close，则调用断路器将调用supplier服务模块；</li>
<li>如果断路器状态为open则直接返回错误；</li>
<li>如果超时，我们将增加失败计数器，成功的调用会将其重置为零；</li>
<li>通过比较故障计数和阈值来确定断路器的状态；</li>
</ul>
<p><img src="_v_images/20191130225056679_1480988248" alt="20191024163112.png" title="20191024163112.png"></p>
<p><strong>扩展模式：</strong></p>
<p>基础模式的断路器避免了在电路断开时发出受保护的呼叫，但是当情况恢复正常时，将需要外部干预才能将其重置。对于建筑物中的电路断路器，这是一种合理的方法，但是对于软件断路器，我们可以让断路器本身检测基础调用是否再次正常工作。我们可以通过在适当的时间间隔后再次尝试受保护的调用来实现这种自我重置行为，并在成功后重置断路器。于是就出现了扩展模式：</p>
<p><img src="_v_images/20191130225056272_406198049" alt="20191024163133.png" title="20191024163133.png"></p>
<ul>
<li>最开始处于<code>closed</code>状态，一旦检测到错误到达一定阈值，便转为<code>open</code>状态；</li>
<li>这时候会有个 reset timeout，到了这个时间了，会转移到<code>half open</code>状态；</li>
<li>尝试放行一部分请求到后端，一旦检测成功便回归到<code>closed</code>状态，即恢复服务；</li>
</ul>
<h3 id="熔断策略"><a href="#熔断策略" class="headerlink" title="熔断策略"></a>熔断策略</h3><p>我们通常用以下几种方式来衡量资源是否处于稳定的状态：</p>
<ul>
<li>平均响应时间：如<code>Sentinel</code>中的熔断就使用了平均响应时间，当 1s 内持续进入 5 个请求，对应时刻的平均响应时间（秒级）均超过阈值（<code>count</code>，以 ms 为单位），那么在接下的时间窗口之内，对这个方法的调用都会自动地熔断。</li>
<li>异常比例 ：主流的容错框架<code>Hystrix</code>和<code>sentinel</code>中都使用了异常比例熔断策略，比如当资源的每秒请求量 &gt;= 5，并且每秒异常总数占通过量的比值超过阈值之后，资源进入熔断状态，即在接下的时间窗口之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 <code>[0.0, 1.0]</code>，代表 0% - 100%。</li>
<li>异常数：如<code>Sentinel</code>中的熔断就使用了异常数熔断策略，当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 <code>timeWindow</code> 小于 60s，则结束熔断状态后仍可能再进入熔断状态。</li>
</ul>
<h2 id="限流机制"><a href="#限流机制" class="headerlink" title="限流机制"></a>限流机制</h2><p>​ 限流也是提高系统的容错性的一种方案，不同的场景对“流”的定义也是不同的，可以是网络流量，带宽，每秒处理的事务数 (<code>TPS</code>)，每秒请求数 (<code>hits per second</code>)，并发请求数，甚至还可能是业务上的某个指标，比如用户在某段时间内允许的最多请求短信验证码次数。我们常说的限流都是限制每秒请求数，从分布式角度来看，限流可分为 <code>分布式限流</code> （比如基于<code>Sentinel</code>或者<code>Redis</code>的集群限流）和 <code>单机限流</code> 。从算法实现角度来看，限流算法可分为 <code>漏桶算法</code>、 <code>令牌桶算法</code> 和 <code>滑动时间窗口算法</code> 。</p>
<h3 id="单机限流"><a href="#单机限流" class="headerlink" title="单机限流"></a>单机限流</h3><p><strong>漏桶算法</strong></p>
<p><img src="_v_images/20191130225055766_1808623677" alt="1570701032430.png" title="1570701032430.png"></p>
<ul>
<li>一个固定容量的漏桶，按照常量固定速率流出水滴；</li>
<li>如果桶是空的，则不需流出水滴；</li>
<li>可以以任意速率流入水滴到漏桶；</li>
<li>如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。</li>
</ul>
<p><strong>令牌桶算法</strong></p>
<p><img src="_v_images/20191130225055360_839601664" alt="1570700342271.png" title="1570700342271.png"></p>
<ul>
<li>假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌；</li>
<li>桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝；</li>
<li>当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上；</li>
<li>如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。</li>
</ul>
<p><strong>固定时间窗口算法</strong><br><img src="_v_images/20191130225054755_1892726461" alt="20191024163948.png" title="20191024163948.png"></p>
<p>这种实现计数器限流方式由于是在一个时间间隔内进行限制，如果用户在上个时间间隔结束前请求（但没有超过限制），同时在当前时间间隔刚开始请求（同样没超过限制），在各自的时间间隔内，这些请求都是正常的，但是将间隔临界的一段时间内的请求就会超过系统限制，可能导致系统被压垮。</p>
<p><strong>滑动时间窗口算法</strong></p>
<p><img src="_v_images/20191130225054050_1038055339" alt="1571219763433.png" title="1571219763433.png"></p>
<ul>
<li>0、初始化，设置时间窗口，设置时间窗口时间点间隔长度；</li>
<li>1、判断请求时间点是否在时间窗口中，在进入步骤2，否则进入步骤3；</li>
<li>2、判断是否超过时间窗口限流值，是-&gt;进行限流，否-&gt;对应时间窗口计数器+1；</li>
<li>3、移动当时时间窗口，移动方式是：起始时间点变为时间列表中的第二时间点，结束时间增加一个时间点。重新步骤一的判断 。</li>
</ul>
<h3 id="分布式限流"><a href="#分布式限流" class="headerlink" title="分布式限流"></a>分布式限流</h3><p>当应用为单点应用时，只要应用进行了限流，那么应用所依赖的各种服务也都得到了保护。 但线上业务出于各种原因考虑，多是分布式系统，单节点的限流仅能保护自身节点，但无法保护应用依赖的各种服务，并且在进行节点扩容、缩容时也无法准确控制整个服务的请求限制。</p>
<p><img src="_v_images/20191130225053543_420645799" alt="1571903140149.png" title="1571903140149.png"></p>
<p>如果实现了分布式限流，那么就可以方便地控制整个服务集群的请求限制，且由于整个集群的请求数量得到了限制，因此服务依赖的各种资源也得到了限流的保护。</p>
<p><img src="_v_images/20191130225052943_1592738452" alt="1571904304647.png" title="1571904304647.png"></p>
<p><strong>分布式限流方案</strong></p>
<p>分布式限流的思想我列举下面三个方案：</p>
<p><strong>1，<code>Redis</code>令牌桶</strong></p>
<p>这种方案是最简单的一种集群限流思想。在本地限流中，我们使用Long的原子类作令牌桶，当实例数量超过1，我们就考虑将<code>Redis</code>用作公共内存区域，进行读写。涉及到的并发控制，也可以使用<code>Redis</code>实现分布式锁。</p>
<p><strong>缺点：</strong>每取一次令牌都会进行一次网络开销，而网络开销起码是毫秒级，所以这种方案支持的并发量是非常有限的。</p>
<p><strong>2，<code>QPS</code>统一分配</strong></p>
<p>这种方案的思想是将集群限流最大程度的本地化。</p>
<p>举个例子，我们有两台服务器实例，对应的是同一个应用程序（<code>Application.name</code>相同），程序中设置的<code>QPS</code>为100，将应用程序与同一个控制台程序进行连接，控制台端依据应用的实例数量将<code>QPS</code>进行均分，动态设置每个实例的<code>QPS</code>为50，若是遇到两个服务器的配置并不相同，在负载均衡层的就已经根据服务器的优劣对流量进行分配，例如一台分配70%流量，另一台分配30%的流量。面对这种情况，控制台也可以对其实行加权分配<code>QPS</code>的策略。</p>
<p><strong>缺点：</strong></p>
<p>这也算一种集群限流的实现方案，但依旧存在不小的问题。该模式的分配比例是建立在大数据流量下的趋势进行分配，实际情况中可能并不是严格的五五分或三七分，误差不可控，极容易出现用户连续访问某一台服务器遇到请求驳回而另一台服务器此刻空闲流量充足的尴尬情况。</p>
<p><strong>3，发票服务器</strong></p>
<p>这种方案的思想是建立在<code>Redis</code>令牌桶方案的基础之上的。如何解决每次取令牌都伴随一次网络开销，该方案的解决方法是建立一层控制端，利用该控制端与<code>Redis</code>令牌桶进行交互，只有当客户端的剩余令牌数不足时，客户端才向该控制层取令牌并且每次取一批。</p>
<p><strong>缺点：</strong><br>这种思想类似于Java集合框架的数组扩容，设置一个阈值，只有当超过该临界值时，才会触发异步调用。其余存取令牌的操作与本地限流无二。虽然该方案依旧存在误差，但误差最大也就一批次令牌数而已。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1，<a href="https://www.cnblogs.com/rjzheng/p/10340176.html">https://www.cnblogs.com/rjzhe…</a><br>2，<a href="https://www.martinfowler.com/bliki/CircuitBreaker.html">https://www.martinfowler.com/…</a><br>3，<a href="https://www.cnblogs.com/babycomeon/p/11216538.html">https://www.cnblogs.com/babyc…</a><br>4，<a href="https://github.com/alibaba/Sentinel/wiki/Sentinel-%E4%B8%8E-Hystrix-%E7%9A%84%E5%AF%B9%E6%AF%94">https://github.com/alibaba/Se…</a><br>5，<a href="https://www.jishuwen.com/d/2TX1">https://www.jishuwen.com/d/2TX1</a><br>6，<a href="https://juejin.im/post/5c74a2e2f265da2dea053355">https://juejin.im/post/5c74a2…</a><br>7，<a href="https://www.jianshu.com/p/2596e559db5c">https://www.jianshu.com/p/259…</a><br>8，<a href="https://zhuanlan.zhihu.com/p/48965194">https://zhuanlan.zhihu.com/p/…</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>熔断</tag>
        <tag>限流</tag>
        <tag>异步</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库设计</title>
    <url>/database/concept/</url>
    <content><![CDATA[<h1 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h1><p>SQL(Structured Query Language, 结构化查询语言)可以分为DDL(data definition language,数据定义语言) TPL(事务处理语言)  DML(data manipulation language, 数据操作语言)和DCL(data control language, 数据控制语言)。</p>
<p>其主要的语句有:</p>
<ol>
<li>DDL(data definition language,数据定义语言) 创建、删除和更改数据库对象<ol>
<li>创建 删除 修改数据库<ol>
<li> creat database</li>
<li> drop database</li>
<li> alter database</li>
</ol>
</li>
<li>创建 删除 修改数据表<ol>
<li> create table</li>
<li> alter table</li>
<li> drop table</li>
</ol>
</li>
<li>创建 删除索引<ol>
<li> create index</li>
<li> drop index</li>
</ol>
</li>
</ol>
</li>
<li>DML(data manipulation language, 数据操作语言) 查询和更新指令都成了SQL的DML部分<ol>
<li>select 从表或试图中检索数据</li>
<li>update 更改表中的数据</li>
<li>delete 从表中删除数据行</li>
<li>insert into  添加数据行到表</li>
</ol>
</li>
<li>DCL(data control language, 数据控制语言)<ol>
<li>用于规定数据库用户的各种权限<ol>
<li>grant 将权限或角色授予用户或其他角色</li>
<li>revoke 从用户或数据库角色回收权限</li>
</ol>
</li>
<li>数据库事务控制<ol>
<li>commit 把当前事务所有的更改写入磁盘</li>
<li>rollback 作废上次提交依赖的所有的更改</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1 id="数据库设计"><a href="#数据库设计" class="headerlink" title="数据库设计"></a>数据库设计</h1><p>数据库设计可以分为需求分析、逻辑分析、物理设计和维护优化四个阶段。</p>
<p>数据库的基本名词：</p>
<ul>
<li>关系：一个关系对应通常所说的一张表</li>
<li>元组：表中的一行即为一个元组</li>
<li>属性：表中的一列即为一个属性；每一个属性都有一个名称，称为属性名。</li>
<li>候选码：表中的某个属性组，它可以唯一确定一个元组。</li>
<li>主码：一个关系有多个候选码，确定其中一个为主码</li>
<li>域：属性的取值范围</li>
<li>分量：元组中的一个属性值。</li>
</ul>
<h2 id="ER图"><a href="#ER图" class="headerlink" title="ER图"></a>ER图</h2><p>ER图中各符号的含义：</p>
<p><img src="/images/j2ee/database/ER-Components.png"></p>
<p>在这里以订单、用户、商品、供应商以及购物车的关系构建ER图</p>
<p><img src="/images/j2ee/database/ER-sample01.png"></p>
<p>矩形框表示实体, 即图中的订单、用户、商品、供应商以及购物车。<br>椭圆表示视图的属性， 如用户的用户ID、用户名、密码、昵称和身份证。椭圆中的文本表示属性的名称，文本带下划线表示为主键。<br>线段将属性与实体集相互连接，表示属性是实体的。将实体间相互连接，表示实体间的对应关系。<br>线段的两端标示1或M，表示是一对一、一对多或者多对多的关系。</p>
<h2 id="数据操作异常与数据冗余"><a href="#数据操作异常与数据冗余" class="headerlink" title="数据操作异常与数据冗余"></a>数据操作异常与数据冗余</h2><p>数据操作异常是判断数据库设计是否合理的依据。</p>
<ul>
<li>插入异常： 如果某实体随着另一个实体的存在而存在， 即缺少某个实体时无法表示这个实体，那么这个表就存在插入异常。</li>
<li>更新异常： 如果更改表所对应的某个实体实例的单独属性时，需要将多行更新，那么就说这个表存在更新异常。</li>
<li>删除异常： 如果删除表的某一行来反应某实体实例。失效时导致另一个不同实体实例信息丢失，那么这个表存在删除异常。</li>
</ul>
<p>数据冗余：<br>是指相同的数据在多个地方存在， 或者说表中的某个列可以有其他列计算得到，这样就说表中存在着数据冗余。</p>
<h2 id="三范式"><a href="#三范式" class="headerlink" title="三范式"></a>三范式</h2><h3 id="第一范式-1NF"><a href="#第一范式-1NF" class="headerlink" title="第一范式(1NF)"></a>第一范式(1NF)</h3><p>字段具有原子性,不可再分。所有关系型数据库系统都满足第一范式。<br>数据库表中的字段都是单一属性的，不可再分。例如，姓名字段，其中的姓和名必须作为一个整体，无法区分哪部分是姓，哪部分是名，如果要区分出姓和名，必须设计成两个独立的字段。</p>
<p>这个单一属性是由基本的数据类型所构成的， 如整数，浮点数，字符串等；<br>换句话说： <strong>第一范式要求数据库中的表都是二维表</strong></p>
<p>如下表中</p>
<p><img src="/images/j2ee/database/1NF-sample01.png"></p>
<p>第二个表格中， 用户信息列又包含<code>姓名</code> <code>电话</code>两个列。 不符合第一范式的要求</p>
<h3 id="第二范式-2NF"><a href="#第二范式-2NF" class="headerlink" title="第二范式(2NF)"></a>第二范式(2NF)</h3><p>满足第二范式（2NF）必须先满足第一范式（1NF）。<br>要求数据库表中的每个实例或行必须可以被惟一地区分。通常需要为表加上一个列，以存储各个实例的惟一标识。这个惟一属性列被称为主关键字或主键。<br>第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。简而言之，第二范式就是非主属性非部分依赖于主关键字。</p>
<p><img src="/images/j2ee/database/2NF-sample01.png"></p>
<p>由于供应商和商品之间是多对多的关系<br>所以只有使用<code>商品名称</code>和<code>供应商名称</code>才可以唯一表示出一件商品。<br>也就是商品名称和供应商名称是一组组合关键字。<br>上表的依赖关系为:</p>
<ul>
<li>(商品名称)-&gt;(价格、描述、重量、商品有效期)</li>
<li>(供应商名称)-&gt;(供应商电话)</li>
</ul>
<p>存在的问题：</p>
<ol>
<li>插入异常</li>
<li>删除异常</li>
<li>更新异常</li>
<li>数据冗余</li>
</ol>
<h3 id="第三范式"><a href="#第三范式" class="headerlink" title="第三范式"></a>第三范式</h3><p>必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。<br>所以第三范式具有如下特征：<br>    1. 每一列只有一个值<br>    2. 每一行都能区分。<br>    3. 每一个表都不包含其他表已经包含的非主关键字信息。</p>
<p>例如，帖子表中只能出现发帖人的id，而不能出现发帖人的id，还同时出现发帖人姓名，否则，只要出现同一发帖人id的所有记录，它们中的姓名部分都必须严格保持一致，这就是数据冗余。</p>
<p>如果数据表中不存在非关键字段对任一候选字段的传递函数依赖则符合第三范式。</p>
<h3 id="BC范式-Boyce-Codd范式"><a href="#BC范式-Boyce-Codd范式" class="headerlink" title="BC范式(Boyce.Codd范式)"></a>BC范式(Boyce.Codd范式)</h3><p>在第三范式的基础上，数据库表中如果不存在任何字段对任一候选关键字段的传递函数依赖则符合BC范式。<br>也就是说如果是符合关键字，则符合关键字之间也不能存在函数依赖关系。</p>
<p><img src="/images/j2ee/database/BCNF-sample01.png"></p>
<p>上表中存在的下列关系不符合BCNF:</p>
<ul>
<li>(供应商)-&gt;(供应商联系人)</li>
<li>(供应商联系人)-&gt;(供应商)</li>
<li>并且存在数据存在异常及数据冗余</li>
</ul>
<h2 id="数据库锁"><a href="#数据库锁" class="headerlink" title="数据库锁"></a>数据库锁</h2><p>锁的类型有三种：</p>
<ul>
<li>共享（S)锁：多个事务可封锁一个共享页；任何事务都不能修改该页； 通常是该页被读取完毕，S锁立即被释放。 </li>
<li>排它（X)锁：仅允许一个事务封锁此页；其他任何事务必须等到X锁被释放才能对该页进行访问；X锁一直到事务结束才能被释放。 </li>
<li>更新（U)锁：用来预定要对此页施加X锁，它允许其他事务读，但不允许再施加U锁或X锁；当被读取的页将要被更新时，则升级为X锁；U锁一直到事务结束时才能被释放。</li>
</ul>
<p><a href="http://www.cnblogs.com/zhouqianhua/archive/2011/04/15/2017049.html">SQLServer中的数据库锁</a></p>
<p><a href="http://www.cnblogs.com/ggjucheng/archive/2012/11/14/2770445.html">MySQL中的数据库锁</a></p>
<p><a href="http://tec.5lulu.com/detail/104d2n2wtryip85cd.html">数据库锁原理</a></p>
<h2 id="TODOs"><a href="#TODOs" class="headerlink" title="TODOs"></a>TODOs</h2><ol>
<li>事务 各个层次的操作</li>
<li>键 唯一键 主键 外键</li>
<li>MySQL集群</li>
<li>事务隔离级别</li>
</ol>
<hr>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库锁的基本原理</title>
    <url>/database/sql-lock/</url>
    <content><![CDATA[<h1 id="数据库锁的基本原理"><a href="#数据库锁的基本原理" class="headerlink" title="数据库锁的基本原理"></a>数据库锁的基本原理</h1><h2 id="为什么要锁"><a href="#为什么要锁" class="headerlink" title="为什么要锁"></a>为什么要锁</h2><p>数据库通常有大量的用户在同时操作，所以并发的情况下需要控制对临界资源的操作，数据库通过锁来控制对临界资源的访问，从而保证数据的一致性。例如对于同一个账户，操作之前账户余额为1000，同时开始2个事务，一个事务取款100，一个事务往账户中汇入100，那么2个事务结束后，账户的余额必须还是1000，否则要么银行不干，要么个人不干。 </p>
<h2 id="锁类型"><a href="#锁类型" class="headerlink" title="锁类型"></a>锁类型</h2><h3 id="共享锁-读锁"><a href="#共享锁-读锁" class="headerlink" title="共享锁(读锁)"></a>共享锁(读锁)</h3><p>读锁是共享的，互相不阻塞，也就是可以多个客户同时读取同一资源，而不互相干扰。</p>
<p>加锁条件：当执行select时，数据库为这个事务分配一把共享锁，来锁定被查询的数据。 </p>
<p>解锁条件：默认情况下，数据被读取之后，数据库立即解锁。例如select * from table中，先锁定第一行，读取后，立即解锁第一行，然后再锁定第二行，这样大大降低锁争用程度。在repeatable read和serializable 这两种事务隔离级别下，共享锁是在事务结束时释放的，serializable对表加锁。 </p>
<h3 id="排它锁-独占锁-写锁"><a href="#排它锁-独占锁-写锁" class="headerlink" title="排它锁(独占锁)(写锁)"></a>排它锁(独占锁)(写锁)</h3><p>写锁是排他的，一个写锁会阻塞其他的读锁和写锁，只有这样才能保证同一时刻，只有一个用户能够写入，并阻止其他用户读取正在写入的同一资源。如果要锁定的数据资源，已经放置了其他的锁，则不能再放置排它锁。<br>加锁条件：当执行insert update 和delete语句时，数据库会对操纵的资源使用排它锁。<br>解锁条件：事务结束时解锁。 </p>
<h2 id="锁原理"><a href="#锁原理" class="headerlink" title="锁原理"></a>锁原理</h2><p>锁的基本原理如下：</p>
<p>1.当第一个事务访问数据库资源时，如果执行select语句，则必须先获得共享锁，如果执行insert update和delete时，必须获得排它锁<br>2.当第二个事务也要访问相同的资源时，如果执行select语句，也必须先获得共享锁，如果执行insert update或者delete，也必须获得共享锁。根据已经放置在资源上的锁类型，来决定第二个事务是应该等待第一个事务释放锁，还是立即获得锁。 </p>
<table>
<thead>
<tr>
<th>资源上的锁</th>
<th>第二个事务进行读</th>
<th>第二个事务进行写</th>
</tr>
</thead>
<tbody><tr>
<td>无</td>
<td>立即获得共享锁</td>
<td>立即获得排他锁</td>
</tr>
<tr>
<td>共享锁</td>
<td>立即获得共享锁</td>
<td>等待第一个事务释放锁</td>
</tr>
<tr>
<td>排他锁</td>
<td>等待第一个事务释放锁</td>
<td>等待第一个事务释放锁</td>
</tr>
</tbody></table>
<h2 id="锁粒度"><a href="#锁粒度" class="headerlink" title="锁粒度"></a>锁粒度</h2><p>常见的锁有表锁、 行锁、 页锁、外键锁等。 </p>
<p>锁有一定的消耗，主要有：获得锁，检查锁是否已经解除，释放锁等，这些操作都会增加系统的开销。<br>表锁开销比较小，但是并发性能也较差，行锁并发性能高，但是需要更多锁，数据库系统一般都支持锁的自动升级，例如一个事务中的锁过多的时候，可能会将行锁升级到表锁。</p>
<p>mysql的各个存储引擎根据不同的应用场景采用不同的锁机制，MyISAM存储引擎采用表锁，InnoDB使用行锁。如果执行alert table之类的操作，服务器也会采用表锁，而忽略存储引擎的锁机制。<br>页锁，某些数据库支持页锁，页锁粒度介于行锁和表锁之间，用于锁定存放数据的页，1页通常含有n个数据行。 </p>
<p>外键锁：外键会产生高级别的锁，后面介绍死锁的时候会提到。 </p>
<h2 id="乐观锁和悲观锁"><a href="#乐观锁和悲观锁" class="headerlink" title="乐观锁和悲观锁"></a>乐观锁和悲观锁</h2><p>悲观锁：假设如果不加锁就一定会出现问题。<br>乐观锁：先假定不会出现并发问题，出现问题后再采取相应的措施。<br>悲观锁通过<code>select * from tbl for update</code>实现。<br>乐观锁可以在表中加一个version字段，每次更新的时候都+1，这样如果出现并发，第二次更新的时候version的值已经不再匹配，可以在这时采取相应的措施。</p>
<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><h3 id="死锁是如何产生的"><a href="#死锁是如何产生的" class="headerlink" title="死锁是如何产生的"></a>死锁是如何产生的</h3><p>同java的死锁一样，都是互相等待对方释放锁，造成了相互阻塞，造成的死锁。<br>请看下面的表格： </p>
<p><img src="/images/database/lock/concept-02.gif"></p>
<h3 id="如何避免死锁"><a href="#如何避免死锁" class="headerlink" title="如何避免死锁"></a>如何避免死锁</h3><p>1.修改操作表的顺序<br>从上面的示例中可以看出，如果调整一下操作表的顺序就可以避免死锁。<br>2.外键<br>如果向子表写记录，那么外键约束会检查父表的记录，并锁住父表的记录，来保证这条记录不会在这个事务完成之时就被删除了。<br>产生高级别的锁，会阻止其他事务操作或者其他DML操作，如果是因为外键产生的死锁，可以去掉外键约束，由应用来保证数据的完整性，通常生产环境都不建议加外键约束。<br>3.短事务<br>缩短事务的执行时间，可以减少锁的持有时间，可以降低死锁的风险。 </p>
<h2 id="锁可能出现的问题"><a href="#锁可能出现的问题" class="headerlink" title="锁可能出现的问题"></a>锁可能出现的问题</h2><p>上锁是有开销的，即使不是给数据行而是给数据页上锁，也是有一定的时间的，如果第一个事务update一张大表，这时候第二个事务update这张大表比较靠后的位置的数据，这时候就可能会出现，第一个事务还没来得及给相应的数据上锁，第二个事务已经上了锁，所以出现第一个事务要等待第二个事务提交后释放锁，才能继续执行的情况。 </p>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title>消息推送</title>
    <url>/network/push/</url>
    <content><![CDATA[<h1 id="推送服务"><a href="#推送服务" class="headerlink" title="推送服务"></a>推送服务</h1><p>维护任何一个长连接都需要心跳机制，客户端发送一个心跳给服务器，服务器给客户端一个心跳应答，这样就形成客户端服务器的一次完整的握手，这个握手是让双方都知道他们之间的连接是没有断开，客户端是在线的。如果超过一个时间的阈值，客户端没有收到服务器的应答，或者服务器没有收到客户端的心跳，那么对客户端来说则断开与服务器的连接重新建立一个连接，对服务器来说只要断开这个连接即可。那么在智能手机上的长连接心跳和在Internet上的长连接心跳有什么不同的目的呢？原因就在于智能手机使用的是移动无线网络，那么我们在讲长连接之前我们首先要了解无线移动网络的特点。<br>由于大部分的移动无线网络运营商为了减少网关NAT映射表的负荷，如果一个链路有一段时间没有通信时就会删除其对应表，造成链路中断，正是这种刻意缩短空闲连接的释放超时，原本是想节省信道资源的作用，没想到让互联网的应用不得以远高于正常频率发送心跳来维护推送的长连接。这也是为什么会有之前的信令风暴，微信摇收费的传言，因为这类的应用发送心跳的频率是很短的，既造成了信道资源的浪费，也造成了手机电量的快速消耗。</p>
<p>推送的实现方式：</p>
<ol>
<li>客户端不断的查询服务器，检索新内容，也就是所谓的pull 或者轮询方式</li>
<li>客户端和服务器之间维持一个TCP/IP长连接，服务器向客户端push</li>
<li>服务器又新内容时，发送一条类似短信的信令给客户端，客户端收到后从服务器中下载新内容，也就是SMS的推送方式。</li>
</ol>
<p>苹果的推送系统和googleC2DM推送系统其实都是在系统级别维护一个TCP/IP长连接，都是基于第二种的方式进行推送的。第三种方式由于运营商没有免费开放这种信令导致了这种推送在成本上是无法接受的，虽然这种推送的方式非常的稳定，高效和及时。</p>
<h1 id="IOS推送"><a href="#IOS推送" class="headerlink" title="IOS推送"></a>IOS推送</h1><p>首先第一步当然是介绍一下苹果的推送机制(APNS)咯（ps:其实每一篇教程都有），先来看一张苹果官方对其推送做出解释的概要图。<br><img src="/images/network/push/APNS-process.png"></p>
<p>Provider是给你手机应用发出推送消息的服务器，而APNS（Apple Push Notification Service）则是苹果消息推送服务器。<br>你本地的服务器当需要给应用推送一条消息的时候，先要将消息发出到苹果推送服务器，然后再由苹果推送服务器将消息发到安装了该应用的手机。</p>
<p>接下来再看一张解释图：<br><img src="/images/network/push/APNS-process-detail.png"></p>
<p>根据上图的逻辑我来给大家解释一下：</p>
<ol>
<li>你的IOS应用需要去注册APNS消息推送功能。</li>
<li>当苹果APNS推送服收到来自你应用的注册消息就会返回一串device token给你（很重要）</li>
<li>将应用收到的device Token传给你本地的Push服务器。</li>
<li>当你需要为应用推送消息的时候，你本地的推送服务器会将消息，以及Device Token打包发送到苹果的APNS服</li>
<li>APNS再将消息推送给目的iphone</li>
</ol>
<p>   IOS长连接是由系统来维护的，也就是说苹果的IOS系统在系统级别维护了一个客户端和苹果服务器的长链接，IOS上的所有应用上的推送都是先将消息推送到苹果的服务器然后将苹果服务器通过这个系统级别的长链接推送到手机终端上，这样的的几个好处为：1.在手机终端始终只要维护一个长连接即可，而且由于这个长链接是系统级别的不会出现被杀死而无法推送的情况。2.省电，不会出现每个应用都各自维护一个自己的长连接。3.安全，只有在苹果注册的开发者才能够进行推送，等等。</p>
<h1 id="Android推送"><a href="#Android推送" class="headerlink" title="Android推送"></a>Android推送</h1><p>android的长连接是由每个应用各自维护的，但是google也推出了和苹果技术架构相似的推送框架，C2DM,云端推送功能，但是由于google<br>的服务器不在中国境内，其他的原因你懂的。所以导致这个推送无法使用，android的开发者不得不自己去维护一个长链接，于是每个应用如果都24小时在<br>线，那么都得各自维护一个长连接，这种电量和流量的消耗是可想而知的。虽然国内也出现了各种推送平台，但是都无法达到只维护一个长连接这种消耗的级别。</p>
<hr>
]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>push</tag>
        <tag>IOS</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络基础知识</title>
    <url>/network/base/</url>
    <content><![CDATA[<h1 id="OSI七层模型-amp-常见五层模型"><a href="#OSI七层模型-amp-常见五层模型" class="headerlink" title="OSI七层模型 &amp; 常见五层模型"></a>OSI七层模型 &amp; 常见五层模型</h1><p>OSI（Open System Interconnection, 开放系统互连）七层网络模型称为开放式系统互联参考模型 , 是一个逻辑上的定义, 一个规范, 它把网络从逻辑上分为了7层. 每一层都有相关、相对应的物理设备, 比如路由器(网络层), 交换机(数据链路层). OSI 七层模型是一种框架性的设计方法 , 建立七层模型的主要目的是为解决异种网络互连时所遇到的兼容性问题, 其最主要的功能就是帮助不同类型的主机实现数据传输. 它的最大优点是将服务、接口和协议这三个概念明确地区分开来, 通过七个层次化的结构模型使不同的系统不同的网络之间实现可靠的通讯. </p>
<p><img src="/images/network/7.jpg"></p>
<table>
<thead>
<tr>
<th>应用层</th>
</tr>
</thead>
<tbody><tr>
<td>表示层</td>
</tr>
<tr>
<td>会话层</td>
</tr>
<tr>
<td>传输层：TCP/UDP</td>
</tr>
<tr>
<td>网络层: IP/ICMP</td>
</tr>
<tr>
<td>数据链路层: ARP/HDLC/PPP/SLIP</td>
</tr>
<tr>
<td>物理层</td>
</tr>
</tbody></table>
<p>图1 OSI七层模型</p>
<p>目前较为常用的5层模型, 模型分层如图2.</p>
<p><img src="/images/network/5.png"></p>
<table>
<thead>
<tr>
<th>应用层</th>
</tr>
</thead>
<tbody><tr>
<td>传输层</td>
</tr>
<tr>
<td>网络层</td>
</tr>
<tr>
<td>数据链路层</td>
</tr>
<tr>
<td>物理层</td>
</tr>
</tbody></table>
<h1 id="分层的好处"><a href="#分层的好处" class="headerlink" title="分层的好处"></a>分层的好处</h1><p>建立七层模型的主要目的是为解决异种网络互连时所遇到的兼容性问题. 它的最大优点是将服务、接口和协议这三个概念明确地区分开来：服务说明某一层为上一层提供一些什么功能, 接口说明上一层如何使用下层的服务, 而协议涉及如何实现本层的服务；这样各层之间具有很强的独立性, 互连网络中各实体采用什么样的协议是没有限制的, 只要向上提供相同的服务并且不改变相邻层的接口就可以了. 网络七层的划分也是为了使网络的不同功能模块（不同层次）分担起不同的职责, 从而带来如下好处：</p>
<ul>
<li>减轻问题的复杂程度, 一旦网络发生故障, 可迅速定位故障所处层次, 便于查找和纠错；</li>
<li>在各层分别定义标准接口, 使具备相同对等层的不同网络设备能实现互操作, 各层之间则相对独立, 一种高层协议可放在多种低层协议上运行；</li>
<li>能有效刺激网络技术革新, 因为每次更新都可以在小范围内进行, 不需对整个网络动大手术</li>
</ul>
<h1 id="各层功能说明"><a href="#各层功能说明" class="headerlink" title="各层功能说明"></a>各层功能说明</h1><ol>
<li><p>物理层</p>
<p>OSI 模型的最低层或第一层, 该层包括物理连网媒介, 如电缆连线连接器. 物理层的协议产生并检测电压以便发送和接收携带数据的信号. 在你的桌面PC 上插入网络接口卡, 你就建立了计算机连网的基础. 换言之, 你提供了一个物理层. 尽管物理层不提供纠错服务, 但它能够设定数据传输速率并监测数据出错率. 网络物理问题, 如电线断开, 将影响物理层. </p>
<p>用户要传递信息就要利用一些物理媒体, 如双绞线、同轴电缆等, 但具体的物理媒体并不在OSI的7层之内, 有人把物理媒体当做第0层, 物理层的任务就是为它的上一层提供一个物理连接, 以及它们的机械、电气、功能和过程特性. 如规定使用电缆和接头的类型、传送信号的电压等. 在这一层, 数据还没有被组织, 仅作为原始的位流或电气电压处理, 单位是bit比特. </p>
</li>
<li><p>数据链路层</p>
<p>OSI模型的第二层, 它控制网络层与物理层之间的通信. 它的主要功能是如何在不可靠的物理线路上进行数据的可靠传递. 为了保证传输, 从网络层接收到的数据被分割成特定的可被物理层传输的帧. 帧是用来移动数据的结构包, 它不仅包括原始数据, 还包括发送方和接收方的物理地址以及检错和控制信息. 其中的地址确定了帧将发送到何处, 而纠错和控制信息则确保帧无差错到达.  如果在传送数据时, 接收点检测到所传数据中有差错, 就要通知发送方重发这一帧. </p>
<p>数据链路层的功能独立于网络和它的节点和所采用的物理层类型, 它也不关心是否正在运行 Word 、Excel 或使用Internet. 有一些连接设备, 如交换机, 由于它们要对帧解码并使用帧信息将数据发送到正确的接收方, 所以它们是工作在数据链路层的. </p>
<p>在物理层提供比特流服务的基础上, 建立相邻结点之间的数据链路, 通过差错控制提供数据帧（Frame）在信道上无差错的传输, 并进行各电路上的动作系列. </p>
<p>数据链路层在不可靠的物理介质上提供可靠的传输. 该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等. </p>
<p>数据链路层协议的代表包括：SDLC、HDLC、PPP、STP、帧中继等. </p>
</li>
<li><p>网络层</p>
<p>OSI 模型的第三层, 其主要功能是决定如何将数据从发送方路由到接收方. </p>
<p>网络层通过综合考虑发送优先权、网络拥塞程度、服务质量以及可选路由的花费来决定从一个网络中节点A 到另一个网络中节点B 的最佳路径. 由于网络层处理, 并智能指导数据传送, 路由器连接网络各段, 所以路由器属于网络层. 在网络中, “路由”是基于编址方案、使用模式以及可达性来指引数据的发送. </p>
<p>网络层负责在源机器和目标机器之间建立它们所使用的路由. 这一层本身没有任何错误检测和修正机制, 因此, 网络层必须依赖于端端之间的由DLL提供的可靠传输服务. </p>
<p>网络层用于本地LAN网段之上的计算机系统建立通信, 它之所以可以这样做, 是因为它有自己的路由地址结构, 这种结构与第二层机器地址是分开的、独立的. 这种协议称为路由或可路由协议. 路由协议包括IP、Novell公司的IPX以及Apple Talk协议. </p>
<p>网络层是可选的, 它只用于当两个计算机系统处于不同的由路由器分割开的网段这种情况, 或者当通信应用要求某种网络层或传输层提供的服务、特性或者能力时. 例如, 当两台主机处于同一个LAN网段的直接相连这种情况, 它们之间的通信只使用LAN的通信机制就可以了(即OSI 参考模型的一二层). </p>
</li>
<li><p>传输层</p>
<p>传输协议同时进行流量控制或是基于接收方可接收数据的快慢程度规定适当的发送速率. 除此之外, 传输层按照网络能处理的最大尺寸将较长的数据包进行强制分割. 例如, 以太网无法接收大于1500字节的数据包. 发送方节点的传输层将数据分割成较小的数据片, 同时对每一数据片安排一序列号, 以便数据到达接收方节点的传输层时, 能以正确的顺序重组. 该过程即被称为排序. </p>
<p>工作在传输层的一种服务是 TCP/IP 协议套中的TCP （Transport Control Protocol, 传输控制协议）, UPD (User Packet Data, 用户数据报协议), 另一项传输层服务是IPX/SPX协议集的SPX（序列包交换）. </p>
</li>
</ol>
<h1 id="三次握手与四次挥手"><a href="#三次握手与四次挥手" class="headerlink" title="三次握手与四次挥手"></a>三次握手与四次挥手</h1><p><img src="/images/network/34.png"></p>
<h2 id="三次握手过程："><a href="#三次握手过程：" class="headerlink" title="三次握手过程："></a>三次握手过程：</h2><ul>
<li>第一次握手：host1发送一个TCP标志位SYN=1、ACK=0的数据包给host2, 并随机会产生一个Sequence number=3233.当host2接收到这个数据后, host2由SYN=1可知客户端是想要建立连接；</li>
<li>第二次握手：host2要对客户端的联机请求进行确认, 向host1发送应答号ACK=1、SYN=1、<br>确认号Acknowledge number=3234, 此值是host1的序列号加1, 还会产生一个随机的序列号Sequence number=36457, 这样就告诉host1可以进行连接；</li>
<li>第三次握手：host1收到数据后检查Acknowledge number是否是3233+1的值, 以及ACK的值是否为1, 若为1, host1会发送ACK=1、确认号码Acknowledge number=36457, 告诉host2,你的请求连接被确认, 连接可以建立. </li>
</ul>
<h2 id="四次挥手过程："><a href="#四次挥手过程：" class="headerlink" title="四次挥手过程："></a>四次挥手过程：</h2><ul>
<li>第一次挥手：当传输的数据到达尾部时, host1向host2发送FIN=1标志位；可理解成, host1向host2说, 我这边的数据传送完成了, 我准备断开了连接；</li>
<li>第二次挥手：因TCP的连接是全双工的双向连接, 关闭也是要从两边关闭；当host2收到host1发来的FIN=1的标志位后, host2不会立刻向host1发送FIND=1的请求关闭信息, 而是先向host1发送一个ACK=1的应答信息, 表示：你请求关闭的请求我已经收到, 但我可能还有数据没有完成传送, 你再等下, 等我数据传输完成了我就告诉你；</li>
<li>第三次挥手：host2数据传输完成, 向host1发送FIN=1, host1收到请求关闭连接的请求后, host1就明白host2的数据已传输完成, 现在可以断开连接了, </li>
<li>第四次挥手：host1收到FIND=1后, host1还是怕由于网络不稳定的原因, 怕host2不知道他要断开连接, 于是向host2发送ACK=1确认信息进行确认, 把自己设置成TIME_WAIT状态并启动定时器, 如果host2没有收到ACK, host2端TCP的定时器到达后, 会要求host1重新发送ACK, 当host2收到ACK后, host2就断开连接；当host1等待2MLS（2倍报文最大生存时间）后, 没有收到host2的重传请求后, 他就知道host2已收到了ACK, 所以host1此时才关闭自己的连接. </li>
</ul>
<h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><h2 id="HTTPS的工作原理"><a href="#HTTPS的工作原理" class="headerlink" title="HTTPS的工作原理"></a>HTTPS的工作原理</h2><p>HTTPS在传输数据之前需要客户端(浏览器)与服务端(网站)之间进行一次握手,  在握手过程中将确立双方加密传输数据的密码信息. TLS/SSL协议不仅仅是一套加密传输的协议, 更是一件经过艺术家精心设计的艺术品, TLS/SSL中使用了非对称加密, 对称加密以及HASH算法. 握手过程的具体描述如下：</p>
<ol>
<li>浏览器将自己支持的一套加密规则发送给网站.</li>
<li>网站从中选出一组加密算法与HASH算法, 并将自己的身份信息以证书的形式发回给浏览器. 证书里面包含了网站地址, 加密公钥, 以及证书的颁发机构等信息.</li>
<li>浏览器获得网站证书之后浏览器要做以下工作：</li>
</ol>
<ul>
<li> 验证证书的合法性(颁发证书的机构是否合法, 证书中包含的网站地址是否与正在访问的地址一致等), 如果证书受信任, 则浏览器栏里面会显示一个小锁头, 否则会给出证书不受信的提示.</li>
<li> 如果证书受信任, 或者是用户接受了不受信的证书, 浏览器会生成一串随机数的密码, 并用证书中提供的公钥加密.</li>
<li> 使用约定好的HASH算法计算握手消息, 并使用生成的随机数对消息进行加密, 最后将之前生成的所有信息发送给网站.</li>
</ul>
<ol start="4">
<li>网站接收浏览器发来的数据之后要做以下的操作：</li>
</ol>
<ul>
<li>使用自己的私钥将信息解密取出密码, 使用密码解密浏览器发来的握手消息, 并验证HASH是否与浏览器发来的一致.</li>
<li>使用密码加密一段握手消息, 发送给浏览器.</li>
</ul>
<ol start="5">
<li>浏览器解密并计算握手消息的HASH, 如果与服务端发来的HASH一致, 此时握手过程结束, 之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密.  这里浏览器与网站互相发送加密的握手消息并验证, 目的是为了保证双方都获得了一致的密码, 并且可以正常的加密解密数据, 为后续真正数据的传输做一次测试. 另外, HTTPS一般使用的加密与HASH算法如下：</li>
</ol>
<ul>
<li><p>非对称加密算法：RSA, DSA/DSS</p>
</li>
<li><p>对称加密算法：AES, RC4, 3DES</p>
</li>
<li><p>HASH算法：MD5, SHA1, SHA256 HTTPS对应的通信时序图如下：</p>
<p><img src="/images/network/https-process.png"></p>
</li>
</ul>
<hr>
<p>【参考文献】:</p>
<ol>
<li><a href="http://www.admin5.com/article/20150525/600230.shtml">HTTPS工作原理和TCP握手机制</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>图片上传与接收</title>
    <url>/network/uploadAndReceiveImages/</url>
    <content><![CDATA[<h1 id="服务端接收图片"><a href="#服务端接收图片" class="headerlink" title="服务端接收图片"></a>服务端接收图片</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">boolean</span> excu;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    MultipartHttpServletRequest multipartRequest = (MultipartHttpServletRequest)request;</span><br><span class="line">    MultipartFile multipartFile = multipartRequest.getFile(CommonConstant.FORM_NAME);</span><br><span class="line">    LogUtil.trace(<span class="string">&quot;--&gt;上传图片=multipartFile:&quot;</span> + multipartFile);</span><br><span class="line"></span><br><span class="line">    String originalName = multipartFile.getOriginalFilename();</span><br><span class="line">    LogUtil.trace(<span class="string">&quot;--&gt;上传图片=originaName:&quot;</span> + originalName+<span class="string">&quot; multipartFileSize:&quot;</span> + multipartFile.getSize());</span><br><span class="line"></span><br><span class="line">    InputStream inputStream = multipartFile.getInputStream();</span><br><span class="line">    <span class="keyword">long</span> size = inputStream.available();</span><br><span class="line">    LogUtil.trace(<span class="string">&quot;--&gt;上传图片=file size:&quot;</span> + size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(<span class="number">0</span> == size || size == -<span class="number">1</span> || <span class="keyword">null</span> == userId || <span class="string">&quot;&quot;</span>.equals(userId)) &#123;</span><br><span class="line">        excu = <span class="keyword">false</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        excu = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(excu) &#123;</span><br><span class="line">        originalName = System.currentTimeMillis() + <span class="string">&quot;&quot;</span> + <span class="keyword">new</span> Random().nextInt(<span class="number">100</span>)</span><br><span class="line">                + originalName.substring(originalName.lastIndexOf(<span class="string">&quot;.&quot;</span>));</span><br><span class="line">        <span class="keyword">boolean</span> isUploadSuccess = QiniuUploadUtil.uploadFileToQiniu(“userImgBucketName”, originalName,</span><br><span class="line">                inputStream);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(isUploadSuccess) &#123;</span><br><span class="line">            String imageUrl = “userImgURL” + originalName;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
      <tags>
        <tag>upload</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/01.%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/</url>
    <content><![CDATA[<h1 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h1><h2 id="为什么构建实时数仓"><a href="#为什么构建实时数仓" class="headerlink" title="为什么构建实时数仓"></a>为什么构建实时数仓</h2>]]></content>
  </entry>
  <entry>
    <title>ClickHouse： one of the fastest olap engine</title>
    <url>/bigdata/ClickHouse/</url>
    <content><![CDATA[<h1 id="ClickHouse"><a href="#ClickHouse" class="headerlink" title="ClickHouse"></a>ClickHouse</h1><p><a href="https://clickhouse.yandex/docs/zh/">官方文档</a></p>
<h1 id="Clickhouse"><a href="#Clickhouse" class="headerlink" title="Clickhouse"></a>Clickhouse</h1><p><a href="https://clickhouse.yandex/">offical website</a> <a href="https://github.com/ClickHouse/ClickHouse/">github</a><br><a href="https://github.com/ClickHouse-China/ClickhouseMeetup">meetup backup</a></p>
<h2 id="why-do-we-need-ClickHouse"><a href="#why-do-we-need-ClickHouse" class="headerlink" title="why do we need ClickHouse"></a>why do we need ClickHouse</h2><ul>
<li>交互式查询</li>
<li>持续追加数据</li>
</ul>
<blockquote>
<p>Hypothesis<br>If we have good enough column-oriented DBMS,<br>we could store all our data in non-aggregated form<br>(raw pageviews and sessions) and generate all the reports on the fly,<br>to allow infinite customization.</p>
</blockquote>
<p>愿景：<br>足够好的列式DBMS，可以存储所有非聚合数据(原始的浏览数据和会话)，可以在线生成所有的报告，拥有足够的个性化</p>
<h3 id="yandex数据量"><a href="#yandex数据量" class="headerlink" title="yandex数据量"></a>yandex数据量</h3><ul>
<li><blockquote>
<p>30 trillions of rows (as of 2019)</p>
</blockquote>
</li>
<li><blockquote>
<p>600 servers</p>
</blockquote>
</li>
<li>  total throughput of query processing is up to two terabytes per second</li>
</ul>
<h2 id="feature"><a href="#feature" class="headerlink" title="feature"></a>feature</h2><ul>
<li>  column-oriented 列数存储</li>
<li>  distributed 分布式</li>
<li>  linearly scalable 线性扩展</li>
<li>  fault-tolerant 容错</li>
<li>  data ingestion in realtime 实时数据摄取</li>
<li>  realtime (sub-second) queries 实时亚秒级查询</li>
<li>  support of SQL dialect + extensions 支持SQL方言和扩展</li>
</ul>
<h2 id="why-fast"><a href="#why-fast" class="headerlink" title="why fast"></a>why fast</h2><h3 id="High-level-architecture-架构"><a href="#High-level-architecture-架构" class="headerlink" title="High level architecture 架构"></a>High level architecture 架构</h3><p>— Scale-out shared nothing; 横向伸缩无共享</p>
<p>— Massive Parallel Processing; MPP</p>
<h3 id="Data-storage-optimizations-存储优化"><a href="#Data-storage-optimizations-存储优化" class="headerlink" title="Data storage optimizations 存储优化"></a>Data storage optimizations 存储优化</h3><p>— Column-oriented storage; 列式存储</p>
<p>— Merge Tree;</p>
<p>— Sparse index; 稀疏index</p>
<p>— Data compression; 数据压缩</p>
<h3 id="Algorithmic-optimizations-算法优化"><a href="#Algorithmic-optimizations-算法优化" class="headerlink" title="Algorithmic optimizations 算法优化"></a>Algorithmic optimizations 算法优化</h3><p>Best algorithms in the world…<br>… are happy to be used in ClickHouse.</p>
<p>— Volnitsky substring search</p>
<p>— Hyperscan and RE2</p>
<p>— SIMD JSON</p>
<p>— HDR Histograms</p>
<p>— Roaring Bitmaps</p>
<p>…</p>
<h3 id="Low-level-optimizations-底层优化"><a href="#Low-level-optimizations-底层优化" class="headerlink" title="Low-level optimizations 底层优化"></a>Low-level optimizations 底层优化</h3><p>Optimizations for CPU instruction sets<br>using SIMD processing. 使用SIMD优化CPU指令集</p>
<p>— SIMD text parsing</p>
<p>— SIMD data filtering</p>
<p>— SIMD decompression</p>
<p>— SIMD string operations</p>
<p>…</p>
<h3 id="Specializations-of-algorithms…"><a href="#Specializations-of-algorithms…" class="headerlink" title="Specializations of algorithms…"></a>Specializations of algorithms…</h3><p>… and attention to detail:</p>
<p>— uniq, uniqExact, uniqCombined, uniqUpTo;</p>
<p>— quantile, quantileTiming, quantileExact, quantileTDigest, quantileWeighted;</p>
<p>— 40+ specializations of GROUP BY;</p>
<p>— algorithms optimize itself for data distribution:<br>LZ4 decompression with Bayesian Bandits.</p>
<h3 id="Interfaces"><a href="#Interfaces" class="headerlink" title="Interfaces"></a>Interfaces</h3><p>HTTP REST</p>
<p>clickhouse-client</p>
<p>JDBC, ODBC</p>
<p>(new) MySQL protocol compatibility</p>
<p>Python, PHP, Perl, Go,<br>Node.js, Ruby, C++, .NET, Scala, R, Julia, Rust</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>Druid基础</title>
    <url>/bigdata/Druid/</url>
    <content><![CDATA[<h1 id="Druid"><a href="#Druid" class="headerlink" title="Druid"></a>Druid</h1><h2 id="什么样的业务适合用-Druid"><a href="#什么样的业务适合用-Druid" class="headerlink" title="什么样的业务适合用 Druid?"></a>什么样的业务适合用 Druid?</h2><p>建议如下：</p>
<p>时序化数据：Druid 可以理解为时序数据库，所有的数据必须有时间字段。<br>实时数据接入可容忍丢数据（tranquility）： tranquility 有丢数据的风险，所以建议实时和离线一起用，实时接当天数据，离线第二天把今天的数据全部覆盖，保证数据完备性。<br>OLAP 查询而不是 OLTP 查询：Druid 查询并发有限，不适合 OLTP 查询。<br>非精确的去重计算：目前 Druid 的去重都是非精确的。<br>无 Join 操作：Druid 适合处理星型模型的数据，不支持关联操作。<br>数据没有 update 更新操作，只对 segment 粒度进行覆盖：由于时序化数据的特点，Druid 不支持数据的更新</p>
<h2 id="离线批量入库脚本"><a href="#离线批量入库脚本" class="headerlink" title="离线批量入库脚本"></a>离线批量入库脚本</h2><h3 id="druid-indexing-on-spark"><a href="#druid-indexing-on-spark" class="headerlink" title="druid indexing on spark"></a>druid indexing on spark</h3><p><a href="https://github.com/Fokko/druid-indexing-on-spark.git">https://github.com/Fokko/druid-indexing-on-spark.git</a></p>
<h3 id="pyspark"><a href="#pyspark" class="headerlink" title="pyspark"></a>pyspark</h3><p>Druid是一款高性能的列式存储时序数据库，其支持实时数据分析并在OLAP数据分析领域有其特有的优势。Druid除了支持实时摄入数据外也支持离线批量导入数据，主要通过离线MR任务去HDFS上拉取数据并做聚合roll up处理入库。<br>该脚本可作为通用的druid入库离线任务脚本，方便在配置离线任务流即数据写到HDFS后起对应的入库任务。该脚本可运行在tesla平台作为pyspark任务执行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urlparse</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_task_file</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        contents = f.read()</span><br><span class="line">        <span class="comment"># We don&#x27;t use the parsed data, but we want to throw early if it&#x27;s invalid</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            json.loads(contents)</span><br><span class="line">        <span class="keyword">except</span> Exception, e:</span><br><span class="line">            print(<span class="string">&#x27;Invalid JSON in task file &quot;&#123;0&#125;&quot;: &#123;1&#125;\n&#x27;</span>.<span class="built_in">format</span>(filename, <span class="built_in">repr</span>(e)))</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> contents</span><br><span class="line"></span><br><span class="line"><span class="comment"># Keep trying until timeout_at, maybe die then</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post_task</span>(<span class="params">url, task_json, timeout_at</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        task_url = url.rstrip(<span class="string">&quot;/&quot;</span>) + <span class="string">&quot;/druid/indexer/v1/task&quot;</span></span><br><span class="line">        req = urllib2.Request(task_url, task_json, &#123;<span class="string">&#x27;Content-Type&#x27;</span> : <span class="string">&#x27;application/json&#x27;</span>&#125;)</span><br><span class="line">        timeleft = timeout_at - time.time()</span><br><span class="line">        response_timeout = <span class="built_in">min</span>(<span class="built_in">max</span>(timeleft, <span class="number">5</span>), <span class="number">10</span>)</span><br><span class="line">        response = urllib2.urlopen(req, <span class="literal">None</span>, response_timeout)</span><br><span class="line">        <span class="keyword">return</span> response.read().rstrip()</span><br><span class="line">    <span class="keyword">except</span> urllib2.URLError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(e, urllib2.HTTPError) <span class="keyword">and</span> e.code &gt;= <span class="number">400</span> <span class="keyword">and</span> e.code &lt;= <span class="number">500</span>:</span><br><span class="line">            <span class="comment"># 4xx (problem with the request) or 500 (something wrong on the server)</span></span><br><span class="line">            raise_friendly_error(e)</span><br><span class="line">        <span class="keyword">elif</span> time.time() &gt;= timeout_at:</span><br><span class="line">            <span class="comment"># No futher retries</span></span><br><span class="line">            raise_friendly_error(e)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(e, urllib2.HTTPError) <span class="keyword">and</span> e.code <span class="keyword">in</span> [<span class="number">301</span>, <span class="number">302</span>, <span class="number">303</span>, <span class="number">305</span>, <span class="number">307</span>] <span class="keyword">and</span> \</span><br><span class="line">                        e.info().getheader(<span class="string">&quot;Location&quot;</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Set the new location in args.url so it can be used by await_task_completion and re-issue the request</span></span><br><span class="line">            location = urlparse.urlparse(e.info().getheader(<span class="string">&quot;Location&quot;</span>))</span><br><span class="line">            url = <span class="string">&quot;&#123;0&#125;://&#123;1&#125;&quot;</span>.<span class="built_in">format</span>(location.scheme, location.netloc)</span><br><span class="line">            print(<span class="string">&quot;Redirect response received, setting url to [&#123;0&#125;]\n&quot;</span>.<span class="built_in">format</span>(url))</span><br><span class="line">            <span class="keyword">return</span> post_task(url, task_json, timeout_at)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># If at first you don&#x27;t succeed, try, try again!</span></span><br><span class="line">            sleep_time = <span class="number">30</span></span><br><span class="line">            extra = <span class="string">&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(e, <span class="string">&#x27;read&#x27;</span>):</span><br><span class="line">                extra = e.read().rstrip()</span><br><span class="line">            print(<span class="string">&quot;Waiting up to &#123;0&#125;s for indexing service to become available. [Got: &#123;1&#125; &#123;2&#125;]&quot;</span>.<span class="built_in">format</span>(<span class="built_in">max</span>(sleep_time, <span class="built_in">int</span>(timeout_at - time.time())), <span class="built_in">str</span>(e), extra).rstrip())</span><br><span class="line">            print(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            time.sleep(sleep_time)</span><br><span class="line">            <span class="keyword">return</span> post_task(url, task_json, timeout_at)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Keep trying until timeout_at, maybe die then</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">await_task_completion</span>(<span class="params">url, task_id, timeout_at</span>):</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        task_url = url.rstrip(<span class="string">&quot;/&quot;</span>) + <span class="string">&quot;/druid/indexer/v1/task/&#123;0&#125;/status&quot;</span>.<span class="built_in">format</span>(task_id)</span><br><span class="line">        req = urllib2.Request(task_url)</span><br><span class="line">        timeleft = timeout_at - time.time()</span><br><span class="line">        response_timeout = <span class="built_in">min</span>(<span class="built_in">max</span>(timeleft, <span class="number">5</span>), <span class="number">30</span>)</span><br><span class="line">        response = urllib2.urlopen(req, <span class="literal">None</span>, response_timeout)</span><br><span class="line">        response_obj = json.loads(response.read())</span><br><span class="line">        response_status_code = response_obj[<span class="string">&quot;status&quot;</span>][<span class="string">&quot;status&quot;</span>]</span><br><span class="line">        <span class="keyword">if</span> response_status_code <span class="keyword">in</span> [<span class="string">&#x27;SUCCESS&#x27;</span>, <span class="string">&#x27;FAILED&#x27;</span>]:</span><br><span class="line">            <span class="keyword">return</span> response_status_code</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> time.time() &lt; timeout_at:</span><br><span class="line">                print(<span class="string">&quot;Task &#123;0&#125; still running...&quot;</span>.<span class="built_in">format</span>(task_id))</span><br><span class="line">                timeleft = timeout_at - time.time()</span><br><span class="line">                time.sleep(<span class="built_in">min</span>(<span class="number">30</span>, timeleft))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> Exception(<span class="string">&quot;Task &#123;0&#125; did not finish in time!&quot;</span>.<span class="built_in">format</span>(task_id))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">raise_friendly_error</span>(<span class="params">e</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(e, urllib2.HTTPError):</span><br><span class="line">        text = e.read().strip()</span><br><span class="line">        reresult = re.search(<span class="string">r&#x27;&lt;pre&gt;(.*?)&lt;/pre&gt;&#x27;</span>, text, re.DOTALL)</span><br><span class="line">        <span class="keyword">if</span> reresult:</span><br><span class="line">            text = reresult.group(<span class="number">1</span>).strip()</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">&quot;HTTP Error &#123;0&#125;: &#123;1&#125;, check overlord log for more details.\n&#123;2&#125;&quot;</span>.<span class="built_in">format</span>(e.code, e.reason, text))</span><br><span class="line">    <span class="keyword">raise</span> e</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_task_json</span>(<span class="params">content, hdfspath, data_source, date, segment, query</span>):</span></span><br><span class="line">    input_json = json.loads(content)</span><br><span class="line">    input_json[<span class="string">&quot;spec&quot;</span>][<span class="string">&quot;ioConfig&quot;</span>][<span class="string">&quot;inputSpec&quot;</span>][<span class="string">&quot;paths&quot;</span>] = hdfspath + <span class="string">&quot;/&quot;</span> + date</span><br><span class="line">    input_json[<span class="string">&quot;spec&quot;</span>][<span class="string">&quot;dataSchema&quot;</span>][<span class="string">&quot;dataSource&quot;</span>] = data_source</span><br><span class="line"></span><br><span class="line">    date_array = []</span><br><span class="line">    date_time = datetime.datetime(<span class="built_in">int</span>(date[<span class="number">0</span>:<span class="number">4</span>]),<span class="built_in">int</span>(date[<span class="number">4</span>:<span class="number">6</span>]),<span class="built_in">int</span>(date[<span class="number">6</span>:<span class="number">8</span>]))</span><br><span class="line">    date_time_next = date_time + datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    date_array.append(date_time.strftime(<span class="string">&#x27;%Y-%m-%dT%H:%M:%S+08:00&#x27;</span>) + <span class="string">&quot;/&quot;</span> + date_time_next.strftime(<span class="string">&#x27;%Y-%m-%dT%H:%M:%S+08:00&#x27;</span>))</span><br><span class="line">    input_json[<span class="string">&quot;spec&quot;</span>][<span class="string">&quot;dataSchema&quot;</span>][<span class="string">&quot;granularitySpec&quot;</span>][<span class="string">&quot;segmentGranularity&quot;</span>] = segment</span><br><span class="line">    input_json[<span class="string">&quot;spec&quot;</span>][<span class="string">&quot;dataSchema&quot;</span>][<span class="string">&quot;granularitySpec&quot;</span>][<span class="string">&quot;queryGranularity&quot;</span>] = query</span><br><span class="line">    input_json[<span class="string">&quot;spec&quot;</span>][<span class="string">&quot;dataSchema&quot;</span>][<span class="string">&quot;granularitySpec&quot;</span>][<span class="string">&quot;intervals&quot;</span>] = date_array</span><br><span class="line">    <span class="keyword">return</span> json.dumps(input_json, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Usage: druid_task.py &lt;url&gt; &lt;task_file&gt; &lt;date&gt; &lt;submit_timeout&gt; &lt;complete_timeout&gt; &lt;hdfs_path&gt; &lt;data_source&gt;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &lt; <span class="number">10</span>:</span><br><span class="line">        print(<span class="string">&quot;Usage: druid_task.py &lt;url&gt; &lt;task_file&gt; &lt;date&gt; &lt;submit_timeout&gt; &lt;complete_timeout&gt; &lt;hdfs_path&gt; &lt;data_source&gt; &lt;segment&gt; &lt;query&gt;&quot;</span>)</span><br><span class="line">        exit(<span class="number">1</span>)</span><br><span class="line">    print(sys.argv)</span><br><span class="line"></span><br><span class="line">    url = sys.argv[<span class="number">1</span>].strip()</span><br><span class="line">    task_file = sys.argv[<span class="number">2</span>].strip()</span><br><span class="line">    date = sys.argv[<span class="number">3</span>].strip()</span><br><span class="line">    submit_timeout = sys.argv[<span class="number">4</span>].strip()</span><br><span class="line">    complete_timeout = sys.argv[<span class="number">5</span>].strip()</span><br><span class="line">    hdfspath = sys.argv[<span class="number">6</span>].strip()</span><br><span class="line">    data_source = sys.argv[<span class="number">7</span>].strip()</span><br><span class="line">    date_segment = sys.argv[<span class="number">8</span>].strip()</span><br><span class="line">    date_query = sys.argv[<span class="number">9</span>].strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># data path</span></span><br><span class="line">    datapath = hdfspath + <span class="string">&quot;/&quot;</span> + date</span><br><span class="line"></span><br><span class="line">    <span class="comment"># init spark context</span></span><br><span class="line">    sc = SparkContext(appName=<span class="string">&quot;druid_index_task_day&quot;</span>)</span><br><span class="line"></span><br><span class="line">    datafiles_rdd = sc.wholeTextFiles(datapath)</span><br><span class="line">    is_empty = datafiles_rdd.isEmpty()</span><br><span class="line">    print(is_empty)</span><br><span class="line">    print(<span class="string">&quot;datapath:&quot;</span> + datapath)</span><br><span class="line">    <span class="keyword">if</span> is_empty == <span class="literal">False</span>:</span><br><span class="line">        submit_timeout_at = time.time() + <span class="built_in">float</span>(submit_timeout)</span><br><span class="line">        complete_timeout_at = time.time() + <span class="built_in">float</span>(complete_timeout)</span><br><span class="line">        task_json = get_task_json(read_task_file(task_file), hdfspath, data_source, date, date_segment, date_query)</span><br><span class="line">        print(task_json)</span><br><span class="line"></span><br><span class="line">        task_id = json.loads(post_task(url, task_json, submit_timeout_at))[<span class="string">&quot;task&quot;</span>]</span><br><span class="line">        sys.stderr.write(<span class="string">&#x27;\033[1m&#x27;</span> + <span class="string">&quot;Task started: &quot;</span> + <span class="string">&#x27;\033[0m&#x27;</span> + <span class="string">&quot;&#123;0&#125;\n&quot;</span>.<span class="built_in">format</span>(task_id))</span><br><span class="line">        sys.stderr.write(<span class="string">&#x27;\033[1m&#x27;</span> + <span class="string">&quot;Task log:     &quot;</span> + <span class="string">&#x27;\033[0m&#x27;</span> + <span class="string">&quot;&#123;0&#125;/druid/indexer/v1/task/&#123;1&#125;/log\n&quot;</span>.<span class="built_in">format</span>(url.rstrip(<span class="string">&quot;/&quot;</span>),task_id))</span><br><span class="line">        sys.stderr.write(<span class="string">&#x27;\033[1m&#x27;</span> + <span class="string">&quot;Task status:  &quot;</span> + <span class="string">&#x27;\033[0m&#x27;</span> + <span class="string">&quot;&#123;0&#125;/druid/indexer/v1/task/&#123;1&#125;/status\n&quot;</span>.<span class="built_in">format</span>(url.rstrip(<span class="string">&quot;/&quot;</span>),task_id))</span><br><span class="line"></span><br><span class="line">        task_status = await_task_completion(url, task_id, complete_timeout_at)</span><br><span class="line">        print(<span class="string">&quot;Task finished with status: &#123;0&#125;\n&quot;</span>.<span class="built_in">format</span>(task_status))</span><br><span class="line">        <span class="keyword">if</span> task_status != <span class="string">&#x27;SUCCESS&#x27;</span>:</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">&quot;Task finished with no data.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>下钻和聚合</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Druid</tag>
      </tags>
  </entry>
  <entry>
    <title>flink local deploy</title>
    <url>/bigdata/Flink-local-demo/</url>
    <content><![CDATA[<h1 id="Flink本地部署"><a href="#Flink本地部署" class="headerlink" title="Flink本地部署"></a>Flink本地部署</h1>]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>PhamtomJs</title>
    <url>/bigdata/PhantomJS/</url>
    <content><![CDATA[<p>PhamtomJs 是服务端的无界面的Chrome浏览器，提供JS API和shell命令行，方便操作</p>
<blockquote>
<p><a href="http://phantomjs.org/quick-start.html">官方的文档</a></p>
</blockquote>
<h1 id="Java-操作"><a href="#Java-操作" class="headerlink" title="Java 操作"></a>Java 操作</h1><h2 id="阻塞式"><a href="#阻塞式" class="headerlink" title="阻塞式"></a>阻塞式</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">openWithPhanatomjs</span><span class="params">(String viewUrl)</span> </span>&#123;</span><br><span class="line">      logger.info(<span class="string">&quot;openWithPhanatomjs start&quot;</span> + viewUrl);</span><br><span class="line">      InputStreamReader inReader = <span class="keyword">null</span>;</span><br><span class="line">      InputStream inputStream = <span class="keyword">null</span>;</span><br><span class="line">      BufferedReader reader = <span class="keyword">null</span>;</span><br><span class="line">      InputStream errorStream = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">          String path = <span class="keyword">null</span>;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">              path = Thread.currentThread().getContextClassLoader().getResource(<span class="string">&quot;/&quot;</span>).toURI().getPath();</span><br><span class="line">          &#125; <span class="keyword">catch</span> (URISyntaxException e) &#123;</span><br><span class="line">              e.printStackTrace();</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">final</span> String s = path + File.separator + <span class="string">&quot;otwp.js&quot;</span>;</span><br><span class="line"><span class="comment">//            logger.info(s);</span></span><br><span class="line">          Process process = Runtime.getRuntime().exec(phanatomjsHome + <span class="string">&quot; &quot;</span> + s + <span class="string">&quot; &quot;</span> + viewUrl);</span><br><span class="line">          inputStream = process.getInputStream();</span><br><span class="line">          inReader = <span class="keyword">new</span> InputStreamReader(inputStream, <span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">          reader = <span class="keyword">new</span> BufferedReader(inReader);</span><br><span class="line">          String line = <span class="keyword">null</span>;</span><br><span class="line">          <span class="keyword">while</span> ((line = reader.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">              logger.info(line);</span><br><span class="line">          &#125;</span><br><span class="line">          errorStream = process.getErrorStream();</span><br><span class="line">          <span class="keyword">final</span> BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(errorStream));</span><br><span class="line">          <span class="keyword">while</span> ((line = bufferedReader.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">              logger.info(line);</span><br><span class="line">          &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          logger.error(<span class="string">&quot;&quot;</span>, e);</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">if</span> (inReader != <span class="keyword">null</span>) &#123;</span><br><span class="line">                  inReader.close();</span><br><span class="line">              &#125;</span><br><span class="line">              <span class="keyword">if</span> (inputStream != <span class="keyword">null</span>) &#123;</span><br><span class="line">                  inputStream.close();</span><br><span class="line">              &#125;</span><br><span class="line">              <span class="keyword">if</span> (reader != <span class="keyword">null</span>) &#123;</span><br><span class="line">                  reader.close();</span><br><span class="line">              &#125;</span><br><span class="line">          &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">              logger.error(<span class="string">&quot;&quot;</span>, e);</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      logger.info(<span class="string">&quot;openWithPhanatomjs end&quot;</span> + viewUrl);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h1 id="样例"><a href="#样例" class="headerlink" title="样例"></a>样例</h1><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// run this js with command:</span></span><br><span class="line"><span class="comment">// phantomjs openTableauWithPhantomjs.js &lt;Tableau view url&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&quot;start open with Phantomjs&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> system = <span class="built_in">require</span>(<span class="string">&#x27;system&#x27;</span>);</span><br><span class="line"><span class="keyword">if</span> (system.args.length === <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;Please input view url&#x27;</span>);</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;exit&#x27;</span>);</span><br><span class="line">    phantom.exit();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> viewUrl = system.args[<span class="number">1</span>];</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;Open url: &#x27;</span> + viewUrl);</span><br><span class="line">    <span class="keyword">var</span> page = <span class="built_in">require</span>(<span class="string">&#x27;webpage&#x27;</span>).create();</span><br><span class="line">    <span class="keyword">var</span> t = <span class="built_in">Date</span>.now();</span><br><span class="line"></span><br><span class="line">    page.onConsoleMessage = <span class="function"><span class="keyword">function</span> (<span class="params">msg</span>) </span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(msg);</span><br><span class="line">    &#125;;</span><br><span class="line">    page.onLoadFinished = <span class="function"><span class="keyword">function</span> (<span class="params">status</span>) </span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&#x27;加载完毕, 状态: &#x27;</span> + status);</span><br><span class="line"></span><br><span class="line">    &#125;;</span><br><span class="line">    page.settings.resourceTimeout=<span class="number">100000</span>;</span><br><span class="line"></span><br><span class="line">    page.open(viewUrl, <span class="function"><span class="keyword">function</span> (<span class="params">status</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> title = page.evaluate(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">document</span>.title;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="built_in">console</span>.log(status + <span class="string">&#x27;\ttitle:&#x27;</span> + title);</span><br><span class="line">        <span class="keyword">if</span> (status !== <span class="string">&#x27;success&#x27;</span>) &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;Fail to load the address!&#x27;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            t = <span class="built_in">Date</span>.now() - t;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;open success: elase time : &#x27;</span> + t);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&#x27;exit&#x27;</span>);</span><br><span class="line">        phantom.exit();</span><br><span class="line"></span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
















<hr>
<p>[参考文献]</p>
<ol>
<li><a href="https://www.qcloud.com/community/article/743451001489391682">PhantomJS 基础及示例</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>PhamtomJs</tag>
      </tags>
  </entry>
  <entry>
    <title>RPC</title>
    <url>/bigdata/RPC/</url>
    <content><![CDATA[<p>RPC -  Remote Procedure Call 远程过程调用<br>是一种进程间通信方式。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的，本质上编写的调用代码基本相同。</p>
<p>RPC 的鼻祖<a href="https://en.wikipedia.org/wiki/Bruce_Jay_Nelson">Bruce Jay Nelson</a> 在1980s提出了基本的实现结构<br><img src="/images/distributed/RPC/rpc-struct-01.png" alt="RPC基本实现结构"></p>
<p>图中的<code>user</code>即为<code>client</code></p>
<h1 id="常见的RPC协议"><a href="#常见的RPC协议" class="headerlink" title="常见的RPC协议"></a>常见的RPC协议</h1><p>CORBAR: 为了解决异构平台的 RPC，使用了 <code>IDL</code>（Interface Definition Language）来定义远程接口，并将其映射到特定的平台语言中。后来大部分的跨语言平台 RPC 基本都采用了此类方式，比如我们熟悉的 Web Service（SOAP），近年开源的Thrift 等。他们大部分都通过 IDL 定义，并提供工具来映射生成不同语言平台的 user-stub 和 server-stub，并通过框架库来提供 RPCRuntime 的支持。不过貌似每个不同的 RPC 框架都定义了各自不同的 IDL 格式，导致程序员的学习成本进一步上升（苦逼啊），Web Service 尝试建立业界标准，无赖标准规范复杂而效率偏低，否则 Thrift 等更高效的 RPC 框架就没必要出现了。</p>
<p>IDL 是为了跨平台语言实现 RPC 不得已的选择，要解决更广泛的问题自然导致了更复杂的方案。而对于同一平台内的 RPC 而言显然没必要搞个中间语言出来，例如Java原生的 RMI，这样对于 java 程序员而言显得更直接简单，降低使用的学习成本。目前市面上提供的 RPC 框架已经可算是五花八门，百家争鸣了。需要根据实际使用场景谨慎选型，需要考虑的选型因素我觉得至少包括下面几点：</p>
<ol>
<li>性能指标</li>
<li>是否需要跨语言平台</li>
<li>内网开放还是公网开放</li>
<li>开源 RPC 框架本身的质量、社区活跃度</li>
</ol>
<h2 id="CORBAR"><a href="#CORBAR" class="headerlink" title="CORBAR"></a>CORBAR</h2><h2 id="RMI"><a href="#RMI" class="headerlink" title="RMI"></a>RMI</h2><h2 id="Web-Service（SOAP）"><a href="#Web-Service（SOAP）" class="headerlink" title="Web Service（SOAP）"></a>Web Service（SOAP）</h2><h2 id="Thrift"><a href="#Thrift" class="headerlink" title="Thrift"></a>Thrift</h2><h1 id="异步调用与同步调用"><a href="#异步调用与同步调用" class="headerlink" title="异步调用与同步调用"></a>异步调用与同步调用</h1><ol>
<li>同步调用<br>客户方等待调用执行完成并返回结果。  </li>
<li>异步调用<br>客户方调用后不用等待执行结果返回，但依然可以通过回调通知等方式获取返回结果。<br>若客户方不关心调用返回结果，则变成单向异步调用，单向调用不用返回结果。  </li>
</ol>
<h2 id="RPC-结构拆解"><a href="#RPC-结构拆解" class="headerlink" title="RPC 结构拆解"></a>RPC 结构拆解</h2><p><img src="http://img.blog.csdn.net/20150108170231000?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbWluZGZsb2F0aW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p>RPC 服务方通过 <code>RpcServer</code> 去导出（export）远程接口方法，而客户方通过 <code>RpcClient</code> 去引入（import）远程接口方法。客户方像调用本地方法一样去调用远程接口方法，RPC 框架提供接口的代理实现，实际的调用将委托给代理<code>RpcProxy</code> 。代理封装调用信息并将调用转交给<code>RpcInvoker</code> 去实际执行。在客户端的<code>RpcInvoker</code> 通过连接器<code>RpcConnector</code> 去维持与服务端的通道<code>RpcChannel</code>，并使用<code>RpcProtocol</code> 执行协议编码（encode）并将编码后的请求消息通过通道发送给服务方。</p>
<p>RPC 服务端接收器 <code>RpcAcceptor</code> 接收客户端的调用请求，同样使用<code>RpcProtocol</code> 执行协议解码（decode）。解码后的调用信息传递给<code>RpcProcessor</code> 去控制处理调用过程，最后再委托调用给<code>RpcInvoker</code> 去实际执行并返回调用结果。</p>
<h2 id="RPC-组件职责"><a href="#RPC-组件职责" class="headerlink" title="RPC 组件职责"></a>RPC 组件职责</h2><p>上面我们进一步拆解了 RPC 实现结构的各个组件组成部分，下面我们详细说明下每个组件的职责划分。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. RpcServer  </span><br><span class="line">   负责导出（export）远程接口  </span><br><span class="line">2. RpcClient  </span><br><span class="line">   负责导入（import）远程接口的代理实现  </span><br><span class="line">3. RpcProxy  </span><br><span class="line">   远程接口的代理实现  </span><br><span class="line">4. RpcInvoker  </span><br><span class="line">   客户方实现：负责编码调用信息和发送调用请求到服务方并等待调用结果返回  </span><br><span class="line">   服务方实现：负责调用服务端接口的具体实现并返回调用结果  </span><br><span class="line">5. RpcProtocol  </span><br><span class="line">   负责协议编&#x2F;解码  </span><br><span class="line">6. RpcConnector  </span><br><span class="line">   负责维持客户方和服务方的连接通道和发送数据到服务方  </span><br><span class="line">7. RpcAcceptor  </span><br><span class="line">   负责接收客户方请求并返回请求结果  </span><br><span class="line">8. RpcProcessor  </span><br><span class="line">   负责在服务方控制调用过程，包括管理调用线程池、超时时间等  </span><br><span class="line">9. RpcChannel  </span><br><span class="line">   数据传输通道  </span><br></pre></td></tr></table></figure>
<h2 id="RPC-实现分析"><a href="#RPC-实现分析" class="headerlink" title="RPC 实现分析"></a>RPC 实现分析</h2><p>在进一步拆解了组件并划分了职责之后，这里以在  Java 平台实现该 RPC 框架概念模型为例，详细分析下实现中需要考虑的因素。</p>
<h3 id="导出远程接口"><a href="#导出远程接口" class="headerlink" title="导出远程接口"></a>导出远程接口</h3><p>导出远程接口的意思是指只有导出的接口可以供远程调用，而未导出的接口则不能。在 java 中导出接口的代码片段可能如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DemoService demo   = <span class="keyword">new</span> ...;  </span><br><span class="line">RpcServer   server = <span class="keyword">new</span> ...;  </span><br><span class="line">server.export(DemoService.class, demo, options);  </span><br></pre></td></tr></table></figure>
<p>我们可以导出整个接口，也可以更细粒度一点只导出接口中的某些方法，如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 只导出 DemoService 中签名为 hi(String s) 的方法  </span></span><br><span class="line">server.export(DemoService.class, demo, <span class="string">&quot;hi&quot;</span>, <span class="keyword">new</span> Class&lt;?&gt;[] &#123; String.class &#125;, options);  </span><br></pre></td></tr></table></figure>
<p>java 中还有一种比较特殊的调用就是多态，也就是一个接口可能有多个实现，那么远程调用时到底调用哪个？这个本地调用的语义是通过 jvm 提供的引用多态性隐式实现的，那么对于 RPC 来说跨进程的调用就没法隐式实现了。如果前面<code>DemoService</code> 接口有 2 个实现，那么在导出接口时就需要特殊标记不同的实现，如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DemoService demo   = <span class="keyword">new</span> ...;  </span><br><span class="line">DemoService demo2  = <span class="keyword">new</span> ...;  </span><br><span class="line">RpcServer   server = <span class="keyword">new</span> ...;  </span><br><span class="line">server.export(DemoService.class, demo, options);  </span><br><span class="line">server.export(<span class="string">&quot;demo2&quot;</span>, DemoService.class, demo2, options);  </span><br></pre></td></tr></table></figure>
<p>上面 demo2 是另一个实现，我们标记为 “demo2” 来导出，那么远程调用时也需要传递该标记才能调用到正确的实现类，这样就解决了多态调用的语义。</p>
<h3 id="导入远程接口与客户端代理"><a href="#导入远程接口与客户端代理" class="headerlink" title="导入远程接口与客户端代理"></a>导入远程接口与客户端代理</h3><p>导入相对于导出远程接口，客户端代码为了能够发起调用必须要获得远程接口的方法或过程定义。目前，大部分跨语言平台 RPC 框架采用根据 IDL 定义通过 code generator 去生成 stub 代码，这种方式下实际导入的过程就是通过代码生成器在编译期完成的。我所使用过的一些跨语言平台 RPC 框架如 CORBAR、WebService、ICE、Thrift 均是此类方式。</p>
<p>代码生成的方式对跨语言平台 RPC 框架而言是必然的选择，而对于同一语言平台的 RPC 则可以通过共享接口定义来实现。在 java 中导入接口的代码片段可能如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RpcClient client = <span class="keyword">new</span> ...;  </span><br><span class="line">DemoService demo = client.refer(DemoService.class);  </span><br><span class="line">demo.hi(<span class="string">&quot;how are you?&quot;</span>);  </span><br></pre></td></tr></table></figure>
<p>在 java 中 ‘import’ 是关键字，所以代码片段中我们用 refer 来表达导入接口的意思。这里的导入方式本质也是一种代码生成技术，只不过是在运行时生成，比静态编译期的代码生成看起来更简洁些。java 里至少提供了两种技术来提供动态代码生成，一种是 jdk 动态代理，另外一种是字节码生成。动态代理相比字节码生成使用起来更方便，但动态代理方式在性能上是要逊色于直接的字节码生成的，而字节码生成在代码可读性上要差很多。两者权衡起来，个人认为牺牲一些性能来获得代码可读性和可维护性显得更重要。</p>
<h3 id="协议编解码"><a href="#协议编解码" class="headerlink" title="协议编解码"></a>协议编解码</h3><p>客户端代理在发起调用前需要对调用信息进行编码，这就要考虑需要编码些什么信息并以什么格式传输到服务端才能让服务端完成调用。出于效率考虑，编码的信息越少越好（传输数据少），编码的规则越简单越好（执行效率高）。我们先看下需要编码些什么信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 调用编码 --  </span><br><span class="line">1. 接口方法  </span><br><span class="line">   包括接口名、方法名  </span><br><span class="line">2. 方法参数  </span><br><span class="line">   包括参数类型、参数值  </span><br><span class="line">3. 调用属性  </span><br><span class="line">   包括调用属性信息，例如调用附件隐式参数、调用超时时间等  </span><br><span class="line">  </span><br><span class="line">-- 返回编码 --  </span><br><span class="line"> 1. 返回结果  </span><br><span class="line">    接口方法中定义的返回值  </span><br><span class="line"> 2. 返回码  </span><br><span class="line">    异常返回码  </span><br><span class="line"> 3. 返回异常信息  </span><br><span class="line">    调用异常信息  </span><br></pre></td></tr></table></figure>
<p>除了以上这些必须的调用信息，我们可能还需要一些元信息以方便程序编解码以及未来可能的扩展。这样我们的编码消息里面就分成了两部分，一部分是元信息、另一部分是调用的必要信息。如果设计一种 RPC 协议消息的话，元信息我们把它放在协议消息头中，而必要信息放在协议消息体中。下面给出一种概念上的 RPC 协议消息设计格式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 消息头 --  </span><br><span class="line">magic      : 协议魔数，为解码设计  </span><br><span class="line">header size: 协议头长度，为扩展设计  </span><br><span class="line">version    : 协议版本，为兼容设计  </span><br><span class="line">st         : 消息体序列化类型  </span><br><span class="line">hb         : 心跳消息标记，为长连接传输层心跳设计  </span><br><span class="line">ow         : 单向消息标记，  </span><br><span class="line">rp         : 响应消息标记，不置位默认是请求消息  </span><br><span class="line">status code: 响应消息状态码  </span><br><span class="line">reserved   : 为字节对齐保留  </span><br><span class="line">message id : 消息 id  </span><br><span class="line">body size  : 消息体长度  </span><br><span class="line">  </span><br><span class="line">-- 消息体 --  </span><br><span class="line">采用序列化编码，常见有以下格式  </span><br><span class="line">xml   : 如 webservie soap  </span><br><span class="line">json  : 如 JSON-RPC  </span><br><span class="line">binary: 如 thrift; hession; kryo 等  </span><br></pre></td></tr></table></figure>
<p>格式确定后编解码就简单了，由于头长度一定所以我们比较关心的就是消息体的序列化方式。序列化我们关心三个方面：<br>\1. 序列化和反序列化的效率，越快越好。 <br>\2. 序列化后的字节长度，越小越好。 <br>\3. 序列化和反序列化的兼容性，接口参数对象若增加了字段，是否兼容。<br>上面这三点有时是鱼与熊掌不可兼得，这里面涉及到具体的序列化库实现细节，就不在本文进一步展开分析了。</p>
<h3 id="传输服务"><a href="#传输服务" class="headerlink" title="传输服务"></a>传输服务</h3><p>协议编码之后，自然就是需要将编码后的 RPC 请求消息传输到服务方，服务方执行后返回结果消息或确认消息给客户方。RPC 的应用场景实质是一种可靠的请求应答消息流，和 HTTP 类似。因此选择长连接方式的 TCP 协议会更高效，与 HTTP 不同的是在协议层面我们定义了每个消息的唯一 id，因此可以更容易的复用连接。</p>
<p>既然使用长连接，那么第一个问题是到底 client 和 server 之间需要多少根连接？实际上单连接和多连接在使用上没有区别，对于数据传输量较小的应用类型，单连接基本足够。单连接和多连接最大的区别在于，每根连接都有自己私有的发送和接收缓冲区，因此大数据量传输时分散在不同的连接缓冲区会得到更好的吞吐效率。所以，如果你的数据传输量不足以让单连接的缓冲区一直处于饱和状态的话，那么使用多连接并不会产生任何明显的提升，反而会增加连接管理的开销。</p>
<p>连接是由 client 端发起建立并维持。如果 client 和 server 之间是直连的，那么连接一般不会中断（当然物理链路故障除外）。如果 client 和 server 连接经过一些负载中转设备，有可能连接一段时间不活跃时会被这些中间设备中断。为了保持连接有必要定时为每个连接发送心跳数据以维持连接不中断。心跳消息是 RPC 框架库使用的内部消息，在前文协议头结构中也有一个专门的心跳位，就是用来标记心跳消息的，它对业务应用透明。</p>
<h3 id="执行调用"><a href="#执行调用" class="headerlink" title="执行调用"></a>执行调用</h3><p>client stub 所做的事情仅仅是编码消息并传输给服务方，而真正调用过程发生在服务方。server stub 从前文的结构拆解中我们细分了 <code>RpcProcessor</code> 和<code>RpcInvoker</code> 两个组件，一个负责控制调用过程，一个负责真正调用。这里我们还是以 java 中实现这两个组件为例来分析下它们到底需要做什么？</p>
<p>java 中实现代码的动态接口调用目前一般通过反射调用。除了原生的 jdk 自带的反射，一些第三方库也提供了性能更优的反射调用，因此 <code>RpcInvoker</code> 就是封装了反射调用的实现细节。</p>
<p>调用过程的控制需要考虑哪些因素，<code>RpcProcessor</code> 需要提供什么样地调用控制服务呢？下面提出几点以启发思考：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 效率提升  </span><br><span class="line">   每个请求应该尽快被执行，因此我们不能每请求来再创建线程去执行，需要提供线程池服务。  </span><br><span class="line">2. 资源隔离  </span><br><span class="line">   当我们导出多个远程接口时，如何避免单一接口调用占据所有线程资源，而引发其他接口执行阻塞。  </span><br><span class="line">3. 超时控制  </span><br><span class="line">   当某个接口执行缓慢，而 client 端已经超时放弃等待后，server 端的线程继续执行此时显得毫无意义。  </span><br></pre></td></tr></table></figure>

<h2 id="RPC-异常处理"><a href="#RPC-异常处理" class="headerlink" title="RPC 异常处理"></a>RPC 异常处理</h2><p>无论 RPC 怎样努力把远程调用伪装的像本地调用，但它们依然有很大的不同点，而且有一些异常情况是在本地调用时绝对不会碰到的。在说异常处理之前，我们先比较下本地调用和 RPC 调用的一些差异：</p>
<ol>
<li>本地调用一定会执行，而远程调用则不一定，调用消息可能因为网络原因并未发送到服务方。</li>
<li>本地调用只会抛出接口声明的异常，而远程调用还会跑出 RPC 框架运行时的其他异常。</li>
<li>本地调用和远程调用的性能可能差距很大，这取决于 RPC 固有消耗所占的比重。<br>正是这些区别决定了使用 RPC 时需要更多考量。当调用远程接口抛出异常时，异常可能是一个业务异常，也可能是 RPC 框架抛出的运行时异常（如：网络中断等）。业务异常表明服务方已经执行了调用，可能因为某些原因导致未能正常执行，而 RPC 运行时异常则有可能服务方根本没有执行，对调用方而言的异常处理策略自然需要区分。</li>
</ol>
<p>由于 RPC 固有的消耗相对本地调用高出几个数量级，本地调用的固有消耗是纳秒级，而 RPC 的固有消耗是在毫秒级。那么对于过于轻量的计算任务就并不合适导出远程接口由独立的进程提供服务，只有花在计算任务上时间远远高于 RPC 的固有消耗才值得导出为远程接口提供服务。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>至此我们提出了一个 RPC 实现的概念框架，并详细分析了需要考虑的一些实现细节。无论 RPC 的概念是如何优雅，但是“草丛中依然有几条蛇隐藏着”，只有深刻理解了 RPC 的本质，才能更好地应用。</p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>RPC</tag>
        <tag>Distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>mac搭建hadoop、hive、spark、flink环境</title>
    <url>/bigdata/cluster_deploy/</url>
    <content><![CDATA[<h1 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h1><p>启动mysql</p>
<p>brew services start mysql</p>
<p>abc.ABC.123</p>
<h1 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/33117305">mac osx 搭建hadoop开发环境</a></li>
<li><a href="https://blog.csdn.net/u010638969/article/details/51283216">spark on yarn</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/65825211">hive环境搭建</a></li>
</ol>
<p>按照上面文章的方式搭建，启动hdfs、yarn</p>
<p><a href="https://stackoverflow.com/questions/33968422/bin-bash-bin-java-no-such-file-or-directory"><strong>必须使用这个命令</strong></a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动yarn</span></span></span><br><span class="line">hadoop/sbin/./yarn-daemon.sh start resourcemanager</span><br><span class="line">hadoop/sbin./yarn-daemon.sh start nodemanager</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动hdfs</span></span></span><br><span class="line">hadoop/sbin/start-hdfs.sh</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="http://localhost:50070/">hdfs-web</a><br><a href="http://localhost:8088/">yarn-web</a></p>
<h2 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h2><p>create user ‘hadoop’@’%’ identified by ‘hadoop%HADOOP%123’;</p>
<p>grant all privileges on <em>.</em> to ‘hadoop’@’%’ with grant option;</p>
<p>flush privileges;</p>
<h2 id="flink-on-yarn"><a href="#flink-on-yarn" class="headerlink" title="flink on yarn"></a>flink on yarn</h2><p><a href="https://blog.csdn.net/xu470438000/article/details/79576989">flink on yarn部署</a></p>
<p>在flink lib下增加flink-hadoop兼容包<a href="https://repo.maven.apache.org/maven2/org/apache/flink/flink-shaded-hadoop-2-uber/2.7.5-7.0/flink-shaded-hadoop-2-uber-2.7.5-7.0.jar">Pre-bundled Hadoop 2.7.5</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动</span></span><br><span class="line">bin/start-cluster.sh</span><br></pre></td></tr></table></figure>

<h2 id="搭建AthenaX"><a href="#搭建AthenaX" class="headerlink" title="搭建AthenaX"></a>搭建AthenaX</h2><p><a href="https://athenax.readthedocs.io/en/latest/getting_started/">Building AthenaX and Flink</a></p>
<h2 id="mac-install-kafka"><a href="#mac-install-kafka" class="headerlink" title="mac install kafka"></a>mac install kafka</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install zookeeper</span><br><span class="line">brew install kafka</span><br></pre></td></tr></table></figure>
<p>修改 /usr/local/etc/kafka/server.properties, 找到 listeners=PLAINTEXT://:9092 那一行，把注释取消掉。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ brew services start zookeeper</span><br><span class="line">$ brew services start kafka</span><br></pre></td></tr></table></figure>
<p>创建topic</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic order-streaming-test</span><br></pre></td></tr></table></figure>
<h3 id="清理topic"><a href="#清理topic" class="headerlink" title="清理topic"></a>清理topic</h3><p>cd /usr/local/var/lib/kafka-logs</p>
<p><a href="https://colobu.com/2019/09/27/install-Kafka-on-Mac/">install kafka on mac</a></p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>RPC</tag>
        <tag>Distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>大规模分布式系统故障恢复和容错架构探究</title>
    <url>/bigdata/failover-recovery/</url>
    <content><![CDATA[<p>在大规模数据处理的分布式系统中，如何保障数据的高可用、数据的一致性和幂等性(exactly once)是系统的一大难题!<br>使用廉价机器构建集群成为大数据平台的标配，故障恢复和容错（failover recovery）机制成为防止消息丢失和快速恢复服务必不可少的组成部分; 在通用的大数据架构中，也是保障数据高可用、一致性和幂等性的基础。</p>
<p>分布式系统故障恢复需要解决的问题:</p>
<ol>
<li>吞吐量大的场景，当出现了失败时，需要保证失败的数据可以重放，且状态可恢复。</li>
<li>某一个时刻，多个计算节点存在处理速度不一致的问题，一条数据可能经过多个计算节点才能完成计算。如何保存多个计算节点的状态，且保证数据对齐？</li>
<li>如何保证数据经过各个计算节点的顺序性和不重复？</li>
<li>如何回放数据？</li>
</ol>
<p>虽然大规模分布式系统的侧重各不相同，但是failover recovery的机制却如出一辙, 主要有ack模式、异步checkpoint模式、CL模式、补偿模式等，接下来就这四种模式分别总结。</p>
<h1 id="Ack模式"><a href="#Ack模式" class="headerlink" title="Ack模式"></a>Ack模式</h1><p>在分布式系统中，为了确保一条(批)数据被正确处理，且当出现任何故障，保障数据不丢。ack机制是最简单的方式，每一条(批)数据正确处理完后，发送一条确认标示。</p>
<h2 id="TCP-ack"><a href="#TCP-ack" class="headerlink" title="TCP ack"></a>TCP ack</h2><p>在TCP握手时，当收到客户端发起的握手报文时, 返回一个Acknowledgement Number, 标示客户端的请求已经收到，并返回给客户端。<br>而后客户端返回Acknowledgement Number以确保服务端请求正确接受。<br>当网络抖动或者服务器和客户端故障时，报文可能丢失。此时就要依赖于与ack机制相配合的faiover-recovery机制。</p>
<p>如果服务器没有收到客户端的最终ACK确认报文，会一直处于<code>SYN_RECV</code>状态，将客户端IP加入等待列表，<br>并重发<code>SYN+ACK</code>报文。<br>重发一般进行3-5次，大约间隔30秒左右轮询一次等待列表重试所有客户端。<br>另一方面，服务器在自己发出了<code>SYN+ACK</code>报文后，会预分配资源为即将建立的TCP连接储存信息做准备，<br>这个资源在等待重试期间一直保留。更为重要的是，服务器资源有限，可以维护的<code>SYN_RECV</code>状态超过极限后就不再接受新的SYN报文，<br>也就是拒绝新的TCP连接建立。</p>
<p>然而著名的<code>SYNC Flood</code>的DDos攻击正式利用上述的<code>failover-recovery</code>机制。<br>攻击者伪装大量的IP地址给服务器发送SYN报文，由于伪造的IP地址几乎不可能存在，也就几乎没有设备会给服务器返回任何应答了。<br>因此，服务器将会维持一个庞大的等待列表，不停地重试发送SYN+ACK报文，同时占用着大量的资源无法释放。<br>更为关键的是，被攻击服务器的<code>SYN_RECV</code>队列被恶意的数据包占满，不再接受新的SYN请求，合法用户无法完成三次握手建立起TCP连接。<br>也就是说，这个服务器被SYN Flood拒绝服务了。</p>
<p>SYN Flood攻击大量消耗服务器的CPU、内存资源，并占满SYN等待队列。相应的，我们修改内核参数即可有效缓解。主要参数如下：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">net.ipv4.tcp_syncookies</span> = <span class="string">1</span></span><br><span class="line"><span class="meta">net.ipv4.tcp_max_syn_backlog</span> = <span class="string">8192</span></span><br><span class="line"><span class="meta">net.ipv4.tcp_synack_retries</span> = <span class="string">2</span></span><br></pre></td></tr></table></figure>
<p>分别为启用SYN Cookie、设置SYN最大队列长度以及设置SYN+ACK最大重试次数。<br>SYNC Cookie主要是在服务端缓冲基于时间种子的SYN号，只有客户端发送的SYN+ACK与缓冲完全匹配才完成握手，否则直接丢弃。<br><code>tcp_max_syn_backlog</code>则是增加等待队列的长度。</p>
<h2 id="Apache-storm中的ack机制"><a href="#Apache-storm中的ack机制" class="headerlink" title="Apache storm中的ack机制"></a>Apache storm中的ack机制</h2><p>Apache storm是首个真正意义上的流式处理引擎，在spark/Flink出现之前，是实时计算领域的一枝独秀。</p>
<p>storm中是没有checkpoint机制的，但storm以大名鼎鼎的ack算法来保证at least once语义，(在<a href="http://storm.apache.org/releases/2.0.0-SNAPSHOT/Trident-tutorial.html">Trident</a>出现之前，storm是没有办法保证exactly once语义的)。ack需要spout节点保存每条数据，当所有的计算节点处理完毕，再发送给spout节点，因此与Chandy-Lamport算法相比，每条数据都需要保存和反复发送，而状态和数据回滚需要用户来保证。</p>
<p>实时大数据处理，数据源源不断的流入系统。无法在一个线程中串行的处理并确认一条或一批数据。<br>strom采用的是异步并行处理的模式(这里以JStorm的实现分析),<br>当excutor节点（executor节点是storm的进程，spout和bolt都是executor启动的task线程）收到消息时，首先将消息压入disruptor队列，disruptor的消费者从队列中获取数据，执行转发或者计算。</p>
<p><img src="/images/bigdata/storm/strom-queue.png"></p>
<p>strom引入ack机制来确保数据不丢，但是对系统整体架构也带来了很大的影响，那么问题来了：</p>
<ul>
<li>消息量大，如何保存消息？</li>
<li>消息可能流过多个节点，如何保证每个节点都正确处理？</li>
<li>spout节点重启，如何确保消息不丢失？</li>
<li>消息堆积，如何确保集群的稳定？</li>
</ul>
<p>ack机制是如何巧妙解决这写问题的呢？</p>
<p><img src="https://images2015.cnblogs.com/blog/639357/201612/639357-20161207181349866-1482908747.png"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A xor A &#x3D; 0.</span><br><span class="line">A xor B … xor B xor A &#x3D; 0，</span><br></pre></td></tr></table></figure>
<p>其中每一个操作数出现且仅出现两次。</p>
<p>strom的ack机制，巧妙的利用了两个相同的值异或为0的原理.</p>
<p>理解下整个大体节奏分为几部分:</p>
<ul>
<li><p>步骤1和2 spout把一条信息同时发送给了bolt1和bolt2，步骤3表示spout emit成功后去 acker bolt里注册本次根消息，ack值设定为本次发送的消息对应的64位id的异或运算值，上图对应的是T1^T2。</p>
</li>
<li><p>步骤4表示bolt1收到T1后，单条tuple被拆成了三条消息T3T4T5发送给bolt3。步骤6 bolt1在ack()方法调用时会向acker bolt提交T1^T3^T4^T5的ack值。</p>
</li>
<li><p>步骤5和7的bolt都没有产生新消息，所以ack()的时候分别向acker bolt提交了T2 和T3^T4^T5的ack值。综上所述，本次spout产生的tuple树对应的ack值经过的运算为 T1^T2^T1^T3^T4^T5^T2^T3^T4^T5按照异或运算的规则，ack值最终正好归零。</p>
</li>
<li><p>步骤8为acker bolt发现根spout最终对应的的ack是0以后认为所有衍生出来的数据都已经处理成功，它会通知对应的spout，spout会调用相应的ack方法。</p>
</li>
</ul>
<p>storm这个机制的实现方式保证了无论一个tuple树有多少个节点，一个根消息对应的追踪ack值所占用的空间大小是固定的，极大地节约了内存空间。</p>
<p>通过ack机制，spout发出的每一条消息，都可以确定是被成功或失败处理。但是，需要备份每条消息，来确认消息是否处理完成，如果消息流过的每个节点都备份数据，总数据量将翻几倍。spout作为消息流入到topology的起点，在这里备份数据既可以节省内存，又可以验证整条链路。此外，Ack机制还常用于<strong>限流</strong>作用： 为了避免spout发送数据太快，而bolt处理太慢，常常设置pending数，当spout有等于或超过pending数的tuple没有收到ack或fail响应时，跳过执行nextTuple， 从而限制spout发送数据。</p>
<p>strom逐条发送逐条处理逐条ack，这也是吞吐量不及spark和flink。</p>
<h1 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>通俗来讲:  就是在分布式系统中，通过状态的checkpoint来确保数据的高可用。</p>
<p>checkpoint俗称检查点，是指定时将数据快照保存到持久化存储介质中，来提供数据的可靠性和与增量文件结合快速恢复数据。</p>
<h2 id="Hadoop-NameNode-的checkpoint"><a href="#Hadoop-NameNode-的checkpoint" class="headerlink" title="Hadoop NameNode 的checkpoint"></a>Hadoop NameNode 的checkpoint</h2><p>NameNode负责管理Hadoop的元数据(workspace信息、blockMap信息、network topology等)信息，是HDFS的心脏。<br>checkpoint机制是NameNode数据故障恢复的方案。</p>
<p><img src="/images/bigdata/hdfs/nameNode_1.x.png" alt="HDFS namenode 1.x"></p>
<p>HDFS 2.x 引入了HA来解决NameNode的单点问题，社区也涌现了多种共享内存方案来保存editlog，而namenode的元数据的数据结构几乎没有变化。</p>
<p><img src="/images/bigdata/hdfs/namenode-workspace-memory.png" alt="name node workspace 内存结构"></p>
<p>workspace信息常驻内存，并定时checkpoint成fsimage文件, 当HDFS-Client发起修改文件目录的请求时，直接修改内存中的数据， 并将修改记录写到editlog文件中。可以将name node的workspace的维护过程简单理解为分布式系统中消息处理的过程，</p>
<h1 id="Chandy-Lamport算法"><a href="#Chandy-Lamport算法" class="headerlink" title="Chandy-Lamport算法"></a>Chandy-Lamport算法</h1><p>在实时流式处理中，简单的使用checkpoint没办法保证exactly once语义，主要是由于在某一个时刻：</p>
<ol>
<li>消息还在处理(没有合并到状态中)，source接收数据的偏移量不能准确的与状态做到数据一致性。</li>
<li>每个子任务处理进度也难以统一。</li>
</ol>
<p>理想情况下，停止接收新数据并排干整个流处理系统，再做checkpoint，才能保证数据一致性和exactly once。停机显然是不可能的！Chandy-Lamport算法使用巧妙的方法，在不停止流处理的前提下拿到每个子任务的状态并checkpoint下来。</p>
<p>著名的一致性算法 Paxos 的作者Leslie Lamport与Chandy合作发表了算法论文: <a href="https://dl.acm.org/ft_gateway.cfm?id=214456&ftid=20679&dwn=1&CFID=72171565&CFTOKEN=2bfe026b198b5dc8-AEFB79E7-EF87-025C-C01DC78635F21DF8">Distributed snapshots: determining global states of distributed systems</a>, 在该论文中提出了分布式快照算法: <strong>Chandy-Lamport</strong></p>
<blockquote>
<p>A <strong>snapshot algorithm</strong> is used to create a consistent snapshot of the global state of a <a href="https://en.wikipedia.org/wiki/Distributed_system">distributed system</a>. Due to the lack of globally shared memory and a global clock, this isn’t trivially possible.</p>
</blockquote>
<p>Chandy-Lamport算法用于在缺乏全局共享内存和全局时钟的分布式系统中创建一致性的全局分布式快照。而这个算法正是1978年提出的<a href="http://lamport.azurewebsites.net/pubs/pubs.html?spm=a2c4e.11153940.blogcont688764.10.4f964568O0SyIm#time-clocks"><strong>Time, Clocks and the Ordering of Events in a Distributed System</strong></a>的直接应用。在分布式系统中，为了确保数据在不同计算节点的有序性，引入barrier机制，当相同的barrier到达每一个计算节点时，认为全局节点处理结束。</p>
<p>Chandy-Lamport算法将全局的状态简化为有限个节点以及节点与节点之间的channel组成，也就是有向图。节点是进程，边是channel；分布式系统中，进程运行在不同的物理机器上，一个分布式的系统中的全局状态由进程的状态和channel中的message组成，这些都是分布式快照要保存的内容。</p>
<p>因为是有向图，一个节点的channel包含了input channel和output channel，流经channel的数据源源不断，假设channel是FIFO队列，保证不重复，那么只需要保存每个节点的局部状态和input message的偏移量，合并起来就是全局的分布式快照。</p>
<h2 id="Flink中的Chandy-Lamport算法"><a href="#Flink中的Chandy-Lamport算法" class="headerlink" title="Flink中的Chandy-Lamport算法"></a>Flink中的Chandy-Lamport算法</h2><p>Chandy-Lamport算法在flink中用于实现at least once语义。具体工作流程如下:</p>
<ol>
<li><p>在checkpoint触发时刻，Job Manager会往所有Source的流中放入一个barrier（图中三角形）。barrier包含当前checkpoint的ID<br><img src="https://upload-images.jianshu.io/upload_images/1431048-f1583d01e8fad051.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/521"></p>
</li>
<li><p>当barrier经过一个subtask时，即表示当前这个subtask处于checkpoint触发的“时刻”，他就会立即将barrier法往下游，并执行checkpoint方法将当前的state存入backend storage。图中Source1和Source2就是完成了checkpoint动作。<br><img src="https://upload-images.jianshu.io/upload_images/1431048-29b12d52fb1ccf05.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/523"></p>
</li>
<li><p>如果一个subtask有多个上游节点，这个subtask就需要等待所有上游发来的barrier都接收到，才能表示这个subtask到达了checkpoint触发“时刻”。但所有节点的barrier不一定一起到达，这时候就会面临“是否要对齐barrier”的问题（Barrier Alignment）。如图中的Task1.1，他有2个上游节点，Source1和Source2。假设Source1的barrier先到，这时候Task1.1就有2个选择：</p>
</li>
</ol>
<ul>
<li>是马上把这个barrier发往下游并等待Source2的barrier来了再做checkpoint</li>
<li>还是把Source1这边后续的event全都cache起来，等Source2的barrier来了，在做checkpoint，完了再继续处理Source1和Source2的event，当前Source1这边需要先处理cache里的event。</li>
</ul>
<h1 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h1><p>WAL是一种常见的故障恢复方式，如NameNode的元数据、HBase WAL、kafka消息中间件、SQLite WAL等。</p>
<blockquote>
<p>“In computer science, write-ahead logging (WAL) is a family of techniques for providing atomicity and durability (two of the ACID properties) in database systems.”——维基百科</p>
</blockquote>
<h2 id="HBase中的WAL"><a href="#HBase中的WAL" class="headerlink" title="HBase中的WAL"></a>HBase中的WAL</h2><p>这里介绍一下HBase WAL(write ahead log)机制，Hbase的RegionServer在处理数据插入和删除的过程中用来记录操作内容的一种日志。在每次Put、Delete等一条记录时，首先将其数据写入到RegionServer对应的HLog文件中去。</p>
<p>客户端向RegionServer端提交数据的时候，会先写入WAL日志，只有当WAL日志写入成功的时候，客户端才会被告诉提交数据成功。如果写WAL失败会告知客户端提交失败，这其实就是数据落地的过程。</p>
<p>在一个RegionServer上的所有Region都共享一个HLog，一次数据的提交先写入WAL，写入成功后，再写入menstore之中。当menstore的值达到一定的时候，就会形成一个个StoreFile。<br><img src="https://img-blog.csdn.net/20180419134053354"></p>
<p>WAL记载了每一个RegionServer对应的HLog。RegionServer1或者RegionServer1上某一个regiong挂掉了，都会迁移到其它的机器上处理，重新操作，进行恢复。</p>
<p>当RegionServer意外终止的时候，Master会通过Zookeeper感知到，Master首先会处理遗留下来的HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应的Region目录下，然后再将实效的Region重新分配，领取到这些Regio你的RegionMaster发现有历史的HLog需要处理，因此会Replay HLog的数据到Memstore之中，然后flush数据到StoreFiles，完成数据的恢复。</p>
<p>飞行日志+补偿机制，也是常用的方法，如基于消息的分布式事务是保证最终一致性的方式之一、Quartz中的恢复执行等。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a href="https://elf8848.iteye.com/blog/2067774">深入浅出DDoS攻击防御</a></li>
<li><a href="">《Storm源码分析》</a></li>
<li><a href="https://www.jianshu.com/p/9b10313fde10">Flink Checkpoint</a></li>
<li><a href="https://www.cnblogs.com/hzmark/p/wal.html">什么是WAL</a></li>
<li><a href="https://www.sqlite.org/wal.html">Write-Ahead Logging in SQLite</a></li>
</ol>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>mapReducer</tag>
      </tags>
  </entry>
  <entry>
    <title>SuperSet</title>
    <url>/bigdata/superset/</url>
    <content><![CDATA[<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker serach superset</span><br><span class="line">docker pull amancevice/superset</span><br><span class="line">docker images</span><br><span class="line">mkdir ~/apps/data/superset/</span><br><span class="line">docker run -d -p 8088:8088 -v  ~/apps/data/superset/:/home/superset amancevice/superset</span><br><span class="line">docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID   IMAGE                 COMMAND                  CREATED          STATUS                            PORTS                    NAMES</span><br><span class="line">71a1400d1e98   amancevice/superset   &quot;gunicorn superset.a…&quot;   10 seconds ago   Up 9 seconds (health: starting)   0.0.0.0:8088-&gt;8088/tcp   quizzical_wright</span><br><span class="line">docker exec -it 71a1400d1e98 superset-init</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>SuperSet</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据技术概论</title>
    <url>/bigdata/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E6%A6%82%E8%AE%BA/</url>
    <content><![CDATA[<h1 id="大数据技术概论"><a href="#大数据技术概论" class="headerlink" title="大数据技术概论"></a>大数据技术概论</h1><p>大数据存储管理：</p>
<ul>
<li>弹性扩展、容错技术</li>
<li>分层存储、索引（Hash、B树、倒排）</li>
<li>弱并发一致性管理</li>
</ul>
<p>单一计算模式不能涵盖所有<br>大数据计算需求<br>• MapReduce并行计算模式<br>• 分布内存抽象RDD<br>• 图计算模式<br>• 流式计算</p>
<p>硬件发展速度</p>
<p>存储墙: CPU性能每两年速度翻倍、硬盘性能每六年速度翻倍</p>
<p>数据访问速度： 磁盘容量增长远快于存储访问带宽</p>
<p>数据分发</p>
<p>并行计算框架发展</p>
<p><img src="../images/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%8F%91%E5%B1%95.png" alt="1557370798476"></p>
<p>1、Java <a href="https://www.bilibili.com/video/av47103781/">av47103781</a><br>2、Spring <a href="https://www.bilibili.com/video/av47103781/?spm_id_from=333.788.b_636f6d6d656e74.7">av47103781</a><br>3、Spring Mvc <a href="https://www.bilibili.com/video/av47176832/">av47176832</a><br>4、MyBatis <a href="https://www.bilibili.com/video/av47228830/">av47228830</a><br>5、Spring Boot <a href="https://www.bilibili.com/video/av47230137/">av47230137</a><br>6、Spring Cloud <a href="https://www.bilibili.com/video/av47228830/">av47228830</a><br>7、Dubbo <a href="https://www.bilibili.com/video/av47009143/">av47009143</a><br>8、MySQL <a href="https://www.bilibili.com/video/av47702905/">av47702905</a><br>9、Redis <a href="https://www.bilibili.com/video/av47423174/">av47423174</a><br>10、MongoDB <a href="https://www.bilibili.com/video/av47425352/">av47425352</a><br>11、Zookeeper <a href="https://www.bilibili.com/video/av47773419/">av47773419</a><br>12、Kafka <a href="https://www.bilibili.com/video/av47773990/">av47773990</a><br>13、Linux <a href="https://www.bilibili.com/video/av47701443/">av47701443</a><br>14、Docker <a href="https://www.bilibili.com/video/av47715282/">av47715282</a><br>15、Maven <a href="https://www.bilibili.com/video/av47382482/">av47382482</a><br>16、Git <a href="https://www.bilibili.com/video/av47701443/">av47701443</a><br>17、Jenkins <a href="https://www.bilibili.com/video/av47714706/">av47714706</a><br>18、IDEA <a href="https://www.bilibili.com/video/av47382482/">av47382482</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>mac搭建hadoop、hive、spark、flink环境</title>
    <url>/bigdata/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h1 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h1><p>启动mysql</p>
<p>brew services start mysql</p>
<p>abc.ABC.123</p>
<h1 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/33117305">mac osx 搭建hadoop开发环境</a></li>
<li><a href="https://blog.csdn.net/u010638969/article/details/51283216">spark on yarn</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/65825211">hive环境搭建</a></li>
</ol>
<p>按照上面文章的方式搭建，启动hdfs、yarn</p>
<p><a href="https://stackoverflow.com/questions/33968422/bin-bash-bin-java-no-such-file-or-directory"><strong>必须使用这个命令</strong></a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动yarn</span></span></span><br><span class="line">hadoop/sbin/./yarn-daemon.sh start resourcemanager</span><br><span class="line">hadoop/sbin./yarn-daemon.sh start nodemanager</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动hdfs</span></span></span><br><span class="line">hadoop/sbin/start-hdfs.sh</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="http://localhost:50070/">hdfs-web</a><br><a href="http://localhost:8088/">yarn-web</a></p>
<h2 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h2><p>create user ‘hadoop’@’%’ identified by ‘hadoop%HADOOP%123’;</p>
<p>grant all privileges on <em>.</em> to ‘hadoop’@’%’ with grant option;</p>
<p>flush privileges;</p>
<h2 id="flink-on-yarn"><a href="#flink-on-yarn" class="headerlink" title="flink on yarn"></a>flink on yarn</h2><p><a href="https://blog.csdn.net/xu470438000/article/details/79576989">flink on yarn部署</a></p>
<p>在flink lib下增加flink-hadoop兼容包<a href="https://repo.maven.apache.org/maven2/org/apache/flink/flink-shaded-hadoop-2-uber/2.7.5-7.0/flink-shaded-hadoop-2-uber-2.7.5-7.0.jar">Pre-bundled Hadoop 2.7.5</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动</span></span><br><span class="line">bin/start-cluster.sh</span><br></pre></td></tr></table></figure>

<h2 id="搭建AthenaX"><a href="#搭建AthenaX" class="headerlink" title="搭建AthenaX"></a>搭建AthenaX</h2><p><a href="https://athenax.readthedocs.io/en/latest/getting_started/">Building AthenaX and Flink</a></p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>RPC</tag>
        <tag>Distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>【草稿】妙极监控设计</title>
    <url>/bigdata/%E7%A7%92%E6%9E%81%E7%9B%91%E6%8E%A7%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h1 id="妙极监控设计"><a href="#妙极监控设计" class="headerlink" title="妙极监控设计"></a>妙极监控设计</h1><p>TDE是一个全内存的分布式KV存储系统，写操作即put单台机器能力为6.6万笔/秒，读操作即get达到38万笔/秒。</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
      </tags>
  </entry>
  <entry>
    <title>时光荏苒，岁月如梭</title>
    <url>/other/meiwen/</url>
    <content><![CDATA[<p>时光荏苒，岁月如梭。素什锦年，稍纵即逝，半载青春年华，似沙漏般，弹指间，流在昨天。苦涩与喜悦，都不再去回忆，依然埋在时光的烟尘里。只知青丝变白发，冥冥之中，注定青春与那寂寞有染。</p>
<p>春去秋来，潮起潮落。往日里，天庭空旷，时光静谧；闲看云雾，静听风雨；可谓悠闲自得，其乐无穷。转眼，又至寂寞时节，秋风抚叶，泛成黄色，落了一地的沧桑；鸟落廊前，轻声一吟，留下几世的凄凉。如花美眷，敌不过似水流年。一切美好，都会悄然褪色，暗自凋零，最后落入尘埃。化作孤独，上了心头。</p>
<p>繁华落尽，乱世成殇。人生似列车，几经周转，穿行了多少过往。世人都是过客，到了青春驿站，转身何去何从。亲人，已挥手离去；朋友，也渐行渐远。风无定人无常，聚散两茫茫，留下寂寞的你我来来往往。看遍了人间繁华，城市的余辉，再美也终将落幕。远方飘来忧伤的夜曲，难得此生相逢，怎料寂寞如歌。待到繁华落尽，在这乱世，成殇。</p>
<p>寂寞流年，染泪红颜。 灯火阑珊，最难将息。下玄月，西风凉，此夜何人眠；别时易，见时难，相思系红颜。弱水三千，只取一瓢；梦有万千，只梦一朝。衣带渐宽，为得伊人憔悴；千年等待，只求揽你入怀。泪如烈酒，灼人心肺，谁知相思，已成灾。</p>
<p>往事成烟，宿命依旧。青春染指流年，流年染指红颜。画地为牢，锁我几春秋，染予寂寞。无奈拾起青春的记忆，等一阵清风扑面，挥挥衣袖，又是潇洒一片。</p>
]]></content>
      <categories>
        <category>wiki</category>
      </categories>
  </entry>
  <entry>
    <title>张氏族谱辈分</title>
    <url>/other/other-family-genealogy/</url>
    <content><![CDATA[<h1 id="问我故乡在何处，山西洪洞大槐树"><a href="#问我故乡在何处，山西洪洞大槐树" class="headerlink" title="问我故乡在何处，山西洪洞大槐树"></a>问我故乡在何处，山西洪洞大槐树</h1><p>据多方家谱记载，大约500年前，明朝靖难之役前后，明朝政府征调山西省洪洞县乡民迁往今河北、山东、河南、湖北、江西等地，史称“大槐树移民”。如今大槐树移民的后裔占这几个省的大部分。<br>移民是被明朝政府所迫，背井离乡，骨肉分离，是我们的祖先所经历的辛酸和苦楚。<br>每当本宗族黑白喜事，总要拿出族谱，勾起对祖先的思念和怜惜, 也让自己徐徐感觉到作为传承人的自豪。</p>
<h1 id="张氏族谱辈分"><a href="#张氏族谱辈分" class="headerlink" title="张氏族谱辈分"></a>张氏族谱辈分</h1><table>
<thead>
<tr>
<th>伟</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
<td>瑾</td>
<td>起</td>
<td>广</td>
</tr>
<tr>
<td>鼐</td>
<td>世</td>
<td>得</td>
<td>士</td>
<td>凤</td>
</tr>
<tr>
<td>国</td>
<td>云</td>
<td>锺</td>
<td>光</td>
<td>亦</td>
</tr>
<tr>
<td>方(思)</td>
<td>玉(欲)</td>
<td>再</td>
<td>显</td>
<td>传</td>
</tr>
<tr>
<td>兴</td>
<td>茂</td>
<td>恒</td>
<td>祚</td>
<td>延</td>
</tr>
<tr>
<td>庆</td>
<td>祥</td>
<td>恩</td>
<td>嘉</td>
<td>澍</td>
</tr>
<tr>
<td>令(零)</td>
<td>儒(罗)</td>
<td>肇(兆)</td>
<td>复(补)</td>
<td>天</td>
</tr>
<tr>
<td>立</td>
<td>志</td>
<td>新</td>
<td>法</td>
<td>邦</td>
</tr>
<tr>
<td>登</td>
<td>殿</td>
<td>瑞</td>
<td>义</td>
<td>祯</td>
</tr>
<tr>
<td>保</td>
<td>善</td>
<td>绪</td>
<td>洪</td>
<td>德</td>
</tr>
<tr>
<td>昌</td>
<td>凡</td>
<td>要</td>
<td>英</td>
<td>先</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>wiki</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>/Java/JavaFx/basic/</url>
    <content><![CDATA[<h1 id="basic"><a href="#basic" class="headerlink" title="basic"></a>basic</h1><h2 id="UI框架"><a href="#UI框架" class="headerlink" title="UI框架"></a>UI框架</h2><ul>
<li><a href="https://github.com/FXMisc/RichTextFX/tree/master/richtextfx-demos">RichTextFx 文本编辑框</a></li>
<li><a href="http://fxexperience.com/controlsfx">ControllsFx</a></li>
<li><a href="http://github.com/jfoenixadmin/JFoenix">JFoenix</a></li>
<li><a href="http://bitbucket.org/Jerady/fontawesomefx">fontawesomefx</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>探索 ConcurrentHashMap 高并发性的实现机制</title>
    <url>/Java/collection/ConcurrentHashMap/</url>
    <content><![CDATA[<p><a href="http://www.ibm.com/developerworks/cn/java/java-lo-concurrenthashmap/index.html">转载自 探索 ConcurrentHashMap 高并发性的实现机制</a></p>
<p>ConcurrentHashMap 是 Java concurrent 包的重要成员。本文将结合 Java 内存模型，来分析 ConcurrentHashMap 的 JDK 源代码。通过本文，读者将了解到 ConcurrentHashMap 高并发性的具体实现机制。这对于我们在实际应用中更加高效的使用它是很有帮助的。</p>
<p>[TOC]</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>ConcurrentHashMap 是 util.concurrent 包的重要成员。本文将结合 Java 内存模型，分析 JDK 源代码，探索 ConcurrentHashMap 高并发的具体实现机制。</p>
<p>由于 ConcurrentHashMap 的源代码实现依赖于 Java 内存模型，所以阅读本文需要读者了解 <a href="/java">Java 内存模型</a>。同时，ConcurrentHashMap 的源代码会涉及到<a href="/hashing">散列算法</a>和链表数据结构，所以，读者需要对散列算法和基于链表的数据结构有所了解。</p>
<h2 id="Java-内存模型"><a href="#Java-内存模型" class="headerlink" title="Java 内存模型"></a>Java 内存模型</h2><p>由于 ConcurrentHashMap 是建立在 Java 内存模型基础上的，为了更好的理解 ConcurrentHashMap，让我们首先来了解一下 Java 的内存模型。</p>
<p>Java 语言的内存模型由一些规则组成，这些规则确定线程对内存的访问如何排序以及何时可以确保它们对线程是可见的。下面我们将分别介绍 Java 内存模型的重排序，内存可见性和 happens-before 关系。</p>
<h3 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h3><p>内存模型描述了程序的可能行为。具体的编译器实现可以产生任意它喜欢的代码 – <strong>只要所有执行这些代码产生的结果，能够和内存模型预测的结果保持一致</strong>。这为编译器实现者提供了很大的自由，包括操作的重排序。</p>
<p>编译器生成指令的次序，可以不同于源代码所暗示的“显然”版本。重排序后的指令，对于优化执行以及成熟的全局寄存器分配算法的使用，都是大有脾益的，它使得程序在计算性能上有了很大的提升。</p>
<p>重排序类型包括：</p>
<ul>
<li>编译器生成指令的次序，可以不同于源代码所暗示的“显然”版本。</li>
<li>处理器可以乱序或者并行的执行指令。</li>
<li>缓存会改变写入提交到主内存的变量的次序。</li>
</ul>
<h3 id="内存可见性"><a href="#内存可见性" class="headerlink" title="内存可见性"></a>内存可见性</h3><p>由于现代可共享内存的多处理器架构可能导致一个线程无法马上（甚至永远）看到另一个线程操作产生的结果。所以 Java 内存模型规定了 JVM 的一种最小保证：什么时候写入一个变量对其他线程可见。</p>
<p>在现代可共享内存的多处理器体系结构中每个处理器都有自己的缓存，并周期性的与主内存协调一致。假设线程 A 写入一个变量值 V，随后另一个线程 B 读取变量 V 的值，在下列情况下，线程 B 读取的值可能不是线程 A 写入的最新值：</p>
<ul>
<li>执行线程 A 的处理器把变量 V 缓存到寄存器中。</li>
<li>执行线程 A 的处理器把变量 V 缓存到自己的缓存中，但还没有同步刷新到主内存中去。</li>
<li>执行线程 B 的处理器的缓存中有变量 V 的旧值。</li>
</ul>
<h3 id="Happens-before-关系"><a href="#Happens-before-关系" class="headerlink" title="Happens-before 关系"></a>Happens-before 关系</h3><p>happens-before 关系保证：如果线程 A 与线程 B 满足 happens-before 关系，则线程 A 执行动作的结果对于线程 B 是可见的。如果两个操作未按 happens-before 排序，JVM 将可以对他们任意重排序。</p>
<p>下面介绍几个与理解 ConcurrentHashMap 有关的 happens-before 关系法则：</p>
<ol>
<li>程序次序法则：如果在程序中，所有动作 A 出现在动作 B 之前，则线程中的每动作 A 都 happens-before 于该线程中的每一个动作 B。</li>
<li>监视器锁法则：对一个监视器的解锁 happens-before 于每个后续对同一监视器的加锁。</li>
<li>Volatile 变量法则：对 Volatile 域的写入操作 happens-before 于每个后续对同一 Volatile 的读操作。</li>
<li>传递性：如果 A happens-before 于 B，且 B happens-before C，则 A happens-before C</li>
</ol>
<h2 id="ConcurrentHashMap-的结构分析"><a href="#ConcurrentHashMap-的结构分析" class="headerlink" title="ConcurrentHashMap 的结构分析"></a>ConcurrentHashMap 的结构分析</h2><p>为了更好的理解 <code>ConcurrentHashMap</code> 高并发的具体实现，让我们先探索它的结构模型。</p>
<p><code>ConcurrentHashMap</code> 类中包含两个静态内部类 <code>HashEntry</code> 和 <code>Segment</code> 。 <code>HashEntry</code> 用来封装映射表的键 / 值对；<code>Segment</code> 用来充当锁的角色，每个 <code>Segment</code> 对象守护整个散列映射表的若干个桶。每个桶是由若干个 <code>HashEntry</code> 对象链接起来的链表。一个 <code>ConcurrentHashMap</code> 实例中包含由若干个 <code>Segment</code> 对象组成的数组。</p>
<h3 id="HashEntry-类"><a href="#HashEntry-类" class="headerlink" title="HashEntry 类"></a>HashEntry 类</h3><p>HashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。</p>
<p>清单 1.HashEntry 类的定义</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">HashEntry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123; </span><br><span class="line">    <span class="keyword">final</span> K key;                       <span class="comment">// 声明 key 为 final 型</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;                   <span class="comment">// 声明 hash 值为 final 型 </span></span><br><span class="line">    <span class="keyword">volatile</span> V value;                 <span class="comment">// 声明 value 为 volatile 型</span></span><br><span class="line">    <span class="keyword">final</span> HashEntry&lt;K,V&gt; next;      <span class="comment">// 声明 next 为 final 型 </span></span><br><span class="line"></span><br><span class="line">    HashEntry(K key, <span class="keyword">int</span> hash, HashEntry&lt;K,V&gt; next, V value) &#123; </span><br><span class="line">        <span class="keyword">this</span>.key = key; </span><br><span class="line">        <span class="keyword">this</span>.hash = hash; </span><br><span class="line">        <span class="keyword">this</span>.next = next; </span><br><span class="line">        <span class="keyword">this</span>.value = value; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。下图是在一个空桶中依次插入 A，B，C 三个 HashEntry 对象后的结构图：</p>
<p><img src="/images/java/Collection_Map/concurrentHashMap_01.jpg"></p>
<p>图 1. 插入三个节点后桶的结构示意图：</p>
<p>注意：由于只能在表头插入，所以链表中节点的顺序和插入的顺序相反。</p>
<p>避免热点域</p>
<p>在 <code>ConcurrentHashMap</code>中，每一个 Segment 对象都有一个 count 对象来表示本 Segment 中包含的 <code>HashEntry</code> 对象的个数。这样当需要更新计数器时，不用锁定整个 <code>ConcurrentHashMap</code>。</p>
<h3 id="Segment-类"><a href="#Segment-类" class="headerlink" title="Segment 类"></a>Segment 类</h3><p>Segment 类继承于 <code>ReentrantLock</code> 类，从而使得 Segment 对象能充当锁的角色。每个 Segment 对象用来守护其（成员对象 table 中）包含的若干个桶。</p>
<p>table 是一个由 HashEntry 对象组成的数组。table 数组的每一个数组成员就是散列映射表的一个桶。</p>
<p>count 变量是一个计数器，它表示每个 Segment 对象管理的 table 数组（若干个 HashEntry 组成的链表）包含的 HashEntry 对象的个数。每一个 Segment 对象都有一个 count 对象来表示本 Segment 中包含的 HashEntry 对象的总数。注意，之所以在每个 Segment 对象中包含一个计数器，而不是在 ConcurrentHashMap 中使用全局的计数器，是为了避免出现“热点域”而影响 ConcurrentHashMap 的并发性。</p>
<p>清单 2.Segment 类的定义</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Segment</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">ReentrantLock</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123; </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 在本 segment 范围内，包含的 HashEntry 元素的个数</span></span><br><span class="line"><span class="comment">     * 该变量被声明为 volatile 型</span></span><br><span class="line"><span class="comment">     */</span> </span><br><span class="line">    <span class="keyword">transient</span> <span class="keyword">volatile</span> <span class="keyword">int</span> count; </span><br><span class="line"></span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * table 被更新的次数</span></span><br><span class="line"><span class="comment">     */</span> </span><br><span class="line">    <span class="keyword">transient</span> <span class="keyword">int</span> modCount; </span><br><span class="line"></span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 当 table 中包含的 HashEntry 元素的个数超过本变量值时，触发 table 的再散列</span></span><br><span class="line"><span class="comment">     */</span> </span><br><span class="line">    <span class="keyword">transient</span> <span class="keyword">int</span> threshold; </span><br><span class="line"></span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * table 是由 HashEntry 对象组成的数组</span></span><br><span class="line"><span class="comment">     * 如果散列时发生碰撞，碰撞的 HashEntry 对象就以链表的形式链接成一个链表</span></span><br><span class="line"><span class="comment">     * table 数组的数组成员代表散列映射表的一个桶</span></span><br><span class="line"><span class="comment">     * 每个 table 守护整个 ConcurrentHashMap 包含桶总数的一部分</span></span><br><span class="line"><span class="comment">     * 如果并发级别为 16，table 则守护 ConcurrentHashMap 包含的桶总数的 1/16 </span></span><br><span class="line"><span class="comment">     */</span> </span><br><span class="line">    <span class="keyword">transient</span> <span class="keyword">volatile</span> HashEntry&lt;K,V&gt;[] table; </span><br><span class="line"></span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 装载因子</span></span><br><span class="line"><span class="comment">     */</span> </span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">float</span> loadFactor; </span><br><span class="line"></span><br><span class="line">    Segment(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> lf) &#123; </span><br><span class="line">        loadFactor = lf; </span><br><span class="line">        setTable(HashEntry.&lt;K,V&gt;newArray(initialCapacity)); </span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 设置 table 引用到这个新生成的 HashEntry 数组</span></span><br><span class="line"><span class="comment">     * 只能在持有锁或构造函数中调用本方法</span></span><br><span class="line"><span class="comment">     */</span> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setTable</span><span class="params">(HashEntry&lt;K,V&gt;[] newTable)</span> </span>&#123; </span><br><span class="line">        <span class="comment">// 计算临界阀值为新数组的长度与装载因子的乘积</span></span><br><span class="line">        threshold = (<span class="keyword">int</span>)(newTable.length * loadFactor); </span><br><span class="line">        table = newTable; </span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 根据 key 的散列值，找到 table 中对应的那个桶（table 数组的某个数组成员）</span></span><br><span class="line"><span class="comment">     */</span> </span><br><span class="line">    <span class="function">HashEntry&lt;K,V&gt; <span class="title">getFirst</span><span class="params">(<span class="keyword">int</span> hash)</span> </span>&#123; </span><br><span class="line">        HashEntry&lt;K,V&gt;[] tab = table; </span><br><span class="line">        <span class="comment">// 把散列值与 table 数组长度减 1 的值相“与”，</span></span><br><span class="line">        <span class="comment">// 得到散列值对应的 table 数组的下标</span></span><br><span class="line">        <span class="comment">// 然后返回 table 数组中此下标对应的 HashEntry 元素</span></span><br><span class="line">        <span class="keyword">return</span> tab[hash &amp; (tab.length - <span class="number">1</span>)]; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下图是依次插入 ABC 三个 HashEntry 节点后，Segment 的结构示意图。</p>
<p><img src="/images/java/Collection_Map/concurrentHashMap_02.jpg"></p>
<p>图 2. 插入三个节点后 Segment 的结构示意图：</p>
<h3 id="ConcurrentHashMap-类"><a href="#ConcurrentHashMap-类" class="headerlink" title="ConcurrentHashMap 类"></a>ConcurrentHashMap 类</h3><p>ConcurrentHashMap 在默认并发级别会创建包含 16 个 Segment 对象的数组。每个 Segment 的成员对象 table 包含若干个散列表的桶。每个桶是由 HashEntry 链接起来的一个链表。如果键能均匀散列，每个 Segment 大约守护整个散列表中桶总数的 1/16。</p>
<p>清单 3.ConcurrentHashMap 类的定义</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcurrentHashMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span></span><br><span class="line"><span class="class">       <span class="keyword">implements</span> <span class="title">ConcurrentMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt;, <span class="title">Serializable</span> </span>&#123; </span><br><span class="line"></span><br><span class="line">   <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * 散列映射表的默认初始容量为 16，即初始默认为 16 个桶</span></span><br><span class="line"><span class="comment">    * 在构造函数中没有指定这个参数时，使用本参数</span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">   <span class="keyword">static</span> <span class="keyword">final</span> 	 <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY= <span class="number">16</span>; </span><br><span class="line"></span><br><span class="line">   <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * 散列映射表的默认装载因子为 0.75，该值是 table 中包含的 HashEntry 元素的个数与</span></span><br><span class="line"><span class="comment">* table 数组长度的比值</span></span><br><span class="line"><span class="comment">    * 当 table 中包含的 HashEntry 元素的个数超过了 table 数组的长度与装载因子的乘积时，</span></span><br><span class="line"><span class="comment">* 将触发 再散列</span></span><br><span class="line"><span class="comment">    * 在构造函数中没有指定这个参数时，使用本参数</span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">   <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR= <span class="number">0.75f</span>; </span><br><span class="line"></span><br><span class="line">   <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * 散列表的默认并发级别为 16。该值表示当前更新线程的估计数</span></span><br><span class="line"><span class="comment">    * 在构造函数中没有指定这个参数时，使用本参数</span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">   <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CONCURRENCY_LEVEL= <span class="number">16</span>; </span><br><span class="line"></span><br><span class="line">   <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * segments 的掩码值</span></span><br><span class="line"><span class="comment">    * key 的散列码的高位用来选择具体的 segment </span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">   <span class="keyword">final</span> <span class="keyword">int</span> segmentMask; </span><br><span class="line"></span><br><span class="line">   <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * 偏移量</span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">   <span class="keyword">final</span> <span class="keyword">int</span> segmentShift; </span><br><span class="line"></span><br><span class="line">   <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * 由 Segment 对象组成的数组</span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">   <span class="keyword">final</span> Segment&lt;K,V&gt;[] segments; </span><br><span class="line"></span><br><span class="line">   <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * 创建一个带有指定初始容量、加载因子和并发级别的新的空映射。</span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, </span></span></span><br><span class="line"><span class="function"><span class="params">                            <span class="keyword">float</span> loadFactor, <span class="keyword">int</span> concurrencyLevel)</span> </span>&#123; </span><br><span class="line">       <span class="keyword">if</span>(!(loadFactor &gt; <span class="number">0</span>) || initialCapacity &lt; <span class="number">0</span> || </span><br><span class="line">concurrencyLevel &lt;= <span class="number">0</span>) </span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(); </span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span>(concurrencyLevel &gt; MAX_SEGMENTS) </span><br><span class="line">           concurrencyLevel = MAX_SEGMENTS; </span><br><span class="line"></span><br><span class="line">       <span class="comment">// 寻找最佳匹配参数（不小于给定参数的最接近的 2 次幂） </span></span><br><span class="line">       <span class="keyword">int</span> sshift = <span class="number">0</span>; </span><br><span class="line">       <span class="keyword">int</span> ssize = <span class="number">1</span>; </span><br><span class="line">       <span class="keyword">while</span>(ssize &lt; concurrencyLevel) &#123; </span><br><span class="line">           ++sshift; </span><br><span class="line">           ssize &lt;&lt;= <span class="number">1</span>; </span><br><span class="line">       &#125; </span><br><span class="line">       segmentShift = <span class="number">32</span> - sshift;       <span class="comment">// 偏移量值</span></span><br><span class="line">       segmentMask = ssize - <span class="number">1</span>;           <span class="comment">// 掩码值 </span></span><br><span class="line">       <span class="keyword">this</span>.segments = Segment.newArray(ssize);   <span class="comment">// 创建数组</span></span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY) </span><br><span class="line">           initialCapacity = MAXIMUM_CAPACITY; </span><br><span class="line">       <span class="keyword">int</span> c = initialCapacity / ssize; </span><br><span class="line">       <span class="keyword">if</span>(c * ssize &lt; initialCapacity) </span><br><span class="line">           ++c; </span><br><span class="line">       <span class="keyword">int</span> cap = <span class="number">1</span>; </span><br><span class="line">       <span class="keyword">while</span>(cap &lt; c) </span><br><span class="line">           cap &lt;&lt;= <span class="number">1</span>; </span><br><span class="line"></span><br><span class="line">       <span class="comment">// 依次遍历每个数组元素</span></span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.segments.length; ++i) </span><br><span class="line">           <span class="comment">// 初始化每个数组元素引用的 Segment 对象</span></span><br><span class="line"><span class="keyword">this</span>.segments[i] = <span class="keyword">new</span> Segment&lt;K,V&gt;(cap, loadFactor); </span><br><span class="line">   &#125; </span><br><span class="line"></span><br><span class="line">   <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * 创建一个带有默认初始容量 (16)、默认加载因子 (0.75) 和 默认并发级别 (16) </span></span><br><span class="line"><span class="comment"> * 的空散列映射表。</span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMap</span><span class="params">()</span> </span>&#123; </span><br><span class="line">       <span class="comment">// 使用三个默认参数，调用上面重载的构造函数来创建空散列映射表</span></span><br><span class="line"><span class="keyword">this</span>(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>}</p>
<p>下面是 ConcurrentHashMap 的结构示意图。</p>
<p><img src="/images/java/Collection_Map/concurrentHashMap_03.jpg"></p>
<p>图 3.ConcurrentHashMap 的结构示意图：</p>
<h2 id="用分离锁实现多个线程间的并发写操作"><a href="#用分离锁实现多个线程间的并发写操作" class="headerlink" title="用分离锁实现多个线程间的并发写操作"></a>用分离锁实现多个线程间的并发写操作</h2><p>在 ConcurrentHashMap 中，线程对映射表做读操作时，<em>一般情况下</em>不需要加锁就可以完成，对容器做结构性修改的操作才需要加锁。下面以 put 操作为例说明对 ConcurrentHashMap 做结构性修改的过程。</p>
<p>首先，根据 key 计算出对应的 hash 值：</p>
<p>清单 4.Put 方法的实现</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">if</span> (value == <span class="keyword">null</span>)          <span class="comment">//ConcurrentHashMap 中不允许用 null 作为映射值</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(); </span><br><span class="line">    <span class="keyword">int</span> hash = hash(key.hashCode());        <span class="comment">// 计算键对应的散列码</span></span><br><span class="line">    <span class="comment">// 根据散列码找到对应的 Segment </span></span><br><span class="line">    <span class="keyword">return</span> segmentFor(hash).put(key, hash, value, <span class="keyword">false</span>); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后，根据 hash 值找到对应的<code>Segment</code> 对象：</p>
<p>清单 5.根据 hash 值找到对应的 Segment</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 使用 key 的散列码来得到 segments 数组中对应的 Segment </span></span><br><span class="line"><span class="comment"> */</span> </span><br><span class="line"><span class="function"><span class="keyword">final</span> Segment&lt;K,V&gt; <span class="title">segmentFor</span><span class="params">(<span class="keyword">int</span> hash)</span> </span>&#123; </span><br><span class="line"><span class="comment">// 将散列值右移 segmentShift 个位，并在高位填充 0 </span></span><br><span class="line"><span class="comment">// 然后把得到的值与 segmentMask 相“与”</span></span><br><span class="line"><span class="comment">// 从而得到 hash 值对应的 segments 数组的下标值</span></span><br><span class="line"><span class="comment">// 最后根据下标值返回散列码对应的 Segment 对象</span></span><br><span class="line">    <span class="keyword">return</span> segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后，在这个 Segment 中执行具体的 put 操作：</p>
<p>清单 6.在 Segment 中执行具体的 put 操作</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">V <span class="title">put</span><span class="params">(K key, <span class="keyword">int</span> hash, V value, <span class="keyword">boolean</span> onlyIfAbsent)</span> </span>&#123; </span><br><span class="line">    lock();  <span class="comment">// 加锁，这里是锁定某个 Segment 对象而非整个 ConcurrentHashMap </span></span><br><span class="line">    <span class="keyword">try</span> &#123; </span><br><span class="line">        <span class="keyword">int</span> c = count; </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (c++ &gt; threshold)     <span class="comment">// 如果超过再散列的阈值</span></span><br><span class="line">            rehash();              <span class="comment">// 执行再散列，table 数组的长度将扩充一倍</span></span><br><span class="line"></span><br><span class="line">        HashEntry&lt;K,V&gt;[] tab = table; </span><br><span class="line">        <span class="comment">// 把散列码值与 table 数组的长度减 1 的值相“与”</span></span><br><span class="line">        <span class="comment">// 得到该散列码对应的 table 数组的下标值</span></span><br><span class="line">        <span class="keyword">int</span> index = hash &amp; (tab.length - <span class="number">1</span>); </span><br><span class="line">        <span class="comment">// 找到散列码对应的具体的那个桶</span></span><br><span class="line">        HashEntry&lt;K,V&gt; first = tab[index]; </span><br><span class="line"></span><br><span class="line">        HashEntry&lt;K,V&gt; e = first; </span><br><span class="line">        <span class="keyword">while</span> (e != <span class="keyword">null</span> &amp;&amp; (e.hash != hash || !key.equals(e.key))) </span><br><span class="line">            e = e.next; </span><br><span class="line"></span><br><span class="line">        V oldValue; </span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;            <span class="comment">// 如果键 / 值对以经存在</span></span><br><span class="line">            oldValue = e.value; </span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent) </span><br><span class="line">                e.value = value;    <span class="comment">// 设置 value 值</span></span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">else</span> &#123;                        <span class="comment">// 键 / 值对不存在 </span></span><br><span class="line">            oldValue = <span class="keyword">null</span>; </span><br><span class="line">            ++modCount;         <span class="comment">// 要添加新节点到链表中，所以 modCont 要加 1  </span></span><br><span class="line">            <span class="comment">// 创建新节点，并添加到链表的头部 </span></span><br><span class="line">            tab[index] = <span class="keyword">new</span> HashEntry&lt;K,V&gt;(key, hash, first, value); </span><br><span class="line">            count = c;               <span class="comment">// 写 count 变量</span></span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">return</span> oldValue; </span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123; </span><br><span class="line">        unlock();                     <span class="comment">// 解锁</span></span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意：<br>这里的加锁操作是针对（键的 hash 值对应的）某个具体的 Segment，锁定的是该 <code>Segment</code> 而不是整个 <code>ConcurrentHashMap</code>。因为插入键 / 值对操作只是在这个 Segment 包含的某个桶中完成，不需要锁定整个<code>ConcurrentHashMap</code>。此时，其他写线程对另外 15 个<code>Segment</code> 的加锁并不会因为当前线程对这个 Segment 的加锁而阻塞。同时，所有读线程几乎不会因本线程的加锁而阻塞（除非读线程刚好读到这个 Segment 中某个 <code>HashEntry</code> 的 <code>value</code> 域的值为 null，此时需要加锁后重新读取该值）。</p>
<p>相比较于 <code>HashTable</code> 和由同步包装器包装的 <code>HashMap</code>每次只能有一个线程执行读或写操作，<code>ConcurrentHashMap</code> 在并发访问性能上有了质的提高。<em>在理想状态下</em>，ConcurrentHashMap 可以支持 16 个线程执行并发写操作（如果并发级别设置为 16），及任意数量线程的读操作。</p>
<h2 id="用-HashEntery-对象的不变性来降低读操作对加锁的需求"><a href="#用-HashEntery-对象的不变性来降低读操作对加锁的需求" class="headerlink" title="用 HashEntery 对象的不变性来降低读操作对加锁的需求"></a>用 HashEntery 对象的不变性来降低读操作对加锁的需求</h2><p>在代码清单“HashEntry 类的定义”中我们可以看到，HashEntry 中的 key，hash，next 都声明为 final 型。这意味着，不能把节点添加到链接的中间和尾部，也不能在链接的中间和尾部删除节点。这个特性可以保证：在访问某个节点时，这个节点之后的链接不会被改变。这个特性可以大大降低处理链表时的复杂性。</p>
<p>同时，HashEntry 类的 value 域被声明为 Volatile 型，Java 的内存模型可以保证：某个写线程对 value 域的写入马上可以被后续的某个读线程“看”到。在 ConcurrentHashMap 中，不允许用 null 作为键和值，<strong>当读线程读到某个 HashEntry 的 value 域的值为 null 时，便知道产生了冲突——发生了重排序现象，需要加锁后重新读入这个 value 值。</strong>这些特性互相配合，使得读线程即使在不加锁状态下，也能正确访问 ConcurrentHashMap。</p>
<p>下面我们分别来分析线程写入的两种情形：对散列表做非结构性修改的操作和对散列表做结构性修改的操作。</p>
<p>非结构性修改操作只是更改某个 HashEntry 的 value 域的值。由于对 Volatile 变量的写入操作将与随后对这个变量的读操作进行同步。当一个写线程修改了某个 HashEntry 的 value 域后，另一个读线程读这个值域，Java 内存模型能够保证读线程读取的一定是更新后的值。所以，写线程对链表的非结构性修改能够被后续不加锁的读线程“看到”。</p>
<p>对 ConcurrentHashMap 做结构性修改，实质上是对某个桶指向的链表做结构性修改。如果能够确保：在读线程遍历一个链表期间，写线程对这个链表所做的结构性修改不影响读线程继续正常遍历这个链表。那么读 / 写线程之间就可以安全并发访问这个 ConcurrentHashMap。</p>
<p>结构性修改操作包括 put，remove，clear。下面我们分别分析这三个操作。</p>
<p>clear 操作只是把 ConcurrentHashMap 中所有的桶“置空”，每个桶之前引用的链表依然存在，只是桶不再引用到这些链表（所有链表的结构并没有被修改）。正在遍历某个链表的读线程依然可以正常执行对该链表的遍历。</p>
<p>从上面的代码清单“在 Segment 中执行具体的 put 操作”中，我们可以看出：put 操作如果需要插入一个新节点到链表中时 , 会在链表头部插入这个新节点。此时，链表中的原有节点的链接并没有被修改。也就是说：插入新健 / 值对到链表中的操作不会影响读线程正常遍历这个链表。</p>
<p>下面来分析 remove 操作，先让我们来看看 remove 操作的源代码实现。</p>
<p>清单 7.remove 操作</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">V <span class="title">remove</span><span class="params">(Object key, <span class="keyword">int</span> hash, Object value)</span> </span>&#123; </span><br><span class="line">lock();         <span class="comment">// 加锁</span></span><br><span class="line"><span class="keyword">try</span>&#123; </span><br><span class="line">    <span class="keyword">int</span> c = count - <span class="number">1</span>; </span><br><span class="line">    HashEntry&lt;K,V&gt;[] tab = table; </span><br><span class="line">    <span class="comment">// 根据散列码找到 table 的下标值</span></span><br><span class="line">    <span class="keyword">int</span> index = hash &amp; (tab.length - <span class="number">1</span>); </span><br><span class="line">    <span class="comment">// 找到散列码对应的那个桶</span></span><br><span class="line">    HashEntry&lt;K,V&gt; first = tab[index]; </span><br><span class="line">    HashEntry&lt;K,V&gt; e = first; </span><br><span class="line">    <span class="keyword">while</span>(e != <span class="keyword">null</span>&amp;&amp; (e.hash != hash || !key.equals(e.key))) </span><br><span class="line">        e = e.next; </span><br><span class="line"></span><br><span class="line">    V oldValue = <span class="keyword">null</span>; </span><br><span class="line">    <span class="keyword">if</span>(e != <span class="keyword">null</span>) &#123; </span><br><span class="line">        V v = e.value; </span><br><span class="line">        <span class="keyword">if</span>(value == <span class="keyword">null</span>|| value.equals(v)) &#123; <span class="comment">// 找到要删除的节点</span></span><br><span class="line">            oldValue = v; </span><br><span class="line">            ++modCount; </span><br><span class="line">            <span class="comment">// 所有处于待删除节点之后的节点原样保留在链表中</span></span><br><span class="line">            <span class="comment">// 所有处于待删除节点之前的节点被克隆到新链表中</span></span><br><span class="line">            HashEntry&lt;K,V&gt; newFirst = e.next;<span class="comment">// 待删节点的后继结点</span></span><br><span class="line">            <span class="keyword">for</span>(HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) </span><br><span class="line">                newFirst = <span class="keyword">new</span> HashEntry&lt;K,V&gt;(p.key, p.hash, </span><br><span class="line">                                              newFirst, p.value); </span><br><span class="line">            <span class="comment">// 把桶链接到新的头结点</span></span><br><span class="line">            <span class="comment">// 新的头结点是原链表中，删除节点之前的那个节点</span></span><br><span class="line">            tab[index] = newFirst; </span><br><span class="line">            count = c;      <span class="comment">// 写 count 变量</span></span><br><span class="line">        &#125; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">return</span> oldValue; </span><br><span class="line">&#125; <span class="keyword">finally</span>&#123; </span><br><span class="line">    unlock();               <span class="comment">// 解锁</span></span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和 get 操作一样，首先根据散列码找到具体的链表；然后遍历这个链表找到要删除的节点；最后把待删除节点之后的所有节点原样保留在新链表中，把待删除节点之前的每个节点克隆到新链表中。下面通过图例来说明 remove 操作。假设写线程执行 remove 操作，要删除链表的 C 节点，另一个读线程同时正在遍历这个链表。</p>
<p><img src="/images/java/Collection_Map/concurrentHashMap_04.jpg"></p>
<p>图 4. 执行删除之前的原链表：</p>
<p><img src="/images/java/Collection_Map/concurrentHashMap_05.jpg"></p>
<p>图 5. 执行删除之后的新链表</p>
<p>从上图可以看出，删除节点 C 之后的所有节点原样保留到新链表中；删除节点 C 之前的每个节点被克隆到新链表中，<em>注意：它们在新链表中的链接顺序被反转了</em>。</p>
<p>在执行 remove 操作时，原始链表并没有被修改，也就是说：读线程不会受同时执行 remove 操作的并发写线程的干扰。</p>
<p>综合上面的分析我们可以看出，写线程对某个链表的结构性修改不会影响其他的并发读线程对这个链表的遍历访问。</p>
<h2 id="用-Volatile-变量协调读写线程间的内存可见性"><a href="#用-Volatile-变量协调读写线程间的内存可见性" class="headerlink" title="用 Volatile 变量协调读写线程间的内存可见性"></a>用 Volatile 变量协调读写线程间的内存可见性</h2><p>由于内存可见性问题，未正确同步的情况下，写线程写入的值可能并不为后续的读线程可见。</p>
<p>下面以写线程 M 和读线程 N 来说明 ConcurrentHashMap 如何协调读 / 写线程间的内存可见性问题。</p>
<p>图 6. 协调读 - 写线程间的内存可见性的示意图：</p>
<p><img src="/images/java/Collection_Map/concurrentHashMap_06.jpg"></p>
<p>假设线程 M 在写入了 volatile 型变量 count 后，线程 N 读取了这个 volatile 型变量 count。</p>
<p>根据 happens-before 关系法则中的程序次序法则，A appens-before 于 B，C happens-before D。</p>
<p>根据 Volatile 变量法则，B happens-before C。</p>
<p>根据传递性，连接上面三个 happens-before 关系得到：A appens-before 于 B； B appens-before C；C happens-before D。也就是说：写线程 M 对链表做的结构性修改，在读线程 N 读取了同一个 volatile 变量后，对线程 N 也是可见的了。</p>
<p>虽然线程 N 是在未加锁的情况下访问链表。Java 的内存模型可以保证：只要之前对链表做结构性修改操作的写线程 M 在退出写方法前写 volatile 型变量 count，读线程 N 在读取这个 volatile 型变量 count 后，就一定能“看到”这些修改。</p>
<p>ConcurrentHashMap 中，每个 Segment 都有一个变量 count。它用来统计 Segment 中的 HashEntry 的个数。这个变量被声明为 volatile。</p>
<p>清单 8.Count 变量的声明</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">transient</span> <span class="keyword">volatile</span> <span class="keyword">int</span> count;</span><br></pre></td></tr></table></figure>
<p> 所有不加锁读方法，在进入读方法时，首先都会去读这个 count 变量。比如下面的 get 方法：</p>
<p>清单 9.get 操作</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">V <span class="title">get</span><span class="params">(Object key, <span class="keyword">int</span> hash)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(count != <span class="number">0</span>) &#123;       <span class="comment">// 首先读 count 变量</span></span><br><span class="line">        HashEntry&lt;K,V&gt; e = getFirst(hash); </span><br><span class="line">        <span class="keyword">while</span>(e != <span class="keyword">null</span>) &#123; </span><br><span class="line">            <span class="keyword">if</span>(e.hash == hash &amp;&amp; key.equals(e.key)) &#123; </span><br><span class="line">                V v = e.value; </span><br><span class="line">                <span class="keyword">if</span>(v != <span class="keyword">null</span>)            </span><br><span class="line">                    <span class="keyword">return</span> v; </span><br><span class="line">                <span class="comment">// 如果读到 value 域为 null，说明发生了重排序，加锁后重新读取</span></span><br><span class="line">                <span class="keyword">return</span> readValueUnderLock(e); </span><br><span class="line">            &#125; </span><br><span class="line">            e = e.next; </span><br><span class="line">        &#125; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 ConcurrentHashMap 中，所有执行写操作的方法（put, remove, clear），在对链表做结构性修改之后，在退出写方法前都会去写这个 count 变量。所有未加锁的读操作（get, contains, containsKey）在读方法中，都会首先去读取这个 count 变量。</p>
<p>根据 Java 内存模型，对 同一个 volatile 变量的写 / 读操作可以确保：写线程写入的值，能够被之后未加锁的读线程“看到”。</p>
<p>这个特性和前面介绍的 HashEntry 对象的不变性相结合，使得在 ConcurrentHashMap 中，读线程在读取散列表时，基本不需要加锁就能成功获得需要的值。这两个特性相配合，不仅减少了请求同一个锁的频率（读操作一般不需要加锁就能够成功获得值），也减少了持有同一个锁的时间（只有读到 value 域的值为 null 时 , 读线程才需要加锁后重读）。</p>
<h2 id="ConcurrentHashMap-实现高并发的总结"><a href="#ConcurrentHashMap-实现高并发的总结" class="headerlink" title="ConcurrentHashMap 实现高并发的总结"></a>ConcurrentHashMap 实现高并发的总结</h2><h3 id="基于通常情形而优化"><a href="#基于通常情形而优化" class="headerlink" title="基于通常情形而优化"></a>基于通常情形而优化</h3><p>在实际的应用中，散列表一般的应用场景是：除了少数插入操作和删除操作外，绝大多数都是读取操作，而且读操作在大多数时候都是成功的。正是基于这个前提，ConcurrentHashMap 针对读操作做了大量的优化。通过 HashEntry 对象的不变性和用 volatile 型变量协调线程间的内存可见性，使得 大多数时候，读操作不需要加锁就可以正确获得值。这个特性使得 ConcurrentHashMap 的并发性能在分离锁的基础上又有了近一步的提高。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>ConcurrentHashMap 是一个并发散列映射表的实现，它允许完全并发的读取，并且支持给定数量的并发更新。相比于 <code>HashTable 和</code>用同步包装器包装的 HashMap（Collections.synchronizedMap(new HashMap())），ConcurrentHashMap 拥有更高的并发性。在 HashTable 和由同步包装器包装的 HashMap 中，使用一个全局的锁来同步不同线程间的并发访问。同一时间点，只能有一个线程持有锁，也就是说在同一时间点，只能有一个线程能访问容器。这虽然保证多线程间的安全并发访问，但同时也导致对容器的访问变成<code>串行化</code>的了。</p>
<p>在使用锁来协调多线程间并发访问的模式下，减小对锁的竞争可以有效提高并发性。有两种方式可以减小对锁的竞争：</p>
<ol>
<li>减小请求 同一个锁的 频率。</li>
<li>减少持有锁的 时间。</li>
</ol>
<p>ConcurrentHashMap 的高并发性主要来自于三个方面：</p>
<ol>
<li>用分离锁实现多个线程间的更深层次的共享访问。</li>
<li>用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。</li>
<li>通过对同一个 Volatile 变量的写/读访问，协调不同线程间读/写操作的内存可见性。</li>
</ol>
<p>使用分离锁，减小了请求 <em>同一个锁</em> 的频率。</p>
<p>通过 HashEntery 对象的不变性及对同一个 Volatile 变量的读/写来协调内存可见性，使得 读操作大多数时候不需要加锁就能成功获取到需要的值。由于散列映射表在实际应用中大多数操作都是成功的 读操作，所以 2 和 3 既可以减少请求同一个锁的频率，也可以有效减少持有锁的时间。</p>
<p>通过减小请求同一个锁的频率和尽量减少持有锁的时间 ，使得 ConcurrentHashMap 的并发性相对于 HashTable 和<code>用同步包装器包装的 HashMap</code>有了质的提高。</p>
<h2 id="Java-8中的优化"><a href="#Java-8中的优化" class="headerlink" title="Java 8中的优化"></a>Java 8中的优化</h2><p>参考文献</p>
<hr>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Collection</tag>
        <tag>Map</tag>
        <tag>ConcurrentHashMap</tag>
        <tag>Hash</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/Java/collection/ConcurrentSkipListMap/</url>
    <content><![CDATA[<h1 id="基于跳跃表的-ConcurrentSkipListMap-内部实现（Java-8）"><a href="#基于跳跃表的-ConcurrentSkipListMap-内部实现（Java-8）" class="headerlink" title="基于跳跃表的 ConcurrentSkipListMap 内部实现（Java 8）"></a>基于跳跃表的 ConcurrentSkipListMap 内部实现（Java 8）</h1><p>我们知道 HashMap 是一种键值对形式的数据存储容器，但是它有一个缺点是，元素内部无序。由于它内部根据键的 hash 值取模表容量来得到元素的存储位置，所以整体上说 HashMap 是无序的一种容器。当然，jdk 中也为我们提供了基于红黑树的存储的 TreeMap 容器，它的内部元素是有序的，但是由于它内部通过红黑结点的各种变换来维持二叉搜索树的平衡，相对复杂，并且在并发环境下碍于 rebalance 操作，性能会受到一定的影响。</p>
<p>跳表（SkipList）是一种随机化的数据结构，通过“空间来换取时间”的一个算法，建立多级索引，实现以二分查找遍历一个有序链表。时间复杂度等同于红黑树，O(log n)。但实现却远远比红黑树要简单，本篇我们主要从以下几个方面来对这种并发版本的数据结构进行学习：</p>
<ul>
<li>跳跃表的数据结构介绍</li>
<li>ConcurrentSkipListMap 的前导知识预备</li>
<li>基本的成员属性介绍</li>
<li>put 方法并发添加</li>
<li>remove 方法的并发删除</li>
<li>get 方法获取指定结点的 value</li>
<li>其它的一些方法的简单描述</li>
</ul>
<h2 id="一、跳跃表的数据结构介绍"><a href="#一、跳跃表的数据结构介绍" class="headerlink" title="一、跳跃表的数据结构介绍"></a>一、跳跃表的数据结构介绍</h2><p><img src="_v_images/20200819194446142_966009886" alt="这里写图片描述"></p>
<p>跳跃表具有以下几个必备的性质：</p>
<ul>
<li>最底层包含所有节点的一个有序的链表</li>
<li>每一层都是一个有序的链表</li>
<li>每个节点都有两个指针，一个指向右侧节点（没有则为空），一个指向下层节点（没有则为空）</li>
<li>必备一个头节点指向最高层的第一个节点，通过它可以遍历整张表</li>
</ul>
<p>当我们查找一个元素的时候就是这样的：</p>
<p><img src="_v_images/20200819194445937_815191891" alt="这里写图片描述"></p>
<p>查找的过程有点像我们的二分查找，不过这里我们是通过为链表建立多级索引，以空间换时间来实现二分查找。所以，跳表的查询操作的时间复杂度为 O(logN)。</p>
<p>接着我们看看跳表的插入操作：<br>首先，跳表的插入必然会在底层增加一个节点，但是往上的层次是否需要增加节点则完全是随机的，SkipList 通过概率保证整张表的节点分布均匀，它不像红黑树是通过人为的 rebalance 操作来保证二叉树的平衡性。（数学对于计算机还是很重要的）。</p>
<p>通过概率算法得到新插入节点的一个 level 值，如果小于当前表的最大 level，从最底层到 level 层都添加一个该节点。例如：</p>
<p><img src="_v_images/20200819194445733_1944248029" alt="这里写图片描述"></p>
<p>如图，首先 119 节点会被添加到最底层链表的合适位置，然后通过概率算法得到 level 为 2，于是 1—level 层中的每一层都添加了 119 节点。</p>
<p>如果概率算法得到的 level 大于当前表的最大 level 值的话，那么将会新增一个 level，并且将新节点添加到该 level 上。</p>
<p><img src="_v_images/20200819194445529_52135211" alt="这里写图片描述"></p>
<p>跳表的删除操作其实就是一个查找加删除节点的操作</p>
<p><img src="_v_images/20200819194445324_1213153640" alt="这里写图片描述"></p>
<p>好了，有关跳表这种数据结构的基本理论知识已经简单的介绍了，下面我们看 jdk 中对该数据结构的基本实现情况，并了解它的并发版本是如何实现的。</p>
<h2 id="二、ConcurrentSkipListMap-的前导知识预备"><a href="#二、ConcurrentSkipListMap-的前导知识预备" class="headerlink" title="二、ConcurrentSkipListMap 的前导知识预备"></a>二、ConcurrentSkipListMap 的前导知识预备</h2><p>在实际分析 put 方法之前，有一些预备的知识我们需要先有个大致的了解，否则在实际分析源码的时候会感觉吃力些。</p>
<p>首先是删除操作，在我们上述的跳表数据结构中谈及的删除操作主要是定位待删结点+删除该结点的一个复合操作。而在我们的并发跳表中，删除操作相对复杂点，需要分为以下三个步骤：</p>
<ul>
<li>找到待删结点并将其 value 属性值由 notnull 置为 null，整个过程是基于 CAS 无锁式算法的</li>
<li>向待删结点的 next 位置新增一个 marker 标记结点，整个过程也是基于 CAS 无锁式算法</li>
<li>CAS 式删除具体的结点，实际上也就是跳过该待删结点，让待删结点的前驱节点直接越过本身指向待删结点的后继结点即可</li>
</ul>
<p>例如我们有以下三个结点，n 为待删除的结点。</p>
<blockquote>
<p>+------+ +------+ +——+<br>… | b |——&gt;| n |—–&gt;| f | …<br>+------+ +------+ +——+</p>
</blockquote>
<p>第一步是找到 n ，然后 CAS 该结点的 value 值为 null。如果该步骤失败了，那么 ConcurrentSkipListMap 会通过循环再次尝试 CAS 将 n 的 value 属性赋值为 null。</p>
<p>第二步是建立在第一步成功的前提下的，n 的当前 value 属性的值为 null，ConcurrentSkipListMap 试图在 n 的后面增加一个空的 node 结点（marker）以分散下一步的并发冲突性。</p>
<blockquote>
<p>+------+ +------+ +------+ +——+<br>… | b |——&gt;| n |—–&gt;|marker|—-&gt;| f | …<br>+------+ +------+ +------+ +——+</p>
</blockquote>
<p>第三步，断链操作。如果 marker 添加失败，将不会有第三步，直接回重新回到第一步。如果成功添加，那么将试图断开 b 到 n 的链接，直接绕过 n，让 b 的 next 指向 f。那么，这个 n 结点将作为内存中的一个游离结点，最终被 GC 掉。断开失败的话，也将回到第一步。</p>
<blockquote>
<p>+------+ +——+<br>… | b |———————–&gt;| f | …<br>+------+ +——+</p>
</blockquote>
<p>主要还是有关删除这方面的预备知识，其它的信息点我们将从实际方法的源码中再进行分析。</p>
<h2 id="三、基本的成员属性介绍"><a href="#三、基本的成员属性介绍" class="headerlink" title="三、基本的成员属性介绍"></a>三、基本的成员属性介绍</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="keyword">volatile</span> Object value;</span><br><span class="line">    <span class="keyword">volatile</span> Node&lt;K,V&gt; next;</span><br><span class="line"></span><br><span class="line">    Node(K key, Object value, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.next = next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//省略其它的一些基于当前结点的 CAS 方法</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这是 node 结点类型的定义，是最基本的数据存储单元。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Index</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;K,V&gt; node;</span><br><span class="line">    <span class="keyword">final</span> Index&lt;K,V&gt; down;</span><br><span class="line">    <span class="keyword">volatile</span> Index&lt;K,V&gt; right;</span><br><span class="line"></span><br><span class="line">    Index(Node&lt;K,V&gt; node, Index&lt;K,V&gt; down, Index&lt;K,V&gt; right) &#123;</span><br><span class="line">        <span class="keyword">this</span>.node = node;</span><br><span class="line">        <span class="keyword">this</span>.down = down;</span><br><span class="line">        <span class="keyword">this</span>.right = right;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//省略其它的一些基于当前结点的 CAS 方法</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Index 结点封装了 node 结点，作为跳表的最基本组成单元。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">HeadIndex</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Index</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> level;</span><br><span class="line">    HeadIndex(Node&lt;K,V&gt; node, Index&lt;K,V&gt; down, Index&lt;K,V&gt; right, <span class="keyword">int</span> level) &#123;</span><br><span class="line">        <span class="keyword">super</span>(node, down, right);</span><br><span class="line">        <span class="keyword">this</span>.level = level;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>封装了 Index 结点，作为每层的头结点，level 属性用于标识当前层次的序号。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The topmost head index of the skiplist.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> HeadIndex&lt;K,V&gt; head;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>整个跳表的头结点，通过它可以遍历访问整张跳表。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//比较器，用于比较两个元素的键值大小，如果没有显式传入则默认为自然排序</span></span><br><span class="line"><span class="keyword">final</span> Comparator&lt;? <span class="keyword">super</span> K&gt; comparator;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Special value used to identify base-level header</span></span><br><span class="line"><span class="comment"> * 特殊的值，用于初始化跳表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object BASE_HEADER = <span class="keyword">new</span> Object();</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>紧接着，我们看看它的几个构造器：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//未传入比较器，则为默认值</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentSkipListMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.comparator = <span class="keyword">null</span>;</span><br><span class="line">    initialize();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentSkipListMap</span><span class="params">(Comparator&lt;? <span class="keyword">super</span> K&gt; comparator)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.comparator = comparator;</span><br><span class="line">    initialize();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//所有的构造器都会调用这个初始化的方法</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    keySet = <span class="keyword">null</span>;</span><br><span class="line">    entrySet = <span class="keyword">null</span>;</span><br><span class="line">    values = <span class="keyword">null</span>;</span><br><span class="line">    descendingMap = <span class="keyword">null</span>;</span><br><span class="line">    head = <span class="keyword">new</span> HeadIndex&lt;K,V&gt;(<span class="keyword">new</span> Node&lt;K,V&gt;(<span class="keyword">null</span>, BASE_HEADER, <span class="keyword">null</span>),<span class="keyword">null</span>, <span class="keyword">null</span>, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这个初始化方法主要完成的是对整张跳表的一个初始化操作，head 头指针指向这个并没有什么实际意义的头结点。</p>
<p>基本的成员属性就简单介绍到这，重点还是那三个内部类，都分别代表了什么样的结点类型，都使用在何种场景下，务必清晰。</p>
<h3 id="四、put-并发添加的内部实现"><a href="#四、put-并发添加的内部实现" class="headerlink" title="四、put 并发添加的内部实现"></a>四、put 并发添加的内部实现</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//基本的 put 方法，向跳表中添加一个节点</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (value == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="keyword">return</span> doPut(key, value, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>put 方法的内部调用的是 doPut 方法来实现添加元素的，但是由于 doPut 方法的方法体很长，我们分几个部分进行分析。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//第一部分</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> V <span class="title">doPut</span><span class="params">(K key, V value, <span class="keyword">boolean</span> onlyIfAbsent)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; z;</span><br><span class="line">    <span class="comment">//边界值判断，空的 key 自然是不允许插入的</span></span><br><span class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="comment">//拿到比较器的引用</span></span><br><span class="line">    Comparator&lt;? <span class="keyword">super</span> K&gt; cmp = comparator;</span><br><span class="line">    outer: <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">	    <span class="comment">//根据 key，找到待插入的位置</span></span><br><span class="line">	    <span class="comment">//b 叫做前驱节点，将来作为新加入结点的前驱节点</span></span><br><span class="line">	    <span class="comment">//n 叫做后继结点，将来作为新加入结点的后继结点</span></span><br><span class="line">	    <span class="comment">//也就是说，新节点将插入在 b 和 n 之间</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;K,V&gt; b = findPredecessor(key, cmp), n = b.next;;) &#123;</span><br><span class="line">	        <span class="comment">//如果 n 为 null，那么说明 b 是链表的最尾端的结点，这种情况比较简单，直接构建新节点插入即可</span></span><br><span class="line">	        <span class="comment">//否则走下面的判断体</span></span><br><span class="line">            <span class="keyword">if</span> (n != <span class="keyword">null</span>) &#123;</span><br><span class="line">                Object v; <span class="keyword">int</span> c;</span><br><span class="line">                Node&lt;K,V&gt; f = n.next;</span><br><span class="line">                <span class="comment">//如果 n 不再是 b 的后继结点了，说明有其他线程向 b 后面添加了新元素</span></span><br><span class="line">                <span class="comment">//那么我们直接退出内循环，重新计算新节点将要插入的位置</span></span><br><span class="line">                <span class="keyword">if</span> (n != b.next)</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="comment">//value =0 说明 n 已经被标识位待删除，其他线程正在进行删除操作</span></span><br><span class="line">                <span class="comment">//调用 helpDelete 帮助删除，并退出内层循环重新计算待插入位置</span></span><br><span class="line">                <span class="keyword">if</span> ((v = n.value) == <span class="keyword">null</span>) &#123; </span><br><span class="line">                    n.helpDelete(b, f);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//b 已经被标记为待删除，前途结点 b 都丢了，可不得重新计算待插入位置吗</span></span><br><span class="line">                <span class="keyword">if</span> (b.value == <span class="keyword">null</span> || v == n) </span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">				<span class="comment">//如果新节点的 key 大于 n 的 key 说明找到的前驱节点有误，按序往后挪一个位置即可</span></span><br><span class="line">				<span class="comment">//回到内层循环重新试图插入</span></span><br><span class="line">                <span class="keyword">if</span> ((c = cpr(cmp, key, n.key)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    b = n;</span><br><span class="line">                    n = f;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//新节点的 key 等于 n 的 key，这是一次 update 操作，CAS 更新即可</span></span><br><span class="line">                <span class="comment">//如果更新失败，重新进循环再来一次</span></span><br><span class="line">                <span class="keyword">if</span> (c == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (onlyIfAbsent || n.casValue(v, value)) &#123;</span><br><span class="line">                        <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span> V vv = (V)v;</span><br><span class="line">                        <span class="keyword">return</span> vv;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">break</span>; </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">	    <span class="comment">//无论遇到何种问题，到这一步说明待插位置已经确定</span></span><br><span class="line">            z = <span class="keyword">new</span> Node&lt;K,V&gt;(key, value, n);</span><br><span class="line">            <span class="keyword">if</span> (!b.casNext(n, z))</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="comment">//如果成功了，退出最外层循环，完成了底层的插入工作        </span></span><br><span class="line">            <span class="keyword">break</span> outer;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以上这一部分主要完成了向底层链表插入一个节点，至于其中具体的怎么找前驱节点的方法稍后介绍。但这其实只不过才完成一小半的工作，就像红黑树在插入后需要 rebalance 一样，我们的跳表需要根据概率算法保证节点分布稳定，它的调节措施相对于红黑树来说就简单多了，通过往上层索引层添加相关引用即可，以空间换时间。具体的我们来看：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//第二部分</span></span><br><span class="line"><span class="comment">//获取一个线程无关的随机数，占四个字节，32 个比特位</span></span><br><span class="line"><span class="keyword">int</span> rnd = ThreadLocalRandom.nextSecondarySeed();</span><br><span class="line">	<span class="comment">//和 1000 0000 0000 0000 0000 0000 0000 0001 与</span></span><br><span class="line">	<span class="comment">//如果等于 0，说明这个随机数最高位和最低位都为 0，这种概率很大</span></span><br><span class="line">	<span class="comment">//如果不等于 0，那么将仅仅把新节点插入到最底层的链表中即可，不会往上层递归</span></span><br><span class="line">    <span class="keyword">if</span> ((rnd &amp; <span class="number">0x80000001</span>) == <span class="number">0</span>) &#123; </span><br><span class="line">        <span class="keyword">int</span> level = <span class="number">1</span>, max;</span><br><span class="line">        <span class="comment">//用低位连续为 1 的个数作为 level 的值，也是一种概率策略</span></span><br><span class="line">        <span class="keyword">while</span> (((rnd &gt;&gt;&gt;= <span class="number">1</span>) &amp; <span class="number">1</span>) != <span class="number">0</span>)</span><br><span class="line">            ++level;</span><br><span class="line">        Index&lt;K,V&gt; idx = <span class="keyword">null</span>;</span><br><span class="line">        HeadIndex&lt;K,V&gt; h = head;</span><br><span class="line">        <span class="comment">//如果概率算得的 level 在当前跳表 level 范围内</span></span><br><span class="line">        <span class="comment">//构建一个从 1 到 level 的纵列 index 结点引用</span></span><br><span class="line">        <span class="keyword">if</span> (level &lt;= (max = h.level)) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= level; ++i)</span><br><span class="line">                idx = <span class="keyword">new</span> Index&lt;K,V&gt;(z, idx, <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//否则需要新增一个 level 层</span></span><br><span class="line">        <span class="keyword">else</span> &#123; </span><br><span class="line">            level = max + <span class="number">1</span>; </span><br><span class="line">            <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">            Index&lt;K,V&gt;[] idxs =(Index&lt;K,V&gt;[])<span class="keyword">new</span> Index&lt;?,?&gt;[level+<span class="number">1</span>];</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= level; ++i)</span><br><span class="line">                idxs[i] = idx = <span class="keyword">new</span> Index&lt;K,V&gt;(z, idx, <span class="keyword">null</span>);</span><br><span class="line">            <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                h = head;</span><br><span class="line">                <span class="keyword">int</span> oldLevel = h.level;</span><br><span class="line">                <span class="comment">//level 肯定是比 oldLevel 大一的，如果小了说明其他线程更新过表了</span></span><br><span class="line">                <span class="keyword">if</span> (level &lt;= oldLevel) </span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                HeadIndex&lt;K,V&gt; newh = h;</span><br><span class="line">                Node&lt;K,V&gt; oldbase = h.node;</span><br><span class="line">                <span class="comment">//正常情况下，循环只会执行一次，如果由于其他线程的并发操作导致 oldLevel 的值不稳定，那么会执行多次循环体</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = oldLevel+<span class="number">1</span>; j &lt;= level; ++j)</span><br><span class="line">                    newh = <span class="keyword">new</span> HeadIndex&lt;K,V&gt;(oldbase, newh, idxs[j], j);</span><br><span class="line">                <span class="comment">//更新头指针</span></span><br><span class="line">                <span class="keyword">if</span> (casHead(h, newh)) &#123;</span><br><span class="line">                    h = newh;</span><br><span class="line">                    idx = idxs[level = oldLevel];</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这一部分的代码主要完成的是根据 level 的值，确认是否需要增加一层索引，如果不需要则构建好底层到 level 层的 index 结点的纵向引用。如果需要，则新创建一层索引，完成 head 结点的指针转移，并构建好纵向的 index 结点引用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//第三部分</span></span><br><span class="line"><span class="keyword">if</span> ((rnd &amp; <span class="number">0x80000001</span>) == <span class="number">0</span>)&#123;</span><br><span class="line"><span class="comment">//省略第二部分的代码段</span></span><br><span class="line"><span class="comment">//第三部分的代码是紧接着第二部分代码段后面的</span></span><br><span class="line">	splice: <span class="keyword">for</span> (<span class="keyword">int</span> insertionLevel = level;;) &#123;</span><br><span class="line">            <span class="keyword">int</span> j = h.level;</span><br><span class="line">            <span class="keyword">for</span> (Index&lt;K,V&gt; q = h, r = q.right, t = idx;;) &#123;</span><br><span class="line">	            <span class="comment">//其他线程并发操作导致头结点被删除，直接退出外层循环</span></span><br><span class="line">	            <span class="comment">//这种情况发生的概率很小，除非并发量实在太大</span></span><br><span class="line">                <span class="keyword">if</span> (q == <span class="keyword">null</span> || t == <span class="keyword">null</span>)</span><br><span class="line">                    <span class="keyword">break</span> splice;</span><br><span class="line">                <span class="keyword">if</span> (r != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    Node&lt;K,V&gt; n = r.node;</span><br><span class="line">                    <span class="keyword">int</span> c = cpr(cmp, key, n.key);</span><br><span class="line">                    <span class="comment">//如果 n 正在被其他线程删除，那么调用 unlink 去删除它</span></span><br><span class="line">                    <span class="keyword">if</span> (n.value == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (!q.unlink(r))</span><br><span class="line">                            <span class="keyword">break</span>;</span><br><span class="line">                        <span class="comment">//重新获取 q 的右结点，再次进入循环</span></span><br><span class="line">                        r = q.right;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">//c &gt; 0 说明前驱结点定位有误，重新进入</span></span><br><span class="line">                    <span class="keyword">if</span> (c &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        q = r;</span><br><span class="line">                        r = r.right;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (j == insertionLevel) &#123;</span><br><span class="line">		            <span class="comment">//尝试着将 t 插在 q 和 r 之间，如果失败了，退出内循环重试</span></span><br><span class="line">                    <span class="keyword">if</span> (!q.link(r, t))</span><br><span class="line">                        <span class="keyword">break</span>; <span class="comment">// restart</span></span><br><span class="line">                    <span class="comment">//如果插入完成后，t 结点被删除了，那么结束插入操作</span></span><br><span class="line">                    <span class="keyword">if</span> (t.node.value == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        findNode(key);</span><br><span class="line">                        <span class="keyword">break</span> splice;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">// insertionLevel-- 处理底层链接</span></span><br><span class="line">                    <span class="keyword">if</span> (--insertionLevel == <span class="number">0</span>)</span><br><span class="line">                        <span class="keyword">break</span> splice;</span><br><span class="line">                &#125;</span><br><span class="line">				<span class="comment">//--j，j 应该与 insertionLevel 同步，它代表着我们创建的那个纵向的结点数组的索引</span></span><br><span class="line">				<span class="comment">//并完成层次下移操作</span></span><br><span class="line">                <span class="keyword">if</span> (--j &gt;= insertionLevel &amp;&amp; j &lt; level)</span><br><span class="line">                    t = t.down;</span><br><span class="line">                <span class="comment">//至此，新节点在当前层次的前后引用关系已经被链接完成，现在处理下一层</span></span><br><span class="line">                q = q.down;</span><br><span class="line">                r = q.right;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们根据概率算法得到了一个 level 值，并且通过第二步创建了 level 个新节点并构成了一个纵向的引用关联，但是这些纵向的结点并没有链接到每层中。而我们的第三部分代码就是完成的这个工作，将我们的新节点在每个索引层都构建好前后的链接关系。下面用三张图描述着三个部分所完成的主要工作。</p>
<p>初始化的跳表如下：</p>
<p><img src="_v_images/20200819194445120_1704156511" alt="这里写图片描述"></p>
<p>第一部分，新增一个结点到最底层的链表上。</p>
<p><img src="_v_images/20200819194444915_223530245" alt="这里写图片描述"></p>
<p>第二部分，假设概率得出一个 level 值为 10，那么根据跳表的算法描述需要新建一层索引层。</p>
<p><img src="_v_images/20200819194444711_692580724" alt="这里写图片描述"></p>
<p>第三步，链接各个索引层次上的新节点。</p>
<p><img src="_v_images/20200819194444122_943848032" alt="这里写图片描述"></p>
<p>这样就完成了新增结点到跳表中的全部过程，大体上已如上图描述，至于 ConcurrentSkipListMap 中关于并发处理的细节之处，图中无法展示，大家可据此重新感受下源码的实现过程。下面我们着重描述下整个 doPut 方法中还涉及的其他几个方法的具体实现。</p>
<p><strong>首先是 findPredecessor 方法</strong>，我们说该方法将根据给定的 key，为我们返回最合适的前驱节点。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node&lt;K,V&gt; <span class="title">findPredecessor</span><span class="params">(Object key, Comparator&lt;? <span class="keyword">super</span> K&gt; cmp)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(); </span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">for</span> (Index&lt;K,V&gt; q = head, r = q.right, d;;) &#123;</span><br><span class="line">            <span class="comment">//r 为空说明 head 后面并没有其他节点了</span></span><br><span class="line">            <span class="keyword">if</span> (r != <span class="keyword">null</span>) &#123;</span><br><span class="line">                Node&lt;K,V&gt; n = r.node;</span><br><span class="line">				<span class="comment">// r 节点处于待删除状态，那么尝试 unlink 它，失败了将重新进入循环再此尝试</span></span><br><span class="line">				<span class="comment">//否则重新获取 q 的右结点并重新进入循环查找前驱节点</span></span><br><span class="line">                <span class="keyword">if</span> (n.value == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (!q.unlink(r))</span><br><span class="line">                        <span class="keyword">break</span>;           <span class="comment">// restart</span></span><br><span class="line">                    r = q.right;         <span class="comment">// reread r</span></span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//大于零说明当前位置上的 q 还不是我们要的前驱节点，继续往后找</span></span><br><span class="line">                <span class="keyword">if</span> (cpr(cmp, key, k) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    q = r;</span><br><span class="line">                    r = r.right;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//如果当前的 level 结束了或者 cpr(cmp, key, k) &lt;= 0 会达到此位置</span></span><br><span class="line">            <span class="comment">//往低层递归，如果没有低层了，那么当前的 q 就是最合适的前驱节点</span></span><br><span class="line">            <span class="comment">//整个循环只有这一个出口，无论如何最终都会从此处结束方法</span></span><br><span class="line">            <span class="keyword">if</span> ((d = q.down) == <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> q.node;</span><br><span class="line">           <span class="comment">//否则向低层递归并重置 q 和 r</span></span><br><span class="line">            q = d;</span><br><span class="line">            r = d.right;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最后总结下 findPredecessor 方法的大体逻辑，首先程序会从 head 节点开始在当前的索引层上寻找最后一个比给定 key 小的结点，它就是我们需要的前驱节点（q），我们只需要返回它即可。</p>
<p><strong>其次我们看看 helpDelete 方法</strong>，当检测到某个结点的 value 属性值为 null 的时候，一般都会调用这个方法来删除该结点。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">   一般的调用形式如下：</span></span><br><span class="line"><span class="comment">   n.helpDelete(b, f);</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">helpDelete</span><span class="params">(Node&lt;K,V&gt; b, Node&lt;K,V&gt; f)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (f == next &amp;&amp; <span class="keyword">this</span> == b.next) &#123;</span><br><span class="line">       <span class="keyword">if</span> (f == <span class="keyword">null</span> || f.value != f) </span><br><span class="line">            casNext(f, <span class="keyword">new</span> Node&lt;K,V&gt;(f));</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            b.casNext(<span class="keyword">this</span>, f.next);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>该方法是 Node 结点的内部实例方法，逻辑相对简单，此处不再赘述。通过该方法可以完成将 b.next 指向 f，完成对 n 结点的删除。</p>
<p>至此，有关 put 方法的源码分析就简单到这，大部分的代码还是用于实现跳表这种数据结构的构建和插入，关于并发的处理，你会发现基本都是双层 for 循环+ CAS 无锁式更新，如果遇到竞争失利将退出里层循环重新进行尝试，否则成功的话就会直接 return 或者退出外层循环并结束 CAS 操作。下面我们看删除操作是如何实现的。</p>
<h2 id="五、remove-并发删除操作的内部实现"><a href="#五、remove-并发删除操作的内部实现" class="headerlink" title="五、remove 并发删除操作的内部实现"></a>五、remove 并发删除操作的内部实现</h2><p>remove 方法的部分内容我们在介绍相关预备知识中已经提及过，此处的理解想必会容易些。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> doRemove(key, <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//代码比较多，建议读者结合自己的 jdk 源码共同来分析</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">doRemove</span><span class="params">(Object key, Object value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    Comparator&lt;? <span class="keyword">super</span> K&gt; cmp = comparator;</span><br><span class="line">    outer: <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">		<span class="comment">//找到 key 的前驱节点</span></span><br><span class="line">		<span class="comment">//因为删除不单单是根据 key 找到对应的结点，然后赋 null 就完事的，还要负责链接该结点前后的关联</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;K,V&gt; b = findPredecessor(key, cmp), n = b.next;;) &#123;</span><br><span class="line">            Object v; <span class="keyword">int</span> c;</span><br><span class="line">            <span class="comment">//目前 n 基本上就是我们要删除的结点，它为 null，那自然不用继续了，已经被删除了</span></span><br><span class="line">            <span class="keyword">if</span> (n == <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">break</span> outer;</span><br><span class="line">            Node&lt;K,V&gt; f = n.next;</span><br><span class="line">            <span class="comment">//再次确认 n 还是不是 b 的后继结点，如果不是将退出里层循环重新进入</span></span><br><span class="line">            <span class="keyword">if</span> (n != b.next)               </span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="comment">//如果有人正在删除 n，那么帮助它删除</span></span><br><span class="line">            <span class="keyword">if</span> ((v = n.value) == <span class="keyword">null</span>) &#123;     </span><br><span class="line">                n.helpDelete(b, f);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//b 被删除了，重新定位前驱节点</span></span><br><span class="line">            <span class="keyword">if</span> (b.value == <span class="keyword">null</span> || v == n)     </span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="comment">//正常情况下，key 应该等于 n.key</span></span><br><span class="line">            <span class="comment">//key 大于 n.key 说明我们要找的结点可能在 n 的后面，往后递归即可</span></span><br><span class="line">            <span class="comment">//key 小于 n.key 说明 key 所代表的结点根本不存在</span></span><br><span class="line">            <span class="keyword">if</span> ((c = cpr(cmp, key, n.key)) &lt; <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">break</span> outer;</span><br><span class="line">            <span class="keyword">if</span> (c &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                b = n;</span><br><span class="line">                n = f;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//如果删除是根据键和值两个参数来删除的话，value 是不为 null 的</span></span><br><span class="line">            <span class="comment">//这种情况下，如果 n 的 value 属性不等于我们传入的 value ，那么是不进行删除的</span></span><br><span class="line">            <span class="keyword">if</span> (value != <span class="keyword">null</span> &amp;&amp; !value.equals(v))</span><br><span class="line">                <span class="keyword">break</span> outer;</span><br><span class="line">			<span class="comment">//下面三个步骤才是整个删除操作的核心，大致的逻辑我们也在上文提及过了，此处想必会容易理解些</span></span><br><span class="line">			<span class="comment">//第一步，尝试将待删结点的 value 属性赋值 null，失败将退出重试</span></span><br><span class="line">            <span class="keyword">if</span> (!n.casValue(v, <span class="keyword">null</span>))</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="comment">//第二步和第三步如果有一步由于竞争失败，将调用 findNode 方法根据我们第一步的成果，也就是删除所有 value 为 null 的结点</span></span><br><span class="line">            <span class="keyword">if</span> (!n.appendMarker(f) || !b.casNext(n, f))</span><br><span class="line">                findNode(key);  </span><br><span class="line">            <span class="comment">//否则说明三个步骤都成功完成了   </span></span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                findPredecessor(key, cmp);  </span><br><span class="line">                <span class="comment">//判断此次删除后是否导致某一索引层没有其他节点了，并适情况删除该层索引  </span></span><br><span class="line">                <span class="keyword">if</span> (head.right == <span class="keyword">null</span>)</span><br><span class="line">                    tryReduceLevel();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span> V vv = (V)v;</span><br><span class="line">            <span class="keyword">return</span> vv;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>remove 方法其实从整体上来看，首先会有一堆的判断，根据给定的 key 和 value 会判断是否存在与 key 对应的一个节点，也会判断和待删结点相关的前后结点是否正在被删除，并适情况帮助删除。其次才是删除的三大步骤，核心步骤还是将待删结点的 value 属性赋 null 以标记该结点无用了，至于这个 marker 也是为了分散并发冲突的，最后通过 casNext 完成结点的删除。</p>
<h2 id="六、get-方法获取指定结点的-value"><a href="#六、get-方法获取指定结点的-value" class="headerlink" title="六、get 方法获取指定结点的 value"></a><strong>六、get 方法获取指定结点的 value</strong></h2><p>算上本小节将要介绍的 “查” 方法，我们就完成了对并发跳表 “增删改查” 的全部分析。 相对于“增”来说，其他的三种操作还是相对容易的，尤其是本小节的“查”操作，下面我们看看它的内部实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> doGet(key);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> V <span class="title">doGet</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    Comparator&lt;? <span class="keyword">super</span> K&gt; cmp = comparator;</span><br><span class="line">	<span class="comment">//依然是双层循环来处理并发</span></span><br><span class="line">    outer: <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">for</span> (Node&lt;K,V&gt; b = findPredecessor(key, cmp), n = b.next;;) &#123;</span><br><span class="line">            Object v; <span class="keyword">int</span> c;</span><br><span class="line">            <span class="comment">//以下的一些判断的作用已经描述了多次，此处不再赘述了</span></span><br><span class="line">            <span class="keyword">if</span> (n == <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">break</span> outer;</span><br><span class="line">            Node&lt;K,V&gt; f = n.next;</span><br><span class="line">            <span class="keyword">if</span> (n != b.next)           </span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">if</span> ((v = n.value) == <span class="keyword">null</span>) &#123;    </span><br><span class="line">                n.helpDelete(b, f);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (b.value == <span class="keyword">null</span> || v == n)  </span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="comment">//c = 0 说明 n 就是我们要的结点</span></span><br><span class="line">            <span class="keyword">if</span> ((c = cpr(cmp, key, n.key)) == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span> V vv = (V)v;</span><br><span class="line">                <span class="keyword">return</span> vv;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//c &lt; 0 说明不存在这个 key 所对应的结点</span></span><br><span class="line">            <span class="keyword">if</span> (c &lt; <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">break</span> outer;</span><br><span class="line">            b = n;</span><br><span class="line">            n = f;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>doGet 方法的实现相对还是比较简单的，所以并没有给出太多的注释，主要还是由于大量的并发判断的代码都是一样的，大多都已经在 doPut 方法中给予了详细的注释了。</p>
<h2 id="七、其它的一些方法的简单描述"><a href="#七、其它的一些方法的简单描述" class="headerlink" title="七、其它的一些方法的简单描述"></a><strong>七、其它的一些方法的简单描述</strong></h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//是否包含指定 key 的结点</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">containsKey</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> doGet(key) != <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//根据 key 返回该 key 所代表的结点的 value 值，不存在该结点则返回默认的 defaultValue</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">getOrDefault</span><span class="params">(Object key, V defaultValue)</span> </span>&#123;</span><br><span class="line">    V v;</span><br><span class="line">    <span class="keyword">return</span> (v = doGet(key)) == <span class="keyword">null</span> ? defaultValue : v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//返回跳表的实际存储元素个数，采取遍历来进行统计</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (Node&lt;K,V&gt; n = findFirst(); n != <span class="keyword">null</span>; n = n.next) &#123;</span><br><span class="line">        <span class="keyword">if</span> (n.getValidValue() != <span class="keyword">null</span>)</span><br><span class="line">            ++count;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (count &gt;= Integer.MAX_VALUE) ? Integer.MAX_VALUE : (<span class="keyword">int</span>) count;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//返回所有键的集</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> NavigableSet&lt;K&gt; <span class="title">keySet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    KeySet&lt;K&gt; ks = keySet;</span><br><span class="line">    <span class="keyword">return</span> (ks != <span class="keyword">null</span>) ? ks : (keySet = <span class="keyword">new</span> KeySet&lt;K&gt;(<span class="keyword">this</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//返回所有值的集</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Collection&lt;V&gt; <span class="title">values</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Values&lt;V&gt; vs = values;</span><br><span class="line">    <span class="keyword">return</span> (vs != <span class="keyword">null</span>) ? vs : (values = <span class="keyword">new</span> Values&lt;V&gt;(<span class="keyword">this</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这里需要说明一点的是，虽然返回来的是键或者值的一个集合，但是无论你是通过这个集合获取键或者值，还是删除集合中的键或者值，都会直接映射到当前跳表实例中。原因是这个集合中没有一个方法是自己实现的，都是调用传入的跳表实例的内部方法，具体的大家查看源码即可知晓，此处不再贴出源码。</p>
<p>至此，有关 SkipList 这种跳表数据结构及其在 jdk 中的实现，以及它的并发版本 ConcurrentSkipListMap 的实现，我们都已经简单的分析完了，有理解错误之处，望指出，相互学习！</p>
<h4 id="参考的几篇优秀博文"><a href="#参考的几篇优秀博文" class="headerlink" title="参考的几篇优秀博文"></a><strong>参考的几篇优秀博文</strong></h4><p><a href="http://xiaobaoqiu.github.io/blog/2014/12/19/javabing-fa-rong-qi-zhi-skiplist/">Java并发容器之SkipList（需要科学上网）  
</a></p>
<p><a href="http://blog.csdn.net/lihui6636/article/details/48947407">深入Java集合学习系列：ConcurrentSkipListMap实现原理</a></p>
<p><a href="http://blog.csdn.net/guangcigeyun/article/details/8278349">Java多线程（四）之ConcurrentSkipListMap深入分析</a></p>
]]></content>
  </entry>
  <entry>
    <title>Java HashMap</title>
    <url>/Java/collection/HashMap/</url>
    <content><![CDATA[<h1 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h1><p><img src="_v_images/20200709141031567_1720882596.png"></p>
<p>jdk8和jdk7不一样，jdk7中没有红黑树,数组中只挂载链表。而jdk8中在桶容量大于等于64且链表节点数大于等于8的时候转换为红黑树。当红黑树节点数量小于6时又会转换为链表。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化容量，必须要2的n次幂</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>; <span class="comment">// aka 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 负载因子默认值</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="number">0.75f</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 需要从链表转换为红黑树时,链表节点的最小长度</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换为红黑树时数组的最小容量</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// resize操作时,红黑树节点个数小于6则转换为链表。</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// HashMap阈值，用于判断是否需要扩容(threshold = 容量*loadFactor)</span></span><br><span class="line"><span class="keyword">int</span> threshold;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 负载因子</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">float</span> loadFactor;</span><br></pre></td></tr></table></figure>

<h2 id="HashMap解决hash冲突的方法"><a href="#HashMap解决hash冲突的方法" class="headerlink" title="HashMap解决hash冲突的方法"></a>HashMap解决hash冲突的方法</h2><h2 id="Java7的死循环问题"><a href="#Java7的死循环问题" class="headerlink" title="Java7的死循环问题"></a>Java7的死循环问题</h2><h2 id="Java8-中的HashMap扩容"><a href="#Java8-中的HashMap扩容" class="headerlink" title="Java8 中的HashMap扩容"></a>Java8 中的HashMap扩容</h2><p>而newTab[j + oldCap] = hiHead;这一步，是一个非常巧妙的地方，也是本文分析的重点。</p>
<p>解释<br>经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，经过rehash之后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。对应的就是下方的resize的注释。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * Initializes or doubles table size.  If null, allocates in</span><br><span class="line"> * accord with initial capacity target held in field threshold.</span><br><span class="line"> * Otherwise, because we are using power-of-two expansion, the</span><br><span class="line"> * elements from each bin must either stay at same index, or move</span><br><span class="line"> * with a power of two offset in the new table.</span><br><span class="line"> * &#x2F;</span><br></pre></td></tr></table></figure>

<p>看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希值(也就是根据key1算出来的hashcode值)与高位与运算的结果。</p>
<p><img src="_v_images/20200709130208070_533098526.png"></p>
<p><img src="_v_images/20200709130233960_485151198.png"></p>
<p>因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。<br>这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。</p>
<p>再解释：为什么刚好原位置+原数组长度就会等于新的数组中的位置呢？<br>要搞明白这个问题首先要清楚</p>
<p>HashMap的数组长度恒定为2的n次方，也就是说只会为2 4 8 16 。。。。。这种数。源码中有限制，也就是说即使你创建HashMap的时候是写的</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String,String&gt; hashMap = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">13</span>);</span><br></pre></td></tr></table></figure>
<p>最后数组长度也会变成16，而不是你的13. 会取与你传入的数最近的一个2的n次方的数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;Illegal initial capacity: &quot;</span> +</span><br><span class="line">                                               initialCapacity);</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">            initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">        <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;Illegal load factor: &quot;</span> +</span><br><span class="line">                                               loadFactor);</span><br><span class="line">        <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">        <span class="keyword">this</span>.threshold = tableSizeFor(initialCapacity);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">tableSizeFor</span><span class="params">(<span class="keyword">int</span> cap)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = cap - <span class="number">1</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">2</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">8</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">16</span>;</span><br><span class="line">        <span class="keyword">return</span> (n &lt; <span class="number">0</span>) ? <span class="number">1</span> : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>那么明确这一点有什么用呢？我们知道2,4,8,16,32所对应的二进制分别为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2：  0000 0000 0000 0000 0000 0000 0000 0010</span><br><span class="line">4：  0000 0000 0000 0000 0000 0000 0000 0100</span><br><span class="line">8：  0000 0000 0000 0000 0000 0000 0000 1000</span><br><span class="line">16： 0000 0000 0000 0000 0000 0000 0001 0000</span><br><span class="line">32:  0000 0000 0000 0000 0000 0000 0010 0000</span><br></pre></td></tr></table></figure>
<p>而我们知道，0在做位与运算时与任何一个数运算结果都恒为0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 &amp; 1 &#x3D; 0</span><br><span class="line">0 &amp; 0 &#x3D; 0</span><br></pre></td></tr></table></figure>
<p>故看源码中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if ((e.hash &amp; oldCap) &#x3D;&#x3D; 0) </span><br></pre></td></tr></table></figure>
<p>这一步是否为0只需要看元素的二进制数对应数组长度的二进制数1那个位置是否为0.<br>假设某个元素的hashcode为52：<br><img src="_v_images/20200709130402587_2088260774.png"></p>
<p>而假设某个元素的hashcode为100：<br><img src="_v_images/20200709130419110_1073585697.png"><br>而通过源码可以看出0就还是在原来的位置。不为0就需要变动位置了，新的位置为元素在原数组的位置+原数组的长度，那么为什么是这样呢？我们接着看<br>看之前我们先使用jdk1.7中的方式重新进行hash运算<br>HashMap在运算元素位置的时候使用为 数组长度-1。也就是15.31这种数15 31 对应的二进制为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">15：0000 0000 0000 0000 0000 0000 0000 1111</span><br><span class="line">31: 0000 0000 0000 0000 0000 0000 0001 1111</span><br></pre></td></tr></table></figure>
<p>这里需要注意的是hashmap中，计算元素位置采用的是length-1，而leng是用来判断元素是否需要更换位置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if ((e.hash &amp; oldCap) &#x3D;&#x3D; 0)  &#x2F;&#x2F;仅仅是判断元素是否需要换位置</span><br></pre></td></tr></table></figure>
<p>这一步才是计算位置，使用的是length-1.</p>
<p>16扩容后变成32.那么1.7中计算元素的位置方式为 31&amp;52, 31&amp;100.我们把他与扩容前的15&amp;52。15&amp;100做对比看看<br><img src="_v_images/20200709130508438_597207385.png"><br>可以看到，由于每次扩容会把原数组的长度*2，那么再二进制上的表现就是多出来一个1，比如元数组16-1二进制为1111，那么扩容后的32-1的二进制就变成了1 1111<br>而扩容前和扩容后的位置是否一样完全取决于多出来的那一位与key值的hash做按位与运算之后的值值是为0还是1。为0则新位置与原位置相同，不需要换位置，不为零则需要换位置。</p>
<p>而为什么新的位置是原位置+原数组长度，是因为每次换的位置只是前面多了一个1而已。那么新位置的变化的高位进1位。而每一次高位进1都是在加上原数组长度的过程。<br><img src="_v_images/20200709130528192_2073437264.png"><br>正好1+2=3 3+4=7 7+8=15 。也就验证了新的位置为原位置+原数组长度。</p>
<p><img src="_v_images/20200709130901169_1202973639.png"></p>
<p>[参考文献]<br>————————————————</p>
<ol>
<li><a href="https://blog.csdn.net/qq32933432/java/article/details/86668385">jdk8之HashMap resize方法详解（深入讲解为什么1.8中扩容后的元素新位置为原位置+原数组长度）</a></li>
<li><a href="https://www.jianshu.com/p/3797c6f83d4f">JAVA8对HashMap扩容机制的优化</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Collection</tag>
        <tag>Map</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Collection与Map</title>
    <url>/Java/collection/collection-map/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt; Java高级软件工程师知识结构</a></p>
<blockquote>
<ol>
<li>掌握Collection和Map的继承体系。</li>
<li>掌握ArrayList、LinkedList、Vector、Stack、PriorityQueue、HashSet、LinkedHashSet、TreeSet、HashMap、</li>
<li>LinkedHashMap、TreeMap、WeakHashMap、EnumMap、HashTable的特点和实现原理。<br>4.掌握CopyOnWriteArrayList、CopyOnWriteArraySet、ConcurrentHashMap的实现原理和适用场景。</li>
</ol>
</blockquote>
<h1 id="Java-Collection与Map的继承关系"><a href="#Java-Collection与Map的继承关系" class="headerlink" title="Java Collection与Map的继承关系"></a>Java Collection与Map的继承关系</h1><p>在程序设计中, 集合可以存储和传递一组数据. 集合虽然比不上数组的查询速度, 但是有更加方便的功能,<br>如可变长度、键值对、去重复等.<br>其家族成员有:</p>
<p><img src="/images/java/Collection_Map/java-collections-integrated-relation.png"></p>
<p><code>Collection</code>是一个接口, 该接口允许添加和查找一个或多个元素、<code>生成迭代器</code>等功能.</p>
<p><code>List</code> <code>Set</code>和<code>Queue</code>分别是继承了<code>Collocation</code>的子接口.<br><code>List</code>用于存放可重复可为<code>null</code>的元素的有序集合. 并且可以对元素进行精确地控制, 可根据整数索引访问元素.<br><code>Set</code>用于存放不可重复可为<code>null</code>的元素的集合,<br><code>Map</code>并没有继承<code>Collection</code>, 是由一系列键值对组成的集合. 在<code>Map</code>中一个<code>key</code>对应一个<code>value</code>, key不能相同.</p>
<h1 id="List接口"><a href="#List接口" class="headerlink" title="List接口"></a>List接口</h1><p>实现了List接口的集合主要有 <code>ArrayList</code> <code>LinkedList</code> <code>Vector</code> <code>Stack</code></p>
<h2 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h2><p><strong>特性</strong></p>
<ol>
<li><strong>可重复</strong>, <strong>可为null</strong>: 添加元素是将元素存放到数组中</li>
<li><strong>有序</strong></li>
<li>擅长随机访问： 快速检索 增删慢</li>
<li><strong>非线程同步</strong><br>通过<code>Collections.synchronizedList(new ArrayList());</code>转换为线程安全的List</li>
</ol>
<p><strong>实现原理</strong><br>动态数组, 底层也是通过<code>单个Java数组</code>实现的, <code>ArrayList</code>根据元素个数动态调整内部数组的长度以达到实现动态数组的效果.<br>内部数组的初始长度为10, 当添加的元素的个数超出了内部数组的长度时, 调用JNI函数对内部数组实现扩容（为原长度的<code>150%</code>）和复制.<br>本质上, <code>ArrayList</code>是采用了<strong>线性表</strong>的结构, 因此, <code>ArrayList</code>具有快速检索的优点也具有增删慢的缺点.</p>
<p><strong>复杂度</strong><br>添加n个元素需要O(n)时间</p>
<blockquote>
<p><strong>优化建议 :</strong><br>如果确定了插入元素的多少, 最好可以指定初始容量值,<br>避免过多的进行扩容和复制而浪费时间.</p>
</blockquote>
<h2 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h2><p><strong>特性</strong></p>
<ol>
<li><strong>不能随机访问</strong></li>
<li><strong>非线程同步</strong><br> 通过<code>Collections.synchronizedList(new LinkedList());</code>转换为线程安全的List</li>
<li>善于<strong>插入和删除</strong> 不善于随机访问</li>
</ol>
<p><strong>实现原理</strong><br>双向链表, 可以通过<code>get</code> <code>remove</code> <code>insert</code>方法操作首部和尾部的元素.</p>
<p><strong>复杂度</strong></p>
<p><strong>与ArrayList对比</strong><br>由于<code>ArrayList</code>是线性表的形式存储的, 需要连续的存储空间. 而<code>LinkedList</code>不需要连续,<br>因此在存储数据量较大的情况下, 优先选择<code>LinkedList</code>.</p>
<h2 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h2><p><strong>特性</strong></p>
<ol>
<li><strong>线程同步</strong></li>
<li>与ArrayList一样 <strong>???</strong></li>
</ol>
<p><strong>实现原理</strong><br>线程安全的动态数组, 内部也是采用单个数组</p>
<p><strong>复杂度</strong></p>
<h2 id="Stack-栈"><a href="#Stack-栈" class="headerlink" title="Stack 栈"></a>Stack 栈</h2><p><strong>特性</strong></p>
<ol>
<li><strong>后进先出的栈</strong></li>
<li>提供了除了ArrayList和Vector以外的栈操作方法:<ul>
<li>push 压入栈</li>
<li>pop  出栈</li>
<li>peek 得到栈顶</li>
<li>empty 测试栈是否为空</li>
<li>search 检测一个元素在栈中的位置</li>
</ul>
</li>
</ol>
<p><strong>实现原理</strong><br>用<code>Vector</code>构建,而非继承自<code>Vector</code></p>
<p><strong>复杂度</strong></p>
<p>【样例】: 使用栈实现计算器</p>
<h1 id="Set接口"><a href="#Set接口" class="headerlink" title="Set接口"></a>Set接口</h1><p><strong>特性</strong></p>
<ol>
<li><strong>不可重复</strong></li>
<li><strong>最多只允许一个null</strong></li>
</ol>
<h2 id="EnumSet"><a href="#EnumSet" class="headerlink" title="EnumSet"></a>EnumSet</h2><p><strong>特性</strong></p>
<ol>
<li>枚举专用Set</li>
<li>不是同步的<br>多线程情况下, 最好在创建时完成这一操作, 以防止意外的非同步访问<br><code>Set&lt;MyEnum&gt; s = Collections.synchronizedSet(EnumSet.noneOf(MyEnum.class));</code></li>
<li>枚举 set 中所有键都必须来自单个枚举类型, 该枚举类型在创建 set 时显式或隐式地指定.</li>
</ol>
<p><strong>实现原理</strong></p>
<p>//TODO</p>
<p><strong>复杂度</strong></p>
<h2 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h2><p><strong>特性</strong></p>
<ol>
<li><strong>速度最快的集合</strong></li>
<li>不能重复，最多一个为null</li>
</ol>
<p><strong>实现原理</strong><br>内部存在一个HashMap, 借助于HashCode来实现, 所以不保证元素的顺序</p>
<p><strong>复杂度</strong></p>
<h2 id="LinkedHashSet"><a href="#LinkedHashSet" class="headerlink" title="LinkedHashSet"></a>LinkedHashSet</h2><p><strong>特性</strong></p>
<ol>
<li>有序</li>
</ol>
<p><strong>实现原理</strong><br>内部是<code>LinkedHashMap</code>实现的<br>LinkedHashSet集合同样是根据元素的hashCode值来决定元素的存储位置，但是它 <strong>同时使用链表维护元素的次序</strong> 。<br>当遍历该集合时候，LinkedHashSet将会以元素的添加顺序访问集合的元素。<br>LinkedHashSet在迭代访问Set中的全部元素时，性能比HashSet好，但是插入时性能稍微逊色于HashSet。</p>
<p><strong>复杂度</strong></p>
<h2 id="TreeSet"><a href="#TreeSet" class="headerlink" title="TreeSet"></a>TreeSet</h2><p><strong>特性</strong></p>
<ol>
<li>总是处于排序状态的Set(顺序取决于元素的自然顺序或者创建Set时指定的Comparator)</li>
<li>非线程同步<br> 多线程情况下,最好在创建时进行, 以防止对 set 的意外非同步访问：<br> <code>SortedSet s = Collections.synchronizedSortedSet(new TreeSet(...));</code></li>
</ol>
<p><strong>实现原理</strong><br>内部由TreeMap(使用<a href="http://www.cnblogs.com/liqizhou/archive/2012/09/27/java%E4%B8%ADtreemap%E5%92%8Ctreeset%E5%AE%9E%E7%8E%B0%E7%BA%A2%E9%BB%91%E6%A0%91.html">红黑树</a>)来实现</p>
<p><strong>复杂度</strong></p>
<h1 id="Map接口"><a href="#Map接口" class="headerlink" title="Map接口"></a>Map接口</h1><p><strong>特性</strong></p>
<ol>
<li>键值对</li>
<li>Key不能重复</li>
</ol>
<h2 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h2><p><strong>特性</strong></p>
<ol>
<li><strong>线程不安全</strong></li>
<li>初始容量设定</li>
</ol>
<h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p><a href="http://www.importnew.com/7099.html">参考链接: HashMap的工作原理</a></p>
<p>以哈希表的数据结构实现. 内部存在一个哈希表数组, 每个数组元素又有一组长度不确定的链表.</p>
<p><img src="/images/java/Collection_Map/java-collections-hashtable.png"></p>
<p><code>HashMap</code>是基于hashing的原理，我们使用<code>put(key, value)</code>存储对象到HashMap中，使用<code>get(key)</code>从HashMap中获取对象。当我们给<code>put()</code>方法传递键和值时，我们先对键调用<code>hashCode()</code>方法，返回的hashCode用于找到bucket位置来储存<strong>Entry对象</strong>。”这里关键点在于指出，HashMap是在bucket中储存<strong>键对象和值对象</strong>，作为Map.Entry。</p>
<p><code>HashMap</code>在bucket中存储<code>Map.Entry</code>对象，每个Map.Entry保存有key和value。</p>
<h3 id="get的工作原理"><a href="#get的工作原理" class="headerlink" title="get的工作原理"></a>get的工作原理</h3><p>当使用get(key)方法，<br>首先调用hashing方法，利用<code>key.hashcode</code>计算key所在的bucket，找到相应的bucket后。<br>然后遍历bucket中的Map.Entry，首先比对<code>key.hashcode</code>值，其次比对(key值或<code>key.equals</code>方法比对两个对象)</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (e.hash == hash &amp;&amp;  ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line"><span class="keyword">return</span> e;</span><br></pre></td></tr></table></figure>
<p>在这里，使用了 <code>&amp;&amp;</code> 的短路特性: 只要第一个条件不满足，不再比较后面的条件；只有前面的条件满足了，才比较后面的条件。<br>等价于</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(e.hash==hash)&#123;</span><br><span class="line">  <span class="keyword">if</span>((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))&#123;</span><br><span class="line"><span class="keyword">return</span> e;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="key的hashcode相同的情况"><a href="#key的hashcode相同的情况" class="headerlink" title="key的hashcode相同的情况"></a>key的<code>hashcode</code>相同的情况</h3><p>因为<code>hashcode</code>相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。当<code>hashcode</code>相同时，还会调用key.equals比对两个key对象是否相同。</p>
<h3 id="负载因子-0-75"><a href="#负载因子-0-75" class="headerlink" title="负载因子 0.75"></a>负载因子 0.75</h3><p>“如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？”<br>默认的负载因子大小为 0.75，也就是说，当一个map填满了 75% 的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。<br>这个过程叫作 <strong>rehashing</strong>，因为它调用hash方法找到新的bucket位置。</p>
<h3 id="rehashing-过程"><a href="#rehashing-过程" class="headerlink" title="rehashing 过程"></a>rehashing 过程</h3><p>重新调整HashMap大小存在的问题:<br>当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候， HashMap 并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。</p>
<h3 id="key类型的选择与提速"><a href="#key类型的选择与提速" class="headerlink" title="key类型的选择与提速"></a>key类型的选择与提速</h3><ul>
<li><p>hashing的概念</p>
</li>
<li><p>HashMap 中解决碰撞的方法</p>
</li>
<li><p>equals()和hashCode()的应用，以及它们在HashMap中的重要性</p>
</li>
<li><p><strong>不可变对象的好处</strong></p>
<p>使用不可变的、声明作final的对象，并且采用合适的<code>equals()</code>和<code>hashCode()</code>方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用 String，Interger 这样的wrapper类作为键是非常好的选择。而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。</p>
<p>不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。<strong>不可变性还有其他的优点如线程安全</strong>。如果你可以仅仅通过将某个field声明成final就能<strong>保证hashCode是不变的</strong>，那么请这么做吧。</p>
<p>因为获取对象的时候要用到<code>equals()</code>和<code>hashCode()</code>方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的<code>hashcode</code>的话，那么碰撞的几率就会小些，这样就能提高<code>HashMap</code>的性能。</p>
</li>
</ul>
<p><strong>复杂度</strong></p>
<h2 id="LinkedHashMap"><a href="#LinkedHashMap" class="headerlink" title="LinkedHashMap"></a>LinkedHashMap</h2><p><strong>特性</strong></p>
<ol>
<li>非线程同步</li>
<li>有序： 可以按照访问顺序或者插入顺序排序</li>
</ol>
<p><strong>实现原理</strong><br>底层使用哈希表与<strong>双向链表</strong>来保存所有元素。其基本操作与父类 HashMap 相似</p>
<p>LinkedHashMap 定义了排序模式 accessOrder，该属性为 boolean 型变量，对于访问顺序，为 true；<br>对于插入顺序，则为 false。一般情况下，不必指定排序模式，其迭代顺序即为默认为插入顺序。</p>
<p>//TODO 排序模式</p>
<h2 id="TreeMap"><a href="#TreeMap" class="headerlink" title="TreeMap"></a>TreeMap</h2><p><strong>特性</strong></p>
<ol>
<li><strong>可排序</strong></li>
<li>不是同步的<br><code>SortedMap m = Collections.synchronizedSortedMap(new TreeMap(...));</code></li>
</ol>
<p><strong>实现原理</strong><br><a href="http://www.cnblogs.com/liqizhou/archive/2012/09/27/java%E4%B8%ADtreemap%E5%92%8Ctreeset%E5%AE%9E%E7%8E%B0%E7%BA%A2%E9%BB%91%E6%A0%91.html">红黑树</a>的数据结构, 实现了SortedMap接口</p>
<p><strong>复杂度</strong></p>
<p><strong>应用</strong><br>TreeMap 常用于在接口参数拼接中，以自动对key排序</p>
<h2 id="WeakHashMap"><a href="#WeakHashMap" class="headerlink" title="WeakHashMap"></a>WeakHashMap</h2><p><strong>特性</strong></p>
<ol>
<li>当除了自身有对key的引用外，此key没有其他引用那么此map会自动丢弃此值</li>
</ol>
<p><strong>实现原理</strong><br>使用<a href="http://www.cnblogs.com/-OYK/archive/2011/10/24/2222874.html" title="Java中的四种引用类型">弱引用</a>作为内部数据的存储方案。 WeakHashMap可以作为简单缓存表的解决方案，<br>当系统内存不够的时候，垃圾收集器会自动的清除没有在其他任何地方被引用的键值对。</p>
<h2 id="EnumMap"><a href="#EnumMap" class="headerlink" title="EnumMap"></a>EnumMap</h2><p><strong>特性</strong></p>
<ol>
<li>Key必须是Enum</li>
<li>EnumMap的key不允许为null，value可以为null，按照key在enum中的顺序进行保存，非线程安全。</li>
</ol>
<p><strong>实现原理</strong></p>
<h2 id="HashTable"><a href="#HashTable" class="headerlink" title="HashTable"></a>HashTable</h2><p><strong>特性</strong></p>
<ol>
<li><strong>线程安全</strong></li>
<li>性能比HashMap差</li>
</ol>
<p><strong>实现原理</strong><br>哈希表<br>使用 synchronized 锁住所有的读写操作</p>
<p><strong>复杂度</strong></p>
<h1 id="Queue接口"><a href="#Queue接口" class="headerlink" title="Queue接口"></a>Queue接口</h1><blockquote>
<p>// FIXME 实现原理</p>
</blockquote>
<p>队列, 它主要分为两大类:</p>
<ul>
<li>一类是阻塞式队列, 队列满了以后再插入元素则会抛出异常, 主要包括<ul>
<li><code>ArrayBlockQueue</code></li>
<li><code>PriorityBlockingQueue</code></li>
<li><code>LinkedBlockingQueue</code></li>
</ul>
</li>
<li>另一类是双端队列, 支持在头、尾两端插入和移除元素, 主要包括：<ul>
<li><code>ArrayDeque</code></li>
<li><code>LinkedBlockingDeque</code></li>
<li><code>LinkedList</code></li>
</ul>
</li>
</ul>
<p>常见的队列有:</p>
<ol>
<li>ArrayDeque, （数组双端队列）</li>
<li>PriorityQueue, （优先级队列）</li>
<li>ConcurrentLinkedQueue, （基于链表的并发队列）</li>
<li>DelayQueue, （延期阻塞队列）（阻塞队列实现了BlockingQueue接口）</li>
<li>ArrayBlockingQueue, （基于数组的并发阻塞队列）</li>
<li>LinkedBlockingQueue, （基于链表的FIFO阻塞队列）</li>
<li>LinkedBlockingDeque, （基于链表的FIFO双端阻塞队列）</li>
<li>PriorityBlockingQueue, （带优先级的无界阻塞队列）</li>
<li>SynchronousQueue （并发同步阻塞队列）</li>
</ol>
<h2 id="PriorityQueue"><a href="#PriorityQueue" class="headerlink" title="PriorityQueue"></a>PriorityQueue</h2><p>无界优先级队列<br><strong>特性</strong></p>
<ol>
<li>有序:<ul>
<li>顺序取决于元素的自然顺序或者创建队列时指定的Comparator</li>
<li>依靠自然顺序的优先级队列还不允许插入不可比较的对象（这样做可能导致 ClassCastException）。</li>
</ul>
</li>
<li>不允许元素为null</li>
<li>优先级队列是无界的<br>有一个内部容量，控制着用于存储队列元素的数组大小。它通常至少等于队列的大小。<br>随着不断向优先级队列添加元素，其容量会自动增加。无需指定容量增加策略的细节。</li>
<li>非线程安全</li>
</ol>
<h2 id="PriorityBlockingQueue"><a href="#PriorityBlockingQueue" class="headerlink" title="PriorityBlockingQueue"></a>PriorityBlockingQueue</h2><p>无界优先级阻塞队列<br><strong>特性</strong></p>
<ol>
<li>有序: 与PriorityQueue相同</li>
<li>不允许元素为null</li>
<li>无界: 资源耗尽时执行add会失败（导致 OutOfMemoryError）</li>
<li>线程安全</li>
</ol>
<h1 id="几种特殊的"><a href="#几种特殊的" class="headerlink" title="几种特殊的"></a>几种特殊的</h1><h2 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a><code>CopyOnWriteArrayList</code></h2><p><code>ArrayList</code>的一个线程安全的变体, 所有可变操作（<code>add</code>、<code>set</code> 等等）都是通过对底层数组进行一次新的复制作为新的内部数组来实现的.</p>
<ul>
<li>这一般需要很大的开销, 但是当遍历操作的数量大大超过可变操作的数量时, 这种方法可能比其他替代方法更有效.</li>
<li>在不能或不想进行同步遍历, 但又需要从并发线程中排除冲突时, 它也很有用.</li>
</ul>
<p><code>“快照”风格</code>的迭代器方法在创建迭代器时使用了对数组状态的引用. 此数组在迭代器的生存期内不会更改, 因此不可能发生冲突, 并且迭代器保证不会抛出<code>ConcurrentModificationException</code>. 创建迭代器以后, 迭代器就不会反映列表的添加、移除或者更改. 在迭代器上进行的元素更改操作（remove、set 和 add）不受支持. 这些方法将抛出 <code>UnsupportedOperationException</code>.</p>
<p>允许使用所有元素, 包括 null.</p>
<p>内存一致性效果：</p>
<p>当存在其他并发 collection 时, 将对象放入 <code>CopyOnWriteArrayList</code> 之前的线程中的操作 <code>happen-before</code><br>随后通过另一线程从 <code>CopyOnWriteArrayList</code> 中访问或移除该元素的操作.</p>
<p>这个类和ArrayList最大的区别就是add(E) 的时候。容器会自动copy一份出来然后再尾部add(E)。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Appends the specified element to the end of this list.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> e element to be appended to this list</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;<span class="doctag">@link</span> Collection#add&#125;)</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">  lock.lock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">Object[] elements = getArray();</span><br><span class="line"><span class="keyword">int</span> len = elements.length;</span><br><span class="line">Object[] newElements = Arrays.copyOf(elements, len + <span class="number">1</span>);</span><br><span class="line">newElements[len] = e;</span><br><span class="line">setArray(newElements);</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">lock.unlock();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="CopyOnWriteArraySet"><a href="#CopyOnWriteArraySet" class="headerlink" title="CopyOnWriteArraySet"></a><code>CopyOnWriteArraySet</code></h2><p>对其所有操作使用内部 <code>CopyOnWriteArrayList</code> 的 Set. 因此, 它共享以下相同的基本属性：</p>
<p>它最适合于具有以下特征的应用程序：</p>
<ul>
<li>set 大小通常保持很小, 只读操作远多于可变操作, 需要在遍历期间防止线程间的冲突.</li>
<li>它是线程安全的.</li>
<li>因为通常需要复制整个基础数组, 所以可变操作（add、set 和 remove 等等）的开销很大.</li>
<li>迭代器不支持可变 remove 操作.</li>
<li>使用迭代器进行遍历的速度很快, 并且不会与其他线程发生冲突. 在构造迭代器时, 迭代器依赖于不变的数组快照.</li>
</ul>
<p><strong>示例用法</strong></p>
<p>以下代码使用一个写时复制（copy-on-write）的 set, 以维护在状态更新时执行某项操作的一组 Handler 对象.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span> </span>&#123; <span class="function"><span class="keyword">void</span> <span class="title">handle</span><span class="params">()</span></span>; ... &#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">X</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> CopyOnWriteArraySet&lt;Handler&gt; handlers = <span class="keyword">new</span> CopyOnWriteArraySet&lt;Handler&gt;();</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addHandler</span><span class="params">(Handler h)</span> </span>&#123;</span><br><span class="line">handlers.add(h);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">long</span> internalState;</span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">changeState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">internalState = ...;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">()</span> </span>&#123;</span><br><span class="line">changeState();</span><br><span class="line"><span class="keyword">for</span> (Handler handler : handlers)</span><br><span class="line">    handler.handle();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><blockquote>
<p>   //FIXME 重写介绍</p>
</blockquote>
<h3 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h3><ol>
<li>结构</li>
</ol>
<p><img src="/images/java/Collection_Map/concurrentHashMap-construction.png" alt="c"></p>
<ol>
<li>详情请参考: <a href="http://www.ibm.com/developerworks/cn/java/java-lo-concurrenthashmap/index.html">探索 ConcurrentHashMap 高并发性的实现机制</a>的<a href="/Java/collection/ConcurrentHashMap/">本地版</a></li>
</ol>
<h1 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h1><h2 id="Collections类中的静态方法"><a href="#Collections类中的静态方法" class="headerlink" title="Collections类中的静态方法"></a>Collections类中的静态方法</h2><p>在 Collections类中有多个静态方法，它们可以获取通过同步方法封装非同步集合而得到的集合：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Collection <span class="title">synchronizedCollention</span><span class="params">(Collection c)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List <span class="title">synchronizedList</span><span class="params">(list l)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map <span class="title">synchronizedMap</span><span class="params">(Map m)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Set <span class="title">synchronizedSet</span><span class="params">(Set s)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SortedMap <span class="title">synchronizedSortedMap</span><span class="params">(SortedMap sm)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SortedSet <span class="title">synchronizedSortedSet</span><span class="params">(SortedSet ss)</span></span></span><br></pre></td></tr></table></figure>
<p>这些方法基本上返回具有同步集合方法版本的新类。比如，为了创建多线程安全且由ArrayList支持的List，可以使用如下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List list = Collection.synchronizedList(<span class="keyword">new</span> ArrayList());</span><br></pre></td></tr></table></figure>
<p>注意，ArrayList实例马上封装起来，不存在对未同步化ArrayList的直接引用（即直接封装匿名实例）。这是一种最安全的途径。如果另一个线程要直接引用ArrayList实例，它可以执行非同步修改。</p>
<p>//FIXME 实现原理</p>
<h2 id="CopyOnWrite机制"><a href="#CopyOnWrite机制" class="headerlink" title="CopyOnWrite机制"></a>CopyOnWrite机制</h2><h2 id="synchronized机制"><a href="#synchronized机制" class="headerlink" title="synchronized机制"></a>synchronized机制</h2><h2 id="ReteenLock机制"><a href="#ReteenLock机制" class="headerlink" title="ReteenLock机制"></a>ReteenLock机制</h2><h2 id="ConcurrentHashMap是个特例"><a href="#ConcurrentHashMap是个特例" class="headerlink" title="ConcurrentHashMap是个特例"></a>ConcurrentHashMap是个特例</h2><h1 id="异同点"><a href="#异同点" class="headerlink" title="异同点"></a>异同点</h1><h2 id="Vector-和-ArrayList"><a href="#Vector-和-ArrayList" class="headerlink" title="Vector 和 ArrayList"></a>Vector 和 ArrayList</h2><ol>
<li>Vector是线程同步的, 所以它也是线程安全的, 而ArrayList是线程异步的, 是不安全的. 如果不考虑到线程的安全因素, 一般用ArrayList效率比较高.</li>
<li>如果集合中的元素的数目大于目前集合数组的长度时, Vector增长率为目前数组长度的100%, 而ArrayList增长率为目前数组长度的50%. 如果在集合中使用数据量比较大的数据, 用Vector有一定的优势.</li>
<li>如果查找一个指定位置的数据, Vector和ArrayList使用的时间是相同的, 都是<code>O(1)</code>,这个时候使用Vector和ArrayList都可以; 而如果移动一个指定位置的数据花费的时间为<code>O(n-i)</code>  n为总长度, 这个时候就应该考虑到使用LinkedList, 因为它移动一个指定位置的数据所花费的时间为<code>O(1)</code>, 而查询一个指定位置的数据时花费的时间为<code>O(i)</code>.</li>
</ol>
<h2 id="Arraylist和LinkedList"><a href="#Arraylist和LinkedList" class="headerlink" title="Arraylist和LinkedList"></a>Arraylist和LinkedList</h2><ol>
<li>ArrayList是实现了基于动态数组的数据结构, LinkedList基于链表的数据结构.</li>
<li>对于随机访问<code>get</code>和<code>set</code>, <code>ArrayList</code>优于<code>LinkedList</code>, 因为<code>LinkedList</code>要移动指针.</li>
<li>对于新增和删除操作<code>add</code>和<code>remove</code>, <code>LinkedList</code>比较占优势, 因为<code>ArrayList</code>要移动数据.<br>这一点要看实际情况的. 若只对单条数据插入或删除, <code>ArrayList</code>的速度反而优于<code>LinkedList</code>. 但若是批量随机的插入删除数据, <code>LinkedList</code>的速度大大优于<code>ArrayList</code>. 因为<code>ArrayList</code>每插入一条数据, 要移动插入点及之后的所有数据.</li>
</ol>
<h2 id="HashMap-与-TreeMap"><a href="#HashMap-与-TreeMap" class="headerlink" title="HashMap 与 TreeMap"></a>HashMap 与 TreeMap</h2><ol>
<li>HashMap通过hashcode对其内容进行快速查找, 而TreeMap中所有的元素都保持着某种固定的顺序,<br> 如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）.</li>
<li>在Map 中插入、删除和定位元素, HashMap 是最好的选择. 但如果您要按自然顺序或自定义顺序遍历键, 那么TreeMap会更好.<br>使用HashMap要求添加的键类明确定义了hashCode()和 equals()的实现.  这个TreeMap没有调优选项, 因为该树总处于平衡状态.</li>
</ol>
<h2 id="HashMap与HashTable的区别"><a href="#HashMap与HashTable的区别" class="headerlink" title="HashMap与HashTable的区别"></a>HashMap与HashTable的区别</h2><ol>
<li>继承不同<br><code>public class Hashtable extends Dictionary implements Map</code><br><code>public class HashMap  extends AbstractMap implements Map</code></li>
<li>Hashtable 中的方法是同步的, 而HashMap中的方法在缺省情况下是非同步的. 在多线程并发的环境下, 可以直接使用Hashtable, 但是要使用HashMap的话就要自己增加同步处理了.</li>
<li>Hashtable中, key和value都不允许出现null值, 在HashMap中, null可以作为键, 这样的键只有一个; 可以有一个或多个键所对应的值为null. 当get()方法返回null值时, 即可以表示 HashMap中没有该键,也可以表示该键所对应的值为null. 因此, 在HashMap中不能由get()方法来判断HashMap中是否存在某个键, 而应该用containsKey()方法来判断.</li>
<li>两个遍历方式的内部实现上不同.<br>Hashtable、HashMap都使用了 Iterator. 而由于历史原因, Hashtable还使用了Enumeration的方式 .</li>
<li>哈希值的使用不同, HashTable直接使用对象的hashCode. 而HashMap重新计算hash值.</li>
<li>Hashtable和HashMap它们两个内部实现方式的数组的初始大小和扩容的方式. HashTable中hash数组默认大小是11, 增加的方式是 old*2+1. HashMap中hash数组的默认大小是16, 而且一定是2的指数</li>
</ol>
<h2 id="对集合的选择"><a href="#对集合的选择" class="headerlink" title="对集合的选择"></a>对集合的选择</h2><h3 id="对List的选择"><a href="#对List的选择" class="headerlink" title="对List的选择"></a>对List的选择</h3><ol>
<li>对于随机查询与迭代遍历操作, 数组比所有的容器都要快. 所以在随机访问中一般使用ArrayList</li>
<li>LinkedList使用双向链表对元素的增加和删除提供了非常好的支持, 而ArrayList执行增加和删除元素需要进行元素位移.</li>
<li>对于Vector而已, 我们一般都是避免使用.</li>
<li>将ArrayList当做首选, 毕竟对于集合元素而已我们都是进行遍历, 只有当程序的性能因为List的频繁插入和删除而降低时, 再考虑LinkedList.</li>
</ol>
<h3 id="对Set的选择"><a href="#对Set的选择" class="headerlink" title="对Set的选择"></a>对Set的选择</h3><ol>
<li><code>HashSet</code>由于使用<code>HashCode</code>实现, 所以在某种程度上来说它的性能永远比<code>TreeSet</code>要好, 尤其是进行增加和查找操作.</li>
<li>虽然<code>TreeSet</code>没有<code>HashSet</code>性能好, 但是由于它可以维持元素的排序, 所以它还是存在用武之地的.</li>
</ol>
<h3 id="对Map的选择"><a href="#对Map的选择" class="headerlink" title="对Map的选择"></a>对Map的选择</h3><ol>
<li>HashMap与HashSet同样, 支持快速查询. 虽然HashTable的速度也不慢, 但是在HashMap面前还是稍微慢了些, 所以HashMap在查询方面可以取代HashTable.</li>
<li>由于TreeMap需要维持内部元素的顺序, 所以它通常要比HashMap和HashTable慢.</li>
</ol>
<h1 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h1><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><h3 id="数组复制System-arrayCopy"><a href="#数组复制System-arrayCopy" class="headerlink" title="数组复制System.arrayCopy"></a>数组复制<code>System.arrayCopy</code></h3><p>该方法是个JNI函数, 是在JVM中实现的</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">*从src的srcPos位置复制数据到dest的destPos位置, 长度为length</span></span><br><span class="line"><span class="comment">*src - 源数组.</span></span><br><span class="line"><span class="comment">*srcPos - 源数组中的起始位置.</span></span><br><span class="line"><span class="comment">*dest - 目标数组.</span></span><br><span class="line"><span class="comment">*destPos - 目标数据中的起始位置.</span></span><br><span class="line"><span class="comment">*length - 要复制的数组元素的数量.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">arraycopy</span><span class="params">(Object src, <span class="keyword">int</span> srcPos, Object dest, <span class="keyword">int</span> destPos, <span class="keyword">int</span> length)</span></span>;</span><br></pre></td></tr></table></figure>
<h3 id="Arrays-copyOf"><a href="#Arrays-copyOf" class="headerlink" title="Arrays.copyOf"></a>Arrays.copyOf</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 由U类型复制为T类型？</span></span><br><span class="line"><span class="comment">* original - 要复制的数组</span></span><br><span class="line"><span class="comment">* newLength - 要返回的副本的长度</span></span><br><span class="line"><span class="comment">* newType - 要返回的副本的类型</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T,U&gt; T[] copyOf(U[] original, <span class="keyword">int</span> newLength, Class&lt;? extends T[]&gt; newType) &#123;</span><br><span class="line">  T[] copy = ((Object)newType == (Object)Object[].class)</span><br><span class="line">? (T[]) <span class="keyword">new</span> Object[newLength]</span><br><span class="line">: (T[]) Array.newInstance(newType.getComponentType(), newLength);</span><br><span class="line">  System.arraycopy(original, <span class="number">0</span>, copy, <span class="number">0</span>,</span><br><span class="line"> Math.min(original.length, newLength));</span><br><span class="line">  <span class="keyword">return</span> copy;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; T[] copyOf(T[] original, <span class="keyword">int</span> newLength) &#123;</span><br><span class="line">    <span class="keyword">return</span> (T[]) copyOf(original, newLength, original.getClass());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Arrays-asList-将数组转换为ArrayList"><a href="#Arrays-asList-将数组转换为ArrayList" class="headerlink" title="Arrays.asList: 将数组转换为ArrayList"></a>Arrays.asList: 将数组转换为ArrayList</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">List&lt;T&gt; <span class="title">asList</span><span class="params">(T... a)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> ArrayList&lt;T&gt;(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Arrays.asList返回的<code>ArrayList</code>并不是<code>java.util.ArrayList</code>, 只是<code>Arrays</code>的内部类. 该类只提供了一些基本的操作,</p>
<ol>
<li>size：元素数量</li>
<li>toArray：转换为数组, 实现了数组的浅拷贝.</li>
<li>get：获得指定元素.</li>
<li>contains：是否包含某元素.<br>asList返回的是一个长度不可变的列表. 数组是多长, 转换成的列表是多长, 我们是无法通过add、remove来增加或者减少其长度的<br>我们经常需要使用到Arrays这个工具的asList()方法将其转换成列表. 方便是方便, 但是有时候会出现莫名其妙的问题. 如下：</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span>[] datas = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line">  List list = Arrays.asList(datas);</span><br><span class="line">  System.out.println(list.size());</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>输出结果:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure>
<p>结果是1, 为什么会是1而不是5呢？先注意这个参数: T…a, 这个参数是一个泛型的变长参数, 我们知道 <strong>基本数据类型是不可能泛型化的</strong> ,也就是说8个基本数据类型是不可作为泛型参数的, 但是为什么编译器没有报错呢？这是因为数组会当做一个对象来处理, 它是可以泛型的, 所以我们的程序是把一个int型的数组作为了T的类型,所以在转换之后List中就只会存在一个类型为int数组的元素了.<br>所以我们这样的程序<code>System.out.println(datas.equals(list.get(0)));</code>输出结果肯定是<code>true</code>.<br>当然如果将int改为Integer, 则长度就会变成5了.</p>
<h3 id="Arrays-fill"><a href="#Arrays-fill" class="headerlink" title="Arrays.fill"></a>Arrays.fill</h3><p>使用值填充数组</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] a=<span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line">Arrays.fill(a,<span class="number">0</span>);</span><br><span class="line"><span class="comment">// 使用0填充数组a</span></span><br></pre></td></tr></table></figure>

<h2 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h2><h3 id="Map的遍历"><a href="#Map的遍历" class="headerlink" title="Map的遍历"></a>Map的遍历</h3><p>Map的遍历,都是需要转换为Collection</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String, String&gt; map = ...;</span><br></pre></td></tr></table></figure>
<ol>
<li><p>由Map生成<code>Collection</code>, 获取所有的值</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Collection&lt;String&gt; values = map.values();</span><br><span class="line">Iterator&lt;String&gt; iterator = values.iterator();</span><br><span class="line"><span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">	System.out.println(iterator.next());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>由Map.keySet, 遍历key值</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Set&lt;String&gt; keySet = map.keySet();</span><br><span class="line">Iterator&lt;String&gt; keyIterator = keySet.iterator();</span><br></pre></td></tr></table></figure></li>
<li><p>获取Map.Entry类型的Set</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Set&lt;Map.Entry&lt;String, String&gt;&gt; entrySet = map.entrySet();</span><br><span class="line">Iterator&lt;Map.Entry&lt;String, String&gt;&gt; entryIterator = entrySet.iterator();</span><br><span class="line"><span class="keyword">while</span> (entryIterator.hasNext()) &#123;</span><br><span class="line">	Map.Entry&lt;String, String&gt; entry = entryIterator.next();</span><br><span class="line">	String key = entry.getKey();</span><br><span class="line">	String value = entry.getValue();</span><br><span class="line">	System.out.println(key + <span class="string">&quot;\t&quot;</span> + value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Collection的遍历方法"><a href="#Collection的遍历方法" class="headerlink" title="Collection的遍历方法"></a>Collection的遍历方法</h3></li>
<li><p>Iterator 迭代子</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Collection&lt;String&gt; values2 = map.values();</span><br><span class="line">Iterator&lt;String&gt; iterator2 = values2.iterator();</span><br><span class="line"><span class="keyword">while</span> (iterator2.hasNext()) &#123;</span><br><span class="line">	System.out.println(iterator.next());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>foreach</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (String valueItem : values2) &#123;</span><br><span class="line">	System.out.println(valueItem);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>List特有的遍历方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; list = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">assert</span> list != <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; list.size(); i++) &#123;</span><br><span class="line">	System.out.println(list.get(i));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 当然也可以写成</span></span><br><span class="line"><span class="keyword">for</span> (String aList : list) &#123;</span><br><span class="line">	System.out.println(aList);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>List遍历方式有三种:</p>
<ul>
<li>下标遍历</li>
<li>Iterator遍历</li>
<li>Foreach遍历（最快）</li>
</ul>
</li>
</ol>
<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><blockquote>
<p>FIXME 排序：集合自带排序 对集合排序</p>
</blockquote>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="Java中有多少种数据结构-分别是什么？"><a href="#Java中有多少种数据结构-分别是什么？" class="headerlink" title="Java中有多少种数据结构, 分别是什么？"></a>Java中有多少种数据结构, 分别是什么？</h2><pre><code>- List：是列表, 有下标值, 存储元素可以重复, 遍历元素是有序的.
- Set：是散列集, 无下标值, 存储元素不可重复, 遍历元素时无序的.
- Map：是以键值对存储, 一个key一个value, key不可以重复, value可以重复.
- 数组：指定类型, 固定长度, 元素存储地址是连续的.
- 树：元素以树形结构存储, 只有一个根节点.
- 栈：元素是先进后出, 后进先出.
- 向量：动态数组, 可以存储任何类型元素, 动态长度, 元素存储地址是连续的.
- 队列：元素存储是排列有序的, 一定保证先进的先出, 后进的后出.</code></pre>
<hr>
<p>修改记录:</p>
<ol>
<li>HashMap的详细实现原理 重写ConcurrentHashMap介绍     2016-08-20</li>
</ol>
<hr>
<p>参考文献:</p>
<ol>
<li><a href="http://cmsblogs.com/?p=106">java提高篇（二十）集合大家族</a></li>
<li><a href="http://blog.csdn.net/softwave/article/details/4166598">Java集合类详解</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/java-lo-concurrenthashmap/index.html">探索 ConcurrentHashMap 高并发性的实现机制</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Collection</tag>
        <tag>Map</tag>
        <tag>List</tag>
        <tag>Set</tag>
        <tag>Vector</tag>
      </tags>
  </entry>
  <entry>
    <title>Java IO</title>
    <url>/Java/io/BIO/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt; Java高级软件工程师知识结构</a></p>
<ol>
<li>掌握InputStream、OutputStream、Reader、Writer的继承体系。</li>
<li>掌握字节流(FileInputStream、DataInputStream、BufferedInputStream、FileOutputSteam、DataOutputStream、BufferedOutputStream)和 字符流(BufferedReader、InputStreamReader、FileReader、BufferedWriter、OutputStreamWriter、PrintWriter、FileWriter)，并熟练运用。</li>
<li>掌握NIO实现原理及使用方法。</li>
</ol>
<p>Java IO包括:</p>
<ul>
<li><a href="/Java/io/IO-Model/">IO Model</a></li>
<li><a href="/Java/io/BIO/">Java BIO</a></li>
<li><a href="/Java/io/NIO/">Java NIO</a></li>
<li><a href="/Java/io/AIO/">Java AIO</a></li>
<li><a href="/Java/io/java-zip/">Java压缩</a></li>
<li><a href="/Java/io/object-serialization/">Java序列化</a></li>
<li><a href="/Java/io/java-XML-JSON/">Java XML与JSON</a></li>
</ul>
<p>本文介绍的是Java IO的基础部分, 也叫作<code>BIO</code>.</p>
<h1 id="Java-IO-继承关系"><a href="#Java-IO-继承关系" class="headerlink" title="Java IO 继承关系"></a>Java IO 继承关系</h1><p>java.io包中包含了一系列的<code>Java IO</code>相关的类和接口：</p>
<p><img src="/images/java/io/java-io-package.png"></p>
<ul>
<li>File 文件类</li>
<li>FileDescriptor 文件描述类</li>
<li>InputStream 字节流输入抽象类</li>
<li>OutputStream 字节流输出抽象类</li>
<li>Reader 字符流输入抽象类</li>
<li>Writer 字符流输出抽象类</li>
<li>RandomAccessFile随机访问文件类 不是InputStream或者OutputStream继承层次的一部分，除了实现了DataInput和DataOutput接口（DataInputStream和DataOutputStream也实现这两个接口）外, 他和这两个继承层次没任何关系。甚至不使用InputStream和OutputStream类中的任何功能。完全是独立的类，RandomAccessFile拥有和别的IO类型本质完全不同的行为，可以在一个文件中向前和向后移动，因此重新编写了所有的方法。任何情况下都是相互独立的，直接从Object类派生而来。</li>
<li><ul>
<li>Console类,该类提供了用于读取密码的方法，可以禁止控制台回显并返回char数组，这两个特性对保证安全有作用，平时用的不多，了解就行。</li>
</ul>
</li>
<li><ul>
<li>StreamTokenizer 类，这个类非常有用，它可以把输入流解析为标记（token）, StreamTokenizer 并非派生自InputStream或者OutputStream，而是归类于io库中，因为StreamTokenizer只处理InputStream对象。</li>
</ul>
</li>
</ul>
<p>流，是编程语言的IO类库常用的概念， 所谓流是指任何有能力产出数据的数据源和任何有能力接收数据的接收端对象。”流”屏蔽了实际的IO设备中处理数据的细节。<br>Java中的流，根据处理数据类型的不同分为：字符流和字节流; 根据数据流向不同分为：输入流和输出流。可以通过类名的结尾来判断。</p>
<h2 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a>字节流</h2><p><a href="/Java/io/java-zip/">java中的压缩</a>都是面向字节的 (<code>java.util.zip</code>)。</p>
<h2 id="InputStream"><a href="#InputStream" class="headerlink" title="InputStream"></a>InputStream</h2><p>字节输入流都是继承于InputStream并且以InputStream结尾，InputStream表示从不同的数据源产生输入的类，这些数据源包括字节数组、String对象(StringBufferInputStream已经不再使用，需要转换为字节数组来实现)、文件、“管道”、其他种类的流组成的序列及其他数据源。每种数据源都有相应的 InputStream 子类，FilterInputStream也属于一种 InputStream， 为装饰器类提供基类，其中，“装饰器”类可以把属性或有用的接口与输入流连接在一起。<a href="/designPattern-Strategy/">装饰器模式</a></p>
<p><img src="/images/java/io/java-io-InputStream.png"></p>
<ol>
<li>PipedInputStream 作为多线程中的数据源，将其与FilterInputStream对象相连以提供有用接口</li>
<li><code>FilterInputStream</code> 类定义了一些方法<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mark</span><span class="params">(<span class="keyword">int</span> readlimit)</span></span></span><br><span class="line"><span class="function">	在输入流中的当前位置上作标记。 </span></span><br><span class="line"><span class="function"> reset 方法的后续调用将此流重新定位在最后标记的位置上，</span></span><br><span class="line"><span class="function"> 以便后续读取操作重新读取相同的字节。</span></span><br><span class="line"><span class="function">	readlimit 参数告知此输入流在标记位置无效之前允许读取的字节数。</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reset</span><span class="params">()</span>  <span class="keyword">throws</span> IOException</span></span><br><span class="line"><span class="function">	将此流重新定位到对此输入流最后调用 mark 方法时的位置。</span></span><br><span class="line"><span class="function">	此方法只执行 in.<span class="title">reset</span><span class="params">()</span>。</span></span><br><span class="line"><span class="function">	在需要提前读取一小部分数据以查看流中有什么的情况下，可以使用流的标记。</span></span><br><span class="line"><span class="function">	通过调用通用解析器常常最容易做到这一点。如果流属于通过解析处理的类型，那么解析起来就很容易。</span></span><br><span class="line"><span class="function">	如果流不属于那种类型，那么解析器应该在解析失败时抛出一个异常。</span></span><br><span class="line"><span class="function">	如果这发生在 readlimit 个字节内，那么它允许外部代码重置流，并尝试另一种解析器。</span></span><br></pre></td></tr></table></figure></li>
<li>除了DataInputStream以外的FilterInputStream类在内部修改了InputStream的行为方式，是否缓冲，是否记录读过的行，以及是否把单一字符推回输入流等。</li>
</ol>
<h2 id="OutputStream"><a href="#OutputStream" class="headerlink" title="OutputStream"></a>OutputStream</h2><p>接收端对象包括字节数组(但不是String)、文件或者管道。<br>字节输出流都是继承于OutputStream并以OutputStream结尾</p>
<p><img src="/images/java/io/java-io-OutputStream.png"></p>
<p>字节输入流和输出流的对应关系</p>
<p><img src="/images/java/io/InputStream-OutputStream-match.png"></p>
<h2 id="字符流"><a href="#字符流" class="headerlink" title="字符流"></a>字符流</h2><p>字节流仅支持8位字节流，不能很好的处理16位的Unicode字符，<code>Reader</code>和<code>Writer</code>提供了兼容Unicode与面向字符的I/O功能，可以方便的实现国际化。</p>
<h2 id="Reader-字符输入流"><a href="#Reader-字符输入流" class="headerlink" title="Reader 字符输入流"></a>Reader 字符输入流</h2><p>读取字符序列的类都是继承于Reader并且以Reader结尾</p>
<p><img src="/images/java/io/java-io-Reader.png"></p>
<h2 id="Writer-字符输出流"><a href="#Writer-字符输出流" class="headerlink" title="Writer 字符输出流"></a>Writer 字符输出流</h2><p>写入字符流的类都是继承于Writer并且以Writer结尾</p>
<p><img src="/images/java/io/java-io-Writer.png"></p>
<ol>
<li>FilterWriter形同虚设： BufferedWriter并不是FilterWriter的子类，尽管FilterWriter是抽象类。没有任何子类。</li>
<li>CharArrayWriter、StringWriter 是两种基本的介质流，它们分别向Char 数组、String 中写入数据。PipedWriter 是向与其它线程共用的管道中写入数据</li>
<li>PrintWriter 和 PrintStream 极其类似，功能和使用也非常相似。</li>
<li>OutputStreamWriter 是OutputStream 到Writer 转换的桥梁</li>
</ol>
<p>字符输入流与字符输出流的对应关系</p>
<p><img src="/images/java/io/Reader-Writer-match.png"></p>
<h2 id="字节流与字符流的对应关系"><a href="#字节流与字符流的对应关系" class="headerlink" title="字节流与字符流的对应关系"></a>字节流与字符流的对应关系</h2><p><img src="/images/java/io/%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB.png"></p>
<p><img src="/images/java/io/%E8%BF%87%E6%BB%A4%E5%99%A8%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB.png"></p>
<h2 id="字节流与字符流的区别"><a href="#字节流与字符流的区别" class="headerlink" title="字节流与字符流的区别"></a>字节流与字符流的区别</h2><p>把一片二进制数据数据逐一输出到某个设备中，或者从某个设备中逐一读取一片二进制数据，不管输入输出设备是什么，我们要用统一的方式来完成这些操作，用一种抽象的方式进行描述，这个抽象描述方式起名为IO流，对应的抽象类为OutputStream和InputStream ，不同的实现类就代表不同的输入和输出设备，它们都是针对字节进行操作的。</p>
<p>在应用中，经常要完全是字符的一段文本输出去或读进来，用字节流可以吗？计算机中的一切最终都是二进制的字节形式存在。对于“中国”这些字符，首先要得到其对应的字节，然后将字节写入到输出流。读取时，首先读到的是字节，可是我们要把它显示为字符，我们需要将字节转换成字符。由于这样的需求很广泛，人家专门提供了字符流的包装类。</p>
<p>底层设备永远只接受字节数据，有时候要写字符串到底层设备，需要将字符串转成字节再进行写入。字符流是字节流的包装，字符流则是直接接受字符串，它内部将串转成字节，再写入底层设备，这为我们向IO设别写入或读取字符串提供了一点点方便。字符向字节转换时，要注意编码的问题，因为字符串转成字节数组，其实是转成该字符的某种编码的字节形式，读取也是反之的道理。</p>
<h1 id="字节流-1"><a href="#字节流-1" class="headerlink" title="字节流"></a>字节流</h1><h2 id="FileInputStream-文件输入流"><a href="#FileInputStream-文件输入流" class="headerlink" title="FileInputStream 文件输入流"></a>FileInputStream 文件输入流</h2><p>构造器只能接受File对象 File路径字符串或者 FileDescriptor对象</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">available</span><span class="params">()</span></span></span><br><span class="line"><span class="function">     返回下一次对此输入流调用的方法可以不受阻塞地从此输入流读取（或跳过）的估计剩余字节数。</span></span><br><span class="line"><span class="function">FileDescriptor 	<span class="title">getFD</span><span class="params">()</span></span></span><br><span class="line"><span class="function">     返回表示到文件系统中实际文件的连接的 FileDescriptor 对象，</span></span><br><span class="line"><span class="function">     该文件系统正被此 FileInputStream 使用。</span></span><br><span class="line"><span class="function"><span class="keyword">long</span> 	<span class="title">skip</span><span class="params">(<span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function">     从输入流中跳过并丢弃 n 个字节的数据。</span></span><br></pre></td></tr></table></figure>
<h2 id="FileOutputSteam-文件输出流"><a href="#FileOutputSteam-文件输出流" class="headerlink" title="FileOutputSteam 文件输出流"></a>FileOutputSteam 文件输出流</h2><p>文件输出流是用于将数据写入 File 或 FileDescriptor 的输出流。与字符流中的<code>FileWriter</code>对应.</p>
<h2 id="BufferedInputStream-缓冲输入流"><a href="#BufferedInputStream-缓冲输入流" class="headerlink" title="BufferedInputStream 缓冲输入流"></a>BufferedInputStream 缓冲输入流</h2><p>支持一次性读入多个字节</p>
<p>BufferedInputStream 为另一个输入流添加一些功能，即缓冲输入以及支持 mark 和 reset 方法的能力。<br>在创建 BufferedInputStream 时，会创建一个内部缓冲区数组。<br>在读取或跳过流中的字节时，可根据需要从包含的输入流再次填充该内部缓冲区，一次填充多个字节。</p>
<p>实现了FilterInputStream的<code>mark(int readLine)</code>方法</p>
<p>mark 操作记录输入流中的某个点，reset 操作使得在从包含的输入流中获取新字节之前，再次读取自最后一次 mark 操作后读取的所有字节。</p>
<p>构造器只能接受 InputStream</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span>  <span class="title">available</span><span class="params">()</span></span></span><br><span class="line"><span class="function">          返回可以从此输入流读取（或跳过）、且不受此输入流接下来的方法调用阻塞的估计字节数。</span></span><br></pre></td></tr></table></figure>

<h2 id="BufferedOutputStream-缓冲输出流"><a href="#BufferedOutputStream-缓冲输出流" class="headerlink" title="BufferedOutputStream 缓冲输出流"></a>BufferedOutputStream 缓冲输出流</h2><p>该类实现缓冲的字节输出流。通过设置这种输出流，应用程序就可以将各个字节写入底层输出流中，而不必针对每次字节写入调用底层系统。</p>
<p>BufferedOutputStream重写了OutputStream中的write方法,</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">byte</span>[] b,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">int</span> off,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function">           <span class="keyword">throws</span> IOException</span></span><br></pre></td></tr></table></figure>
<p>OutputStream写入多个字节时会逐个字节的调用单字节写入方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">int</span> b)</span></span></span><br><span class="line"><span class="function">           <span class="keyword">throws</span> IOException</span></span><br></pre></td></tr></table></figure>
<p>而 BufferedOutputStream 中的可以一次性将这些字节写入输出流, 因此效率比较高.</p>
<h2 id="DataInputStream-数据输入流"><a href="#DataInputStream-数据输入流" class="headerlink" title="DataInputStream 数据输入流"></a>DataInputStream 数据输入流</h2><p>DataInputStream几乎可以任何形式输出，而<code>readLine()</code>是唯一成不了首选的原因。</p>
<p>数据输出流允许应用程序以适当方式将基本 Java 数据类型写入输出流中。然后，应用程序可以使用数据输入流将数据读入。</p>
<p>使用DataInputStream写字符串并且能够通过DataInputStream恢复的唯一的方法是使用UTF-8编码</p>
<h2 id="DataOutputStream-数据输出流"><a href="#DataOutputStream-数据输出流" class="headerlink" title="DataOutputStream 数据输出流"></a>DataOutputStream 数据输出流</h2><p>不同的数据类型(基本数据类型和String对象)的读取方法都以<code>read</code>开头，如<code>readByte()</code>、<code>readFloat()</code>等</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataOutputStream outputStream = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="string">&quot;abc.txt&quot;</span>)));</span><br><span class="line">outputStream.writeDouble(<span class="number">3.14159265358979</span>);</span><br><span class="line">outputStream.writeUTF(<span class="string">&quot;仅仅是测试&quot;</span>);</span><br><span class="line">outputStream.writeDouble(<span class="number">3.58979</span>);</span><br><span class="line">outputStream.writeUTF(<span class="string">&quot;不仅仅是测试&quot;</span>);</span><br><span class="line">outputStream.close();</span><br><span class="line"></span><br><span class="line">DataInputStream inputStream = <span class="keyword">new</span> DataInputStream(<span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="string">&quot;abc.txt&quot;</span>)));</span><br><span class="line">System.out.println(inputStream.readDouble());</span><br><span class="line">System.out.println(inputStream.readUTF());</span><br><span class="line">System.out.println(inputStream.readDouble());</span><br><span class="line">System.out.println(inputStream.readUTF());</span><br><span class="line">inputStream.close();</span><br></pre></td></tr></table></figure>


<h1 id="字符流-1"><a href="#字符流-1" class="headerlink" title="字符流"></a>字符流</h1><h2 id="FileReader-文件输入字符流"><a href="#FileReader-文件输入字符流" class="headerlink" title="FileReader 文件输入字符流"></a>FileReader 文件输入字符流</h2><p>用来读取字符文件的便捷类。此类的构造方法假定默认字符编码和默认字节缓冲区大小都是适当的。<br>要自己指定这些值，可以先在 FileInputStream 上构造一个 InputStreamReader。<br>FileReader 用于读取字符流。要读取原始字节流，请考虑使用 FileInputStream。</p>
<h2 id="FileWriter-文件输出字符流"><a href="#FileWriter-文件输出字符流" class="headerlink" title="FileWriter 文件输出字符流"></a>FileWriter 文件输出字符流</h2><p>用来写入字符文件的便捷类。此类的构造方法假定默认字符编码和默认字节缓冲区大小都是可接受的。<br>要自己指定这些值，可以先在 FileOutputStream 上构造一个 OutputStreamWriter。</p>
<p>文件是否可用或是否可以被创建取决于底层平台。特别是某些平台一次只允许一个 FileWriter（或其他文件写入对象）打开文件进行写入。<br>在这种情况下，如果所涉及的文件已经打开，则此类中的构造方法将失败。</p>
<p>FileWriter 用于写入字符流。要写入原始字节流，请考虑使用 FileOutputStream。</p>
<h2 id="BufferedReader-缓冲字符输入流"><a href="#BufferedReader-缓冲字符输入流" class="headerlink" title="BufferedReader 缓冲字符输入流"></a>BufferedReader 缓冲字符输入流</h2><p>从<code>字符输入流</code>中读取文本，缓冲各个字符，从而实现字符、数组和行的高效读取。<br>可以指定缓冲区的大小，或者可使用默认的大小。大多数情况下，默认值就足够大了。<br>通常，Reader 所作的每个读取请求都会导致对底层字符或字节流进行相应的读取请求。<br>因此，建议用 BufferedReader 包装所有其 read() 操作可能开销很高的 Reader（如 FileReader 和 InputStreamReader）。例如，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BufferedReader in</span><br><span class="line">   = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(<span class="string">&quot;foo.in&quot;</span>));</span><br></pre></td></tr></table></figure>
<p>将缓冲指定文件的输入。如果没有缓冲，则每次调用 read() 或 readLine() 都会导致从文件中读取字节，并将其转换为字符后返回，而这是极其低效的。</p>
<p>通过用合适的 BufferedReader 替代每个 DataInputStream，可以对将 DataInputStream 用于文字输入的程序进行本地化。</p>
<p>主要的方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">String 	<span class="title">readLine</span><span class="params">()</span></span></span><br><span class="line"><span class="function">	  读取一个文本行。</span></span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">ready</span><span class="params">()</span></span></span><br><span class="line"><span class="function">	  判断此流是否已准备好被读取。</span></span><br></pre></td></tr></table></figure>
<h2 id="BufferedWriter-缓冲字符输出流"><a href="#BufferedWriter-缓冲字符输出流" class="headerlink" title="BufferedWriter 缓冲字符输出流"></a>BufferedWriter 缓冲字符输出流</h2><p>将文本写入字符输出流，缓冲各个字符，从而提供单个字符、数组和字符串的高效写入。<br>可以指定缓冲区的大小，或者接受默认的大小。在大多数情况下，默认值就足够大了。<br>该类提供了 newLine() 方法，它使用平台自己的行分隔符概念，此概念由系统属性 line.separator 定义。<br>并非所有平台都使用新行符 (‘\n’) 来终止各行。因此调用此方法来终止每个输出行要优于直接写入新行符。</p>
<p>通常 Writer 将其输出立即发送到底层字符或字节流。<br>除非要求提示输出，否则建议用 BufferedWriter 包装所有其 write() 操作可能开销很高的 Writer（如 FileWriters 和 OutputStreamWriters）。<br>例如，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PrintWriter out = <span class="keyword">new</span> PrintWriter(<span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> FileWriter(<span class="string">&quot;foo.out&quot;</span>)));</span><br></pre></td></tr></table></figure>
<p>将缓冲 PrintWriter 对文件的输出。如果没有缓冲，则每次调用 print() 方法会导致将字符转换为字节，然后立即写入到文件，而这是极其低效的。</p>
<h2 id="PrintWriter-打印输出字符流"><a href="#PrintWriter-打印输出字符流" class="headerlink" title="PrintWriter 打印输出字符流"></a>PrintWriter 打印输出字符流</h2><p>向文本输出流打印对象的格式化表示形式，支持写入各种格式的字符流。但不能写入字节流。</p>
<p>如果启用了自动刷新(<code>autoFlush</code>)，则只有在调用 println、printf 或 format 的其中一个方法时才可能完成此操作，而不是每当正好输出换行符时才完成。这些方法使用平台自有的行分隔符概念，而不是换行符。</p>
<p>为了更容易的过渡到使用<code>PrintWriter</code>，他提供了一个既能接受<code>Writer</code>对象又能接收<code>OutputStream</code>对象的构造器。<br>甚至提供了可以直接接收文件的构造器。</p>
<p>例如，基本文件输出</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PrintWriter printWriter = <span class="keyword">new</span> PrintWriter(<span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> FileWriter(<span class="string">&quot;abc.text&quot;</span>)));</span><br><span class="line">PrintWriter printWriter = <span class="keyword">new</span> PrintWriter(<span class="string">&quot;abc.text&quot;</span>); <span class="comment">//快捷方式</span></span><br></pre></td></tr></table></figure>
<p>构造器有:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PrintWriter(File file)</span><br><span class="line">  使用指定文件创建不具有自动行刷新的新 PrintWriter。</span><br><span class="line">PrintWriter(File file, String csn)</span><br><span class="line">  创建具有指定文件和字符集且不带自动刷行新的新 PrintWriter。</span><br><span class="line">PrintWriter(OutputStream out)</span><br><span class="line">  根据现有的 OutputStream 创建不带自动行刷新的新 PrintWriter。</span><br><span class="line">PrintWriter(OutputStream out, <span class="keyword">boolean</span> autoFlush)</span><br><span class="line">  通过现有的 OutputStream 创建新的 PrintWriter。</span><br><span class="line">PrintWriter(String fileName)</span><br><span class="line">  创建具有指定文件名称且不带自动行刷新的新 PrintWriter。</span><br><span class="line">PrintWriter(String fileName, String csn)</span><br><span class="line">  创建具有指定文件名称和字符集且不带自动行刷新的新 PrintWriter。</span><br><span class="line">PrintWriter(Writer out)</span><br><span class="line">  创建不带自动行刷新的新 PrintWriter。</span><br><span class="line">PrintWriter(Writer out, <span class="keyword">boolean</span> autoFlush)</span><br><span class="line">  创建新 PrintWriter。</span><br></pre></td></tr></table></figure>
<p>构造PrintWriter的方式主要有： <code>File</code>或者文件名、<code>OutputStream</code>以及<code>Writer</code>.</p>
<p>主要的方法：</p>
<p>append方法将指定字符、字符序列和指定字符序列的子序列添加到此 writer。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">PrintWriter 	<span class="title">append</span><span class="params">(<span class="keyword">char</span> c)</span></span></span><br><span class="line"><span class="function">PrintWriter 	<span class="title">append</span><span class="params">(CharSequence csq)</span></span></span><br><span class="line"><span class="function">PrintWriter 	<span class="title">append</span><span class="params">(CharSequence csq, <span class="keyword">int</span> start, <span class="keyword">int</span> end)</span></span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> 	<span class="title">println</span><span class="params">()</span> 通过写入行分隔符字符串终止当前行。</span></span><br></pre></td></tr></table></figure>
<p>PrintStream 存在两个重要的方法：<code>print</code>和<code>println</code>。对它们了重载，以便可打印出各种不同的类型。<br><code>print</code>可以打印的类型有 <code>boolean</code> <code>char</code> <code>char[]</code> <code>double</code> <code>float</code> <code>int</code> <code>long</code> <code>Object</code>和<code>String</code>.<br><code>println</code>的参数有<code>boolean</code> <code>char</code> <code>char[]</code> <code>double</code> <code>float</code> <code>int</code> <code>long</code> <code>Object</code>和<code>String</code>.</p>
<p><code>printf</code>、<code>format</code>和<code>write</code>可以打印更多的格式</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">PrintWriter 	<span class="title">printf</span><span class="params">(Locale l, String format, Object... args)</span></span></span><br><span class="line"><span class="function">PrintWriter 	<span class="title">printf</span><span class="params">(String format, Object... args)</span></span></span><br><span class="line"><span class="function">PrintWriter 	<span class="title">format</span><span class="params">(Locale l, String format, Object... args)</span></span></span><br><span class="line"><span class="function">        使用指定格式字符串和参数将一个格式化字符串写入此 writer 中。</span></span><br><span class="line"><span class="function">PrintWriter 	<span class="title">format</span><span class="params">(String format, Object... args)</span></span></span><br><span class="line"><span class="function">        使用指定格式字符串和参数将一个格式化字符串写入此 writer 中。</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> 	<span class="title">write</span><span class="params">(<span class="keyword">char</span>[] buf)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> 	<span class="title">write</span><span class="params">(<span class="keyword">char</span>[] buf, <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> 写入字符数组，字符数组的某一部分。</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> 	<span class="title">write</span><span class="params">(<span class="keyword">int</span> c)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> 	<span class="title">write</span><span class="params">(String s)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> 	<span class="title">write</span><span class="params">(String s, <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function">        写入单个字符、字符串及字符串的一部分。</span></span><br></pre></td></tr></table></figure>
<p>其他方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> 	<span class="title">checkError</span><span class="params">()</span></span></span><br><span class="line"><span class="function">        如果流没有关闭，则刷新流且检查其错误状态。</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span>  <span class="keyword">void</span> 	<span class="title">setError</span><span class="params">()</span></span></span><br><span class="line"><span class="function">                指示已发生错误。</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span>  <span class="keyword">void</span> 	<span class="title">clearError</span><span class="params">()</span></span></span><br><span class="line"><span class="function">        清除此流的错误状态。</span></span><br></pre></td></tr></table></figure>



<h2 id="InputStreamReader-输入流转换器"><a href="#InputStreamReader-输入流转换器" class="headerlink" title="InputStreamReader 输入流转换器"></a>InputStreamReader 输入流转换器</h2><p>有时需要将字节流转换为字符流，为了实现这个目的，要用到<code>适配器(adapter)</code>类： <code>InputStreamReader</code>将<code>InputStream</code>转换为<code>Reader</code>； <code>OutputStreamWriter</code>将<code>OutputStream</code>转换为<code>Writer</code></p>
<h2 id="OutputStreamWriter-输出流转换器"><a href="#OutputStreamWriter-输出流转换器" class="headerlink" title="OutputStreamWriter 输出流转换器"></a>OutputStreamWriter 输出流转换器</h2><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="管道流"><a href="#管道流" class="headerlink" title="管道流"></a>管道流</h3><ol>
<li>PipedInputStream </li>
<li>PipedOutputStream </li>
<li>PipedReader </li>
<li>PipedWriter</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 验证管道流</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消息发送类</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Send</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">   <span class="keyword">private</span> PipedOutputStream out=<span class="keyword">null</span>;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">Send</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       out = <span class="keyword">new</span> PipedOutputStream();</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> PipedOutputStream <span class="title">getOut</span><span class="params">()</span></span>&#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">this</span>.out;</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">       String message = <span class="string">&quot;hello , Rollen&quot;</span>;</span><br><span class="line">       <span class="keyword">try</span>&#123;</span><br><span class="line">           out.write(message.getBytes());</span><br><span class="line">       &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;<span class="keyword">try</span>&#123;</span><br><span class="line">           out.close();</span><br><span class="line">       &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 接受消息类</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Recive</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">   <span class="keyword">private</span> PipedInputStream input=<span class="keyword">null</span>;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">Recive</span><span class="params">()</span></span>&#123;</span><br><span class="line">       <span class="keyword">this</span>.input=<span class="keyword">new</span> PipedInputStream();</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> PipedInputStream <span class="title">getInput</span><span class="params">()</span></span>&#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">this</span>.input;</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">       <span class="keyword">byte</span>[] b=<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1000</span>];</span><br><span class="line">       <span class="keyword">int</span> len=<span class="number">0</span>;</span><br><span class="line">       <span class="keyword">try</span>&#123;</span><br><span class="line">           len=<span class="keyword">this</span>.input.read(b);</span><br><span class="line">       &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;<span class="keyword">try</span>&#123;</span><br><span class="line">           input.close();</span><br><span class="line">       &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">       System.out.println(<span class="string">&quot;接受的内容为 &quot;</span>+(<span class="keyword">new</span> String(b,<span class="number">0</span>,len)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 测试类</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">hello</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">       Send send=<span class="keyword">new</span> Send();</span><br><span class="line">       Recive recive=<span class="keyword">new</span> Recive();</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line"><span class="comment">//管道连接</span></span><br><span class="line">           send.getOut().connect(recive.getInput());</span><br><span class="line">       &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">new</span> Thread(send).start();</span><br><span class="line">       <span class="keyword">new</span> Thread(recive).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="SequenceInputStream"><a href="#SequenceInputStream" class="headerlink" title="SequenceInputStream"></a>SequenceInputStream</h3><p>SequenceInputStream可以认为是一个工具类，将两个或者多个输入流当成一个输入流依次读取。完全可以从IO 包中去除，还完全不影响IO 包的结构，却让其更“纯洁”――纯洁的Decorator 模式。<br>【案例】将两个文本文件合并为另外一个文本文件</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 将两个文本文件合并为另外一个文本文件</span></span><br><span class="line"><span class="comment">* */</span></span><br><span class="line"></span><br><span class="line">File file1 = newFile(<span class="string">&quot;d:&quot;</span> + File.separator + <span class="string">&quot;hello1.txt&quot;</span>);</span><br><span class="line">File file2 = newFile(<span class="string">&quot;d:&quot;</span> + File.separator + <span class="string">&quot;hello2.txt&quot;</span>);</span><br><span class="line">File file3 = newFile(<span class="string">&quot;d:&quot;</span> + File.separator + <span class="string">&quot;hello.txt&quot;</span>);</span><br><span class="line">InputStream input1 =<span class="keyword">new</span> FileInputStream(file1);</span><br><span class="line">InputStream input2 =<span class="keyword">new</span> FileInputStream(file2);</span><br><span class="line">OutputStream output =<span class="keyword">new</span> FileOutputStream(file3);</span><br><span class="line"><span class="comment">// 合并流</span></span><br><span class="line">SequenceInputStream sis = <span class="keyword">new</span> SequenceInputStream(input1, input2);</span><br><span class="line"><span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>((temp =sis.read()) != -<span class="number">1</span>)&#123;</span><br><span class="line">   output.write(temp);</span><br><span class="line">&#125;</span><br><span class="line">input1.close();</span><br><span class="line">input2.close();</span><br><span class="line">output.close();</span><br><span class="line">sis.close();</span><br></pre></td></tr></table></figure>
<h1 id="RandomAccessFile"><a href="#RandomAccessFile" class="headerlink" title="RandomAccessFile"></a>RandomAccessFile</h1><p>支持搜寻方法，并且只适用于文件。</p>
<p>getFilePointer() 用于查找当前所处的文件位置，seek() 用于在文件内移至新的位置, length()用于判断文件的最大尺寸. 构造器支持在第二个参数中指示<code>随机读(r)</code>还是<code>读写(rw)</code>.但是不支持只写.<br>在JDK1.4后, RandomAccessFile的大多数功能由NIO存储映射文件所取代.</p>
<h2 id="断点下载"><a href="#断点下载" class="headerlink" title="断点下载"></a>断点下载</h2><blockquote>
<p>注意: </p>
<ol>
<li>使用 <code>FileWriter</code>、<code>BufferedOutputStream</code> 或者 <code>BufferedWriter</code> 写文件时，一定要清理缓冲区并且关闭输出流，否则会造成写入的内容丢失</li>
<li>使用字符流装饰字节流时，一定要都关闭掉</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>如何判断读到文件结尾? </li>
</ol>
</blockquote>
<ul>
<li>字符流: 每一个<code>Reader</code>都包含一个<code>ready()</code>方法，该方法用于判断IO是否准备完毕，但是不能是否读到文件的结尾。判断是否读到文件结尾要通过判断读入的内容是否为空判断。</li>
</ul>
<h1 id="File类"><a href="#File类" class="headerlink" title="File类"></a>File类</h1><h2 id="getPath-getAbsolutePath和getCanonicalPath"><a href="#getPath-getAbsolutePath和getCanonicalPath" class="headerlink" title="getPath getAbsolutePath和getCanonicalPath"></a>getPath getAbsolutePath和getCanonicalPath</h2><ul>
<li><code>public String getPath()</code> 获取为文件赋值时的路径名</li>
<li><code>public String getAbsolutePath()</code> 获取绝对路径名（包含<code>..</code>和<code>.</code>等字符）。</li>
<li><code>public String getCanonicalPath()throws IOException</code> 获取规范路径名(经过计算后的精简路径名)</li>
</ul>
<h3 id="getCanonicalPath"><a href="#getCanonicalPath" class="headerlink" title="getCanonicalPath()"></a>getCanonicalPath()</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File file = <span class="keyword">new</span> File(<span class="string">&quot;D:\\Text.txt&quot;</span>);</span><br><span class="line">System.out.println(file.getCanonicalPath());</span><br></pre></td></tr></table></figure>
<p>Windows系统下<br>(1),确定D盘下没有Text.txt这个文件，直接执行这段代码，得到的结果是:<br><code>D:\Text.txt</code><br>注意这里试大写的Text.txt<br>(2)在D盘下建立一个文件，名叫text.txt，再次执行代码，得到结果<br><code>D:\text.txt</code></p>
<p>尝试在linux下执行上边的步骤，两次打印的结果是相同的，因为linux是大小写敏感的系统。</p>
<h2 id="遍历目录下的文件"><a href="#遍历目录下的文件" class="headerlink" title="遍历目录下的文件"></a>遍历目录下的文件</h2><ul>
<li>String[]     list()<pre><code>返回一个字符串数组，这些字符串指定此抽象路径名表示的目录中的文件和目录。</code></pre>
</li>
<li>String[] list(FilenameFilter filter)<pre><code>返回一个字符串数组，这些字符串指定此抽象路径名表示的目录中满足指定过滤器的文件和目录。</code></pre>
</li>
<li>File[] listFiles()<pre><code>返回一个抽象路径名数组，这些路径名表示此抽象路径名表示的目录中的文件。</code></pre>
</li>
<li>File[] listFiles(FileFilter filter)<pre><code>返回抽象路径名数组，这些路径名表示此抽象路径名表示的目录中满足指定过滤器的文件和目录。</code></pre>
</li>
<li>File[] listFiles(FilenameFilter filter)<pre><code>返回抽象路径名数组，这些路径名表示此抽象路径名表示的目录中满足指定过滤器的文件和目录。</code></pre>
</li>
</ul>
<p>上面的遍历方法中存在两个通过FilenameFilter和FileFilter过滤文件的方法。<br>这是<a href="/java-XML-JSON/">策略模式</a>的典型应用。<br>以<code>String[] list(FilenameFilter filter)</code>为例<br>list提供了基本的功能，而且按照FilenameFilter的形式提供策略，以便完善list在提供服务时所需的算法。因为list接受FilenameFilter对象作为参数， 任何实现了FilenameFilter接口的对象都可以传递给list方法，用以选择list方法的行为方式。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">FilenameFilter</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">accept</span><span class="params">(File dir, String name)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File srcDir=<span class="keyword">new</span> File(<span class="string">&quot;~/testDir&quot;</span>);</span><br><span class="line">File[] files = srcDir.listFiles(</span><br><span class="line"> <span class="keyword">new</span> FilenameFilter()&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">accept</span><span class="params">(File dir, String name)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> name.endsWith(<span class="string">&quot;.java&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="设置指定权限"><a href="#设置指定权限" class="headerlink" title="设置指定权限"></a>设置指定权限</h2><h2 id="迭代创建目录"><a href="#迭代创建目录" class="headerlink" title="迭代创建目录"></a>迭代创建目录</h2><p><code>public boolean mkdirs()</code> 创建此抽象路径名指定的目录，包括所有必需但不存在的父目录。注意，此操作失败时也可能已经成功地创建了一部分必需的父目录。</p>
<h2 id="文件系统根"><a href="#文件系统根" class="headerlink" title="文件系统根"></a>文件系统根</h2><p><code>public static File[] listRoots()</code></p>
<h1 id="样例模板"><a href="#样例模板" class="headerlink" title="样例模板"></a>样例模板</h1><h2 id="关闭"><a href="#关闭" class="headerlink" title="关闭"></a>关闭</h2><p>无论使用任何方式打开文件或者流,必须准确的关闭, 标准的形式是在try-catch语句块的finally中关闭.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String fileName = <span class="string">&quot;abc.txt&quot;</span>;</span><br><span class="line">BufferedReader bufferedReader = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    Reader reader = <span class="keyword">new</span> FileReader(fileName);</span><br><span class="line">    bufferedReader = <span class="keyword">new</span> BufferedReader(reader);</span><br><span class="line">    StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    String s;</span><br><span class="line">    <span class="keyword">while</span> ((s = bufferedReader.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        sb.append(s + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (bufferedReader != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            bufferedReader.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h2><p>直接通过FileInputStream, 由于没有使用缓冲<code>BufferedInputStream</code>包装, 每次读取一组字节其实是在一个字节一个字节的从系统中读取.</p>
<h3 id="一次性读入字节数组"><a href="#一次性读入字节数组" class="headerlink" title="一次性读入字节数组"></a>一次性读入字节数组</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File f=<span class="keyword">new</span> File(fileName);</span><br><span class="line">InputStream in=<span class="keyword">new</span> FileInputStream(f);</span><br><span class="line"><span class="keyword">byte</span>[] b=<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">int</span> len = in.read(b);</span><br><span class="line">in.close();</span><br><span class="line">String content = <span class="keyword">new</span> String(b,<span class="number">0</span>,len);</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File f=<span class="keyword">new</span> File(fileName);</span><br><span class="line">InputStream in=<span class="keyword">new</span> FileInputStream(f);</span><br><span class="line"><span class="keyword">byte</span>[] b=<span class="keyword">new</span> <span class="keyword">byte</span>[f.length()];</span><br><span class="line">in.read(b);</span><br><span class="line">in.close();</span><br><span class="line">String content = <span class="keyword">new</span> String(b);</span><br></pre></td></tr></table></figure>
<h3 id="逐个字节读"><a href="#逐个字节读" class="headerlink" title="逐个字节读"></a>逐个字节读</h3><p>FileInputStream的底层原理决定了和上面的读法是一样的<br>读取字节流时, 读到文件的末尾的时候会返回-1, 以此作为判断读取结束的依据.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File f=<span class="keyword">new</span> File(fileName);</span><br><span class="line">InputStream in=<span class="keyword">new</span> FileInputStream(f);</span><br><span class="line"><span class="keyword">byte</span>[] b=<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">int</span> count =<span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> temp=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>((temp=in.read())!=(-<span class="number">1</span>))&#123;</span><br><span class="line">   b[count++]=(<span class="keyword">byte</span>)temp;</span><br><span class="line">&#125;</span><br><span class="line">in.close();</span><br><span class="line">System.out.println(<span class="keyword">new</span> String(b));</span><br></pre></td></tr></table></figure>
<h3 id="加缓冲"><a href="#加缓冲" class="headerlink" title="加缓冲"></a>加缓冲</h3><p>使用<code>BufferedInputStream</code>包装输入流</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File f=<span class="keyword">new</span> File(fileName);</span><br><span class="line">InputStream in=<span class="keyword">new</span> FileInputStream(f);</span><br><span class="line">BufferedInputStream bf = <span class="keyword">new</span> BufferedInputStream(in);</span><br><span class="line"><span class="keyword">byte</span>[] b=<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">int</span> len = bf.read(b);</span><br><span class="line">in.close();</span><br><span class="line">String content = <span class="keyword">new</span> String(b,<span class="number">0</span>,len);</span><br></pre></td></tr></table></figure>
<h3 id="字符流读取"><a href="#字符流读取" class="headerlink" title="字符流读取"></a>字符流读取</h3><p>不加缓冲</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 直接通过字符流读文件 file可为File对象或者文件名String</span></span><br><span class="line">FileReader fileReader = <span class="keyword">new</span> FileReader(file);</span><br><span class="line"><span class="keyword">char</span>[] content = <span class="keyword">new</span> <span class="keyword">char</span>[file.length()]; <span class="comment">// 调用该方法file必须为File对象</span></span><br><span class="line">fileReader.read(content);</span><br><span class="line">System.out.println(<span class="keyword">new</span> String(content));</span><br></pre></td></tr></table></figure>
<p>加缓冲</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建FileInputStream</span></span><br><span class="line">FileInputStream fileInputStream = <span class="keyword">new</span> FileInputStream(file);</span><br><span class="line"><span class="comment">// 将字节流转换为字符流</span></span><br><span class="line">InputStreamReader inputStreamReader = <span class="keyword">new</span> InputStreamReader(fileInputStream);</span><br><span class="line"><span class="comment">// 给字符流加缓冲</span></span><br><span class="line">BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(inputStreamReader);</span><br><span class="line">String s = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">while</span> ((s = bufferedReader.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">	System.out.println(s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 直接通过字符流读文件 file可为File对象或者文件名String</span></span><br><span class="line">FileReader fileReader = <span class="keyword">new</span> FileReader(file);</span><br><span class="line"><span class="comment">// 给字符流加缓冲</span></span><br><span class="line">BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(fileReader);</span><br><span class="line">String s;</span><br><span class="line"><span class="keyword">while</span> ((s = bufferedReader.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">	System.out.println(s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h2><h3 id="字节流写文件"><a href="#字节流写文件" class="headerlink" title="字节流写文件"></a>字节流写文件</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">OutputStream out =<span class="keyword">new</span> FileOutputStream(file);</span><br><span class="line">String str=<span class="string">&quot;Hello World&quot;</span>;</span><br><span class="line"><span class="keyword">byte</span>[] b=str.getBytes();</span><br><span class="line">out.write(b);</span><br><span class="line">out.close();</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">OutputStream out =<span class="keyword">new</span> FileOutputStream(file);</span><br><span class="line">String str=<span class="string">&quot;Hello World！！&quot;</span>;</span><br><span class="line"><span class="keyword">byte</span>[] b=str.getBytes();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; b.length; i++) &#123;</span><br><span class="line">   out.write(b[i]);</span><br><span class="line">&#125;</span><br><span class="line">out.close();</span><br></pre></td></tr></table></figure>
<h3 id="加缓冲-1"><a href="#加缓冲-1" class="headerlink" title="加缓冲"></a>加缓冲</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">OutputStream outputStream = <span class="keyword">new</span> FileOutputSteam(file);</span><br><span class="line">BufferedOutputStream bf = <span class="keyword">new</span> BufferedOutputStream(outputStream);</span><br><span class="line">bf.write(str.getBytes());</span><br></pre></td></tr></table></figure>
<h3 id="利用字节流写文件"><a href="#利用字节流写文件" class="headerlink" title="利用字节流写文件"></a>利用字节流写文件</h3><p>不加缓冲, 底层实现是逐个字符添加到系统文件中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">FileWriter fileWriter = <span class="keyword">new</span> FileWriter(file);</span><br><span class="line">bufferedWriter.write(<span class="string">&quot;Hellp world!&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>加缓冲</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// file为File对象 文件名字符串 FileDescriptor对象</span></span><br><span class="line">FileOutputStream fileOutputStream = <span class="keyword">new</span> FileOutputStream(file);</span><br><span class="line"><span class="comment">// 字节流转换为字节流</span></span><br><span class="line">OutputStreamWriter outputStreamWriter = <span class="keyword">new</span> OutputStreamWriter(fileOutputStream);</span><br><span class="line"><span class="comment">// 加缓冲</span></span><br><span class="line">BufferedWriter bufferedWriter = <span class="keyword">new</span> BufferedWriter(outputStreamWriter);</span><br><span class="line">bufferedWriter.write(<span class="string">&quot;hello world!&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">FileWriter fileWriter = <span class="keyword">new</span> FileWriter(file);</span><br><span class="line">BufferedWriter bufferedWriter = <span class="keyword">new</span> BufferedWriter(fileWriter);</span><br><span class="line">bufferedWriter.write(<span class="string">&quot;Hello world!&quot;</span>);</span><br></pre></td></tr></table></figure>


<h3 id="格式化字符输出"><a href="#格式化字符输出" class="headerlink" title="格式化字符输出"></a>格式化字符输出</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PrintWriter printWriter = <span class="keyword">new</span> PrintWriter(<span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> FileWriter(<span class="string">&quot;abc.text&quot;</span>)));</span><br><span class="line">PrintWriter printWriter = <span class="keyword">new</span> PrintWriter(<span class="string">&quot;abc.text&quot;</span>); <span class="comment">//快捷方式, 本身就已经添加了缓冲</span></span><br></pre></td></tr></table></figure>
<h2 id="内存中的字符串读取"><a href="#内存中的字符串读取" class="headerlink" title="内存中的字符串读取"></a>内存中的字符串读取</h2><h3 id="从内存逐个字节读入字符串"><a href="#从内存逐个字节读入字符串" class="headerlink" title="从内存逐个字节读入字符串"></a>从内存逐个字节读入字符串</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">&quot;这是需要读入的字符串&quot;</span>;</span><br><span class="line">StringReader stringReader = <span class="keyword">new</span> StringReader(s);</span><br><span class="line"><span class="keyword">int</span> c = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> ((c = stringReader.read()) != -<span class="number">1</span>) &#123;</span><br><span class="line">        System.out.println((<span class="keyword">char</span>) c);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    stringReader.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这</span><br><span class="line">是</span><br><span class="line">需</span><br><span class="line">要</span><br><span class="line">读</span><br><span class="line">入</span><br><span class="line">的</span><br><span class="line">字</span><br><span class="line">符</span><br><span class="line">串</span><br></pre></td></tr></table></figure>
<h3 id="格式化内存输入"><a href="#格式化内存输入" class="headerlink" title="格式化内存输入"></a>格式化内存输入</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">&quot;这是需要输出的字符串!&quot;</span>;</span><br><span class="line">ByteArrayInputStream inputStream = <span class="keyword">new</span> ByteArrayInputStream(s.getBytes());</span><br><span class="line">DataInputStream in = <span class="keyword">new</span> DataInputStream(inputStream);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">   <span class="keyword">while</span> (in.available() != <span class="number">0</span>) &#123;</span><br><span class="line">       System.out.println((<span class="keyword">char</span>) in.readByte());</span><br><span class="line">   &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">   System.err.println(<span class="string">&quot;End of Stream&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">       in.close();</span><br><span class="line">   &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">       e.printStackTrace();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DataInputStream.available()方法检测还有多少可供读取的字符</p>
<h2 id="文件拷贝"><a href="#文件拷贝" class="headerlink" title="文件拷贝"></a>文件拷贝</h2><p>这是采用Java IO实现的版本， 采用<a href="/Java/io/NIO/">Java NIO</a>可以大大提高效率。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File file1=<span class="keyword">new</span> File(args[<span class="number">0</span>]);</span><br><span class="line">File file2=<span class="keyword">new</span> File(args[<span class="number">1</span>]);</span><br><span class="line">InputStream input=<span class="keyword">new</span> FileInputStream(file1);</span><br><span class="line">OutputStream output=<span class="keyword">new</span> FileOutputStream(file2);</span><br><span class="line"><span class="keyword">if</span>((input!=<span class="keyword">null</span>)&amp;&amp;(output!=<span class="keyword">null</span>))&#123;</span><br><span class="line">   <span class="keyword">int</span> temp=<span class="number">0</span>;</span><br><span class="line">   <span class="keyword">while</span>((temp=input.read())!=(-<span class="number">1</span>))&#123;</span><br><span class="line">		output.write(temp);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">input.close();</span><br><span class="line">output.close();</span><br></pre></td></tr></table></figure>
<h2 id="RandomAccessFile-1"><a href="#RandomAccessFile-1" class="headerlink" title="RandomAccessFile"></a>RandomAccessFile</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String fileName=<span class="string">&quot;D:&quot;</span>+File.separator+<span class="string">&quot;hello.txt&quot;</span>;</span><br><span class="line">File f=<span class="keyword">new</span> File(fileName);</span><br><span class="line">RandomAccessFile demo=<span class="keyword">new</span> RandomAccessFile(f,<span class="string">&quot;rw&quot;</span>);</span><br><span class="line">demo.writeBytes(<span class="string">&quot;asdsad&quot;</span>);</span><br><span class="line">demo.writeInt(<span class="number">12</span>);</span><br><span class="line">demo.writeBoolean(<span class="keyword">true</span>);</span><br><span class="line">demo.writeChar(<span class="string">&#x27;A&#x27;</span>);</span><br><span class="line">demo.writeFloat(<span class="number">1.21f</span>);</span><br><span class="line">demo.writeDouble(<span class="number">12.123</span>);</span><br><span class="line">demo.close();</span><br></pre></td></tr></table></figure>
<h2 id="与字节数组结合"><a href="#与字节数组结合" class="headerlink" title="与字节数组结合"></a>与字节数组结合</h2><p>//TODO 与字节数组</p>
<h1 id="标准IO"><a href="#标准IO" class="headerlink" title="标准IO"></a>标准IO</h1><p>三个标准IO分别是 <code>System.out</code> <code>System.err</code>  <code>System.in</code>, <code>System.out</code>和<code>System.err</code>已经包装成<code>PrintStream</code>对象, 而<code>System.io</code>是没有被包装的未经过加工的<code>InputStream</code>, 因此在读取<code>System.io</code>之前必须对其进行包装.</p>
<p>例子: 一行一行读取系统输入</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">InputStreamReader in = <span class="keyword">new</span> InputStreamReader(System.in);</span><br><span class="line">BufferedReader stdin = <span class="keyword">new</span> BufferedReader(in);</span><br><span class="line">String s;</span><br><span class="line"><span class="keyword">while</span>((s = stdin.readLine())!=<span class="keyword">null</span> &amp;&amp; s.length!=<span class="number">0</span>)&#123;</span><br><span class="line">  System.out.println(s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>字符输出到标准输出</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PrintWriter out = <span class="keyword">new</span> PrintWriter(System.out,<span class="keyword">true</span>);</span><br><span class="line">out.println(<span class="string">&quot;hello , world!&quot;</span>);</span><br></pre></td></tr></table></figure>
<h2 id="标准IO重定向"><a href="#标准IO重定向" class="headerlink" title="标准IO重定向"></a>标准IO重定向</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">System.setIn(in);</span><br><span class="line">System.setOut(out);</span><br><span class="line">System.setErr(out);</span><br></pre></td></tr></table></figure>
<p>//TODO 如何重定向到<code>java.swing.JTextArea</code></p>
<h1 id="Java-IO-异常与错误"><a href="#Java-IO-异常与错误" class="headerlink" title="Java IO 异常与错误"></a>Java IO 异常与错误</h1><h1 id="进程控制"><a href="#进程控制" class="headerlink" title="进程控制"></a>进程控制</h1><p>所谓的进程控制, 是当Java 调用系统指令启动系统进程时, 利用Java IO输出运行过程中的输出和错位信息</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String command = <span class="string">&quot;CMD /C ping www.baidu.com&quot;</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  Process process = <span class="keyword">new</span> ProcessBuilder(command.split(<span class="string">&quot; &quot;</span>)).start();</span><br><span class="line">  InputStream inputStream = process.getInputStream();</span><br><span class="line">  InputStreamReader inputStreamReader = <span class="keyword">new</span> InputStreamReader(inputStream);</span><br><span class="line">  BufferedReader results = <span class="keyword">new</span> BufferedReader(inputStreamReader);</span><br><span class="line">  String s;</span><br><span class="line">  <span class="keyword">while</span> ((s = results.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">      System.out.println(s);</span><br><span class="line">  &#125;</span><br><span class="line">  BufferedReader errors = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(process.getErrorStream()));</span><br><span class="line">  <span class="keyword">while</span> ((s = errors.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">      System.out.println(s);</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<hr>
<p>[参考文献]:</p>
<ol>
<li>Think in Java</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
        <tag>InputStream</tag>
        <tag>OutputStream</tag>
        <tag>Reader</tag>
        <tag>Writer</tag>
      </tags>
  </entry>
  <entry>
    <title>IO模式(IO Model)与高性能IO设计模式</title>
    <url>/Java/io/IO-Model/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt; Java高级软件工程师知识结构</a></p>
<ol>
<li>掌握InputStream、OutputStream、Reader、Writer的继承体系.</li>
<li>掌握字节流(FileInputStream、DataInputStream、BufferedInputStream、FileOutputSteam、DataOutputStream、BufferedOutputStream)和 字符流(BufferedReader、InputStreamReader、FileReader、BufferedWriter、OutputStreamWriter、PrintWriter、FileWriter), 并熟练运用.</li>
<li>掌握NIO实现原理及使用方法.</li>
</ol>
<p>Java IO包括:</p>
<ul>
<li><a href="/Java/io/IO-Model/">IO Model</a></li>
<li><a href="/Java/io/BIO/">Java BIO</a></li>
<li><a href="/Java/io/NIO/">Java NIO</a></li>
<li><a href="/Java/io/AIO/">Java AIO</a></li>
<li><a href="/Java/io/java-zip/">Java压缩</a></li>
<li><a href="/Java/io/object-serialization/">Java序列化</a></li>
<li><a href="/Java/io/java-XML-JSON/">Java XML与JSON</a></li>
</ul>
<h1 id="IO模式"><a href="#IO模式" class="headerlink" title="IO模式"></a>IO模式</h1><p>IO模式可以分为:</p>
<ul>
<li>blocking IO 阻塞IO</li>
<li>nonblocking IO 非阻塞IO</li>
<li>IO multiplexing IO多路复用</li>
<li>asynchronous IO 异步IO</li>
</ul>
<p>所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。</p>
<p>需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在”干活”，而且这个过程非常快，属于memory copy，带宽通常在1GB/s级别以上，可以理解为基本不耗时。</p>
<p>对于一个network IO (这里我们以read举例), 它会涉及到两个系统对象,<br>一个是调用这个IO的process (or thread), 另一个就是系统内核(kernel).<br>当一个read操作发生时, 它会经历两个阶段：</p>
<ol>
<li>等待数据准备 (Waiting for the data to be ready)</li>
<li>将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)</li>
</ol>
<p>这些IO Model的区别就是在两个阶段上各有不同的情况.</p>
<h2 id="阻塞IO-blocking-IO"><a href="#阻塞IO-blocking-IO" class="headerlink" title="阻塞IO(blocking IO)"></a>阻塞IO(blocking IO)</h2><p><img src="/images/java/io/model/blocking.png" alt="b"></p>
<p>当用户进程调用了recvfrom这个系统调用, kernel就开始了IO的第一个阶段：准备数据. 对于network io来说, 很多时候数据在一开始还没有到达（比如, 还没有收到一个完整的UDP包）, 这个时候kernel就要等待足够的数据到来. 而在用户进程这边, 整个进程会被阻塞. 当kernel一直等到数据准备好了, 它就会将数据从kernel中拷贝到用户内存, 然后kernel返回结果, 用户进程才解除block的状态, 重新运行起来.</p>
<p>所以, blocking IO的特点就是在IO执行的两个阶段都被block了.</p>
<h2 id="非阻塞IO-nonblocking-IO"><a href="#非阻塞IO-nonblocking-IO" class="headerlink" title="非阻塞IO(nonblocking IO)"></a>非阻塞IO(nonblocking IO)</h2><p><img src="/images/java/io/model/noblocking.png" alt="n"></p>
<p>当用户进程发出read操作时, 如果kernel中的数据还没有准备好, 那么它并不会block用户进程, 而是立刻返回一个error. 从用户进程角度讲 , 它发起一个read操作后, 并不需要等待, 而是马上就得到了一个结果. 用户进程判断结果是一个error时, 它就知道数据还没有准备好, 于是它可以再次发送read操作. 一旦kernel中的数据准备好了, 并且又再次收到了用户进程的system call, 那么它马上就将数据拷贝到了用户内存, 然后返回.</p>
<p>所以, 用户进程其实是需要不断的主动询问kernel数据好了没有.</p>
<h2 id="IO多路复用-IO-multiplexing"><a href="#IO多路复用-IO-multiplexing" class="headerlink" title="IO多路复用(IO multiplexing)"></a>IO多路复用(IO multiplexing)</h2><p><img src="/images/java/io/model/ioMultiplexing.png" alt="m"></p>
<p>IO multiplexing就是<code>select/epoll</code>, 也称为<code>event driven IO</code>. <code>select/epoll</code> 的好处就在于单个process就可以同时处理多个网络连接的IO. 它的基本原理就是<code>select/epoll</code> 这个function会不断的轮询所负责的所有socket, 当某个socket有数据到达了, 就通知用户进程. 当用户进程调用了select, 那么整个进程会被block, 而同时, kernel会“监视”所有select负责的socket, 当任何一个socket中的数据准备好了, <code>select</code>就会返回. 这个时候用户进程再调用read操作, 将数据从kernel拷贝到用户进程.</p>
<p>这个图和blocking IO的图其实并没有太大的不同, 事实上, 还更差一些. 因为这里需要使用两个system call (select 和 recvfrom), 而blocking IO只调用了一个system call (recvfrom). 但是, 用select的优势在于它可以同时处理多个connection. （多说一句. 所以, 如果处理的连接数不是很高的话, 使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好, 可能延迟还更大. select/epoll的优势并不是对于单个连接能处理得更快, 而是在于能处理更多的连接. ）</p>
<p>在<code>IO multiplexing Model</code>中, 实际中, 对于每一个socket, 一般都设置成为non-blocking, 但是, 如上图所示, 整个用户的process其实是一直被block的. 只不过process是被<code>select</code>这个函数block, 而不是被<code>socket IO</code>给block.</p>
<h2 id="异步IO-asynchronous-IO"><a href="#异步IO-asynchronous-IO" class="headerlink" title="异步IO(asynchronous IO)"></a>异步IO(asynchronous IO)</h2><p><img src="/images/java/io/model/asynchronousIO.png" alt="a"><br>用户进程发起read操作之后, 立刻就可以开始去做其它的事. 而另一方面, 从kernel的角度, 当它收到一个asynchronous read之后, 首先它会立刻返回, 所以不会对用户进程产生任何block. 然后, kernel会等待数据准备完成, 然后将数据拷贝到用户内存, 当这一切都完成之后, kernel会给用户进程发送一个signal, 告诉它read操作完成了.</p>
<h2 id="四种模式比较"><a href="#四种模式比较" class="headerlink" title="四种模式比较"></a>四种模式比较</h2><p><img src="/images/java/io/model/comparison.png" alt="1"><br><img src="/images/java/io/model/comparison2.jpg" alt="2"></p>
<p>在Java中，以socket.read()为例子：</p>
<ol>
<li>传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。</li>
<li>对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。</li>
<li>最新的AIO(Async I/O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡到内存的过程也是异步的。</li>
</ol>
<p>换句话说，<br>BIO里用户最关心“我要读”，NIO里用户最关心”我可以读了”，在AIO模型里用户更需要关注的是“读完了”。<br>NIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）。</p>
<p><strong>blocking vs non-blocking</strong></p>
<p>调用blocking IO会一直block住对应的进程直到操作完成, 而non-blocking IO 在kernel还准备数据的情况下会立刻返回.</p>
<p><strong>synchronous IO vs asynchronous IO</strong></p>
<p>Stevens给出的定义（其实是POSIX的定义）是这样子的：</p>
<ul>
<li>A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;</li>
<li>An asynchronous I/O operation does not cause the requesting process to be blocked;</li>
</ul>
<p><code>synchronous IO</code>做”IO operation”的时候会将process阻塞. 按照这个定义, 之前所述的blocking IO, non-blocking IO, IO multiplexing都属于synchronous IO. 有人可能会说, non-blocking IO并没有被block啊. 这里有个非常“狡猾”的地方, 定义中所指的”IO operation”是指真实的IO操作, 就是例子中的recvfrom这个system call. non-blocking IO在执行recvfrom这个system call的时候, 如果kernel的数据没有准备好, 这时候不会block进程. 但是, 当kernel中数据准备好的时候, recvfrom会将数据从kernel拷贝到用户内存中, 这个时候进程是被block了, 在这段时间内, 进程是被block的. 而asynchronous IO则不一样, 当进程发起IO 操作之后, 就直接返回再也不理睬了, 直到kernel发送一个信号, 告诉进程说IO完成. 在这整个过程中, 进程完全没有被block.</p>
<p><strong>non-blocking IO vs asynchronous IO</strong></p>
<p>在non-blocking IO中, 虽然进程大部分时间都不会被block, 但是它仍然要求进程去主动的check, 并且当数据准备完成以后, 也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存. 而asynchronous IO则完全不同. 它就像是用户进程将整个IO操作交给了他人（kernel）完成, 然后他人做完后发信号通知. 在此期间, 用户进程不需要去检查IO操作的状态, 也不需要主动的去拷贝数据.</p>
<p>最后, 再举几个不是很恰当的例子来说明这四个IO Model<br>有A, B, C, D四个人在钓鱼：<br>A用的是最老式的鱼竿, 所以呢, 得一直守着, 等到鱼上钩了再拉杆;<br>B的鱼竿有个功能, 能够显示是否有鱼上钩, 所以呢, B就和旁边的MM聊天, 隔会再看看有没有鱼上钩, 有的话就迅速拉杆;<br>C用的鱼竿和B差不多, 但他想了一个好办法, 就是同时放好几根鱼竿, 然后守在旁边, 一旦有显示说鱼上钩了, 它就将对应的鱼竿拉起来;<br>D是个有钱人, 干脆雇了一个人帮他钓鱼, 一旦那个人把鱼钓上来了, 就给D发个短信.</p>
<h1 id="IO设计模式"><a href="#IO设计模式" class="headerlink" title="IO设计模式"></a>IO设计模式</h1><blockquote>
<p>FIXME reactor和proactor模式详细</p>
</blockquote>
<h2 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h2><p><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf">Doug Lea《scalable IO in Java》</a><br><a href="http://www.cnblogs.com/fxjwind/p/3363329.html">中文解读</a><br><a href="https://www.cnblogs.com/doit8791/p/7461479.html">another</a></p>
<p><img src="/images/java/io/model/reactor.png"></p>
<p>首先来看看Reactor模式, Reactor模式应用于同步I/O的场景. 我们以读操作为例来看看Reactor中的具体步骤：<br>读取操作：</p>
<ol>
<li>应用程序注册读就绪事件和相关联的事件处理器</li>
<li>事件分离器等待事件的发生</li>
<li>当发生读就绪事件的时候, 事件分离器调用第一步注册的事件处理器</li>
<li>事件处理器首先执行实际的读取操作, 然后根据读取到的内容进行进一步的处理</li>
</ol>
<h2 id="Proactor"><a href="#Proactor" class="headerlink" title="Proactor"></a>Proactor</h2><p><img src="/images/java/io/model/proactor.png"></p>
<p>读取操作：</p>
<ol>
<li>应用程序初始化一个异步读取操作, 然后注册相应的事件处理器, 此时事件处理器不关注读取就绪事件, 而是关注读取完成事件, 这是区别于Reactor的关键.</li>
<li>事件分离器等待读取操作完成事件</li>
<li>在事件分离器等待读取操作完成的时候, 操作系统调用内核线程完成读取操作, 并将读取的内容放入用户传递过来的缓存区中. 这也是区别于Reactor的一点, Proactor中, 应用程序需要传递缓存区.</li>
<li>事件分离器捕获到读取完成事件后, 激活应用程序注册的事件处理器, 事件处理器直接从缓存区读取数据, 而不需要进行实际的读取操作.</li>
</ol>
<p>Proactor中写入操作和读取操作, 只不过感兴趣的事件是写入完成事件.</p>
<p>从上面可以看出, Reactor和Proactor模式的主要区别就是真正的读取和写入操作是有谁来完成的, Reactor中需要应用程序自己读取或者写入数据, 而Proactor模式中, 应用程序不需要进行实际的读写过程, 它只需要从缓存区读取或者写入即可, 操作系统会读取缓存区或者写入缓存区到真正的IO设备</p>
<h2 id="IO设计模式比较"><a href="#IO设计模式比较" class="headerlink" title="IO设计模式比较"></a>IO设计模式比较</h2><p><strong>主动和被动</strong></p>
<p>Reactor被动的等待指示事件的到来并做出反应;它有一个等待的过程, 做什么都要先放到监听事件集<br>合中等待handler可用时再进行操作;Proactor直接调用异步读写操作, 调用完后立刻返回;<br>实现<br>Reactor实现了一个被动的事件分离和分发模型, 服务等待请求事件的到来, 再通过不受间断的同步处<br>理事件, 从而做出反应;<br>Proactor实现了一个主动的事件分离和分发模型;这种设计允许多个任务并发的执行, 从而提高吞吐<br>量;并可执行耗时长的任务（各个任务间互不影响）</p>
<p><strong>优点</strong></p>
<p>Reactor实现相对简单, 对于耗时短的处理场景处理高效;<br>操作系统可以在多个事件源上等待, 并且避免了多线程编程相关的性能开销和编程复杂性;<br>事件的串行化对应用是透明的, 可以顺序的同步执行而不需要加锁;<br>事务分离：将与应用无关的多路分解和分配机制和与应用相关的回调函数分离开来,<br>Proactor性能更高, 能够处理耗时长的并发场景;</p>
<p><strong>缺点</strong></p>
<p>Reactor处理耗时长的操作会造成事件分发的阻塞, 影响到后续事件的处理;<br>Proactor实现逻辑复杂;依赖操作系统对异步的支持, 目前实现了纯异步操作的操作系统少, 实现优秀<br>的如windows IOCP, 但由于其windows系统用于服务器的局限性, 目前应用范围较小;而Unix/Linux<br>系统对纯异步的支持有限, 应用事件驱动的主流还是通过select/epoll来实现;</p>
<h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><ul>
<li><p>BIO方式适用于连接数目比较小且固定的架构, 这种方式对服务器资源要求比较高, 并发局限于应用中, JDK1.4以前的唯一选择, 但程序直观简单易理解.</p>
</li>
<li><p>NIO方式适用于连接数目多且连接比较短（轻操作）的架构, 比如聊天服务器, 并发局限于应用中, 编程比较复杂, JDK1.4开始支持.</p>
</li>
<li><p>AIO方式使用于连接数目多且连接比较长（重操作）的架构, 比如相册服务器, 充分调用OS参与并发操作, 编程比较复杂, JDK7开始支持.</p>
</li>
</ul>
<hr>
<p>[参考文献]:</p>
<ol>
<li>Think in Java</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title>Java NIO(占坑)</title>
    <url>/Java/io/NIO/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt; Java高级软件工程师知识结构</a></p>
<ol>
<li>掌握InputStream、OutputStream、Reader、Writer的继承体系. </li>
<li>掌握字节流(FileInputStream、DataInputStream、BufferedInputStream、FileOutputSteam、DataOutputStream、BufferedOutputStream)和 字符流(BufferedReader、InputStreamReader、FileReader、BufferedWriter、OutputStreamWriter、PrintWriter、FileWriter), 并熟练运用. </li>
<li>掌握NIO实现原理及使用方法. </li>
</ol>
<p>Java IO包括:</p>
<ul>
<li><a href="/Java/io/IO-Model/">IO Model</a></li>
<li><a href="/Java/io/BIO/">Java BIO</a></li>
<li><a href="/Java/io/NIO/">Java NIO</a></li>
<li><a href="/Java/io/AIO/">Java AIO</a></li>
<li><a href="/Java/io/java-zip/">Java压缩</a></li>
<li><a href="/Java/io/object-serialization/">Java序列化</a></li>
<li><a href="/Java/io/java-XML-JSON/">Java XML与JSON</a></li>
</ul>
<pre><code>感谢`蔡毅`同学对NIO与AIO的深入研究</code></pre>
<p>文后的参考文献 <a href="http://blog.csdn.net/kunluntaishan/article/details/53536386"> <strong>Java NIO浅析</strong> </a> 需要重点关注</p>
<p><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf">Doug Lea《scalable IO in Java》</a><br><a href="http://www.cnblogs.com/fxjwind/p/3363329.html">中文解读</a></p>
<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>新的输入/输出(NIO)库是在JDK 1.4中引入的. NIO弥补了原来的I/O的不足, 它在标准java中提供了高速的、面向块的I/O.<br>   NIO与 <a href="/Java/io/BIO/">BIO</a> 最重要的区别是数据打包和传输的方式的不同, 原来的 I/O 以流 的方式处理数据, 而 NIO 以块 的方式处理数据.  <br>   面向流的I/O系统一次一个字节地处理数据. 一个输入流产生一个字节的数据, 一个输出流消费一个字节的数据. 为流式数据创建过滤器非常容易. 链接几个过滤器, 以便每个过滤器只负责单个复杂处理机制的一部分, 这样也是相对简单的. 不利的一面是, 面向流的I/O通常相当慢.  <br>   NIO与 <a href="/Java/io/BIO/">BIO</a> 有同样的作用和目的, 但是它使用块I/O的处理方式. 每一个操作都在一步中产生或者消费一个数据块. 按块处理数据比按(流式的)字节处理数据要快得多. 但是面向块的I/O缺少一些面向流的I/O所具有的优雅性和简单性. </p>
<p> </p>
<p>从一个例子开始 <br>     下面我们从一个简单的使用IO和NIO读取一个文件中的内容为例, 来进入NIO的学习之旅.<br>     使用IO来读取指定文件中的前1024字节并打印出来：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">* 使用IO读取指定文件的前1024个字节的内容.  </span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> file 指定文件名称.  </span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> java.io.IOException IO异常.  </span></span><br><span class="line"><span class="comment">*/</span>  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ioRead</span><span class="params">(String file)</span> <span class="keyword">throws</span> IOException </span>&#123;  </span><br><span class="line"> FileInputStream in = <span class="keyword">new</span> FileInputStream(file);  </span><br><span class="line"> <span class="keyword">byte</span>[] b = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];  </span><br><span class="line"> in.read(b);  </span><br><span class="line"> System.out.println(<span class="keyword">new</span> String(b));  </span><br><span class="line">&#125;  </span><br><span class="line">​</span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">* 使用NIO读取指定文件的前1024个字节的内容.  </span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> file 指定文件名称.  </span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> java.io.IOException IO异常.  </span></span><br><span class="line"><span class="comment">*/</span>  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nioRead</span><span class="params">(String file)</span> <span class="keyword">throws</span> IOException </span>&#123;  </span><br><span class="line"> FileInputStream in = <span class="keyword">new</span> FileInputStream(file);  </span><br><span class="line"> FileChannel channel = in.getChannel();  </span><br><span class="line"> ​</span><br><span class="line"> ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);  </span><br><span class="line"> channel.read(buffer);  </span><br><span class="line"> <span class="keyword">byte</span>[] b = buffer.array();  </span><br><span class="line"> System.out.println(<span class="keyword">new</span> String(b));  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>从上面的例子中可以看出, NIO以 <code>通道Channel</code> 和 <code>缓冲区Buffer</code> 为基础来实现面向块的IO数据处理. 下面将讨论并学习NIO 库的核心概念以及从高级的特性到底层编程细节的几乎所有方面. </p>
<h1 id="核心概念：通道和缓冲区"><a href="#核心概念：通道和缓冲区" class="headerlink" title="核心概念：通道和缓冲区"></a>核心概念：通道和缓冲区</h1><p>通道和缓冲区是NIO中的核心对象, 几乎在每一个I/O操作中都要使用它们</p>
<ul>
<li>通道Channel 是对原I/O包中的流的模拟. 到任何目的地(或来自任何地方)的所有数据都必须通过一个Channel对象. </li>
<li>缓冲区Buffer 实质上是一个容器对象. 发送给一个通道的所有对象都必须首先放到缓冲区中；同样地, 从通道中读取的任何数据都要读到缓冲区中</li>
</ul>
<h2 id="缓冲区"><a href="#缓冲区" class="headerlink" title="缓冲区"></a>缓冲区</h2><p>Buffer是一个容器对象, 它包含一些要写入或者刚读出的数据. 在NIO中加入Buffer对象, 体现了新库与原I/O的一个重要区别. 在面向流的I/O中, 您将数据直接写入或者将数据直接读到Stream对象中；<br>在NIO库中, 所有数据都是用缓冲区处理的. 在读取数据时, 它是直接读到缓冲区中的. 在写入数据时, 它是写入到缓冲区中的. 任何时候访问NIO中的数据, 您都是将它放到缓冲区中.  <br>缓冲区实质上是一个数组. 通常它是一个字节数组, 但是也可以使用其他种类的数组. 但是一个缓冲区不仅仅是一个数组. 缓冲区提供了对数据的结构化访问, 而且还可以跟踪系统的读/写进程.  </p>
<p>最常用的缓冲区类型是 <code>ByteBuffer</code> .  一个ByteBuffer可以在其底层字节数组上进行get/set操作(即字节的获取和设置).  <br>ByteBuffer不是NIO中唯一的缓冲区类型. 事实上, 对于每一种基本Java类型都有一种缓冲区类型：</p>
<ul>
<li><code>ByteBuffer</code></li>
<li><code>CharBuffer</code></li>
<li><code>ShortBuffer</code></li>
<li><code>IntBuffer</code></li>
<li><code>LongBuffer</code></li>
<li><code>FloatBuffer</code></li>
<li><code>DoubleBuffer</code></li>
</ul>
<p>每一个Buffer类都是Buffer接口的一个实例.  除了ByteBuffer,  每一个Buffer类都有完全一样的操作, 只是它们所处理的数据类型不一样. 因为大多数标准I/O操作都使用 ByteBuffer , 所以它具有所有共享的缓冲区操作以及一些特有的操作. </p>
<p>下面的例子使用类型化的缓冲区<code>FloatBuffer</code>的一个应用例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 分配一个容量为10的新的 float 缓冲区  </span></span><br><span class="line">FloatBuffer buffer = FloatBuffer.allocate(<span class="number">10</span>);  </span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; buffer.capacity(); i++) &#123;  </span><br><span class="line">  <span class="keyword">float</span> f = (<span class="keyword">float</span>) Math.sin((((<span class="keyword">float</span>) i) / <span class="number">10</span>) * (<span class="number">2</span> * Math.PI));  </span><br><span class="line">  buffer.put(f);  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="comment">// 反转此缓冲区  </span></span><br><span class="line">buffer.flip();</span><br><span class="line"><span class="comment">// 告知在当前位置和限制之间是否有元素  </span></span><br><span class="line"><span class="keyword">while</span> (buffer.hasRemaining()) &#123;  </span><br><span class="line">  <span class="keyword">float</span> f = buffer.get();  </span><br><span class="line">  System.out.println(f);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="通道"><a href="#通道" class="headerlink" title="通道"></a>通道</h2><p><code>Channel</code>是对原I/O包中的流的模拟, 可以通过它读取和写入数据. 通道就像流, 所有数据都通过<code>Buffer</code>对象来处理. 您永远不会将字节直接写入通道中, 相反, 是将数据写入包含一个或者多个字节的缓冲区. 同样, 您不会直接从通道中读取字节, 而是将数据从通道 读入缓冲区, 再从缓冲区获取这个字节</p>
<p>**通道与流的不同之处在于通道是双向的. ** 而流只是在一个方向上移动(一个流必须是InputStream或者OutputStream的子类),  而通道可以用于读、写或者同时用于读写. 因为它们是双向的, 所以通道可以比流更好地反映底层操作系统的真实情况. 特别是在UNIX模型中, 底层操作系统通道是双向的. </p>
<h1 id="从理论到实践：NIO中的读和写"><a href="#从理论到实践：NIO中的读和写" class="headerlink" title="从理论到实践：NIO中的读和写"></a>从理论到实践：NIO中的读和写</h1><p>读和写是I/O的基本过程. 从一个通道中读取很简单：只需创建一个缓冲区, 然后让通道将数据读到这个缓冲区中. 写入也相当简单：创建一个缓冲区, 用数据填充它, 然后让通道用这些数据来执行写入操作.  </p>
<h2 id="从文件中读取"><a href="#从文件中读取" class="headerlink" title="从文件中读取"></a>从文件中读取</h2><p>首先从FileInputStream获取一个FileChannel对象, 然后使用这个通道来读取数据.  </p>
<p>在NIO系统中, 任何时候执行一个读操作, 您都是从通道中读取, 但是您不是直接从通道读取. 因为所有数据最终都驻留在缓冲区中, 所以您是从通道读到缓冲区中</p>
<p>   因此读取文件涉及三个步骤：</p>
<p>  (1) 从 FileInputStream 获取 Channel<br>  (2) 创建 Buffer<br>  (3) 将数据从 Channel 读到 Buffer 中</p>
<p>现在, 让我们看一下这个过程. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 第一步是获取通道. 从 FileInputStream 获取通道：</span></span><br><span class="line">FileInputStream fin = <span class="keyword">new</span> FileInputStream( <span class="string">&quot;readandshow.txt&quot;</span> );  </span><br><span class="line">FileChannel fc = fin.getChannel();  </span><br><span class="line"><span class="comment">// 下一步是创建缓冲区：</span></span><br><span class="line">ByteBuffer buffer = ByteBuffer.allocate( <span class="number">1024</span> );  </span><br><span class="line"><span class="comment">// 最后, 需要将数据从通道读到缓冲区中：</span></span><br><span class="line">fc.read( buffer );  </span><br></pre></td></tr></table></figure>
<p>不需要告诉通道要读多少数据到缓冲区中. 每一个缓冲区都有复杂的内部统计机制, 它会跟踪已经读了多少数据以及还有多少空间可以容纳更多的数据. </p>
<h2 id="写入文件："><a href="#写入文件：" class="headerlink" title="写入文件："></a>写入文件：</h2><p>在 NIO 中写入文件类似于从文件中读取. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 首先从 FileOutputStream 获取一个通道：</span></span><br><span class="line">FileOutputStream fout = <span class="keyword">new</span> FileOutputStream( <span class="string">&quot;writesomebytes.txt&quot;</span> );  </span><br><span class="line">FileChannel fc = fout.getChannel();  </span><br><span class="line"><span class="comment">// 下一步是创建一个缓冲区并在其中放入一些数据, 这里, 用message来表示一个持有数据的数组. </span></span><br><span class="line">ByteBuffer buffer = ByteBuffer.allocate( <span class="number">1024</span> );  </span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; message.length; ++i) &#123;  </span><br><span class="line">  buffer.put( message[i] );  </span><br><span class="line">&#125;  </span><br><span class="line">buffer.flip();  </span><br><span class="line"> <span class="comment">// 最后一步是从缓冲区写入通道中：</span></span><br><span class="line">fc.write( buffer );  </span><br></pre></td></tr></table></figure>
<h2 id="读写结合"><a href="#读写结合" class="headerlink" title="读写结合"></a>读写结合</h2><p>将一个文件的所有内容拷贝到另一个文件中. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">* 将一个文件的所有内容拷贝到另一个文件中. ​</span></span><br><span class="line"><span class="comment">* 执行三个基本操作： </span></span><br><span class="line"><span class="comment">* 首先创建一个 Buffer, 然后从源文件中将数据读到这个缓冲区中, </span></span><br><span class="line"><span class="comment">* 然后将缓冲区写入目标文件.  </span></span><br><span class="line"><span class="comment">* 程序不断重复 — 读、写、读、写 — 直到源文件结束.  </span></span><br><span class="line"><span class="comment">*  ​</span></span><br><span class="line"><span class="comment">*/</span>  </span><br><span class="line">String infile = <span class="string">&quot;C:\\copy.sql&quot;</span>;  </span><br><span class="line">String outfile = <span class="string">&quot;C:\\copy.txt&quot;</span>;  </span><br><span class="line">​</span><br><span class="line"><span class="comment">// 获取源文件和目标文件的输入输出流  </span></span><br><span class="line">FileInputStream fin = <span class="keyword">new</span> FileInputStream(infile);  </span><br><span class="line">FileOutputStream fout = <span class="keyword">new</span> FileOutputStream(outfile);  </span><br><span class="line">​</span><br><span class="line"><span class="comment">// 获取输入输出通道  </span></span><br><span class="line">FileChannel fcin = fin.getChannel();  </span><br><span class="line">FileChannel fcout = fout.getChannel();  </span><br><span class="line">​</span><br><span class="line"><span class="comment">// 创建缓冲区  </span></span><br><span class="line">ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);  </span><br><span class="line">​</span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;  </span><br><span class="line">  <span class="comment">// clear方法重设缓冲区, 使它可以接受读入的数据  </span></span><br><span class="line">  buffer.clear();  </span><br><span class="line">  ​</span><br><span class="line">  <span class="comment">// 从输入通道中将数据读到缓冲区  </span></span><br><span class="line">  <span class="keyword">int</span> r = fcin.read(buffer);  </span><br><span class="line">  ​</span><br><span class="line">  <span class="comment">// read方法返回读取的字节数, 可能为零, </span></span><br><span class="line">  <span class="comment">// 如果该通道已到达流的末尾, 则返回-1  </span></span><br><span class="line">  <span class="keyword">if</span> (r == -<span class="number">1</span>) &#123;  </span><br><span class="line">    <span class="keyword">break</span>;  </span><br><span class="line">  &#125;  </span><br><span class="line">  ​</span><br><span class="line">  <span class="comment">// flip方法让缓冲区可以将新读入的数据写入另一个通道  </span></span><br><span class="line">  buffer.flip();  </span><br><span class="line">  ​</span><br><span class="line">  <span class="comment">// 从输出通道中将数据写入缓冲区  </span></span><br><span class="line">  fcout.write(buffer);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<h1 id="缓冲区内部实现"><a href="#缓冲区内部实现" class="headerlink" title="缓冲区内部实现"></a>缓冲区内部实现</h1><p>每一个缓冲区都有复杂的内部统计机制, 它会跟踪已经读了多少数据以及还有多少空间可以容纳更多的数据, 以便我们对缓冲区的操作. </p>
<p>本节介绍两个重要的缓冲区组件：状态变量和访问方法. 虽然NIO的内部统计机制初看起来可能很复杂, 但是您很快就会看到大部分的实际工作都已经替您完成了. 您只需像平时使用字节数组和索引变量一样进行操作即可. </p>
<h2 id="状态变量"><a href="#状态变量" class="headerlink" title="状态变量"></a>状态变量</h2><p>状态变量是”内部统计机制”的关键.  每一个读/写操作都会改变缓冲区的状态. 通过记录和跟踪这些变化, 缓冲区就能够管理内部地自己的资源. </p>
<p>每一种Java基本类型的缓冲区都是抽象类Buffer的子类, 从Buffer的源代码中可以发现, 它定义了三个私有属性：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> position = <span class="number">0</span>;  </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> limit;  </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> capacity;  </span><br></pre></td></tr></table></figure>
<p>实际上, 这三个属性值可以指定缓冲区在任意时刻的状态和它所包含的数据.<br>我们知道, 每一个基本类型的缓冲区底层实际上就是一个该类型的数组. 如在ByteBuffer中, 有：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="keyword">byte</span>[] hb;  </span><br></pre></td></tr></table></figure>
<p>在从通道读取时, 所读取的数据将放被到底层的数组中；同理, 向通道中写入时, 将从底层数组中将数据写入通道. 下面我们来具体介绍这三个变量的作用：</p>
<h3 id="position"><a href="#position" class="headerlink" title="position"></a>position</h3><p>position变量跟踪了向缓冲区中写入了多少数据或者从缓冲区中读取了多少数据.<br>更确切的说, 当您从通道中读取数据到缓冲区中时, 它指示了下一个数据将放到数组的哪一个元素中. 比如, 如果您从通道中读三个字节到缓冲区中, 那么缓冲区的position将会设置为3, 指向数组中第4个元素. 反之, 当您从缓冲区中获取数据进行写通道时, 它指示了下一个数据来自数组的哪一个元素. 比如, 当您从缓冲区写了5个字节到通道中, 那么缓冲区的 position 将被设置为5, 指向数组的第六个元素. </p>
<h3 id="limit"><a href="#limit" class="headerlink" title="limit"></a>limit</h3><p>limit变量表明还有多少数据需要取出(在从缓冲区写入通道时), 或者还有多少空间可以放入数据(在从通道读入缓冲区时).<br>position总是小于或者等于limit. </p>
<h3 id="capacity"><a href="#capacity" class="headerlink" title="capacity"></a>capacity</h3><p>capacity变量表明可以储存在缓冲区中的最大数据容量. 实际上, 它指定了底层数组的大小—或者至少是指定了准许我们使用的底层数组的容量.  <br>limit总是小于或者等于capacity. </p>
<h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><p>下面我们就以数据从一个输入通道拷贝到一个输出通道为例, 来详细分析每一个变量, 并说明它们是如何协同工作的：</p>
<p>初始变量： </p>
<p>我们首先观察一个新创建的缓冲区, 以ByteBuffer为例, 假设缓冲区的大小为8个字节, ByteBuffer初始状态如下：</p>
<p><img src="/images/java/io/NIO/01.gif" alt="NIO缓冲区内部实现机制"></p>
<p>回想一下 , limit决不能大于capacity, 此例中这两个值都被设置为8. 我们通过将它们指向数组的尾部之后(第8个槽位)来说明这点. </p>
<p><img src="/images/java/io/NIO/02.gif" alt="NIO缓冲区内部实现机制"></p>
<p>我们再将position设置为0. 表示如果我们读一些数据到缓冲区中, 那么下一个读取的数据就进入 slot 0. 如果我们从缓冲区写一些数据, 从缓冲区读取的下一个字节就来自slot 0. position设置如下所示：</p>
<p><img src="/images/java/io/NIO/03.gif" alt="NIO缓冲区内部实现机制"></p>
<p>由于缓冲区的最大数据容量capacity不会改变, 所以我们在下面的讨论中可以忽略它. </p>
<p>第一次读取： <br>   现在我们可以开始在新创建的缓冲区上进行读/写操作了. 首先从输入通道中读一些数据到缓冲区中. 第一次读取得到三个字节. 它们被放到数组中从position开始的位置, 这时position被设置为0. 读完之后, position就增加到了3, 如下所示, limit没有改变. </p>
<p><img src="/images/java/io/NIO/04.gif" alt="NIO缓冲区内部实现机制"></p>
<p>第二次读取： <br>   在第二次读取时, 我们从输入通道读取另外两个字节到缓冲区中. 这两个字节储存在由position所指定的位置上,  position因而增加2, limit没有改变. </p>
<p><img src="/images/java/io/NIO/05.gif" alt="NIO缓冲区内部实现机制"></p>
<p>flip： <br>   现在我们要将数据写到输出通道中. 在这之前, 我们必须调用flip()方法.  其源代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">flip</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">	limit = position;  </span><br><span class="line">	position = <span class="number">0</span>;  </span><br><span class="line">	mark = -<span class="number">1</span>;  </span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">this</span>;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>


<p>   这个方法做两件非常重要的事：<br>   i  将limit设置为当前position.<br>   ii 将position设置为0. </p>
<p>   上一个图显示了在flip之前缓冲区的情况. 下面是在flip之后的缓冲区：</p>
<p><img src="/images/java/io/NIO/06.gif" alt="NIO缓冲区内部实现机制"></p>
<p>   我们现在可以将数据从缓冲区写入通道了. position被设置为0, 这意味着我们得到的下一个字节是第一个字节. limit已被设置为原来的position, 这意味着它包括以前读到的所有字节, 并且一个字节也不多.<br>第一次写入： <br>   在第一次写入时, 我们从缓冲区中取四个字节并将它们 写入输出通道. 这使得position增加到4, 而limit不变, 如下所示：</p>
<p><img src="/images/java/io/NIO/07.gif" alt="NIO缓冲区内部实现机制"></p>
<p>第二次写入： <br>   我们只剩下一个字节可写了. limit在我们调用flip()时被设置为5, 并且position不能超过limit.  所以最后一次写入操作从缓冲区取出一个字节并将它写入输出通道. 这使得position增加到5, 并保持limit不变, 如下所示：</p>
<p><img src="/images/java/io/NIO/08.gif" alt="NIO缓冲区内部实现机制"></p>
<p>clear： <br>   最后一步是调用缓冲区的clear()方法. 这个方法重设缓冲区以便接收更多的字节. 其源代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">clear</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">	position = <span class="number">0</span>;  </span><br><span class="line">	limit = capacity;  </span><br><span class="line">	mark = -<span class="number">1</span>;  </span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">this</span>;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>


<p>clear做两种非常重要的事情：</p>
<p>i 将limit设置为与capacity相同.  <br>ii 设置position为0.  </p>
<p>下图显示了在调用clear()后缓冲区的状态,  此时缓冲区现在可以接收新的数据了. </p>
<p><img src="/images/java/io/NIO/09.gif" alt="NIO缓冲区内部实现机制"></p>
<p> </p>
<h2 id="访问方法"><a href="#访问方法" class="headerlink" title="访问方法"></a>访问方法</h2><p>程序需要直接处理数据. 例如, 您可能需要将用户数据保存到磁盘. 在这种情况下, 您必须将这些数据直接放入缓冲区, 然后用通道将缓冲区写入磁盘.  或者, 您可能想要从磁盘读取用户数据. 在这种情况下, 您要将数据从通道读到缓冲区中, 然后检查缓冲区中的数据.  <br>   实际上, 每一个基本类型的缓冲区都为我们提供了直接访问缓冲区中数据的方法, 我们以ByteBuffer为例, 分析如何使用其提供的get()和put()方法直接访问缓冲区中的数据. </p>
<h3 id="get"><a href="#get" class="headerlink" title="get()"></a>get()</h3><p>   ByteBuffer类中有四个get()方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">byte</span> <span class="title">get</span><span class="params">()</span></span>;  </span><br><span class="line"><span class="function">ByteBuffer <span class="title">get</span><span class="params">( <span class="keyword">byte</span> dst[] )</span></span>;  </span><br><span class="line"><span class="function">ByteBuffer <span class="title">get</span><span class="params">( <span class="keyword">byte</span> dst[], <span class="keyword">int</span> offset, <span class="keyword">int</span> length )</span></span>;  </span><br><span class="line"><span class="function"><span class="keyword">byte</span> <span class="title">get</span><span class="params">( <span class="keyword">int</span> index )</span></span>;</span><br></pre></td></tr></table></figure>
<p>   第一个方法获取单个字节. 第二和第三个方法将一组字节读到一个数组中. 第四个方法从缓冲区中的特定位置获取字节. 那些返回ByteBuffer的方法只是返回调用它们的缓冲区的this值.  <br>   前三个get()方法是相对的, 而最后一个方法是绝对的. “相对”意味着get()操作服从limit和position值, 更明确地说, 字节是从当前position读取的, 而position在get之后会增加. 另一方面, 一个“绝对”方法会忽略limit和position值, 也不会影响它们. 事实上, 它完全绕过了缓冲区的统计方法.  </p>
<p>上面列出的方法对应于ByteBuffer类. 其他类有等价的get()方法, 这些方法除了不是处理字节外, 其它方面是是完全一样的, 它们处理的是与该缓冲区类相适应的类型. </p>
<h3 id="put"><a href="#put" class="headerlink" title="put()"></a>put()</h3><p>   ByteBuffer类中有五个put()方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">ByteBuffer <span class="title">put</span><span class="params">( <span class="keyword">byte</span> b )</span></span>;  </span><br><span class="line"><span class="function">ByteBuffer <span class="title">put</span><span class="params">( <span class="keyword">byte</span> src[] )</span></span>;  </span><br><span class="line"><span class="function">ByteBuffer <span class="title">put</span><span class="params">( <span class="keyword">byte</span> src[], <span class="keyword">int</span> offset, <span class="keyword">int</span> length )</span></span>;  </span><br><span class="line"><span class="function">ByteBuffer <span class="title">put</span><span class="params">( ByteBuffer src )</span></span>;  </span><br><span class="line"><span class="function">ByteBuffer <span class="title">put</span><span class="params">( <span class="keyword">int</span> index, <span class="keyword">byte</span> b )</span></span>;</span><br></pre></td></tr></table></figure>
<p>   第一个方法 写入（put）单个字节. 第二和第三个方法写入来自一个数组的一组字节. 第四个方法将数据从一个给定的源ByteBuffer写入这个ByteBuffer. 第五个方法将字节写入缓冲区中特定的 位置 . 那些返回ByteBuffer的方法只是返回调用它们的缓冲区的this值.  <br>   与get()方法一样, 我们将把put()方法划分为“相对”或者“绝对”的. 前四个方法是相对的, 而第五个方法是绝对的.  <br>   上面显示的方法对应于ByteBuffer类. 其他类有等价的put()方法, 这些方法除了不是处理字节之外, 其它方面是完全一样的. 它们处理的是与该缓冲区类相适应的类型.  </p>
<h3 id="类型化的-get-和-put-方法"><a href="#类型化的-get-和-put-方法" class="headerlink" title="类型化的 get() 和 put() 方法"></a>类型化的 get() 和 put() 方法</h3><p>   除了前些小节中描述的get()和put()方法,  ByteBuffer还有用于读写不同类型的值的其他方法, 如下所示</p>
<p> -  <code>getByte()</code><br> -  <code>getChar()</code><br> -  <code>getShort()</code><br> -  <code>getInt()</code><br> -  <code>getLong()</code><br> -  <code>getFloat()</code><br> -  <code>getDouble()</code><br> -  <code>putByte()</code><br> -  <code>putChar()</code><br> -  <code>putShort()</code><br> -  <code>putInt()</code><br> -  <code>putLong()</code><br> -  <code>putFloat()</code><br> -  <code>putDouble()</code></p>
<p>   事实上, 这其中的每个方法都有两种类型：一种是相对的, 另一种是绝对的. 它们对于读取格式化的二进制数据（如图像文件的头部）很有用. </p>
<p> </p>
<h2 id="如何使用？"><a href="#如何使用？" class="headerlink" title="如何使用？"></a>如何使用？</h2><p>   下面的内部循环概括了使用缓冲区将数据从输入通道拷贝到输出通道的过程. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;  </span><br><span class="line"> buffer.clear();  </span><br><span class="line"> <span class="keyword">int</span> r = fcin.read( buffer );  </span><br><span class="line"></span><br><span class="line"> <span class="keyword">if</span> (r==-<span class="number">1</span>) &#123;  </span><br><span class="line"> 	<span class="keyword">break</span>;  </span><br><span class="line"> &#125;  </span><br><span class="line"> buffer.flip();  </span><br><span class="line"> fcout.write( buffer );  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>   read()和write()调用得到了极大的简化, 因为许多工作细节都由缓冲区完成了. clear()和flip()方法用于让缓冲区在读和写之间切换. </p>
<h1 id="连网和异步IO"><a href="#连网和异步IO" class="headerlink" title="连网和异步IO"></a>连网和异步IO</h1><p>连网是学习异步I/O的很好基础, 而异步I/O对于在Java语言中执行任何输入/输出过程的人来说, 无疑都是必须具备的知识. NIO中的连网与NIO中的其他任何操作没有什么不同, 它依赖通道和缓冲区, 而您通常使用InputStream和OutputStream来获得通道. </p>
<h2 id="异步-I-O"><a href="#异步-I-O" class="headerlink" title="异步 I/O"></a>异步 I/O</h2><p>   异步I/O是一种“没有阻塞地读写数据”的方法. 通常, 在代码进行read()调用时, 代码会阻塞直至有可供读取的数据. 同样,  write()调用将会阻塞直至数据能够写入.  但异步I/O调用不会阻塞. 相反, 您可以注册对特定I/O事件的兴趣：如可读的数据的到达、新的套接字连接等等, 而在发生这样的事件时, 系统将会告诉您.  <br>   异步I/O的一个优势在于, 它允许您同时根据大量的输入和输出执行I/O. 同步程序常常要求助于轮询, 或者创建许许多多的线程以处理大量的连接. 使用异步I/O, 您可以监听任何数量的通道上的事件, 不用轮询, 也不用额外的线程.<br>   我们来看一个基于非阻塞I/O的服务器端的处理流程, 它接受网络连接并向它们echo它们可能发送的数据. 在这里假设它能同时监听多个端口, 并处理来自所有这些端口的连接. 下面是其主方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">execute</span> <span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;  </span><br><span class="line">  <span class="comment">// 创建一个新的选择器  </span></span><br><span class="line">  Selector selector = Selector.open();  </span><br><span class="line"></span><br><span class="line">  <span class="comment">// 打开在每个端口上的监听, 并向给定的选择器注册此通道接受客户端连接的I/O事件.   </span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ports.length; i++) &#123;  </span><br><span class="line">    <span class="comment">// 打开服务器套接字通道  </span></span><br><span class="line">    ServerSocketChannel ssc = ServerSocketChannel.open();  </span><br><span class="line">    <span class="comment">// 设置此通道为非阻塞模式  </span></span><br><span class="line">    ssc.configureBlocking(<span class="keyword">false</span>);  </span><br><span class="line">    <span class="comment">// 绑定到特定地址  </span></span><br><span class="line">    ServerSocket ss = ssc.socket();  </span><br><span class="line">    InetSocketAddress address = <span class="keyword">new</span> InetSocketAddress(ports[i]);  </span><br><span class="line">    ss.bind(address);  </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向给定的选择器注册此通道的接受连接事件  </span></span><br><span class="line">    ssc.register(selector, SelectionKey.OP_ACCEPT);  </span><br><span class="line">    System.out.println(<span class="string">&quot;Going to listen on &quot;</span> + ports[i]);  </span><br><span class="line">  &#125;  </span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;  </span><br><span class="line">    <span class="comment">// 这个方法会阻塞, 直到至少有一个已注册的事件发生.   </span></span><br><span class="line">    <span class="comment">// 当一个或者更多的事件发生时, 此方法将返回所发生的事件的数量.   </span></span><br><span class="line">    <span class="keyword">int</span> num = selector.select();  </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 迭代所有的选择键, 以处理特定的I/O事件.   </span></span><br><span class="line">    Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();  </span><br><span class="line">    Iterator&lt;SelectionKey&gt; iter = selectionKeys.iterator();  </span><br><span class="line"></span><br><span class="line">    SocketChannel sc;  </span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;  </span><br><span class="line">      SelectionKey key = iter.next();  </span><br><span class="line">      <span class="keyword">if</span> ((key.readyOps() </span><br><span class="line">      &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT) &#123;  </span><br><span class="line">        <span class="comment">// 接受服务器套接字撒很能够传入的新的连接, 并处理接受连接事件.   </span></span><br><span class="line">        ServerSocketChannel ssc = (ServerSocketChannel) key.channel();  </span><br><span class="line">        sc = ssc.accept();  </span><br><span class="line">        <span class="comment">// 将新连接的套接字通道设置为非阻塞模式  </span></span><br><span class="line">        sc.configureBlocking(<span class="keyword">false</span>);  </span><br><span class="line"></span><br><span class="line">        <span class="comment">// 接受连接后, 在此通道上从新注册读取事件, 以便接收数据.   </span></span><br><span class="line">        sc.register(selector, SelectionKey.OP_READ);  </span><br><span class="line">        <span class="comment">// 删除处理过的选择键  </span></span><br><span class="line">        iter.remove();  </span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;Got connection from &quot;</span> + sc);  </span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((key.readyOps() </span><br><span class="line">      &amp; SelectionKey.OP_READ) == SelectionKey.OP_READ) &#123;  </span><br><span class="line">          <span class="comment">// 处理读取事件, 读取套接字通道中发来的数据.   </span></span><br><span class="line">          sc = (SocketChannel) key.channel();  </span><br><span class="line"></span><br><span class="line">          <span class="comment">// 读取数据  </span></span><br><span class="line">          <span class="keyword">int</span> bytesEchoed = <span class="number">0</span>;  </span><br><span class="line">          <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;  </span><br><span class="line">            echoBuffer.clear();  </span><br><span class="line">            <span class="keyword">int</span> r = sc.read(echoBuffer);  </span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (r == -<span class="number">1</span>) &#123;  </span><br><span class="line">              <span class="keyword">break</span>;  </span><br><span class="line">            &#125;  </span><br><span class="line"></span><br><span class="line">            echoBuffer.flip();  </span><br><span class="line">            sc.write(echoBuffer);  </span><br><span class="line"></span><br><span class="line">            bytesEchoed += r;  </span><br><span class="line">          &#125;  </span><br><span class="line">          System.out.println(<span class="string">&quot;Echoed &quot;</span> + bytesEchoed + <span class="string">&quot; from &quot;</span> + sc);  </span><br><span class="line">          <span class="comment">// 删除处理过的选择键  </span></span><br><span class="line">          iter.remove();  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>3)    Selectors</p>
<p>Selector是异步<code>I/O</code>中的核心对象. Selector就是注册对各种<code>I/O</code>事件的兴趣的地方, 而且当那些事件发生时, 就是这个对象告诉您所发生的事件. 所以, 我们需要做的第一件事就是创建一个Selector：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Selector selector = Selector.open();  </span><br></pre></td></tr></table></figure>
<p>然后, 我们将对不同的通道对象调用<code>register()</code>方法, 以便注册我们对这些对象中发生的I/O事件的兴趣. <code>register()</code>的第一个参数就是这个Selector对象.  </p>
<p>4)    打开一个<code>ServerSocketChannel</code></p>
<p>在服务端为了接收连接, 我们需要一个<code>ServerSocketChannel</code>.  事实上, 我们要监听的每一个端口都需要有一个<code>ServerSocketChannel</code>. 对于每一个端口, 我们打开一个<code>ServerSocketChannel</code>,  如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ServerSocketChannel ssc = ServerSocketChannel.open();  </span><br><span class="line">ssc.configureBlocking( <span class="keyword">false</span> );  </span><br><span class="line">ServerSocket ss = ssc.socket();  </span><br><span class="line">InetSocketAddress address = <span class="keyword">new</span> InetSocketAddress( ports[i] );  </span><br><span class="line">ss.bind( address );  </span><br></pre></td></tr></table></figure>
<p>第一行创建一个新的<code>ServerSocketChannel</code>, 最后三行将它绑定到给定的端口. 第二行将<code>ServerSocketChannel</code>设置为非阻塞的. 我们必须对每一个要使用的套接字通道调用这个方法, 否则异步<code>I/O</code>就不能工作.</p>
<p>5)    选择键</p>
<p>下一步是将新打开的<code>ServerSocketChannels</code>注册到<code>Selector</code>上. 为此我们使用<code>ServerSocketChannel.register()</code>方法, 如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SelectionKey key = ssc.register( selector, SelectionKey.OP_ACCEPT );  </span><br></pre></td></tr></table></figure>
<p><code>register()</code>方法的第一个参数总是这个<code>Selector</code>. 第二个参数是<code>OP_ACCEPT</code>, 这里它指定我们想要监听<code>accept</code>事件, 也就是在新的连接建立时所发生的事件. 这是适用于<code>ServerSocketChannel</code>的唯一事件类型.  </p>
<p>请注意对<code>register()</code>的调用的返回值. <code>SelectionKey</code>代表这个通道在此<code>Selector</code>上的这个注册. 当某个<code>Selector</code>通知您某个传入事件时, 它是通过提供对应于该事件的<code>SelectionKey</code>来进行的. <code>SelectionKey</code>还可以用于取消通道的注册.<br>  <br>6)    内部循环</p>
<p>现在已经注册了我们对一些 <code>I/O</code> 事件的兴趣, 下面将进入主循环. 使用 <code>Selectors</code> 的几乎每个程序都像下面这样使用内部循环：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">int</span> num = selector.select();  </span><br><span class="line"></span><br><span class="line">Set selectedKeys = selector.selectedKeys();  </span><br><span class="line">Iterator it = selectedKeys.iterator();  </span><br><span class="line"><span class="keyword">while</span> (it.hasNext()) &#123;  </span><br><span class="line">SelectionKey key = (SelectionKey)it.next();  </span><br><span class="line"><span class="comment">// ... 处理I/O事件...  </span></span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<ul>
<li>调用<code>Selector</code>的<code>select()</code>方法. 这个方法会阻塞, 直到至少有一个已注册的事件发生. 当一个或者更多的事件发生时, <code>select()</code>方法将返回所发生的事件的数量.  </li>
<li>调用<code>Selector</code>的<code>selectedKeys()</code>方法, 它返回发生了事件的<code>SelectionKey</code>对象的一个集合.  </li>
<li>通过迭代<code>SelectionKeys</code>并依次处理每个<code>SelectionKey</code>来处理事件. 对于每一个<code>SelectionKey</code>, 您必须确定发生的是什么<code>I/O</code>事件, 以及这个事件影响哪些<code>I/O</code>对象.</li>
</ul>
<p>7)    监听新连接</p>
<p>程序执行到这里, 我们仅注册了<code>ServerSocketChannel</code>,  并且仅注册它们“接收”事件. 为确认这一点, 我们对<code>SelectionKey</code>调用<code>readyOps()</code>方法, 并检查发生了什么类型的事件：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ((key.readyOps() &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT) &#123;  </span><br><span class="line"><span class="comment">// ...  </span></span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>可以肯定地说, <code>readOps()</code>方法告诉我们该事件是新的连接. </p>
<p>8)    接受新的连接</p>
<p>因为我们知道这个服务器套接字上有一个传入连接在等待, 所以可以安全地接受它；也就是说, 不用担心<code>accept()</code>操作会阻塞：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ServerSocketChannel ssc = (ServerSocketChannel)key.channel();  </span><br><span class="line">SocketChannel sc = ssc.accept();  </span><br></pre></td></tr></table></figure>
<p>下一步是将新连接的SocketChannel配置为非阻塞的. 而且由于接受这个连接的目的是为了读取来自套接字的数据, 所以我们还必须将SocketChannel注册到Selector上, 如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">sc.configureBlocking( <span class="keyword">false</span> );  </span><br><span class="line">SelectionKey newKey = sc.register( selector, SelectionKey.OP_READ );  </span><br></pre></td></tr></table></figure>
<p>注意我们使用register()的OP_READ参数, 将SocketChannel注册用于“读取”而不是“接受”新连接.</p>
<p>9)    删除处理过的SelectionKey</p>
<p>在处理SelectionKey之后, 我们几乎可以返回主循环了. 但是我们必须首先将处理过的SelectionKey从选定的键集合中删除. 如果我们没有删除处理过的键, 那么它仍然会在主集合中以一个激活的键出现, 这会导致我们尝试再次处理它. 我们调用迭代器的remove()方法来删除处理过的SelectionKey：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">it.remove();  </span><br></pre></td></tr></table></figure>
<p>现在我们可以返回主循环并接受从一个套接字中传入的数据(或者一个传入的I/O事件)了.  </p>
<p>10) 传入的I/O</p>
<p>当来自一个套接字的数据到达时, 它会触发一个I/O事件. 这会导致在主循环中调用Selector.select(), 并返回一个或者多个I/O事件. 这一次,  SelectionKey将被标记为OP_READ事件, 如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> ((key.readyOps() &amp; SelectionKey.OP_READ)  </span><br><span class="line">== SelectionKey.OP_READ) &#123;  </span><br><span class="line"><span class="comment">// Read the data  </span></span><br><span class="line">SocketChannel sc = (SocketChannel)key.channel();  </span><br><span class="line"><span class="comment">// ...  </span></span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>与以前一样, 我们取得发生I/O事件的通道并处理它. 在本例中, 由于这是一个echo server, 我们只希望从套接字中读取数据并马上将它发送回去. 关于这个过程的细节, 请参见附件中的源代码 (MultiPortEcho.java).  </p>
<p>11)    回到主循环</p>
<p>每次返回主循环, 我们都要调用select的Selector()方法, 并取得一组SelectionKey. 每个键代表一个I/O事件. 我们处理事件, 从选定的键集中删除SelectionKey, 然后返回主循环的顶部.</p>
<p>说明： 这个程序有点过于简单, 因为它的目的只是展示异步I/O所涉及的技术. 在现实的应用程序中, 您需要通过将通道从Selector中删除来处理关闭的通道. 而且您可能要使用多个线程. 这个程序可以仅使用一个线程, 因为它只是一个演示, 但是在现实场景中, 创建一个线程池来负责I/O事件处理中的耗时部分会更有意义. </p>
<h1 id="缓冲区更多内容"><a href="#缓冲区更多内容" class="headerlink" title="缓冲区更多内容"></a>缓冲区更多内容</h1><p>比如缓冲区分配、包装和分片. 我们还会讨论NIO带给Java平台的一些新功能. 我们将学如何创建不同类型的缓冲区以达到不同的目的, 如可保护数据不被修改的“只读缓冲区”, 和直接映射到底层操作系统缓冲区的“直接缓冲区”, 以及如何在 NIO 中创建内存映射文件. </p>
<p>   1) 缓冲区分配和包装</p>
<p>在能够读和写之前, 必须有一个缓冲区. 要创建缓冲区, 您必须“分配”它. 我们使用静态方法allocate()来分配缓冲区：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ByteBuffer buffer = ByteBuffer.allocate( <span class="number">1024</span> );  </span><br></pre></td></tr></table></figure>
<p>   allocate()方法分配一个具有指定大小的底层数组, 并将它包装到一个缓冲区对象中, 在本例中是一个ByteBuffer.<br>   您还可以将一个现有的数组转换为缓冲区, 如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">byte</span> array[] = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];  </span><br><span class="line">ByteBuffer buffer = ByteBuffer.wrap( array );  </span><br></pre></td></tr></table></figure>
<p>   本例使用了wrap()方法将一个数组包装为缓冲区. 必须非常小心地进行这类操作. 一旦完成包装, 底层数据就可以通过缓冲区或者直接访问.<br> <br>2) 缓冲区分片 </p>
<p>   slice()方法根据现有的缓冲区创建一个子缓冲区. 也就是说, 它创建一个新的缓冲区, 新缓冲区与原来的缓冲区的一部分共享数据.<br>  <br>   使用例子可以最好地说明这点. 让我们首先创建一个长度为10的ByteBuffer：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ByteBuffer buffer = ByteBuffer.allocate( <span class="number">10</span> );  </span><br></pre></td></tr></table></figure>
<p>   然后使用数据来填充这个缓冲区, 在第n个槽中放入数字n：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;buffer.capacity(); ++i) &#123;  </span><br><span class="line"> buffer.put( (<span class="keyword">byte</span>)i );  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>   现在我们对这个缓冲区“分片”, 以创建一个包含槽3到槽6的子缓冲区. 在某种意义上, 子缓冲区就像原来的缓冲区中的一个窗口 . </p>
<p>   窗口的起始和结束位置通过设置position和limit值来指定, 然后调用Buffer的slice()方法进行分片：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">buffer.position( <span class="number">3</span> );  </span><br><span class="line">buffer.limit( <span class="number">7</span> );  </span><br><span class="line">ByteBuffer slice = buffer.slice();  </span><br></pre></td></tr></table></figure>
<p>   该“片段”是缓冲区的子缓冲区. 不过, “片段”和“缓冲区”共享同一个底层数据数组, 我们在下一节将会看到这一点. </p>
<ol start="3">
<li>缓冲区片份和数据共享 </li>
</ol>
<p>   我们已经创建了原缓冲区的子缓冲区, 并且已经知道缓冲区和子缓冲区共享同一个底层数据数组. 让我们看看这意味着什么.  </p>
<p>   我们遍历子缓冲区, 将每一个元素乘以11来改变它. 例如, 5会变成55. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;slice.capacity(); ++i) &#123;  </span><br><span class="line"> <span class="keyword">byte</span> b = slice.get( i );  </span><br><span class="line"> b *= <span class="number">11</span>;  </span><br><span class="line"> slice.put( i, b );  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>   最后, 再看一下原缓冲区中的内容：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">buffer.position( <span class="number">0</span> );  </span><br><span class="line">buffer.limit( buffer.capacity() );  </span><br><span class="line"><span class="keyword">while</span> ( buffer.remaining() &gt; <span class="number">0</span> ) &#123;  </span><br><span class="line"> System.out.println( buffer.get() );  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>   结果表明只有在子缓冲区窗口中的元素被改变了： </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">33</span><br><span class="line">44</span><br><span class="line">55</span><br><span class="line">66</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td></tr></table></figure>
<p>   缓冲区片对于促进抽象非常有帮助. 可以编写自己的函数处理整个缓冲区, 而且如果想要将这个过程应用于子缓冲区上, 您只需取主缓冲区的一个片, 并将它传递给您的函数. 这比编写自己的函数来取额外的参数以指定要对缓冲区的哪一部分进行操作更容易.  </p>
<ol start="4">
<li>只读缓冲区</li>
</ol>
<p>只读缓冲区的含义已经很直白了：您可以读取它们, 但是不能向它们写入. 可以通过调用缓冲区的<code>asReadOnlyBuffer()</code>方法, 来将任何常规缓冲区转换为只读缓冲区, 这个方法返回一个与原缓冲区完全相同的缓冲区(并与其共享数据), 只不过它是只读的.  </p>
<p>   只读缓冲区对于保护数据很有用. 在将缓冲区传递给某个对象的方法时, 您无法知道这个方法是否会修改缓冲区中的数据. 创建一个只读的缓冲区可以保证该缓冲区不会被修改. 不能将只读的缓冲区转换为可写的缓冲区.  </p>
<ol start="5">
<li>直接和间接缓冲区 </li>
</ol>
<p>   另一种有用的ByteBuffer是直接缓冲区. “直接缓冲区”是为加快I/O速度, 而以一种特殊的方式分配其内存的缓冲区. 实际上, 直接缓冲区的准确定义是与实现相关的. </p>
<blockquote>
<p>Sun的文档是这样描述直接缓冲区的： 给定一个直接字节缓冲区, Java虚拟机将尽最大努力直接对它执行本机I/O操作. 也就是说, 它会在每一次调用底层操作系统的本机I/O操作之前(或之后), 尝试避免将缓冲区的内容拷贝到一个中间缓冲区中(或者从一个中间缓冲区中拷贝数据).  </p>
</blockquote>
<p>附件中, 您可以在例子程序FastCopyFile.java中看到直接缓冲区的实际应用, 这个程序是CopyFile.java的另一个版本, 它使用了直接缓冲区以提高速度. 还可以用内存映射文件创建直接缓冲区.  </p>
<ol start="6">
<li>内存映射文件I/O</li>
</ol>
<p>   内存映射文件I/O是一种读和写文件数据的方法, 它可以比常规的基于流或者基于通道的I/O快得多.  </p>
<p>内存映射文件I/O是通过使文件中的数据神奇般地出现为内存数组的内容来完成的. 这其初听起来似乎不过就是将整个文件读到内存中, 但是事实上并不是这样. 一般来说, 只有文件中实际读取或者写入的部分才会送入（或者映射）到内存中.  </p>
<p><strong>内存映射并不真的神奇或者多么不寻常. 现代操作系统一般根据需要将文件的部分映射为内存的部分, 从而实现文件系统. Java内存映射机制不过是在底层操作系统中可以采用这种机制时, 提供了对该机制的访问</strong></p>
<p>尽管创建内存映射文件相当简单, 但是向它写入可能是危险的. 仅只是改变数组的单个元素这样的简单操作, 就可能会直接修改磁盘上的文件. 修改数据与将 数据保存到磁盘是没有分开的. </p>
<ol start="7">
<li>将文件映射到内存</li>
</ol>
<p>了解内存映射的最好方法是使用例子. 在下面的例子中, 我们要将一个FileChannel (它的全部或者部分)映射到内存中. 为此我们将使用<code>FileChannel.map()</code>方法. 下面代码行将文件的前1024个字节映射到内存中：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MappedByteBuffer mbb = fc.map( FileChannel.MapMode.READ_WRITE, <span class="number">0</span>, <span class="number">1024</span> );  </span><br></pre></td></tr></table></figure>
<p>map()方法返回一个<code>MappedByteBuffer</code>, 它是ByteBuffer的子类. 因此, 您可以像使用其他任何ByteBuffer 一样使用新映射的缓冲区, 操作系统会在需要时负责执行行映射.</p>
<ol>
<li>分散和聚集 </li>
</ol>
<ol>
<li>概述：</li>
</ol>
<p>分散/聚集I/O是使用多个而不是单个缓冲区来保存数据的读写方法.  <br>一个分散的读取就像一个常规通道读取, 只不过它是将数据读到一个缓冲区数组中而不是读到单个缓冲区中. 同样地, 一个聚集写入是向缓冲区数组而不是向单个缓冲区写入数据. 分散/聚集I/O对于将数据流划分为单独的部分很有用, 这有助于实现复杂的数据格式. </p>
<ol start="2">
<li>分散/聚集 I/O：</li>
</ol>
<p>通道可以有选择地实现两个新的接口：ScatteringByteChannel和GatheringByteChannel. 一个 ScatteringByteChannel是一个具有两个附加读方法的通道：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">read</span><span class="params">( ByteBuffer[] dsts )</span></span>;  </span><br><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">read</span><span class="params">( ByteBuffer[] dsts, <span class="keyword">int</span> offset, <span class="keyword">int</span> length )</span></span>;</span><br></pre></td></tr></table></figure>
<p>这些long read()方法很像标准的read方法, 只不过它们不是取单个缓冲区而是取一个缓冲区数组.  </p>
<p>在“分散读取”中, 通道依次填充每个缓冲区. 填满一个缓冲区后, 它就开始填充下一个. 在某种意义上, 缓冲区数组就像一个大缓冲区.  </p>
<ol start="3">
<li>分散/聚集的应用： </li>
</ol>
<p>分散/聚集I/O对于将数据划分为几个部分很有用. 例如, 您可能在编写一个使用消息对象的网络应用程序, 每一个消息被划分为固定长度的头部和固定长度的正文. 您可以创建一个刚好可以容纳头部的缓冲区和另一个刚好可以容难正文的缓冲区. 当您将它们放入一个数组中并使用分散读取来向它们读入消息时, 头部和正文将整齐地划分到这 两个缓冲区中.  </p>
<p>我们从缓冲区所得到的方便性对于缓冲区数组同样有效. 因为每一个缓冲区都跟踪自己还可以接受多少数据, 所以分散读取会自动找到有空间接受数据的第一个缓冲区. 在这个缓冲区填满后, 它就会移动到下一个缓冲区.  </p>
<ol start="4">
<li>聚集写入： </li>
</ol>
<p>聚集写入类似于分散读取, 只不过是用来写入. 它也有接受缓冲区数组的方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">write</span><span class="params">( ByteBuffer[] srcs )</span></span>;  </span><br><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">write</span><span class="params">( ByteBuffer[] srcs, <span class="keyword">int</span> offset, <span class="keyword">int</span> length )</span></span>;</span><br></pre></td></tr></table></figure>
<p>聚集写对于把一组单独的缓冲区中组成单个数据流很有用. 为了与上面的消息例子保持一致, 您可以使用聚集写入来自动将网络消息的各个部分组装为单个数据流, 以便跨越网络传输消息.  <br>从附件的例子程序 UseScatterGather.java 中可以看到分散读取和聚集写入的实际应用. </p>
<h1 id="文件锁定"><a href="#文件锁定" class="headerlink" title="文件锁定"></a>文件锁定</h1><ol>
<li>概述： </li>
</ol>
<p>文件锁定初看起来可能让人迷惑. 它似乎指的是防止程序或者用户访问特定文件. 事实上, <strong>文件锁就像常规的Java对象锁, 它们是“劝告式”的（advisory）锁</strong>. <strong>它们不阻止任何形式的数据访问, 相反, 它们通过锁的共享和获取来允许系统的不同部分相互协调</strong>. 您可以锁定整个文件或者文件的一部分. 如果您获取一个排它锁, 那么其他人就不能获得同一个文件或者文件的一部分上的锁. 如果您获得一个共享锁, 那么其他人可以获得同一个文件或者文件一部分上的共享锁, 但是不能获得排它锁. 文件锁定并不总是出于保护数据的目的. 例如, 您可能临时锁定一个文件以保证特定 的写操作成为原子的, 而不会有其他程序的干扰.  大多数操作系统提供了文件系统锁, 但是它们并不都是采用同样的方式. 有些实现提供了共享锁, 而另一些仅提供了排它锁. 事实上, 有些实现使得文件的锁定部分不可访问, 尽管大多数实现不是这样的.  在这里, 我们将学习如何在 NIO 中执行简单的文件锁过程, 还将探讨一些保证被锁定的文件尽可能可移植的方法.  </p>
<ol start="2">
<li>锁定文件： </li>
</ol>
<p>要获取文件的一部分上的锁, 您要调用一个打开的FileChannel上的lock()方法. 注意, 如果要获取一个排它锁, 您必须以写方式打开文件. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RandomAccessFile raf = <span class="keyword">new</span> RandomAccessFile( <span class="string">&quot;usefilelocks.txt&quot;</span>, <span class="string">&quot;rw&quot;</span> );  </span><br><span class="line">FileChannel fc = raf.getChannel();  </span><br><span class="line">FileLock lock = fc.lock( start, end, <span class="keyword">false</span> );  </span><br></pre></td></tr></table></figure>
<p>   在拥有锁之后, 您可以执行需要的任何敏感操作, 然后再释放锁：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">lock.release();  </span><br></pre></td></tr></table></figure>
<p>   在释放锁后, 尝试获得锁的其他任何程序都有机会获得它.  <br>   本附件的例子程序UseFileLocks.java必须与它自己并行运行. 这个程序获取一个文件上的锁, 持有三秒钟, 然后释放它. 如果同时运行这个程序的多个实例, 您会看到每个实例依次获得锁.  </p>
<ol start="3">
<li>文件锁定和可移植性：</li>
</ol>
<p>文件锁定可能是一个复杂的操作, 特别是考虑到 不同的操作系统是以不同的方式实现锁这一事实. 下面的指导原则将帮助您尽可能保持代码的可移植性： </p>
<p>i 只使用排它锁.  </p>
<p>ii 将所有的锁视为劝告式的（advisory）.  </p>
<h1 id="字符集"><a href="#字符集" class="headerlink" title="字符集"></a>字符集</h1><ol>
<li>概述： </li>
</ol>
<p>根据Sun的文档, 一个Charset是“十六位Unicode字符序列与字节序列之间的一个命名的映射”. 实际上, 一个Charset允许您以尽可能最具可移植性的方式读写字符序列.  </p>
<p>Java语言被定义为基于Unicode. 然而在实际上, 许多人编写代码时都假设一个字符在磁盘上或者在网络流中用一个字节表示. 这种假设在许多情况下成立, 但是并不是在所有情况下都成立, 而且随着计算机变得对Unicode越来越友好, 这个假设就日益变得不能成立了.  </p>
<p>在这里, 我们将看一下如何使用Charsets以适合现代文本格式的方式处理文本数据. 这里将使用的示例程序相当简单, 不过, 它触及了使用Charset的所有关键方面：为给定的字符编码创建Charset, 以及使用该Charset解码和编码文本数据.  </p>
<ol start="2">
<li>编码/解码： </li>
</ol>
<p>要读和写文本, 我们要分别使用CharsetDecoder和CharsetEncoder. 将它们称为“编码器”和“解码器” 是有道理的. 一个字符不再表示一个特定的位模式, 而是表示字符系统中的一个实体. 因此, 由某个实际的位模式表示的字符必须以某种特定的编码来表示.  </p>
<p>CharsetDecoder用于将逐位表示的一串字符转换为具体的char值. 同样, 一个CharsetEncoder用于将字符转换回位.  </p>
<ol start="3">
<li>处理文本的正确方式： </li>
</ol>
<p>现在我们将分析这个例子程序UseCharsets.java. 这个程序非常简单：它从一个文件中读取一些文本, 并将该文本写入另一个文件. 但是它把该数据当作文本数据, 并使用CharBuffer来将该数句读入一个CharsetDecoder中. 同样, 它使用CharsetEncoder来写回该数据.  </p>
<p>我们将假设字符以ISO-8859-1(Latin1)字符集（这是ASCII的标准扩展）的形式储存在磁盘上. 尽管我们必须为使用Unicode做好准备, 但是也必须认识到不同的文件是以不同的格式储存的, 而ASCII无疑是非常普遍的一种格式. 事实上, 每种Java实现都要求对以下字符编码提供完全的支持： </p>
<p>   US-ASCII <br>   ISO-8859-1 <br>   UTF-8 <br>   UTF-16BE <br>   UTF-16LE <br>   UTF-16 </p>
<ol start="4">
<li>示例程序： </li>
</ol>
<p>   在打开相应的文件、将输入数据读入名为inputData的ByteBuffer之后, 我们的程序必须创建ISO-8859-1字符集的一个实例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Charset latin1 = Charset.forName( <span class="string">&quot;ISO-8859-1&quot;</span> );  </span><br></pre></td></tr></table></figure>
<p>   然后, 创建一个解码器（用于读取）和一个编码器 （用于写入）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CharsetDecoder decoder = latin1.newDecoder();  </span><br><span class="line">CharsetEncoder encoder = latin1.newEncoder();</span><br></pre></td></tr></table></figure>
<p>   为了将字节数据解码为一组字符, 我们把ByteBuffer传递给CharsetDecoder,  结果得到一个CharBuffer：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CharBuffer cb = decoder.decode( inputData );  </span><br></pre></td></tr></table></figure>
<p>   如果想要处理字符, 我们可以在程序的此处进行. 但是我们只想无改变地将它写回, 所以没有什么要做的.  </p>
<p>   要写回数据, 我们必须使用CharsetEncoder将它转换回字节：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ByteBuffer outputData = encoder.encode( cb );  </span><br></pre></td></tr></table></figure>
<p>   在转换完成之后, 我们就可以将数据写到文件中了. </p>
<h2 id="Java-NIO-bug"><a href="#Java-NIO-bug" class="headerlink" title="Java NIO bug"></a>Java NIO bug</h2><p>JDK 原生 NIO 程序的问题</p>
<p>JDK 原生也有一套网络应用程序 API，但是存在一系列问题，主要如下：</p>
<p>NIO 的类库和 API 繁杂，使用麻烦。你需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer 等。</p>
<p>需要具备其他的额外技能做铺垫。例如熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的 NIO 程序。</p>
<p>可靠性能力补齐，开发工作量和难度都非常大。例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等等。</p>
<p>NIO 编程的特点是功能开发相对容易，但是可靠性能力补齐工作量和难度都非常大。</p>
<p>JDK NIO 的 Bug。例如臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。</p>
<p>官方声称在 JDK 1.6 版本的 update 18 修复了该问题，但是直到 JDK 1.7 版本该问题仍旧存在，只不过该 Bug 发生概率降低了一些而已，它并没有被根本解决。</p>
<hr>
<p>[参考文献]</p>
<ul>
<li><a href="http://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.html">NIO 入门</a></li>
<li><a href="http://blog.csdn.net/kunluntaishan/article/details/53536386"> <strong>Java NIO浅析</strong> </a></li>
<li><a href="http://zhangshixi.iteye.com/blog/679959">NIO学习系列：核心概念及基本读写</a></li>
<li><a href="http://zhangshixi.iteye.com/blog/683767">NIO学习系列：连网和异步IO</a></li>
<li><a href="http://zhangshixi.iteye.com/blog/684544">NIO学习系列：缓冲区更多特性及分散/聚集IO</a></li>
<li><a href="http://zhangshixi.iteye.com/blog/685022">NIO学习系列：文件锁定和字符集</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDBC</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 压缩</title>
    <url>/Java/io/java-zip/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt; Java高级软件工程师知识结构</a></p>
<ol>
<li>掌握InputStream、OutputStream、Reader、Writer的继承体系。</li>
<li>掌握字节流(FileInputStream、DataInputStream、BufferedInputStream、FileOutputSteam、DataOutputStream、BufferedOutputStream)和 字符流(BufferedReader、InputStreamReader、FileReader、BufferedWriter、OutputStreamWriter、PrintWriter、FileWriter)，并熟练运用。</li>
<li>掌握NIO实现原理及使用方法。</li>
</ol>
<p>Java IO包括:</p>
<ul>
<li><a href="/Java/io/IO-Model/">IO Model</a></li>
<li><a href="/Java/io/BIO/">Java BIO</a></li>
<li><a href="/Java/io/NIO/">Java NIO</a></li>
<li><a href="/Java/io/AIO/">Java AIO</a></li>
<li><a href="/Java/io/java-zip/">Java压缩</a></li>
<li><a href="/Java/io/object-serialization/">Java序列化</a></li>
<li><a href="/Java/io/java-XML-JSON/">Java XML与JSON</a></li>
</ul>
<p>【案例】ZipOutputStream类<br>先看一下ZipOutputStream类的继承关系<br>java.lang.Object<br>java.io.OutputStream<br>java.io.FilterOutputStream<br>java.util.zip.DeflaterOutputStream<br>java.util.zip.ZipOutputStream</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipEntry;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipOutputStream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZipOutputStreamDemo1</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">       File file = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator +<span class="string">&quot;hello.txt&quot;</span>);</span><br><span class="line">       File zipFile = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator +<span class="string">&quot;hello.zip&quot;</span>);</span><br><span class="line">       InputStream input = <span class="keyword">new</span> FileInputStream(file);</span><br><span class="line">       ZipOutputStream zipOut = <span class="keyword">new</span> ZipOutputStream(<span class="keyword">new</span> FileOutputStream(</span><br><span class="line">                zipFile));</span><br><span class="line">       zipOut.putNextEntry(<span class="keyword">new</span> ZipEntry(file.getName()));</span><br><span class="line">       <span class="comment">// 设置注释</span></span><br><span class="line">       zipOut.setComment(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">       <span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">while</span>((temp = input.read()) != -<span class="number">1</span>)&#123;</span><br><span class="line">           zipOut.write(temp);</span><br><span class="line">       &#125;</span><br><span class="line">       input.close();</span><br><span class="line">       zipOut.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>【案例】ZipOutputStream类压缩多个文件</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipEntry;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipOutputStream;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 一次性压缩多个文件</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZipOutputStreamDemo2</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">       <span class="comment">// 要被压缩的文件夹</span></span><br><span class="line">       File file = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator +<span class="string">&quot;temp&quot;</span>);</span><br><span class="line">       File zipFile = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator + <span class="string">&quot;zipFile.zip&quot;</span>);</span><br><span class="line">       InputStream input = <span class="keyword">null</span>;</span><br><span class="line">       ZipOutputStream zipOut = <span class="keyword">new</span> ZipOutputStream(<span class="keyword">new</span> FileOutputStream(</span><br><span class="line">                zipFile));</span><br><span class="line">       zipOut.setComment(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">       <span class="keyword">if</span>(file.isDirectory())&#123;</span><br><span class="line">           File[] files = file.listFiles();</span><br><span class="line">           <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; files.length; ++i)&#123;</span><br><span class="line">                input = newFileInputStream(files[i]);</span><br><span class="line">                zipOut.putNextEntry(newZipEntry(file.getName()</span><br><span class="line">                        + File.separator +files[i].getName()));</span><br><span class="line">               <span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">while</span>((temp = input.read()) !=-<span class="number">1</span>)&#123;</span><br><span class="line">                    zipOut.write(temp);</span><br><span class="line">                &#125;</span><br><span class="line">                input.close();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       zipOut.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>【案例】ZipFile类展示</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipFile;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *ZipFile演示</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZipFileDemo</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">       File file = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator +<span class="string">&quot;hello.zip&quot;</span>);</span><br><span class="line">       ZipFile zipFile = <span class="keyword">new</span> ZipFile(file);</span><br><span class="line">       System.out.println(<span class="string">&quot;压缩文件的名称为：&quot;</span> + zipFile.getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>【案例】解压缩文件（压缩文件中只有一个文件的情况）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipEntry;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipFile;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 解压缩文件（压缩文件中只有一个文件的情况）</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZipFileDemo2</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">       File file = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator +<span class="string">&quot;hello.zip&quot;</span>);</span><br><span class="line">       File outFile = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator +<span class="string">&quot;unZipFile.txt&quot;</span>);</span><br><span class="line">       ZipFile zipFile = <span class="keyword">new</span> ZipFile(file);</span><br><span class="line">       ZipEntry entry =zipFile.getEntry(<span class="string">&quot;hello.txt&quot;</span>);</span><br><span class="line">       InputStream input = zipFile.getInputStream(entry);</span><br><span class="line">       OutputStream output = <span class="keyword">new</span> FileOutputStream(outFile);</span><br><span class="line">       <span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">while</span>((temp = input.read()) != -<span class="number">1</span>)&#123;</span><br><span class="line">           output.write(temp);</span><br><span class="line">       &#125;</span><br><span class="line">       input.close();</span><br><span class="line">       output.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>【案例】ZipInputStream类解压缩一个压缩文件中包含多个文件的情况</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipEntry;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipFile;</span><br><span class="line"><span class="keyword">import</span> java.util.zip.ZipInputStream;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 解压缩一个压缩文件中包含多个文件的情况</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZipFileDemo3</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        File file = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> +File.separator + <span class="string">&quot;zipFile.zip&quot;</span>);</span><br><span class="line">       File outFile = <span class="keyword">null</span>;</span><br><span class="line">       ZipFile zipFile = <span class="keyword">new</span> ZipFile(file);</span><br><span class="line">       ZipInputStream zipInput = <span class="keyword">new</span> ZipInputStream(<span class="keyword">new</span> FileInputStream(file));</span><br><span class="line">       ZipEntry entry = <span class="keyword">null</span>;</span><br><span class="line">        InputStream input = <span class="keyword">null</span>;</span><br><span class="line">       OutputStream output = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">while</span>((entry = zipInput.getNextEntry()) != <span class="keyword">null</span>)&#123;</span><br><span class="line">           System.out.println(<span class="string">&quot;解压缩&quot;</span> + entry.getName() + <span class="string">&quot;文件&quot;</span>);</span><br><span class="line">           outFile = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator + entry.getName());</span><br><span class="line">           <span class="keyword">if</span>(!outFile.getParentFile().exists())&#123;</span><br><span class="line">               outFile.getParentFile().mkdir();</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">if</span>(!outFile.exists())&#123;</span><br><span class="line">                outFile.createNewFile();</span><br><span class="line">           &#125;</span><br><span class="line">           input = zipFile.getInputStream(entry);</span><br><span class="line">           output = <span class="keyword">new</span> FileOutputStream(outFile);</span><br><span class="line">           <span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line">           <span class="keyword">while</span>((temp = input.read()) != -<span class="number">1</span>)&#123;</span><br><span class="line">                output.write(temp);</span><br><span class="line">           &#125;</span><br><span class="line">           input.close();</span><br><span class="line">           output.close();</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<hr>
<p>[参考文献]:</p>
<ol>
<li>Think in Java</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能网络编程IO模型与线程模型</title>
    <url>/Java/io/high-performance-network-programming/</url>
    <content><![CDATA[<h2 id="C10K问题"><a href="#C10K问题" class="headerlink" title="C10K问题"></a>C10K问题</h2><p><a href="http://www.kegel.com/c10k.html">C10K问题</a>: 一万个客户端同时连接</p>
<h3 id="常识一：文件句柄限制"><a href="#常识一：文件句柄限制" class="headerlink" title="常识一：文件句柄限制"></a>常识一：文件句柄限制</h3><p>在linux下每一个tcp连接都要占一个文件描述符，一旦文件描述符使用完了，新的连接到来返回给我们的错误是“Socket/File:Can’t open so many files”。</p>
<p>操作系统可以打开的最大文件数的限制。</p>
<h4 id="1-进程限制"><a href="#1-进程限制" class="headerlink" title="1 进程限制"></a>1 进程限制</h4><p>执行 <code>ulimit -n</code> 输出 <code>1024</code>，说明对于一个进程而言最多只能打开1024个文件，所以采用此配置最多可以并发上千个TCP连接。<br>临时修改：ulimit -n 1000000，但是这种临时修改只对当前登录用户目前的使用环境有效，系统重启或用户退出后就会失效。</p>
<p>重启后失效的修改: （CentOS 6.5下测试，重启后未发现失效），编辑 <code>/etc/security/limits.conf</code> 文件， 修改后内容为：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">soft nofile 1000000</span><br><span class="line">hard nofile 1000000</span><br></pre></td></tr></table></figure>
<p>永久修改：编辑/etc/rc.local，在其后添加如下内容：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -SHn 1000000</span><br></pre></td></tr></table></figure>
<h4 id="2-全局限制"><a href="#2-全局限制" class="headerlink" title="2 全局限制"></a>2 全局限制</h4><p>执行<code>cat /proc/sys/fs/file-nr</code>输出<code>9344 0 592026</code>，分别为：</p>
<ol>
<li>已经分配的文件句柄数，</li>
<li>已经分配但没有使用的文件句柄数，</li>
<li>最大文件句柄数。</li>
</ol>
<p>但在kernel 2.6版本中第二项的值总为0，这并不是一个错误，它实际上意味着已经分配的文件描述符无一浪费的都已经被使用了。我们可以把这个数值改大些，用 root 权限修改 <code>/etc/sysctl.conf</code> 文件:</p>
<ul>
<li>fs.file-max = 1000000</li>
<li>net.ipv4.ip_conntrack_max = 1000000</li>
<li>net.ipv4.netfilter.ip_conntrack_max = 1000000</li>
</ul>
<h3 id="常识二：端口号范围限制？"><a href="#常识二：端口号范围限制？" class="headerlink" title="常识二：端口号范围限制？"></a>常识二：端口号范围限制？</h3><p>操作系统上端口号1024以下是系统保留的，从1024-65535是用户使用的。每个TCP连接都要占一个端口号, 但可以创建的最大并发连接不只60000个</p>
<h4 id="如何标识一个TCP连接："><a href="#如何标识一个TCP连接：" class="headerlink" title="如何标识一个TCP连接："></a>如何标识一个TCP连接：</h4><p>系统用一个4四元组来唯一标识一个TCP连接：<code>&#123;local ip, local port,remote ip,remote port&#125;</code>。</p>
<blockquote>
<p>《UNIX网络编程：卷一》第四章中对accept的讲解，第二个参数cliaddr代表了客户端的ip地址和端口号。而服务端实际只使用了bind时这一个端口，说明端口号65535并不是并发量的限制。</p>
</blockquote>
<h4 id="server最大tcp连接数："><a href="#server最大tcp连接数：" class="headerlink" title="server最大tcp连接数："></a>server最大tcp连接数：</h4><p>server通常固定在某个本地端口上监听，等待client的连接请求。不考虑地址重用（unix的SO_REUSEADDR选项）的情况下，即使server端有多个ip，本地监听端口也是独占的，因此server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，因此最大tcp连接为<code>客户端ip数×客户端port数</code>，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为<code>2的32次方（ip数）×2的16次方（port数）</code>，也就是server端单机最大tcp连接数约为<code>2的48次方</code>。</p>
<h2 id="I-O-Model"><a href="#I-O-Model" class="headerlink" title="I/O Model"></a>I/O Model</h2><p>最初的服务器都是<strong>基于进程/线程模型</strong>的，一个TCP连接，就需要分配1个进程（或者线程）。而进程又是操作系统最昂贵的资源，一台机器无法创建很多进程。<br>如果是C10K就要创建1万个进程，那么单机而言操作系统是无法承受的（往往出现效率低下甚至完全瘫痪）。<br>如果是采用分布式系统，维持1亿用户在线需要10万台服务器，成本巨大，也只有Facebook、Google、雅虎等巨头才有财力购买如此多的服务器。</p>
<p>传统的同步阻塞I/O模型都是一样的，处理的方式都是requests per second，并发10K和100的区别关键在于CPU。<br>创建的进程线程多了，<strong>数据拷贝频繁（缓存I/O、内核将数据拷贝到用户进程空间、阻塞）， 进程/线程上下文切换消耗大</strong>， 导致操作系统崩溃，这就是C10K问题的本质！</p>
<h3 id="互联网服务端处理网络请求的原理"><a href="#互联网服务端处理网络请求的原理" class="headerlink" title="互联网服务端处理网络请求的原理"></a>互联网服务端处理网络请求的原理</h3><p>典型互联网服务端处理网络请求的典型过程：</p>
<p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/211858pgsyanbk1yffennv.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_1.jpeg">    </p>
<p>由上图可以看到，主要处理步骤包括： </p>
<p> 1）获取请求数据，客户端与服务器建立连接发出请求，服务器接受请求（1-3）；<br> 2）构建响应，当服务器接收完请求，并在用户空间处理客户端的请求，直到构建响应完成（4）；<br> 3）返回数据，服务器将已构建好的响应再通过内核空间的网络 I/O 发还给客户端（5-7）。</p>
<p>设计服务端并发模型时，主要有如下两个关键点： </p>
<p> 1）服务器如何管理连接，获取输入数据；<br> 2）服务器如何处理请求。</p>
<h3 id="“I-O-模型”的基本认识"><a href="#“I-O-模型”的基本认识" class="headerlink" title="“I/O 模型”的基本认识"></a>“I/O 模型”的基本认识</h3><h4 id="阻塞调用与非阻塞调用："><a href="#阻塞调用与非阻塞调用：" class="headerlink" title="阻塞调用与非阻塞调用："></a>阻塞调用与非阻塞调用：</h4><ul>
<li>阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回；</li>
<li>非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。</li>
</ul>
<p>两者的最大区别在于被调用方在收到请求到返回结果之前的这段时间内，调用方是否一直在等待。<strong>阻塞</strong>是指调用方一直在等待而且别的事情什么都不做；<strong>非阻塞</strong>是指调用方先去忙别的事情。</p>
<h4 id="同步处理与异步处理："><a href="#同步处理与异步处理：" class="headerlink" title="同步处理与异步处理："></a>同步处理与异步处理：</h4><p>同步处理是指被调用方得到最终结果之后才返回给调用方；异步处理是指被调用方先返回应答，然后再计算调用结果，计算完最终结果后再通知并返回给调用方。</p>
<p>阻塞、非阻塞和同步、异步的区别（阻塞、非阻塞和同步、异步其实针对的对象是不一样的）：</p>
<ul>
<li>1）阻塞、非阻塞的讨论对象是调用者；</li>
<li>2）同步、异步的讨论对象是被调用者。</li>
</ul>
<h4 id="recvfrom-函数："><a href="#recvfrom-函数：" class="headerlink" title="recvfrom 函数："></a>recvfrom 函数：</h4><p>// FIXME 究竟什么是Socket，操作系统套接字代表的是什么</p>
<p>recvfrom 函数(经 <code>Socket</code> 接收数据)，这里把它视为系统调用。</p>
<p>一个输入操作通常包括两个不同的阶段：</p>
<ul>
<li>1）等待数据准备好；</li>
<li>2）从内核向进程复制数据。</li>
</ul>
<p>对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。</p>
<p>实际应用程序在系统调用完成上面的 2 步操作时，调用方式的阻塞、非阻塞，操作系统在处理应用程序请求时，处理方式的同步、异步处理的不同，可以分为 5 种 I/O 模型（下面的章节将逐个展开介绍）。（参考《UNIX网络编程卷1》）</p>
<h3 id="阻塞式-I-O-blocking-I-O）"><a href="#阻塞式-I-O-blocking-I-O）" class="headerlink" title="阻塞式 I/O(blocking I/O）"></a>阻塞式 I/O(blocking I/O）</h3><p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/212717yp8iwt5z8j1niw8a.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_2.jpeg">    </p>
<p> 在阻塞式 I/O 模型中，应用程序在从调用 recvfrom 开始到它返回有数据报准备好这段时间是阻塞的，recvfrom 返回成功后，应用进程开始处理数据报。</p>
<p><strong>比喻：</strong> 一个人在钓鱼，当没鱼上钩时，就坐在岸边一直等。</p>
<p><strong>优点：</strong> 程序简单，在阻塞等待数据期间进程/线程挂起，基本不会占用 CPU 资源。</p>
<p><strong>缺点：</strong> 每个连接需要独立的进程/线程单独处理，当并发请求量大时为了维护程序，内存、线程切换开销较大，这种模型在实际生产中很少使用。</p>
<h3 id="非阻塞式-I-O-non-blocking-I-O）"><a href="#非阻塞式-I-O-non-blocking-I-O）" class="headerlink" title="非阻塞式 I/O (non-blocking I/O）"></a>非阻塞式 I/O (non-blocking I/O）</h3><p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/212910wn44nrr6zp5siiuo.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_3.jpeg"></p>
<p> 应用程序把一个套接口设置为非阻塞，就是告诉内核，当所请求的 I/O 操作无法完成时，不要将进程睡眠。<br> 而是返回一个错误，应用程序基于 I/O 操作函数将不断的轮询数据是否已经准备好，如果没有准备好，继续轮询，直到数据准备好为止。</p>
<p><strong>比喻：</strong> 边钓鱼边玩手机，隔会再看看有没有鱼上钩，有的话就迅速拉杆。</p>
<p><strong>优点：</strong> 不会阻塞在内核的等待数据过程，每次发起的 I/O 请求可以立即返回，不用阻塞等待，实时性较好。</p>
<p><strong>缺点：</strong> 轮询将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低，所以一般 Web 服务器不使用这种 I/O 模型。</p>
<h3 id="I-O-多路复用-I-O-multiplexing）"><a href="#I-O-多路复用-I-O-multiplexing）" class="headerlink" title="I/O 多路复用(I/O multiplexing）"></a>I/O 多路复用(I/O multiplexing）</h3><p><img src="http://www.52im.net/data/attachment/forum/201809/05/213041mtejdsoeojfjy7dd.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_4.jpeg"></p>
<p> 在 I/O 复用模型中，会用到 Select 或 Poll 函数或 Epoll 函数(Linux 2.6 以后的内核开始支持)，这两个函数也会使进程阻塞，但是和阻塞 I/O 有所不同。</p>
<p> 这两个函数可以同时阻塞多个 I/O 操作，而且可以同时对多个读操作，多个写操作的 I/O 函数进行检测，直到有数据可读或可写时，才真正调用 I/O 操作函数。</p>
<p><strong>比喻：</strong> 放了一堆鱼竿，在岸边一直守着这堆鱼竿，没鱼上钩就玩手机。</p>
<p><strong>优点：</strong> 可以基于一个阻塞对象，同时在多个描述符上等待就绪，而不是使用多个线程(每个文件描述符一个线程)，这样可以大大节省系统资源。</p>
<p><strong>缺点：</strong> 当连接数较少时效率相比多线程+阻塞 I/O 模型效率较低，可能延迟更大，因为单个连接处理需要 2 次系统调用，占用时间会有增加。</p>
<p>众所周之，Nginx这样的高性能互联网反向代理服务器大获成功的关键就是得益于<code>Epoll</code>。</p>
<h3 id="信号驱动式-I-O-（signal-driven-I-O"><a href="#信号驱动式-I-O-（signal-driven-I-O" class="headerlink" title="信号驱动式 I/O （signal-driven I/O)"></a>信号驱动式 I/O （signal-driven I/O)</h3><p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/213143a7n3mnxb38ybgxy3.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_5.jpeg"></p>
<p> 在信号驱动式 I/O 模型中，应用程序使用套接口进行信号驱动 I/O，并安装一个信号处理函数，进程继续运行并不阻塞。<br> 当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中调用 I/O 操作函数处理数据。</p>
<p><strong>比喻：</strong> 鱼竿上系了个铃铛，当铃铛响，就知道鱼上钩，然后可以专心玩手机。</p>
<p><strong>优点：</strong> 线程并没有在等待数据时被阻塞，可以提高资源的利用率。</p>
<p><strong>缺点：</strong> 信号 I/O 在大量 IO 操作时可能会因为信号队列溢出导致没法通知。</p>
<p> 信号驱动 I/O 尽管对于处理 UDP 套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。</p>
<p> 但是，对于 TCP 而言，信号驱动的 I/O 方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源，与前几种方式相比优势尽失。</p>
<h3 id="异步-I-O（即AIO，全称asynchronous-I-O）"><a href="#异步-I-O（即AIO，全称asynchronous-I-O）" class="headerlink" title="异步 I/O（即AIO，全称asynchronous I/O）"></a>异步 I/O（即AIO，全称asynchronous I/O）</h3><p><img src="http://www.52im.net/data/attachment/forum/201809/05/213218wbeovsvt6g7s4zsj.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_6.jpeg"></p>
<p> 由 POSIX 规范定义，应用程序告知内核启动某个操作，并让内核在整个操作（包括将数据从内核拷贝到应用程序的缓冲区）完成后通知应用程序。</p>
<p> 这种模型与信号驱动模型的主要区别在于：信号驱动 I/O 是由内核通知应用程序何时启动一个 I/O 操作，而异步 I/O 模型是由内核通知应用程序 I/O 操作何时完成。</p>
<p><strong>优点：</strong> 异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠。</p>
<p><strong>缺点：</strong> 要实现真正的异步 I/O，操作系统需要做大量的工作。目前 Windows 下通过 IOCP 实现了真正的异步 I/O。</p>
<p> 而在 Linux 系统下，Linux 2.6才引入，目前 AIO 并不完善，因此在 Linux 下实现高并发网络编程时都是以 IO 复用模型模式为主。</p>
<p> 关于AOI的介绍，请见：《Java新一代网络编程模型AIO原理及Linux系统AIO介绍》。</p>
<h3 id="5-种-I-O-模型总结"><a href="#5-种-I-O-模型总结" class="headerlink" title="5 种 I/O 模型总结"></a>5 种 I/O 模型总结</h3><p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/213459mmmhohhgwom24uoj.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_7.jpeg">    </p>
<p> 从上图中我们可以看出，越往后，阻塞越少，理论上效率也是最优。</p>
<p> 这五种 I/O 模型中，前四种属于同步 I/O，因为其中真正的 I/O 操作(recvfrom)将阻塞进程/线程，只有异步 I/O 模型才与 POSIX 定义的异步 I/O 相匹配。</p>
<h2 id="高性能网络编程中的线程模型"><a href="#高性能网络编程中的线程模型" class="headerlink" title="高性能网络编程中的线程模型"></a>高性能网络编程中的线程模型</h2><h3 id="传统阻塞-I-O-服务模型"><a href="#传统阻塞-I-O-服务模型" class="headerlink" title="传统阻塞 I/O 服务模型"></a>传统阻塞 I/O 服务模型</h3><p><img src="http://www.52im.net/data/attachment/forum/201809/06/195333v2cj2o6y92d2zp5z.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_1.jpeg">    </p>
<p><strong>特点：</strong></p>
<p>1）采用阻塞式 I/O 模型获取输入数据；<br>2）每个连接都需要独立的线程完成数据输入，业务处理，数据返回的完整操作。</p>
<p><strong>存在问题：</strong></p>
<p>1）当并发数较大时，需要创建大量线程来处理连接，系统资源占用较大；<br>2）连接建立后，如果当前线程暂时没有数据可读，则线程就阻塞在 Read 操作上，造成线程资源浪费。</p>
<h3 id="Reactor-模式"><a href="#Reactor-模式" class="headerlink" title="Reactor 模式"></a>Reactor 模式</h3><h4 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h4><p>针对传统阻塞 I/O 服务模型的 2 个缺点，比较常见的有如下解决方案： </p>
<p> 1）基于 I/O 复用模型：多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接。当某条连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理；<br> 2）基于线程池复用线程资源：不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。</p>
<p>I/O 复用结合线程池，这就是 Reactor 模式基本设计思想，如下图：</p>
<p><img src="http://www.52im.net/data/attachment/forum/201809/06/195839s5hi3te5pxueq5ze.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_2.jpeg"></p>
<p>Reactor 模式，是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。 </p>
<p>服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor 模式也叫 Dispatcher 模式。即 I/O 多了复用统一监听事件，收到事件后分发(Dispatch 给某进程)，是编写高性能网络服务器的必备技术之一。</p>
<p>Reactor 模式中有 2 个关键组成：</p>
<p>1）Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人；<br>2）Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。</p>
<p>根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现：</p>
<p>1）单 Reactor 单线程；<br>2）单 Reactor 多线程；<br>3）主从 Reactor 多线程。</p>
<p>下面详细介绍这 3 种实现方式。</p>
<h4 id="单-Reactor-单线程"><a href="#单-Reactor-单线程" class="headerlink" title="单 Reactor 单线程"></a>单 Reactor 单线程</h4><p><img src="http://www.52im.net/data/attachment/forum/201809/06/200048bgll2l41w72174ot.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_3.jpeg">    </p>
<p>其中，Select 是前面 I/O 复用模型介绍的标准网络编程 API，可以实现应用程序通过一个阻塞对象监听多路连接请求，其他方案示意图类似。</p>
<p>方案说明：</p>
<p>1）Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发；<br>2）如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理；<br>3）如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应；<br>4）Handler 会完成 Read→业务处理→Send 的完整业务流程。</p>
<p><strong>优点：</strong></p>
<p>模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成。</p>
<p>缺点：</p>
<p>性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈。</p>
<p> 可靠性问题，线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。</p>
<p><strong>使用场景：</strong></p>
<p>客户端的数量有限，业务处理非常快速，比如 Redis，业务处理的时间复杂度 O(1)。</p>
<h4 id="单-Reactor-多线程"><a href="#单-Reactor-多线程" class="headerlink" title="单 Reactor 多线程"></a>单 Reactor 多线程</h4><p>  <img src="http://www.52im.net/data/attachment/forum/201809/06/200650wun9j9ghkgk7ngna.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_4.jpeg">    </p>
<p>方案说明：</p>
<ul>
<li>1）Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发；</li>
<li>2）如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后续的各种事件；</li>
<li>3）如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应；</li>
<li>4）Handler 只负责响应事件，不做具体业务处理，通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理；</li>
<li>5）Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 Handler 进行处理；</li>
<li>6）Handler 收到响应结果后通过 Send 将响应结果返回给 Client。</li>
</ul>
<p>优点：</p>
<p>可以充分利用多核 CPU 的处理能力。</p>
<p>缺点：</p>
<p>多线程数据共享和访问比较复杂；Reactor 承担所有事件的监听和响应，在单线程中运行，高并发场景下容易成为性能瓶颈。</p>
<h4 id="主从-Reactor-多线程"><a href="#主从-Reactor-多线程" class="headerlink" title="主从 Reactor 多线程"></a>主从 Reactor 多线程</h4><p>  <img src="http://www.52im.net/data/attachment/forum/201809/06/200759gg777fr7v7wzcr7r.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_5.jpeg">    </p>
<p> 针对单 Reactor 多线程模型中，Reactor 在单线程中运行，高并发场景下容易成为性能瓶颈，可以让 Reactor 在多线程中运行。</p>
<p>方案说明：</p>
<ul>
<li>1）Reactor 主线程 MainReactor 对象通过 Select 监控建立连接事件，收到事件后通过 Acceptor 接收，处理建立连接事件；</li>
<li>2）Acceptor 处理建立连接事件后，MainReactor 将连接分配 Reactor 子线程给 SubReactor 进行处理；</li>
<li>3）SubReactor 将连接加入连接队列进行监听，并创建一个 Handler 用于处理各种连接事件；</li>
<li>4）当有新的事件发生时，SubReactor 会调用连接对应的 Handler 进行响应；</li>
<li>5）Handler 通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理；</li>
<li>6）Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 Handler 进行处理；</li>
<li>7）Handler 收到响应结果后通过 Send 将响应结果返回给 Client。</li>
</ul>
<p>优点：</p>
<p>父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。</p>
<p> 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。</p>
<p> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>3 种模式可以用个比喻来理解：</p>
<p>（餐厅常常雇佣接待员负责迎接顾客，当顾客入坐后，侍应生专门为这张桌子服务）</p>
<ul>
<li>1）单 Reactor 单线程，接待员和侍应生是同一个人，全程为顾客服务；</li>
<li>2）单 Reactor 多线程，1 个接待员，多个侍应生，接待员只负责接待；</li>
<li>3）主从 Reactor 多线程，多个接待员，多个侍应生。</li>
</ul>
<p>Reactor 模式具有如下的优点：</p>
<ul>
<li>1）响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的；</li>
<li>2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销；</li>
<li>3）可扩展性，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源；</li>
<li>4）可复用性，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。</li>
</ul>
<h3 id="Proactor-模型"><a href="#Proactor-模型" class="headerlink" title="Proactor 模型"></a>Proactor 模型</h3><p> 在 Reactor 模式中，Reactor 等待某个事件或者可应用或者操作的状态发生（比如文件描述符可读写，或者是 Socket 可读写）。 然后把这个事件传给事先注册的 Handler（事件处理函数或者回调函数），由后者来做实际的读写操作。其中的读写操作都需要应用程序同步操作，所以 Reactor 是非阻塞同步网络模型。</p>
<p> 如果把 I/O 操作改为异步，即交给操作系统来完成就能进一步提升性能，这就是异步网络模型 Proactor。</p>
<p>  <img src="http://www.52im.net/data/attachment/forum/201809/06/201251i0om3mro9wtcxrty.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_1.jpeg">    </p>
<p>Proactor 是和异步 I/O 相关的，详细方案如下：</p>
<p>1）Proactor Initiator 创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 AsyOptProcessor（Asynchronous Operation Processor）注册到内核；<br>2）AsyOptProcessor 处理注册请求，并处理 I/O 操作；<br>3）AsyOptProcessor 完成 I/O 操作后通知 Proactor；<br>4）Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；<br>5）Handler 完成业务处理。</p>
<p>可以看出 Proactor 和 Reactor 的区别：</p>
<p>1）Reactor 是在事件发生时就通知事先注册的事件（读写在应用程序线程中处理完成）；<br>2）Proactor 是在事件发生时基于异步 I/O 完成读写操作（由内核完成），待 I/O 操作完成后才回调应用程序的处理器来进行业务处理。</p>
<p>理论上 Proactor 比 Reactor 效率更高，异步 I/O 更加充分发挥 DMA(Direct Memory Access，直接内存存取)的优势。</p>
<p>但是Proactor有如下缺点：</p>
<p>1）编程复杂性，由于异步操作流程的事件的初始化和事件完成在时间和空间上都是相互分离的，因此开发异步应用程序更加复杂。应用程序还可能因为反向的流控而变得更加难以 Debug；<br>2）内存使用，缓冲区在读或写操作的时间段内必须保持住，可能造成持续的不确定性，并且每个并发操作都要求有独立的缓存，相比 Reactor 模式，在 Socket 已经准备好读或写前，是不要求开辟缓存的；<br>3）操作系统支持，Windows 下通过 IOCP 实现了真正的异步 I/O，而在 Linux 系统下，Linux 2.6 才引入，目前异步 I/O 还不完善。</p>
<p>因此在 Linux 下实现高并发网络编程都是以 Reactor 模型为主。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title>Java IO之XML与JSON解析</title>
    <url>/Java/io/java-XML-JSON/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt; Java高级软件工程师知识结构</a></p>
<ol>
<li>掌握InputStream、OutputStream、Reader、Writer的继承体系。</li>
<li>掌握字节流(FileInputStream、DataInputStream、BufferedInputStream、FileOutputSteam、DataOutputStream、BufferedOutputStream)和 字符流(BufferedReader、InputStreamReader、FileReader、BufferedWriter、OutputStreamWriter、PrintWriter、FileWriter)，并熟练运用。</li>
<li>掌握NIO实现原理及使用方法。</li>
</ol>
<p>Java IO包括:</p>
<ul>
<li><a href="/Java/io/IO-Model/">IO Model</a></li>
<li><a href="/Java/io/BIO/">Java BIO</a></li>
<li><a href="/Java/io/NIO/">Java NIO</a></li>
<li><a href="/Java/io/AIO/">Java AIO</a></li>
<li><a href="/Java/io/java-zip/">Java压缩</a></li>
<li><a href="/Java/io/object-serialization/">Java序列化</a></li>
<li><a href="/Java/io/java-XML-JSON/">Java XML与JSON</a></li>
</ul>
<h1 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h1><p>JSON: JavaScript对象表示法(JavaScript Object Notation)<br>是存储和交换文本信息的语法， 类似于XML，它采用键值对的形式来组织，易于阅读和编写，同时也已于机器解析和生成。JSON是独立于语言的，也就是说不管什么语言，都可以解析json，只需要按照json的规则来执行。</p>
<h2 id="JSON与XML比较"><a href="#JSON与XML比较" class="headerlink" title="JSON与XML比较"></a>JSON与XML比较</h2><ol>
<li>json长度更小</li>
<li>json读写速度更快</li>
<li>可以通过JavaScript内建的方法直接解析，转换成JavaScript对象，非常方便 。</li>
</ol>
<h2 id="JSON格式"><a href="#JSON格式" class="headerlink" title="JSON格式"></a>JSON格式</h2><p><img src="/images/java/io/jsonFormat.png"></p>
<h2 id="JavaScript中的解析"><a href="#JavaScript中的解析" class="headerlink" title="JavaScript中的解析"></a>JavaScript中的解析</h2><p>要两种方式：<code>eval</code>和<code>JSON.parse</code></p>
<p>在代码中使用eval时和危险的！ 特别是用它第三方的JSON数据（可能包含恶意代码）时， 尽可能使用 <code>JSON.parse()</code>方法解析字符串本身， 该方法还可以捕捉JSON中的语法错误。</p>
<p>例子:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> jsondata = <span class="string">&#x27;&#123;&quot;staff&quot;:[&#123;&quot;name&quot;:&quot;洪七&quot;,&quot;age&quot;:70&#125;,&#123;&quot;name&quot;:&quot;郭靖&quot;,&quot;age&quot;:35&#125;,&#123;&quot;name&quot;:&quot;黄蓉&quot;,&quot;age&quot;:30&#125;]&#125;&#x27;</span>；</span><br><span class="line"><span class="keyword">var</span> jsonobj= <span class="built_in">eval</span>(<span class="string">&#x27;(&#x27;</span>+jsondata+<span class="string">&#x27;)&#x27;</span>);</span><br><span class="line">alert(jsonobj.staff[<span class="number">0</span>].name);</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> jsondata = <span class="string">&#x27;&#123;&quot;staff&quot;:[&#123;&quot;name&quot;:&quot;洪七&quot;,&quot;age&quot;:70&#125;,&#123;&quot;name&quot;:&quot;郭靖&quot;,&quot;age&quot;:35&#125;,&#123;&quot;name&quot;:&quot;黄蓉&quot;,&quot;age&quot;:30&#125;]&#125;&#x27;</span>；</span><br><span class="line"><span class="keyword">var</span> jsonobj=<span class="built_in">JSON</span>.parse(jsondata);</span><br><span class="line">alert(jsonobj.staff[<span class="number">0</span>].name);</span><br></pre></td></tr></table></figure>
<hr>
<p>[参考文献]:</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
        <tag>InputStream</tag>
        <tag>OutputStream</tag>
        <tag>Reader</tag>
        <tag>Writer</tag>
      </tags>
  </entry>
  <entry>
    <title>Java对象序列化</title>
    <url>/Java/io/object-serialization/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt; Java高级软件工程师知识结构</a></p>
<ol>
<li>掌握InputStream、OutputStream、Reader、Writer的继承体系.</li>
<li>掌握字节流(FileInputStream、DataInputStream、BufferedInputStream、FileOutputSteam、DataOutputStream、BufferedOutputStream)和 字符流(BufferedReader、InputStreamReader、FileReader、BufferedWriter、OutputStreamWriter、PrintWriter、FileWriter), 并熟练运用.</li>
<li>掌握NIO实现原理及使用方法.</li>
</ol>
<p>Java IO包括:</p>
<ul>
<li><a href="/Java/io/IO-Model/">IO Model</a></li>
<li><a href="/Java/io/BIO/">Java BIO</a></li>
<li><a href="/Java/io/NIO/">Java NIO</a></li>
<li><a href="/Java/io/AIO/">Java AIO</a></li>
<li><a href="/Java/io/java-zip/">Java压缩</a></li>
<li><a href="/Java/io/object-serialization/">Java对象序列化</a></li>
<li><a href="/Java/io/java-XML-JSON/">Java XML与JSON</a></li>
</ul>
<h1 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h1><p>所谓序列化是将内存中Java对象转化为二进制字节数据, 反序列化就是从二进制字节数据转换为内存中的对象.  </p>
<ul>
<li>对象保存到文件: Java序列化将对象转换为二进制字节数据, 可以用于将内存中的对象保存到文件中.</li>
<li>复制对象：由于Java中的对象变量仅仅是栈中的一个指针, 而对象保存在堆内存中. 当<code>clone</code>复制对象时, 只是将对象中的对象变量复制, 而没有复制对象本身. 这被称为**<code>浅复制</code>**；相比之下, 使用序列化的方法, 可以将对象的值转换为二进制字节数组, 再<code>反序列化</code>便可以复制对象的所有内容, 这就是<code>深复制</code>.</li>
<li>自定义序列化</li>
</ul>
<h2 id="实现的样例"><a href="#实现的样例" class="headerlink" title="实现的样例"></a>实现的样例</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">123l</span>;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> birthday;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Person&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;name=&#x27;&quot;</span> + name + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, age=&quot;</span> + age +</span><br><span class="line">                <span class="string">&quot;, birthday=&quot;</span> + birthday +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age, <span class="keyword">long</span> birthday)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">        <span class="keyword">this</span>.birthday = birthday;</span><br><span class="line">    &#125;</span><br><span class="line">   ....<span class="comment">// getter setter</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="实现要点"><a href="#实现要点" class="headerlink" title="实现要点"></a>实现要点</h2><h3 id="Serializable接口"><a href="#Serializable接口" class="headerlink" title="Serializable接口"></a>Serializable接口</h3><p>Java是通过实现Serializable接口, 实现的序列化, Serializable接口里面没有任何的方法, 只是个标示接口.</p>
<h3 id="SerialVersionUID"><a href="#SerialVersionUID" class="headerlink" title="SerialVersionUID"></a>SerialVersionUID</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = ...;</span><br></pre></td></tr></table></figure>
<p><code>serialVersionUID</code>变量用于标记该类的版本UID.</p>
<p>Java使用一种<code>hash</code>值来快速的区分序列化流中的对象与要转换为的对象是否相同. 该 <code>hash</code>值 是根据给定源文件中几乎所有东西 — 方法名称、字段名称、字段类型、访问修改方法等 — 计算出来的, 序列化将该 hash 值与序列化流中的 hash 值相比较. 这个<code>hash</code>值就是<code>serialVersionUID</code>，<code>serialVersionUID</code>变量可以手动指定, 如果不指定, Java将使用 JDK<code>serialver</code> 命令计算出.</p>
<h3 id="ObjectOutputStream"><a href="#ObjectOutputStream" class="headerlink" title="ObjectOutputStream"></a>ObjectOutputStream</h3><p>实际的序列化和反序列化工作是通过ObjectOuputStream和ObjectInputStream来完成的。ObjectOutputStream的writeObject方法可以把一个Java对象写入到流中，ObjectInputStream的readObject方法可以从流中读取一个Java对象。在写入和读取的时候，虽然用的参数或返回值是单个对象，但实际上操纵的是一个对象图，包括该对象所引用的其它对象，以及这些对象所引用的另外的对象。Java会自动帮你遍历对象图并逐个序列化。除了对象之外，Java中的基本类型和数组也是可以通过 ObjectOutputStream和ObjectInputStream来序列化的。<br>下面的深复制是将内存中的二进制数组作为媒介来复制对象的. <a href="/Java/io/BIO/">关于ObjectOutputStream详情请看</a></p>
<h1 id="深复制与浅复制"><a href="#深复制与浅复制" class="headerlink" title="深复制与浅复制"></a>深复制与浅复制</h1><p>基础变量和对象的引用变量都是保存在JVM栈内存(<code>stack</code>)之中的, 而对象保存在JVM堆(Heap)内存中.<a href="/Java/JVM/">^JVM结构</a></p>
<p>实现<code>Clonable</code>接口, 并调用对象上的<code>clone</code>方法, 只会将JVM栈内存(stack)复制到新对象之中. 对象的引用变量所引用的对象实体不能使用.  这就是<code>浅复制</code>.</p>
<p>为了可以复制对象的所有的内容, 可以采用将目标序列化到内存中, 转换为二进制数据, 然后再反序列化回对象. 这就是”<code>深复制</code>“.</p>
<p>上代码:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShallowCopy</span> <span class="keyword">implements</span> <span class="title">Cloneable</span>, <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 浅复制</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> ShallowCopy <span class="title">clone</span><span class="params">()</span> <span class="keyword">throws</span> CloneNotSupportedException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (ShallowCopy) <span class="keyword">super</span>.clone();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 深复制</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ShallowCopy <span class="title">deepClone</span><span class="params">()</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</span><br><span class="line">        ByteArrayOutputStream baos = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">        ObjectOutputStream oos = <span class="keyword">new</span> ObjectOutputStream(baos);</span><br><span class="line">        oos.writeObject(<span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">        ByteArrayInputStream bis = <span class="keyword">new</span> ByteArrayInputStream(baos.toByteArray());</span><br><span class="line">        ObjectInputStream ois = <span class="keyword">new</span> ObjectInputStream(bis);</span><br><span class="line">        ShallowCopy shallowCopy = (ShallowCopy) ois.readObject();</span><br><span class="line">        <span class="keyword">return</span> shallowCopy;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="序列化多个目标"><a href="#序列化多个目标" class="headerlink" title="序列化多个目标"></a>序列化多个目标</h1><p>如上文所述, 序列化是将对象转换为字节数组, 需要<code>ObjectOutputStream</code>和<code>ObjectInputStream</code>实现. 因此, 可以向<code>ObjectOutputStream</code>输出多个对象, 也可以从<code>ObjectInputStream</code>中输入多个对象.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeObjects</span><span class="params">(List os, String fileName)</span> </span>&#123;</span><br><span class="line">    FileOutputStream outputStream = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        outputStream = <span class="keyword">new</span> FileOutputStream(fileName);</span><br><span class="line">        ObjectOutputStream stream = <span class="keyword">new</span> ObjectOutputStream(outputStream);</span><br><span class="line">        <span class="keyword">for</span> (Object o : os) &#123;</span><br><span class="line">            stream.writeObject(o);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (outputStream != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                outputStream.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">List&lt;T&gt; <span class="title">readObjects</span><span class="params">(String fileName, Class&lt;T&gt; clasz)</span> </span>&#123;</span><br><span class="line">    FileInputStream inputStream = <span class="keyword">null</span>;</span><br><span class="line">    T result = <span class="keyword">null</span>;</span><br><span class="line">    List&lt;T&gt; list = <span class="keyword">new</span> ArrayList&lt;T&gt;();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        inputStream = <span class="keyword">new</span> FileInputStream(fileName);</span><br><span class="line">        ObjectInputStream in = <span class="keyword">new</span> ObjectInputStream(inputStream);</span><br><span class="line">        Object object = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ((object = in.readObject()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            result = (T) object;</span><br><span class="line">            list.add(result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (inputStream != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                inputStream.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> list;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="序列化允许重构"><a href="#序列化允许重构" class="headerlink" title="序列化允许重构"></a>序列化允许重构</h1><p>序列化在保存对象的同时, 也就保存了数据. 序列化也成为保存数据的方式之一. 与数据库、XML或JSON等方式不同, 序列化依赖于对象体. 当变更数据项时, 需要修改类. 序列化是允许重构的.</p>
<p>序列化允许一定数量的类变种, 甚至重构之后也是如此, ObjectInputStream 仍可以很好地将其读出来.<br>Java Object Serialization 规范可以自动管理的关键任务是：</p>
<ul>
<li>将新字段添加到类中</li>
<li>将字段从 static 改为非 static</li>
<li>将字段从 transient 改为非 transient</li>
</ul>
<p>取决于所需的向后兼容程度, 转换字段形式（从非 static 转换为 static 或从非 transient 转换为 transient）或者删除字段需要额外的消息传递.</p>
<p>假设要在上面的<code>Person</code>类增加<code>gender</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">123l</span>;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> birthday;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> gender;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;PersonV1&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;name=&#x27;&quot;</span> + name + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, age=&quot;</span> + age +</span><br><span class="line">                <span class="string">&quot;, birthday=&quot;</span> + birthday +</span><br><span class="line">                <span class="string">&quot;, gender=&quot;</span> + gender +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age, <span class="keyword">long</span> birthday, <span class="keyword">int</span> gender)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">        <span class="keyword">this</span>.birthday = birthday;</span><br><span class="line">        <span class="keyword">this</span>.gender = gender;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// setter getter .....</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>重构, 需要满足两个条件：</p>
<ul>
<li>serialVersionUID必须相同</li>
<li>类名必须与原类相同</li>
</ul>
<p>为了使 Java 运行时相信两种类型实际上是一样的, 第二版和随后版本的 <code>Person</code> 必须与第一版有相同的序列化版本 hash（存储为 private static final <code>serialVersionUID</code> 字段）. 因此, 我们需要 <code>serialVersionUID</code> 字段, 它是通过对原始（或 V1）版本的 <code>Person</code> 类运行 JDK<code>serialver</code> 命令计算出的.</p>
<p>一旦有了 <code>Person</code> 的 <code>serialVersionUID</code>, 不仅可以从原始对象 <code>Person</code> 的序列化数据创建 <code>PersonV2</code> 对象（当出现新字段时, 新字段被设为缺省值, 最常见的是“null”）, 还可以反过来做：即从 <code>PersonV2</code> 的数据通过反序列化得到 <code>Person</code>, 这毫不奇怪.</p>
<h1 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h1><p>Java对象序列化之后的内容格式是公开的。所以可以很容易的从中提取出各种信息。从实现的角度来说，可以从不同的层次来加强序列化的安全性。<br>对序列化之后的流进行加密。这可以通过CipherOutputStream来实现。实现自己的writeObject和readObject方法，在调用defaultWriteObject之前，先对要序列化的域的值进行加密处理。使用一个SignedObject或SealedObject来封装当前对象，用SignedObject或SealedObject进行序列化。在从流中进行反序列化的时候，可以通过ObjectInputStream的registerValidation方法添加ObjectInputValidation接口的实现，用来验证反序列化之后得到的对象是否合法。</p>
<h2 id="自定义序列化，提高安全性"><a href="#自定义序列化，提高安全性" class="headerlink" title="自定义序列化，提高安全性"></a>自定义序列化，提高安全性</h2><p>为了避免保存的数据被恶意利用, 可以通过模糊化需要保密的字段. 此处, hook<code>Person</code>类中的<code>age</code>字段, 在上面的<code>Person</code>类中添加两个方法:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 自定义将对象写入输出流的方法&lt;br/&gt;</span></span><br><span class="line"><span class="comment">* 此处, 判断性别为女, 将年龄左移2个单位</span></span><br><span class="line"><span class="comment">* &lt;code&gt;stream.defaultWriteObject();&lt;/code&gt;接下来将所有的对象写入.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeObject</span><span class="params">(java.io.ObjectOutputStream stream)</span> <span class="keyword">throws</span> java.io.IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (gender == <span class="number">1</span>) &#123;</span><br><span class="line">    age = age &lt;&lt; <span class="number">2</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  stream.defaultWriteObject();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 自定义从输入流读入对象的方法:</span></span><br><span class="line"><span class="comment">* 与写对应, 在读入对象后, 女士的年龄右移2个单位</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readObject</span><span class="params">(java.io.ObjectInputStream stream)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> java.io.IOException, ClassNotFoundException </span>&#123;</span><br><span class="line">  stream.defaultReadObject();</span><br><span class="line">  <span class="keyword">if</span> (gender == <span class="number">1</span>) &#123;  </span><br><span class="line">    age = age &gt;&gt; <span class="number">2</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当调用<code>ObjectInputStream</code>读入对象时, 首先判断是否Entity实现了<code>readObject</code>方法, 如果实现了将调用该方法.</p>
<h1 id="签名与密封"><a href="#签名与密封" class="headerlink" title="签名与密封"></a>签名与密封</h1><p>//TODO</p>
<p>如果需要对整个对象进行加密和签名, 最简单的是将它放在一个 javax.crypto.SealedObject 和/或 java.security.SignedObject 包装器中. 两者都是可序列化的, 所以将对象包装在 SealedObject 中可以围绕原对象创建一种 “包装盒”. 必须有对称密钥才能解密, 而且密钥必须单独管理. 同样, 也可以将 SignedObject 用于数据验证, 并且对称密钥也必须单独管理.<br>结合使用这两种对象, 便可以轻松地对序列化数据进行密封和签名, 而不必强调关于数字签名验证或加密的细节. 很简洁, 是吧？</p>
<h1 id="将代理放在流中"><a href="#将代理放在流中" class="headerlink" title="将代理放在流中"></a>将代理放在流中</h1><p>很多情况下, 类中包含一个核心数据元素, 通过它可以派生或找到类中的其他字段. 在此情况下, 没有必要序列化整个对象. 可以将字段标记为<em>transient</em>, 但是每当有方法访问一个字段时, 类仍然必须显式地产生代码来检查它是否被初始化.</p>
<p>如果首要问题是序列化, 那么最好指定一个 flyweight 或代理放在流中. 为原始 <code>Person</code> 提供一个 <code>writeReplace</code> 方法, 可以序列化不同类型的对象来代替它. 类似地, 如果反序列化期间发现一个 <code>readResolve</code> 方法, 那么将调用该方法, 将替代对象提供给调用者.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PersonProxy</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PersonProxy</span><span class="params">(Person orig)</span></span>&#123;</span><br><span class="line">        data = orig.getFirstName() + <span class="string">&quot;,&quot;</span> + orig.getLastName() + <span class="string">&quot;,&quot;</span> + orig.getAge();</span><br><span class="line">        <span class="keyword">if</span> (orig.getSpouse() != <span class="keyword">null</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            Person spouse = orig.getSpouse();</span><br><span class="line">            data = data + <span class="string">&quot;,&quot;</span> + spouse.getFirstName() + <span class="string">&quot;,&quot;</span> + spouse.getLastName() + <span class="string">&quot;,&quot;</span>  </span><br><span class="line">              + spouse.getAge();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String data;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> Object <span class="title">readResolve</span><span class="params">()</span> <span class="keyword">throws</span> java.io.ObjectStreamException</span>&#123;</span><br><span class="line">        String[] pieces = data.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">        Person result = <span class="keyword">new</span> Person(pieces[<span class="number">0</span>], pieces[<span class="number">1</span>], Integer.parseInt(pieces[<span class="number">2</span>]));</span><br><span class="line">        <span class="keyword">if</span> (pieces.length &gt; <span class="number">3</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            result.setSpouse(<span class="keyword">new</span> Person(pieces[<span class="number">3</span>], pieces[<span class="number">4</span>], Integer.parseInt</span><br><span class="line">              (pieces[<span class="number">5</span>])));</span><br><span class="line">            result.getSpouse().setSpouse(result);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String fn, String ln, <span class="keyword">int</span> a)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.firstName = fn; <span class="keyword">this</span>.lastName = ln; <span class="keyword">this</span>.age = a;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getFirstName</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> firstName; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getLastName</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> lastName; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> age; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Person <span class="title">getSpouse</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> spouse; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Object <span class="title">writeReplace</span><span class="params">()</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> java.io.ObjectStreamException</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> PersonProxy(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFirstName</span><span class="params">(String value)</span> </span>&#123; firstName = value; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setLastName</span><span class="params">(String value)</span> </span>&#123; lastName = value; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAge</span><span class="params">(<span class="keyword">int</span> value)</span> </span>&#123; age = value; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpouse</span><span class="params">(Person value)</span> </span>&#123; spouse = value; &#125;   </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;[Person: firstName=&quot;</span> + firstName +</span><br><span class="line">            <span class="string">&quot; lastName=&quot;</span> + lastName +</span><br><span class="line">            <span class="string">&quot; age=&quot;</span> + age +</span><br><span class="line">            <span class="string">&quot; spouse=&quot;</span> + spouse.getFirstName() +</span><br><span class="line">            <span class="string">&quot;]&quot;</span>;</span><br><span class="line">    &#125;    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String firstName;</span><br><span class="line">    <span class="keyword">private</span> String lastName;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">private</span> Person spouse;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>注意, <code>PersonProxy</code> 必须跟踪 <code>Person</code> 的所有数据. 这通常意味着代理需要是 <code>Person</code> 的一个内部类, 以便能访问 private 字段. 有时候, 代理还需要追踪其他对象引用并手动序列化它们, 例如 <code>Person</code> 的 spouse.</p>
<p>这种技巧是少数几种不需要读/写平衡的技巧之一. 例如, 一个类被重构成另一种类型后的版本可以提供一个 <code>readResolve</code> 方法, 以便静默地将被序列化的对象转换成新类型. 类似地, 它可以采用 <code>writeReplace</code> 方法将旧类序列化成新版本.</p>
<h1 id="信任但要验证"><a href="#信任但要验证" class="headerlink" title="信任但要验证"></a>信任但要验证</h1><p>认为序列化流中的数据总是与最初写到流中的数据一致, 这没有问题. 但是, 正如一位美国前总统所说的, “信任, 但要验证”.</p>
<p>对于序列化的对象, 这意味着验证字段, 以确保在反序列化之后它们仍具有正确的值, “以防万一”. 为此, 可以实现 <code>ObjectInputValidation</code>接口, 并覆盖 <code>validateObject()</code> 方法. 如果调用该方法时发现某处有错误, 则抛出一个 <code>InvalidObjectException</code>.</p>
<h1 id="声明某个字段不序列化"><a href="#声明某个字段不序列化" class="headerlink" title="声明某个字段不序列化"></a>声明某个字段不序列化</h1><p>在默认的序列化实现中，Java对象中的非静态和非瞬时域都会被包括进来，而与域的可见性声明没有关系。这可能会导致某些不应该出现的域被包含在序列化之后的字节数组中，比如密码等隐私信息。由于Java对象序列化之后的格式是固定的，其它人可以很容易的从中分析出其中的各种信息。对于这种情况，一种解决办法是把域声明为瞬时的，即使用transient关键词。另外一种做法是添加一个serialPersistentFields?</p>
<p>域来声明序列化时要包含的域。从这里可以看到在Java序列化机制中的这种仅在书面层次上定义的契约。声明序列化的域必须使用固定的名称和类型。在后面还可以看到其它类似这样的契约。虽然Serializable只是一个标记接口，但它其实是包含有不少隐含的要求。下面的代码给出了<br> serialPersistentFields的声明示例，即只有firstName这个域是要被序列化的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ObjectStreamField[] serialPersistentFields = &#123;</span><br><span class="line">    <span class="keyword">new</span> ObjectStreamField(<span class="string">&quot;firstName&quot;</span>, String.class)</span><br><span class="line">&#125;;  </span><br></pre></td></tr></table></figure>
<h1 id="定制化序列化Externalizable"><a href="#定制化序列化Externalizable" class="headerlink" title="定制化序列化Externalizable"></a>定制化序列化Externalizable</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 序列化和反序列化的操作</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExternalizableDemo</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        ser(); <span class="comment">// 序列化</span></span><br><span class="line">        dser(); <span class="comment">// 反序列话</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">ser</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        File file = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator + <span class="string">&quot;hello.txt&quot;</span>);</span><br><span class="line">        ObjectOutputStream out = <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(</span><br><span class="line">                file));</span><br><span class="line">        out.writeObject(<span class="keyword">new</span> Person(<span class="string">&quot;rollen&quot;</span>, <span class="number">20</span>));</span><br><span class="line">        out.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dser</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        File file = <span class="keyword">new</span> File(<span class="string">&quot;d:&quot;</span> + File.separator + <span class="string">&quot;hello.txt&quot;</span>);</span><br><span class="line">        ObjectInputStream input = <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> FileInputStream(</span><br><span class="line">                file));</span><br><span class="line">        Object obj = input.readObject();</span><br><span class="line">        input.close();</span><br><span class="line">        System.out.println(obj);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="keyword">implements</span> <span class="title">Externalizable</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;姓名：&quot;</span> + name + <span class="string">&quot;  年龄：&quot;</span> + age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 复写这个方法, 根据需要可以保存的属性或者具体内容, 在序列化的时候使用</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeExternal</span><span class="params">(ObjectOutput out)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        out.writeObject(<span class="keyword">this</span>.name);</span><br><span class="line">        out.writeInt(age);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 复写这个方法, 根据需要读取内容 反序列话的时候需要</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readExternal</span><span class="params">(ObjectInput in)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">            ClassNotFoundException</span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = (String) in.readObject();</span><br><span class="line">        <span class="keyword">this</span>.age = in.readInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问:"></a>疑问:</h1><ol>
<li>转换成的二进制数据是什么样子？</li>
<li>Enum类型的变量是否能正确的序列化和反序列化？</li>
</ol>
<h1 id="其他序列化框架"><a href="#其他序列化框架" class="headerlink" title="其他序列化框架"></a>其他序列化框架</h1><h2 id="kryo"><a href="#kryo" class="headerlink" title="kryo"></a>kryo</h2><hr>
<p>[参考文献]:</p>
<ol>
<li>Think in Java</li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-5things1/">关于 Java 对象序列化您不知道的 5 件事</a></li>
<li><a href="http://www.infoq.com/cn/articles/cf-java-object-serialization-rmi/">Java深度历险（十）——Java对象序列化与RMI</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
        <tag>InputStream</tag>
        <tag>OutputStream</tag>
        <tag>Reader</tag>
        <tag>Writer</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/Java/jvm/GraalVm/</url>
    <content><![CDATA[<h1 id="GraalVm"><a href="#GraalVm" class="headerlink" title="GraalVm"></a>GraalVm</h1><p><a href="https://www.graalvm.org/docs/getting-started-with-graalvm/">https://www.graalvm.org/docs/getting-started-with-graalvm/</a>    </p>
<p><a href="https://medium.com/graalvm/simplifying-native-image-generation-with-maven-plugin-and-embeddable-configuration-d5b283b92f57">https://medium.com/graalvm/simplifying-native-image-generation-with-maven-plugin-and-embeddable-configuration-d5b283b92f57</a></p>
]]></content>
  </entry>
  <entry>
    <title>深入理解JVM(Java虚拟机)</title>
    <url>/Java/jvm/JVM/</url>
    <content><![CDATA[<pre><code>JVM内存区域划分
    1. 掌握程序计数器、堆、虚拟机栈、本地方法栈、方法区（JAVA8已移除）、元空间（JAVA8新增）的作用及基本原理.
    2. 掌握堆的划分:  新生代（Eden、Survivor1、Survivor2）和老年代的作用及工作原理.
    3. 掌握JVM内存参数设置及调优.
类加载
    1. 掌握类的加载阶段:  加载、链接（验证、准备、解析）、初始化、使用、卸载.
    2. 掌握类加载器分类及其应用:  启动类加载器、扩展类加载器、应用程序类加载器、自定义加载器.</code></pre>
<h1 id="运行时内存结构"><a href="#运行时内存结构" class="headerlink" title="运行时内存结构"></a>运行时内存结构</h1><h1 id="Class文件格式"><a href="#Class文件格式" class="headerlink" title="Class文件格式"></a>Class文件格式</h1><h1 id="Java字节码和执行引擎"><a href="#Java字节码和执行引擎" class="headerlink" title="Java字节码和执行引擎"></a>Java字节码和执行引擎</h1><h1 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h1><h1 id="监控调优"><a href="#监控调优" class="headerlink" title="监控调优"></a>监控调优</h1><h1 id="GC算法和垃圾回收"><a href="#GC算法和垃圾回收" class="headerlink" title="GC算法和垃圾回收"></a>GC算法和垃圾回收</h1><h1 id="类加载"><a href="#类加载" class="headerlink" title="类加载"></a>类加载</h1><h1 id="线程和锁"><a href="#线程和锁" class="headerlink" title="线程和锁"></a>线程和锁</h1><h1 id="JVM内存区域划分"><a href="#JVM内存区域划分" class="headerlink" title="JVM内存区域划分"></a>JVM内存区域划分</h1><p><img src="/images/java/JVM/jvm-struct.jpg" alt="java虚拟机运行时数据区"><br><img src="/images/java/JVM/jvm-struct-thread.jpg" alt="java虚拟机运行时数据区与线程的关系"></p>
<p>JVM内存区域可以划分为:</p>
<ul>
<li>程序计数器</li>
<li>堆</li>
<li>虚拟机栈</li>
<li>本地方法栈</li>
<li>方法区(Java8已移除)</li>
<li>元空间(Java8新增)</li>
</ul>
<h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><ol>
<li><p>程序计数器可以看做是当前线程所执行的字节码的行号指示器. 在JVM的概念模型里, 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令.</p>
</li>
<li><p>由于JVM的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的, 为了在线程切换后能恢复到正确的执行位置, 每条线程都需要有一个独立的程序计数器, 独立存储, 互不影响. 所以, 程序计数器是<strong>线程私有</strong>的内存区域.</p>
</li>
<li><p>如果线程执行的是一个Java方法, 计数器记录的是正在执行的虚拟机字节码指令的地址；如果线程执行的是一个Native方法, 计数器的值为空.</p>
</li>
<li><p>程序计数器是Java虚拟机规范中<strong>唯一</strong>一个<strong>没有</strong>规定任何<strong>OutOfMemoryError</strong>情况的区域.</p>
</li>
</ol>
<h2 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h2><ol>
<li><p>Java虚拟机栈描述的是Java方法执行的内存模型:  </p>
<p>每个方法执行的同时会创建一个栈帧, 栈帧用于存储<strong>局部变量表</strong>、操作数栈、动态链接、方法出口等信息. 每个方法从调用直至执行完成的过程, 就对应着一个栈帧在虚拟机栈中入栈到出栈的过程.</p>
<p><img src="/images/java/JVM/jvm-stack-frame.png" alt="栈帧"></p>
</li>
</ol>
<ol>
<li><p>Java虚拟机栈是<strong>线程私有</strong>的, 它的生命周期与线程相同.</p>
</li>
<li><p>程序员主要关注的stack栈内存, 就是虚拟机栈中局部变量表部分.<br>局部变量表存放了编译时期可知的各种<strong>基本数据类型</strong>和<strong>对象引用</strong>.<br>局部变量表所需的内存空间在编译时期完成分配, 当进入一个方法时, 这个方法需要在栈帧中分配多大的局部变量空间是完全确定的, 在方法运行期间不会改变局部变量表的大小.</p>
</li>
<li><p>Java虚拟机规范对这个区域规定了两种异常情况:  </p>
</li>
</ol>
<ul>
<li>如果线程请求的栈深度大于虚拟机所允许的深度, 将抛出<code>StackOverflowError</code> 异常；</li>
<li>如果虚拟机栈可以动态扩展, 如果扩展时无法申请到足够的内存, 就会抛出<code>OutOfMemoryError</code>异常；<br>  （当前大部分JVM都可以动态扩展, 只不过JVM规范也允许固定长度的虚拟机栈）</li>
</ul>
<blockquote>
<p>栈深度:   每次方法调用, 都会创建一个栈帧, 一个方法调用另一个方法, 栈帧就会深度增加一层</p>
</blockquote>
<h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><ol>
<li><p>本地方法栈与虚拟机栈所发挥的作用是非常相似的, 它们之间的区别不过是虚拟机栈为虚拟机执行Java方法服务（也就是字节码）, 而本地方法栈为虚拟机使用到的Native方法服务.</p>
</li>
<li><p>Java虚拟机规范对本地方法栈使用的语言、使用方法与数据结构并没有强制规定, 因此可以由虚拟机自由实现. 例如:  HotSpot虚拟机直接将本地方法栈和虚拟机栈合二为一.</p>
</li>
<li><p>同虚拟机栈相同, Java虚拟机规范对这个区域也规定了两种异常情况<code>StackOverflowError</code> 和 <code>OutOfMemoryError</code>异常.</p>
</li>
</ol>
<h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><ol>
<li>Java堆是被<strong>所有的线程共享</strong>的一块内存区域, 在虚拟机启动时创建.<br>Java堆的唯一目的就是存放对象实例, 几乎所有的对象实例都在这里分配内存.</li>
<li>Java堆是垃圾回收器管理的主要区域, 因此也被称为”GC堆”.</li>
</ol>
<p>从内存回收的角度看, 由于现在收集器基本都采用分代收集算法, 所以Java堆可以细分为:  新生代、老生代；</p>
<p>从内存分配的角度看, 线程共享的Java堆可能划分出多个线程私有的分配缓冲区（TLAB）；</p>
<p>不论如何划分, 都与存放的内容无关, 无论哪个区域, 存储的仍然是对象实例.</p>
<ol>
<li><p>Java虚拟机规范规定, Java堆可以处于物理上不连续的内存空间中, 只要逻辑上是连续的即可, 就像我们的磁盘空间一样. 在实现上, 既可以是固定大小的, 也可以是可扩展的, 不过当前主流JVM都是按照可扩展来实现的.</p>
</li>
<li><p>Java虚拟机规范规定, 如果在堆上没有内存完成实例分配, 并且堆上也无法再扩展时, 将会抛出<code>OutOfMemoryError</code>异常.</p>
</li>
<li><p>内存泄露和内存溢出<br> Java堆内存的<code>OOM</code>异常是非常常见的异常情况, 重点是根据内存中的对象是否是必要的, 来弄清楚到底是出现了<code>内存泄露(Memory Leak)</code>还是<code>内存溢出(Memory Overflow)</code>.</p>
</li>
</ol>
<ul>
<li> 内存泄露:  指程序中一些对象不会被GC所回收, 它始终占用内存, 即被分配的对象引用链可达但已无用. （可用内存减少）</li>
<li> 内存溢出:  程序运行过程中无法申请到足够的内存而导致的一种错误. 内存溢出通常发生于OLD段或Perm段垃圾回收后, 仍然无内存空间容纳新的Java对象的情况.</li>
<li> 内存泄露是内存溢出的一种诱因, 不是唯一因素.</li>
</ul>
<h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><ol>
<li><p>方法区也是被<code>所有的线程共享</code>的一块内存区域. 它用于存储已被虚拟机加载的<code>类信息</code>、<code>常量</code>、<code>静态变量</code>、<code>即时编译器编译后的代码</code>等数据.</p>
</li>
<li><p>Java虚拟机规范对方法区的限制非常宽松, 除了和Java堆一样 不需要连续的内存和可以选择固定大小或者可扩展之外, 还可以选择不实现垃圾回收.<br> 这区域的内存回收目标主要是针对常量池的回收和类型的卸载, 一般而言, 这个区域的内存回收比较难以令人满意, 尤其是类型的回收, 条件相当苛刻, 但是这部分区域的内存回收确实是必要的.</p>
</li>
<li><p>Java虚拟机规范规定, 当方法区无法满足内存分配的需求时, 将抛出<code>OutOfMemoryError</code>异常.</p>
</li>
<li><p><strong>运行时常量池</strong></p>
<p><code>运行时常量池</code>是方法区的一部分. Class文件中除了有类的版本、字段、方法、接口等描述信息外, 还有一项信息是常量池, 用于存放编译期生成的各种字面量和符号引用, 这部分内容将在类加载后进入方法区的运行时常量池中存放.</p>
<p><code>运行时常量池</code>相对于Class文件常量池的另外一个重要特征是具备动态性, Java语言并不要求常量一定只有编译期才能产生, 也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池, 运行期间也可能将新的常量放入池中, 这种特性被开发人员利用比较多的就是String类的intern()方法.</p>
</li>
<li><p>String.intern()</p>
<p><code>String.intern()</code>是一个<code>Native</code>方法, 它的作用是:  如果字符串常量池中已经包含了一个等于此String对象的字符串, 则返回代表池中这个字符串的String对象；否则, 将此String对象包含的字符串添加到常量池中, 并且返回此字符串的引用.</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"> String str1 = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;计算机&quot;</span>).append(<span class="string">&quot;软件&quot;</span>).toString();</span><br><span class="line"> System.out.println(str1.intern() == str1);</span><br><span class="line"></span><br><span class="line"> String str2 = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;ja&quot;</span>).append(<span class="string">&quot;va&quot;</span>).toString();</span><br><span class="line"> System.out.println(str2.intern() == str2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  这段代码在JDK1.6中运行, 会得到两个false, 而在JDK1.7中运行, 会得到一个true和一个false. 原因是:  </p>
<ol>
<li>在JDK1.6中<code>intern()</code>方法会把首次遇到的字符串实例复制到永久代中, 返回的也是永久代中这个字符串实例的引用, 而由<code>StringBuilder</code>创建的字符串实例在Java堆上, 所以必然不是一个引用.</li>
<li>在JDK1.7中<code>intern()</code>方法不会复制实例, 只是在常量池中记录首次出现的实例引用, 因此<code>intern()</code>返回的引用和由<code>StringBuilder</code>创建的字符串实例是同一个.</li>
<li>str2返回false是因为Java这个字符串在执行<code>StringBuilder(&quot;ja&quot;).append(&quot;va&quot;).toString()</code>之前已经出现过, 字符串常量池中已经有它的引用了, 不符合首次出现的原则, 而”计算机软件”这个字符串是首次出现的.</li>
</ol>
<h1 id="堆的划分"><a href="#堆的划分" class="headerlink" title="堆的划分"></a>堆的划分</h1><p><img src="/images/java/JVM/jvm-heap-generations.jpg" alt="堆的分代划分"><br>堆的分代划分</p>
<ol>
<li><p>Young（年轻代）</p>
<p>年轻代分三个区. 一个<code>Eden</code>区, 两个 <code>Survivor</code>区. 大部分对象在<code>Eden</code>区中生成. 当Eden区满时, 还存活的对象将被复制到Survivor区（两个中的一个）, 当这个 Survivor区满时, 此区的存活对象将被复制到另外一个Survivor区, 当这个Survivor区也满了的时候, 从第一个Survivor区复制过来的并且此时还存活的对象, 将被复制“<code>年老区(Tenured)</code>”. 需要注意, Survivor的两个区是对称的, 没先后关系, 所以同一个区中可能同时存在从Eden复制过来的对象和从前一个Survivor复制过来的对象, 而复制到年老区的只有从第一个Survivor区过来的对象. 而且, Survivor区总有一个是空的.</p>
</li>
<li><p>Tenured（年老代）</p>
<p>年老代存放从年轻代存活的对象. 一般来说年老代存放的都是生命期较长的对象.</p>
</li>
<li><p>Perm（持久代）</p>
<p>用于存放静态文件, 如Java类、方法等. 持久代对垃圾回收没有显著影响, 但是有些应用可能动态生成或者调用一些Class, 例如Hibernate等,  在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类. 持久代大小通过-XX:MaxPermSize=进行设置.</p>
</li>
</ol>
<h2 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h2><p>GC有两种类型:  Scavenge GC和Full GC.</p>
<ol>
<li><p><code> Scavenge GC</code></p>
<p>一般情况下, 当新对象生成, 并且在Eden申请空间失败时, 就好触发Scavenge GC, 堆Eden区域进行GC, 清除非存活对象, 并且把尚且存活的对象移动到Survivor区. 然后整理Survivor的两个区.</p>
</li>
<li><p><code> Full GC</code></p>
<p>对整个堆进行整理, 包括Young、Tenured和Perm. Full GC比Scavenge GC要慢, 因此应该尽可能减少Full GC. 有如下原因可能导致Full GC:  </p>
</li>
</ol>
<ul>
<li>   Tenured被写满</li>
<li> Perm域被写满<ul>
<li>   System.gc()被显示调用</li>
<li>   上一次GC之后Heap的各域分配策略动态变化</li>
</ul>
</li>
</ul>
<h2 id="基本回收算法"><a href="#基本回收算法" class="headerlink" title="基本回收算法"></a>基本回收算法</h2><ul>
<li>引用计数（Reference Counting）<br>比较古老的回收算法。原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象。此算法最致命的是无法处理循环引用的问题。</li>
<li>标记-清除（Mark-Sweep）<br>此算法执行分两阶段。第一阶段从引用根节点开始标记所有被引用的对象，第二阶段遍历整个堆，把未标记的对象清除。此算法需要暂停整个应用，同时，会产生内存碎片。</li>
<li>复制（Copying）<br>此 算法把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。次算法每次只处理 正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不过出现“碎片”问题。当然，此算法的缺点也是很明显的，就是需要两倍 内存空间。</li>
<li>标记-整理（Mark-Compact）<br>此算法结 合了“标记-清除”和“复制”两个算法的优点。也是分两阶段，第一阶段从根节点开始标记所有被引用对象，第二阶段遍历整个堆，把清除未标记对象并且把存活 对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。</li>
<li>增量收集（Incremental Collecting）<br>实施垃圾回收算法，即：在应用进行的同时进行垃圾回收。不知道什么原因JDK5.0中的收集器没有使用这种算法的。</li>
<li>分代（Generational Collecting）<br>基于对对象生命周期分析后得出的垃圾回收算法。把对象分为年青代、年老代、持久代，对不同生命周期的对象使用不同的算法（上述方式中的一个）进行回收。现在的垃圾回收器（从J2SE1.2开始）都是使用此算法的。</li>
</ul>
<h1 id="JVM内存参数设置与调优"><a href="#JVM内存参数设置与调优" class="headerlink" title="JVM内存参数设置与调优"></a>JVM内存参数设置与调优</h1><p>常见配置举例</p>
<p>堆大小设置</p>
<p>  JVM 中最大堆大小有三方面限制:  相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制. 32位系统 下, 一般限制在1.5G~2G；64为操作系统对内存无限制. 我在Windows Server 2003 系统, 3.5G物理内存, JDK5.0下测试, 最大可设置为1478m.</p>
<p>典型设置:  </p>
<ul>
<li><code>java -Xmx3550m -Xms3550m -Xmn2g -Xss128k</code><ul>
<li> -Xmx3550m:  设置JVM最大可用内存为3550M.</li>
<li> -Xms3550m:  设置JVM初始内存为3550m. 此值可以设置与-Xmx相同, 以避免每次垃圾回收完成后JVM重新分配内存.</li>
<li> -Xmn2g:  设置年轻代大小为2G. 整个堆大小=年轻代大小 + 年老代大小 + 持久代大小. 持久代一般固定大小为64m, 所以增大年轻代后, 将会减小年老代大小. 此值对系统性能影响较大, Sun官方推荐配置为整个堆的3/8.</li>
<li> -Xss128k:   设置每个线程的堆栈大小. JDK5.0以后每个线程堆栈大小为1M, 以前每个线程堆栈大小为256K. 更具应用的线程所需内存大小进行调整. 在相同物理内 存下, 减小这个值能生成更多的线程. 但是操作系统对一个进程内的线程数还是有限制的, 不能无限生成, 经验值在3000~5000左右.</li>
</ul>
</li>
<li><code>java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0</code><ul>
<li> -XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）. 设置为4, 则年轻代与年老代所占比值为1:  4, 年轻代占整个堆栈的1/5</li>
<li> -XX:SurvivorRatio=4:  设置年轻代中Eden区与Survivor区的大小比值. 设置为4, 则两个Survivor区与一个Eden区的比值为2:4, 一个Survivor区占整个年轻代的1/6</li>
<li> -XX:MaxPermSize=16m:设置持久代大小为16m.</li>
<li> -XX:MaxTenuringThreshold=0:  设置垃圾最大年龄. 如果设置为0的话, 则年轻代对象不经过Survivor区, 直接进入年老代. 对于年老代比较多的应用, 可以提高效率. 如果将此值设置为一个较大值, 则年轻代对象会在Survivor区进行多次复制, 这样可以增加对象再年轻代的存活时间, 增加在年轻代即被回收的概论.</li>
</ul>
</li>
</ul>
<h2 id="调优总结"><a href="#调优总结" class="headerlink" title="调优总结"></a>调优总结</h2><ol>
<li><p>年轻代大小选择</p>
<p>  响应时间优先的应用:  尽可能设大, 直到接近系统的最低响应时间限制（根据实际情况选择）. 在此种情况下, 年轻代收集发生的频率也是最小的. 同时, 减少到达年老代的对象.</p>
<p>  吞吐量优先的应用:  尽可能设大, 可能到达Gbit的程度. 因为对响应时间没有要求, 垃圾收集可以并行进行, 一般适合8CPU以上的应用.</p>
</li>
<li><p>年老代大小选择</p>
<pre><code>响应时间优先的应用:  

年老代使用并发收集器, 所以其大小需要小心设置, 一般要考虑并发会话率和会话持续时间等一些参数. 如果堆设置小了, 可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了, 则需要较长的收集时间. 最优化的方案, 一般需要参考以下数据获得:  </code></pre>
<ul>
<li>   并发垃圾收集信息</li>
<li>   持久代并发收集次数</li>
<li>   传统GC信息</li>
<li>   花在年轻代和年老代回收上的时间比例 减少年轻代和年老代花费的时间, 一般会提高应用的效率</li>
</ul>
<p>吞吐量优先的应用:  一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代. 原因是, 这样可以尽可能回收掉大部分短期对象, 减少中期的对象, 而年老代尽存放长期存活对象.</p>
</li>
<li><p>较小堆引起的碎片问题</p>
<p>因为年老代的并发收集器使用标记、清除算法, 所以不会对堆进行压缩. 当收集器回收时, 他会把相邻的空间进行合并, 这样可以分配给较大的对象. 但是, 当堆空间 较小时, 运行一段时间以后, 就会出现“碎片”, 如果并发收集器找不到足够的空间, 那么并发收集器将会停止, 然后使用传统的标记、清除方式进行回收. 如果出 现“碎片”, 可能需要进行如下配置:  </p>
<ul>
<li>-XX:+UseCMSCompactAtFullCollection:  使用并发收集器时, 开启对年老代的压缩.</li>
<li>-XX:CMSFullGCsBeforeCompaction=0:  上面配置开启的情况下, 这里设置多少次Full GC后, 对年老代进行压缩</li>
</ul>
</li>
</ol>
<h2 id="常见配置参数汇总"><a href="#常见配置参数汇总" class="headerlink" title="常见配置参数汇总"></a>常见配置参数汇总</h2><ol>
<li>堆设置<ul>
<li>-Xms:初始堆大小</li>
<li>-Xmx:最大堆大小</li>
<li>-XX:NewSize=n:设置年轻代大小</li>
<li>-XX:NewRatio=n:设置年轻代和年老代的比值. 如:为3, 表示年轻代与年老代比值为1:  3, 年轻代占整个年轻代年老代和的1/4</li>
<li>-XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值. 注意Survivor区有两个. 如:  3, 表示Eden:  Survivor=3:  2, 一个Survivor区占整个年轻代的1/5</li>
<li>-XX:MaxPermSize=n:设置持久代大小</li>
</ul>
</li>
<li>收集器设置<ul>
<li>-XX:+UseSerialGC:设置串行收集器</li>
<li>-XX:+UseParallelGC:设置并行收集器</li>
<li>-XX:+UseParalledlOldGC:设置并行年老代收集器</li>
<li>-XX:+UseConcMarkSweepGC:设置并发收集器</li>
</ul>
</li>
<li>垃圾回收统计信息<ul>
<li>-XX:+PrintGC</li>
<li>-XX:+Printetails</li>
<li>-XX:+PrintGCTimeStamps</li>
<li>-Xloggc:filename</li>
</ul>
</li>
<li>并行收集器设置<ul>
<li>-XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数. 并行收集线程数.</li>
<li>-XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间</li>
<li>-XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比. 公式为1/(1+n)</li>
</ul>
</li>
<li>并发收集器设置<ul>
<li>-XX:+CMSIncrementalMode:设置为增量模式. 适用于单CPU情况.</li>
<li>-XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时, 使用的CPU数. 并行收集线程数.</li>
</ul>
</li>
</ol>
<h1 id="类加载-1"><a href="#类加载-1" class="headerlink" title="类加载"></a>类加载</h1><h2 id="类的加载阶段"><a href="#类的加载阶段" class="headerlink" title="类的加载阶段"></a>类的加载阶段</h2><p>类加载分为装载、链接、初始化三步.</p>
<ol>
<li><p>装载</p>
<p>通过类的全限定名和ClassLoader加载类, 主要是将指定的.Class文件加载至JVM. 当类被加载以后, 在JVM内部就以“类的全限定名+ClassLoader实例ID”来标明类.</p>
<p>在内存中, ClassLoader实例和类的实例都位于堆中, 它们的类信息都位于方法区.</p>
<p>装载过程采用了一种被称为“双亲委派模型（Parent Delegation Model）”的方式, 当一个ClassLoader要加载类时, 它会先请求它的双亲ClassLoader（其实这里只有两个ClassLoader, 所以称为父ClassLoader可能更容易理解）加载类, 而它的双亲ClassLoader会继续把加载请求提交再上一级的ClassLoader, 直到启动类加载器. 只有其双亲ClassLoader无法加载指定的类时, 它才会自己加载类.</p>
<p>双亲委派模型是JVM的第一道安全防线, 它保证了类的安全加载, 这里同时依赖了类加载器隔离的原理:  不同类加载器加载的类之间是无法直接交互的, 即使是同一个类, 被不同的ClassLoader加载, 它们也无法感知到彼此的存在. 这样即使有恶意的类冒充自己在核心包（例如java.lang）下, 由于它无法被启动类加载器加载, 也造成不了危害.</p>
<p>由此也可见, 如果用户自定义了类加载器, 那就必须自己保障类加载过程中的安全.</p>
</li>
<li><p>链接</p>
<p>链接的任务是把二进制的类型信息合并到JVM运行时状态中去.<br>链接分为以下三步:  </p>
</li>
</ol>
<ul>
<li>验证:  校验.Class文件的正确性, 确保该文件是符合规范定义的, 并且适合当前JVM使用.</li>
<li>准备:  为类分配内存, 同时初始化类中的静态变量赋值为默认值.</li>
<li>解析（可选）:  主要是把类的常量池中的符号引用解析为直接引用, 这一步可以在用到相应的引用时再解析.</li>
</ul>
<ol>
<li>初始化</li>
</ol>
<p>初始化类中的静态变量, 并执行类中的static代码、构造函数.</p>
<p>JVM规范严格定义了何时需要对类进行初始化:  </p>
<ul>
<li>通过new关键字、反射、clone、反序列化机制实例化对象时.</li>
<li>调用类的静态方法时.</li>
<li>使用类的静态字段或对其赋值时.</li>
<li>通过反射调用类的方法时.</li>
<li>初始化该类的子类时（初始化子类前其父类必须已经被初始化）.</li>
<li>JVM启动时被标记为启动类的类（简单理解为具有main方法的类）.</li>
</ul>
<h2 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h2><p><img src="/images/java/JVM/ClassLoader-01.png"></p>
<p>ClassLoader的分类:  </p>
<p>1）BootstrapClassLoader（启动类加载器）<br>　　负责加载$JAVA_HOME中jre/lib/rt.jar里所有的Class，加载System.getProperty(“sun.boot.Class.path”)所指定的路径或jar。<br>2）ExtensionClassLoader（标准扩展类加载器）<br>　　负责加载java平台中扩展功能的一些jar包，包括<code>$JAVA_HOME</code>中jre/lib/*.jar或-Djava.ext.dirs指定目录下的jar包。<br>   在System.getProperty(“java.ext.dirs”)所指定的路径或jar。<br>3）AppClassLoader（系统类加载器）<br>　　负责记载Classpath中指定的jar包及目录中Class<br>4）CustomClassLoader（自定义加载器）<br>　　属于应用程序根据自身需要自定义的ClassLoader，如tomcat、jboss都会根据j2ee规范自行实现。</p>
<h3 id="类加载器的顺序-双亲委派"><a href="#类加载器的顺序-双亲委派" class="headerlink" title="类加载器的顺序: 双亲委派"></a>类加载器的顺序: 双亲委派</h3><p>当一个ClassLoader要加载类时，它会先请求它的双亲ClassLoader（其实这里只有两个ClassLoader，所以称为父ClassLoader可能更容易理解）加载类，而它的双亲ClassLoader会继续把加载请求提交再上一级的ClassLoader，直到启动类加载器。只有其双亲ClassLoader无法加载指定的类时，它才会自己加载类。</p>
<p>双亲委派模型是JVM的第一道安全防线，它保证了类的安全加载，这里同时依赖了类加载器隔离的原理：不同类加载器加载的类之间是无法直接交互的，即使是同一个类，被不同的ClassLoader加载，它们也无法感知到彼此的存在。这样即使有恶意的类冒充自己在核心包（例如java.lang）下，由于它无法被启动类加载器加载，也造成不了危害。</p>
<p>由此也可见，如果用户自定义了类加载器，那就必须自己保障类加载过程中的安全。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a href="http://www.jianshu.com/p/7ebbe102c1ae">深入理解JVM 1</a></li>
<li><a href="http://blog.csdn.net/anders_zhuo/article/details/47776569">JVM调优总结 </a></li>
<li><a href="https://yq.aliyun.com/articles/26594">浅析Java虚拟机结构与机制 </a></li>
<li><a href="http://blog.csdn.net/ochangwen/article/details/51407574"> 深入理解JVM03–垃圾收集算法</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>GC</title>
    <url>/Java/jvm/jvm2/</url>
    <content><![CDATA[<p>heap分代的目的是，应对不同生命周期的对象，大部分对象是朝生夕死的，也用一些常量是长期占用内存的，如数据值的枚举<br>动态调整：</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Java JPA</title>
    <url>/Java/lib/Jpa/</url>
    <content><![CDATA[<h1 id="Jpa"><a href="#Jpa" class="headerlink" title="Jpa"></a>Jpa</h1><h2 id="创建时间-更新时间"><a href="#创建时间-更新时间" class="headerlink" title="创建时间 更新时间"></a>创建时间 更新时间</h2><p>1.实体类加注解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 创建时间</span><br><span class="line"> *&#x2F;</span><br><span class="line">@CreatedDate</span><br><span class="line">@Column(name &#x3D; &quot;create_time&quot;)</span><br><span class="line">private Date createTime;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 修改时间</span><br><span class="line"> *&#x2F;</span><br><span class="line">@LastModifiedDate</span><br><span class="line">@Column(name &#x3D; &quot;modify_time&quot;)</span><br><span class="line">private Date modifyTime;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2.实体类头加注解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@EntityListeners(AuditingEntityListener.class)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>3.SpringBoot启动类加注解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@EnableJpaAuditing</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>另外数据库添加相应控制也可以：<br>createTime ： CURRENT_TIMESTAMP<br>modifyTime ： CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>log4j</title>
    <url>/Java/log/log4j/</url>
    <content><![CDATA[<p>log4j 是目前最常见的日志系统之一，本文主要总结log4j的使用和配置.</p>
<h1 id="log4j的组件"><a href="#log4j的组件" class="headerlink" title="log4j的组件"></a>log4j的组件</h1><ul>
<li>logger</li>
<li>appender</li>
<li>level</li>
<li>layout</li>
</ul>
<h2 id="logger-记录器-打印事件"><a href="#logger-记录器-打印事件" class="headerlink" title="logger-记录器 打印事件"></a>logger-记录器 打印事件</h2><p>logger 可以理解为日志记录器，它有name、appender和level等属性.<br>当调用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Logger logger = LoggerFactory.getLogger(AClass.class);</span><br></pre></td></tr></table></figure>
<p>时，<code>logger</code>变量即为名称为<code>AClass</code>类的全名的logger.</p>
<p>如果使用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Logger logger = LoggerFactory.getLogger(<span class="string">&quot;myRedo&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>logger变量即为名称为myRedo的logger</p>
<ol>
<li>所有的logger的根都是rootLogger</li>
<li>一般情况下，取类名作为logger的名称. 父子关系遵从Java package的方法</li>
<li>子logger默认继承父logger的所有的配置. 子logger的配置会覆盖父logger的配置</li>
<li>logger的名称可以为任意字符串</li>
<li>log4j可以使用多种配置方式: properties文件、xml文件和Java代码</li>
<li>使用Java代码配置时，可以指定为基本配置: <code>BasicConfigurator.configure();</code></li>
<li>可以指定特定包的log<br>样例: 使用代码的方式配置特定包的logger<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">  Logger.getRootLogger().setLevel(Level.WARN);</span><br><span class="line">Logger.getLogger(<span class="string">&quot;cd.itcast.core&quot;</span>).setLevel(Level.DEBUG);</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="appender-打印目的地"><a href="#appender-打印目的地" class="headerlink" title="appender 打印目的地"></a>appender 打印目的地</h2><p>log4j定义了多种appender:</p>
<ul>
<li>org.apache.log4j.ConsoleAppender(控制台)</li>
<li>org.apache.log4j.FileAppender(文件)</li>
<li>org.apache.log4j.DailyRollingFileAppender(每天产生一个日志文件)</li>
<li>org.apache.log4j.RollingFileAppender(文件大小到达指定尺寸的时候产生一个新的文件)</li>
<li>org.apache.log4j.WriterAppender(将日志信息以流格式发送到任意指定的地方)</li>
<li>org.apache.log4j.jdbc.JDBCAppender(将日志信息写入数据库)</li>
</ul>
<p>在properties文件中配置</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">log4j.appender.&lt;appenderName&gt;</span> = <span class="string">fully.qualified.name.of.appender.class</span></span><br></pre></td></tr></table></figure>
<p>Appender类的属性</p>
<h3 id="ConsoleAppender"><a href="#ConsoleAppender" class="headerlink" title="ConsoleAppender"></a>ConsoleAppender</h3><p>   Threshold=DEBUG :指定日志消息的输出最低层次.<br>   ImmediateFlush=true :默认值是true,意谓着所有的消息都会被立即输出.<br>   Target=System.err :默认情况下是:System.out,指定输出控制台</p>
<h3 id="FileAppender"><a href="#FileAppender" class="headerlink" title="FileAppender"></a>FileAppender</h3><p>   Threshold=DEBUF    :指定日志消息的输出最低层次.<br>   ImmediateFlush=true   :默认值是true,意谓着所有的消息都会被立即输出.<br>   File=mylog.txt   :指定消息输出到mylog.txt文件.<br>   Append=false   :默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容.</p>
<h3 id="RollingFileAppender"><a href="#RollingFileAppender" class="headerlink" title="RollingFileAppender"></a>RollingFileAppender</h3><p>   Threshold=DEBUG    :指定日志消息的输出最低层次.<br>   ImmediateFlush=true    :默认值是true,意谓着所有的消息都会被立即输出.<br>   File=mylog.txt    :指定消息输出到mylog.txt文件.<br>   Append=false    :默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容.<br>   MaxFileSize=100KB    : 后缀可以是KB, MB 或者是 GB. 在日志文件到达该大小时，将会自动滚动，即将原来的内容移到mylog.log.1文件.<br>   MaxBackupIndex=2   :指定可以产生的滚动文件的最大数.<br>   log4j.appender.A1.layout.ConversionPattern=%-4r %-5p %d{yyyy-MM-dd HH:mm:ssS} %c %m%n</p>
<h3 id="DailyRollingFileAppender"><a href="#DailyRollingFileAppender" class="headerlink" title="DailyRollingFileAppender"></a>DailyRollingFileAppender</h3><p>  DatePattern<br>  layout<br>  Encoding<br>  MaxBackupIndex</p>
<h2 id="level-输出级别"><a href="#level-输出级别" class="headerlink" title="level 输出级别"></a>level 输出级别</h2><p>ERROR、WARN、INFO、DEBUG</p>
<ul>
<li>ERROR 为严重错误 主要是程序的错误</li>
<li>WARN 为一般警告，比如session丢失</li>
<li>INFO 为一般要显示的信息，比如登录登出</li>
<li>DEBUG 为程序的调试信息</li>
</ul>
<h2 id="layout"><a href="#layout" class="headerlink" title="layout"></a>layout</h2><p>-X号: X信息输出时左对齐；</p>
<p>%p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL,<br>%d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如:%d{yyy MMM dd HH:mm:ss,SSS}，输出类似:2002年10月18日 22:10:28，921<br>%r: 输出自应用启动到输出该log信息耗费的毫秒数<br>%c: 输出日志信息所属的类目，通常就是所在类的全名<br>%t: 输出产生该日志事件的线程名<br>%l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数. 举例:Testlog4.main (TestLog4.java:10)<br>%x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像java servlets这样的多客户多线程的应用中.<br>%%: 输出一个”%”字符<br>%F: 输出日志消息产生时所在的文件名称<br>%L: 输出代码中的行号<br>%m: 输出代码中指定的消息,产生的日志具体信息<br>%n: 输出一个回车换行符，Windows平台为”/r/n”，Unix平台为”/n”输出日志信息换行</p>
<p>日志信息格式中几个符号所代表的含义:<br>可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式. 如:</p>
<ol>
<li>  %20c:指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，默认的情况下右对齐.</li>
<li>  %-20c:指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，”-“号指定左对齐.</li>
<li>  %.30c:指定输出category的名称，最大的宽度是30，如果category的名称大于30的话，就会将左边多出的字符截掉，但小于30的话也不会有空格.</li>
<li>  %20.30c:如果category的名称小于20就补空格，并且右对齐，如果其名称长于30字符，就从左边较远输出的字符截掉.</li>
</ol>
<h2 id="log4j性能优化"><a href="#log4j性能优化" class="headerlink" title="log4j性能优化"></a>log4j性能优化</h2><ol>
<li>为了避免多次打开文件引起资源的浪费，log4j当打开文件或连接数据库后，会始终保持着连接，直到引用关闭.<br>因此， 当引用运行过程中，删除文件. log4j不会再次创建该文件.</li>
<li>logger文件是懒生成模式:当打印时，判断是否需要创建新文件</li>
</ol>
<h1 id="典型应用"><a href="#典型应用" class="headerlink" title="典型应用"></a>典型应用</h1><h2 id="配置非类名logger及代码获取logger的信息"><a href="#配置非类名logger及代码获取logger的信息" class="headerlink" title="配置非类名logger及代码获取logger的信息"></a>配置非类名logger及代码获取logger的信息</h2><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">###################</span></span><br><span class="line"><span class="comment"># rootLogger的级别为INFO，appender为terminal01和allToFile</span></span><br><span class="line"><span class="comment">###################</span></span><br><span class="line"><span class="meta">log4j.rootLogger</span>=<span class="string">INFO,terminal01,allToFile</span></span><br><span class="line"><span class="comment">###################</span></span><br><span class="line"><span class="comment"># Console Appender</span></span><br><span class="line"><span class="comment">###################</span></span><br><span class="line"><span class="meta">log4j.appender.terminal01</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="meta">log4j.appender.terminal01.Target</span>=<span class="string">System.out</span></span><br><span class="line"><span class="meta">log4j.appender.terminal01.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="meta">log4j.appender.terminal01.layout.ConversionPattern</span>=<span class="string">%d&#123;yyyy-MM-dd HH:mm:ss.sss&#125;,%c,%-p,%m %n</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="comment"># Rolling File</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="meta">log4j.appender.allToFile</span>=<span class="string">org.apache.log4j.DailyRollingFileAppender</span></span><br><span class="line"><span class="meta">log4j.appender.allToFile.File</span>=<span class="string">/data/logs/blog-all.log</span></span><br><span class="line"><span class="meta">log4j.appender.allToFile.Append</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">log4j.appender.allToFile.MaxFileSize</span>=<span class="string">100MB</span></span><br><span class="line"><span class="meta">log4j.appender.allToFile.MaxBackupIndex</span>=<span class="string">7</span></span><br><span class="line"><span class="meta">log4j.appender.allToFile.Encoding</span>=<span class="string">UTF-8  </span></span><br><span class="line"><span class="meta">log4j.appender.allToFile.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="meta">log4j.appender.allToFile.layout.ConversionPattern</span>=<span class="string">%d&#123;yyyy-MM-dd HH:mm:ss.sss&#125;,%c,%-p,%m %n</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="comment"># 指定某个包的logger</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="meta">log4j.logger.com.abc.engin</span>=<span class="string">INFO,engin</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="comment"># appender engin</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="meta">log4j.additivity.engin</span>=<span class="string">false</span></span><br><span class="line"><span class="comment">## 是否追加到root appender中</span></span><br><span class="line"><span class="meta">log4j.appender.engin</span>=<span class="string">org.apache.log4j.DailyRollingFileAppender</span></span><br><span class="line"><span class="meta">log4j.appender.engin.File</span>=<span class="string">/data/logs/engin.log</span></span><br><span class="line"><span class="meta">log4j.appender.engin.Append</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">log4j.appender.engin.MaxFileSize</span>=<span class="string">500MB</span></span><br><span class="line"><span class="meta">log4j.appender.engin.MaxBackupIndex</span>=<span class="string">7</span></span><br><span class="line"><span class="meta">log4j.appender.engin.Encoding</span>=<span class="string">UTF-8</span></span><br><span class="line"><span class="meta">log4j.appender.engin.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="meta">log4j.appender.engin.layout.ConversionPattern</span>=<span class="string">%d&#123;yyyy-MM-dd HH:mm:ss.sss&#125;,%c,%-p,%m %n</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="comment"># 非类名logger</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="meta">log4j.logger.error</span>=<span class="string">ERROR,errorAppender</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="comment"># appender errorAppender</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="meta">log4j.appender.errorAppender</span>=<span class="string">org.apache.log4j.DailyRollingFileAppender</span></span><br><span class="line"><span class="meta">log4j.appender.errorAppender.File</span>=<span class="string">/data/logs/blog-error.log</span></span><br><span class="line"><span class="meta">log4j.appender.errorAppender.Append</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">log4j.appender.errorAppender.MaxFileSize</span>=<span class="string">500MB</span></span><br><span class="line"><span class="meta">log4j.appender.errorAppender.MaxBackupIndex</span>=<span class="string">7</span></span><br><span class="line"><span class="meta">log4j.appender.errorAppender.Encoding</span>=<span class="string">UTF-8</span></span><br><span class="line"><span class="meta">log4j.appender.errorAppender.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="meta">log4j.appender.errorAppender.layout.ConversionPattern</span>=<span class="string">%d&#123;yyyy-MM-dd HH:mm:ss.sss&#125;,%c,%-p,%m %n</span></span><br></pre></td></tr></table></figure>
<h3 id="打印"><a href="#打印" class="headerlink" title="打印"></a>打印</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Logger logger = LoggerFactory.getLogger(AClass.class);</span><br><span class="line">logger.error(<span class="string">&quot;this is an error log&quot;</span>);</span><br><span class="line"><span class="comment">// 获取名称为error的logger</span></span><br><span class="line">Logger loggerError = LoggerFactory.getLogger(<span class="string">&quot;error&quot;</span>);</span><br><span class="line">loggerError.error(<span class="string">&quot;this is an error log&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="从Java代码获取logger的配置信息"><a href="#从Java代码获取logger的配置信息" class="headerlink" title="从Java代码获取logger的配置信息"></a>从Java代码获取logger的配置信息</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">org.apache.log4j.Logger loggerError = org.apache.log4j.Logger.getLogger(<span class="string">&quot;error&quot;</span>);</span><br><span class="line">Appender appender = loggerError.getAppender(<span class="string">&quot;errorAppender&quot;</span>);</span><br><span class="line">DailyRollingFileAppender errorAppender = (DailyRollingFileAppender) appender;</span><br><span class="line">String fileName = errorAppender.getFile();</span><br><span class="line">String datePattern = errorAppender.getDatePattern();</span><br></pre></td></tr></table></figure>

<h2 id="每个小时打印一个文件"><a href="#每个小时打印一个文件" class="headerlink" title="每个小时打印一个文件"></a>每个小时打印一个文件</h2><h3 id="配置文件的方式"><a href="#配置文件的方式" class="headerlink" title="配置文件的方式"></a>配置文件的方式</h3><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">log4j.logger.redo</span>=<span class="string">ERROR,redoLogger</span></span><br><span class="line"><span class="comment"># appender for redo logger</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger</span>=<span class="string">org.apache.log4j.DailyRollingFileAppender</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger.File</span>=<span class="string">/data/logs/my-redo.log</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger.Append</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger.MaxFileSize</span>=<span class="string">500MB</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger.MaxBackupIndex</span>=<span class="string">7</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger.Encoding</span>=<span class="string">UTF-8</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger.layout.ConversionPattern</span>=<span class="string">%d&#123;yyyy-MM-dd HH:mm:ss.sss&#125;,%c,%-p,%m \n</span></span><br><span class="line"><span class="meta">log4j.appender.redoLogger.DatePattern</span>=<span class="string">&#x27;.&#x27;yyyy-MM-dd-HH</span></span><br></pre></td></tr></table></figure>
<h3 id="Java代码的方式"><a href="#Java代码的方式" class="headerlink" title="Java代码的方式"></a>Java代码的方式</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DailyRollingFileAppender redoAppender = <span class="keyword">new</span> DailyRollingFileAppender();</span><br><span class="line">redoAppender.setDatePattern(<span class="string">&quot;&#x27;.&#x27;yyyy-MM-dd-HH&quot;</span>);</span><br><span class="line"></span><br><span class="line">Logger loggerRedo = Logger.getLogger(<span class="string">&quot;redo&quot;</span>);</span><br><span class="line">loggerRedo.addAppender(appender);</span><br></pre></td></tr></table></figure>
<p>使用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger redoLogger = LoggerFactory.getLogger(<span class="string">&quot;redo&quot;</span>);</span><br><span class="line">...</span><br><span class="line">redoLogger.error(<span class="string">&quot;something is wrong&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>下面的列表<br>The following list shows all the date patterns which have defined by log4j,</p>
<table>
<thead>
<tr>
<th align="left">name</th>
<th align="left">DatePattern</th>
<th align="left">sample</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Minutely</td>
<td align="left"><code>&#39;.&#39;yyyy-MM-dd-HH-mm</code></td>
<td align="left">application.log.2013-02-28-13-54</td>
</tr>
<tr>
<td align="left">Hourly</td>
<td align="left"><code>&#39;.&#39;yyyy-MM-dd-HH</code></td>
<td align="left">application.log.2013-02-28-13</td>
</tr>
<tr>
<td align="left">Half-daily</td>
<td align="left"><code>&#39;.&#39;yyyy-MM-dd-a</code></td>
<td align="left">application.log.2013-02-28-AM    app.log.2013-02-28-PM</td>
</tr>
<tr>
<td align="left">Daily</td>
<td align="left"><code>&#39;.&#39;yyyy-MM-dd</code></td>
<td align="left">application.log.2013-02-28</td>
</tr>
<tr>
<td align="left">Weekly</td>
<td align="left"><code>&#39;.&#39;yyyy-ww</code></td>
<td align="left">application.log.2013-07 app.log.2013-08</td>
</tr>
<tr>
<td align="left">Monthly</td>
<td align="left"><code>&#39;.&#39;yyyy-MM</code></td>
<td align="left">application.log.2013-01 app.log.2013-02</td>
</tr>
</tbody></table>
<h2 id="自定义-writerAppender"><a href="#自定义-writerAppender" class="headerlink" title="自定义 writerAppender"></a>自定义 writerAppender</h2><p>log4j将日志输出到swing控件</p>
<h3 id="自定义-writer"><a href="#自定义-writer" class="headerlink" title="自定义 writer"></a>自定义 writer</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogWriter</span> <span class="keyword">extends</span> <span class="title">Writer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> LogListModel model;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LogWriter</span><span class="params">(LogListModel model)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.model = model;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">int</span> c)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        model.addElement(<span class="string">&quot;&quot;</span> + c);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">char</span>[] cbuf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        model.addElement(<span class="keyword">new</span> String(cbuf));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String str)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        model.addElement(str);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String str, <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        model.addElement(str);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">char</span>[] cbuf, <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        model.addElement(<span class="keyword">new</span> String(cbuf));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flush</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="创建logger与Swing组件"><a href="#创建logger与Swing组件" class="headerlink" title="创建logger与Swing组件"></a>创建logger与Swing组件</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> Logger loggerA = LoggerFactory.getLogger(<span class="string">&quot;A1&quot;</span>);</span><br><span class="line"><span class="keyword">private</span> LogListModel logListModel;</span><br><span class="line"></span><br><span class="line">logListModel = <span class="keyword">new</span> LogListModel();</span><br><span class="line">JList ml = <span class="keyword">new</span> JList(logListModel);</span><br><span class="line"></span><br><span class="line">WriterAppender writeappender = <span class="keyword">new</span> WriterAppender(<span class="keyword">new</span> SimpleLayout(), <span class="keyword">new</span> LogWriter(logListModel));</span><br><span class="line">writeappender.setName(<span class="string">&quot;A1&quot;</span>);</span><br><span class="line">writeappender.setImmediateFlush(<span class="keyword">true</span>);</span><br><span class="line">Logger.getRootLogger().addAppender(writeappender);</span><br><span class="line">Logger.getRootLogger().setLevel(Level.INFO);</span><br></pre></td></tr></table></figure>







<p>-</p>
<ol>
<li><a href="https://stackoverflow.com/questions/1711423/how-to-rotate-log-files-based-on-time-rather-than-size-in-log4j">How to rotate log files based on time rather than size in Log4j?
</a></li>
<li><a href="http://www.cnblogs.com/ArtsCrafts/archive/2013/06/07/log4j5.html">Log4j详细介绍(五)—-输出地Appender</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>log4j</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker构建Java调试环境</title>
    <url>/Java/metric/00_docker%E6%9E%84%E5%BB%BAJava%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="Docker构建Java调试环境"><a href="#Docker构建Java调试环境" class="headerlink" title="Docker构建Java调试环境"></a>Docker构建Java调试环境</h1><p><a href="https://c.163yun.com/hub#/home">网易镜像仓库</a></p>
<p>Docker动态给容器Container暴露端口</p>
<p><a href="https://blog.csdn.net/lsziri/article/details/69396990">https://blog.csdn.net/lsziri/article/details/69396990</a></p>
<h2 id="Docker-container"><a href="#Docker-container" class="headerlink" title="Docker container"></a>Docker container</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull hub.c.163.com/public/centos:6.7-tools</span><br><span class="line">docker tag hub.c.163.com/public/centos:6.7-tools  centos</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 增加参数解决不能获取ptrace的问题</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> https://blog.csdn.net/russle/article/details/99708261</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这种不可用 docker run --name centos-one --cap-add=SYS_PTRACE  -d -P centos</span></span><br><span class="line">docker run --cap-add=SYS_PTRACE --security-opt seccomp:unconfined --name centos-two  -d -P centos</span><br><span class="line">➜  ~ docker container ls -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS                   NAMES</span><br><span class="line">3ae403bf463c        centos              &quot;/usr/bin/supervisord&quot;   About a minute ago   Up About a minute   0.0.0.0:32772-&gt;22/tcp   centos-one</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入容器</span></span><br><span class="line">➜  ~ docker exec -it centos-one su deploy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="Java环境"><a href="#Java环境" class="headerlink" title="Java环境"></a>Java环境</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装全部 yum install -y java-1.8.0-openjdk*</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 只安装需要的</span></span><br><span class="line">yum install -y java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel.x86_64</span><br></pre></td></tr></table></figure>
<p> install git</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install gcc gcc-c++ autoconf make automake -y</span><br><span class="line">yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel -y</span><br><span class="line">yum install perl docbook2X texinfo sgml2xml openjade perl-ExtUtils-MakeMaker -y</span><br><span class="line">yum install asciidoc xmlto cpio expat-devel gettext-devel  -y</span><br><span class="line">yum install perl-ExtUtils-MakeMaker</span><br><span class="line"></span><br><span class="line">yum install -y tk zlib-devel openssl-devel perl cpio expat-devel gettext-devel  asciidoc xmlto autoconf gcc</span><br><span class="line">wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.9.5.tar.gz</span><br><span class="line"></span><br><span class="line">tar zxvf git-2.9.5.tar.gz</span><br><span class="line">cd git-2.9.5</span><br><span class="line"></span><br><span class="line">make configure</span><br><span class="line">./configure --prefix=/usr/local/git --with-iconv=/usr/local/libiconv</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置安装路径</span></span><br><span class="line">make all doc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 编译</span></span><br><span class="line">make install install-doc install-html</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装</span></span><br><span class="line"></span><br><span class="line">修改环境变量</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> -e <span class="string">&quot;# git\nexport PATH=/usr/local/git/bin:\$PATH&quot;</span>&gt; /etc/profile.d/git.sh</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cat /etc/profile.d/git.sh</span></span><br><span class="line">\# git        // 文件内容</span><br><span class="line">export PATH=/usr/local/git/bin:$PATH</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">source</span> /etc/profile</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>安装oh-my-zsh</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">yum install -y zsh</span><br><span class="line">chsh -s /bin/zsh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>编辑~/.zshrc文件</p>
<p>找到plugins=(git)这一行，然后再添加autosuggestions，最后为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plugins&#x3D;(git zsh-autosuggestions)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container cp target/demo-0.0.1-SNAPSHOT.jar centos-one:/home/deploy/</span><br></pre></td></tr></table></figure>



<h3 id="增加端口，做远程debug"><a href="#增加端口，做远程debug" class="headerlink" title="增加端口，做远程debug"></a>增加端口，做远程debug</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker commit 95c6d4eed5f0 jdk8-debug</span><br><span class="line"></span><br><span class="line">docker run --cap-add=SYS_PTRACE --security-opt seccomp:unconfined --name centos-jdk8-debug  -d -p 8000:8000 -p  8001:8001 -p 8002:8002  -P jdk8-debug</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker exec -it centos-jdk8-debug zsh</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
      </tags>
  </entry>
  <entry>
    <title>Java性能调优</title>
    <url>/Java/metric/01_tuner/</url>
    <content><![CDATA[<h1 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h1><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>jhat<br>vmstat</p>
<h2 id="测试样例"><a href="#测试样例" class="headerlink" title="测试样例"></a>测试样例</h2><p>新docker container，全新的系统，以纯净的系统Centos为例</p>
<h3 id="安装java"><a href="#安装java" class="headerlink" title="安装java"></a>安装java</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装java8</span></span><br><span class="line">[root@centos ~]# yum install -y java-1.8.0-openjdk*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建deploy用户，用于折腾</span></span><br><span class="line">[root@centos ~]# useradd deploy</span><br><span class="line">[root@centos ~]# su deploy</span><br><span class="line">[root@centos ~]# cd</span><br></pre></td></tr></table></figure>


<h3 id="创建工作目录"><a href="#创建工作目录" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建并切换到工作目录</span></span><br><span class="line">[deploy@centos ~]$ mkdir -p lk-optimization</span><br><span class="line">[deploy@centos ~]$ cd !$</span><br></pre></td></tr></table></figure>
<p>创建package，用于存放java源文件和编译后的class文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[deploy@centos ~]$ mkdir -p src/com/lk/optimization/demo target</span><br><span class="line">[deploy@centos ~]$ vim !$/DemoTest.java</span><br></pre></td></tr></table></figure>
<h3 id="新建Java文件"><a href="#新建Java文件" class="headerlink" title="新建Java文件"></a>新建Java文件</h3><p>//        Thread thread = Thread.currentThread();</p>
<p>//        System.out.println(thread.getName());<br>//        thread.join();<br>        System.out.println(“join over”);</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lk.optimization.demo;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoTest</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] atgs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">		<span class="keyword">new</span> Handler().doHandle();</span><br><span class="line">		Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">				System.out.println(<span class="keyword">this</span>.getName() + <span class="string">&quot; is shutting down ....&quot;</span>);</span><br><span class="line">				&#125;</span><br><span class="line">				&#125;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doHandle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">			String workerName=<span class="string">&quot;worker-&quot;</span>+(i+<span class="number">1</span>);</span><br><span class="line">			<span class="keyword">new</span> Thread(<span class="keyword">new</span> Worker(workerName), <span class="string">&quot;handler-&quot;</span> + i).start();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> String workerName;</span><br><span class="line">	<span class="keyword">private</span> List&lt;String&gt; list;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Worker</span><span class="params">(String workerName)</span></span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.workerName=workerName;</span><br><span class="line">		<span class="keyword">this</span>.list=<span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">1000</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">			System.out.println(workerName+<span class="string">&quot; start!&quot;</span>);</span><br><span class="line">			<span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">				<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">100</span>;i++)&#123;</span><br><span class="line">					list.add(<span class="string">&quot;&quot;</span>+i);</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">if</span>(list.size()&gt;<span class="number">1000</span>)&#123;</span><br><span class="line">					list.clear();</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">try</span> &#123;</span><br><span class="line">					Thread.sleep(<span class="number">100</span>);</span><br><span class="line">					System.out.println(workerName+<span class="string">&quot;: sleep over&quot;</span>);</span><br><span class="line">				&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">					e.printStackTrace();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[deploy@centos ~]$ find src -name &quot;*.java&quot; | xargs javac -d target</span><br><span class="line"></span><br><span class="line">[deploy@centos ~]$ tree</span><br><span class="line">.</span><br><span class="line">├── src</span><br><span class="line">│   └── com</span><br><span class="line">│       └── lk</span><br><span class="line">│           └── optimization</span><br><span class="line">│               └── demo</span><br><span class="line">│                   └── DemoTest.java</span><br><span class="line">└── target</span><br><span class="line">    └── com</span><br><span class="line">        └── lk</span><br><span class="line">            └── optimization</span><br><span class="line">                └── demo</span><br><span class="line">                    ├── DemoTest$1.class</span><br><span class="line">                    ├── DemoTest.class</span><br><span class="line">                    ├── Handler.class</span><br><span class="line">                    └── Worker.class</span><br><span class="line"></span><br><span class="line">10 directories, 5 files</span><br></pre></td></tr></table></figure>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[deploy@centos ~]$ nohup java -cp target  -Xcomp -XX:MaxNewSize=1000000  -XX:MaxHeapSize=2000000 com.lk.optimization.demo.DemoTest &amp;</span><br><span class="line">main</span><br></pre></td></tr></table></figure>


<h2 id="ps-查看进程和线程信息"><a href="#ps-查看进程和线程信息" class="headerlink" title="ps 查看进程和线程信息"></a>ps 查看进程和线程信息</h2><p>ps命令选项:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">********* simple selection *********  ********* selection by list *********</span><br><span class="line">-A all processes                      -C by command name</span><br><span class="line">-N negate selection                   -G by real group ID (supports names)</span><br><span class="line">-a all w/ tty except session leaders  -U by real user ID (supports names)</span><br><span class="line">-d all except session leaders         -g by session OR by effective group name</span><br><span class="line">-e all processes                      -p by process ID</span><br><span class="line">T  all processes on this terminal     -s processes in the sessions given</span><br><span class="line">a  all w/ tty, including other users  -t by tty</span><br><span class="line">g  OBSOLETE -- DO NOT USE             -u by effective user ID (supports names)</span><br><span class="line">r  only running processes             U  processes for specified users</span><br><span class="line">x  processes w/o controlling ttys     t  by tty</span><br><span class="line">*********** output format **********  *********** long options ***********</span><br><span class="line">-o,o user-defined  -f full            --Group --User --pid --cols --ppid</span><br><span class="line">-j,j job control   s  signal          --group --user --sid --rows --info</span><br><span class="line">-O,O preloaded -o  v  virtual memory  --cumulative --format --deselect</span><br><span class="line">-l,l long          u  user-oriented   --sort --tty --forest --version</span><br><span class="line">-F   extra full    X  registers       --heading --no-heading --context</span><br><span class="line">                         ********* misc options *********</span><br><span class="line">-V,V  show version      L  list format codes  f  ASCII art forest</span><br><span class="line">-m,m,-L,-T,H  threads   S  children in sum    -y change -l format</span><br><span class="line">-M,Z  security data     c  true command name  -c scheduling class</span><br><span class="line">-w,w  wide output       n  numeric WCHAN,UID  -H process hierarchy</span><br></pre></td></tr></table></figure>


<p>root用户查看进程信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos ~]# ps -ef  | grep -v ps</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 13:16 ?        00:00:00 /usr/sbin/sshd -D</span><br><span class="line">root        14     0  0 13:23 pts/0    00:00:00 /bin/bash</span><br><span class="line">root       421     1  0 13:58 ?        00:00:00 sshd: root@pts/1</span><br><span class="line">root       423   421  0 13:58 pts/1    00:00:00 -bash</span><br><span class="line">root       461     1  0 14:15 ?        00:00:00 sshd: root@pts/2</span><br><span class="line">root       463   461  0 14:15 pts/2    00:00:00 -bash</span><br><span class="line">root       519     1  0 14:16 ?        00:00:00 sshd: root@pts/3</span><br><span class="line">root       521   519  0 14:16 pts/3    00:00:00 -bash</span><br><span class="line">root       785   423  0 14:59 pts/1    00:00:00 su deploy</span><br><span class="line">deploy     786   785  0 14:59 pts/1    00:00:00 bash</span><br><span class="line">deploy    1129   786  0 15:32 pts/1    00:00:02 java -cp target com.lk.optimization.demo.DemoTest</span><br></pre></td></tr></table></figure>
<p>ps 命令</p>
<ul>
<li>-e 显示所有进程信息</li>
<li>-f 显示所有的字段</li>
<li>-l long format</li>
<li>-L 显示NLWP (number of threads) and LWP (thread ID) 显示线程信息</li>
<li>-p 只显示指定的PID</li>
</ul>
<p>字段的解释可以在man页的<code>STANDARD FORMAT SPECIFIERS</code>中查找</p>
<p>默认情况下，ps显示与当前用户相同EUID以及调用了同一个终端的进程。</p>
<ul>
<li>PID是进程ID</li>
<li>TTY为与进程关联的终端名称</li>
<li>TIME为以<code>[dd-]hh:mm:ss</code>格式显示的CPU时间</li>
<li>CMD为执行的名称, 默认不排序</li>
<li>PPID为父进程ID，根据ID可以找到进程的调用关系</li>
</ul>
<p>样例中的进程信息:</p>
<table>
<thead>
<tr>
<th>进程id</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0号进程是根进程</td>
</tr>
<tr>
<td>1</td>
<td>通过sshd发起的ssh连接</td>
</tr>
<tr>
<td>421</td>
<td>ssh连接，用户为root，终端为pts/1，子进程全部这个终端</td>
</tr>
<tr>
<td>423</td>
<td>bash shell</td>
</tr>
<tr>
<td>785</td>
<td>切换deploy账户</td>
</tr>
<tr>
<td>786</td>
<td>deploy账户的bash shell</td>
</tr>
<tr>
<td>1129</td>
<td>java启动进程</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos ~]# ps -flL -p 1129</span><br><span class="line">F S UID        PID  PPID   LWP  C NLWP PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD</span><br><span class="line">0 S deploy    1129   786  1129  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">5 S deploy    1129   786  1130  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1131  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1132  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1133  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1134  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1135  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1136  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1137  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1138  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1139  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1140  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br></pre></td></tr></table></figure>
<h3 id="Process-Format"><a href="#Process-Format" class="headerlink" title="Process Format"></a>Process Format</h3><ol>
<li>F PROCESS FLAGS   1 forked但没有执行 5超级用户权限</li>
<li>S PROCESS STATE CODES<pre><code>D    Uninterruptible sleep (usually IO)
R    Running or runnable (on run queue)
S    Interruptible sleep (waiting for an event to complete)
T    Stopped, either by a job control signal or because it is being traced.
W    paging (not valid since the 2.6.xx kernel)
X    dead (should never be seen)
Z    Defunct (&quot;zombie&quot;) process, terminated but not reaped by its parent.</code></pre>
</li>
<li>lwp (light weight process, or thread) ID 线程ID</li>
<li>C  processor utilization. Currently, this is the integer value of the percent usage over the lifetime of the process.</li>
<li>NLWP 轻量级进程的个数</li>
<li>ni         NI       nice value. This ranges from 19 (nicest) to -20 (not nice to others)</li>
<li>size       SZ       approximate amount of swap space that would be required if the process were to dirty all writable pages and then be swapped out. This number is very rough!</li>
<li>wchan      WCHAN    name of the kernel function in which the process is sleeping, a “-“ if the process is running, or a “*” if the process is multi-threaded and ps is not displaying threads.</li>
</ol>
<h3 id="线程信息"><a href="#线程信息" class="headerlink" title="线程信息"></a>线程信息</h3><p>线程线程的选项:</p>
<ul>
<li>H     Show threads as if they were processes 显示正在处理的线程</li>
<li>-L     Show threads, possibly with LWP and NLWP columns 显示线程</li>
<li>-T     Show threads, possibly with SPID column 显示线程</li>
<li>m     Show threads after processes</li>
<li>-m    Show threads after processes</li>
</ul>
<p>通过上面的例子，可以看出</p>
<p>线程id是1129~1154, 共27个线程<br>实际handler线程和main线程加起来是11个，为什么是27个线程呢</p>
<h2 id="top-查看资源"><a href="#top-查看资源" class="headerlink" title="top 查看资源"></a>top 查看资源</h2><p>以线程模式查看下进程31951的所有线程情况</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">top -Hp 31951</span><br></pre></td></tr></table></figure>
<p>![top-thread](images/20190728100827299_123372753.png =634x)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-H : Threads toggle</span><br><span class="line">            Starts  top with the last remembered ’H’ state reversed.  When this toggle is On, all individual threads will be displayed.  Otherwise, top displays a summation of all threads in a process. 当此开关打开时，将显示所有单个线程。否则，top显示进程中所有线程的总和。</span><br><span class="line"></span><br><span class="line">-p : Monitor PIDs as:  -pN1 -pN2 ...  or  -pN1, N2 [,...]</span><br><span class="line">            Monitor only processes with specified process IDs.  This option can be given up to 20 times, or you can provide a comma delimited list with up  to  20 pids.  Co-mingling both approaches is permitted. This  is  a  command-line  option  only.  And should you wish to return to normal operation, it is not necessary to quit and and restart top  --  just issue the ’&#x3D;’ interactive command.</span><br><span class="line">            打开top后，&#x3D; 可以切换回全部进程</span><br></pre></td></tr></table></figure>


<h2 id="jstack-Java线程栈信息"><a href="#jstack-Java线程栈信息" class="headerlink" title="jstack Java线程栈信息"></a>jstack Java线程栈信息</h2><p>jstack中的线程id为16进制，需要将从top或ps获取的线程id转换为16进制,</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">printf %x &lt;tid&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意:</p>
<ol>
<li>jstack必须和运行的JVM进程是同一个用户</li>
</ol>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Options:</span><br><span class="line">    -F  to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung)</span><br><span class="line">    -m  to print both java and native frames (mixed mode)</span><br><span class="line">    -l  long listing. Prints additional information about locks</span><br><span class="line">    -h or -help to print this help message</span><br></pre></td></tr></table></figure>
<h2 id="虚拟机信息flag"><a href="#虚拟机信息flag" class="headerlink" title="虚拟机信息flag"></a>虚拟机信息flag</h2><p>打印虚拟机所有的参数</p>
<p><a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html">java 命令文档</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -XX:+PrintFlagsFinal -version | grep :</span><br><span class="line">java -XX:+PrintFlagsInitial -version</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">java -XX:+PrintFlagsFinal -version | grep -v :&#x3D;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">The -XX:+PrintFlagsFinal (emphasis on &quot;Final&quot;) option displays what options HotSpot ended up using for running Java code while </span><br><span class="line">-XX:+PrintFlagsInitial (emphasis on &quot;Initial&quot;) displays what options were provided to HotSpot initially, before HotSpot has made its own tweaks.</span><br></pre></td></tr></table></figure>

<h2 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a>jinfo</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jinfo -flags <span class="variable">$PID</span></span><br><span class="line"></span><br><span class="line">Attaching to process ID 29893, please <span class="built_in">wait</span>...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.  <span class="comment"># 服务器版本的编译器</span></span><br><span class="line">JVM version is 25.232-b09 <span class="comment"># jvm版本</span></span><br><span class="line">Non-default VM flags:</span><br><span class="line">-XX:CICompilerCount=2</span><br><span class="line">-XX:InitialHeapSize=33554432 <span class="comment"># 初始堆大小 33M</span></span><br><span class="line">-XX:MaxHeapSize=524288000 <span class="comment"># 最大堆大小 524M</span></span><br><span class="line">-XX:MaxNewSize=174718976  <span class="comment">#年轻代最大大小 174M</span></span><br><span class="line">-XX:MinHeapDeltaBytes=196608 <span class="comment">#堆自动增加步长最小196K</span></span><br><span class="line">-XX:NewSize=11141120  <span class="comment">#年轻代大小11M</span></span><br><span class="line">-XX:OldSize=22413312 <span class="comment">#老年代大小22M</span></span><br><span class="line">-XX:+UseCompressedClassPointers  <span class="comment">#压缩类指针</span></span><br><span class="line">-XX:+UseCompressedOops <span class="comment">#压缩</span></span><br><span class="line">-XX:+UseParallelGC <span class="comment"># 使用并行回收器</span></span><br><span class="line"></span><br><span class="line">Command line:</span><br></pre></td></tr></table></figure>
<h2 id="jstat查看jvm统计信息和垃圾回收信息"><a href="#jstat查看jvm统计信息和垃圾回收信息" class="headerlink" title="jstat查看jvm统计信息和垃圾回收信息"></a>jstat查看jvm统计信息和垃圾回收信息</h2><p>JVM statistics</p>
<p><a href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jstat.html#BEHHGFAE">jstat docs</a></p>
<p><a href="https://app.yinxiang.com/shard/s30/nl/6747836/1db66cb0-6a66-4766-84ba-5d5b51df1fd2">jstat 命令使用样例</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">➜ jstat -options</span><br><span class="line">-<span class="class"><span class="keyword">class</span> # <span class="title">classLoader</span>行为的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">compiler</span> #  <span class="title">Java</span> <span class="title">HotSpot</span> <span class="title">VM</span> <span class="title">Just</span>-<span class="title">in</span>-<span class="title">Time</span> <span class="title">compiler</span>行为的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">gc</span> # 垃圾回收堆的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">gccapacity</span> # 每代的大小和容量</span></span><br><span class="line"><span class="class">-<span class="title">gccause</span> # 垃圾收集统计及回收原因</span></span><br><span class="line"><span class="class">-<span class="title">gcmetacapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcnew</span></span></span><br><span class="line"><span class="class">-<span class="title">gcnewcapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcold</span></span></span><br><span class="line"><span class="class">-<span class="title">gcoldcapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcutil</span> # <span class="title">gc</span>统计信息汇总，展示<span class="title">gc</span>次数、耗时和各个分区的大小</span></span><br><span class="line"><span class="class">-<span class="title">printcompilation</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line">class: Displays statistics about the behavior of the class loader.</span><br><span class="line">compiler: Displays statistics about the behavior of the Java HotSpot VM Just-in-Time compiler.</span><br><span class="line">gc: Displays statistics about the behavior of the garbage collected heap.</span><br><span class="line">gccapacity: Displays statistics about the capacities of the generations and their corresponding spaces.</span><br><span class="line">gccause: <span class="function">Displays a summary about garbage collection <span class="title">statistics</span> <span class="params">(same as -gcutil)</span>, with the cause of the last and <span class="title">current</span> <span class="params">(when applicable)</span> garbage collection events.</span></span><br><span class="line"><span class="function">gcnew: Displays statistics of the behavior of the new generation.</span></span><br><span class="line"><span class="function">gcnewcapacity: Displays statistics about the sizes of the new generations and its corresponding spaces.</span></span><br><span class="line"><span class="function">gcold: Displays statistics about the behavior of the old generation and metaspace statistics.</span></span><br><span class="line"><span class="function">gcoldcapacity: Displays statistics about the sizes of the old generation.</span></span><br><span class="line"><span class="function">gcmetacapacity: Displays statistics about the sizes of the metaspace.</span></span><br><span class="line"><span class="function">gcutil: Displays a summary about garbage collection statistics.</span></span><br><span class="line"><span class="function">printcompilation: Displays Java HotSpot VM compilation method statistics.</span></span><br></pre></td></tr></table></figure>
<p>GC堆统计</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">jstat -gc <span class="number">12196</span></span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   </span><br><span class="line"><span class="number">512.0</span>  <span class="number">1024.0</span> <span class="number">496.0</span>   <span class="number">0.0</span>   <span class="number">67584.0</span>  <span class="number">38337.9</span>   <span class="number">437248.0</span>   <span class="number">75268.8</span>   <span class="number">83992.0</span> <span class="number">80411.0</span> <span class="number">9496.0</span> <span class="number">8854.4</span>    <span class="number">388</span>    <span class="number">5.643</span>   <span class="number">3</span>      <span class="number">0.390</span>    <span class="number">6.033</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-gc option</span><br><span class="line">Garbage-collected heap statistics.</span><br><span class="line"></span><br><span class="line">S0C: Current survivor space 0 capacity (kB).   #s0区当前容量</span><br><span class="line">S1C: Current survivor space 1 capacity (kB). #s1区当前容量</span><br><span class="line">S0U: Survivor space 0 utilization (kB). #s0区使用量</span><br><span class="line">S1U: Survivor space 1 utilization (kB). #s1区使用量</span><br><span class="line">EC: <span class="function">Current eden space <span class="title">capacity</span> <span class="params">(kB)</span>. #eden区容量</span></span><br><span class="line"><span class="function">EU: Eden space <span class="title">utilization</span> <span class="params">(kB)</span>. #eden区使用量</span></span><br><span class="line"><span class="function">OC: Current old space <span class="title">capacity</span> <span class="params">(kB)</span>. #old区容量</span></span><br><span class="line"><span class="function">OU: Old space <span class="title">utilization</span> <span class="params">(kB)</span>. #old区使用量</span></span><br><span class="line"><span class="function">MC: Metaspace <span class="title">capacity</span> <span class="params">(kB)</span>. #metaspace容量</span></span><br><span class="line"><span class="function">MU: Metacspace <span class="title">utilization</span> <span class="params">(kB)</span>. #metaspace使用量</span></span><br><span class="line"><span class="function">CCSC: Compressed class space <span class="title">capacity</span> <span class="params">(kB)</span>. #压缩类空间容量</span></span><br><span class="line"><span class="function">CCSU: Compressed class space <span class="title">used</span> <span class="params">(kB)</span>. #压缩类空间使用量</span></span><br><span class="line"><span class="function">YGC: Number of young generation garbage collection events.  # YGC次数</span></span><br><span class="line"><span class="function">YGCT: Young generation garbage collection time. #YGC耗时</span></span><br><span class="line"><span class="function">FGC: Number of full GC events. # Full GC次数</span></span><br><span class="line"><span class="function">FGCT: Full garbage collection time. # Full GC耗时</span></span><br><span class="line"><span class="function">GCT: Total garbage collection time. # GC总耗时</span></span><br></pre></td></tr></table></figure>
<p>GC统计</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">jstat -gcutil <span class="number">12196</span></span><br><span class="line">  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> <span class="number">96.88</span>   <span class="number">0.00</span>  <span class="number">89.96</span>  <span class="number">17.21</span>  <span class="number">95.74</span>  <span class="number">93.24</span>    <span class="number">388</span>    <span class="number">5.643</span>     <span class="number">3</span>    <span class="number">0.390</span>    <span class="number">6.033</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">-gcutil option</span><br><span class="line">Summary of garbage collection statistics.</span><br><span class="line"></span><br><span class="line">S0: Survivor space <span class="number">0</span> utilization as a percentage of the space<span class="string">&#x27;s current capacity. # s0区使用率</span></span><br><span class="line">S1: Survivor space 1 utilization as a percentage of the space&#x27;s current capacity. # S1区使用率</span><br><span class="line">E: Eden space utilization as a percentage of the space<span class="string">&#x27;s current capacity. # eden区使用率</span></span><br><span class="line">O: Old space utilization as a percentage of the space&#x27;s current capacity. # old区使用率</span><br><span class="line">M: Metaspace utilization as a percentage of the space<span class="string">&#x27;s current capacity. # Metaspace使用率</span></span><br><span class="line"><span class="string">CCS: Compressed class space utilization as a percentage. # 压缩类空间使用率</span></span><br><span class="line"><span class="string">YGC: Number of young generation GC events. # YGC次数</span></span><br><span class="line"><span class="string">YGCT: Young generation garbage collection time. # YGC耗时</span></span><br><span class="line"><span class="string">FGC: Number of full GC events. # Full GC次数</span></span><br><span class="line"><span class="string">FGCT: Full garbage collection time. # Full GC耗时</span></span><br><span class="line"><span class="string">GCT: Total garbage collection time. # GC总耗时</span></span><br></pre></td></tr></table></figure>

<h2 id="堆dump"><a href="#堆dump" class="headerlink" title="堆dump"></a>堆dump</h2><p>full gc前后dump</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java -XX:HeapDumpPath=./heap/ -XX:+HeapDumpOnOutOfMemoryError -XX:+HeapDumpAfterFullGC</span><br></pre></td></tr></table></figure>
<p><code>HeapDumpPath</code>: dump path<br><code>HeapDumpOnOutOfMemoryError</code> 内存溢出dump<br><code>HeapDumpAfterFullGC</code>、<code>HeapDumpBeforeFullGC</code> ：Full GC前后dump</p>
<h3 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h3><p>Prints shared object memory maps or heap memory details for a process, core file, or remote debug server. This command is experimental and unsupported.<br>打印进程、核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息</p>
<p><a href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jmap.html#BEHHGFAE">jmap docs</a></p>
<p>jmap -heap <pid></p>
<p>堆的各个分区大小</p>
<p><a href="https://segmentfault.com/a/1190000010648021">堆内存分析-GC日志解读</a></p>
<p>展示堆满的情况下的各个分区大小</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&gt; jmap -heap <span class="number">16186</span></span><br><span class="line">Attaching to process ID <span class="number">16186</span>, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is <span class="number">25.242</span>-b08</span><br><span class="line"></span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Parallel GC with <span class="number">6</span> thread(s)</span><br><span class="line"></span><br><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio         = <span class="number">0</span></span><br><span class="line">   MaxHeapFreeRatio         = <span class="number">100</span></span><br><span class="line">   MaxHeapSize              = <span class="number">522190848</span> (<span class="number">498.</span>0MB)</span><br><span class="line">   NewSize                  = <span class="number">11010048</span> (<span class="number">10.</span>5MB)</span><br><span class="line">   MaxNewSize               = <span class="number">174063616</span> (<span class="number">166.</span>0MB)</span><br><span class="line">   OldSize                  = <span class="number">22544384</span> (<span class="number">21.</span>5MB)</span><br><span class="line">   NewRatio                 = <span class="number">2</span></span><br><span class="line">   SurvivorRatio            = <span class="number">8</span></span><br><span class="line">   MetaspaceSize            = <span class="number">21807104</span> (<span class="number">20.</span>796875MB)</span><br><span class="line">   CompressedClassSpaceSize = <span class="number">1073741824</span> (<span class="number">1024.</span>0MB)</span><br><span class="line">   MaxMetaspaceSize         = <span class="number">17592186044415</span> MB</span><br><span class="line">   G1HeapRegionSize         = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line"></span><br><span class="line">Heap Usage:</span><br><span class="line">PS Young Generation</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity = <span class="number">58720256</span> (<span class="number">56.</span>0MB)</span><br><span class="line">   used     = <span class="number">49193976</span> (<span class="number">46.</span>91503143310547MB)</span><br><span class="line">   free     = <span class="number">9526280</span> (<span class="number">9.</span>084968566894531MB)</span><br><span class="line">   <span class="number">83.7768418448312</span>% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity = <span class="number">57147392</span> (<span class="number">54.</span>5MB)</span><br><span class="line">   used     = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line">   free     = <span class="number">57147392</span> (<span class="number">54.</span>5MB)</span><br><span class="line">   <span class="number">0.0</span>% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity = <span class="number">57671680</span> (<span class="number">55.</span>0MB)</span><br><span class="line">   used     = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line">   free     = <span class="number">57671680</span> (<span class="number">55.</span>0MB)</span><br><span class="line">   <span class="number">0.0</span>% used</span><br><span class="line">PS Old Generation</span><br><span class="line">   capacity = <span class="number">348127232</span> (<span class="number">332.</span>0MB)</span><br><span class="line">   used     = <span class="number">347644232</span> (<span class="number">331.</span>5393753051758MB)</span><br><span class="line">   free     = <span class="number">483000</span> (<span class="number">0.</span>46062469482421875MB)</span><br><span class="line">   <span class="number">99.8612576220409</span>% used</span><br><span class="line"></span><br><span class="line"><span class="number">10381</span> interned Strings occupying <span class="number">935984</span> bytes.</span><br></pre></td></tr></table></figure>

<h2 id="远程监控"><a href="#远程监控" class="headerlink" title="远程监控"></a>远程监控</h2><h3 id="JVM开启远程JMX"><a href="#JVM开启远程JMX" class="headerlink" title="JVM开启远程JMX"></a>JVM开启远程JMX</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 开启远程调试端口</span></span><br><span class="line">-Dcom.sun.management.jmxremote.port=8777</span><br><span class="line"><span class="comment"># 开启本地调试端口</span></span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port=8777</span><br><span class="line"><span class="comment"># jmx远程服务默认是开启ssl和认证功能功能的，也可以通过jvm选项把这两个功能关闭</span></span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate=<span class="literal">false</span></span><br><span class="line">-Dcom.sun.management.jmxremote.ssl=<span class="literal">false</span></span><br><span class="line"><span class="comment"># jmx默认是通过localhost的ip地址提供RMI服务的，如果要明确指定RMI服务地址或主机名（比如主机有多个接口，想使用非hostname关联的接口）</span></span><br><span class="line">-Djava.rmi.server.hostname=10.242.93.40</span><br></pre></td></tr></table></figure>
<p>例子:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java \</span><br><span class="line">-Djava.rmi.server.hostname=0.0.0.0 \</span><br><span class="line">-Dcom.sun.management.jmxremote \</span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port=8000 \</span><br><span class="line">-Dcom.sun.management.jmxremote.port=8001 \</span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate=false \</span><br><span class="line">-Dcom.sun.management.jmxremote.ssl=false \</span><br><span class="line">-jar demo-0.0.1-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>
<h3 id="Tomcat-开启远程"><a href="#Tomcat-开启远程" class="headerlink" title="Tomcat 开启远程"></a>Tomcat 开启远程</h3><p>修改<code>catalina.sh</code>,</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS&#x3D;&quot;$JAVA_OPTS -Djava.rmi.server.hostname&#x3D;0.0.0.0 </span><br><span class="line">-Dcom.sun.management.jmxremote </span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port&#x3D;8000 </span><br><span class="line">-Dcom.sun.management.jmxremote.port&#x3D;8001 </span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate&#x3D;false </span><br><span class="line">-Dcom.sun.management.jmxremote.ssl&#x3D;false &quot;</span><br></pre></td></tr></table></figure>
<h3 id="jvisualvm"><a href="#jvisualvm" class="headerlink" title="jvisualvm"></a>jvisualvm</h3><p><a href="https://visualvm.github.io/pluginscenters.html">插件中心</a></p>
<ul>
<li>新建远程主机0.0.0.0</li>
<li>新建JMX链接: 端口是8001</li>
</ul>
<p><a href="https://visualvm.github.io/documentation.html">中文文档</a></p>
<h2 id="开启jstatd连接"><a href="#开启jstatd连接" class="headerlink" title="开启jstatd连接"></a>开启jstatd连接</h2><h2 id="BTrace"><a href="#BTrace" class="headerlink" title="BTrace"></a>BTrace</h2><p><a href="https://github.com/btraceio/btrace">官网</a></p>
<h2 id="JDWP与tomcat远程调试"><a href="#JDWP与tomcat远程调试" class="headerlink" title="JDWP与tomcat远程调试"></a>JDWP与tomcat远程调试</h2><h2 id="Tomcat-监控"><a href="#Tomcat-监控" class="headerlink" title="Tomcat 监控"></a>Tomcat 监控</h2><h3 id="JDWP"><a href="#JDWP" class="headerlink" title="JDWP"></a>JDWP</h3><h3 id="Tomcat-manager"><a href="#Tomcat-manager" class="headerlink" title="Tomcat-manager"></a>Tomcat-manager</h3><h3 id="psi-probe监控"><a href="#psi-probe监控" class="headerlink" title="psi-probe监控"></a>psi-probe监控</h3><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><h3 id="ngx-http-stub-status监控连接信息"><a href="#ngx-http-stub-status监控连接信息" class="headerlink" title="ngx_http_stub_status监控连接信息"></a>ngx_http_stub_status监控连接信息</h3><h3 id="ngxtop监控请求信息"><a href="#ngxtop监控请求信息" class="headerlink" title="ngxtop监控请求信息"></a>ngxtop监控请求信息</h3><h2 id="字节码"><a href="#字节码" class="headerlink" title="字节码"></a>字节码</h2><p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html#jvms-4.4">常量池官方文档</a></p>
<h3 id="深入解析String-intern"><a href="#深入解析String-intern" class="headerlink" title="深入解析String#intern"></a>深入解析String#intern</h3><p><a href="https://blog.csdn.net/goldenfish1919/article/details/80410349">深入解析String.intern</a><br><a href="https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html">原文出处: 深入解析String.intern</a></p>
<p>字符串的常量池</p>
<p>常量池在哪里？</p>
<ul>
<li>Jdk1.6及之前： 有永久代, 常量池在方法区</li>
<li>Jdk1.7：       有永久代，但已经逐步“去永久代”，常量池在堆</li>
<li>Jdk1.8及之后： 无永久代，常量池在元空间</li>
</ul>
<h3 id="String去重"><a href="#String去重" class="headerlink" title="String去重"></a>String去重</h3><p><a href="https://blog.csdn.net/goldenfish1919/article/details/20233263">String Deduplication in G1</a></p>
<p>-XX:+UseStringDeduplication   开启String去重<br>-XX:+PrintStringDeduplicationStatistics 打印详细的去重统计<br>-XX:StringDeduplicationAgeThreshold=15 达到这个年龄的String对象才会去重</p>
<h2 id="重用代码优化方法"><a href="#重用代码优化方法" class="headerlink" title="重用代码优化方法"></a>重用代码优化方法</h2><ul>
<li>尽量重用对象，不要循环创建对象，比如：for循环字符串拼接</li>
<li>容器类初始化的时候指定长度</li>
<li>ArrayList随机遍历快，LinkedList添加删除快</li>
<li>集合遍历尽量减少重复计算  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;collection.size();i++) <span class="comment">// collection.size() 提取成常量</span></span><br></pre></td></tr></table></figure></li>
<li>使用Entry遍历Map  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(Map.Entry&lt;String,String&gt; entry:map.entrySet())&#123;</span><br><span class="line">    String key=entry.getKey();</span><br><span class="line">    String value=entry.getValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>大数组复制用<code>System.arrayCopy()</code></li>
<li>尽量使用基本类型而不是包装类型  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i=<span class="number">100</span>;</span><br><span class="line">System.out.println(i);</span><br></pre></td></tr></table></figure>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack&#x3D;2, locals&#x3D;2, args_size&#x3D;1</span><br><span class="line">     0: bipush        100                 &#x2F;&#x2F; 将100压入栈</span><br><span class="line">     2: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">     5: astore_1</span><br><span class="line">     6: getstatic     #3                  &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;</span><br><span class="line">     9: aload_1</span><br><span class="line">    10: invokevirtual #4                  &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;Object;)V</span><br><span class="line">    13: return</span><br></pre></td></tr></table></figure>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i1=<span class="number">100</span>;</span><br><span class="line">Integer i2=<span class="number">100</span>;</span><br><span class="line">System.out.println(i1==i2); <span class="comment">// true</span></span><br></pre></td></tr></table></figure>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack&#x3D;3, locals&#x3D;3, args_size&#x3D;1</span><br><span class="line">     0: bipush        100</span><br><span class="line">     2: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">     5: astore_1</span><br><span class="line">     6: bipush        100</span><br><span class="line">     8: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">    11: astore_2</span><br><span class="line">    12: getstatic     #3                  &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;</span><br><span class="line">    15: aload_1</span><br><span class="line">    16: aload_2</span><br><span class="line">    17: if_acmpne     24</span><br><span class="line">    20: iconst_1</span><br><span class="line">    21: goto          25</span><br><span class="line">    24: iconst_0</span><br><span class="line">    25: invokevirtual #5                  &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Z)V</span><br><span class="line">    28: return</span><br></pre></td></tr></table></figure>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i1=<span class="number">1000</span>;</span><br><span class="line">Integer i2=<span class="number">1000</span>;</span><br><span class="line">System.out.println(i1==i2);  <span class="comment">// false</span></span><br></pre></td></tr></table></figure>
  <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack=3, locals=3, args_size=1</span><br><span class="line">     0: sipush        1000</span><br><span class="line">     3: invokestatic  #2                  // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;</span><br><span class="line">     6: astore_1</span><br><span class="line">     7: sipush        1000</span><br><span class="line">    10: invokestatic  #2                  // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;</span><br><span class="line">    13: astore_2</span><br><span class="line">    14: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;</span><br><span class="line">    17: aload_1</span><br><span class="line">    18: aload_2</span><br><span class="line">    19: if_acmpne     26</span><br><span class="line">    22: iconst_1</span><br><span class="line">    23: goto          27</span><br><span class="line">    26: iconst_0</span><br><span class="line">    27: invokevirtual #5                  // Method java/io/PrintStream.println:(Z)V</span><br><span class="line">    30: return</span><br></pre></td></tr></table></figure>
  Integer.valueOf 内部有缓存，如果大于-128且小于<code>java.lang.Integer.IntegerCache.high</code>(默认值是127)，则返回缓存</li>
<li>尽量使用非同步的容器，vector和ArrayList</li>
<li>尽量减少同步作用范围，synchronized方法vs代码块  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">f1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;f1&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">f2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;f4&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">f3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;f3&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">f4</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (TestPrimaryType.class) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;f4&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>使用ThreadLocal缓存线程不安全对象，simpleDateFormat</li>
<li>尽量使用延迟加载，懒惰单例模式  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPrimaryType</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">TestPrimaryType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPrimaryTypeHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> TestPrimaryType instance = <span class="keyword">new</span> TestPrimaryType();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    ** 调用这个方法时，发生对TestPrimaryTypeHolder的引用，才创建instance对象</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> TestPrimaryType <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> TestPrimaryTypeHolder.instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>尽量减少使用反射，加缓存</li>
<li>尽量使用连接池、线程池、对象池、缓存</li>
<li>及时释放资源，I/O流、socket、数据库连接</li>
<li>慎用异常，不要用抛异常来标示正常的业务逻辑</li>
<li>String操作尽量少用正则表达式  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">replace VS replaceAll: 尽量用replace</span><br><span class="line">split</span><br></pre></td></tr></table></figure></li>
<li>日志输出注意使用不同的级别</li>
<li>日志中参数拼接使用占位符  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log.info(“orderId:”+orgerId); &#x2F;&#x2F; 不推荐</span><br><span class="line">log.info(“orderId:&#123;&#125;”,orgerId); &#x2F;&#x2F;推荐</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
      </tags>
  </entry>
  <entry>
    <title>GC调优</title>
    <url>/Java/metric/02_GC_tuning/</url>
    <content><![CDATA[<h1 id="GC调优"><a href="#GC调优" class="headerlink" title="GC调优"></a>GC调优</h1><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>内容：</p>
<ol>
<li>教程</li>
<li>压测+调优</li>
<li>实际样例</li>
</ol>
<p>tip:</p>
<ul>
<li>collector</li>
<li>gc logs</li>
<li>gc viewer</li>
<li>jmeter</li>
<li>压测与调优</li>
</ul>
<h2 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h2><p><a href="https://blog.csdn.net/qq_40368860/article/details/84447085">jvm整体架构图文详解</a></p>
<p><a href="https://docs.oracle.com/javase/specs/jls/se8/html/index.html">Java8 语言规范</a><br><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/index.html">Java8 JVM规范</a><br><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5">Java8 JVM规范-内存结构</a></p>
<p>运行时数据区</p>
<p>![](_v_images/20200205234634496_2051245788.png =526x)</p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><h3 id="虚拟机栈JVM-Stacks"><a href="#虚拟机栈JVM-Stacks" class="headerlink" title="虚拟机栈JVM Stacks"></a>虚拟机栈JVM Stacks</h3><p>栈帧分为哪些快？每块又保存什么内容？</p>
<h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p>非堆</p>
<ul>
<li>JDK6 perm区</li>
<li>JDK7 perm区</li>
<li>JDK8 metaspace</li>
</ul>
<h3 id="常量池Run-Time-Constant-Pool-方法区中"><a href="#常量池Run-Time-Constant-Pool-方法区中" class="headerlink" title="常量池Run-Time Constant Pool (方法区中)"></a>常量池Run-Time Constant Pool (方法区中)</h3><h3 id="本地方法栈Native-Method-Stacks"><a href="#本地方法栈Native-Method-Stacks" class="headerlink" title="本地方法栈Native Method Stacks"></a>本地方法栈Native Method Stacks</h3><h3 id="JVM的内存结构"><a href="#JVM的内存结构" class="headerlink" title="JVM的内存结构"></a>JVM的内存结构</h3><p>![](_v_images/20200205235938340_210349887.png =500x)</p>
<ul>
<li>CCS：只有启用了短指针的时候，才存在</li>
<li>CodeCache：只有启用了JIT和有JNI调用Native代码的时候，才存在<ul>
<li><code>-Xcomp</code>：JIT完全编译执行</li>
<li><code>-Xint</code>完全解释执行</li>
<li><code>-Xmixed</code>编译和解释混合</li>
</ul>
</li>
</ul>
<h3 id="非堆区"><a href="#非堆区" class="headerlink" title="非堆区"></a>非堆区</h3><p>![](_v_images/20200206000408818_592467847.png =516x)</p>
<h3 id="标准参数"><a href="#标准参数" class="headerlink" title="标准参数"></a>标准参数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-version -showversion</span><br><span class="line">-help</span><br><span class="line">-cp -classpath</span><br><span class="line">-server -client</span><br></pre></td></tr></table></figure>




<h3 id="X"><a href="#X" class="headerlink" title="-X"></a>-X</h3><p>-Xint: 解释执行模式<br>-Xcomp: 编译执行模式, 第一次使用就编译成本地代码, 编译结果保存在metaspace的code cache空间<br>-Xmixed: 混合执行模式, JVM决定是否编译成本地代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; java -Xint -version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_232&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (build 1.8.0_232-b09)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 25.232-b09, interpreted mode)</span><br><span class="line"></span><br><span class="line">&gt; java -Xcomp -version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_232&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (build 1.8.0_232-b09)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 25.232-b09, compiled mode)</span><br></pre></td></tr></table></figure>
<h3 id="XX"><a href="#XX" class="headerlink" title="-XX"></a>-XX</h3><table>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>-Xms</td>
<td>最小堆内存</td>
</tr>
<tr>
<td>-Xmx</td>
<td>最大堆内存</td>
</tr>
<tr>
<td>-XX:NewSize</td>
<td>新生代大小</td>
</tr>
<tr>
<td>-XX:MaxNewSize</td>
<td>最大新生代大小</td>
</tr>
<tr>
<td>-XX:NewRatio</td>
<td>new区和old区的比例</td>
</tr>
<tr>
<td>-XX:SurvivorRatio</td>
<td>eden区与survivor区大小比例</td>
</tr>
<tr>
<td>-XX:MetaspaceSize</td>
<td>Metaspace大小</td>
</tr>
<tr>
<td>-XX:MaxMetaspaceSize</td>
<td>Metaspace最大大小</td>
</tr>
<tr>
<td>-XX:+UseCompressedClassPointers</td>
<td>压缩类指针</td>
</tr>
<tr>
<td>-XX:CompressedClassSpaceSize</td>
<td>压缩类空间(<code>CCS</code>)的大小,默认1G</td>
</tr>
<tr>
<td>-XX:InitialCodeCacheSize</td>
<td>code cache的初始大小</td>
</tr>
<tr>
<td>-XX:ReservedCodeCacheSize</td>
<td>code cache的最大的大小</td>
</tr>
<tr>
<td>-XX:PretenureSizeThreshold</td>
<td>大对象直接进入老年代，大对象的大小阈值</td>
</tr>
<tr>
<td>-XX:MaxTenuringThreshold</td>
<td>长期存活的对象进入老年代，晋升年龄阈值</td>
</tr>
<tr>
<td>-XX:+PrintTrnuringDistuibution</td>
<td>youngGC时打印年龄分布情况</td>
</tr>
<tr>
<td>-XX:TargetSurvivorRatio</td>
<td>survivor垃圾回收存活的比例，超过值将直接晋升</td>
</tr>
</tbody></table>
<h3 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h3><p><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc.html">gc调优官方指南</a></p>
<p>GC Root：</p>
<ul>
<li>类加载器：由类加载器生成的对象，都持有指针</li>
<li>Thread：线程运行会持有很多对象</li>
<li>虚拟机栈的本地变量表</li>
<li>static成员</li>
<li>常量引用</li>
<li>本地方法栈的变量</li>
</ul>
<h4 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h4><p>缺点：<br>无法处理循环引用</p>
<h4 id="标记清除"><a href="#标记清除" class="headerlink" title="标记清除"></a>标记清除</h4><p>先标记需要回收的对象，在统一回收所有对象</p>
<p><strong>缺点：</strong></p>
<p>效率不高:标记和清除两个过程效率都不高；碎片：导致提前GC</p>
<h4 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h4><p>内存划分为大小相同的两块，每次只使用其中一块，一块用完复制存活的对象到另一块，然后再把已使用的内存空间一次清理掉</p>
<p><strong>缺点：</strong></p>
<p>使用简单，效率高，空间利用率不高</p>
<h4 id="标记整理"><a href="#标记整理" class="headerlink" title="标记整理"></a>标记整理</h4><p>先标记需要回收的对象，让所有存活的对象都向一端移动，然后清理掉端边界外的内存</p>
<p><strong>缺点：</strong><br>无内存碎片，比较耗时</p>
<h3 id="分带垃圾回收"><a href="#分带垃圾回收" class="headerlink" title="分带垃圾回收"></a>分带垃圾回收</h3><p>young区朝生夕死，生命周期端，用复制算法：效率高<br>Old区生命周期长，用标记清除或标记整理</p>
<ul>
<li>对象优先分配在eden区</li>
<li>大对象直接进入老年代：<code>-XX:PretenureSizeThreshold</code></li>
<li>长期存活的对象进入老年代：<ul>
<li><code>-XX:MaxTenuringThreshold</code>: 晋升年龄代数阈值</li>
<li><code>-XX:+PrintTenuringDistribution</code>：ygc打印存活对象的分布情况</li>
<li><code>-XX:TargetSurvivorRatio</code>：Survivor区存活对象比例，动态调整，取存活对象的平均值与晋升年龄阈值间的最小值</li>
</ul>
</li>
</ul>
<h3 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h3><p>枚举根节点，做可达性分析<br>根节点: 类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量</p>
<ul>
<li>串行收集器Serial: Serial、 Serial old</li>
<li>并行收集器Parallel: Parallel Scavenge、Parallel old，吞吐量优先</li>
<li>并发收集器Concurrent: CMS、G1,停顿时间优先</li>
</ul>
<h4 id="并行-vs-并发"><a href="#并行-vs-并发" class="headerlink" title="并行 vs 并发"></a>并行 vs 并发</h4><p>并行(Parallel): 多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互的场景</p>
<p>并发(Concurrent): 用户线程和垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），垃圾收集线程在执行的时候不会停顿用户程序的运行。适合对响应时间有要求的场景，如web。</p>
<h4 id="停顿时间-vs-吞吐量"><a href="#停顿时间-vs-吞吐量" class="headerlink" title="停顿时间 vs 吞吐量"></a>停顿时间 vs 吞吐量</h4><p>停顿时间：垃圾收集器做垃圾回收中断应用执行的时间。<code>-XX:MaxGCPauseMillis</code></p>
<p>吞吐量：花在垃圾收集的时间和花在应用时间的占比。 <code>-XX:GCTimeRatio=&lt;n&gt;</code>, 垃圾收集时间占: <code>1/(1+n)</code></p>
<h3 id="串行收集器"><a href="#串行收集器" class="headerlink" title="串行收集器"></a>串行收集器</h3><p>-XX:+UseSerialGC<br>-XX:+UseSerialOldGC</p>
<p>采用串行收集器，默认old区采用串行收集器</p>
<h3 id="并行收集器-ParallelCollector"><a href="#并行收集器-ParallelCollector" class="headerlink" title="并行收集器 ParallelCollector"></a>并行收集器 ParallelCollector</h3><p>吞吐量优先</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseParallelGC</span><br><span class="line">-XX:+UseParallelOldGC</span><br><span class="line"></span><br><span class="line">Server模式下的默认收集器</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:ParallelGCThreads&#x3D;&lt;N&gt; 多少个GC线程</span><br><span class="line"></span><br><span class="line">CPU&gt;8 N&#x3D;5&#x2F;8</span><br><span class="line">CPU&lt;8 N&#x3D;CPU</span><br></pre></td></tr></table></figure>
<h3 id="并发收集器"><a href="#并发收集器" class="headerlink" title="并发收集器"></a>并发收集器</h3><p>响应时间优先</p>
<p>CMS:  -XX:+UseConcMarkSweepGC  -XX:+UseParNewGC<br>G1:  -XX:+UseG1GC</p>
<h3 id="如何选择垃圾收集器"><a href="#如何选择垃圾收集器" class="headerlink" title="如何选择垃圾收集器"></a>如何选择垃圾收集器</h3><p><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/collectors.html#sthref27">如何选择垃圾收集器</a></p>
<ul>
<li>优先调整堆的大小让服务器自己选择</li>
<li>如果内存小于100M，使用串行收集器</li>
<li>如果是单核，并且没有停顿时间的要求，串行或者jvm自己选</li>
<li>如果允许停顿时间超过1s，选择并行或者jvm自己选</li>
<li>如果响应时间最重要，并且不能超过1s，则使用并发收集器</li>
</ul>
<table>
<thead>
<tr>
<th>young</th>
<th>Tenured</th>
<th>JVM options</th>
</tr>
</thead>
<tbody><tr>
<td>Serial</td>
<td>Serial</td>
<td>-XX:+UseSerialGC</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>Serial</td>
<td>-XX:+UseParallelGC -XX:-UseParallelOldGC</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>Parallel Old</td>
<td>-XX:+UseParallelGC -XX:+UseParallelOldGC</td>
</tr>
<tr>
<td>Parallel New或Serial</td>
<td>CMS</td>
<td>-XX:+UseParNewGC -XX:+UseConcMarkSweepGC</td>
</tr>
<tr>
<td>G1</td>
<td>G1</td>
<td>-XX:+UseG1GC</td>
</tr>
</tbody></table>
<p>![](_v_images/20200202130338468_927467357.png =500x)</p>
<p>垃圾回收器从线程运行情况分类有三种</p>
<p>串行回收: Serial回收器，单线程回收，全程stw；<br>并行回收: 名称以Parallel开头的回收器，多线程回收，全程stw；<br>并发回收: cms与G1，多线程分阶段回收，只有某阶段会stw；</p>
<h2 id="并行收集器-Parallel-Collector"><a href="#并行收集器-Parallel-Collector" class="headerlink" title="并行收集器 Parallel Collector"></a>并行收集器 Parallel Collector</h2><p>暂停应用程序，开启多个垃圾收集线程开始垃圾回收</p>
<ul>
<li><code>-XX:+UseParallelGC</code> 手动开启，Server默认开启</li>
<li><code>-XX:ParallelGCThreads=&lt;N&gt;</code>多少个GC线程<ul>
<li><code>CPU&gt;8 N=5/8</code></li>
<li><code>CPU&lt;8 N=CPU</code></li>
</ul>
</li>
</ul>
<p>查找使用ParallelGC的进程<br><code>jps -v  | grep -v grep | awk &#39;&#123;print $1&#125;&#39;   | xargs -L 1 -t jinfo -flag UseParallelGC</code></p>
<h3 id="Parallel-Collector-Ergonomics自适应"><a href="#Parallel-Collector-Ergonomics自适应" class="headerlink" title="Parallel Collector Ergonomics自适应"></a>Parallel Collector Ergonomics自适应</h3><ul>
<li><code>-XX:MaxGCPauseMillis=&lt;N&gt;</code>：最大停顿时间</li>
<li><code>-XX:GCTimeRatio=&lt;N&gt;</code>: GC时间占比，代表吞吐量</li>
<li><code>-Xmx&lt;N&gt;</code>: 堆最大大小</li>
</ul>
<p>优先满足停顿时间，再满足吞吐量的要求，最后再调整满足堆最大大小</p>
<p>动态调整每个分区的大小</p>
<h3 id="动态内存调整"><a href="#动态内存调整" class="headerlink" title="动态内存调整"></a>动态内存调整</h3><ul>
<li><code>-XX:YoungGenerationSizeIncrement=&lt;Y&gt;</code> 年轻代大小调整增量，默认值20%</li>
<li><code>-XX:TenuredGenerationSizeIncrement=&lt;T&gt;</code> 老年代大小调整增量，默认值</li>
<li><code>-XX:AdaptiveSizeDecrementScaleFactor=&lt;D&gt;</code> 减少增量，默认值4%</li>
</ul>
<h2 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java -XX:+UseConcMarkSweepGC  -jar -server console.jar</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jps -l | grep buried | awk &#x27;&#123;print $1&#125;&#x27; | xargs -L 1 -t /usr/local/soft/jdk1.8.0_191/bin/jinfo  -flags</span><br><span class="line">/usr/local/soft/jdk1.8.0_191/bin/jinfo -flags 4893</span><br><span class="line">Attaching to process ID 4893, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.191-b12</span><br><span class="line">Non-default VM flags: </span><br><span class="line">-XX:CICompilerCount=3 </span><br><span class="line">-XX:InitialHeapSize=524288000 </span><br><span class="line">-XX:MaxHeapSize=8363442176 </span><br><span class="line">-XX:MaxNewSize=348913664 </span><br><span class="line">-XX:MaxTenuringThreshold=6 </span><br><span class="line">-XX:MinHeapDeltaBytes=196608 </span><br><span class="line">-XX:NewSize=174718976 </span><br><span class="line">-XX:OldPLABSize=16 </span><br><span class="line">-XX:OldSize=349569024 </span><br><span class="line">-XX:+UseCompressedClassPointers </span><br><span class="line">-XX:+UseCompressedOops </span><br><span class="line">-XX:+UseConcMarkSweepGC </span><br><span class="line">-XX:+UseFastUnorderedTimeStamps </span><br><span class="line">-XX:+UseParNewGC</span><br><span class="line">Command line:  -XX:+UseConcMarkSweepGC </span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jps -l | grep buried | awk &#x27;&#123;print $1&#125;&#x27; | xargs -L 1 -t /usr/local/soft/jdk1.8.0_191/bin/jinfo  -flag CMSInitiatingOccupancyFraction</span><br><span class="line">/usr/local/soft/jdk1.8.0_191/bin/jinfo -flag CMSInitiatingOccupancyFraction 4893</span><br><span class="line">-XX:CMSInitiatingOccupancyFraction=-1</span><br></pre></td></tr></table></figure>
<p>cms是一种预处理垃圾回收器，它不能等到old内存用尽时回收，需要在内存用尽前，完成回收操作，否则会导致并发回收失败；所以cms垃圾回收器开始执行回收操作，有一个触发阈值，默认是老年代或永久带达到92%</p>
<ul>
<li>并发收集</li>
<li>低停顿 低延迟</li>
<li>老年代收集器</li>
</ul>
<p><strong>CMS垃圾收集过程</strong></p>
<ol>
<li>CMS inital mark: 初始标记Root  STW</li>
<li>CMS concurrent mark：并发标记</li>
<li>CMS-concurrent-preclean: 并发预清理</li>
<li>CMS remark: 重新标记 STW</li>
<li>CMS concurrent sweep：并发清除</li>
<li>CMS-concurrent-reset：并发重置</li>
</ol>
<p><strong>缺点</strong></p>
<ul>
<li>低停顿 低延迟</li>
<li>CPU敏感</li>
<li>浮动垃圾：边运行应用程序，边回收</li>
<li>空间碎片</li>
</ul>
<p><strong>调优参数</strong></p>
<table>
<thead>
<tr>
<th>参数</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>-XX:ConcGCThreads</td>
<td>并发的GC线程数</td>
</tr>
<tr>
<td>-XX:+UseCMSCompactAtFullCollection</td>
<td>FullGC之后做压缩</td>
</tr>
<tr>
<td>-XX:CMSFullGCsBeforeCompaction</td>
<td>多少次FullGC之后压缩一次</td>
</tr>
<tr>
<td>-XX:CMSInitiatingOccupancyFraction</td>
<td>触发FullGC  92%</td>
</tr>
<tr>
<td>-XX:+UseCMSInitiatingOccupancyOnly</td>
<td>是否动态调</td>
</tr>
<tr>
<td>-XX:+CMSScavengeBeforeRemark</td>
<td>FullGC之前先做YGC</td>
</tr>
<tr>
<td>-XX:+CMSClassUnloadingEnabled</td>
<td>启用回收Perm区</td>
</tr>
</tbody></table>
<h2 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h2><p>大内存(大于6G)，优先延迟(小于0.5s)</p>
<p>![](_v_images/20200206210747611_907596705.png =421x)</p>
<p>H区：大对象，如果对象超过了region的一半大小</p>
<p>Region</p>
<p>SATB：snapshot-at-the-beginning, 通过Root tracing得到的，GC开始时候存活对象的快照。垃圾回收以此为基础回收</p>
<p>RSet：记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）</p>
<p><strong>YoungGC</strong></p>
<ul>
<li>新独享进入Eden区</li>
<li>存活对象拷贝到s区</li>
<li>存活时间达到年龄阈值时，对象晋升到old区</li>
</ul>
<p><strong>mixedGC</strong></p>
<p>没有full gc</p>
<ul>
<li>不是FullGC，回收所有的Young和部分Old</li>
<li>global concurrent marking</li>
</ul>
<p><strong>global concurrent marking</strong></p>
<ol>
<li>Initial marking phase：标记GC Root ，STW</li>
<li>Root region scanning phase：标记存活Region</li>
<li>Concurrent marking phase：标记存活的对象</li>
<li>Remark phase：重新标记 STW</li>
<li>Cleanup phase：部分STW</li>
</ol>
<p><strong>MixedGC时机</strong></p>
<ul>
<li>InitiatingHeapOccupancyPercent: 堆占有率达到这个数值则触发global concurrent marking，默认45%</li>
<li>G1HeapWastePercent：在gloabl concurrent marking结束之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生MixedGC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生MixedGC</li>
<li>G1MixedGCLiveThresholdPercent: Old区的region被回收时候的存活对象占比</li>
<li>G1MixedGCCountTarget：一次global concurrent marking之后，最多执行MixedGC的次数<br>![](_v_images/20200206214458093_401476294.png =473x)</li>
</ul>
<p>![](_v_images/20200206215456237_1513279165.png =412x)</p>
<p>![](_v_images/20200206215646888_1034094734.png =400x)</p>
<h3 id="调优最佳实践"><a href="#调优最佳实践" class="headerlink" title="调优最佳实践"></a>调优最佳实践</h3><p>![](_v_images/20200206220804596_445039167.png =408x)</p>
<p>![](_v_images/20200206220825238_87737268.png =427x)</p>
<p>![](_v_images/20200206221006981_1426481434.png =384x)</p>
<h2 id="可视化GC日志分析工具"><a href="#可视化GC日志分析工具" class="headerlink" title="可视化GC日志分析工具"></a>可视化GC日志分析工具</h2><p>![](_v_images/20200206222823823_366026130.png =490x)</p>
<p>吞吐量与延迟时间的权衡</p>
<h2 id="Tomcat调优实例"><a href="#Tomcat调优实例" class="headerlink" title="Tomcat调优实例"></a>Tomcat调优实例</h2><p><a href="https://blog.csdn.net/zqz_zqz/article/details/70568819">CMS垃圾回收器详解</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
        <tag>GC</tag>
        <tag>tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>CMS GC</title>
    <url>/Java/metric/02_CMS_GC/</url>
    <content><![CDATA[<h1 id="CMS-GC"><a href="#CMS-GC" class="headerlink" title="CMS GC"></a>CMS GC</h1><h2 id="垃圾回收器组合"><a href="#垃圾回收器组合" class="headerlink" title="垃圾回收器组合"></a>垃圾回收器组合</h2><table>
<thead>
<tr>
<th>Young 年轻代</th>
<th>Tenured 老生代</th>
<th>JVM options</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Serial</td>
<td>Serial</td>
<td>-XX:+UseSerialGC</td>
<td>单线程回收，全程STW</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>Serial</td>
<td>-XX:+UseParallelGC -XX:-UseParallelOldGC</td>
<td>年轻代并行，老年代串行，全程STW</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>Parallel Old</td>
<td>-XX:+UseParallelGC -XX:+UseParallelOldGC</td>
<td>多线程回收，全程STW</td>
</tr>
<tr>
<td>Parallel New或Serial</td>
<td>CMS</td>
<td>-XX:+UseParNewGC -XX:+UseConcMarkSweepGC</td>
<td>年轻代并行或串行，老年代并发，只有某个阶段会STW</td>
</tr>
<tr>
<td>G1</td>
<td>G1</td>
<td>-XX:+UseG1GC</td>
<td>并发回收， 某个阶段会STW</td>
</tr>
</tbody></table>
<p>垃圾回收器从线程运行情况分类有三种：</p>
<ul>
<li><code>串行回收</code>： Serial回收器，单线程回收，全程STW；</li>
<li><code>并行回收</code>： 名称以Parallel开头的回收器，多线程回收，全程STW;</li>
<li><code>并发回收</code>： CMS与G1，多线程分阶段回收，只有某阶段会STW；</li>
</ul>
<p><img src="_v_images/20200716125314502_95470953.png"></p>
<h2 id="Minor-GC、Major-GC与Full-GC"><a href="#Minor-GC、Major-GC与Full-GC" class="headerlink" title="Minor GC、Major GC与Full GC"></a>Minor GC、Major GC与Full GC</h2><p>分代回收中:</p>
<p>Minor GC清理年轻代(Young GC)，除了G1 GC外，都会STW<br>Major GC清理老年代(Tenured GC)<br>Full GC清理整个堆</p>
<p>Minor GC触发条件:</p>
<p>Major GC触发条件:</p>
<p>Full GC触发条件:</p>
<ul>
<li>调用<code>System.gc</code>时，系统建议执行Full GC，不是必然执行</li>
<li>老年代空间不足</li>
<li>方法区空间不足</li>
<li>通过Minor GC后，进入老年代的平均大小 &gt; 老年代的可用内存</li>
<li>由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。即老年代无法存放新年代过度到老年代的对象的时候，会触发Full GC</li>
<li>手动触发Full GC: jmap -histo:live <pid> 或者 jmap -dump:live,file=dump_001.bin PID,然后删掉dump_001.bin文件</li>
</ul>
<h2 id="CMS垃圾收集器-Concurrent-Mark-Sweep-CMS-Collector"><a href="#CMS垃圾收集器-Concurrent-Mark-Sweep-CMS-Collector" class="headerlink" title="CMS垃圾收集器 Concurrent Mark Sweep(CMS) Collector"></a>CMS垃圾收集器 Concurrent Mark Sweep(CMS) Collector</h2><p>并发，低停顿<br>特别是拥有大量长期数据（大老年代），多核心，低停顿</p>
<p>启用<code>-XX:+UseConcMarkSweepGC</code></p>
<p>CMS收集器是分代的。 因此，minor GC和major GC都会发生。 CMS收集器尝试通过使用单独的垃圾收集器线程在执行应用程序线程的同时跟踪可访问对象，来减少由于major GC而导致的暂停时间。 在每个major收集周期中，CMS收集器会在收集开始时暂停所有应用程序线程一小段时间，然后收集中间再暂停一次。 第二次停顿往往是两个停顿中较长的一个。 在两个暂停期间都使用多个线程来执行收集工作。 收集的其余部分（包括大部分活动对象的跟踪和无法访问对象的清除）是通过与应用程序同时运行的一个或多个垃圾收集器线程来完成的。minor GC可以与正在进行的主要周期交错，并在一个 类似于并行收集器的方式（特别是在次要收集期间停止了应用程序线程）。</p>
<p><strong>并发模式失效Concurrent Mode Failure</strong></p>
<ol>
<li>如果CMS收集器在老年代填满之前无法完成回收无法访问的对象，</li>
<li>如果老年代的可用空闲空间块(出现了碎片)无法满足分配，则暂停应用程序，并使所有应用程序线程已停止。 无法同时完成收集的情况称为并发模式失败，代表需要调整CMS收集器参数。</li>
<li>如果并发收集被显式垃圾收集（<code>System.gc()</code>）中断</li>
<li>为提供诊断工具信息所需的垃圾收集中断了，则将报告并发模式中断。</li>
</ol>
<blockquote>
<p>if the CMS collector is unable to finish reclaiming the unreachable objects before the tenured generation fills up, or if an allocation cannot be satisfied with the available free space blocks in the tenured generation, then the application is paused and the collection is completed with all the application threads stopped. The inability to complete a collection concurrently is referred to as concurrent mode failure and indicates the need to adjust the CMS collector parameters. If a concurrent collection is interrupted by an explicit garbage collection (System.gc()) or for a garbage collection needed to provide information for diagnostic tools, then a concurrent mode interruption is reported.</p>
</blockquote>
<p><strong>Excessive GC Time and OutOfMemoryError</strong></p>
<p>太多的时间花在gc上: 如果总时间的98%花在GC上，并且回收不到2%的堆空间，将抛出<code>OutOfMemoryError</code></p>
<p>禁用命令行: <code>-XX:-UseGCOverheadLimit</code></p>
<p><strong>浮动垃圾Floating Garbage</strong></p>
<p>边收集边运行，出现浮动垃圾</p>
<h2 id="CMS垃圾回收特点"><a href="#CMS垃圾回收特点" class="headerlink" title="CMS垃圾回收特点"></a>CMS垃圾回收特点</h2><p>CMS只会回收老年代和永久代（1.8开始为元数据区，需要设置CMSClassUnloadingEnabled），不会收集年轻代；</p>
<p>CMS是一种预处理垃圾回收器，它不能等到老年代内存用尽时回收，需要在内存用尽前，完成回收操作，否则会导致并发回收失败(并发回收降级)；<br>所以CMS垃圾回收器开始执行回收操作，有一个触发阈值(<code>参数名称</code>)，默认是老年代或永久代达到92%；</p>
<h2 id="CMS垃圾收集器步骤"><a href="#CMS垃圾收集器步骤" class="headerlink" title="CMS垃圾收集器步骤"></a>CMS垃圾收集器步骤</h2><p>CMS 处理过程有七个步骤：</p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>是否STW</th>
<th>详情</th>
</tr>
</thead>
<tbody><tr>
<td>初始标记(CMS-initial-mark)</td>
<td>会导致STW</td>
<td>标记GCRoot和被年轻代引用的老年代对象</td>
</tr>
<tr>
<td>并发标记(CMS-concurrent-mark)</td>
<td>与用户线程同时运行；</td>
<td>扫描整个老年代，将引用关系变化的对象置为dirty</td>
</tr>
<tr>
<td>预清理（CMS-concurrent-preclean）</td>
<td>与用户线程同时运行；</td>
<td></td>
</tr>
<tr>
<td>可被终止的预清理（CMS-concurrent-abortable-preclean）</td>
<td>与用户线程同时运行；</td>
<td></td>
</tr>
<tr>
<td>重新标记(CMS-remark)</td>
<td>会导致STW</td>
<td></td>
</tr>
<tr>
<td>并发清除(CMS-concurrent-sweep)</td>
<td>与用户线程同时运行；</td>
<td></td>
</tr>
<tr>
<td>并发重置状态等待下次CMS的触发(CMS-concurrent-reset)</td>
<td>与用户线程同时运行；</td>
<td></td>
</tr>
</tbody></table>
<p>CMS运行流程图如下所示：</p>
<p><img src="_v_images/20200208214054081_1122407096.png"></p>
<h3 id="Phase-1-Initial-Mark（初始化标记）"><a href="#Phase-1-Initial-Mark（初始化标记）" class="headerlink" title="Phase 1: Initial Mark（初始化标记）"></a>Phase 1: Initial Mark（初始化标记）</h3><p>这是CMS中两次stop-the-world事件中的一次。这一步的作用是标记存活的对象，有两部分：</p>
<ol>
<li>从GC Roots遍历可直达的老年代对象，下图中1；</li>
<li>遍历被新生代存活对象所引用的老年代对象，如下图节点2、3；</li>
</ol>
<ul>
<li>支持单线程或并发标记</li>
<li>发生STW</li>
</ul>
<p><img src="_v_images/20200208214053938_762753439.png"></p>
<p>在Java语言里，可作为GC Roots对象的包括如下几种：</p>
<ol>
<li>虚拟机栈(栈桢中的本地变量表)中的引用的对象 ；</li>
<li>方法区中的类静态属性引用的对象 ；</li>
<li>方法区中的常量引用的对象 ；</li>
<li>本地方法栈中JNI的引用的对象；</li>
</ol>
<blockquote>
<p>ps：为了加快此阶段处理速度，减少停顿时间:</p>
<ul>
<li>开启并行化初始标记: <code>-XX:+CMSParallelInitialMarkEnabled</code></li>
<li>同时调大并行标记的线程数，线程数不要超过cpu的核数: <code>-XX:ConcGCThreads=4</code></li>
</ul>
</blockquote>
<h3 id="Phase-2-Concurrent-Mark（并发标记）"><a href="#Phase-2-Concurrent-Mark（并发标记）" class="headerlink" title="Phase 2: Concurrent Mark（并发标记）"></a>Phase 2: Concurrent Mark（并发标记）</h3><p>通过遍历第一个阶段（Initial Mark）标记出来的存活对象，继续递归遍历老年代，并标记可直接或间接到达的所有老年代存活对象。</p>
<p>由于应用线程和GC线程是并发执行的，因此可能产生新的对象或对象关系发生变化，例如：</p>
<ul>
<li>新生代的对象晋升到老年代；</li>
<li>直接在老年代分配对象；</li>
<li>老年代对象的引用关系发生变更；</li>
<li>等等。</li>
</ul>
<p>对于这些对象，需要重新标记以防止被遗漏。为了提高重新标记的效率，本阶段只会把发生变化的对象所在的Card标识为Dirty，这样后续就只需要扫描这些Dirty Card的对象，从而避免扫描整个老年代。</p>
<p>并发标记阶段只负责将引用发生改变的Card标记为Dirty状态，不负责处理；</p>
<p>如下图所示，也就是节点1、2、3，最终找到了节点4和5。并不是老年代的所有存活对象都会被标记，因为标记的同时应用程序会改变一些对象的引用等。</p>
<p><img src="_v_images/20200208214053815_1244593749.png"></p>
<p>这个阶段因为是并发的, 容易导致concurrent mode failure</p>
<h3 id="Phase-3-Concurrent-Preclean（并发预清理）"><a href="#Phase-3-Concurrent-Preclean（并发预清理）" class="headerlink" title="Phase 3: Concurrent Preclean（并发预清理）"></a>Phase 3: Concurrent Preclean（并发预清理）</h3><p>在并发预清洗阶段，将会重新扫描前一个阶段标记的Dirty对象，并标记被Dirty对象直接或间接引用的对象，然后清除Card标识。</p>
<p>前一个阶段已经说明，不能标记出老年代全部的存活对象，是因为标记的同时应用程序会改变一些对象引用，这个阶段就是用来处理前一个阶段因为引用关系改变导致没有标记到的存活对象的，它会扫描所有标记为Direty的Card</p>
<p>如下图所示，在并发清理阶段，节点3的引用指向了6；则会把节点3的card标记为Dirty；</p>
<p><img src="_v_images/20200208214053691_1851185723.png"></p>
<p>最后将6标记为存活,如下图所示：</p>
<p><img src="_v_images/20200208214053551_1708409185.png"></p>
<h3 id="Phase-4-Concurrent-Abortable-Preclean（可中止的并发预清理）"><a href="#Phase-4-Concurrent-Abortable-Preclean（可中止的并发预清理）" class="headerlink" title="Phase 4: Concurrent Abortable Preclean（可中止的并发预清理）"></a>Phase 4: Concurrent Abortable Preclean（可中止的并发预清理）</h3><p>本阶段尽可能承担更多的并发预处理工作，从而减轻在Final Remark阶段的stop-the-world。</p>
<p>这个阶段尝试着去承担下一个阶段Final Remark阶段足够多的工作。这个阶段持续的时间依赖好多的因素，由于这个阶段是重复的做相同的事情直到发生abort的条件（比如：重复的次数、多少量的工作、持续的时间等等）之一才会停止。</p>
<p>ps:此阶段最大持续时间为5秒，之所以可以持续5秒，另外一个原因也是为了期待这5秒内能够发生一次ygc，清理年轻代的引用，是的下个阶段的重新标记阶段，扫描年轻代指向老年代的引用的时间减少；</p>
<p>在该阶段，主要循环的做两件事：</p>
<ul>
<li>处理 From 和 To 区的对象，标记可达的老年代对象；</li>
<li>和上一个阶段一样，扫描处理Dirty Card中的对象。</li>
</ul>
<p>具体执行多久，取决于许多因素，满足其中一个条件将会中止运行：</p>
<ul>
<li>执行循环次数达到了阈值；</li>
<li>执行时间达到了阈值；</li>
<li>新生代Eden区的内存使用率达到了阈值。</li>
</ul>
<h3 id="Phase-5-Final-Remark（重新标记）"><a href="#Phase-5-Final-Remark（重新标记）" class="headerlink" title="Phase 5: Final Remark（重新标记）"></a>Phase 5: Final Remark（重新标记）</h3><p>预清理阶段也是并发执行的，并不一定是所有存活对象都会被标记，因为在并发标记的过程中对象及其引用关系还在不断变化中。</p>
<p>因此，需要有一个stop-the-world的阶段来完成最后的标记工作，这就是重新标记阶段（CMS标记阶段的最后一个阶段）。主要目的是重新扫描之前并发处理阶段的所有残留更新对象。</p>
<p>主要工作：</p>
<p>遍历新生代对象，重新标记；（新生代会被分块，多线程扫描）<br>根据GC Roots，重新标记；<br>遍历老年代的Dirty Card，重新标记。这里的Dirty Card，大部分已经在Preclean阶段被处理过了。</p>
<p>这个阶段会导致第二次stop the world，该阶段的任务是完成标记整个年老代的所有的存活对象。</p>
<p>这个阶段，重新标记的内存范围是整个堆，包含young_gen和old_gen。为什么要扫描新生代呢，因为对于老年代中的对象，如果被新生代中的对象引用，那么就会被视为存活对象，即使新生代的对象已经不可达了，也会使用这些不可达的对象当做CMS的“gc root”，来扫描老年代； 因此对于老年代来说，引用了老年代中对象的新生代的对象，也会被老年代视作“GC ROOTS”:<br>当此阶段耗时较长的时候，可以加入参数<code>-XX:+CMSScavengeBeforeRemark</code>，在重新标记之前，先执行一次ygc，回收掉年轻代的对象无用的对象，并将对象放入survivor区或晋升到老年代，这样再进行年轻代扫描时，只需要扫描幸存区的对象即可，一般survivor区非常小，这大大减少了扫描时间</p>
<p>由于之前的预处理阶段是与用户线程并发执行的，这时候可能年轻代的对象对老年代的引用已经发生了很多改变，这个时候，remark阶段要花很多时间处理这些改变，会导致很长stop the word，所以通常CMS尽量运行Final Remark阶段在年轻代是足够干净的时候。</p>
<p>另外，还可以开启并行收集：<code>-XX:+CMSParallelRemarkEnabled</code></p>
<h3 id="Phase-6-Concurrent-Sweep（并发清理"><a href="#Phase-6-Concurrent-Sweep（并发清理" class="headerlink" title="Phase 6: Concurrent Sweep（并发清理"></a>Phase 6: Concurrent Sweep（并发清理</h3><p>并发清理阶段，主要工作是清理所有未被标记的死亡对象，回收被占用的空间。</p>
<p><img src="_v_images/20200209233712414_1450669107.png"></p>
<p>通过以上5个阶段的标记，老年代所有存活的对象已经被标记并且现在要通过Garbage Collector采用清扫的方式回收那些不能用的对象了。</p>
<p>这个阶段主要是清除那些没有标记的对象并且回收空间；</p>
<p>由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。</p>
<h3 id="步骤7-并发重置"><a href="#步骤7-并发重置" class="headerlink" title="步骤7: 并发重置"></a>步骤7: 并发重置</h3><p>并发重置阶段，将清理并恢复在CMS GC过程中的各种状态，重新初始化CMS相关数据结构，为下一个垃圾收集周期做好准备。</p>
<p>这个阶段并发执行，重新设置CMS算法内部的数据结构，准备下一个CMS生命周期的使用。</p>
<h2 id="CMS日志分析"><a href="#CMS日志分析" class="headerlink" title="CMS日志分析"></a>CMS日志分析</h2><p>下面就是该参数设置打印出来的gc信息，一些非关键的信息已经去掉，如时间：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//第一步 初始标记 这一步会停顿*</span></span><br><span class="line">[GC (CMS Initial Mark) [<span class="number">1</span> CMS-initial-mark: 299570K(307200K)] 323315K(491520K), <span class="number">0.0026208</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.00</span> secs]</span><br><span class="line">vmop [threads: total initially_running wait_to_block] [time: spin block sync cleanup vmop] page_trap_count</span><br><span class="line"><span class="number">0.345</span>: CMS_Initial_Mark [ <span class="number">10</span> <span class="number">0</span> <span class="number">1</span> ] [ <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> ] <span class="number">0</span></span><br><span class="line">Total time <span class="keyword">for</span> which application threads were stopped: <span class="number">0.0028494</span> seconds</span><br><span class="line"></span><br><span class="line"><span class="comment">//第二步 并发标记</span></span><br><span class="line">[CMS-concurrent-mark-start]</span><br><span class="line">[CMS-concurrent-mark: <span class="number">0.012</span>/<span class="number">0.012</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.01</span> secs]</span><br><span class="line"></span><br><span class="line"><span class="comment">//第三步 并发预清理</span></span><br><span class="line">[CMS-concurrent-preclean-start]</span><br><span class="line">[CMS-concurrent-preclean: <span class="number">0.001</span>/<span class="number">0.001</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.00</span> secs]</span><br><span class="line"></span><br><span class="line"><span class="comment">//第四步 可被终止的并发预清理</span></span><br><span class="line">[CMS-concurrent-abortable-preclean-start]</span><br><span class="line">[CMS-concurrent-abortable-preclean: <span class="number">0.000</span>/<span class="number">0.000</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.00</span> secs]</span><br><span class="line"></span><br><span class="line"><span class="comment">//第五步 最终重新标记</span></span><br><span class="line">[GC (CMS Final Remark) [YG occupancy: 72704 K (184320 K)][Rescan (parallel) , 0.0009069 secs][weak refs processing, 0.0000083 secs][class unloading, 0.0002626 secs][scrub symbol table, 0.0003789 secs][scrub string table, 0.0001326 secs][1 CMS-remark: 299570K(307200K)] 372275K(491520K), 0.0017842 secs] [Times: user=0.05 sys=0.00, real=0.00 secs]</span><br><span class="line">vmop [threads: total initially_running wait_to_block] [time: spin block sync cleanup vmop] page_trap_count</span><br><span class="line"><span class="number">0.360</span>: CMS_Final_Remark [ <span class="number">10</span> <span class="number">0</span> <span class="number">1</span> ] [ <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> ] <span class="number">0</span></span><br><span class="line">Total time <span class="keyword">for</span> which application threads were stopped: <span class="number">0.0018800</span> seconds</span><br><span class="line"></span><br><span class="line"><span class="comment">//第六步 并发清理</span></span><br><span class="line">[CMS-concurrent-sweep-start]</span><br><span class="line">[CMS-concurrent-sweep: <span class="number">0.007</span>/<span class="number">0.007</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.01</span> secs]</span><br><span class="line"></span><br><span class="line"><span class="comment">//第七步 并发重置</span></span><br><span class="line">[CMS-concurrent-reset-start]</span><br><span class="line">[CMS-concurrent-reset: <span class="number">0.002</span>/<span class="number">0.002</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.00</span> secs]</span><br></pre></td></tr></table></figure>
<p>输出GC详情，需要添加 <code>-verbose:gc</code> 和 <code>-XX:+PrintGCDetails</code> 参数</p>
<p><code>CMS-initial-mark</code>标示着并发收集周期的开始<br><code>CMS-concurrent-mark</code>标示着并发标记阶段的结束<br><code>CMS-concurrent-sweep</code>标志着并发清理阶段的结束<br><code>CMS-concurrent-preclean</code>标志着预清理阶段，预清理代表着在准备CMS-remark阶段可以并发处理的工作<br><code>CMS-concurrent-reset</code>是最后阶段，为下一次并发收集做准备</p>
<blockquote>
<p>CMS-initial-mark indicates the start of the concurrent collection cycle,<br>CMS-concurrent-mark indicates the end of the concurrent marking phase,<br>and CMS-concurrent-sweep marks the end of the concurrent sweeping phase.<br>Not discussed previously is the precleaning phase indicated by CMS-concurrent-preclean.<br>Precleaning represents work that can be done concurrently in preparation for the remark phase CMS-remark.<br>The final phase is indicated by CMS-concurrent-reset and is in preparation for the next concurrent collection.</p>
</blockquote>
<h2 id="调优参数与启用参数"><a href="#调优参数与启用参数" class="headerlink" title="调优参数与启用参数"></a>调优参数与启用参数</h2><p>下面抓取一下gc信息，来进行详细分析，首先将jvm中加入以下运行参数：</p>
<ul>
<li>-XX:+PrintCommandLineFlags [0]</li>
<li>-XX:+UseConcMarkSweepGC [1]</li>
<li>-XX:+UseCMSInitiatingOccupancyOnly [2]</li>
<li>-XX:CMSInitiatingOccupancyFraction=80 [3]</li>
<li>-XX:+CMSClassUnloadingEnabled [4]</li>
<li>-XX:+UseParNewGC [5]</li>
<li>-XX:+CMSParallelRemarkEnabled [6]</li>
<li>-XX:+CMSScavengeBeforeRemark [7]</li>
<li>-XX:+UseCMSCompactAtFullCollection [8]</li>
<li>-XX:CMSFullGCsBeforeCompaction=0 [9]</li>
<li>-XX:+CMSConcurrentMTEnabled [10]</li>
<li>-XX:ConcGCThreads=4 [11]</li>
<li>-XX:+ExplicitGCInvokesConcurrent [12]</li>
<li>-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses [13]</li>
<li>-XX:+CMSParallelInitialMarkEnabled [14]</li>
<li>-XX:+PrintGCDetails [15]</li>
<li>-XX:+PrintGCCause [16]</li>
<li>-XX:+PrintGCTimeStamps [17]</li>
<li>-XX:+PrintGCDateStamps [18]</li>
<li>-Xloggc:../logs/gc.log [19]</li>
<li>-XX:+HeapDumpOnOutOfMemoryError [20]</li>
<li>-XX:HeapDumpPath=../dump [21]</li>
</ul>
<p>先来介绍下下面几个参数的作用：</p>
<p>[0] 打印出启动参数行</p>
<p>[1] 参数指定使用CMS垃圾回收器；</p>
<p>[2]、[3] 参数指定CMS垃圾回收器在老年代达到80%的时候开始工作，如果不指定那么默认的值为92%；</p>
<p>[4] 开启永久代（jdk1.8以下版本）或元数据区（jdk1.8及其以上版本）收集，如果没有设置这个标志，一旦永久代或元数据区间也会尝试进行垃圾回收，但是收集不会是并行的，而再一次进行Full GC；</p>
<p>[5] 使用CMS时默认这个参数就是打开的，不需要配置，CMS只回收老年代，年轻代只能配合Parallel New或Serial回收器；</p>
<p>[6] 减少Remark阶段暂停的时间，启用并行Remark，如果Remark阶段暂停时间长，可以启用这个参数</p>
<p>[7] 如果Remark阶段暂停时间太长，可以启用这个参数，在Remark执行之前，先做一次ygc。因为这个阶段，年轻代也是CMS的gcroot，CMS会扫描年轻代指向老年代对象的引用，如果年轻代有大量引用需要被扫描，会让Remark阶段耗时增加；</p>
<p>[8]、[9]两个参数是针对CMS垃圾回收器碎片做优化的，CMS是不会移动内存的， 运行时间长了，会产生很多内存碎片， 导致没有一段连续区域可以存放大对象，出现”promotion failed”、”concurrent mode failure”, 导致fullgc，启用UseCMSCompactAtFullCollection 在FULL GC的时候， 对年老代的内存进行压缩。-XX:CMSFullGCsBeforeCompaction=0 则是代表多少次FGC后对老年代做压缩操作，默认值为0，代表每次都压缩, 把对象移动到内存的最左边，可能会影响性能,但是可以消除碎片；</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">106.641</span>: [GC <span class="number">106.641</span>: [ParNew (promotion failed): 14784K-&gt;14784K(14784K), <span class="number">0.0370328</span> secs]<span class="number">106.678</span>: [CMS106<span class="number">.715</span>: [CMS-concurrent-mark: <span class="number">0.065</span>/<span class="number">0.103</span> secs] [Times: user=<span class="number">0.17</span> sys=<span class="number">0.00</span>, real=<span class="number">0.11</span> secs]</span><br><span class="line"></span><br><span class="line">(concurrent mode failure): 41568K-&gt;27787K(49152K), <span class="number">0.2128504</span> secs] 52402K-&gt;27787K(63936K), [CMS Perm : 2086K-&gt;2086K(12288K)], <span class="number">0.2499776</span> secs] [Times: user=<span class="number">0.28</span> sys=<span class="number">0.00</span>, real=<span class="number">0.25</span> secs]</span><br></pre></td></tr></table></figure>
<p>[11] 定义并发CMS过程运行时的线程数。比如value=4意味着CMS周期的所有阶段都以4个线程来执行。尽管更多的线程会加快并发CMS过程，但其也会带来额外的同步开销。因此，对于特定的应用程序，应该通过测试来判断增加CMS线程数是否真的能够带来性能的提升。如果未设置这个参数，JVM会根据并行收集器中的-XX:ParallelGCThreads参数的值来计算出默认的并行CMS线程数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ParallelGCThreads = (ncpus &lt;=<span class="number">8</span> ? ncpus : <span class="number">8</span>+(ncpus-<span class="number">8</span>)*<span class="number">5</span>/<span class="number">8</span>) ，ncpus为cpu个数，</span><br><span class="line">ConcGCThreads =(ParallelGCThreads + <span class="number">3</span>)/<span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>这个参数一般不要自己设置，使用默认就好，除非发现默认的参数有调整的必要；<br>[12]、[13]开启foreground CMS GC，CMS gc 有两种模式，background和foreground，正常的CMS gc使用background模式，就是我们平时说的CMS gc；当并发收集失败或者调用了System.gc()的时候，就会导致一次full gc，这个fullgc是不是CMS回收，而是Serial单线程回收器，加入了参数[12]后，执行full gc的时候，就变成了CMS foreground gc，它是并行full gc，只会执行CMS中stop the world阶段的操作，效率比单线程Serial full GC要高；需要注意的是它只会回收old，因为CMS收集器是老年代收集器；而正常的Serial收集是包含整个堆的，加入了参数[13],代表永久代也会被CMS收集；</p>
<p>[14] 开启初始标记过程中的并行化，进一步提升初始化标记效率;</p>
<p>[15]、[16]、[17]、[18] 、[19]是打印gc日志，其中[16]在jdk1.8之后无需设置</p>
<p>[20]、[21]则是内存溢出时dump堆</p>
<h2 id="CMS需要注意的问题"><a href="#CMS需要注意的问题" class="headerlink" title="CMS需要注意的问题"></a>CMS需要注意的问题</h2><h3 id="CMS不是full-GC"><a href="#CMS不是full-GC" class="headerlink" title="CMS不是full GC"></a>CMS不是full GC</h3><p>有一点需要注意的是：CMS并发GC不是“full GC”。HotSpot VM里对concurrent collection和full collection有明确的区分。所有带有“FullCollection”字样的VM参数都是跟真正的full GC相关，而跟CMS并发GC无关的，CMS收集算法只是清理老年代。</p>
<h3 id="减少remark阶段停顿"><a href="#减少remark阶段停顿" class="headerlink" title="减少remark阶段停顿"></a>减少remark阶段停顿</h3><p>一般CMS的GC耗时 80%都在remark阶段，如果发现remark阶段停顿时间很长，可以尝试添加该参数：</p>
<p>-XX:+CMSScavengeBeforeRemark</p>
<p>在执行remark操作之前先做一次ygc，目的在于减少ygen对oldgen的无效引用，降低remark时的开销，如果添加该参数后 ”ygc停顿时间+remark时间&lt;添加该参数之前的remark时间“,说明该参数是有效的；</p>
<h3 id="内存碎片"><a href="#内存碎片" class="headerlink" title="内存碎片"></a>内存碎片</h3><p>CMS是基于标记-清除算法的，只会将标记为为存活的对象删除，并不会移动对象整理内存空间，会造成内存碎片，这时候我们需要用到这个参数;</p>
<p>-XX:CMSFullGCsBeforeCompaction=n</p>
<p>这个参数大部分人的使用方式都是错误的，往往会导致设置后问题更大。</p>
<p>CMSFullGCsBeforeCompaction这个参数在HotSpot VM里是这样声明的：</p>
<p>product(bool, UseCMSCompactAtFullCollection, true, \</p>
<p>“Use mark sweep compact at full collections”) \</p>
<p>\</p>
<p>product(uintx, CMSFullGCsBeforeCompaction, 0, \</p>
<p>“Number of CMS full collection done before compaction if &gt; 0”) \</p>
<p>然后这样使用的：</p>
<p>*should_compact =</p>
<p>UseCMSCompactAtFullCollection &amp;&amp;</p>
<p>((_full_gcs_since_conc_gc &gt;= CMSFullGCsBeforeCompaction) ||</p>
<p>GCCause::is_user_requested_gc(gch-&gt;gc_cause()) ||</p>
<p>gch-&gt;incremental_collection_will_fail(true <em>/\</em> consult_young <em>/</em>));</p>
<p>CMS GC要决定是否在full GC时做压缩，会依赖几个条件。其中，</p>
<ol>
<li><p>UseCMSCompactAtFullCollection 与 CMSFullGCsBeforeCompaction 是搭配使用的；前者目前默认就是true了，也就是关键在后者上。</p>
</li>
<li><p>用户调用了System.gc()，而且DisableExplicitGC没有开启。</p>
</li>
<li><p>young gen报告接下来如果做增量收集会失败；简单来说也就是young gen预计old gen没有足够空间来容纳下次young GC晋升的对象。</p>
</li>
</ol>
<p>上述三种条件的任意一种成立都会让CMS决定这次做full GC时要做压缩。</p>
<p>CMSFullGCsBeforeCompaction 说的是，在上一次CMS并发GC执行过后，到底还要再执行多少次full GC才会做压缩。默认是0，也就是在默认配置下每次CMS GC顶不住了而要转入full GC的时候都会做压缩。 如果把CMSFullGCsBeforeCompaction配置为10，就会让上面说的第一个条件变成每隔10次真正的full GC才做一次压缩（而不是每10次CMS并发GC就做一次压缩，目前VM里没有这样的参数）。这会使full GC更少做压缩，也就更容易使CMS的old gen受碎片化问题的困扰。 本来这个参数就是用来配置降低full GC压缩的频率，以期减少某些full GC的暂停时间。CMS回退到full GC时用的算法是mark-sweep-compact，但compaction是可选的，不做的话碎片化会严重些但这次full GC的暂停时间会短些；这是个取舍。</p>
<h3 id="concurrent-mode-failure"><a href="#concurrent-mode-failure" class="headerlink" title="concurrent mode failure"></a>concurrent mode failure</h3><p>这个异常发生在CMS正在回收的时候。执行CMS GC的过程中，同时业务线程也在运行，当年轻代空间满了，执行ygc时，需要将存活的对象放入到老年代，而此时老年代空间不足，这时CMS还没有机会回收老年带产生的，或者在做Minor GC的时候，新生代救助空间放不下，需要放入老年代，而老年代也放不下而产生的。</p>
<p>设置CMS触发时机有两个参数：</p>
<p>-XX:+UseCMSInitiatingOccupancyOnly</p>
<p>-XX:CMSInitiatingOccupancyFraction=70</p>
<p>-XX:CMSInitiatingOccupancyFraction=70 是指设定CMS在对内存占用率达到70%的时候开始GC。</p>
<p>-XX:+UseCMSInitiatingOccupancyOnly如果不指定, 只是用设定的回收阈值CMSInitiatingOccupancyFraction,则JVM仅在第一次使用设定值,后续则自动调整会导致上面的那个参数不起作用。</p>
<p>为什么要有这两个参数？</p>
<p>由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。</p>
<p>CMS前五个阶段都是标记存活对象的，除了”初始标记”和”重新标记”阶段会stop the word ，其它三个阶段都是与用户线程一起跑的，就会出现这样的情况gc线程正在标记存活对象，用户线程同时向老年代提升新的对象，清理工作还没有开始，old gen已经没有空间容纳更多对象了，这时候就会导致concurrent mode failure， 然后就会使用串行收集器回收老年代的垃圾，导致停顿的时间非常长。</p>
<p>CMSInitiatingOccupancyFraction参数要设置一个合理的值，设置大了，会增加concurrent mode failure发生的频率，设置的小了，又会增加CMS频率，所以要根据应用的运行情况来选取一个合理的值。</p>
<p>如果发现这两个参数设置大了会导致fullgc，设置小了会导致频繁的CMSgc，说明你的老年代空间过小，应该增加老年代空间的大小了；</p>
<h3 id="promotion-failed"><a href="#promotion-failed" class="headerlink" title="promotion failed"></a>promotion failed</h3><p>这个异常发生在年轻代回收的时候；</p>
<p>在进行Minor GC时，Survivor Space放不下，对象只能放入老年代，而此时老年代也放不下造成的，多数是由于老年带有足够的空闲空间，但是由于碎片较多，新生代要转移到老年带的对象比较大,找不到一段连续区域存放这个对象导致的，以下是一段promotion failed的日志：</p>
<p>106.641: [GC 106.641: [ParNew (promotion failed): 14784K-&gt;14784K(14784K), 0.0370328 secs]106.678: [CMS106.715: [CMS-concurrent-mark: 0.065/0.103 secs] [Times: user=0.17 sys=0.00, real=0.11 secs]</p>
<p>(concurrent mode failure): 41568K-&gt;27787K(49152K), 0.2128504 secs] 52402K-&gt;27787K(63936K), [CMS Perm : 2086K-&gt;2086K(12288K)], 0.2499776 secs] [Times: user=0.28 sys=0.00, real=0.25 secs]</p>
<p><strong><em>过早提升与提升失败</em></strong></p>
<p>在 Minor GC 过程中，Survivor Unused 可能不足以容纳 Eden 和另一个 Survivor 中的存活对象， 那么多余的将被移到老年代， 称为过早提升（Premature Promotion）,这会导致老年代中短期存活对象的增长， 可能会引发严重的性能问题。 再进一步， 如果老年代满了， Minor GC 后会进行 Full GC， 这将导致遍历整个堆， 称为提升失败（Promotion Failure）。</p>
<p><strong><em>早提升的原因</em></strong></p>
<ol>
<li><p>Survivor空间太小，容纳不下全部的运行时短生命周期的对象，如果是这个原因，可以尝试将Survivor调大，否则端生命周期的对象提升过快，导致老年代很快就被占满，从而引起频繁的full gc；</p>
</li>
<li><p>对象太大，Survivor和Eden没有足够大的空间来存放这些大象；</p>
</li>
</ol>
<p><strong><em>提升失败原因</em></strong></p>
<p>当提升的时候，发现老年代也没有足够的连续空间来容纳该对象。</p>
<p>为什么是没有足够的连续空间而不是空闲空间呢？</p>
<p>老年代容纳不下提升的对象有两种情况：</p>
<ol>
<li><p>老年代空闲空间不够用了；</p>
</li>
<li><p>老年代虽然空闲空间很多，但是碎片太多，没有连续的空闲空间存放该对象；</p>
</li>
</ol>
<p><strong><em>解决方法</em></strong></p>
<ol>
<li><p>如果是因为内存碎片导致的大对象提升失败，CMS需要进行空间整理压缩；</p>
</li>
<li><p>如果是因为提升过快导致的，说明Survivor 空闲空间不足，那么可以尝试调大 Survivor；</p>
</li>
<li><p>如果是因为老年代空间不够导致的，尝试将CMS触发的阈值调低；</p>
</li>
</ol>
<h2 id="其它导致回收停顿时间变长原因"><a href="#其它导致回收停顿时间变长原因" class="headerlink" title="其它导致回收停顿时间变长原因"></a>其它导致回收停顿时间变长原因</h2><p>linux使用了swap，内存换入换出（vmstat），尤其是开启了大内存页的时候，因为swap只支持4k的内存页，大内存页的大小为2M，大内存页在swap的交换的时候需要先将swap中4k内存页合并成一个大内存页再放入内存或将大内存页切分为4k的内存页放入swap，合并和切分的操作会导致操作系统占用cup飙高，用户cpu占用反而很低；</p>
<p>除了swap交换外，网络io（netstat）、磁盘I/O （iostat）在 GC 过程中发生会使 GC 时间变长。</p>
<p>如果是以上原因，就要去查看gc日志中的Times耗时：</p>
<p>[Times: user=0.00 sys=0.00, real=0.00 secs]</p>
<p>user是用户线程占用的时间，sys是系统线程占用的时间，如果是io导致的问题，会有两种情况</p>
<ol>
<li>user与sys时间都非常小，但是real却很长，如下：</li>
</ol>
<p>[ Times: user=0.51 sys=0.10, real=5.00 secs ]</p>
<p>user+sys的时间远远小于real的值，这种情况说明停顿的时间并不是消耗在cup执行上了，不是cup肯定就是io导致的了，所以这时候要去检查系统的io情况。</p>
<p>sys时间很长，user时间很短，real几乎等于sys的时间，如下：</p>
<p>[ Times: user=0.11 sys=31.10, real=33.12 secs ]</p>
<p>这时候其中一种原因是开启了大内存页，还开启了swap，大内存进行swap交换时会有这种现象；</p>
<h2 id="增加线程数"><a href="#增加线程数" class="headerlink" title="增加线程数"></a>增加线程数</h2><p>CMS默认启动的回收线程数目是 (ParallelGCThreads + 3)/4) ，这里的ParallelGCThreads是年轻代的并行收集线程数，感觉有点怪怪的；</p>
<p>年轻代的并行收集线程数默认是(ncpus &lt;= 8) ? ncpus : 3 + ((ncpus * 5) / 8)，可以通过-XX:ParallelGCThreads= N 来调整；</p>
<p>如果要直接设定CMS回收线程数，可以通过-XX:ParallelCMSThreads=n，注意这个n不能超过cpu线程数，需要注意的是增加gc线程数，就会和应用争抢资源；</p>
<p>参考</p>
<p><a href="https://plumbr.eu/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep">https://plumbr.eu/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep</a></p>
<p><a href="http://www.infoq.com/cn/presentations/a-long-period-of-atypical-jvm-gc-caused-by-os/">http://www.infoq.com/cn/presentations/a-long-period-of-atypical-jvm-gc-caused-by-os/</a></p>
<p>GC Cause</p>
<p>Heap Inspection Initiated GC</p>
<p>因为执行了jmap -histo:live 触发的gc</p>
<p>![](_v_images/20200621105321510_162455977.png =546x)</p>
<p>![](_v_images/20200621105825309_1900989220.png =541x)</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://docs.oracle.com/javase/8/">Java 8 document</a></li>
<li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html">Java 8 CMS collector</a></li>
<li><a href="https://www.iteye.com/blog/zhanjia-2435266">Java之CMS GC的7个阶段</a></li>
</ul>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
      </tags>
  </entry>
  <entry>
    <title>大堆问题定位</title>
    <url>/Java/metric/03.%E5%A4%A7%E5%A0%86%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/</url>
    <content><![CDATA[<h1 id="03-大堆问题定位"><a href="#03-大堆问题定位" class="headerlink" title="03.大堆问题定位"></a>03.大堆问题定位</h1><ol>
<li>首先确定是内存问题，还是内存泄露。如果是内存问题，则可以通过JVM监控等手段，判断内存持续增长的区域；假设确定了是内存泄露，也可能是堆内或者堆外</li>
<li>堆内内存泄露的情况，最有效的手段莫过于Heap Dump，使用<code>jmap -heap $PID</code>、<code>jcmd</code>或者<code>HeapDumpOnOutOfMemoryError</code>等等手段都可以获取，使用MAT找超级powerful的机器分析；MAT 其实提供了分析脚本可以在不用 IDE 加载整个 HEAP 获取到需要的信息, 也就是通过脚本解析 HEAP 逐步分析, 具体可参考 <a href="https://www.techpaste.com/2015/07/how-to-analyse-large-heap-dumps">How to Analyse Large Heap Dumps</a>. PS: 曾经分析过 108G 的堆</li>
<li>实际生产中，这么大的堆，不管是dump对生产系统的影响，还是dump本身的难度，都往往不切实际，相对低成本的手段：</li>
<li><code>jmap -histo $PID</code>或<code>jmap -histo:live $PID</code>获得当前堆内对象的个数统计，并采样多次，查看一下里面object的分布，看哪类对象比较多，一般来说200G的堆，做一次<code>jmap -histo</code>可能要几十秒到一分钟，可能会触发full gc，如果使用 <code>CMS</code> 或 <code>G1</code> 的话, 可加入 <code>-XX:+ExplicitGCInvokesConcurrent</code> 使用并发收集器显式；如果不能探明的话, 只能使用 jmap 将整个堆 dump 下来。<br>所以如果有类似timeout killer的守护线程，要注意不要让它把进程kill掉</li>
<li>详细的GC日志等，比如判断引用堆积情况等，看看没有没什么异常， 比如有没有因为metaspace 满了而导致的GC。这种情况，可以看看是不是打开XX:+TraceClassLoading -XX:+TraceClassUnloading 分析下类加载情况。</li>
<li>使用Tencent JDK，可以利用old object sampling技术，不做Heap dump定位相当一部分memory leak</li>
<li>堆外内存： 确认下是否是 Java 的 direct bytebuffer 泄露, 由于采用 reference 机制回收, 如果一直没有触发 JVM GC 或回收线程偏少也会导致堆外内存回收缓慢导致泄露<br>如果是 Native 或者使用 Unsafe 方式直接向 OS 申请内存, 可通过 NMT以及 pmap 等查看, JDK 团队分享的 <a href="http://km.oa.com/group/42239/articles/show/404478?ts=1574932416">http://km.oa.com/group/42239/articles/show/404478?ts=1574932416</a> 可谓是面面俱到.</li>
</ol>
<h2 id="使用MAT命令行分析"><a href="#使用MAT命令行分析" class="headerlink" title="使用MAT命令行分析"></a>使用MAT命令行分析</h2><p><a href="https://www.techpaste.com/2015/07/how-to-analyse-large-heap-dumps">How to Analyse Large Heap Dumps</a></p>
<ol>
<li><p>下载MAT</p>
</li>
<li><p>到MAT的安装目录下，打开<code>MemoryAnalyzer.ini</code>，调整MAT的启动jvm参数</p>
 <figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">-Xms6144m</span></span><br><span class="line"><span class="attr">-Xmx8192m</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+UseConcMarkSweepGC</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+UseParNewGC</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+CMSParallelRemarkEnabled</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+CMSClassUnloadingEnabled</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+UseCMSInitiatingOccupancyOnly</span></span><br></pre></td></tr></table></figure>
<p> 堆最大大小调整为机器内存大小</p>
</li>
<li><p>dump文件所在文件夹，确保有dump文件两倍的空间</p>
</li>
<li><p>到MAT的安装目录下，使用root账户运行命令<br> For UNIX:</p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./ParseHeapDump.sh /opt/heap_dump/jvm.hprof org.eclipse.mat.api:suspects</span><br><span class="line">./ParseHeapDump.sh /opt/heap_dump/jvm.hprof org.eclipse.mat.api:overview</span><br><span class="line">./ParseHeapDump.sh /opt/heap_dump/jvm.hprof org.eclipse.mat.api:top_components</span><br></pre></td></tr></table></figure>
<p> For Windows:</p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ParseHeapDump.bat D:\heap_dump\jvm.hprof org.eclipse.mat.api:suspects</span><br><span class="line">ParseHeapDump.bat D:\heap_dump\jvm.hprof org.eclipse.mat.api:overview</span><br><span class="line">ParseHeapDump.bat D:\heap_dump\jvm.hprof org.eclipse.mat.api:top_components</span><br></pre></td></tr></table></figure></li>
<li><p>使用MAT打开生成的分析结果文件</p>
</li>
</ol>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
      </tags>
  </entry>
  <entry>
    <title>Java G1 GC</title>
    <url>/Java/metric/03_G1_GC/</url>
    <content><![CDATA[<h1 id="1-03-G1-GC"><a href="#1-03-G1-GC" class="headerlink" title="1. 03_G1_GC"></a>1. 03_G1_GC</h1><h2 id="1-1-堆内存分配"><a href="#1-1-堆内存分配" class="headerlink" title="1.1. 堆内存分配"></a>1.1. 堆内存分配</h2><p>整个堆分为若干的region，region的大小可以通过参数设置；</p>
<p>Region可以分为Eden、Survivor、Old、Humongous(专门存储大对象的Region：单个对象超过Region大小的50%，就是大对象；</p>
<p>如果大对象超过一个Region，则会继续申请连续的空间，作为Humongous区)和Free(空闲Region: Region的内存被释放后的分区)；Free Region后续可以作为Eden、Survivor、Old或Humongous分区；</p>
<p>堆分为新生代+老年代；</p>
<h2 id="1-2-两个Set"><a href="#1-2-两个Set" class="headerlink" title="1.2. 两个Set"></a>1.2. 两个Set</h2><ol>
<li><p>CSet: collection set, 待回收的Region集合</p>
</li>
<li><p>RSet: remembered set,引用当前Region集合的其他集合</p>
<p>引用当前Region的其他Region集合，是points-in的，每个 Region 都有一个 RSet；在 <code>JDK10</code> 中，只有部分 Region 才存在 RSet。</p>
<ul>
<li><strong>young gc</strong>：指向「Eden」和「Survivor」Region 的 「Old」和「Humongous」Region 集合，避免全堆扫描</li>
<li><strong>mixed gc</strong>：确定「Old」Region 之间的相关引用，确定 Region 的回收价值</li>
</ul>
</li>
</ol>
<h2 id="1-3-垃圾回收过程"><a href="#1-3-垃圾回收过程" class="headerlink" title="1.3. 垃圾回收过程"></a>1.3. 垃圾回收过程</h2><ol>
<li>young gc：标记-复制<ol>
<li>「新生代」的垃圾回收</li>
<li>CSet 中，只包含 Eden、Survivor</li>
</ol>
</li>
<li>mixed gc：标记-复制<ol>
<li>「新生代」和「部分老年代」的垃圾回收</li>
<li>CSet 中，包含 Eden、Survivor、部分 Old、Humongous</li>
</ol>
</li>
<li>full gc：<ol>
<li>G1 gc 失败，退化为 Serial 方式</li>
<li>单线程全堆扫描，对整个 Heap 进行垃圾回收，涵盖所有的「新生代」和「老年代」</li>
</ol>
</li>
</ol>
<blockquote>
<p>G1 垃圾收集器，GC 都是针对 CSet 进行的</p>
</blockquote>
<h3 id="1-3-1-Young-GC"><a href="#1-3-1-Young-GC" class="headerlink" title="1.3.1. Young GC"></a>1.3.1. Young GC</h3><p>Young GC，关键细节：</p>
<ul>
<li>针对「<strong>年轻代</strong>」的 Eden、Survivor 分区，进行 GC</li>
<li><strong>存活的对象</strong>，放置在 「新的 Survivor 分区」或「Old 分区」</li>
<li><strong>触发的时机</strong>：Eden 分区空间不足，无法为普通对象分配存储空间（非大对象）</li>
</ul>
<p><strong>Young GC 的执行过程</strong>：就是「标记-复制」算法</p>
<ol>
<li><strong>根扫描</strong></li>
<li><strong>确定</strong>「老年代」对「新生代」的<strong>引用</strong>，避免全堆扫描：<ol>
<li>根据 card table，扫描 dirty 部分，更新 RSet</li>
<li>新生代中，根据 RSet，确定 Old 对 Eden 和 Survivor 对象的引用</li>
</ol>
</li>
<li><strong>标记复制</strong>：将存活对象，放入到 Survivor 区 或者 Old 区<ol>
<li>新的 Survivor 区：是 Free Region 升级来的</li>
<li>被释放的 Eden 和 Survivor 区：会标记为 Free Region 空白的可用分区</li>
</ol>
</li>
</ol>
<p>Tips：</p>
<ul>
<li>G1 在 Young GC 过程中，是串行？并行？并发？是否会暂停工作线程？<ul>
<li>Re：可以多线程，就看怎么设置了，会暂停工作线程，不是并发的。</li>
</ul>
</li>
</ul>
<h3 id="1-3-2-Mixed-GC"><a href="#1-3-2-Mixed-GC" class="headerlink" title="1.3.2. Mixed GC"></a>1.3.2. Mixed GC</h3><p>Mixed GC，关键细节：</p>
<ul>
<li>针对「<strong>年轻代</strong>」和「<strong>部分老年代</strong>」的 GC，具体 Eden、Survivor、Old、Humongous Region</li>
<li><strong>存活的对象</strong>，放置在「新的 Survivor 分区」或「Old 分区」</li>
<li><strong>触发的时机</strong>：「并发标记周期」中，完成了最后的「<strong>筛选回收</strong>」阶段后，标记出了 X 的 Old Region 分区</li>
</ul>
<p>Mixed GC 的执行过程：就是「标记-复制」算法</p>
<ol>
<li><strong>并发标记周期</strong>：针对 <code>Old 分区</code>，进行标记<ol>
<li><strong>初始标记</strong>：依赖 Young GC</li>
<li><strong>扫描根分区</strong>：如果有 Young GC，则，Young GC block 阻塞等待</li>
<li><strong>并发标记</strong>：<ol>
<li>可以并发进行 Young GC</li>
<li>结束后，并不会进入 Young GC 阶段</li>
</ol>
</li>
<li><strong>重新标记</strong>：不能进行 Young GC</li>
<li><strong>筛选回收</strong>：结束后，进入 mixed 阶段</li>
</ol>
</li>
<li><strong>Mixed GC</strong>，<strong>本质</strong>就是对 <strong>CSet</strong> 中 Region 的回收<ol>
<li><strong>CSet</strong>：在 mixed 模式下，其中涵盖了 Eden、Survivor、Old、Humongous Region</li>
<li><strong>筛选回收阶段</strong>：针对 Old 分区<ol>
<li><strong>完全可回收的 Region</strong>：不存在存活的对象，直接回收 Region，标记为 Free Region 可用分区</li>
<li>存在<strong>部分存活的对象的 Region</strong>：标记分数后，追加在 C-Set 中</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>实际上，可以认为是 2 条线：</p>
<ul>
<li><strong>Young GC</strong>：<ul>
<li>基于 C-Set，进行 Region 回收，本质上，只针对「年轻代」进行回收；</li>
<li>如果 C-Set 中，涵盖了标记为 X 的 Old Region，则，称为 Mixed GC，此时，既针对「年轻代」，也针对「部分老年代」Region 进行回收</li>
</ul>
</li>
<li><strong>并发标记周期</strong>：标记出 Old Region，哪些需要回收，标记为 X<ul>
<li>完成「并发标记阶段」后，Young GC，自动升级为 mixed 模式，即，Mixed GC</li>
<li>Mixed GC：基于 C-Set，进行 Region 回收，只不过，此时，C-Set 中，涵盖了一部分 Old Region</li>
</ul>
</li>
</ul>
<p><img src="_v_images/20200716205954650_1089567156.png"></p>
<p>1 个插图：并发标记周期的说明</p>
<ul>
<li><strong>并发标记周期</strong>：<ul>
<li>触发时机：「老年代」分区的占比，达到阈值</li>
<li>整个周期说明</li>
</ul>
</li>
<li><strong>Mixed GC</strong>：模式生效点、失效点<ul>
<li><strong>生效点</strong>：存在 X 状态的 Old Region，即，标记并发周期的「筛选回收」阶段结束后，再次触发的 GC，就是 Mixed GC</li>
<li><strong>失效点</strong>：完成所有的 X 状态 Old Region 的清理后，会进入 Young GC 状态</li>
</ul>
</li>
<li><strong>补充说明</strong>：<ul>
<li>部分 X 状态的 Old Region：每次 Mixed GC，只有部分 X 状态的 Old Region 会被放入 C-Set</li>
<li>完整 C-Set 都被回收：C-Set 中所有 Region，每次 GC 都会被回收</li>
</ul>
</li>
</ul>
<p><strong>特别说明</strong>：</p>
<blockquote>
<p>G1的收集都是STW的；</p>
<p>但「年轻代」和「老年代」的 GC <strong>界限模糊</strong>，采用了混合(<code>mixed</code>)收集的方式。</p>
<p><strong>Young GC</strong>，可能快速切换为 Mixed GC，只要 X 标记的 Old Region 存在和消失，就会自动升级 or 降级；</p>
<p>这样，即使堆内存很大时，也可以限制<strong>收集 Region 的范围</strong>，从而<strong>降低停顿</strong>，达到设置的「暂停时间的目标」。</p>
</blockquote>
<h3 id="1-3-3-其他"><a href="#1-3-3-其他" class="headerlink" title="1.3.3. 其他"></a>1.3.3. 其他</h3><h4 id="1-3-3-1-启发式算法"><a href="#1-3-3-1-启发式算法" class="headerlink" title="1.3.3.1. 启发式算法"></a>1.3.3.1. 启发式算法</h4><p><strong>启发式算法</strong>：根据执行状态，动态调整</p>
<ol>
<li>设置了「暂停时间的目标」（默认 200ms），G1 会自动调整「年轻代」的空间大小</li>
<li>如果显式设置「年轻代」的大小，则，用户设置的「暂停时间的目标」会自动失效</li>
</ol>
<h4 id="1-3-3-2-SATB，增量式的标记算法"><a href="#1-3-3-2-SATB，增量式的标记算法" class="headerlink" title="1.3.3.2. SATB，增量式的标记算法"></a>1.3.3.2. SATB，增量式的标记算法</h4><p>G1 垃圾收集器，采用了 <strong>SATB</strong>（Snapshot At The Beginning），初始快照，增量式的标记算法，具体：</p>
<ol>
<li><strong>标记开始时</strong>：Region 创建一个 Snapshot</li>
<li><strong>存量标记</strong>：只针对 Snapshot 中存活的对象，进行标记</li>
<li><strong>增量标记</strong>：Snapshot 之后，新生成的对象，都被标记为「存活对象」，此次不回收，下次标记再说</li>
</ol>
<h4 id="1-3-3-3-G1：适用场景"><a href="#1-3-3-3-G1：适用场景" class="headerlink" title="1.3.3.3. G1：适用场景"></a>1.3.3.3. G1：适用场景</h4><p>就目前而言、CMS还是默认首选的GC策略、可能在以下场景下G1更适合：</p>
<ol>
<li><strong>多核+大内存</strong>：服务端多核CPU、JVM内存占用较大的应用（至少大于4G）</li>
<li><strong>业务多碎片</strong>：应用在运行过程中会产生大量内存碎片、需要经常压缩空间</li>
<li><strong>防止高并发雪崩</strong>：想要更可控、可预期的GC停顿周期；防止高并发下应用雪崩现象</li>
</ol>
<h3 id="1-3-4-小结"><a href="#1-3-4-小结" class="headerlink" title="1.3.4. 小结"></a>1.3.4. 小结</h3><p>G1 垃圾收集器，围绕其 Young GC 和 Mixed GC，从整体宏观的角度上，跟之前所有的「串行」「并行」「并发」的垃圾收集器，存在本质的差异：</p>
<ol>
<li>之前的垃圾收集器，要实现 <strong>2 个基本步骤</strong>：<ol>
<li><strong>步骤1</strong>：找到需要回收的对象</li>
<li><strong>步骤2</strong>：回收</li>
<li><strong>Note</strong>：上面两个步骤「步骤2」依赖「步骤1」，并且串行进行</li>
</ol>
</li>
<li>G1 垃圾收集器，在「<strong>老年代</strong>」，把 2 个步骤「同时进行」：<ol>
<li><strong>找到需要回收的对象</strong>：<ol>
<li>在找到需要回收的 Old Region 过程中，仍然可以同时「回收对象」，即 GC</li>
<li>找到需要回收的 Old Region 过程，称为「<strong>并发标记周期</strong>」</li>
</ol>
</li>
<li><strong>回收对象</strong>：<ol>
<li>在「找需要回收的对象」<strong>过程中</strong>，可以持续并发的进行 GC，称为 <code>Young GC</code>，只会收「新生代」</li>
<li>「找需要回收的对象」<strong>过程结束后</strong>，再进行的 GC，称为 <code>Mixed GC</code>，会同时回收「新生代」和「部分老年代」</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>参考示意图：</p>
<p><img src="_v_images/20200716205954411_225227554.png"></p>
<p><img src="_v_images/20200716125557055_1896049925.png"></p>
<p>G1 回收过程如下。</p>
<ol>
<li>G1 的年轻代回收，采用复制算法，并行进行收集，收集过程会 STW。</li>
<li>G1 的老年代回收时也同时会对年轻代进行回收。主要分为四个阶段：<ol>
<li>依然是初始标记阶段完成对根对象的标记，这个过程是STW的；</li>
<li>并发标记阶段，这个阶段是和用户线程并行执行的；</li>
<li>最终标记阶段，完成三色标记周期；</li>
<li>复制/清除阶段，这个阶段会优先对可回收空间较大的 Region 进行回收，即 garbage first，这也是 G1 名称的由来。</li>
</ol>
</li>
</ol>
<p>【参考文献】</p>
<ol>
<li><a href="https://blog.csdn.net/zy1994hyq/article/details/102495471">GC算法之G1算法</a></li>
<li><a href="https://ningg.top/jvm-series-jvm-practice-jvm-gc-g1/">JVM 实践：G1 垃圾收集器</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>JMeter与性能压测</title>
    <url>/Java/metric/JMeter/</url>
    <content><![CDATA[<h1 id="JMeter与性能压测"><a href="#JMeter与性能压测" class="headerlink" title="JMeter与性能压测"></a>JMeter与性能压测</h1><p> jmeter是一款纯java的性能测试工具，跨平台运行方便、提供图形化界面设置、简单易用。</p>
<p>在性能测试方法论中，很典型的方法就是二八原则，量化业务需求。</p>
<p>二八原则：指80%的业务量在20%的时间里完成。</p>
<p>如何理解，下面我们来个例子吧</p>
<p>用户登录场景：早高峰时段，8：50—9：10，5000坐席上线登陆。</p>
<pre><code>  业务量：5000个 

  时间：20x60=1200秒

吞吐量=80%x业务量/(20%*时间)=4000/240=16.7/秒</code></pre>
<p>而并非5000/1200=4.1/秒</p>
<p>实际上，登录请求数分布是一个正态分布，最高峰时肯定比4.1/秒更高，高峰段实际上完成了80%的业务量，却只花了20%的时间。</p>
<p>温馨提示：</p>
<p>1.二八原则计算的结果并非在线并发用户数，是系统要达到的处理能力（吞吐量），初学者容易被误导，那这这个数据就去设置并发数，这是错误滴。</p>
<p>2.如果你的系统性能要求更高，也可以选择一九原则或更严格的算法，二八原则比较通用，一般系统性能比较接近这个算法而已，大家应该活用。</p>
<p>3.tps、响应时间、在线并发数三者关系详解：<a href="http://blog.csdn.net/musen518/article/details/43795047">点击打开链接</a></p>
<p>  三者关系图</p>
<p><img src="_v_images/20200121162958712_1262110967"></p>
<ol start="2">
<li> 结论</li>
</ol>
<ul>
<li>小并发数区间测试，找拐点（如：100-300并发持续5分钟，可以发现上图中200并发时出现拐点）</li>
<li>大并发数区间测试，找符合需求的最大并发数（如：1800-2200并发持续5分钟，可以找到满足响应时间在3秒内的最大并发数2000）</li>
<li>利用最大并发数，压测环境在极限时的资源消耗（压测时间1小时以内）</li>
<li>80%最大并发数，进行稳定性测试（压测时间1小时以上）</li>
</ul>
<p>注：执行机资源消耗必须监控上，保证能提供稳定的并发负载。</p>
<p>注：这里的响应时间是90%响应时间</p>
<p>tps:</p>
<p>每秒事务处理量 - <a href="https://baike.baidu.com/item/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95">性能测试</a>的术语介绍</p>
<p>TPS(Transaction Per Second)</p>
<p>每秒钟系统能够处理的交易或事务的数量。它是衡量系统处理能力的重要指标。TPS是<a href="https://baike.baidu.com/item/LoadRunner">LoadRunner</a>中重要的性能参数指标。</p>
<p> 1.下载安装</p>
<p>仅仅需要从apache的网站找到下载包，解压到本地文件目录即可。</p>
<p><a href="http://jmeter.apache.org/download_jmeter.cgi">http://jmeter.apache.org/download_jmeter.cgi</a></p>
<p>2.启动</p>
<p>解压目录中存在一个bin的目录，里面有很多批处理文件和脚本文件，window系统运行jmeter.bat即可。需要关注的是bin目录中的jmeter.properties文件，这是运行相关的配置文件. 特别是TCP Sampler configuration部分几个配置会和后面内容相关</p>
<p>3.建立一种类型测试</p>
<p>这里只描述简单的tcp测试建立步骤，因为目前支持的测试类型很多，无法一一陈述，功能细节部分可以参考JMeter文档</p>
<p>1）创建测试线程组</p>
<p><strong>1. 启动测试用接口</strong><br>首先我们写一段 php 代码，通过 PHP 内置的 Server 启动它。</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="variable">$user_id</span> = <span class="variable">$_GET</span>[<span class="string">&#x27;user_id&#x27;</span>];</span><br><span class="line">file_put_contents(<span class="string">&#x27;/tmp/1.log&#x27;</span>, <span class="variable">$user_id</span>.PHP_EOL,  FILE_APPEND);</span><br><span class="line"><span class="keyword">echo</span> <span class="variable">$user_id</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以上代码保存为 <code>index.php</code></p>
<p>命令中执行 <code>php -S 127.0.0.1:8080</code></p>
<p>在浏览器访问 <code>http://127.0.0.1:8080/index.php?user_id=1</code> , 输出 <code>1</code> 说明服务接口正常</p>
<p><strong>2. 创建线程组</strong><br>使用 JMeter 测试应用性能首先要创建一个线程组<br>右键 “Text Plan”, 在弹出的菜单栏选择 “Add-&gt;Threads(Users)-&gt;Thread Group”</p>
<p>就创建了一个线程组：</p>
<p><img src="_v_images/20200121162958609_236107942.png"></p>
<p>“Number of Threads (users): ” 即并发用户数，相当于 ab 命令的 -c 参数<br>“Loop Count:” 循环请求次数， 即每个线程请求多少次， 这个数据乘以线程数相当于 ab 命令的 -n 参数</p>
<p>我们设置了 “Number of Threads (users)” 为 5 ， “Loop Count” 为 60 ， 相当于ab 命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ab -c 5 -n 300 http:&#x2F;&#x2F;xxx.com</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>2. 创建测试请求</strong><br>右键我们刚刚创建的线程组“Thread Group”, 选择 “Add-&gt; Sampler-&gt; HTTP Request”</p>
<p><img src="_v_images/20200121162958391_1716814489.png"></p>
<p>这一步相当于通过多个参数拼出要测试的接口地址。</p>
<p>注意<code>Path</code>中， <code>$&#123;__counter(false)&#125;</code> 为 JMeter 内置的函数， 它的返回值为当前请求次数<br>**这样保证了我们每次向服务器请求的 <code>user_id</code> 的值都不一样 **</p>
<p>此时我们将要进行的测试等同于 ab 测试命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ab -c 5 -n 300 http:&#x2F;&#x2F;127.0.0.1&#x2F;index.php?user_id&#x3D;1</span><br></pre></td></tr></table></figure>
<h2 id="、-Counter-函数"><a href="#、-Counter-函数" class="headerlink" title="、_Counter 函数"></a>、_Counter 函数</h2><p>每次调用计数器函数都会产生一个新值，从1开始每次加1。计数器既可以被配置成针对每个虚拟用户是独立的，也可以被配置成所有虚拟用户公用的。如果每个虚拟用户的计数器是独立增长的，那么通常被用于记录测试计划运行了多少遍。全局计数器通常被用于记录发送了多少次请求。</p>
<p>计数器使用一个整数值来记录，允许的最大值为2,147,483,647。</p>
<p>功能：这个函数是一个计数器，用于统计函数的使用次数，它从1开始，每调用这个函数一次它就会自动加1，它有两个参数，第一个参数是布尔型的，只能设置成“TRUE”或者“FALSE”，如果是TRUE，那么每个用户有自己的计数器，可以用于统计每个线程歌执行了多少次。如果是FALSE，那就使用全局计数器，可以统计出这次测试共运行了多少次。第二个参数是“函数名称”</p>
<p><strong>格式：</strong>${__counter(FALSE,test)}</p>
<p><strong>使用：</strong>我们将“_counter”函数生成的参数复制到某个参数下面，如果为TRUE格式，则每个线程各自统计，最大数为循环数，如果为FALSE，则所有线程一起统计，最大数为线程数乘以循环数</p>
<p><strong>参数：</strong></p>
<p>第一个参数：True，如果测试人员希望每个虚拟用户的计数器保持独立，与其他用户的计数器相区别。False，全局计数器</p>
<p>第二个参数：重用计数器函数创建值的引用名。测试人员可以这样引用计数器的值：${test}。这样一来，测试人员就可以创建一个计数器后，在多个地方引用它的值。</p>
<p>以上，摘自网络（不知道怎么用，只好摘抄，记录下来等灵感~~~~(&gt;_&lt;)~~~~ ）。</p>
<p>目前，我测试_Counter函数，就是在参数列表加一个参数，值填写为${__counter(FALSE,test)}</p>
<p>）  </p>
<p><strong>3.开始测试</strong><br>右键线程组 “Thread Group”， 选择 “Add-&gt; Listener-&gt;Summary Report “, 创建一个结果报表</p>
<p>然后点击， 菜单栏中的绿色按钮, 开始测试：</p>
<p><img src="_v_images/20200121162958170_1920589116.png"></p>
<p>结果如图:</p>
<p> <img src="_v_images/20200121162957964_563024753.png"></p>
<p>打开 ‘/tmp/1.log’ 可以看到，每次请求的 user_id的值都是不同的。</p>
<h1 id="Thread-Group-线程组"><a href="#Thread-Group-线程组" class="headerlink" title="Thread Group(线程组)"></a>Thread Group(线程组)</h1><blockquote>
<p>1.线程组，或者可以叫用户组，进行性能测试时的用户资源池。</p>
<p>2.是任何一个测试计划执行的开始点。</p>
<p>3.上一篇提到的“控制器”和“HTTP请求”(采集器)必须在线程组内；监听器等其他组件，可以直接放在测试计划下。</p>
<p><a href="https://www.cnblogs.com/linglingyuese/archive/2013/03/06/linglingyuese-three.html">https://www.cnblogs.com/linglingyuese/archive/2013/03/06/linglingyuese-three.html</a></p>
<p><a href="https://www.cnblogs.com/hait1234/p/6767212.html">https://www.cnblogs.com/hait1234/p/6767212.html</a></p>
</blockquote>
<p>二、Thread Group线程组功能分区</p>
<p>总的来说，一个线程组有三个功能分区，这里分别标注为区域1、区域2、区域3。</p>
<p><img src="_v_images/20200121162957741_1278470356.png"></p>
<p>1.区域1：在取样器错误后要执行的动作，这个区域的主要作用很明显，在线程内的采样器失败后，接下来做什么。</p>
<pre><code> （1）继续：选择此项，将继续执行接下来的操作。

 （2）Start Next Loop：忽略错误，执行下一个循环。

 （3）停止线程：退出该线程（不再进行此线程的任何操作）。

 （4）停止测试：等待当前执行的采样器结束后，结束整个测试。

 （5）Stop Test Now：直接停止整个测试。（注意与4的“停止测试”进行区分）。</code></pre>
<p>2.区域2：线程属性，这里可以设置线程数（模拟的用户数）和循环次数。含义如下图所示：</p>
<p><img src="_v_images/20200121162957533_2123434422.png"></p>
<p>ramp up:斜坡上升; [动词短语] 加强，加大;</p>
<p> 相当于warm up的一个词,包含准备,热身,加速的意思,可用在生产中小批量的试制中, 也可以指人初入公司的锻炼. 在项目初始阶段要做许多准备工作。</p>
<p>3.区域3：调度器配置（全部都在调度器复选框被选中的前提下，下面的选项才会生效。）</p>
<p><img src="_v_images/20200121162957230_2144403715.png"></p>
<p>最重要的Tcp Sampler:tcp取样器</p>
<h4 id="TCPClient-classname"><a href="#TCPClient-classname" class="headerlink" title="TCPClient classname"></a>TCPClient classname</h4><p>TCP Sampler提供了3个Sampler的实现，分别是</p>
<p>org.apache.jmeter.protocol.tcp.sampler.TCPClientImpl </p>
<p>org.apache.jmeter.protocol.tcp.sampler.BinaryTCPClientImpl和<br>org.apache.jmeter.protocol.tcp.sampler.LengthPrefixedBinaryTCPClientImpl。</p>
<p>其中TCPClientImpl实现了以文本编辑器中所编辑的纯文本为内容进行发送，BinaryTCPClientImpl则以文本编辑器中所编辑的16进制字符（hex）内容为基础转换为二进制的字节内容进行发送，LengthPrefixedBinaryTCPClientImpl则会在BinaryTCPClientImpl基础上默认以发送内容的长度以字节前缀进行填充。</p>
<p>我们可以通过配置jmeter.properties文件中tcp.handler属性来设置默认的TCPClient。</p>
<h2 id="测试基于文本套接字应用"><a href="#测试基于文本套接字应用" class="headerlink" title="测试基于文本套接字应用"></a>测试基于文本套接字应用</h2><p>被测应用的源码请参见<a href="https://link.jianshu.com/?t=https://github.com/XMeterSaaSService/Blog_sample_project/blob/master/socket_echo/src/main/java/net/xmeter/echo/TextServer.java">这里</a>. 如果想运行该程序，请点击该链接下载socket_echo-0.0.1-SNAPSHOT.jar，并且在命令行下执行:</p>
<p><a href="https://github.com/XMeterSaaSService/Blog/_sample/_project/tree/master/socket_echo">https://github.com/XMeterSaaSService/Blog\_sample\_project/tree/master/socket_echo</a> </p>
<p>（javac 和java可以去掉包名后再在命令行执行）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -cp socket_echo-0.0.1-SNAPSHOT.jar net.xmeter.echo.TextServer这个程序源码：</span><br></pre></td></tr></table></figure>
<p><img src="_v_images/20200121162957026_1366283370.gif"></p>
<p><a href="javascript:void(0);" title="复制代码"><img src="_v_images/20200121162956724_1452766871.gif" alt="复制代码"></a></p>
<p>import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.io.PrintWriter; import java.net.ServerSocket; import java.net.Socket; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.atomic.AtomicInteger; public class TextServer { public static AtomicInteger sessions = new AtomicInteger(0); public void handleRequest(final Socket socket) {<br>        ExecutorService executor = Executors.newSingleThreadExecutor();</p>
<pre><code>    executor.submit(new Runnable() &#123;
        @Override public void run() &#123; try &#123;
                BufferedReader is = new BufferedReader(new InputStreamReader(socket.getInputStream()));
                PrintWriter os = new PrintWriter(socket.getOutputStream()); while(true) &#123;
                    String line = is.readLine(); if(line == null) &#123;
                        System.out.println(&quot;Probably the client side closed the connection, now close me as well.&quot;);
                        socket.close(); break;
                    &#125;
                    System.out.println(&quot;Received message: &quot; + line);
                    os.println(&quot;Echo: &quot; + line);
                    os.flush(); if(&quot;bye&quot;.equals(line)) &#123; break;
                    &#125;
                &#125;
            &#125; catch(Exception ex) &#123;
                ex.printStackTrace();
            &#125; finally &#123; try &#123;
                    socket.close(); int num = sessions.decrementAndGet();
                    System.out.println(&quot;Now totally has &quot; + num + &quot; of conn.&quot;);
                &#125; catch (IOException e) &#123;
                    e.printStackTrace();
                &#125;
            &#125;
        &#125;

    &#125;);

&#125; public static void main(String\[\] args) &#123; try &#123;
        ServerSocket server = new ServerSocket(4700); while(true) &#123;
            Socket socket = server.accept();
            TextServer srv = new TextServer();
            srv.handleRequest(socket); int num = sessions.incrementAndGet();
            System.out.println(&quot;Received new conn, now totally has &quot; + num + &quot; of conn.&quot;);
        &#125;
    &#125; catch (Exception e) &#123;
        e.printStackTrace();
    &#125;
&#125;</code></pre>
<p>}</p>
<p><a href="javascript:void(0);" title="复制代码"><img src="_v_images/20200121162956522_679224056.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(这个程序测试：</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">注意几图：hello后面有个换行， ENDof line Byte value 填写的是10.LF (NL line feed, new line) 换行键 ，ascill是10.os.println(&quot;Echo: &quot; + line); 用的是println，服务端返回的最后是一个换行符。如果不填写EOF byte value,那么客户端将会一直阻塞没有返回。</span><br></pre></td></tr></table></figure>
<p>我们发<strong>现EOL原来是与读数据相关的，就是设定来自于服务器数据流的一个结束标识字节。没有设置EOL将会一直读到输入流结束为</strong>止。</p>
<p>这里值得注意的是，这是个十进制的值（千万不要写成hex），比如你可以查询ASCII表，来确认一个表示结束字符的十进制值，我们以$作为案例，改造一下Mock TCP Server，输出结尾为$，如下面代码：</p>
<p>)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>（请确保您的机器上已经安装了Java）。 该程序会在4700端口建立一个ServerSocket，等待来自客户端的请求，客户端如果发送了一个字符串，服务器端返回“Echo: “ + 客户端发送的字符串。如下图所示，如果我们使用telnet连接到服务器端的套接字应用，双方就可以直接进行通信了。</p>
<h5 id="TCPClientImpl"><a href="#TCPClientImpl" class="headerlink" title="TCPClientImpl"></a>TCPClientImpl</h5><p>我们使用TCPClientImpl对Mock TCP Server进行测试，配置参考下图：</p>
<p><img src="_v_images/20200121162956318_161208051.png"></p>
<p>点击运行测试，你会发现测试发生了阻塞，原因是服务器使用了readLine获取客户端的发送数据，需要根据发送数据中的CRLF（\r或\n）判断一行的<strong>结束。而我们制作的发送内容并不包括CRLF标识内容，因此，服务器阻塞在了读数据，测试客户端得不到服务器响应，同样</strong>也阻塞在了读数据，正确的配置需要添加一个“回车”（不能是”\r”或”\n”，因为TCPClientImpl会自动将其转换为对应的两个字符而不是CRLF标识）参考下图</p>
<p>TCP 取样器通过TCP/IP来连接特定服务器，连上服务器之后发送消息，然后等待服务器回复。</p>
<p>如果“Re-use connection”(重复使用连接) 复选框被选中了，在同一个线程中Samplers(取样器)共享连接，包含相同主机名和端口，不同主机/端口合并将会使用不同线程。如果“Re-use connection” 和 “Close connection”(关闭连接)同时被选中，这个套接字在运行完当前Samplers将会关闭。再下一个Sampler将会另外创建一个新套接字。你可能想要在每次线程循环结束之后关闭套接字。</p>
<p>如果一个错误被检测到或者“Re-use connection” 没有被选中，这个套接字将会关闭，另外套接字将会在接下Samplers被再一次打开。</p>
<p>详细看这篇文章：</p>
<h1 id="Apache-JMeter-TCPSampler的使用及自定义"><a href="#Apache-JMeter-TCPSampler的使用及自定义" class="headerlink" title="Apache JMeter TCPSampler的使用及自定义"></a><a href="https://blog.csdn.net/xreztento/article/details/73741697">Apache JMeter TCPSampler的使用及自定义</a></h1><p> 还有这篇文章：<a href="https://www.jianshu.com/p/63e08071075e">https://www.jianshu.com/p/63e08071075e</a></p>
<h1 id="JMeter—–TCP-Sampler（TCP-取样器）"><a href="#JMeter—–TCP-Sampler（TCP-取样器）" class="headerlink" title="JMeter—–TCP Sampler（TCP 取样器）"></a><a href="https://blog.csdn.net/m0_37355951/article/details/74779977">JMeter—–TCP Sampler（TCP 取样器）</a></h1><p>jmeter报告结果中会出现三个时间</p>
<ol>
<li><p>Elapsed time    经过的时间(= Sample time = Load time = Response time ) </p>
<p>   这个时间是我们测试常用的时间，也是整个请求的消耗时间，从发送到接收完成全程消耗的时间</p>
</li>
<li><p>Latency time  延迟时间</p>
<p>  不常用，表示请求发送到刚开始接收响应时，这个时间&lt;Elapsed time</p>
</li>
</ol>
<p>3. Connection time  建立连接时间 （2.13新增参数）</p>
<pre><code>   不常用，请求连接建立的时间，这个时间 &lt; Latency time &lt; Elapsed time</code></pre>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
        <tag>JMeter</tag>
      </tags>
  </entry>
  <entry>
    <title>Java微基准测试</title>
    <url>/Java/metric/Java-%E5%BE%AE%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<p>Stalker</p>
<p><a href="http://openjdk.java.net/projects/code-tools/jmh/">JMH</a> 是 Java Microbenchmark Harness（微基准测试</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>【读书笔记】Java程序性能优化</title>
    <url>/Java/metric/Java%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="Java程序性能优化"><a href="#Java程序性能优化" class="headerlink" title="Java程序性能优化"></a>Java程序性能优化</h1><p><img src="/images/java/performance/Java%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%A4%A7%E5%85%A8.png" alt="img"></p>
<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h1><h2 id="OverStack"><a href="#OverStack" class="headerlink" title="OverStack"></a>OverStack</h2><p>默认xss</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java -XX:+PrintFlagsFinal -version | grep -i &#x27;stack&#x27;</span><br><span class="line">     intx CompilerThreadStackSize                   = 0                                   &#123;pd product&#125;</span><br><span class="line">    uintx GCDrainStackTargetSize                    = 64                                  &#123;product&#125;</span><br><span class="line">     bool JavaMonitorsInStackTrace                  = true                                &#123;product&#125;</span><br><span class="line">    uintx MarkStackSize                             = 4194304                             &#123;product&#125;</span><br><span class="line">    uintx MarkStackSizeMax                          = 536870912                           &#123;product&#125;</span><br><span class="line">     intx MaxJavaStackTraceDepth                    = 1024                                &#123;product&#125;</span><br><span class="line">     bool OmitStackTraceInFastThrow                 = true                                &#123;product&#125;</span><br><span class="line">     intx OnStackReplacePercentage                  = 140                                 &#123;pd product&#125;</span><br><span class="line">     intx StackRedPages                             = 1                                   &#123;pd product&#125;</span><br><span class="line">     intx StackShadowPages                          = 20                                  &#123;pd product&#125;</span><br><span class="line">     bool StackTraceInThrowable                     = true                                &#123;product&#125;</span><br><span class="line">     intx StackYellowPages                          = 2                                   &#123;pd product&#125;</span><br><span class="line">     intx ThreadStackSize                           = 1024                                &#123;pd product&#125;</span><br><span class="line">     bool UseOnStackReplacement                     = true                                &#123;pd product&#125;</span><br><span class="line">     intx VMThreadStackSize                         = 1024                                &#123;pd product&#125;</span><br><span class="line">java version &quot;1.8.0_211&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_211-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)</span><br></pre></td></tr></table></figure>
<p><a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html">https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html</a></p>
<p>-Xss is translated in a VM flag named ThreadStackSize, 是-XX:ThreadStackSize的简写形式, 即线程栈的大小,  单位kb</p>
<p>-Xsssize  </p>
<p>   Sets the thread stack size (in bytes). Append the<br>   letter k or K to indicate KB, m or M to indicate MB, g or G to<br>   indicate GB. The default value depends on the platform:</p>
<ul>
<li>Linux/ARM (32-bit): 320 KB</li>
<li>Linux/i386 (32-bit): 320 KB</li>
<li>Linux/x64 (64-bit): 1024 KB</li>
<li>OS X (64-bit): 1024 KB</li>
<li>Oracle Solaris/i386 (32-bit): 320 KB</li>
<li>Oracle Solaris/x64 (64-bit): 1024 KB</li>
</ul>
<p>The following examples set the thread stack size to 1024 KB in different units:</p>
<p>-Xss1m<br>-Xss1024k<br>-Xss1048576</p>
<p>This option is equivalent to -XX:ThreadStackSize.</p>
<h2 id="OverStack样例"><a href="#OverStack样例" class="headerlink" title="OverStack样例"></a>OverStack样例</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OverStackTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> cnt = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">recursion</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        cnt++;</span><br><span class="line">        recursion();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">testOverStack</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            recursion();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;deep of stack is &quot;</span> + cnt);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> OverStackTest().testOverStack();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> javac OverStackTest.java</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> java -Xss256k  OverStackTest</span></span><br><span class="line">deep of stack is 1887</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> java -Xss512k  OverStackTest</span></span><br><span class="line">deep of stack is 7428</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> java -Xss670k  OverStackTest</span></span><br><span class="line">deep of stack is 7616</span><br></pre></td></tr></table></figure>


<ul>
<li>标记复制: 新生代垃圾回收的通用算法</li>
<li>标记压缩: 老年代垃圾回收</li>
</ul>
<h2 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h2><p>三种操作:</p>
<ul>
<li>年轻代回收（暂停所有应用线程）</li>
<li>启动并发线程回收老年带空间</li>
<li>如有必要，full gc</li>
</ul>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>JStack</tag>
      </tags>
  </entry>
  <entry>
    <title>【转载】Java生产环境下性能监控与调优详解笔记</title>
    <url>/Java/metric/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E8%B0%83%E4%BC%98%E8%AF%A6%E8%A7%A3%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="Java生产环境下性能监控与调优详解笔记"><a href="#Java生产环境下性能监控与调优详解笔记" class="headerlink" title="Java生产环境下性能监控与调优详解笔记"></a>Java生产环境下性能监控与调优详解笔记</h1><p>另一个整理<a href="http://alanhou.org/java-optimization/">http://alanhou.org/java-optimization/</a></p>
<h2 id="1：JVM字节码指令与-javap"><a href="#1：JVM字节码指令与-javap" class="headerlink" title="1：JVM字节码指令与 javap"></a>1：JVM字节码指令与 javap</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">javap &lt;options&gt; &lt;classes&gt;</span><br><span class="line"><span class="built_in">cd</span> monitor\_tuning/target/classes/org/alanhou/monitor\_tuning/chapter8/</span><br><span class="line">javap -verbose Test1.class &gt; Test1.txt</span><br></pre></td></tr></table></figure>
<p>即可保存字节码文件<br>会有三个部分组成<br>操作数栈<br>LineNumberTable<br>LocalVariableTable</p>
<p>i++和++i 的执行效果完全相同 多了一个压入栈顶操作<br>for(int i=0;i&lt;10;i++) {}<br>for(int i=0;i&lt;10;++i) {} 执行效果一样</p>
<p>2：</p>
<p>public static void f1() {<br>String src = “”;<br>for(int i=0;i&lt;10;i++) {<br>//每一次循环都会new一个StringBuilder 然后在src.append(“A”);<br>src = src + “A”;<br>}<br>System.out.println(src);<br>}<br>public static void f2() {<br>//只要一个StringBuilder<br>StringBuilder src = new StringBuilder();<br>for(int i=0;i&lt;10;i++) {<br>src.append(“A”);<br>}<br>System.out.println(src);<br>}</p>
<p>3：</p>
<p>public static String f1() {<br>String str = “hello”;<br>try{<br>return str;<br>}<br>finally{<br>str = “imooc”;<br>}<br>} 返回 hello 但会执行finally 中的代码</p>
<p>4：字符串拼接都会在编译阶段转换成stringbuilder</p>
<p>5:字符串去重</p>
<p>字符串在任何应用中都占用了大量的内存。尤其数包含独立UTF-16字符的char[]数组对JVM内存的消耗贡献最多——因为每个字符占用2位。</p>
<p>内存的30%被字符串消耗其实是很常见的，不仅是因为字符串是与我们互动的最好的格式，而且是由于流行的HTTP API使用了大量的字符串。使用Java 8 Update 20，我们现在可以接触到一个新特性，叫做字符串去重，该特性需要G1垃圾回收器，该垃圾回收器默认是被关闭的。</p>
<p>字符串去重利用了字符串内部实际是char数组，并且是final的特性，所以JVM可以任意的操纵他们。</p>
<p>对于字符串去重，开发者考虑了大量的策略，但最终的实现采用了下面的方式：</p>
<p>无论何时垃圾回收器访问了String对象，它会对char数组进行一个标记。它获取char数组的hash value并把它和一个对数组的弱引用存在一起。只要垃圾回收器发现另一个字符串，而这个字符串和char数组具有相同的hash code，那么就会对两者进行一个字符一个字符的比对。</p>
<p>如果他们恰好匹配，那么一个字符串就会被修改，指向第二个字符串的char数组。第一个char数组就不再被引用，也就可以被回收了。</p>
<p>这整个过程当然带来了一些开销，但是被很紧实的上限控制了。例如，如果一个字符未发现有重复，那么一段时间之内，它会不再被检查。</p>
<p>那么该特性实际上是怎么工作的呢？首先，你需要刚刚发布的Java 8 Update 20，然后按照这个配置: -Xmx256m -XX:+UseG1GC 去运行下列的代码:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LotsOfStrings</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> LinkedList LOTS_OF_STRINGS = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> iteration = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">1000</span>; j++) &#123;</span><br><span class="line">                    LOTS_OF_STRINGS.add(<span class="keyword">new</span> String(<span class="string">&quot;String &quot;</span> + j));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            iteration++;</span><br><span class="line">            System.out.println(<span class="string">&quot;Survived Iteration: &quot;</span> + iteration);</span><br><span class="line">            Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码会执行30个迭代之后报OutOfMemoryError。</p>
<p>现在，开启字符串去重，使用如下配置去跑上述代码：</p>
<p>-Xmx256m -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintStringDeduplicationStatistics</p>
<p>此时它已经可以运行更长的时间，而且在50个迭代之后才终止。</p>
<p>6:</p>
<p>ArrayLIst  底层是数组  扩容会拷贝<br>hashmap   底层也是数组+ 链表 扩容 重新计算key 负载因子是 0.75  </p>
<p>linklist底层是双向链表<br>1. 尽量重用对象，不要循环创建对象，比如:for 循环字符串拼接(不在 for中使用+拼接，先new 一个StringBuilder再在 for 里 append)  </p>
<p>2. 容器类初始化的地时候指定长度  </p>
<p>List<String> collection = new ArrayLIst<String>(5);  </p>
<p>Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(32);  </p>
<p>3. ArrayList（底层数组）随机遍历快，LinkedList（底层双向链表）添加删除快  </p>
<p>4. 集合遍历尽量减少重复计算  </p>
<p>5. 使用 Entry 遍历 Map可以同时取出key和value  </p>
<p>6. 大数组复制使用System.arraycopy 底层是native实现的  </p>
<p>7. 尽量使用基本类型而不是包装类型  </p>
<p>public class Test03 {  </p>
<p>  public static void main(String[] args) {<br>  Integer f1 = 100, f2 = 100, f3 = 150, f4 = 150;  </p>
<p>  System.out.println(f1 == f2);<br>  System.out.println(f3 == f4);<br>}<br>}  </p>
<p>如果不明就里很容易认为两个输出要么都是true要么都是false。首先需要注意的是f1、f2、f3、f4四个变量都是Integer对象引用，所以下面的==运算比较的不是值而是引用。装箱的本质是什么呢？当我们给一个Integer对象赋一个int值的时候，会调用Integer类的静态方法valueOf，如果看看valueOf的源代码就知道发生了什么。<br>public static Integer valueOf(int i) {<br>  if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)<br>    return IntegerCache.cache[i + (-IntegerCache.low)];<br>  return new Integer(i);<br>}<br>简单的说，如果整型字面量的值在-128到127之间，那么不会new新的Integer对象，而是直接引用常量池中的Integer对象，所以上面的面试题中f1==f2的结果是true，而f3==f4的结果是false。<br>8. 不要手动调用 System.gc()  </p>
<p>9. 及时消除过期对象的引用，防止内存泄漏<br>public string pop()<br>{<br>  string currentValue=object[size];<br>  //object[size]=null;如果不添加这句话就会造成内存泄漏<br>  size–;<br>  return currentValue;<br>}  </p>
<p>10. 尽量使用局部变量，减小变量的作用域 方便出了作用域尽快垃圾回收  </p>
<p>11. 尽量使用非同步的容器ArraryList vs. Vector  </p>
<p>12. 尽量减小同步作用范围, synchronized 方法 vs. 代码块  </p>
<p>public class SynchronizedTest {<br>  public static void main(String[] args) {<br>}<br>public synchronized void f1() {//在this對象上加鎖<br>  System.out.println(“f1”);<br>}<br>public  void f2() {//在this對象上加鎖<br>  synchronized(this) {<br>    System.out.println(“f2”);<br>  }<br>}<br>public static synchronized void f3() {//在类上加鎖<br>  System.out.println(“f3”);<br>}<br>public static void f4() {//在类上加鎖<br>  synchronized(SynchronizedTest.class) {<br>    System.out.println(“f4”);<br>  }<br>}<br>}  </p>
<p>13. 用ThreadLocal 缓存线程不安全的对象，SimpleDateFormat 缓存重量的对象避免重新构造<br>@SuppressWarnings(“rawtypes”)<br>    private static ThreadLocal threadLocal = new ThreadLocal() {<br>        protected synchronized Object initialValue() {<br>            return new SimpleDateFormat(DATE_FORMAT);<br>        }<br>    };  </p>
<p>14. 尽量使用延迟加载  </p>
<p>15. 尽量减少使用反射，必须用加缓存，反射比较影响性能  </p>
<p>16. 尽量使用连接池、线程池、对象池、缓存  </p>
<p>17. 及时释放资源， I/O 流、Socket、数据库连接  </p>
<p>18. 慎用异常，不要用抛异常来表示正常的业务逻辑，异常也是比较重的对象要记录堆栈信息  </p>
<p>19. String 操作尽量少用正则表达式 比如replaceAll是用正则 比较耗费性能 replace就不是用正则  </p>
<p>20. 日志输出注意使用不同的级别  </p>
<p>21. 日志中参数拼接使用占位符<br>log.info(“orderId:” + orderId); 不推荐 会用字符串拼接<br>log.info(“orderId:{}”, orderId); 推荐 用占位符 不会进行字符串拼接  </p>
<p>7：JVM的参数类型</p>
<p>标准参数（各版本中保持稳定）</p>
<p>-help</p>
<p>-server -client</p>
<p>-version -showversion</p>
<p>-cp -classpath</p>
<p>X 参数（非标准化参数）</p>
<p>-Xint：解释执行</p>
<p>-Xcomp：第一次使用就编译成本地代码</p>
<p>-Xmixed：混合模式，JVM 自己决定是否编译成本地代码</p>
<p>示例：</p>
<p>java -version（默认是混合模式）</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, mixed mode)</p>
<p>java -Xint -version</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, interpreted mode)</p>
<p>XX 参数（非标准化参数）</p>
<p>主要用于 JVM调优和 debug</p>
<ul>
<li>Boolean类型</li>
</ul>
<p>格式：-XX:[+-]<name>表示启用或禁用 name 属性<br>如：-XX:+UseConcMarkSweepGC<br>-XX:+UseG1GC</p>
<ul>
<li>非Boolean类型</li>
</ul>
<p>格式：-XX:<name>=<value>表示 name 属性的值是 value<br>如：-XX:MaxGCPauseMillis=500<br>-xx:GCTimeRatio=19<br>-Xmx -Xms属于 XX 参数<br>-Xms 等价于-XX:InitialHeapSize<br>-Xmx 等价于-XX:MaxHeapSize<br>-xss 等价于-XX:ThreadStackSize</p>
<h3 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h3><p>-XX:+PrintFlagsInitial 查看jvm初始值</p>
<p>-XX:+PrintFlagsFinal 查看jvm最终值</p>
<p>-XX:+UnlockExperimentalVMOptions 解锁实验参数</p>
<p>-XX:+UnlockDiagnosticVMOptions 解锁诊断参数</p>
<p>-XX:+PrintCommandLineFlags 打印命令行参数</p>
<p>输出结果中=表示默认值，:=表示被用户或 JVM 修改后的值</p>
<p>示例：java -XX:+PrintFlagsFinal -version</p>
<p>补充：测试中需要用到 Tomcat，CentOS 7安装示例如下</p>
<p><code>sudo </code>yum -y ``install java-1.8.0-openjdk*<br>wget  <a href="http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz">http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz</a><br>tar -zxvf apache-tomcat-8.5.32.tar.gz<br>mv apache-tomcat-8.5.32 tomcat<br>cd tomcat/bin/sh startup.sh</p>
<p>pid 可通过类似 ps -ef|grep tomcat或 jps来进行查看</p>
<h3 id="jps"><a href="#jps" class="headerlink" title="jps"></a>jps</h3><p>查看java进程 -l 可以知道完全类名</p>
<h3 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a>jinfo</h3><p>jinfo -flag MaxHeapSize <pid></p>
<p>jinfo -flags <pid>  手动赋过值的参数</p>
<h3 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h3><p>可以查看jvm的统计信息 如类加载。垃圾回收信息，jit编译信息</p>
<p>详情参考 <a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html">jstat 官方文档</a></p>
<p><img src="_v_images/20200117100110226_7723.jpg" alt="jstat 使用示例"></p>
<p>类加载</p>
<h1 id="以下1000表每隔1000ms-即1秒，共输出10次"><a href="#以下1000表每隔1000ms-即1秒，共输出10次" class="headerlink" title="以下1000表每隔1000ms 即1秒，共输出10次"></a>以下1000表每隔1000ms 即1秒，共输出10次</h1><p>jstat -class <pid> 1000 10</p>
<p>垃圾收集</p>
<p>-gc, -gcutil, -gccause, -gcnew, -gcold</p>
<p>jstat -gc <pid> 1000 10</p>
<p>以下大小的单位均为 KB</p>
<p>![](_v_images/20200117100110111_28215.png =800x600)</p>
<p>S0C, S1C, S0U, S1U: S0和 S1的总量和使用量</p>
<p>EC, EU: Eden区总量与使用量</p>
<p>OC, OU: Old区总量与使用量</p>
<p>MC, MU: Metacspace区(jdk1.8前为 PermGen)总量与使用量</p>
<p>CCSC, CCSU: 压缩类区总量与使用量</p>
<p>YGC, YGCT: YoungGC 的次数与时间</p>
<p>FGC, FGCT: FullGC 的次数与时间</p>
<p>GCT: 总的 GC 时间</p>
<p>JIT 编译</p>
<p>-compiler, -printcompilation</p>
<p>一个对象默认分配在堆上面 但是有个指针指向class默认是64位长指针，可以设置为用32位存储在压缩类空间</p>
<p>非堆区 即对应于虚拟机规范中的方法区 是操作系统本地内存 独立于jvm堆区之外 jdk8后面叫metaspace jdk8前面叫performancespace</p>
<p>codecache 存储的是jit即时编译的代码 以及native代码</p>
<h3 id="jmap-MAT"><a href="#jmap-MAT" class="headerlink" title="jmap+MAT"></a>jmap+MAT</h3><p>详情参考<a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jmap.html">jmap 官方文档</a></p>
<p>内存溢出演示：</p>
<p><a href="https://start.spring.io/%E7%94%9F%E6%88%90%E5%88%9D%E5%A7%8B%E4%BB%A3%E7%A0%81">https://start.spring.io/生成初始代码</a></p>
<p>最终代码：<a href="https://github.com/alanhou7/java-codes/tree/master/monitor_tuning">monitor_tuning</a></p>
<p>为快速产生内存溢出，右击 Run As&gt;Run Configurations, Arguments 标签VM arguments 中填入</p>
<p>-Xmx32M -Xms32M</p>
<p><img src="_v_images/20200117100109881_9995.png"></p>
<p>访问 <a href="http://localhost:8080/heap">http://localhost:8080/heap</a></p>
<p>Exception in thread “http-nio-8080-exec-2” Exception in thread “http-nio-8080-exec-1” java.lang.OutOfMemoryError: Java heap space<br>java.lang.OutOfMemoryError: Java heap space</p>
<p>-XX:MetaspaceSize=32M -XX:MaxMetaspaceSize=32M（同时在 pom.xml 中加入 asm 的依赖）</p>
<p><img src="_v_images/20200117100109670_1795.png"></p>
<p>访问 <a href="http://localhost:8080/nonheap">http://localhost:8080/nonheap</a></p>
<p>Exception in thread “main” java.lang.OutOfMemoryError: Metaspace<br>Exception in thread “ContainerBackgroundProcessor[StandardEngine[Tomcat]]“ java.lang.OutOfMemoryError: Metaspace</p>
<p>内存溢出自动导出</p>
<p>-XX:+HeapDumpOnOutOfMemoryError</p>
<p>-XX:HeapDumpPath=./</p>
<p>右击 Run As&gt;Run Configurations, Arguments 标签VM arguments 中填入</p>
<p>-Xmx32M -Xms32M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./</p>
<p>可以看到自动在当前目录中生成了一个java_pid660.hprof文件</p>
<p>java.lang.OutOfMemoryError: GC overhead limit exceeded<br>Dumping heap to ./java_pid660.hprof …</p>
<p>另一种导出溢出也更推荐的方式是jmap</p>
<p>option: -heap, -clstats, -dump:<dump-options>, -F</p>
<p>jmap -dump:format=b,file=heap.hprof <pid></p>
<p><img src="_v_images/20200117100109462_23769.jpg" alt="jmap 导出溢出文件"></p>
<p>MAT下载地址：<a href="http://www.eclipse.org/mat/">http://www.eclipse.org/mat/</a></p>
<p>找开上述导出的内存溢出文件即可进行分析，如下图的溢出源头分析：</p>
<p><img src="_v_images/20200117100109352_8610.jpg" alt="Memory Analyzer 内存溢出分析"></p>
<ol>
<li>Histogram可以列出内存中的对象，对象的个数以及大小。</li>
<li>Dominator Tree可以列出那个线程，以及线程下面的那些对象占用的空间。</li>
</ol>
<p>Histogram</p>
<pre><code>[![](_v_images/20200117100109236_4753.png)](http://static.oschina.net/uploads/space/2014/0702/120039_qSi5_1767531.png)</code></pre>
<ul>
<li><p>Class Name ： 类名称，java类名</p>
</li>
<li><p>Objects ： 类的对象的数量，这个对象被创建了多少个</p>
</li>
<li><p>Shallow Heap ：一个对象内存的消耗大小，不包含对其他对象的引用</p>
</li>
</ul>
<ul>
<li>Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收到内存的总和</li>
</ul>
<p>Dominator Tree</p>
<p><a href="http://static.oschina.net/uploads/space/2014/0702/145926_K3ET_1767531.png"><img src="_v_images/20200117100109129_22861.png"></a></p>
<p>我们可以看到ibatis占了较多内存</p>
<p>快速找出某个实例没被释放的原因，可以右健 Path to GC Roots–&gt;exclue all phantom/weak/soft etc. reference :</p>
<p> <img src="_v_images/20200117100108918_9987.png"></p>
<p>得到的结果是：</p>
<p><img src="_v_images/20200117100108703_17828.png"></p>
<p>从表中可以看出 PreferenceManager -&gt; … -&gt;HomePage这条线路就引用着这个 HomePage实例。用这个方法可以快速找到某个对象的 <strong>GC Root</strong>,一个存在 GC Root的对象是不会被 GC回收掉的.</p>
<h3 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h3><p>详情参考 <a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstack.html">jstack 官方文档</a></p>
<p>jstack <pid>  打印jvm内部所有的线程</p>
<p> <em>jstack 15672 &gt;15673.txt  导出当前进程文件</em></p>
<p>可查看其中包含java.lang.Thread.State: WAITING (parking)，JAVA 线程包含的状态有：</p>
<p>NEW：线程尚未启动</p>
<p>RUNNABLE：线程正在 JVM 中执行</p>
<p>BLOCKED：线程在等待监控锁(monitor lock)</p>
<p>WAITING：线程在等待另一个线程进行特定操作（时间不确定）</p>
<p>TIMED_WAITING：线程等待另一个线程进行限时操作</p>
<p>TERMINATED：线程已退出</p>
<p>此时会生成一个monitor_tuning-0.0.1-SNAPSHOT.jar的 jar包，为避免本地的 CPU 消耗过多导致死机，建议上传上传到虚拟机进行测试</p>
<p>nohup java -jar monitor_tuning-0.0.1-SNAPSHOT.jar &amp;</p>
<p>访问 <a href="http://xx.xx.xx.xx:12345/loop(%E7%AB%AF%E5%8F%A312345%E5%9C%A8application.properties%E6%96%87%E4%BB%B6%E4%B8%AD%E5%AE%9A%E4%B9%89)">http://xx.xx.xx.xx:12345/loop(端口12345在application.properties文件中定义)</a></p>
<p>top 是查询所有进程的cpu 占用率<br>top还可以用来显示一个进程中各个线程CPU的占用率：top -p <pid> -H<br>top命令如下  </p>
<p><img src="_v_images/20200117100108489_10785.png"></p>
<p>top -p <pid>  -H 命令如下 看的是7930的进程</p>
<p><img src="_v_images/20200117100108169_20096.png"></p>
<p>使用 jstack <pid>可以导出追踪文件，文件中 PID 在 jstack 中显示的对应 nid 为十六进制(命令行可执行 print ‘%x’ <pid>可以进行转化，如1640对应的十六进制为668)</p>
<p>“http-nio-12345-exec-3” #18 daemon prio=5 os_prio=0 tid=0x00007f10003fb000 nid=0x668 runnable [0x00007f0fcf8f9000]<br>   java.lang.Thread.State: RUNNABLE<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.getPartneridsFromJson(CpuController.java:77)<br>…</p>
<p>访问<a href="http://xx.xx.xx.xx:12345/deadlock">http://xx.xx.xx.xx:12345/deadlock</a>(如上jstack <pid>导出追踪记录会发现如下这样的记录)</p>
<p> ![](_v_images/20200117100107951_17762.png =800x500)</p>
<h1 id="Java-stack-information-for-the-threads-listed-above"><a href="#Java-stack-information-for-the-threads-listed-above" class="headerlink" title="Java stack information for the threads listed above:"></a>Java stack information for the threads listed above:</h1><p>“Thread-5”:<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.lambda$deadlock$1(CpuController.java:41)<br>    - waiting to lock &lt;0x00000000edcf3470&gt; (a java.lang.Object)<br>    - locked &lt;0x00000000edcf3480&gt; (a java.lang.Object)<br>    at org.alanhou.monitor_tuning.chapter2.CpuController$$Lambda$337/547045985.run(Unknown Source)<br>    at java.lang.Thread.run(Thread.java:748)<br>“Thread-4”:<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.lambda$deadlock$0(CpuController.java:33)<br>    - waiting to lock &lt;0x00000000edcf3480&gt; (a java.lang.Object)<br>    - locked &lt;0x00000000edcf3470&gt; (a java.lang.Object)<br>    at org.alanhou.monitor_tuning.chapter2.CpuController$$Lambda$336/1704575158.run(Unknown Source)<br>    at java.lang.Thread.run(Thread.java:748)</p>
<p>Found 1 deadlock.</p>
<p>查看后台日志，都是使用tail -f catalina.out命令来查看  </p>
<p>jvisualvm 图形化工具<br>插件安装Tools&gt;Plugins&gt;Settings根据自身版本(java -version)更新插件中心地址，各版本查询地址：<br><a href="http://visualvm.github.io/pluginscenters.html">http://visualvm.github.io/pluginscenters.html</a><br> 建议安装：Visual GC, BTrace Workbench<br>概述 监控可以堆dump 线程可以线程dump 抽样器可以对cpu和内存进行抽样调查</p>
<p>以上是本地的JAVA进程监控，还可以进行远程的监控，在上图左侧导航的 Applications 下的 Remote 处右击Add Remote Host…，输入主机 IP 即可添加，在 IP 上右击会发现有两种连接 JAVA 进程进行监控的方式:JMX, jstatd</p>
<p>bin/catalina.sh(以192.168.0.5为例)</p>
<p>JAVA_OPTS=”$JAVA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9004 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.net.preferIPv4Stack=true -Djava.rmi.server.hostname=192.168.0.5”</p>
<p>启动tomcat，</p>
<p>启动tomcat服务<br>方式一：直接启动 ./startup.sh<br>方式二：作为服务启动 nohup ./startup.sh &amp;<br>查看tomcat运行日志<br>tail -f catalina.out</p>
<p>tomcat设置jvm参数<br>修改文件 apache-tomcat-9.0.10/bin下catalina.bat文件</p>
<p>以 JMX 为例，在 IP 上右击点击Add JMX Connection…，输入 IP:PORT</p>
<p><img src="_v_images/20200117100107732_2132.jpg" alt="Add JMX Connection"></p>
<p>以上为 Tomcat，其它 JAVA 进程也是类似的，如：</p>
<p>nohup java -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9005 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.net.preferIPv4Stack=true -Djava.rmi.server.hostname=192.168.0.5 -jar monitor_tuning-0.0.1-SNAPSHOT.jar &amp;</p>
<h3 id="BTrace"><a href="#BTrace" class="headerlink" title="BTrace"></a>BTrace</h3><p><a href="https://github.com/jbachorik/btrace/releases/latest">BTrace</a> 可以动态地向目标应用程序的字节码注入追踪代码，使用的技术有 JavaCompilerApi, JVMTI, Agent, Instrumentation+ASM</p>
<p>使用方法：JVisualVM中添加 BTrace 插件</p>
<p>方法二：btrace <pid> <trace_script></p>
<p>btrace只能调试本地进程<br>btrace修改后的字节码不能被还原</p>
<p>pom.xml 中添加 btrace-agent, btrace-boot, btrace-client的依赖</p>
<p><img src="_v_images/20200117100107618_23079.png"></p>
<p><img src="_v_images/20200117100107506_24487.png"></p>
<p>拦截构造方法</p>
<p><img src="_v_images/20200117100107296_11386.png"></p>
<p>拦截同名方法  </p>
<p><img src="_v_images/20200117100107084_31796.png"></p>
<p>拦截返回值  </p>
<p><img src="_v_images/20200117100106870_26027.png"></p>
<p>拦截行号</p>
<p><img src="_v_images/20200117100106659_4260.png"></p>
<p>拦截异常信息</p>
<p><img src="_v_images/20200117100106449_4493.png"></p>
<p>拦截复杂类型</p>
<p><img src="_v_images/20200117100106216_21011.png"></p>
<p>拦截正则表达式</p>
<p><img src="_v_images/20200117100105902_16999.png"></p>
<p>拦截环境参数信息  </p>
<p><img src="_v_images/20200117100105692_8879.png">  </p>
<p>常用参数：  </p>
<p>-Xms -Xmx  </p>
<p>-XX:NewSize -XX:MaxNewSize  </p>
<p>-XX:NewRatio -XX:SurvivorRatio  </p>
<p>-XX:MetaspaceSize -XX:MaxMetaspaceSize 以下几个参数通常这样只设置这个值即可  </p>
<p>-XX:+UseCompressedClassPointers  </p>
<p>-XX:CompressedClassSpaceSize  </p>
<p>-XX:InitialCodeCacheSize  </p>
<p>-XX:ReservedCodeCacheSize</p>
<p>Tomcat 远程 Debug</p>
<p>JDWP</p>
<p>bin/startup.sh 修改最后一行(添加 jpda)</p>
<p>exec “$PRGDIR”/“$EXECUTABLE” jpda start “$@”</p>
<p>bin/catalina.sh 为便于远程调试进行如下修改</p>
<p>JPDA_ADDRESS=”localhost:8000”</p>
<h1 id="修改为"><a href="#修改为" class="headerlink" title="修改为"></a>修改为</h1><p>JPDA_ADDRESS=”54321”</p>
<p>若发现54321端口启动存在问题可尝试bin/catalina.sh jpda start</p>
<p>使用 Eclipse 远程调试，右击 Debug As &gt; Debug Configurations… &gt; Remote Java Application &gt; 右击 New 新建</p>
<p>普通java进程可以这样配置<br>java -jar -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=10001 access-10000.jar</p>
<p>tomcat-manager 监控</p>
<p>1.conf/tomcat-users.xml添加用户</p>
  <role rolename="tomcat"/>
  <role rolename="manager-status"/>
  <role rolename="manager-gui"/>
  <user username="tomcat" password="123456" roles="tomcat,manager-gui,manager-status"/>

<p>2.conf/Catalina/localhost/manager.xml配置允许的远程连接</p>
<?xml version="1.0" encoding="UTF-8"?>
<p><Context privileged="true" antiResourceLocking="false"
        docBase="$(catalina.home)/webapps/manager"><br>  <Valve className="org.apache.catalina.valves.RemoteAddrValve"
        allow="127\\.0\\.0\\.1" /><br></Context></p>
<p>远程连接将allow=”127\.0\.0\.1”修改为allow=”^.*$”，浏览器中输入<a href="http://127.0.0.1:8080/manage%E6%88%96%E5%AF%B9%E5%BA%94%E7%9A%84">http://127.0.0.1:8080/manage或对应的</a> IP，用户名密码为tomcat-users.xml中所设置的</p>
<p>3.重启 Tomcat 服务</p>
<p><img src="_v_images/20200117100105380_4818.jpg" alt="Tomcat Manager"></p>
<p>psi-probe 监控</p>
<p>下载地址：<a href="https://github.com/psi-probe/psi-probe%EF%BC%8C">https://github.com/psi-probe/psi-probe，</a></p>
<p>下载后进入psi-probe-master目录，执行：</p>
<p>mvn clean package -Dmaven.test.skip</p>
<p>将 web/target/probe.war放到 Tomcat 的 webapps 目录下，同样需要conf/tomcat-users.xml和conf/Catalina/localhost/manager.xml中的配置（可保持不变），启动 Tomcat 服务</p>
<p>浏览器中输入<a href="http://127.0.0.1:8080/probe%E6%88%96%E5%AF%B9%E5%BA%94%E7%9A%84">http://127.0.0.1:8080/probe或对应的</a> IP，用户名密码为tomcat-users.xml中所设置的</p>
<p><img src="_v_images/20200117100105268_9524.jpg" alt="PSI Probe演示"></p>
<p>Tomcat 调优</p>
<p>线程优化（webapps/docs/config/http.html）：</p>
<p>maxConnections</p>
<p>acceptCount</p>
<p>maxThreads</p>
<p>minSpareThreads</p>
<p>配置优化（webapps/docs/config/host.html）：</p>
<p>autoDeploy</p>
<p>enableLookups（http.html）</p>
<p>reloadable（context.html）</p>
<p>protocol=”org.apache.coyote.http11.Http11AprProtocol”</p>
<p>Session 优化：</p>
<p>如果是 JSP, 可以禁用 Session</p>
<h3 id="Nginx-性能监控与调优"><a href="#Nginx-性能监控与调优" class="headerlink" title="Nginx 性能监控与调优"></a>Nginx 性能监控与调优</h3><p>Nginx 安装</p>
<p>添加 yum 源（/etc/yum.repos.d/nginx.repo）</p>
<p>[nginx]<br>name=nginx repo<br>baseurl=<a href="http://nginx.org/packages/centos/7/$basesearch/">http://nginx.org/packages/centos/7/$basesearch/</a><br>gpgcheck=0<br>enabled=1</p>
<p>安装及常用命令</p>
<p>yum install -y nginx</p>
<p>systemctl status|start|stop|reload|restart nginx<br>nginx -s stop|reload|quit|reopen  nginx  启动nginx<br>cat default.conf | grep -v “#’ &gt; default2.conf  移除配置文件中的注释 并生成新的配置文件<br>nginx -V<br>nginx -t</p>
<p>配置反向代理 setenforce 0</p>
<p>ngx_http_stub_status 监控连接信息</p>
<p>location = /nginx_status {<br>    stub_status on;<br>    access_log off;<br>    allow 127.0.0.1;<br>    deny all;<br>}</p>
<p>可通过curl <a href="http://127.0.0.1/nginx_status">http://127.0.0.1/nginx_status</a> 进行查看或注释掉 allow 和 deny 两行使用 IP 进行访问</p>
<p>ngxtop监控请求信息</p>
<p>查看官方使用方法：<a href="https://github.com/lebinh/ngxtop">https://github.com/lebinh/ngxtop</a></p>
<h1 id="安装-python-pip"><a href="#安装-python-pip" class="headerlink" title="安装 python-pip"></a>安装 python-pip</h1><p>yum install epel-release<br>yum install python-pip</p>
<h1 id="安装-ngxtop"><a href="#安装-ngxtop" class="headerlink" title="安装 ngxtop"></a>安装 ngxtop</h1><p>pip install ngxtop</p>
<p>使用示例</p>
<p>指定配置文件：ngxtop -c /etc/nginx/nginx.conf</p>
<p>查询状态是200：ngxtop -c /etc/nginx/nginx.conf -i ‘status == 200’</p>
<p>查询访问最多 ip：ngxtop -c /etc/nginx/nginx.conf -g remote_addr</p>
<p><img src="_v_images/20200117100103032_6684.jpg" alt="ngxtop查询访问最多 ip"></p>
<p>Nginx 优化</p>
<p>增加工作线程数和并发连接数</p>
<p>worker_processes  4; # 一般CPU 是几核就设置为几<br>events {<br>    worker_connections  1024; # 每个进程打开的最大连接数，包含了 Nginx 与客户端和 Nginx 与 upstream 之间的连接<br>    multi_accept on; # 可以一次建立多个连接<br>    use epoll;<br>}</p>
<p>启用长连接</p>
<p>upstream server_pool{<br>    server localhost:8080 weight=1 max_fails=2 fail_timeout=30s;<br>    server localhost:8081 weight=1 max_fails=2 fail_timeout=30s;<br>    keepalive 300; # 300个长连接<br>}<br>location / {<br>    proxy_http_version 1.1;<br>    proxy_set_header Upgrade $http_upgrade;<br>    proxy_set_header Connection “upgrade”;<br>    proxy_pass <a href="http://server/_pool">http://server\_pool</a>;<br>}</p>
<p>启用缓存压缩</p>
<p>gzip on;<br>gzip_http_version 1.1;<br>gzip_disable “MSIE [1-6]\.(?!.*SV1)”;<br>gzip_proxied any;<br>gzip_types text/plain text/css application/javascript application/x-javascript application/json application/xml application/vnd.ms-fontobject application/x-font-ttf application/svg+xml application/x-icon;<br>gzip_vary on;<br>gzip_static on;</p>
<p>操作系统优化</p>
<h1 id="配置文件-etc-sysctl-conf"><a href="#配置文件-etc-sysctl-conf" class="headerlink" title="配置文件/etc/sysctl.conf"></a>配置文件/etc/sysctl.conf</h1><p>sysctl -w net.ipv4.tcp_syncookies=1 # 防止一个套接字在有过多试图连接到时引起过载<br>sysctl -w net.core.somaxconn=1024 # 默认128，连接队列<br>sysctl -w net.ipv4.tcp_fin_timeout=10 # timewait 的超时时间<br>sysctl -w net.ipv4.tcp_tw_reuse=1 # os 直接使用 timewait的连接<br>sysctl -w net.ipv4.tcp_tw_recycle=0 # 回收禁用</p>
<h1 id="etc-security-limits-conf"><a href="#etc-security-limits-conf" class="headerlink" title="/etc/security/limits.conf"></a>/etc/security/limits.conf</h1><ul>
<li><pre><code>          hard    nofile            204800</code></pre>
</li>
<li><pre><code>          soft    nofile             204800</code></pre>
</li>
<li><pre><code>          soft    core             unlimited</code></pre>
</li>
<li><pre><code>          soft    stack             204800</code></pre>
</li>
</ul>
<p>其它优化</p>
<p>sendfile    on; # 减少文件在应用和内核之间拷贝<br>tcp_nopush    on; # 当数据包达到一定大小再发送<br>tcp_nodelay    off; # 有数据随时发送</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/Java/metric/MAT/</url>
    <content><![CDATA[<h1 id="MAT"><a href="#MAT" class="headerlink" title="MAT"></a>MAT</h1><p>为了演示MAT的使用方法，本文采用jamp生成了一个Java继承的dump文件。</p>
<h2 id="4-1-Overview选项"><a href="#4-1-Overview选项" class="headerlink" title="4.1 Overview选项"></a>4.1 Overview选项</h2><p>当成功启动MAT后，通过菜单选项“File-&gt;Open heap dump…”打开指定的dump文件后，将会生成Overview选项，如下所示：</p>
<p><img src="_v_images/20201115133304752_1908958530">  </p>
<pre><code>在Overview选项中，以饼状图的形式列举出了程序内存消耗的一些基本信息，其中每一种不同颜色的饼块都代表了不同比例的内存消耗情况。</code></pre>
<h3 id="4-2-Dominator-Tree"><a href="#4-2-Dominator-Tree" class="headerlink" title="4.2 Dominator Tree"></a>4.2 Dominator Tree</h3><p>如果说需要定位内存泄露的代码点，我们可以通过Dominator Tree菜单选项来进行排查。Dominator Tree提供了一个列表。<br>Dominator Tree：对象之间dominator关系树。如果从GC Root到达Y的的所有path都经过X，那么我们称X dominates Y，或者X是Y的Dominator 。<br>Dominator Tree由系统中复杂的对象图计算而来。从MAT的dominator tree中可以看到占用内存最大的对象以及每个对象的dominator，如下所示：</p>
<p> <img src="_v_images/20201115133304642_1953557219"></p>
<p>点开“+”符号，可以进一步查看内层应用情况，同时还可以看到对应类对象的属性值，如下所示：</p>
<p><img src="_v_images/20201115133304535_2038220777">  </p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="4-3-Histogram选项"><a href="#4-3-Histogram选项" class="headerlink" title="4.3 Histogram选项"></a>4.3 Histogram选项</h3><p>进一步，可以通过Histogram分析，Histogram列出了每个类的实例数量，点击Action下的Histogram，得到以下结果：</p>
<p><img src="_v_images/20201115133304326_712812495">  </p>
<p>如果需要查询特性的某个类，我们可以在第一行输入类名或者关键词进行正则匹配查找，如查找“netty”：</p>
<p><img src="_v_images/20201115133304118_1508343283">  </p>
<p>可以看出，查找“netty”输出的结果列表是无序的，如果匹配到的结果很多，查找起来比较困难，因此，我们可以对结果进行排序：选中结果列表的任意一行，鼠标右键-》Colums-&gt;Sort By-&gt;如Class Name，结果如下：</p>
<p><img src="_v_images/20201115133303913_1472138606">  </p>
<pre><code>当我们找到疑似存在泄漏的类之后，我们可以进行进一步分析。比较重要的一点，选中疑似类，右键出来选中List Objects,得到的结果再右键选中&quot;Paths to GC Roots&quot;,我们可以通过它快速找到GC ROOT，如果存在GC ROOT，它就不会被回收。</code></pre>
<h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><h3 id="4-4-Path-to-GC-Roots"><a href="#4-4-Path-to-GC-Roots" class="headerlink" title="4.4 Path to GC Roots"></a>4.4 Path to GC Roots</h3><pre><code>查看一个对象到RC Roots的引用链  

通常在排查内存泄漏的时候，我们会选择exclude all phantom/weak/soft etc.references，意思是查看排除虚引用/弱引用/软引用等的引用链，因为被虚引用/弱引用/软引用的对象可以直接被GC给回收，我们要看的就是某个对象否还存在Strong 引用链（在导出HeapDump之前要手动出发GC来保证），如果有，则说明存在内存泄漏，然后再去排查具体引用。 </code></pre>
<p><img src="_v_images/20201115133303706_1037916552">  </p>
<p><strong>其它重要选项：</strong></p>
<p>1. List objects ：<br>with incoming references 引用到该对象的对象<br>with outcoming references 被该对象引用的对象</p>
<p>2. Show objects by class ：<br>incoming references 引用到该对象的对象<br>outcoming references 被该对象引用的对象 </p>
<h3 id="-2"><a href="#-2" class="headerlink" title=""></a></h3><p>4.5 OQL(Object Query Language)</p>
<p>类似SQL查询语言<br>Classes：Table<br>Objects：Rows<br>Fileds： Cols</p>
<p><code>select  *  from com.example.mat.Listener</code></p>
<p><strong>查找size＝0并且未使用过的ArrayList</strong><br><code>select  *  from java.util.ArrayList  where size=0  and modCount=0</code></p>
<p><strong>查找所有的Activity</strong><br>select * from instanceof android.app.Activity</p>
<h3 id="4-6-利用Histogram和Dominator-Tree分析内存泄露"><a href="#4-6-利用Histogram和Dominator-Tree分析内存泄露" class="headerlink" title="4.6  利用Histogram和Dominator Tree分析内存泄露"></a>4.6  利用Histogram和Dominator Tree分析内存泄露</h3><pre><code>在分析内存泄露时，必须要掌握粒度，所谓粒度就是你此刻dump的hprof文件究竟是分析谁的泄露，如果你在开始前心中没有个目标，最后取出来的hprof也分析不出什么原因。粒度越小，对你分析问题也就越有利，当你把一个个小粒度问题解决后，整个App的泄露就迎刃而解了。也许这么说，大家心中有点迷糊。下面就举例来说吧：

假如现在有个项目包含Module几十个，每个Module包含的Activity数以百计，现在让你分析它是否内存泄露，如果你只是胡乱抓个hprof根本分析不出什么。假如你就针对某个Activity分析这样问题就简单多了。比如你现在分析ActivityA的内存泄露问题，你可以参考如下步骤：

Step1：进入ActivityA之前，你先dump个hprof文件HprofA；

Step2：进入ActivityA操作一会，再退出ActivityA后dump个hprof文件HprofB；

Step3：采用Histogram和Dominator Tree对比分析这两个Hprof文件，即可得出ActivityA是否泄露</code></pre>
<p>现在以分析TestActivity为例，按上述步骤实战分析，先抓取进入TestActivity前后的hprof文件，按如下步骤对比两个hprof的异同，如下图1,2：</p>
<p><img src="_v_images/20201115133303497_195864697">  </p>
<p>图1 选择所需比较的hprof  </p>
<p><img src="_v_images/20201115133303286_1803136553">  </p>
<p>图2 比较两个hprof  </p>
<pre><code>正如图2所示，易知在执行进出TestActivity后，多出了个TestActivity对象，按理论上来说在进入Activity后会创建个Activity，但是按Back键返回后这个Activity就会被销毁进而从Task栈上被移除，也就是说这个操作前后不应该会多出个Activity，因此可以断定TestActivity存在泄漏。

TestActivity存在泄漏，那我们应该怎么解决呢？因此我们就需要找到为何泄漏，为什么本该销毁的Activity却没有被销毁？如知真相如何，请看下图3-4</code></pre>
<p><img src="_v_images/20201115133303070_1797820935">  </p>
<p>图3 获取TestActivity的Reference chain  </p>
<p><img src="_v_images/20201115133302509_954891646">  </p>
<p>图4 TestActivity的引用关系  </p>
<pre><code>从图4易知TestActivity没有被释放就是因为GC Root(TestActivity$1)引用着TestActivity，到此原因也一目了然。找到了只是开始，解决才是关键。这时让我们查看下TestActivity代码：  </code></pre>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestActivity</span> <span class="keyword">extends</span> <span class="title">Activity</span> </span>&#123;       <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object mLock = <span class="keyword">new</span> Object();     <span class="meta">@Override</span>    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;                <span class="keyword">super</span>.onCreate(savedInstanceState);        DebugUtil.StrictModeDebug();        setContentView(R.layout.test_main);           <span class="keyword">new</span> Thread()&#123;<span class="comment">//匿名线程            public void run() &#123;                synchronized (mLock) &#123;                    try &#123;                        mLock.wait();                    &#125; catch (InterruptedException e) &#123;                        // TODO Auto-generated catch block                        e.printStackTrace();                    &#125;                &#125;            &#125;        &#125;.start();    &#125;&#125;</span></span><br></pre></td></tr></table></figure>
<pre><code>从代码上可以发现TestActivity里存在个匿名线程，且一直处于等待状态，直到退出TestActivity仍未被唤醒，进而导致该线程就一直没有结束，它所持有的TestActivity也就无法被释放了（可能大家听到此处会很疑惑，线程没有结束可以理解，但是它并没有持有TestActivity呀？我只能说是隐含this，如还不明白，请自行参阅java内部类相关内容），如要解决此泄露，只需在Activity的onDestory里将线程唤醒让其可以正常结束就OK了。</code></pre>
<p><strong>优化建议</strong></p>
<ol>
<li>使用线程时，一定要确保线程在周期性对象（如Activity）销毁时能正常结束，如能正常结束，但是Activity销毁后还需执行一段时间，也可能造成泄露，此时可采用WeakReference方法来解决，另外在使用Handler的时候，如存在Delay操作，也可以采用WeakReference；</li>
<li>使用Handler + HandlerThread时，记住在周期性对象销毁时调用looper.quit()方法；</li>
<li>建议少使用匿名类或内部类，可考虑使用嵌套类（带static那种类），减少对周期性对象的隐性持有；</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>JDK内置工具的使用</title>
    <url>/Java/metric/jdk-inner-tools/</url>
    <content><![CDATA[<p>参考: <a href="http://blog.csdn.net/fenglibing/article/details/6411999">http://blog.csdn.net/fenglibing/article/details/6411999</a></p>
<ol>
<li>javah (C Header and Stub File Generator:用于生成native方法对应的C头文件,见<a href="/java-NIO/">JNI</a></li>
<li><a href="http://blog.csdn.net/fenglibing/article/details/6411932">jps (Java Virtual Machine Process Status Tool)</a></li>
<li><a href="/Java/tools/jstack/">jstack (Java Stack Trace)</a></li>
<li><a href="http://blog.csdn.net/fenglibing/article/details/6411951">jstat (Java Virtual Machine Statistics Monitoring Tool)</a></li>
<li>jmap (Java Memory Map)</li>
<li>jinfo (Java Configuration Info)</li>
<li>jconsole (Java Monitoring and Management Console)</li>
<li>jvisualvm (Java Virtual Machine Monitoring, Troubleshooting, and Profiling Tool)</li>
<li>jhat (Java Heap Analyse Tool)</li>
<li>Jdb (The Java Debugger)</li>
<li>Jstatd (Java Statistics Monitoring Daemon)</li>
</ol>
<p>//TODO<br>javap</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set JAVA_OPTS=-Xms%INITIAL_HEAP_SIZE% -Xmx%MAXIMUM_HEAP_SIZE% -Xss%STACK_SIZE%</span><br><span class="line">if not &quot;%USER_LANGUAGE%&quot;==&quot;&quot; set JAVA_OPTS=%JAVA_OPTS% -Duser.language=%USER_LANGUAGE%</span><br><span class="line">if not &quot;%USER_COUNTRY%&quot;==&quot;&quot; set JAVA_OPTS=%JAVA_OPTS% -Duser.country=%USER_COUNTRY%</span><br><span class="line"></span><br><span class="line">rem run Jude //注释 运行jude</span><br><span class="line">start javaw %JAVA_OPTS% -jar &quot;%JUDE_HOME%\%JUDE_JAR%&quot;  %1 %2 %3 //</span><br><span class="line">IF ERRORLEVEL 2 goto noJavaw</span><br><span class="line">goto end</span><br></pre></td></tr></table></figure>




<hr>
<p>[源码]:</p>
<ol>
<li><a href="http://pan.baidu.com/s/1c0YLi4S">源码百度云链接</a>     密码：yfo5</li>
</ol>
<p>[参考文献]:</p>
<ol>
<li>Think in Java</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>【转载】jstack和线程dump分析</title>
    <url>/Java/metric/jstack/</url>
    <content><![CDATA[<p><a href="http://jameswxx.iteye.com/blog/1041173">http://jameswxx.iteye.com/blog/1041173</a></p>
<h1 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h1><p>jstack命令的语法格式： jstack  <pid>。可以用jps查看java进程id。这里要注意的是：</p>
<ol>
<li>不同的 JAVA虚机的线程 DUMP的创建方法和文件格式是不一样的, 不同的 JVM版本,  dump信息也有差别。本文中, 只以 SUN的 hotspot JVM 5.0_06 为例。</li>
<li>在实际运行中, 往往一次 dump的信息, 还不足以确认问题。建议产生三次 dump信息, 如果每次 dump都指向同一个问题, 我们才确定问题的典型性。</li>
</ol>
<h1 id="线程分析"><a href="#线程分析" class="headerlink" title="线程分析"></a>线程分析</h1><h2 id="JVM-线程"><a href="#JVM-线程" class="headerlink" title="JVM 线程"></a>JVM 线程</h2><p>在线程中, 有一些 JVM内部的后台线程, 来执行譬如垃圾回收, 或者低内存的检测等等任务, 这些线程往往在 JVM初始化的时候就存在, 如下所示：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&quot;Low Memory Detector&quot; daemon prio=10 tid=0x081465f8 nid=0x7 runnable [0x00000000..0x00000000]  </span><br><span class="line">​&quot;CompilerThread0&quot; daemon prio=10 tid=0x08143c58 nid=0x6 waiting on condition [0x00000000..0xfb5fd798]  </span><br><span class="line">​&quot;Signal Dispatcher&quot; daemon prio=10 tid=0x08142f08 nid=0x5 waiting on condition [0x00000000..0x00000000]  </span><br><span class="line">​&quot;Finalizer&quot; daemon prio=10 tid=0x08137ca0 nid=0x4 in Object.wait() [0xfbeed000..0xfbeeddb8]   ​</span><br><span class="line">​        at java.lang.Object.wait(Native Method)  </span><br><span class="line">​ ​        - waiting on &lt;0xef600848&gt; (a java.lang.ref.ReferenceQueue$Lock)  </span><br><span class="line">​ ​        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116)  </span><br><span class="line">​ ​        - locked &lt;0xef600848&gt; (a java.lang.ref.ReferenceQueue$Lock)  </span><br><span class="line">​ ​        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132)  </span><br><span class="line">​ ​        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)   ​</span><br><span class="line">​&quot;Reference Handler&quot; daemon prio=10 tid=0x081370f0 nid=0x3 in Object.wait() [0xfbf4a000..0xfbf4aa38]  </span><br><span class="line">​ ​        at java.lang.Object.wait(Native Method)  </span><br><span class="line">​ ​        - waiting on &lt;0xef600758&gt; (a java.lang.ref.Reference$Lock)  </span><br><span class="line">​ ​        at java.lang.Object.wait(Object.java:474)  </span><br><span class="line">​ ​        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)  </span><br><span class="line">​ ​        - locked &lt;0xef600758&gt; (a java.lang.ref.Reference$Lock)  </span><br><span class="line">&quot;VM Thread&quot; prio=10 tid=0x08134878 nid=0x2 runnable  </span><br><span class="line">&quot;VM Periodic Task Thread&quot; prio=10 tid=0x08147768 nid=0x8 waiting on condition&lt;/span&gt;  </span><br></pre></td></tr></table></figure>

<p>​     我们更多的是要观察用户级别的线程, 如下所示：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&quot;Thread-1&quot; prio=10 tid=0x08223860 nid=0xa waiting on condition [0xef47a000..0xef47ac38]   ​</span><br><span class="line">​        at java.lang.Thread.sleep(Native Method)   ​</span><br><span class="line">​        at testthread.MySleepingThread.method2(MySleepingThread.java:53)  </span><br><span class="line">​ ​        - locked &lt;0xef63d600&gt; (a testthread.MySleepingThread)  </span><br><span class="line">​ ​        at testthread.MySleepingThread.run(MySleepingThread.java:35)   ​</span><br><span class="line">​        at java.lang.Thread.run(Thread.java:595) &lt;/span&gt;  </span><br></pre></td></tr></table></figure>
<p>我们能看到：<br>​    * 线程的状态： waiting on condition<br>​    * 线程的调用栈<br>​    * 线程的当前锁住的资源： &lt;0xef63d600&gt;</p>
<h2 id="线程的状态分析"><a href="#线程的状态分析" class="headerlink" title="线程的状态分析"></a>线程的状态分析</h2><p>正如我们刚看到的那样, 线程的状态是一个重要的指标, 它会显示在线程 Stacktrace 的头一行结尾的地方。那么线程常见的有哪些状态呢？线程在什么样的情况下会进入这种状态呢？我们能从中发现什么线索？</p>
<h3 id="Runnable"><a href="#Runnable" class="headerlink" title="Runnable"></a>Runnable</h3><p>该状态表示线程具备所有运行条件, 在运行队列中准备操作系统的调度, 或者正在运行。</p>
<h3 id="Wait-on-condition"><a href="#Wait-on-condition" class="headerlink" title="Wait on condition"></a>Wait on condition</h3><p>该状态出现在线程等待某个条件的发生。具体是什么原因, 可以结合 stacktrace 来分析。</p>
<p>最常见的情况是线程在等待网络的读写, 比如当网络数据没有准备好读时, 线程处于这种等待状态, 而一旦有数据准备好读之后, 线程会重新激活, 读取并处理数据。<br>在 Java引入 NewIO之前, 对于每个网络连接, 都有一个对应的线程来处理网络的读写操作, 即使没有可读写的数据, 线程仍然阻塞在读写操作上, 这样有可能造成资源浪费, 而且给操作系统的线程调度也带来压力。在 NewIO里采用了新的机制, 编写的服务器程序的性能和可扩展性都得到提高。<br>​<br>如果发现有大量的线程都在处在 Wait on condition, 从线程 stack看,  正等待网络读写, 这可能是一个网络瓶颈的征兆。因为网络阻塞导致线程无法执行。一种情况是网络非常忙, 几 乎消耗了所有的带宽, 仍然有大量数据等待网络读 写；另一种情况也可能是网络空闲, 但由于路由等问题, 导致包无法正常的到达。所以要结合系统的一些性能观察工具来综合分析, 比如 netstat统计单位时间的发送包的数目, 如果很明显超过了所在网络带宽的限制 ; 观察 cpu的利用率, 如果系统态的 CPU时间, 相对于用户态的 CPU时间比例较高；如果程序运行在 Solaris 10平台上, 可以用 dtrace工具看系统调用的情况, 如果观察到 read/write的系统调用的次数或者运行时间遥遥领先；这些都指向由于网络带宽所限导致的网络瓶颈。另外一种出现 Wait on condition的常见情况是该线程在 sleep, 等待 sleep的时间到了时候, 将被唤醒。</p>
<h3 id="Waiting-for-monitor-entry-和-in-Object-wait"><a href="#Waiting-for-monitor-entry-和-in-Object-wait" class="headerlink" title="Waiting for monitor entry 和 in Object.wait()"></a>Waiting for monitor entry 和 in Object.wait()</h3><p>​<br>在多线程的 JAVA程序中, 实现线程之间的同步, 就要说说 Monitor。 Monitor是 Java中用以实现线程之间的互斥与协作的主要手段, 它可以看成是对象或者 Class的锁。每一个对象都有, 也仅有一个 monitor。每个 Monitor在某个时刻, 只能被一个线程拥有, 该线程就是 “Active Thread”, 而其它线程都是 “Waiting Thread”, 分别在两个队列 “ Entry Set”和 “Wait Set”里面等候。在 “Entry Set”中等待的线程状态是 “Waiting for monitor entry”, 而在 “Wait Set”中等待的线程状态是 “in Object.wait()”。<br>​<br>先看 “Entry Set”里面的线程。我们称被 synchronized保护起来的代码段为临界区。当一个线程申请进入临界区时, 它就进入了 “Entry Set”队列。对应的 code就像：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(obj) &#123;</span><br><span class="line">.........</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这时有两种可能性：</p>
<ol>
<li>该 monitor不被其它线程拥有,  Entry Set里面也没有其它等待线程。本线程即成为相应类或者对象的 Monitor的 Owner, 执行临界区的代码     </li>
<li>该 monitor被其它线程拥有, 本线程在 Entry Set队列中等待。*</li>
</ol>
<p>在第一种情况下, 线程将处于 “Runnable”的状态, 而第二种情况下, 线程 DUMP会显示处于 “waiting for monitor entry”。如下所示：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&quot;Thread-0&quot; prio=10 tid=0x08222eb0 nid=0x9 waiting for monitor entry [0xf927b000..0xf927bdb8]  ​</span><br><span class="line"> at testthread.WaitThread.run(WaitThread.java:39)   ​</span><br><span class="line"> - waiting to lock &lt;0xef63bf08&gt; (a java.lang.Object)   ​</span><br><span class="line"> - locked &lt;0xef63beb8&gt; (a java.util.ArrayList)   ​</span><br><span class="line"> at java.lang.Thread.run(Thread.java:595)  </span><br></pre></td></tr></table></figure>
<p>​<br>临界区的设置, 是为了保证其内部的代码执行的原子性和完整性。但是因为临界区在任何时间只允许线程串行通过, 这 和我们多线程的程序的初衷是相反的。 如果在多线程的程序中, 大量使用 synchronized, 或者不适当的使用了它, 会造成大量线程在临界区的入口等待, 造成系统的性能大幅下降。如果在线程 DUMP中发现了这个情况, 应该审查源码, 改进程序。</p>
<p>现在我们再来看现在线程为什么会进入 “Wait Set”。当线程获得了 Monitor, 进入了临界区之后, 如果发现线程继续运行的条件没有满足, 它则调用对象（一般就是被 synchronized 的对象）的 wait() 方法, 放弃了 Monitor, 进入 “Wait Set”队列。只有当别的线程在该对象上调用了 notify() 或者 notifyAll() ,  “ Wait Set”队列中线程才得到机会去竞争, 但是只有一个线程获得对象的 Monitor, 恢复到运行态。在 “Wait Set”中的线程,  DUMP中表现为： in Object.wait(), 类似于：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&quot;Thread-1&quot; prio=10 tid=0x08223250 nid=0xa in Object.wait() [0xef47a000..0xef47aa38]  </span><br><span class="line">​        at java.lang.Object.wait(Native Method)   ​</span><br><span class="line">​        - waiting on &lt;0xef63beb8&gt; (a java.util.ArrayList)   ​</span><br><span class="line">​        at java.lang.Object.wait(Object.java:474)   ​</span><br><span class="line">​        at testthread.MyWaitThread.run(MyWaitThread.java:40)   ​</span><br><span class="line">​        - locked &lt;0xef63beb8&gt; (a java.util.ArrayList)   ​</span><br><span class="line">​        at java.lang.Thread.run(Thread.java:595)  </span><br></pre></td></tr></table></figure>
<p>仔细观察上面的 DUMP信息, 你会发现它有以下两行：</p>
<ul>
<li>locked &lt;0xef63beb8&gt; (a java.util.ArrayList)</li>
<li>waiting on &lt;0xef63beb8&gt; (a java.util.ArrayList)<br>这里需要解释一下, 为什么先 lock了这个对象, 然后又 waiting on同一个对象呢？让我们看看这个线程对应的代码：</li>
</ul>
<p>Java代码  </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(obj) &#123;  </span><br><span class="line">​       .........  </span><br><span class="line">​       obj.wait();  </span><br><span class="line">​       .........  </span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>
<p>线程的执行中, 先用 synchronized 获得了这个对象的 Monitor（对应于 locked &lt;0xef63beb8&gt; ）。当执行到 obj.wait(), 线程即放弃了 Monitor的所有权, 进入 “wait set”队列（对应于 waiting on &lt;0xef63beb8&gt; ）。<br>​         往往在你的程序中, 会出现多个类似的线程, 他们都有相似的 DUMP信息。这也可能是正常的。比如, 在程序中, 有多个服务线程, 设计成从一个队列里面读取请求数据。这个队列就是 lock以及 waiting on的对象。当队列为空的时候, 这些线程都会在这个队列上等待, 直到队列有了数据, 这些线程被 Notify, 当然只有一个线程获得了 lock, 继续执行, 而其它线程继续等待。</p>
<h2 id="JDK-5-0-的-lock"><a href="#JDK-5-0-的-lock" class="headerlink" title="JDK 5.0 的 lock"></a>JDK 5.0 的 lock</h2><p>​        上面我们提到如果 synchronized和 monitor机制运用不当, 可能会造成多线程程序的性能问题。在 JDK 5.0中, 引入了 Lock机制, 从而使开发者能更灵活的开发高性能的并发多线程程序, 可以替代以往 JDK中的 synchronized和 Monitor的 机制。但是, 要注意的是, 因为 Lock类只是一个普通类,  JVM无从得知 Lock对象的占用情况, 所以在线程 DUMP中, 也不会包含关于 Lock的信息,  关于死锁等问题, 就不如用 synchronized的编程方式容易识别。</p>
<h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><ol>
<li>死锁<br>在多线程程序的编写中, 如果不适当的运用同步机制, 则有可能造成程序的死锁, 经常表现为程序的停顿, 或者不再响应用户的请求。比如在下面这个示例中, 是个较为典型的死锁情况：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&quot;Thread-1&quot; prio=5 tid=0x00acc490 nid=0xe50 waiting for monitor entry [0x02d3f000  </span><br><span class="line">..0x02d3fd68]  </span><br><span class="line">at deadlockthreads.TestThread.run(TestThread.java:31)  </span><br><span class="line">- waiting to lock &lt;0x22c19f18&gt; (a java.lang.Object)  </span><br><span class="line">- locked &lt;0x22c19f20&gt; (a java.lang.Object)  </span><br><span class="line">&quot;Thread-0&quot; prio=5 tid=0x00accdb0 nid=0xdec waiting for monitor entry [0x02cff000  </span><br><span class="line">..0x02cff9e8]  </span><br><span class="line">at deadlockthreads.TestThread.run(TestThread.java:31)  </span><br><span class="line">- waiting to lock &lt;0x22c19f20&gt; (a java.lang.Object)  </span><br><span class="line">- locked &lt;0x22c19f18&gt; (a java.lang.Object)  </span><br></pre></td></tr></table></figure>



<p>在 JAVA 5中加强了对死锁的检测。线程 Dump中可以直接报告出 Java级别的死锁, 如下所示：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Found one Java-level deadlock:  </span><br><span class="line">=============================  </span><br><span class="line">&quot;Thread-1&quot;:  </span><br><span class="line">waiting to lock monitor 0x0003f334 (object 0x22c19f18, a java.lang.Object),  </span><br><span class="line">which is held by &quot;Thread-0&quot;  </span><br><span class="line">&quot;Thread-0&quot;:  </span><br><span class="line">waiting to lock monitor 0x0003f314 (object 0x22c19f20, a java.lang.Object),  </span><br><span class="line">which is held by &quot;Thread-1&quot;   </span><br></pre></td></tr></table></figure>

<ol start="2">
<li>热锁<br>​        热锁, 也往往是导致系统性能瓶颈的主要因素。其表现特征为, 由于多个线程对临界区, 或者锁的竞争, 可能出现：</li>
</ol>
<ul>
<li>  频繁的线程的上下文切换：从操作系统对线程的调度来看, 当 线程在等待资源而阻塞的时候, 操作系统会将之切换出来, 放到等待的队列, 当线程获得资源之后, 调度算法会将这个线程切换进去, 放到执行队列中。    * 大量的系统调用：因为线程的上下文切换, 以及热锁的竞争, 或 者临界区的频繁的进出, 都可能导致大量的系统调用。    * 大部分 CPU开销用在 “系统态 ”：线程上下文切换, 和系统调用, 都会导致 CPU在 “系统态 ”运行, 换而言之, 虽然系统很忙碌, 但是 CPU用在 “用户态 ”的比例较小, 应用程序得不到充分的 CPU资源。</li>
<li> 随着 CPU数目的增多, 系统的性能反而下降。因为 CPU数目多, 同 时运行的线程就越多, 可能就会造成更频繁的线程上下文切换和系统态的 CPU开销, 从而导致更糟糕的性能。 *<br>上面的描述, 都是一个 scalability（可扩展性）很差的系统的表现。从整体的性能指标看, 由于线程热锁的存在, 程序的响应时间会变长, 吞吐量会降低。&lt; /span&gt;<br>​<br>那么, 怎么去了解 “热锁 ”出现在什么地方呢？一个重要的方法还是结合操作系统的各种工具观察系统资源使用状况, 以及收集 Java线程的 DUMP信息, 看线程都阻塞在什么方法上, 了解原因, 才能找到对应的解决方法。<br>​<br>我们曾经遇到过这样的例子, 程序运行时, 出现了以上指出的各种现象, 通过观察操作系统的资源使用统计信息, 以及线程 DUMP信息, 确定了程序中热锁的存在, 并发现大多数的线程状态都是 Waiting for monitor entry或者 Wait on monitor, 且是阻塞在压缩和解压缩的方法上。后来采用第三方的压缩包 javalib替代 JDK自带的压缩包后, 系统的性能提高了几倍。</li>
</ul>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>JStack</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/Java/metric/%E6%A0%88%E4%B8%8A%E5%88%86%E9%85%8D%E4%B8%8ETLAB/</url>
    <content><![CDATA[<h1 id="栈上分配与TLAB"><a href="#栈上分配与TLAB" class="headerlink" title="栈上分配与TLAB"></a>栈上分配与TLAB</h1><h2 id="逃逸分析-Escape-Analysis"><a href="#逃逸分析-Escape-Analysis" class="headerlink" title="逃逸分析(Escape Analysis)"></a>逃逸分析(Escape Analysis)</h2><h2 id="栈上分配"><a href="#栈上分配" class="headerlink" title="栈上分配"></a>栈上分配</h2><p>针对那些作用域不会逃逸出方法的对象，在分配内存时不再将对象分配在堆内存中，而是将对象属性打散后分配在栈（线程私有的，属于栈内存）上，这样，随着方法的调用结束，栈空间的回收就会随着将栈上分配的打散后的对象回收掉，不再给gc增加额外的无用负担，从而提升应用程序整体的性能</p>
<p>优点：</p>
<p>　　　　1）可以在函数调用结束后自行销毁对象，不需要垃圾回收器的介入，有效避免垃圾回收带来的负面影响</p>
<p>　　　　2）栈上分配速度快，提高系统性能</p>
<p>线程私有变量，大对象虚拟机会分配到TLAB中，<a href="https://www.jianshu.com/p/a7414c0ebb17">TLAB（Thread Local Allocation Buffer）要不要了解下？</a></p>
<p>在栈上分配该对象的内存,当栈帧从Java虚拟机栈中弹出，就自动销毁这个对象。减小垃圾回收器压力。</p>
<h2 id="TLAB"><a href="#TLAB" class="headerlink" title="TLAB"></a>TLAB</h2><p>TLAB全称ThreadLocalAllocBuffer，是线程的一块私有内存，如果设置了虚拟机参数 -XX:UseTLAB，在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个Buffer，如果需要分配内存，就在自己的Buffer上分配，这样就不存在竞争的情况，可以大大提升分配效率，当Buffer容量不够的时候，再重新从Eden区域申请一块继续使用，这个申请动作还是需要原子操作的。</p>
<p>TLAB的目的是在为新对象分配内存空间时，让每个Java应用线程能使用自己专属的分配指针来分配空间，均摊对GC堆（eden区）里共享的分配指针做更新而带来的同步开销。</p>
<p>TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。</p>
<table>
<thead>
<tr>
<th>启动参数</th>
<th>JVM内存分配模式</th>
<th>Eden区</th>
<th>YoungGC</th>
<th>耗时</th>
</tr>
</thead>
<tbody><tr>
<td>-XX:+DoEscapeAnalysis（开逃逸分析）-XX:+UseTLAB （开启TLAB）</td>
<td>虚拟机栈上分配模式(小对象)</td>
<td>较少使用</td>
<td>较少使用</td>
<td>很低</td>
</tr>
<tr>
<td>-XX:-DoEscapeAnalysis（关闭逃逸分析）-XX:+UseTLAB（开启TLAB）</td>
<td>TLAB区分配模式</td>
<td>大量使用</td>
<td>大量使用</td>
<td>较高</td>
</tr>
<tr>
<td>-XX:-DoEscapeAnalysis（关闭逃逸分析）-XX:-UseTLAB（关闭TLAB）</td>
<td>Eden区分配模式</td>
<td>大量使用</td>
<td>大量使用</td>
<td>特别高</td>
</tr>
</tbody></table>
<p>在学习Java的过程中，一般认为new出来的对象都是被分配在堆上的，其实这个结论不完全正确，因为是大部分new出来的对象被分配在堆上，而不是全部。通过对Java对象分配的过程分析，可以知道有另外两个地方也是可以存放对象的。这两个地方分别栈 （涉及逃逸分析相关知识）和TLAB（Thread Local Allocation Buffer）。我们首先对这两者进行介绍，而后对Java对象分配过程进行介绍。</p>
<h3 id="栈上分配-1"><a href="#栈上分配-1" class="headerlink" title="栈上分配"></a><strong>栈上分配</strong></h3><p>在JVM中，堆是线程共享的，因此堆上的对象对于各个线程都是共享和可见的，只要持有对象的引用，就可以访问堆中存储的对象数据。虚拟机的垃圾收集系统可以回收堆中不再使用的对象，但对于垃圾收集器来说，无论筛选可回收对象，还是回收和整理内存都需要耗费时间。</p>
<p>如果确定一个对象的作用域不会逃逸出方法之外，那可以将这个对象分配在栈上，这样，对象所占用的内存空间就可以随栈帧出栈而销毁。在一般应用中，不会逃逸的局部对象所占的比例很大，如果能使用栈上分配，那大量的对象就会随着方法的结束而自动销毁了，无须通过垃圾收集器回收，可以减小垃圾收集器的负载。</p>
<p>JVM允许将线程私有的对象打散分配在栈上，而不是分配在堆上。分配在栈上的好处是可以在函数调用结束后自行销毁，而不需要垃圾回收器的介入，从而提高系统性能。<br><strong>栈上分配的技术基础：</strong><br><strong>一是逃逸分析：</strong>逃逸分析的目的是判断对象的作用域是否有可能逃逸出函数体。关于逃逸分析的问题可以看我另一篇文章：</p>
<p><strong>二是标量替换：</strong>允许将对象打散分配在栈上，比如若一个对象拥有两个字段，会将这两个字段视作局部变量进行分配。</p>
<p>只能在server模式下才能启用逃逸分析，参数-XX:DoEscapeAnalysis启用逃逸分析，参数-XX:+EliminateAllocations开启标量替换（默认打开）。Java SE 6u23版本之后，HotSpot中默认就开启了逃逸分析，可以通过选项-XX:+PrintEscapeAnalysis查看逃逸分析的筛选结果。</p>
<h3 id="TLAB-1"><a href="#TLAB-1" class="headerlink" title="TLAB"></a><strong>TLAB</strong></h3><p>TLAB的全称是Thread Local Allocation Buffer，即线程本地分配缓存区，这是一个线程专用的内存分配区域。<br>由于对象一般会分配在堆上，而堆是全局共享的。因此在同一时间，可能会有多个线程在堆上申请空间。因此，每次对象分配都必须要进行同步（虚拟机采用CAS配上失败重试的方式保证更新操作的原子性），而在竞争激烈的场合分配的效率又会进一步下降。JVM使用TLAB来避免多线程冲突，在给对象分配内存时，每个线程使用自己的TLAB，这样可以避免线程同步，提高了对象分配的效率。  </p>
<p>TLAB本身占用eEden区空间，在开启TLAB的情况下，虚拟机会为<strong>每个Java线程分配一块TLAB空间</strong>。参数-XX:+UseTLAB开启TLAB，默认是开启的。TLAB空间的内存非常小，缺省情况下仅占有整个Eden空间的1%，当然可以通过选项-XX:TLABWasteTargetPercent设置TLAB空间所占用Eden空间的百分比大小。<br>由于TLAB空间一般不会很大，因此大对象无法在TLAB上进行分配，总是会直接分配在堆上。TLAB空间由于比较小，因此很容易装满。比如，一个100K的空间，已经使用了80KB，当需要再分配一个30KB的对象时，肯定就无能为力了。这时虚拟机会有两种选择，第一，废弃当前TLAB，这样就会浪费20KB空间；第二，将这30KB的对象直接分配在堆上，保留当前的TLAB，这样可以希望将来有小于20KB的对象分配请求可以直接使用这块空间。实际上虚拟机内部会维护一个叫作refill_waste的值，当请求对象大于refill_waste时，会选择在堆中分配，若小于该值，则会废弃当前TLAB，新建TLAB来分配对象。这个阈值可以使用TLABRefillWasteFraction来调整，它表示TLAB中允许产生这种浪费的比例。默认值为64，即表示使用约为1/64的TLAB空间作为refill_waste。默认情况下，TLAB和refill_waste都会在运行时不断调整的，使系统的运行状态达到最优。如果想要禁用自动调整TLAB的大小，可以使用-XX:-ResizeTLAB禁用ResizeTLAB，并使用-XX:TLABSize手工指定一个TLAB的大小。<br>-XX:+PrintTLAB可以跟踪TLAB的使用情况。一般不建议手工修改TLAB相关参数，推荐使用虚拟机默认行为。</p>
<h3 id="对象内存分配的两种方法"><a href="#对象内存分配的两种方法" class="headerlink" title="对象内存分配的两种方法"></a><strong>对象内存分配的两种方法</strong></h3><p>为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。</p>
<p>指针碰撞(Serial、ParNew等带Compact过程的收集器)<br>假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump the Pointer）。<br>空闲列表(CMS这种基于Mark-Sweep算法的收集器)<br>如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。  
  </p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p><strong>总体流程</strong><br><img src="_v_images/20200818211412253_811602284" alt="这里写图片描述"></p>
<p><strong>对象分配流程</strong><br><img src="_v_images/20200818211412147_1281640355" alt="这里写图片描述"><br>如果开启栈上分配，JVM会先进行栈上分配，如果没有开启栈上分配或则不符合条件的则会进行TLAB分配，如果TLAB分配不成功，再尝试在eden区分配，如果对象满足了直接进入老年代的条件，那就直接分配在老年代。</p>
<p><strong>对象在内存的引用方式</strong><br><img src="_v_images/20200818211411943_2105805507" alt="这里写图片描述"></p>
<p><strong>对象在内存中的结构</strong><br><img src="_v_images/20200818211411726_1562017878" alt="这里写图片描述"></p>
<p><a href="https://segmentfault.com/a/1190000004606059">参考</a></p>
]]></content>
  </entry>
  <entry>
    <title>Java性能指标与调优</title>
    <url>/Java/metric/performance/</url>
    <content><![CDATA[<p>无论是web服务、集群应用还是单机应用，涉及的性能相关的内容很多:</p>
<p>接下来分别从上层到底层介绍所涉及的点:</p>
<p>webpage–&gt;nginx–&gt;io–&gt;cpu–&gt;memory–&gt;JVM–&gt;Java</p>
<h2 id="webpage"><a href="#webpage" class="headerlink" title="webpage"></a>webpage</h2><h2 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h2><h2 id="io"><a href="#io" class="headerlink" title="io"></a>io</h2><h2 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h2><h2 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h2><h2 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h2><h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>memory</tag>
        <tag>IO</tag>
        <tag>JVM</tag>
        <tag>CPU</tag>
        <tag>Tomcat</tag>
        <tag>nginx</tag>
        <tag>queue</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title>monitor和synchronized</title>
    <url>/Java/multithread/01.1.monitor-synchronized/</url>
    <content><![CDATA[<p>转载自<a href="https://blog.csdn.net/javazejian/article/details/72828483#synchronized%E6%96%B9%E6%B3%95%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86">深入理解Java并发之synchronized实现原理</a></p>
<p>线程安全是并发编程中的重要关注点，应该注意到的是，造成线程安全问题的主要诱因有两点:</p>
<p>一是存在共享数据(也称临界资源)，二是存在多条线程共同操作共享数据。</p>
<p>因此为了解决这个问题，我们可能需要这样一个方案，当存在多个线程操作共享数据时，需要保证同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再进行，这种方式有个高尚的名称叫<strong>互斥锁</strong>，即能达到互斥访问目的的锁，也就是说当一个共享数据被当前正在访问的线程加上互斥锁后，在同一个时刻，其他线程只能处于等待的状态，直到当前线程处理完毕释放该锁。</p>
<p>在 Java 中，关键字 synchronized可以保证在同一个时刻，只有一个线程可以执行某个方法或者某个代码块(主要是对方法或者代码块中存在共享数据的操作)，同时我们还应该注意到synchronized另外一个重要的作用，synchronized可保证一个线程的变化(主要是共享数据的变化)被其他线程所看到（保证可见性，完全可以替代Volatile功能），这点确实也是很重要的。</p>
<h1 id="synchronized底层语义原理"><a href="#synchronized底层语义原理" class="headerlink" title="synchronized底层语义原理"></a>synchronized底层语义原理</h1><p>Java 虚拟机中的同步(Synchronization)基于进入和退出管程(Monitor)对象实现， 无论是显式同步(有明确的 <code>monitorenter</code> 和 <code>monitorexit</code> 指令,即同步代码块)还是隐式同步都是如此。同步用的最多的地方可能是被 <code>synchronized</code> 修饰的同步方法。同步方法 并不是由 <code>monitorenter</code> 和 <code>monitorexit</code> 指令来实现同步的，而是由方法调用指令读取运行时常量池中方法的 <code>ACC_SYNCHRONIZED</code> 标志来隐式实现的，先来了解一个概念Java对象头，这对深入理解synchronized实现原理非常关键。</p>
<h2 id="理解Java对象头与Monitor"><a href="#理解Java对象头与Monitor" class="headerlink" title="理解Java对象头与Monitor"></a>理解Java对象头与Monitor</h2><p>在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。如下：</p>
<p><img src="/images/java/multithread/monitor/object_struct_in_heap.png"></p>
<p>实例变量：存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。</p>
<p>填充数据：由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。</p>
<p>而对于顶部，则是Java对象头，它实现<code>synchronized</code>的锁对象的基础，这点我们重点分析它，一般而言，<code>synchronized</code>使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由<code>Mark Word</code> 和 <code>Class Metadata Address</code> 组成，其结构说明如下表：</p>
<table>
<thead>
<tr>
<th>虚拟机位数</th>
<th>头对象结构</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>32/64bit</td>
<td>Mark Word</td>
<td>存储对象的hashCode、锁信息或分代年龄或GC标志等信息</td>
</tr>
<tr>
<td>32/64bit</td>
<td>Class Metadata Address</td>
<td>类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的实例。</td>
</tr>
</tbody></table>
<p>其中Mark Word在默认情况下存储着对象的HashCode、分代年龄、锁标记位等</p>
<p>以下是32位JVM的Mark Word默认存储结构</p>
<table>
<thead>
<tr>
<th>锁状态</th>
<th>25bit</th>
<th>4bit</th>
<th>1bit是否是偏向锁</th>
<th>2bit 锁标志位</th>
</tr>
</thead>
<tbody><tr>
<td>无锁状态</td>
<td>对象HashCode</td>
<td>对象分代年龄</td>
<td>0</td>
<td>01</td>
</tr>
</tbody></table>
<p>由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间，如32位JVM下，除了上述列出的Mark Word默认存储结构外，还有如下可能变化的结构：</p>
<p><img src="/images/java/multithread/monitor/object_mark_word.png"></p>
<p>其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的，重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ObjectMonitor() &#123;</span><br><span class="line">    _header       = <span class="literal">NULL</span>;</span><br><span class="line">    _count        = <span class="number">0</span>; <span class="comment">//记录个数</span></span><br><span class="line">    _waiters      = <span class="number">0</span>,</span><br><span class="line">    _recursions   = <span class="number">0</span>;</span><br><span class="line">    _object       = <span class="literal">NULL</span>;</span><br><span class="line">    _owner        = <span class="literal">NULL</span>;</span><br><span class="line">    _WaitSet      = <span class="literal">NULL</span>; <span class="comment">//处于wait状态的线程，会被加入到_WaitSet</span></span><br><span class="line">    _WaitSetLock  = <span class="number">0</span> ;</span><br><span class="line">    _Responsible  = <span class="literal">NULL</span> ;</span><br><span class="line">    _succ         = <span class="literal">NULL</span> ;</span><br><span class="line">    _cxq          = <span class="literal">NULL</span> ;</span><br><span class="line">    FreeNext      = <span class="literal">NULL</span> ;</span><br><span class="line">    _EntryList    = <span class="literal">NULL</span> ; <span class="comment">//处于等待锁block状态的线程，会被加入到该列表</span></span><br><span class="line">    _SpinFreq     = <span class="number">0</span> ;</span><br><span class="line">    _SpinClock    = <span class="number">0</span> ;</span><br><span class="line">    OwnerIsThread = <span class="number">0</span> ;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>ObjectMonitor中有两个队列，<code>_WaitSet</code> 和 <code>_EntryList</code>，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，<code>_owner</code>指向持有ObjectMonitor对象的线程</p>
<ul>
<li>当多个线程同时访问一段同步代码时，首先会进入 <code>_EntryList</code> 集合</li>
<li>当线程获取到对象的<code>monitor</code> 后进入 <code>_Owner</code> 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1</li>
<li>若线程调用 <code>wait()</code> 方法，将释放当前持有的<code>monitor</code>，owner变量恢复为null，count自减1，同时该线程进入 <code>WaitSet</code>集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。</li>
</ul>
<p><img src="/images/java/multithread/monitor/monitor_lock.png"></p>
<p>monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，<strong>synchronized锁便是通过这种方式获取锁的</strong>，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因</p>
<h2 id="synchronized代码块底层原理"><a href="#synchronized代码块底层原理" class="headerlink" title="synchronized代码块底层原理"></a>synchronized代码块底层原理</h2><p>现在我们重新定义一个synchronized修饰的同步代码块，在代码块中操作共享变量i，如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SyncCodeBlock</span> </span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">int</span> i;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">syncTask</span><span class="params">()</span></span>&#123;</span><br><span class="line">       <span class="comment">//同步代码库</span></span><br><span class="line">       <span class="keyword">synchronized</span> (<span class="keyword">this</span>)&#123;</span><br><span class="line">           i++;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译上述代码并使用javap反编译后得到字节码如下(这里我们省略一部分没有必要的信息)：</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Classfile</span> /Users/zejian/Downloads/Java8_Action/src/main/java/com/zejian/concurrencys/SyncCodeBlock.class</span><br><span class="line">  Last modified <span class="number">2017</span>-<span class="number">6</span>-<span class="number">2</span><span class="comment">; size 426 bytes</span></span><br><span class="line">  MD5 checksum c80bc322c87b312de760942820b4fed5</span><br><span class="line">  Compiled from <span class="string">&quot;SyncCodeBlock.java&quot;</span></span><br><span class="line"><span class="symbol">public</span> class com.zejian.concurrencys.SyncCodeBlock</span><br><span class="line">  minor version: <span class="number">0</span></span><br><span class="line">  major version: <span class="number">52</span></span><br><span class="line"><span class="symbol">  flags:</span> ACC_PUBLIC, ACC_SUPER</span><br><span class="line"><span class="symbol">Constant</span> pool:</span><br><span class="line">  <span class="comment">//........省略常量池中数据</span></span><br><span class="line">  <span class="comment">//构造函数</span></span><br><span class="line">  public com.zejian.concurrencys.SyncCodeBlock()<span class="comment">;</span></span><br><span class="line"><span class="symbol">    descriptor:</span> ()V</span><br><span class="line"><span class="symbol">    flags:</span> ACC_PUBLIC</span><br><span class="line"><span class="symbol">    Code:</span></span><br><span class="line">      stack<span class="number">=1</span>, locals<span class="number">=1</span>, args_size<span class="number">=1</span></span><br><span class="line">         <span class="number">0</span>: aload_0</span><br><span class="line">         <span class="number">1</span>: invokespecial <span class="number">#1</span>                  <span class="comment">// Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span></span><br><span class="line">         <span class="number">4</span>: return</span><br><span class="line"><span class="symbol">      LineNumberTable:</span></span><br><span class="line">        line <span class="number">7</span>: <span class="number">0</span></span><br><span class="line">  <span class="comment">//===========主要看看syncTask方法实现================</span></span><br><span class="line">  public void syncTask()<span class="comment">;</span></span><br><span class="line"><span class="symbol">    descriptor:</span> ()V</span><br><span class="line"><span class="symbol">    flags:</span> ACC_PUBLIC</span><br><span class="line"><span class="symbol">    Code:</span></span><br><span class="line">      stack<span class="number">=3</span>, locals<span class="number">=3</span>, args_size<span class="number">=1</span></span><br><span class="line">         <span class="number">0</span>: aload_0</span><br><span class="line">         <span class="number">1</span>: dup</span><br><span class="line">         <span class="number">2</span>: astore_1</span><br><span class="line">         <span class="number">3</span>: monitorenter  <span class="comment">//注意此处，进入同步方法</span></span><br><span class="line">         <span class="number">4</span>: aload_0</span><br><span class="line">         <span class="number">5</span>: dup</span><br><span class="line">         <span class="number">6</span>: getfield      <span class="number">#2</span>             <span class="comment">// Field i:I</span></span><br><span class="line">         <span class="number">9</span>: iconst_1</span><br><span class="line">        <span class="number">10</span>: iadd</span><br><span class="line">        <span class="number">11</span>: putfield      <span class="number">#2</span>            <span class="comment">// Field i:I</span></span><br><span class="line">        <span class="number">14</span>: aload_1</span><br><span class="line">        <span class="number">15</span>: monitorexit   <span class="comment">//注意此处，退出同步方法</span></span><br><span class="line">        <span class="number">16</span>: goto          <span class="number">24</span></span><br><span class="line">        <span class="number">19</span>: astore_2</span><br><span class="line">        <span class="number">20</span>: aload_1</span><br><span class="line">        <span class="number">21</span>: monitorexit <span class="comment">//注意此处，退出同步方法</span></span><br><span class="line">        <span class="number">22</span>: aload_2</span><br><span class="line">        <span class="number">23</span>: athrow</span><br><span class="line">        <span class="number">24</span>: return</span><br><span class="line">      Exception table:</span><br><span class="line">      <span class="comment">//省略其他字节码.......</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="symbol">SourceFile:</span> <span class="string">&quot;SyncCodeBlock.java&quot;</span></span><br></pre></td></tr></table></figure>
<p>我们主要关注字节码中的如下代码</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line"><span class="number">3</span>: monitorenter  <span class="comment">//进入同步方法</span></span><br><span class="line"><span class="comment">//..........省略其他  </span></span><br><span class="line"><span class="number">15</span>: monitorexit   <span class="comment">//退出同步方法</span></span><br><span class="line"><span class="number">16</span>: goto          <span class="number">24</span></span><br><span class="line"><span class="comment">//省略其他.......</span></span><br><span class="line"><span class="number">21</span>: monitorexit <span class="comment">//退出同步方法</span></span><br></pre></td></tr></table></figure>
<p>从字节码中可知同步语句块的实现使用的是<code>monitorenter</code> 和 <code>monitorexit</code> 指令，其中<code>monitorenter</code>指令指向同步代码块的开始位置，<code>monitorexit</code>指令则指明同步代码块的结束位置，当执行<code>monitorenter</code>指令时，当前线程将试图获取 <code>objectref</code>(即对象锁) 所对应的 <code>monitor</code> 的持有权，当 <code>objectref</code> 的 <code>monitor</code> 的进入计数器为 0，那线程可以成功取得 <code>monitor</code>，并将计数器值设置为 1，取锁成功。如果当前线程已经拥有 <code>objectref</code> 的 <code>monitor</code> 的持有权，那它可以重入这个 <code>monitor</code> (关于重入性稍后会分析)，重入时计数器的值也会加 1。倘若其他线程已经拥有 <code>objectref</code> 的 <code>monitor</code> 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即<code>monitorexit</code>指令被执行，执行线程将释放 <code>monitor</code>(锁)并设置计数器值为0 ，其他线程将有机会持有 <code>monitor</code> 。</p>
<p>值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 <code>monitorenter</code> 指令都有执行其对应 <code>monitorexit</code> 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 <code>monitorenter</code> 和 <code>monitorexit</code> 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 <code>monitorexit</code> 指令。从字节码中也可以看出多了一个<code>monitorexit</code>指令，它就是异常结束时被执行的释放monitor 的指令。</p>
<h2 id="synchronized方法底层原理"><a href="#synchronized方法底层原理" class="headerlink" title="synchronized方法底层原理"></a>synchronized方法底层原理</h2><p>方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的<code>方法表结构</code>(method_info Structure) 中的 <code>ACC_SYNCHRONIZED</code> 访问标志区分一个方法是否同步方法。当方法调用时，调用指令将会 检查方法的 <code>ACC_SYNCHRONIZED</code> 访问标志是否被设置，如果设置了，执行线程将先持有 <code>monitor</code> （虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放 <code>monitor</code> 。在方法执行期间，执行线程持有了 <code>monitor</code> ，其他任何线程都无法再获得同一个 <code>monitor</code> 。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的 <code>monitor</code> 将在异常抛到同步方法之外时自动释放。下面我们看看字节码层面如何实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SyncMethod</span> </span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">int</span> i;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">syncTask</span><span class="params">()</span></span>&#123;</span><br><span class="line">           i++;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用javap反编译后的字节码如下：</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Classfile</span> /Users/zejian/Downloads/Java8_Action/src/main/java/com/zejian/concurrencys/SyncMethod.class</span><br><span class="line">  Last modified <span class="number">2017</span>-<span class="number">6</span>-<span class="number">2</span><span class="comment">; size 308 bytes</span></span><br><span class="line">  MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94</span><br><span class="line">  Compiled from <span class="string">&quot;SyncMethod.java&quot;</span></span><br><span class="line"><span class="symbol">public</span> class com.zejian.concurrencys.SyncMethod</span><br><span class="line">  minor version: <span class="number">0</span></span><br><span class="line">  major version: <span class="number">52</span></span><br><span class="line"><span class="symbol">  flags:</span> ACC_PUBLIC, ACC_SUPER</span><br><span class="line"><span class="symbol">Constant</span> pool<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">//省略没必要的字节码</span></span><br><span class="line">  <span class="comment">//==================syncTask方法======================</span></span><br><span class="line">  public synchronized void syncTask()<span class="comment">;</span></span><br><span class="line"><span class="symbol">    descriptor:</span> ()V</span><br><span class="line">    <span class="comment">//方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法</span></span><br><span class="line"><span class="symbol">    flags:</span> ACC_PUBLIC, ACC_SYNCHRONIZED</span><br><span class="line"><span class="symbol">    Code:</span></span><br><span class="line">      stack<span class="number">=3</span>, locals<span class="number">=1</span>, args_size<span class="number">=1</span></span><br><span class="line">         <span class="number">0</span>: aload_0</span><br><span class="line">         <span class="number">1</span>: dup</span><br><span class="line">         <span class="number">2</span>: getfield      <span class="number">#2</span>                  <span class="comment">// Field i:I</span></span><br><span class="line">         <span class="number">5</span>: iconst_1</span><br><span class="line">         <span class="number">6</span>: iadd</span><br><span class="line">         <span class="number">7</span>: putfield      <span class="number">#2</span>                  <span class="comment">// Field i:I</span></span><br><span class="line">        <span class="number">10</span>: return</span><br><span class="line"><span class="symbol">      LineNumberTable:</span></span><br><span class="line">        line <span class="number">12</span>: <span class="number">0</span></span><br><span class="line">        line <span class="number">13</span>: <span class="number">10</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="symbol">SourceFile:</span> <span class="string">&quot;SyncMethod.java&quot;</span></span><br></pre></td></tr></table></figure>
<p>从字节码中可以看出，synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。这便是synchronized锁在同步代码块和同步方法上实现的基本原理。</p>
<p>同时我们还必须注意到的是在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁，接下来我们将简单了解一下Java官方在JVM层面对synchronized锁的优化。</p>
<h2 id="Java虚拟机对synchronized的优化"><a href="#Java虚拟机对synchronized的优化" class="headerlink" title="Java虚拟机对synchronized的优化"></a>Java虚拟机对synchronized的优化</h2><p>锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。<br>随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级，下面我们将介绍偏向锁和轻量级锁以及JVM的其他优化手段，阐述Java虚拟机所提供的每个锁的核心优化思想，毕竟涉及到具体过程比较繁琐，如需了解详细过程可以查阅《深入理解Java虚拟机原理》。</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，<strong>在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得</strong>，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，<strong>如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提高了程序的性能</strong>。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果。但对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>倘若偏向锁失败，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“<strong>对绝大部分的锁，在整个同步周期内都不存在竞争</strong>”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。</p>
<h4 id="加锁过程"><a href="#加锁过程" class="headerlink" title="加锁过程"></a>加锁过程</h4><p>锁升级为轻量级锁之后，对象的 <code>Mark word</code> 也会进行相应的的变化。升级为轻量级锁的过程：</p>
<ul>
<li>线程在自己的栈桢中创建锁记录 LockRecord。</li>
<li>将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。</li>
<li>将锁记录中的 Owner 指针指向锁对象。</li>
<li>将锁对象的对象头的 MarkWord替换为指向锁记录的指针。</li>
</ul>
<h4 id="通过自旋锁加锁"><a href="#通过自旋锁加锁" class="headerlink" title="通过自旋锁加锁"></a>通过自旋锁加锁</h4><p>轻量级锁失败后，<strong>虚拟机为了避免线程真实地在操作系统层面挂起</strong>，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，<strong>线程持有锁的时间都不会太长</strong>，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。</p>
<p>轻量级锁在加锁过程中，用到了自旋锁所谓自旋，就是指当有另外一个线程来竞争锁时，这个线程会在原地循环等待，而不是把该线程给阻塞，直到那个获得锁的线程释放锁之后，这个线程就可以马上获得锁的。注意，锁在原地循环的时候，是会消耗 cpu 的，就相当于在执行一个啥也没有的 for 循环。所以，轻量级锁适用于那些同步代码块执行的很快的场景，这样，线程原地等待很短的时间就能够获得锁了。自旋锁的使用，其实也是有一定的概率背景，在大部分同步代码块执行的时间都是很短的。所以通过看似无异议的循环反而能提升锁的性能。但是自旋必要有一定的条件控制，否则如果一个线程执行同步代码块的时间很长，那么这个线程不断的循环反而会消耗 CPU 资源。默认情况下自旋的次数是 10 次，可以通过 preBlockSpin 来修改在 JDK1.6 之后，引入了自适应自旋锁，自适应意味着自旋的次数不是固定不变的，而是根据前一次在同一个锁上自旋的时间以及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。</p>
<h3 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h3><p>消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by zejian on 2017/6/4.</span></span><br><span class="line"><span class="comment"> * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创]</span></span><br><span class="line"><span class="comment"> * 消除StringBuffer同步锁</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringBufferRemoveSync</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(String str1, String str2)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//StringBuffer是线程安全,由于sb只会在append方法中使用,不可能被其他线程引用</span></span><br><span class="line">        <span class="comment">//因此sb属于不可能共享的资源,JVM会自动消除内部的锁</span></span><br><span class="line">        StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        sb.append(str1).append(str2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        StringBufferRemoveSync rmsync = <span class="keyword">new</span> StringBufferRemoveSync();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000000</span>; i++) &#123;</span><br><span class="line">            rmsync.add(<span class="string">&quot;abc&quot;</span>, <span class="string">&quot;123&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="关于synchronized-可能需要了解的关键点"><a href="#关于synchronized-可能需要了解的关键点" class="headerlink" title="关于synchronized 可能需要了解的关键点"></a>关于synchronized 可能需要了解的关键点</h2><h3 id="synchronized的可重入性"><a href="#synchronized的可重入性" class="headerlink" title="synchronized的可重入性"></a>synchronized的可重入性</h3><p>从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AccountingSync</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> AccountingSync instance=<span class="keyword">new</span> AccountingSync();</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> j=<span class="number">0</span>;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">1000000</span>;j++)&#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//this,当前实例对象锁</span></span><br><span class="line">            <span class="keyword">synchronized</span>(<span class="keyword">this</span>)&#123;</span><br><span class="line">                i++;</span><br><span class="line">                increase();<span class="comment">//synchronized的可重入性</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span></span>&#123;</span><br><span class="line">        j++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread t1=<span class="keyword">new</span> Thread(instance);</span><br><span class="line">        Thread t2=<span class="keyword">new</span> Thread(instance);</span><br><span class="line">        t1.start();t2.start();</span><br><span class="line">        t1.join();t2.join();</span><br><span class="line">        System.out.println(i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在获取当前实例对象锁后进入synchronized代码块执行同步代码，并在代码块中调用了当前实例对象的另外一个synchronized方法，再次请求当前实例锁时，将被允许，进而执行方法体代码，这就是重入锁最直接的体现，需要特别注意另外一种情况，<strong>当子类继承父类时，子类也是可以通过可重入锁调用父类的同步方法</strong>。注意由于synchronized是基于monitor实现的，因此每次重入，monitor中的计数器仍会加1。</p>
<h3 id="三种锁的对比"><a href="#三种锁的对比" class="headerlink" title="三种锁的对比"></a>三种锁的对比</h3><p><img src="/images/java/multithread/monitor/synchronized-3-locks.png" alt="三种锁对比"></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>monitor</tag>
        <tag>syncronized</tag>
      </tags>
  </entry>
  <entry>
    <title>线程生命周期</title>
    <url>/Java/multithread/01.thread-lifecycle/</url>
    <content><![CDATA[<pre><code>理解Java多线程, 需要深入理解`线程状态和锁`</code></pre>
<p>[TOC]</p>
<h1 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h1><p>由于每个时钟周期内, CPU 实际上只能执行一条指令. CPU每一个时刻只能做一件事, 多线程是通过任务调度给CPU分配任务实现的, 多线程的目的是为了最大限度的利用CPU资源.</p>
<p>操作系统负责管理进程和线程, 轮流(没有固定的顺序)分配每个进程很短的时间(不一定是均分), 然后在每个线程内部, 程序代码自己处理该进程内部线程的时间分配, 多个线程之间相互的切换去执行, 这个切换时间也是非常短的.</p>
<h2 id="程序、进程、线程之间的关系"><a href="#程序、进程、线程之间的关系" class="headerlink" title="程序、进程、线程之间的关系"></a>程序、进程、线程之间的关系</h2><ul>
<li>程序是一段静态的代码，是应用软件执行的蓝本。</li>
<li>进程是程序一次动态执行的过程，它对应了从代码加载、执行完毕的一个完整过程，这也是进程开始到消亡的过程。</li>
<li>线程是进程中独立、可调度的执行单元，是执行中最小单位。</li>
<li>一个程序一般是一个进程，但一个程序中也可以有多个进程。</li>
<li>一个进程中可以有多个线程，但只有一个主线程。</li>
<li>Java应用程序中默认的主线程是main方法，如果main方法中创建了其他线程，JVM就会执行其他的线程。</li>
</ul>
<h2 id="Java-进程"><a href="#Java-进程" class="headerlink" title="Java 进程"></a>Java 进程</h2><p>Java编写的程序是运行在JVM中的, 启动一个Java应用程序,  就会启动一个JVM进程. 在同一个JVM进程中, 有且只有一个进程, 就是它自己. 因此, 所有的程序代码的运行都是以线程运行的. 同一个进程中的所有线程共享一块内存块,  <strong>因此线程间通信很容易且速度很快</strong>.</p>
<ul>
<li>Java 中的线程是一个对象, 与其他 Java 中的对象一样, 具有变量和方法, 生死于堆上.</li>
</ul>
<p>调用栈</p>
<ul>
<li>Java 中的每个线程都有一个调用栈, 即使不创建任何新的线程,  线程也在后台运行着.</li>
<li>一旦创建一个新的线程,  就产生一个新的调用栈.</li>
</ul>
<h2 id="主线程"><a href="#主线程" class="headerlink" title="主线程"></a>主线程</h2><p>在JVM上运行一个应用程序时,  JVM首先寻找程序入口的<code>main()</code>方法,  然后运行<code>main()</code>方法, 此时就产生了一个Java线程, 这个线程就是主线程. 当main方法结束后,  主线程运行完成,  如果不存在额外的线程运行,  JVM进程随即退出.</p>
<p>调度的方式有两种：分时调度和抢占式调度, Java中采用的是<em>抢占式调度</em></p>
<h2 id="线程优先级"><a href="#线程优先级" class="headerlink" title="线程优先级"></a>线程优先级</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static int MAX_PRIORITY</span><br><span class="line">          线程可以具有的最高优先级.</span><br><span class="line">static int MIN_PRIORITY</span><br><span class="line">          线程可以具有的最低优先级.</span><br><span class="line">static int NORM_PRIORITY</span><br><span class="line">          分配给线程的默认优先级.</span><br></pre></td></tr></table></figure>
<p>当线程池中线程都具有相同的优先级, 调度程序的JVM实现自由选择它喜欢的线程. 这时候调度程序的操作有两种可能：<br>一是选择一个线程运行, 直到它阻塞或者运行完成为止.<br>二是时间分片, 为池内的每个线程提供均等的运行机会.</p>
<p>1~10之间的值是没有保证的. 一些JVM可能不能识别10个不同的值, 而将这些优先级进行每两个或多个合并, 变成少于10个的优先级, 则两个或多个优先级的线程可能被映射为一个优先级.</p>
<p>与线程休眠类似, 线程的优先级仍然无法保障线程的执行次序. 只不过, 优先级高的线程获取CPU资源的概率较大, 优先级低的并非没机会执行.</p>
<h1 id="线程的生命周期"><a href="#线程的生命周期" class="headerlink" title="线程的生命周期"></a>线程的生命周期</h1><p>创建–运行–中断–死亡</p>
<ul>
<li>创建：线程构造</li>
<li>运行：调用start()方法，进入run()方法</li>
<li>中断：sleep()、wait()</li>
<li>死亡：执行完run()方法或强制run()方法结束，线程死亡</li>
</ul>
<h1 id="线程的状态与转换"><a href="#线程的状态与转换" class="headerlink" title="线程的状态与转换"></a>线程的状态与转换</h1><p><img src="/images/java/multithread/01.base/Java-Thread-statue-01.png" alt="线程生命周期与状态转换"></p>
<h2 id="new与新建状态"><a href="#new与新建状态" class="headerlink" title="new与新建状态"></a>new与新建状态</h2><p>新建线程有两个方法: 继承Thread类 和 实现Runnable接口.</p>
<p>Runnable 接口的定义如下:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实现<code>Runnable</code>接口就需要实现run方法. <code>run</code>方法的内容就是线程要执行的任务.<br>Thread类, 是实现了Runable接口的类, 因此在Thread类中也存在run方法.</p>
<p>新建线程有若干种重载方法:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Thread</span><span class="params">(Runnable target)</span> </span>&#123;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Thread</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//由于 Thread 实现了 Runnable 接口,</span></span><br><span class="line"><span class="comment">//这种形式也可以以 Thread 对象为参数</span></span><br></pre></td></tr></table></figure>
<h2 id="start-启动与就绪状态-即可运行状态"><a href="#start-启动与就绪状态-即可运行状态" class="headerlink" title="start 启动与就绪状态(即可运行状态)"></a>start 启动与就绪状态(即可运行状态)</h2><p>调用<code>Thread.start()</code>方法, 该线程进入Runable(可运行)状态, 等待分配 CPU 资源, 当抢占到CPU资源时,<br>该线程启动,开始执行run方法.</p>
<p><code>Thread.start()</code>是唯一可以新建线程的方法. 执行 Thread.run() 和 Runable.run() 只会执行run方法, 不会启动新的线程.</p>
<p>一旦线程启动, 它就永远不能再重新启动. 只有一个新的线程可以被启动, 并且只能一次. 一个可运行的线程或死线程可以被重新启动.</p>
<p>线程的调度是JVM的一部分, 在一个CPU的机器上, 实际上一次只能运行一个线程. 一次只有一个<strong>线程栈</strong>执行. JVM线程调度程序决定实际运行哪个处于可运行状态的线程. 众多可运行线程中的某一个会被选中作为当前线程. 可运行线程被选择运行的顺序是没有保障的. 尽管通常采用队列形式, 但这是没有保障的. 队列形式是指当一个线程完成“一轮”时, 它移到可运行队列的尾部等待, 直到它最终排队到该队列的前端为止, 它才能被再次选中. 事实上, 我们把它称为<em>可运行池</em>而不是一个可运行队列, 目的是帮助认识线程并<em>不都是</em>以某种有保障的顺序排列成一个队列的事实.</p>
<h2 id="Running-运行"><a href="#Running-运行" class="headerlink" title="Running 运行"></a>Running 运行</h2><p>运行状态, 执行<code>run()</code>方法的内容.</p>
<p>当 Java 虚拟机继续执行线程, 直到下面任一情况出现为止:</p>
<ul>
<li>调用 Runtime的 exit 方法 <code>System.exit()</code></li>
<li>非守护线程全部停止运行, 无论是从 <code>run</code> 方法返回还是通过抛出一个传播到 <code>run</code> 方法之外的异常.</li>
</ul>
<p>几种特殊情况可能使线程离开运行状态：</p>
<ol>
<li>线程的<code>run()</code>方法完成.</li>
<li>在对象上调用<code>wait()</code>方法（不是在线程上调用）.</li>
<li>线程不能在对象上获得锁定, 它正试图运行该对象的方法代码.</li>
<li>线程调度程序可以决定将当前运行状态移动到可运行状态, 以便让另一个线程获得运行机会, 而不需要任何理由.</li>
</ol>
<h2 id="sleep-休眠"><a href="#sleep-休眠" class="headerlink" title="sleep() 休眠"></a>sleep() 休眠</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  Thread.sleep();</span><br><span class="line">&#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//原始定义</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">sleep</span><span class="params">(<span class="keyword">long</span> millis)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br></pre></td></tr></table></figure>
<p>调用 Thread 的静态方法可以进入休眠, sleep()作用：</p>
<ul>
<li>执行带锁的代码时, 不会释放锁</li>
<li>进入Blocked状态</li>
<li>线程在mills时间内不会醒来</li>
<li>mills时间到了, 线程变为<code>Runnable</code>状态</li>
<li>再次进入运行状态, 继续执行 sleep() 后面的代码</li>
</ul>
<p><code>Thread.sleep(long millis)</code>和<code>Thread.sleep(long millis, int nanos)</code>静态方法强制当前正在执行的线程休眠（暂停执行）, 以“减慢线程”.<br>当线程睡眠时, 它入睡在某个地方, 在苏醒之前不会返回到可运行状态. 当睡眠时间到期, 则返回到可运行状态.<br>线程睡眠的原因：线程执行太快, 或者需要强制进入下一轮, 因为Java规范不保证合理的轮换.</p>
<p>当休眠一定时间后, 线程会苏醒, 进入准备状态等待执行.</p>
<h2 id="Blocked-阻塞状态"><a href="#Blocked-阻塞状态" class="headerlink" title="Blocked 阻塞状态"></a>Blocked 阻塞状态</h2><p>阻塞状态是线程因为某种原因放弃CPU使用权, 暂时停止运行. 直到线程进入就绪状态, 才有机会转到运行状态. 阻塞的情况分三种：</p>
<ul>
<li>等待阻塞：运行的线程执行<code>wait()</code>方法, JVM会把该线程放入等待池中.</li>
<li>同步阻塞：运行的线程在获取对象的同步锁时, 若该同步锁被别的线程占用, 则JVM会把该线程放入锁池中.</li>
<li>其他阻塞：运行的线程执行<code>sleep()</code>或<code>join()</code>方法, 或者发出了<code>I/O</code>请求时, JVM会把该线程置为阻塞状态.<pre><code> 当`sleep()`状态超时、`join()`等待线程终止或者超时、或者`I/O`处理完毕时, 线程重新转入就绪状态.</code></pre>
</li>
</ul>
<h2 id="Synchronized锁与同步"><a href="#Synchronized锁与同步" class="headerlink" title="Synchronized锁与同步"></a>Synchronized锁与同步</h2><p><a href="/Java/multithread/01.1.monitor-synchronized/">monitor与synchronized</a></p>
<p>在 Java 中每个对象都有一个锁,(问题来了: Java对象锁信息保存在哪里?) 并且对象的锁同时只能被一个线程使用, 因此当某个线程得到对象的锁时, 其他线程也就没办法获得锁.<br>利用对象的锁, 可以实现只允许一个线程访问, 即同步.</p>
<p>当线程运行到 <code>synchronized</code> 时, 首先检测是否可以获得对象的锁, 如果可以获得,则马上获取锁. 如果不能获取锁, 线程阻塞, 开始等待其他线程释放锁.</p>
<p>当同步锁被释放时, 线程重新进入 Runnable 可运行状态.</p>
<p>需要同步时,一定要搞清楚<code>加锁的对象是什么</code></p>
<p>关于锁和同步, 有一下几个要点：</p>
<ul>
<li>只能同步方法, 而不能同步变量和类；</li>
<li>每个对象只有一个锁；当提到同步时, 应该清楚在什么上同步？也就是说, 在哪个对象上同步？</li>
<li>不必同步类中所有的方法, 类可以同时拥有同步和非同步方法.</li>
<li>线程睡眠(执行<code>sleep</code>)时, 它所持的任何锁都不会释放.</li>
<li>线程可以获得多个锁. 比如, 在一个对象的同步方法里面调用另外一个对象的同步方法, 则获取了两个对象的同步锁.</li>
</ul>
<h3 id="同步方法"><a href="#同步方法" class="headerlink" title="同步方法"></a>同步方法</h3><p>在方法名称前面增加 <code>synchronized</code> 关键字, 此时相当于以类的对象(即<code>this</code>)作为对象锁.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">function</span><span class="params">()</span></span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="同步代码块"><a href="#同步代码块" class="headerlink" title="同步代码块"></a>同步代码块</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(object1)&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以 <code>object1</code>作为对象锁</p>
<h3 id="同步静态方法"><a href="#同步静态方法" class="headerlink" title="同步静态方法"></a>同步静态方法</h3><ol>
<li><p>静态方法同步是以方法所在的class对象作为锁的.<br> 要同步静态方法, 需要一个用于整个类对象的锁, 这个对象是就是这个类（XXX.class).<br> 例如：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">setName</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">    Xxx.name = name;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 等价于</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">setName</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(Xxx.class)&#123;</span><br><span class="line">            Xxx.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 实质上, 线程进入该对象的的一种池中, 必须在那里等待, 直到其锁被释放</p>
</li>
<li><p>调用同一个类中的静态同步方法的线程将彼此阻塞, 它们都是锁定在相同的Class对象上.</p>
</li>
<li><p>静态同步方法和非静态同步方法将永远不会彼此阻塞, 因为静态方法锁定在Class对象上, 非静态方法锁定在该类的对象上.<br>对于非静态字段中可更改的数据, 通常使用非静态方法访问.<br>对于静态字段中可更改的数据, 通常使用静态方法访问.</p>
</li>
</ol>
<p><strong>减少锁定时间</strong></p>
<p>线程同步的目的是为了保护多个线程访问一个资源时对资源的破坏. 线程同步方法是通过锁来实现, 每个对象都有且仅有一个锁, 这个锁与一个特定的对象关联, 线程一旦获取了对象锁, 其他访问该对象的线程就无法再访问该对象的其他同步方法.</p>
<p><strong>synchronized中慎用sleep和yield</strong></p>
<p>在使用<code>synchronized</code>关键字时候, 应该尽可能避免在<code>synchronized</code>方法或<code>synchronized块</code>中使用<code>sleep</code>或者<code>yield</code>方法:<br>因为<code>synchronized</code>程序块占有着对象锁, 你休息那么其他的线程只能一边等着你醒来执行完了才能执行. 不但严重影响效率, 也不合逻辑. 同样, 在同步程序块内调用<code>yield</code>方法让出CPU资源也没有意义, 因为你占用着锁, 其他互斥线程还是无法访问同步程序块. 当然与同步程序块无关的线程可以获得更多的执行时间.</p>
<h2 id="wait-等待-与-notify-notifyAll-通知"><a href="#wait-等待-与-notify-notifyAll-通知" class="headerlink" title="wait 等待 与 notify/notifyAll 通知"></a><code>wait</code> 等待 与 <code>notify</code>/<code>notifyAll</code> 通知</h2><p><code>wait</code> 让本线程等待, <code>notify</code> 通知某个线程不再等待</p>
<p><code>wait()</code>作用主要有:</p>
<ul>
<li>释放锁</li>
<li>不继续执行 wait 后面的代码</li>
<li>本线程进入等待阻塞</li>
</ul>
<p><a href="https://stackoverflow.com/questions/1038007/why-should-wait-always-be-called-inside-a-loop">wait必须与while一起使用:(避免假唤醒)</a></p>
<blockquote>
<p>A thread can also wake up without being notified, interrupted, or timing out, a so-called spurious wakeup. While this will rarely occur in practice, applications must guard against it by testing for the condition that should have caused the thread to be awakened, and continuing to wait if the condition is not satisfied. In other words, waits should always occur in loops, like this one:<br>线程也可以在没有被通知，中断或超时的情况下唤醒，即所谓的虚假唤醒。 虽然这在实践中很少发生，但应用程序必须通过测试应该导致线程被唤醒的条件来防范它，并且如果条件不满足则继续等待。 换句话说，等待应该总是出现在循环中</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (!condition) &#123;</span><br><span class="line">     obj.wait();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>notify</code>()与 <code>notifyAll</code>()<br>针对同一个对象锁上的线程, 主要的作用是:</p>
<ul>
<li>不再等待, 从等待 Blocked 中转出</li>
<li>进入 Runnable 状态, 等待获取 CPU 资源. ??</li>
</ul>
<p><strong>线程唤醒 notify</strong></p>
<p>Object类中的<code>notify()</code>方法, 唤醒在此对象监视器上等待的单个线程. 如果所有线程都在此对象上等待, 则会选择唤醒其中一个线程. 选择是任意性的, 并在对实现做出决定时发生. 线程通过调用其中一个 <code>wait</code> 方法, 在对象的监视器上等待.  直到当前的线程放弃此对象上的锁定, 才能继续执行被唤醒的线程. 被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争；例如, 唤醒的线程在作为锁定此对象的下一个线程方面没有可靠的特权或劣势. 类似的方法还有一个<code>notifyAll()</code>, 唤醒在此对象监视器上等待的所有线程.</p>
<p><code>wait()</code>、<code>notify()</code>、<code>notifyAll()</code>都是Object的实例方法. 与每个对象具有锁一样, 每个对象可以有一个<code>线程列表</code>, 他们等待来自该信号（通知）. 线程通过执行对象上的wait()方法获得这个等待列表.</p>
<p>这3个方法<strong>必须处于synchronized代码块或者synchronized方法中</strong>，否则就会抛出IllegalMonitorStateException异常，这是因为这几个方法必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，</p>
<p><strong>千万注意</strong></p>
<p>当在对象上调用<code>wait()</code>方法时, 执行该代码的线程立即<code>放弃</code>它在对象上的锁. 然而调用<code>notify()</code>时, 并不意味着这时线程会放弃其锁. 如果线程仍然在完成同步代码, 则线程在移出之前不会放弃锁. 因此, 只要调用notify()并不意味着这时该锁变得可用.</p>
<p><code>notifyAll()</code> 方法, 起到的是一个通知作用,<strong>不释放锁, 也不获取锁.</strong> 只是告诉该对象上等待的线程“可以竞争执行了, 都醒来去执行吧”</p>
<h2 id="yield-让步"><a href="#yield-让步" class="headerlink" title="yield() 让步"></a>yield() 让步</h2><ul>
<li>当前线程让出, 进入<code>Runnable可执行状态</code></li>
<li>但是<strong>继续占着锁</strong></li>
<li>同级别或较高级别的开始竞争 CPU 资源</li>
</ul>
<p>Thread.yield()方法作用是：暂停当前正在执行的线程对象, 并执行其他线程.<br>yield()应该做的是让当前运行线程回到可运行状态, 以允许具有相同优先级的其他线程获得运行机会.</p>
<p>yield()从未导致线程转到等待/睡眠/阻塞状态. 在大多数情况下, yield()将导致线程从运行状态转到可运行状态, 但有可能没有效果.</p>
<p>// TODO 使用场景</p>
<h2 id="join-合并"><a href="#join-合并" class="headerlink" title="join() 合并"></a>join() 合并</h2><p>假设在 A 线程中,执行<code>B.join()</code> , B 线程放到 A 线程前面执行. A 线程转入阻塞状态首先执行 B 线程,<br>直到执行完 B 线程后, A 线程转入可运行状态就绪, 获取到 CPU 资源后再继续执行 join 后面的代码</p>
<p>还有 join() 的重载形式:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">B.join(<span class="number">1000</span>);  </span><br></pre></td></tr></table></figure>
<p>首先执行 B 1000毫秒, 1000毫秒后, 即使是没有执行完, 也会停止执行 B 线程, 开始执行join 语句后面的代码</p>
<p>请看join的原始定义</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Waits at most &#123;<span class="doctag">@code</span> millis&#125; milliseconds for this thread to</span></span><br><span class="line"><span class="comment">* die. A timeout of &#123;<span class="doctag">@code</span> 0&#125; means to wait forever.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt; This implementation uses a loop of &#123;<span class="doctag">@code</span> this.wait&#125; calls</span></span><br><span class="line"><span class="comment">* conditioned on &#123;<span class="doctag">@code</span> this.isAlive&#125;. As a thread terminates the</span></span><br><span class="line"><span class="comment">* &#123;<span class="doctag">@code</span> this.notifyAll&#125; method is invoked. It is recommended that</span></span><br><span class="line"><span class="comment">* applications not use &#123;<span class="doctag">@code</span> wait&#125;, &#123;<span class="doctag">@code</span> notify&#125;, or</span></span><br><span class="line"><span class="comment">* &#123;<span class="doctag">@code</span> notifyAll&#125; on &#123;<span class="doctag">@code</span> Thread&#125; instances.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span>  millis</span></span><br><span class="line"><span class="comment">*         the time to wait in milliseconds</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span>  IllegalArgumentException</span></span><br><span class="line"><span class="comment">*          if the value of &#123;<span class="doctag">@code</span> millis&#125; is negative</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span>  InterruptedException</span></span><br><span class="line"><span class="comment">*          if any thread has interrupted the current thread. The</span></span><br><span class="line"><span class="comment">*          &lt;i&gt;interrupted status&lt;/i&gt; of the current thread is</span></span><br><span class="line"><span class="comment">*          cleared when this exception is thrown.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">join</span><span class="params">(<span class="keyword">long</span> millis)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> base = System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">long</span> now = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (millis &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;timeout value is negative&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (millis == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">while</span> (isAlive()) &#123;</span><br><span class="line">            wait(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (isAlive()) &#123;</span><br><span class="line">            <span class="keyword">long</span> delay = millis - now;</span><br><span class="line">            <span class="keyword">if</span> (delay &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            wait(delay);</span><br><span class="line">            now = System.currentTimeMillis() - base;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实Join 方法实现是通过wait实现的.<br>当main 线程调用t.join 时候, main 线程会获得线程对象t 的锁 （wait 意味着拿到该对象的锁), 调用该对象的wait( 等待时间) ,直到该对象唤醒main 线程, 比如退出后.</p>
<h2 id="stop-停止"><a href="#stop-停止" class="headerlink" title="stop 停止"></a>stop 停止</h2><p>避免使用stop()，是因为它不安全。它会解除由线程获取的所有锁定，而且如果对象处于一种不连贯状态，那么其他线程能在那种状态下检查和修改它们。结果很难检查出真正的问题所在。</p>
<h2 id="suspend-暂停"><a href="#suspend-暂停" class="headerlink" title="suspend 暂停"></a>suspend 暂停</h2><p>suspend()方法容易发生死锁。调用suspend()的时候，目标线程会停下来，但却仍然持有在这之前获得的锁定。此时，其他任何线程都不能访问锁定的资源，除非被”挂起”的线程恢复运行。对任何线程来说，如果它们想恢复目标线程，同时又试图使用任何一个锁定的资源，就会造成死锁。所以不应该使用suspend()，而应在自己的Thread类中置入一个标志，指出线程应该活动还是挂起。若标志指出线程应该挂起，便用wait()命其进入等待状态。若标志指出线程应当恢复，则用一个notify()重新启动线程。</p>
<h2 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> Thread <span class="title">currentThread</span><span class="params">()</span></span></span><br><span class="line"><span class="function">        返回对当前正在执行的线程对象的引用.</span></span><br><span class="line"><span class="function">ClassLoader <span class="title">getContextClassLoader</span><span class="params">()</span></span></span><br><span class="line"><span class="function">        返回该线程的上下文 ClassLoader.</span></span><br><span class="line"><span class="function">Thread.State <span class="title">getState</span><span class="params">()</span></span></span><br><span class="line"><span class="function">        返回该线程的状态.</span></span><br><span class="line"><span class="function">ThreadGroup <span class="title">getThreadGroup</span><span class="params">()</span></span></span><br><span class="line"><span class="function">        返回该线程所属的线程组.</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">holdsLock</span><span class="params">(Object obj)</span></span></span><br><span class="line"><span class="function">        当且仅当当前线程在指定的对象上保持监视器锁时, 才返回 <span class="keyword">true</span>.</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setDefaultUncaughtExceptionHandler</span><span class="params">(Thread.UncaughtExceptionHandler eh)</span></span></span><br><span class="line"><span class="function">          设置当线程”由于未捕获到异常而突然终止, 并且没有为该线程定义其他处理程序时”所调用的默认处理程序.</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">stop</span><span class="params">()</span></span></span><br><span class="line"><span class="function">        已过时.</span></span><br><span class="line"><span class="function">        stop 的许多使用都应由只修改某些变量以指示目标线程应该停止运行的代码来取代.</span></span><br><span class="line"><span class="function">        目标线程应定期检查该变量, 并且如果该变量指示它要停止运行,  则从其运行方法依次返回.</span></span><br><span class="line"><span class="function">        如果目标线程等待很长时间（例如基于一个条件变量）,  则应使用 interrupt 方法来中断该等待.</span></span><br></pre></td></tr></table></figure>
<h3 id="线程中断与synchronized"><a href="#线程中断与synchronized" class="headerlink" title="线程中断与synchronized"></a>线程中断与synchronized</h3><p>线程中断</p>
<p>正如中断二字所表达的意义，在线程运行(run方法)中间打断它，在Java中，提供了以下3个有关线程中断的方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//中断线程（实例方法）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> Thread.interrupt();</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断线程是否被中断（实例方法）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">boolean</span> Thread.isInterrupted();</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断是否被中断并清除当前中断状态（静态方法）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> Thread.interrupted();</span><br></pre></td></tr></table></figure>
<p>当一个线程处于被阻塞状态或者试图执行一个阻塞操作时，使用Thread.interrupt()方式中断该线程，注意此时将会抛出一个InterruptedException的异常，同时中断状态将会被复位(由中断状态改为非中断状态)，如下代码将演示该过程：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterruptSleepThread3</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread t1 = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="comment">//while在try中，通过异常中断就可以退出run循环</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                        <span class="comment">//当前线程处于阻塞状态，异常必须捕捉处理，无法往外抛出</span></span><br><span class="line">                        TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;Interruted When Sleep&quot;</span>);</span><br><span class="line">                    <span class="keyword">boolean</span> interrupt = <span class="keyword">this</span>.isInterrupted();</span><br><span class="line">                    <span class="comment">//中断状态被复位</span></span><br><span class="line">                    System.out.println(<span class="string">&quot;interrupt:&quot;</span>+interrupt);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        t1.start();</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">        <span class="comment">//中断处于阻塞状态的线程</span></span><br><span class="line">        t1.interrupt();</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 输出结果:</span></span><br><span class="line"><span class="comment">           Interruted When Sleep</span></span><br><span class="line"><span class="comment">           interrupt:false</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如上述代码所示，我们创建一个线程，并在线程中调用了sleep方法从而使线程进入阻塞状态，启动线程后，调用线程实例对象的interrupt方法中断阻塞异常，并抛出InterruptedException异常，此时中断状态也将被复位。除了阻塞中断的情景，我们还可能会遇到处于运行期且非阻塞的状态的线程，这种情况下，直接调用Thread.interrupt()中断线程是不会得到任响应的，如下代码，将无法中断非阻塞状态下的线程：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterruputThread</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread t1=<span class="keyword">new</span> Thread()&#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">                <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;未被中断&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        t1.start();</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">        t1.interrupt();</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 输出结果(无限执行):</span></span><br><span class="line"><span class="comment">             未被中断</span></span><br><span class="line"><span class="comment">             未被中断</span></span><br><span class="line"><span class="comment">             未被中断</span></span><br><span class="line"><span class="comment">             ......</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>虽然我们调用了interrupt方法，但线程t1并未被中断，因为<strong>处于非阻塞状态的线程需要我们手动进行中断检测并结束程序</strong>，改进后代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterruputThread</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread t1=<span class="keyword">new</span> Thread()&#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">                <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">                    <span class="comment">//判断当前线程是否被中断</span></span><br><span class="line">                    <span class="keyword">if</span> (<span class="keyword">this</span>.isInterrupted())&#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;线程中断&quot;</span>);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                System.out.println(<span class="string">&quot;已跳出循环,线程中断!&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        t1.start();</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">        t1.interrupt();</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 输出结果:</span></span><br><span class="line"><span class="comment">            线程中断</span></span><br><span class="line"><span class="comment">            已跳出循环,线程中断!</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>一种是当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位，</li>
<li>另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码(其实就是结束run方法体的代码)。有时我们在编码时可能需要兼顾以上两种情况，那么就可以如下编写：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">//判断当前线程是否已中断,注意interrupted方法是静态的,执行后会对中断状态进行复位</span></span><br><span class="line">    <span class="keyword">while</span> (!Thread.interrupted()) &#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>事实上线程的中断操作对于正在等待获取的锁对象的synchronized方法或者代码块并不起作用，也就是对于synchronized来说，<strong>如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效</strong>。演示代码如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Created by zejian on 2017/6/2.</span></span><br><span class="line"><span class="comment">* Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创]</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SynchronizedBlocked</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Trying to call f()&quot;</span>);</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123; <span class="comment">// Never releases lock</span></span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 在构造器中创建新线程并启动获取对象锁</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SynchronizedBlocked</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//该线程已持有当前实例锁</span></span><br><span class="line">        <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                f(); <span class="comment">// Lock acquired by this thread</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//中断判断</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (Thread.interrupted()) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;中断线程!!&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                f();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        SynchronizedBlocked sync = <span class="keyword">new</span> SynchronizedBlocked();</span><br><span class="line">        Thread t = <span class="keyword">new</span> Thread(sync);</span><br><span class="line">        <span class="comment">//启动后调用f()方法,无法获取当前实例锁处于等待状态</span></span><br><span class="line">        t.start();</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//中断线程,无法生效</span></span><br><span class="line">        t.interrupt();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们在<code>SynchronizedBlocked</code>构造函数中创建一个新线程并启动获取调用f()获取到当前实例锁，由于<code>SynchronizedBlocked</code>自身也是线程，启动后在其run方法中也调用了f()，但由于对象锁被其他线程占用，导致t线程只能等到锁，此时我们调用了<code>t.interrupt();</code>但并不能中断线程。</p>
<h1 id="线程死锁"><a href="#线程死锁" class="headerlink" title="线程死锁"></a>线程死锁</h1><p>线程A当前持有互斥所锁 lock1 ，线程B当前持有互斥锁 lock2 。 接下来，当线程A仍然持有lock1时，它试图获取lock2，因为线程B正持有lock2，因此线程A会阻塞等待线程B对lock2的释放。如果此时线程B在持有lock2的时候，也在试图获取lock1，因为线程A正持有lock1，因此线程B会阻塞等待A对lock1的释放。二者都在等待对方所持有锁的释放，而二者却又都没释放自己所持有的锁，这时二者便会一直阻塞下去。这种情形称为死锁。</p>
<p>规避死锁：</p>
<ol>
<li>只在必要的最短时间内持有锁，考虑使用同步语句块代替整个同步方法；</li>
<li>尽量编写不在同一时刻需要持有多个锁的代码，如果不可避免，则确保线程持有第二个锁的时间尽量短暂；</li>
<li>创建和使用一个大锁来代替若干小锁，并把这个锁用于互斥，而不是用作单个对象的对象级别锁；</li>
</ol>
<h1 id="同步方案"><a href="#同步方案" class="headerlink" title="同步方案"></a>同步方案</h1><p>在需要同步的时候，第一选择应该是synchronized关键字，这是最安全的方式，尝试其他任何方式都是有风险的。尤其在jdK1.5之后，对synchronized同步机制做了很多优化，如：自适应的自旋锁、锁粗化、锁消除、轻量级锁等，使得它的性能明显有了很大的提升。</p>
<p>[volatile][a-volatile] 也是确保可见性的方法之一，但是不能实现原子性</p>
<h2 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h2><p>如果同一个方法内同时有两个或更多线程，则每个线程有自己的局部变量拷贝， 采用 <code>synchronized</code> 修饰符实现的同步机制叫做互斥锁机制，它所获得的锁叫做互斥锁。 每个对象都有一个monitor(锁标记)，当线程拥有这个锁标记时才能访问这个资源，没有锁标记便进入锁池。 任何一个对象系统都会为其创建一个互斥锁，这个锁是为了分配给线程的，防止打断原子操作。每个对象的锁只能分配给一个线程，因此叫做互斥锁。</p>
<p>互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。synchronized 关键字经过编译后，会在同步块的前后分别形成 <code>monitorenter</code> 和 <code>monitorexit</code> <code>这两个字节码指令。根据虚拟机规范的要求，在执行monitorenter</code> 指令时，首先要尝试获取对象的锁，如果获得了锁，把锁的计数器加1，相应地，在执行 <code>monitorexit</code> 指令时会将锁计数器减1，当计数器为0时，锁便被释放了。由于synchronized同步块对同一个线程是可重入的，因此一个线程可以多次获得同一个对象的互斥锁，同样，要释放相应次数的该互斥锁，才能最终释放掉该锁。</p>
<p>当一个线程进入一个对象的一个synchronized方法后，其它线程是否可进入此对象的其它方法? 分几种情况：</p>
<ol>
<li>其他方法前是否加了synchronized关键字，如果没加，则能。</li>
<li>如果这个方法内部调用了wait，则可以进入其他synchronized方法。</li>
<li>如果其他个方法都加了synchronized关键字，并且内部没有调用wait，则不能。</li>
<li>如果其他方法是static，它用的同步锁是当前类的字节码，与非静态的方法不能同步，因为非静态的方法用的是this。</li>
</ol>
<h1 id="线程安全类"><a href="#线程安全类" class="headerlink" title="线程安全类"></a>线程安全类</h1><p>请查看 <a href="/Java/collection-map/">Java集合</a></p>
<h1 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h1><p>线程总体分两类：用户线程和守候线程.</p>
<p>当所有用户线程执行完毕的时候, JVM自动关闭. 但是守候线程却不独立于JVM, 守候线程一般是由操作系统或者用户自己创建的.</p>
<p>举例来说, JVM的垃圾回收、内存管理等线程都是守护线程.<br>还有就是在做数据库应用时候, 使用的数据库连接池, 连接池本身也包含着很多后台线程, 监控连接个数、超时时间、状态等等.</p>
<h1 id="Timer"><a href="#Timer" class="headerlink" title="Timer"></a>Timer</h1><p>有一个后台运行的线程,  按照指定的时间执行定时任务. <code>Timer.schedual()</code>方法向后台线程添加定时任务,<br>后台线程按照的既定的时间执行定时任务.</p>
<p>调用<code>Timer.cancel()</code>取消所有已安排的定时任务,  正在的执行的任务不会被取消.</p>
<p>调用构造方法, 后台线程就已经启动.</p>
<hr>
<p>[参考文献]：</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程2: Lock、信号量、原子量与队列</title>
    <url>/Java/multithread/02.Lock-Semaphore-Atomic/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt;Java高级软件工程师知识结构</a></p>
<pre><code>Java多线程是Java基础的重要的一部分，支持多线程是Java的重要特性之一. 主要包括如下内容:</code></pre>
<blockquote>
<ol>
<li><a href="/Java/multithread/01.base/">Java多线程1: 线程生命周期和多线程基础</a></li>
<li><a href="/Java/multithread/02.Lock-Semaphore-Atomic/">Java多线程2: Lock、信号量、原子量与队列</a></li>
<li><a href="/Java/multithread/03.volatile/">Java多线程3: volatile</a></li>
<li><a href="/Java/multithread/04.thread-synchronization/">Java多线程4: 同步锁与Java线程同步方法比较</a></li>
<li><a href="/Java/multithread/05.ThreadPool/">Java多线程5: 线程池</a></li>
<li><a href="/Java/multithread/06.BlockingQueue/">Java多线程6: Java阻塞队列与生产者消费者模式</a></li>
</ol>
</blockquote>
<p>更详细内容请参考博文 <a href="http://www.cnblogs.com/dolphin0520/p/3923167.html">Java并发编程：Lock</a></p>
<p>Sun在Java5中, 对Java线程的类库做了大量的扩展</p>
<h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><p>在<code>java.util.concurrent.locks</code> 包下面, 里面有三个重要的接口<code>Condition</code>、<code>Lock</code>、<code>ReadWriteLock</code>.</p>
<h2 id="Condition"><a href="#Condition" class="headerlink" title="Condition"></a>Condition</h2><p><code>Condition</code> 将 Object 监视器方法（<code>wait</code>、<code>notify</code> 和 <code>notifyAll</code>）分解成截然不同的对象, 以便通过将这些对象与任意 <code>Lock</code> 实现组合使用, 为每个对象提供多个等待 <code>set</code> （<code>wait-set</code>）.</p>
<h2 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h2><p><code>Lock</code>实现提供了比使用 <code>synchronized</code> 方法和语句可获得的更广泛的锁定操作.</p>
<h2 id="ReadWriteLock"><a href="#ReadWriteLock" class="headerlink" title="ReadWriteLock"></a>ReadWriteLock</h2><p><code>ReadWriteLock</code>维护了一对相关的锁定, 一个用于只读操作, 另一个用于写入操作.</p>
<h2 id="Lock-与-synchronized的区别"><a href="#Lock-与-synchronized的区别" class="headerlink" title="Lock 与 synchronized的区别"></a>Lock 与 synchronized的区别</h2><p>见文献 <a href="http://blog.csdn.net/natian306/article/details/18504111">深入研究 Java Synchronize 和 Lock 的区别与用法</a></p>
<ol>
<li><p>用法上的区别<br><code>synchronized</code>可以加在方法或代码块上，而<code>Lock</code>必须指定起始位置，一般使用<code>ReentrantLock</code>类做为锁，多个线程中必须要使用一个<code>ReentrantLock</code>类做为对象才能保证锁的生效。且在加锁和解锁处需要通过<code>lock()</code>和<code>unlock()</code>显式指出。所以一般会在<code>finally</code>块中写<code>unlock()</code>以防死锁。</p>
<ol>
<li>ReentrantLock非阻塞</li>
<li>ReentrantLock CAS实现无锁</li>
<li>可以指定等待时间，可以中断</li>
<li>公平锁：按照申请顺序</li>
<li>可以指定条件</li>
<li><code>await</code>必须与<code>while</code>一起使用  </li>
<li>Lock可以知道线程有没有成功获取到锁。这个是synchronized无法办到的</li>
<li>synchronized在发生异常时，会自动释放线程占有的锁，不会导致死锁现象发生；<br>而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；</li>
</ol>
</li>
<li><p>性能上的区别<br><code>synchronized</code>是托管给JVM执行的，而lock是java写的控制锁的代码。<code>synchronized</code>是悲观锁，线程获取到的是<code>独占锁</code>。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。多个线程竞争资源，CPU频繁切换效率变低。</p>
<p><code>Lock</code>使用的是乐观锁，乐观锁就是CAS，调用CPU的指令，效率比较高。是非阻塞算法。 每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是CAS操作（Compare and Swap）。获得锁的一个方法是compareAndSetState. CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。这个算法称作<code>非阻塞算法</code>，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。</p>
</li>
<li><p>用途上的区别<br>高并发情况下，比较适合使用Lock，特别是在下面的情况下:</p>
<ul>
<li>某个线程在等待一个锁的控制权的这段时间需要中断</li>
<li>需要分开处理一些<code>wait-notify</code>，<code>ReentrantLock</code>里面的<code>Condition</code>应用，能够控制<code>notify</code>哪个线程</li>
<li>具有公平锁功能，每个到来的线程都将排队等候</li>
</ul>
</li>
</ol>
<h2 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h2><p>ReentrantLock是唯一实现了Lock接口的类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建并发访问的账户</span></span><br><span class="line">MyCount myCount = <span class="keyword">new</span> MyCount(<span class="string">&quot;95599200901215522&quot;</span>, <span class="number">10000</span>);</span><br><span class="line"><span class="comment">//创建一个锁对象</span></span><br><span class="line">Lock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line"><span class="comment">//创建一个线程池</span></span><br><span class="line">ExecutorService pool = Executors.newCachedThreadPool();</span><br><span class="line"><span class="comment">//创建一些并发访问用户, 一个信用卡, 存的存, 取的取, 好热闹啊</span></span><br><span class="line">User u1 = <span class="keyword">new</span> User(<span class="string">&quot;张三&quot;</span>, myCount, -<span class="number">4000</span>, lock);</span><br><span class="line">User u2 = <span class="keyword">new</span> User(<span class="string">&quot;张三他爹&quot;</span>, myCount, <span class="number">6000</span>, lock);</span><br><span class="line">User u3 = <span class="keyword">new</span> User(<span class="string">&quot;张三他弟&quot;</span>, myCount, -<span class="number">8000</span>, lock);</span><br><span class="line">User u4 = <span class="keyword">new</span> User(<span class="string">&quot;张三&quot;</span>, myCount, <span class="number">800</span>, lock);</span><br><span class="line"><span class="comment">//在线程池中执行各个用户的操作</span></span><br><span class="line">pool.execute(u1);</span><br><span class="line">pool.execute(u2);</span><br><span class="line">pool.execute(u3);</span><br><span class="line">pool.execute(u4);</span><br><span class="line"><span class="comment">//关闭线程池</span></span><br><span class="line">pool.shutdown();</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 信用卡的用户</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String name;                <span class="comment">//用户名</span></span><br><span class="line">  <span class="keyword">private</span> MyCount myCount;        <span class="comment">//所要操作的账户</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> iocash;                 <span class="comment">//操作的金额, 当然有正负之分了</span></span><br><span class="line">  <span class="keyword">private</span> Lock myLock;                <span class="comment">//执行操作所需的锁对象</span></span><br><span class="line">  User(String name, MyCount myCount, <span class="keyword">int</span> iocash, Lock myLock) &#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">    <span class="keyword">this</span>.myCount = myCount;</span><br><span class="line">    <span class="keyword">this</span>.iocash = iocash;</span><br><span class="line">    <span class="keyword">this</span>.myLock = myLock;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//获取锁</span></span><br><span class="line">    myLock.lock();</span><br><span class="line">    <span class="comment">//执行现金业务</span></span><br><span class="line">    System.out.println(name + <span class="string">&quot;正在操作&quot;</span> + myCount + <span class="string">&quot;账户, 金额为&quot;</span> + iocash + <span class="string">&quot;, 当前金额为&quot;</span> + myCount.getCash());</span><br><span class="line">    myCount.setCash(myCount.getCash() + iocash);</span><br><span class="line">    System.out.println(name + <span class="string">&quot;操作&quot;</span> + myCount + <span class="string">&quot;账户成功, 金额为&quot;</span> + iocash + <span class="string">&quot;, 当前金额为&quot;</span> + myCount.getCash());</span><br><span class="line">    <span class="comment">//释放锁, 否则别的线程没有机会执行了</span></span><br><span class="line">    myLock.unlock();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 信用卡账户, 可随意透支</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCount</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String oid;         <span class="comment">//账号</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> cash;             <span class="comment">//账户余额</span></span><br><span class="line">  MyCount(String oid, <span class="keyword">int</span> cash) &#123;</span><br><span class="line">          <span class="keyword">this</span>.oid = oid;</span><br><span class="line">          <span class="keyword">this</span>.cash = cash;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getOid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> oid;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setOid</span><span class="params">(String oid)</span> </span>&#123;</span><br><span class="line">          <span class="keyword">this</span>.oid = oid;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCash</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> cash;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCash</span><span class="params">(<span class="keyword">int</span> cash)</span> </span>&#123;</span><br><span class="line">          <span class="keyword">this</span>.cash = cash;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;MyCount&#123;&quot;</span> +</span><br><span class="line">                    <span class="string">&quot;oid=&#x27;&quot;</span> + oid + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                    <span class="string">&quot;, cash=&quot;</span> + cash +</span><br><span class="line">                    <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="线程的中断"><a href="#线程的中断" class="headerlink" title="线程的中断"></a>线程的中断</h3><p>Java线程中的中断，提供了三个方法:</p>
<ul>
<li>interrupt()<br>  通知线程中断, 但是线程不会立即中断, 只会将interrupt标志位设置为  true, 当在线程中获取到这个标志位时自行判断</li>
<li>interrupted()<br>  判断是否中断, 如果未中断, 立即设置为中断</li>
<li>isInterrupted()<br>  判断是否中断</li>
</ul>
<p>这三个方法都不能使线程中断执行。而ReetrantLock提供了响应的方案。</p>
<p>ReentrantLock的lock机制有2种，忽略中断锁和响应中断锁，这给我们带来了很大的灵活性。</p>
<p>比如：如果A、B2个线程去竞争锁，A线程得到了锁，B线程等待，但是A线程这个时候实在有太多事情要处理，就是一直不返回，B线程可能就会等不及了，想中断自己，不再等待这个锁了，转而处理其他事情。这个时候ReentrantLock就提供了2种机制，</p>
<ul>
<li>第一，B线程中断自己（或者别的线程中断它），但是ReentrantLock不去响应，继续让B线程等待，你再怎么中断，我全当耳边风（synchronized原语就是如此）；Lock.lock()也不会响应中断操作</li>
<li>第二，B线程中断自己（或者别的线程中断它），ReentrantLock处理了这个中断，并且不再等待这个锁的到来，完全放弃。<br>  在Thread类中使用lock.lockInterruptibly();锁定时可以响应中断操作，当调用Thread.interupt()方法，该lock会放弃锁定，抛出InterruptedException异常</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="keyword">boolean</span> isProcess = <span class="keyword">false</span>;</span><br><span class="line">ReentrantLock lock  = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">Condition processReady = lock.newCondition();</span><br><span class="line">thread: run() &#123;</span><br><span class="line">    lock.lock();</span><br><span class="line">    isProcess = <span class="keyword">true</span>;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span>(!isProcessReady) &#123;  </span><br><span class="line">    <span class="comment">//isProcessReady 是另外一个线程的控制变量</span></span><br><span class="line">      processReady.await();</span><br><span class="line">      <span class="comment">//释放了lock，在此等待signal</span></span><br><span class="line">     &#125;<span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">          Thread.currentThread().interrupt();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          lock.unlock();</span><br><span class="line">          isProcess = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Lock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span>  </span>&#123;</span><br><span class="line">        Test test = <span class="keyword">new</span> Test();</span><br><span class="line">        MyThread thread1 = <span class="keyword">new</span> MyThread(test);</span><br><span class="line">        MyThread thread2 = <span class="keyword">new</span> MyThread(test);</span><br><span class="line">        thread1.start();</span><br><span class="line">        thread2.start();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        thread2.interrupt();</span><br><span class="line">    &#125;      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">(Thread thread)</span> <span class="keyword">throws</span> InterruptedException</span>&#123;</span><br><span class="line">        lock.lockInterruptibly();   </span><br><span class="line">        <span class="comment">//注意，如果需要正确中断等待锁的线程，必须将获取锁放在外面，然后将InterruptedException抛出</span></span><br><span class="line">        <span class="keyword">try</span> &#123;   </span><br><span class="line">            System.out.println(thread.getName()+<span class="string">&quot;得到了锁&quot;</span>);</span><br><span class="line">            <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">            <span class="keyword">for</span>(    ;     ;) &#123;</span><br><span class="line">                <span class="keyword">if</span>(System.currentTimeMillis() - startTime &gt;= Integer.MAX_VALUE)</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="comment">//插入数据</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+<span class="string">&quot;执行finally&quot;</span>);</span><br><span class="line">            lock.unlock();</span><br><span class="line">            System.out.println(thread.getName()+<span class="string">&quot;释放了锁&quot;</span>);</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Test test = <span class="keyword">null</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyThread</span><span class="params">(Test test)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.test = test;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;       </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            test.insert(Thread.currentThread());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+<span class="string">&quot;被中断&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="读写锁-ReadWriteLock"><a href="#读写锁-ReadWriteLock" class="headerlink" title="读写锁 ReadWriteLock"></a>读写锁 ReadWriteLock</h2><p>为了提高性能, Java提供了读写锁, 在读的地方使用读锁, 在写的地方使用写锁, 灵活控制, 在一定程度上提高了程序的执行效率.<br>Java中读写锁有个接口<code>java.util.concurrent.locks.ReadWriteLock</code>, 也有具体的实现<code>ReentrantReadWriteLock</code></p>
<p>ReadWriteLock也是一个接口，在它里面只定义了两个方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ReadWriteLock</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Returns the lock used for reading.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> the lock used for reading.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">Lock <span class="title">readLock</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Returns the lock used for writing.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> the lock used for writing.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function">Lock <span class="title">writeLock</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建并发访问的账户</span></span><br><span class="line">MyCount myCount = <span class="keyword">new</span> MyCount(<span class="string">&quot;95599200901215522&quot;</span>, <span class="number">10000</span>);</span><br><span class="line"><span class="comment">//创建一个锁对象</span></span><br><span class="line">ReadWriteLock lock = <span class="keyword">new</span> ReentrantReadWriteLock(<span class="keyword">false</span>);</span><br><span class="line"><span class="comment">//创建一个线程池</span></span><br><span class="line">ExecutorService pool = Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line"><span class="comment">//创建一些并发访问用户, 一个信用卡, 存的存, 取的取, 好热闹啊</span></span><br><span class="line">User u1 = <span class="keyword">new</span> User(<span class="string">&quot;张三&quot;</span>, myCount, -<span class="number">4000</span>, lock, <span class="keyword">false</span>);</span><br><span class="line">User u2 = <span class="keyword">new</span> User(<span class="string">&quot;张三他爹&quot;</span>, myCount, <span class="number">6000</span>, lock, <span class="keyword">false</span>);</span><br><span class="line">User u3 = <span class="keyword">new</span> User(<span class="string">&quot;张三他弟&quot;</span>, myCount, -<span class="number">8000</span>, lock, <span class="keyword">false</span>);</span><br><span class="line">User u4 = <span class="keyword">new</span> User(<span class="string">&quot;张三&quot;</span>, myCount, <span class="number">800</span>, lock, <span class="keyword">false</span>);</span><br><span class="line">User u5 = <span class="keyword">new</span> User(<span class="string">&quot;张三他爹&quot;</span>, myCount, <span class="number">0</span>, lock, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">//在线程池中执行各个用户的操作</span></span><br><span class="line">pool.execute(u1);</span><br><span class="line">pool.execute(u2);</span><br><span class="line">pool.execute(u3);</span><br><span class="line">pool.execute(u4);</span><br><span class="line">pool.execute(u5);</span><br><span class="line"><span class="comment">//关闭线程池</span></span><br><span class="line">pool.shutdown();</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 信用卡的用户</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String name;                <span class="comment">//用户名</span></span><br><span class="line">  <span class="keyword">private</span> MyCount myCount;        <span class="comment">//所要操作的账户</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> iocash;                 <span class="comment">//操作的金额, 当然有正负之分了</span></span><br><span class="line">  <span class="keyword">private</span> ReadWriteLock myLock;                <span class="comment">//执行操作所需的锁对象</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">boolean</span> ischeck;        <span class="comment">//是否查询</span></span><br><span class="line">  User(String name, MyCount myCount, <span class="keyword">int</span> iocash, ReadWriteLock myLock, <span class="keyword">boolean</span> ischeck) &#123;</span><br><span class="line">          <span class="keyword">this</span>.name = name;</span><br><span class="line">          <span class="keyword">this</span>.myCount = myCount;</span><br><span class="line">          <span class="keyword">this</span>.iocash = iocash;</span><br><span class="line">          <span class="keyword">this</span>.myLock = myLock;</span><br><span class="line">          <span class="keyword">this</span>.ischeck = ischeck;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (ischeck) &#123;</span><br><span class="line">            <span class="comment">//获取读锁</span></span><br><span class="line">            myLock.readLock().lock();</span><br><span class="line">            System.out.println(<span class="string">&quot;读：&quot;</span> + name + <span class="string">&quot;正在查询&quot;</span> + myCount + <span class="string">&quot;账户, 当前金额为&quot;</span> + myCount.getCash());</span><br><span class="line">            <span class="comment">//释放读锁</span></span><br><span class="line">            myLock.readLock().unlock();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//获取写锁</span></span><br><span class="line">            myLock.writeLock().lock();</span><br><span class="line">            <span class="comment">//执行现金业务</span></span><br><span class="line">            System.out.println(<span class="string">&quot;写：&quot;</span> + name + <span class="string">&quot;正在操作&quot;</span> + myCount + <span class="string">&quot;账户, 金额为&quot;</span> + iocash + <span class="string">&quot;, 当前金额为&quot;</span> + myCount.getCash());</span><br><span class="line">            myCount.setCash(myCount.getCash() + iocash);</span><br><span class="line">            System.out.println(<span class="string">&quot;写：&quot;</span> + name + <span class="string">&quot;操作&quot;</span> + myCount + <span class="string">&quot;账户成功, 金额为&quot;</span> + iocash + <span class="string">&quot;, 当前金额为&quot;</span> + myCount.getCash());</span><br><span class="line">            <span class="comment">//释放写锁</span></span><br><span class="line">            myLock.writeLock().unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 信用卡账户, 可随意透支</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCount</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String oid;         <span class="comment">//账号</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> cash;             <span class="comment">//账户余额</span></span><br><span class="line">        MyCount(String oid, <span class="keyword">int</span> cash) &#123;</span><br><span class="line">                <span class="keyword">this</span>.oid = oid;</span><br><span class="line">                <span class="keyword">this</span>.cash = cash;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getOid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> oid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setOid</span><span class="params">(String oid)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">this</span>.oid = oid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCash</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> cash;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCash</span><span class="params">(<span class="keyword">int</span> cash)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">this</span>.cash = cash;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="string">&quot;MyCount&#123;&quot;</span> +</span><br><span class="line">                          <span class="string">&quot;oid=&#x27;&quot;</span> + oid + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                          <span class="string">&quot;, cash=&quot;</span> + cash +</span><br><span class="line">                          <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="条件变量-Condition"><a href="#条件变量-Condition" class="headerlink" title="条件变量 Condition"></a>条件变量 Condition</h1><p>条件变量就是表示条件的一种变量. 但是必须说明, 这里的条件是没有实际含义的, 仅仅是个标记而已, 并且条件的含义往往通过代码来赋予其含义.</p>
<p>条件变量都实现了<code>java.util.concurrent.locks.Condition</code>接口, 条件变量的实例化是<strong>通过一个<code>Lock</code>对象上调用<code>newCondition()</code>方法</strong>来获取的, 这样, 条件就和一个锁对象绑定起来了. 因此, Java中的条件变量只能和锁配合使用, 来控制并发程序访问竞争资源的安全.</p>
<p>在Java5中, 一个锁可以有多个条件, 每个条件上可以有多个线程等待, 通过调用<code>await()</code>方法, 可以让线程在该条件下等待. 当调用<code>signalAll()</code>方法, 又可以唤醒该条件下的等待的线程.</p>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>有一个账户, 多个用户（线程）在同时操作这个账户, 有的存款有的取款, 存款随便存, 取款有限制, 不能透支, 任何试图透支的操作都将等待里面有足够存款才执行操作.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建并发访问的账户</span></span><br><span class="line">MyCount myCount = <span class="keyword">new</span> MyCount(<span class="string">&quot;95599200901215522&quot;</span>, <span class="number">10000</span>);</span><br><span class="line"><span class="comment">//创建一个线程池</span></span><br><span class="line">ExecutorService pool = Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line">Thread t1 = <span class="keyword">new</span> SaveThread(<span class="string">&quot;张三&quot;</span>, myCount, <span class="number">2000</span>);</span><br><span class="line">Thread t2 = <span class="keyword">new</span> SaveThread(<span class="string">&quot;李四&quot;</span>, myCount, <span class="number">3600</span>);</span><br><span class="line">Thread t3 = <span class="keyword">new</span> DrawThread(<span class="string">&quot;王五&quot;</span>, myCount, <span class="number">2700</span>);</span><br><span class="line">Thread t4 = <span class="keyword">new</span> SaveThread(<span class="string">&quot;老张&quot;</span>, myCount, <span class="number">600</span>);</span><br><span class="line">Thread t5 = <span class="keyword">new</span> DrawThread(<span class="string">&quot;老牛&quot;</span>, myCount, <span class="number">1300</span>);</span><br><span class="line">Thread t6 = <span class="keyword">new</span> DrawThread(<span class="string">&quot;胖子&quot;</span>, myCount, <span class="number">800</span>);</span><br><span class="line"><span class="comment">//执行各个线程</span></span><br><span class="line">pool.execute(t1);</span><br><span class="line">pool.execute(t2);</span><br><span class="line">pool.execute(t3);</span><br><span class="line">pool.execute(t4);</span><br><span class="line">pool.execute(t5);</span><br><span class="line">pool.execute(t6);</span><br><span class="line"><span class="comment">//关闭线程池</span></span><br><span class="line">pool.shutdown();</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 存款线程类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SaveThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String name;     <span class="comment">//操作人</span></span><br><span class="line">  <span class="keyword">private</span> MyCount myCount; <span class="comment">//账户</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> x;   <span class="comment">//存款金额</span></span><br><span class="line">  SaveThread(String name, MyCount myCount, <span class="keyword">int</span> x) &#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">    <span class="keyword">this</span>.myCount = myCount;</span><br><span class="line">    <span class="keyword">this</span>.x = x;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    myCount.saving(x, name);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 取款线程类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DrawThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String name; <span class="comment">//操作人</span></span><br><span class="line">  <span class="keyword">private</span> MyCount myCount; <span class="comment">//账户</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> x; <span class="comment">//存款金额</span></span><br><span class="line">  DrawThread(String name, MyCount myCount, <span class="keyword">int</span> x) &#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">    <span class="keyword">this</span>.myCount = myCount;</span><br><span class="line">    <span class="keyword">this</span>.x = x;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    myCount.drawing(x, name);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 普通银行账户, 不可透支</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCount</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String oid;                         <span class="comment">//账号</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> cash;                             <span class="comment">//账户余额</span></span><br><span class="line">  <span class="keyword">private</span> Lock lock = <span class="keyword">new</span> ReentrantLock();                <span class="comment">//账户锁</span></span><br><span class="line">  <span class="keyword">private</span> Condition _save = lock.newCondition();    <span class="comment">//存款条件</span></span><br><span class="line">  <span class="keyword">private</span> Condition _draw = lock.newCondition();    <span class="comment">//取款条件</span></span><br><span class="line">  MyCount(String oid, <span class="keyword">int</span> cash) &#123;</span><br><span class="line">    <span class="keyword">this</span>.oid = oid;</span><br><span class="line">    <span class="keyword">this</span>.cash = cash;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 存款</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> x        操作金额</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> name 操作人</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">saving</span><span class="params">(<span class="keyword">int</span> x, String name)</span> </span>&#123;</span><br><span class="line">    lock.lock();                        <span class="comment">//获取锁</span></span><br><span class="line">    <span class="keyword">if</span> (x &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      cash += x;                    <span class="comment">//存款</span></span><br><span class="line">      System.out.println(name + <span class="string">&quot;存款&quot;</span> + x + <span class="string">&quot;, 当前余额为&quot;</span> + cash);</span><br><span class="line">    &#125;</span><br><span class="line">    _draw.signalAll();            <span class="comment">//唤醒所有等待线程.</span></span><br><span class="line">    lock.unlock();                    <span class="comment">//释放锁</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 取款</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> x        操作金额</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> name 操作人</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drawing</span><span class="params">(<span class="keyword">int</span> x, String name)</span> </span>&#123;</span><br><span class="line">    lock.lock();                                 <span class="comment">//获取锁</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">if</span> (cash - x &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            _draw.await();             <span class="comment">//阻塞取款操作</span></span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            cash -= x;                     <span class="comment">//取款</span></span><br><span class="line">            System.out.println(name + <span class="string">&quot;取款&quot;</span> + x + <span class="string">&quot;, 当前余额为&quot;</span> + cash);</span><br><span class="line">          &#125;</span><br><span class="line">          _save.signalAll();             <span class="comment">//唤醒所有存款操作</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock();                     <span class="comment">//释放锁</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h1><p><a href="http://blog.csdn.net/shihuacai/article/details/8856370">参考来源：未引入样例</a></p>
<p> 一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。用给定的计数初始化 CountDownLatch。由于调用了 countDown() 方法，所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await 的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。 一个线程(或者多个)， 等待另外N个线程完成某个事情之后才能执行</p>
<p>在一些应用场合中，需要等待某个条件达到要求后才能做后面的事情；同时当线程都完成后也会触发事件，以便进行后面的操作。 这个时候就可以使用CountDownLatch。CountDownLatch最重要的方法是countDown()和await()，前者主要是倒数一次，后者是等待倒数到0，如果没有到达0，就只有阻塞等待了。</p>
<h2 id="主要方法"><a href="#主要方法" class="headerlink" title="主要方法"></a>主要方法</h2><p>countDown</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">countDown</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">递减锁存器的计数，如果计数到达零，则释放所有等待的线程。如果当前计数大于零，则将计数减少。</span></span><br><span class="line"><span class="function">如果新的计数为零，出于线程调度目的，将重新启用所有的等待线程。</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">如果当前计数等于零，则不发生任何操作。</span></span><br></pre></td></tr></table></figure>
<p>await</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">await</span><span class="params">(<span class="keyword">long</span> timeout,</span></span></span><br><span class="line"><span class="function"><span class="params">                     TimeUnit unit)</span></span></span><br><span class="line"><span class="function">              <span class="keyword">throws</span> InterruptedException</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">使当前线程在锁存器倒计数至零之前一直等待，除非线程被中断或超出了指定的等待时间。</span></span><br><span class="line"><span class="function">如果当前计数为零，则此方法立刻返回 <span class="keyword">true</span> 值。</span></span><br><span class="line"><span class="function">如果当前计数大于零，则出于线程调度目的，将禁用当前线程，</span></span><br><span class="line"><span class="function">且在发生以下三种情况之一前，该线程将一直处于休眠状态：</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">由于调用 <span class="title">countDown</span><span class="params">()</span> 方法，计数到达零；或者其他某个线程中断当前线程；</span></span><br><span class="line"><span class="function">或者已超出指定的等待时间。</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">如果计数到达零，则该方法返回 <span class="keyword">true</span> 值。</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">如果当前线程：</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">在进入此方法时已经设置了该线程的中断状态；或者在等待时被中断，</span></span><br><span class="line"><span class="function">则抛出 InterruptedException，并且清除当前线程的已中断状态。</span></span><br><span class="line"><span class="function">如果超出了指定的等待时间，则返回值为 <span class="keyword">false</span>。如果该时间小于等于零，则此方法根本不会等待。</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">参数：</span></span><br><span class="line"><span class="function">    timeout - 要等待的最长时间</span></span><br><span class="line"><span class="function">    unit - timeout 参数的时间单位。</span></span><br><span class="line"><span class="function">返回：</span></span><br><span class="line"><span class="function">    如果计数到达零，则返回 <span class="keyword">true</span>；如果在计数到达零之前超过了等待时间，则返回 <span class="keyword">false</span></span></span><br><span class="line"><span class="function">抛出：</span></span><br><span class="line"><span class="function">    InterruptedException - 如果当前线程在等待时被中断</span></span><br></pre></td></tr></table></figure>


<h2 id="在控制访问量上的应用"><a href="#在控制访问量上的应用" class="headerlink" title="在控制访问量上的应用"></a>在控制访问量上的应用</h2><h1 id="信号量-Semaphore"><a href="#信号量-Semaphore" class="headerlink" title="信号量 Semaphore"></a>信号量 Semaphore</h1><p>Java的信号量实际上是一个功能完备的计数器, 对控制一定资源的消费与回收有着很重要的意义, 信号量常常用于多线程的代码中, 并能监控有多少数目的线程等待获取资源, 并且通过信号量可以得知<strong>可用资源的数目</strong>等等, 这里总是在强调“数目”二字, 但不能指出来有哪些在等待, 哪些资源可用.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Semaphore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    MyPool myPool = <span class="keyword">new</span> MyPool(<span class="number">20</span>);</span><br><span class="line">    <span class="comment">//创建线程池</span></span><br><span class="line">    ExecutorService threadPool = Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line">    MyThread t1 = <span class="keyword">new</span> MyThread(<span class="string">&quot;任务A&quot;</span>, myPool, <span class="number">3</span>);</span><br><span class="line">    MyThread t2 = <span class="keyword">new</span> MyThread(<span class="string">&quot;任务B&quot;</span>, myPool, <span class="number">12</span>);</span><br><span class="line">    MyThread t3 = <span class="keyword">new</span> MyThread(<span class="string">&quot;任务C&quot;</span>, myPool, <span class="number">7</span>);</span><br><span class="line">    <span class="comment">//在线程池中执行任务</span></span><br><span class="line">    threadPool.execute(t1);</span><br><span class="line">    threadPool.execute(t2);</span><br><span class="line">    threadPool.execute(t3);</span><br><span class="line">    <span class="comment">//关闭池</span></span><br><span class="line">    threadPool.shutdown();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 一个池</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPool</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> Semaphore sp;     <span class="comment">//池相关的信号量</span></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 池的大小, 这个大小会传递给信号量</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> size 池的大小</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  MyPool(<span class="keyword">int</span> size) &#123;</span><br><span class="line">    <span class="keyword">this</span>.sp = <span class="keyword">new</span> Semaphore(size);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> Semaphore <span class="title">getSp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> sp;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSp</span><span class="params">(Semaphore sp)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.sp = sp;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String threadname;            <span class="comment">//线程的名称</span></span><br><span class="line">  <span class="keyword">private</span> MyPool pool;                        <span class="comment">//自定义池</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> x;                                    <span class="comment">//申请信号量的大小</span></span><br><span class="line">  MyThread(String threadname, MyPool pool, <span class="keyword">int</span> x) &#123;</span><br><span class="line">    <span class="keyword">this</span>.threadname = threadname;</span><br><span class="line">    <span class="keyword">this</span>.pool = pool;</span><br><span class="line">    <span class="keyword">this</span>.x = x;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//从此信号量获取给定数目的许可</span></span><br><span class="line">      pool.getSp().acquire(x);</span><br><span class="line">      <span class="comment">//TODO 也许这里可以做更复杂的业务</span></span><br><span class="line">      System.out.println(threadname + <span class="string">&quot;成功获取了&quot;</span> + x + <span class="string">&quot;个许可！&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="comment">//释放给定数目的许可, 将其返回到信号量.</span></span><br><span class="line">      pool.getSp().release(x);</span><br><span class="line">      System.out.println(threadname + <span class="string">&quot;释放了&quot;</span> + x + <span class="string">&quot;个许可！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h1><h1 id="原子量"><a href="#原子量" class="headerlink" title="原子量"></a>原子量</h1><p>所谓的原子量即操作变量的操作是“原子的”, 该操作不可再分, 因此是线程安全的.<br>为何要使用原子变量呢, 原因是多个线程对单个变量操作也会引起一些问题.<br>Java5之后, 专门提供了用来进行单变量多线程并发安全访问的工具包<code>java.util.concurrent.atomic</code>, 其中的类也很简单.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//原子量, 每个线程都可以自由操作</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> AtomicLong aLong = <span class="keyword">new</span> AtomicLong(<span class="number">10000</span>);</span><br><span class="line">lock.lock();</span><br><span class="line">System.out.println(name + <span class="string">&quot;执行了&quot;</span> + x + <span class="string">&quot;, 当前余额：&quot;</span> + aLong.addAndGet(x));</span><br><span class="line">lock.unlock();</span><br></pre></td></tr></table></figure>
<h1 id="锁-1"><a href="#锁-1" class="headerlink" title="锁"></a>锁</h1><h2 id="可重入锁"><a href="#可重入锁" class="headerlink" title="可重入锁"></a>可重入锁</h2><p>如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，<br>可重入性 实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。<br>举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，<br>此时线程不必重新去申请锁，而是可以直接执行方法method2。</p>
<p>看下面这段代码就明白了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        method2();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">method2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>两个方法method1和method2都用synchronized修饰了，假如某一时刻，线程A执行到了method1，此时线程A获取了这个对象的锁，<br>而由于method2也是synchronized方法，假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，<br>因为线程A已经持有了该对象的锁，而又在申请获取该对象的锁，这样就会线程A一直等待永远不会获取到的锁。</p>
<p>由于synchronized和Lock都具备可重入性，所以不会发生上述现象。</p>
<h2 id="可中断锁"><a href="#可中断锁" class="headerlink" title="可中断锁"></a>可中断锁</h2><p>可中断锁：顾名思义，就是可以相应中断的锁。</p>
<p>在Java中，synchronized就不是可中断锁，而Lock是可中断锁。<br>如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，<br>可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。<br>lockInterruptibly()的用法时已经体现了Lock的可中断性。</p>
<h2 id="公平锁"><a href="#公平锁" class="headerlink" title="公平锁"></a>公平锁</h2><p>公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。</p>
<p>非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。<br>在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。</p>
<p>而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。</p>
<p>看一下这2个类的源代码就清楚了：</p>
<p><img src="/images/java/multithread/02.lock/1.jpg"></p>
<p>在ReentrantLock中定义了2个静态内部类，一个是<code>NotFairSync</code>，一个是<code>FairSync</code>，分别用来实现非公平锁和公平锁。</p>
<p>我们可以在创建ReentrantLock对象时，通过以下方式来设置锁的公平性：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ReentrantLock lock = <span class="keyword">new</span> ReentrantLock(<span class="keyword">true</span>);</span><br></pre></td></tr></table></figure>
<p>如果参数为true表示为公平锁，为false为非公平锁。默认情况下，如果使用无参构造器，则是非公平锁。</p>
<p><img src="/images/java/multithread/02.lock/2.jpg"></p>
<p>另外在ReentrantLock类中定义了很多方法，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">isFair() &#x2F;&#x2F;判断锁是否是公平锁</span><br><span class="line">isLocked() &#x2F;&#x2F;判断锁是否被任何线程获取了</span><br><span class="line">isHeldByCurrentThread() &#x2F;&#x2F;判断锁是否被当前线程获取了</span><br><span class="line">hasQueuedThreads() &#x2F;&#x2F;判断是否有线程在等待该锁</span><br></pre></td></tr></table></figure>
<p>在ReentrantReadWriteLock中也有类似的方法，同样也可以设置为公平锁和非公平锁。不过要记住，ReentrantReadWriteLock并未实现Lock接口，它实现的是ReadWriteLock接口。</p>
<h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>读写锁将对一个资源（比如文件）的访问分成了2个锁，一个读锁和一个写锁。<br>正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。<br>ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。<br>可以通过readLock()获取读锁，通过writeLock()获取写锁。</p>
<h1 id="减少锁带来的开销"><a href="#减少锁带来的开销" class="headerlink" title="减少锁带来的开销"></a>减少锁带来的开销</h1><h2 id="使用Java-API中的并发类库"><a href="#使用Java-API中的并发类库" class="headerlink" title="使用Java API中的并发类库"></a>使用Java API中的并发类库</h2><pre><code>可以采用java.util.concurrent等包下面的并发类，通常它们已经经过了充分的优化，能有效地支持高并发环境下的操作，并发类中大量采用了非阻塞算法，有些利用了CAS实现无锁。这里有一个小提示：使用并发哈希表时应优先采用ConcurrentHashMap而不是Hashtable，前者通过分解锁的方法使得效率更高。</code></pre>
<h2 id="用CAS代替锁"><a href="#用CAS代替锁" class="headerlink" title="用CAS代替锁"></a>用CAS代替锁</h2><pre><code>和第一点中提到的一样，CAS可以减小锁的开销，但是CAS本身是基于轮询的操作，实际使用中反而可能增加开销，这一点需要实验来测试。</code></pre>
<h2 id="减小锁的粒度"><a href="#减小锁的粒度" class="headerlink" title="减小锁的粒度"></a>减小锁的粒度</h2><pre><code>尽可能缩小锁定的范围，可以从两个方面入手。第一是只锁定所需的对象，少用synchronized(this)。第二是尽可能缩小锁定的方法块，缩小临界区大小，避免将不必要的操作也归入临界区。</code></pre>
<h2 id="拆分锁"><a href="#拆分锁" class="headerlink" title="拆分锁"></a>拆分锁</h2><pre><code>将普通的对象锁、互斥锁按照场景拆分为读写锁或像ConcurrentHashMap一样拆分为若干把锁。</code></pre>
<h2 id="利用写时复制"><a href="#利用写时复制" class="headerlink" title="利用写时复制"></a>利用写时复制</h2><pre><code>对于读操作次数远远大于写操作的场景，可以在读操作时不加锁，写操作时利用写时复制来完成，但是内存占用会相应上升。</code></pre>
<p>其次，系统中的线程数最好不是固定的，而是按CPU数来计算，这样当CPU增加时，相应的系统会自动增加线程提高并发率。<br>最后，如果对系统的CPU使用率还不满意，应当考虑分解一些单线程任务，改为多线程并发执行，以提高效率。<br>增加内存时，需要进行如下调整：<br>首先类似于线程数按CPU数计算，将Cache大小按内存大小计算，扩展内存后，Cache可以自动增长大小。<br>其次，可以分配更大的JVM堆内存给虚拟机，能减少OOM发生的几率。</p>
<hr>
<p>【参考文献】:</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程3: volatile</title>
    <url>/Java/multithread/03.volatile/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;&lt;Java高级软件工程师知识结构</a></p>
<pre><code>Java多线程是Java基础的重要的一部分,支持多线程是Java的重要特性之一. 主要包括如下内容:</code></pre>
<blockquote>
<ol>
<li><a href="/Java/multithread/01.base/">Java多线程1: 线程生命周期和多线程基础</a></li>
<li><a href="/Java/multithread/02.Lock-Semaphore-Atomic/">Java多线程2: Lock、信号量、原子量与队列</a></li>
<li><a href="/Java/multithread/03.volatile/">Java多线程3: volatile</a></li>
<li><a href="/Java/multithread/04.thread-synchronization/">Java多线程4: 同步锁与Java线程同步方法比较</a></li>
<li><a href="/Java/multithread/05.ThreadPool/">Java多线程5: 线程池</a></li>
<li><a href="/Java/multithread/06.BlockingQueue/">Java多线程6: Java阻塞队列与生产者消费者模式</a></li>
</ol>
</blockquote>
<h1 id="volatile用处"><a href="#volatile用处" class="headerlink" title="volatile用处"></a>volatile用处</h1><p>在JDK1.2之前,Java的内存模型实现总是从主存（即共享内存）读取变量. 为了获得最佳速度,允许线程保存共享成员变量的私有拷贝,而且只当线程进入或者离开同步代码块时才将私有拷贝与共享内存中的原始值进行比较,在当前的Java内存模型下,线程可以把变量保存在本地内存（比如机器的寄存器）中,而不是直接在主存中进行读写,这就可能造成一个线程在主存中修改了一个变量的值,而另外一个线程还继续使用它在寄存器中的变量值的拷贝,造成数据的不一致,</p>
<p>volatile 指示JVM这个变量不稳定,每次使用它都到主存中进行读取,一般说来,多任务环境下,各任务间共享的变量都应该加volatile修饰符,</p>
<p>volatile 修饰的成员变量在每次被线程访问时, 都强迫从共享内存中重读该成员变量的值, 而且, 当成员变量发生变化时, 强迫线程将变化值回写到共享内存, 这样在任何时刻, 两个不同的线程总是看到某个成员变量的同一个值,</p>
<h1 id="使用同步解决变量不一致问题"><a href="#使用同步解决变量不一致问题" class="headerlink" title="使用同步解决变量不一致问题"></a>使用同步解决变量不一致问题</h1><p>内存可见性:<br>在一个任意对象上执行同步语句,目的是为了让该线程在进入和离开同步代码块时,将该线程中的所有变量的私有拷贝与共享内存中的原始值进行比较,从而发现没有用volatile标记的变量所发生的变化</p>
<p>加锁（synchronized同步）的功能不仅仅局限于互斥行为, 同时还存在另外一个重要的方面：内存可见性, 我们不仅希望防止某个线程正在使用对象状态而另一个线程在同时修改该状态, 而且还希望确保当一个线程修改了对象状态后, 其他线程能够看到该变化, 而线程的同步恰恰也能够实现这一点, 内置锁可以用于确保某个线程以一种可预测的方式来查看另一个线程的执行结果, 为了确保所有的线程都能看到共享变量的最新值, 可以在所有执行读操作或写操作的线程上加上同一把锁, 下图示例了同步的可见性保证,</p>
<p><img src="/images/java/multithread/03.volatile/sychronized-sample.png"></p>
<p>当线程A执行某个同步代码块时, 线程B随后进入由同一个锁保护的同步代码块, 这种情况下可以保证, 当锁被释放前, A看到的所有变量值（锁释放前 , A看到的变量包括y和x）在B获得同一个锁后同样可以由B看到, 换句话说, 当线程B执行由锁保护的同步代码块时, 可以看到线程A之前在同一个锁保护的同步代码块中的所有操作结果, 如果在线程A unlock M之后, 线程B才进入lock M, 那么线程B都可以看到线程A unlock M之前的操作, 可以得到i=1,j=1, 如果在线程B unlock M之后, 线程A才进入lock M, 那么线程B就不一定能看到线程A中的操作, 因此j的值就不一定是1</p>
<h1 id="volatile同步机制"><a href="#volatile同步机制" class="headerlink" title="volatile同步机制"></a>volatile同步机制</h1><p>volatile 是一种稍弱的同步机制,在访问 volatile 变量时不会执行加锁操作,也就不会执行线程阻塞,因此 volatile 变量是一种比 synchronized 关键字更轻量级的同步机制,</p>
<blockquote>
<p>在两个或者更多的线程需要访问的成员变量上使用volatile, 当要访问的变量已在synchronized代码块中, 或者为常量时, 没必要使用volatile, 由于使用volatile屏蔽掉了JVM中必要的代码优化, 所以在效率上比较低, 因此一定在必要时才使用此关键字</p>
</blockquote>
<h1 id="实际现象"><a href="#实际现象" class="headerlink" title="实际现象"></a>实际现象</h1><p>对于非volatile修饰的变量, 尽管jvm的优化, 会导致变量的可见性问题, 但这种可见性的问题也只是在短时间内高并发的情况下发生, CPU执行时会很快刷新Cache, 一般的情况下很难出现, 而且出现这种问题是不可预测的, 与jvm、机器配置环境等都有关</p>
<h1 id="正确使用Volatile变量"><a href="#正确使用Volatile变量" class="headerlink" title="正确使用Volatile变量"></a>正确使用Volatile变量</h1><p>当且仅当满足以下所有条件时,才应该使用volatile变量：</p>
<ol>
<li>对变量的写入操作不依赖变量的当前值,或者你能确保只有单个线程更新变量的值</li>
<li>该变量没有包含在具有其他变量的不变式中</li>
</ol>
<p>关于正确使用Volatile请参考: <a href="http://www.ibm.com/developerworks/cn/java/j-jtp06197.html">Java 理论与实践: 正确使用 Volatile 变量</a></p>
<hr>
<p>【参考文献】:</p>
<ol>
<li><a href="http://blog.csdn.net/ns_code/article/details/17101369">【Java并发编程】之五：volatile变量修饰符—意料之外的问题（含代码） </a></li>
<li><a href="http://blog.csdn.net/ns_code/article/details/17382679">【Java并发编程】之十八：第五篇中volatile意外问题的正确分析解答（含代码）</a></li>
<li>《深入Java虚拟机——JVM高级特性与最佳实践》</li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-jtp06197.html">Java 理论与实践: 正确使用 Volatile 变量</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>multithread</tag>
        <tag>volatile</tag>
        <tag>sychronized</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程4: 同步锁与Java线程同步方法比较</title>
    <url>/Java/multithread/04.thread-synchronization/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;Java高级软件工程师知识结构</a></p>
<pre><code>Java多线程是Java基础的重要的一部分，支持多线程是Java的重要特性之一. 主要包括如下内容:</code></pre>
<blockquote>
<ol>
<li><a href="/Java/multithread/01.base/">Java多线程1: 线程生命周期和多线程基础</a></li>
<li><a href="/Java/multithread/02.Lock-Semaphore-Atomic/">Java多线程2: Lock、信号量、原子量与队列</a></li>
<li><a href="/Java/multithread/03.volatile/">Java多线程3: volatile</a></li>
<li><a href="/Java/multithread/04.thread-synchronization/">Java多线程4: 同步锁与Java线程同步方法比较</a></li>
<li><a href="/Java/multithread/05.ThreadPool/">Java多线程5: 线程池</a></li>
<li><a href="/Java/multithread/06.BlockingQueue/">Java多线程6: Java阻塞队列与生产者消费者模式</a></li>
</ol>
</blockquote>
<ol>
<li>Atomic Class 依赖寄存器 CAS</li>
<li>volatile 共享变量</li>
<li>ThreadLocal CopyOnWrite 只读或近似只读</li>
<li>Synchronized CAS级别</li>
<li>Lock condition readAndWriteLock 并发级别</li>
<li>CountdownLatch</li>
<li>Semaphore</li>
</ol>
<hr>
<p>【参考文献】:</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中的线程池原理</title>
    <url>/Java/multithread/05.ThreadPool-principle/</url>
    <content><![CDATA[<p>[TOC]</p>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><h3 id="线程池的组成"><a href="#线程池的组成" class="headerlink" title="线程池的组成"></a>线程池的组成</h3><p><img src="/images/java/multithread/05.thread_pool/1.constructs.png" alt="1.constructs"></p>
<h3 id="提交Job的处理流程："><a href="#提交Job的处理流程：" class="headerlink" title="提交Job的处理流程："></a>提交Job的处理流程：</h3><p><img src="/images/java/multithread/05.thread_pool/2.new_task.png" alt="2.new_task"></p>
<p>核心代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Runnable command)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (command == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">  <span class="comment">// 如果线程数小于核心工作线程数, 则创建线程并执行当前任务</span></span><br><span class="line">  <span class="keyword">if</span> (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123;</span><br><span class="line">    <span class="comment">// 如线程数大于等于核心工作线程数或线程创建失败, 则将当前任务放到任务队列中.</span></span><br><span class="line">    <span class="keyword">if</span> (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class="line">      <span class="keyword">if</span> (runState != RUNNING || poolSize == <span class="number">0</span>) ensureQueuedTaskHandled(command);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果线程池不处于运行中或任务无法放入队列, 并且当前线程数量小于最大工作线程数,</span></span><br><span class="line">    <span class="comment">// 则创建一个线程执行任务.</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (!addIfUnderMaximumPoolSize(command))</span><br><span class="line">      <span class="comment">// 抛出RejectedExecutionException异常</span></span><br><span class="line">      reject(command); <span class="comment">// is shutdown or saturated</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li><code>工作线程worker</code>数量低于<code>核心工作线程数corePoolSize</code>时会优先创建一个<code>工作线程worker</code>处理<code>job</code>, 处理成功则返回.</li>
<li><code>工作线程worker</code>数量高于<code>核心工作线程数</code>时会优先把<code>job</code>放入到<code>任务队列</code>, 放入队列成功时处理结束.</li>
<li>入队失败会识别工作线程数是否还小于<code>最大工作线程数maximumPoolsize</code>, 小于的话也会新创建一个<code>工作线程worker</code>处理<code>job</code>.</li>
<li>饱和策略</li>
</ol>
<p>此外, 运行过程中, 更新核心工作线程数时, 若发现扩容, 会增加工作线程数.</p>
<p><strong>备注:</strong></p>
<ol>
<li>Java中的线程与操作系统的线程是一一对应的</li>
<li>添加新线程需要获得全局锁<br><code>private final ReentrantLock mainLock = new ReentrantLock();</code>, 因此, 当<code>工作线程work数量</code>大于<code>核心工作线程数corePoolSize</code>时, 优先放入<code>任务队列</code></li>
<li>只要工作线程达不到<code>corePoolSize</code>, 不管是否线程空闲, 都会创建新线程</li>
<li>调用<code>prestartAllCoreThreads</code>会初始化所有的核心线程, 没有预热期, 响应快, 但空载浪费资源</li>
<li>向<code>任务队列</code>添加任务, 不需要获取全局锁, 效率高</li>
<li>工作线程的复用: 执行完一个任务, 不断从<code>任务队列</code>取任务, 避免因创建和销毁操作系统线程带来的性能消耗</li>
<li>获取全局锁, 是性能性能瓶颈, <code>corePoolSize</code>是预热</li>
</ol>
<h3 id="工作线程的销毁"><a href="#工作线程的销毁" class="headerlink" title="工作线程的销毁"></a>工作线程的销毁</h3><p>满足下面条件会销毁:</p>
<ol>
<li>任务队列里没有<code>job</code>并且<code>工作线程worker</code>数量超过了<code>核心工作线程数corePoolSize</code>.</li>
<li>任务队列里没有<code>job</code>并且允许<code>工作线程数量</code>小于<code>核心工作线程</code>参数为<code>true</code>, 此场景会至少保留一个工作线程线程.</li>
</ol>
<p>工作线程空闲后, 最长等待<code>keepAliveTime</code></p>
<h2 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ThreadPoolExecutor</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">int</span> maximumPoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">long</span> keepAliveTime,</span></span></span><br><span class="line"><span class="function"><span class="params">                          TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">                          BlockingQueue&lt;Runnable&gt; workQueue,</span></span></span><br><span class="line"><span class="function"><span class="params">                          ThreadFactory threadFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">                          RejectedExecutionHandler handler)</span></span></span><br></pre></td></tr></table></figure>
<p>用给定的初始参数和默认的线程工厂及饱和策略创建新的 <code>ThreadPoolExecutor</code>.<br>使用 <code>Executors</code> 工厂方法之一比使用此通用构造方法方便得多, 但是<a href="https://yq.aliyun.com/attachment/download/?id=2023">阿里巴巴Java规约</a>不推荐使用, 见下文</p>
<ul>
<li>参数:<ul>
<li><code>corePoolSize</code> - 池中所保存的线程数, 包括空闲线程.</li>
<li><code>maximumPoolSize</code> - 池中允许的最大线程数.</li>
<li><code>keepAliveTime</code> - 当线程数大于核心时, 此为终止前多余的空闲线程等待新任务的最长时间.</li>
<li><code>unit</code> - <code>keepAliveTime</code> 参数的时间单位.</li>
<li><code>workQueue</code> - 执行前用于保持任务的队列. 此队列仅保持由 <code>execute</code> 方法提交的 <code>Runnable</code> 任务.</li>
</ul>
</li>
<li>抛出:<ul>
<li><code>IllegalArgumentException</code> - 如果 <code>corePoolSize</code> 或 <code>keepAliveTime</code> 小于零, 或者 <code>maximumPoolSize</code> 小于或等于零, 或者 <code>corePoolSize</code> 大于 <code>maximumPoolSize</code>.</li>
<li><code>NullPointerException</code> - 如果 <code>workQueue</code> 为 <code>null</code></li>
</ul>
</li>
</ul>
<h3 id="工作线程的存储"><a href="#工作线程的存储" class="headerlink" title="工作线程的存储"></a>工作线程的存储</h3><p>使用了<code>HashSet</code>来存储工作线程<code>worker</code>, 通过可重入锁<code>ReentrantLock</code>对其进行并发保护. 每个<code>worker</code>都是一个<code>Runnable</code>接口.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Set containing all worker threads in pool. Accessed only when</span></span><br><span class="line"><span class="comment"> * holding mainLock.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> HashSet&lt;Worker&gt; workers = <span class="keyword">new</span> HashSet&lt;Worker&gt;();</span><br></pre></td></tr></table></figure>



<h3 id="任务队列-runnableTaskQueue"><a href="#任务队列-runnableTaskQueue" class="headerlink" title="任务队列 runnableTaskQueue"></a>任务队列 runnableTaskQueue</h3><p>线程池中的队列采用的是<a href="/Java/multithread/06.BlockingQueue/"><code>BlockingQueue</code></a></p>
<ul>
<li><code>ArrayBlockingQueue</code>：是一个基于数组结构的有界阻塞队列, 此队列按 <code>FIFO（先进先出）</code>原则对元素进行排序.</li>
<li><code>LinkedBlockingQueue</code>：一个基于链表结构的阻塞队列, 此队列按FIFO排序元素, 吞吐量通常要高于<code>ArrayBlockingQueue</code>. 静态工厂方法<code>Executors.newFixedThreadPool()</code>使用了这个队列.</li>
<li><code>SynchronousQueue</code>：一个不存储元素的阻塞队列. 每个插入操作必须等到另一个线程调用移除操作, 否则插入操作一直处于阻塞状态, 吞吐量通常要高于<code>Linked-BlockingQueue</code>, 静态工厂方法<code>Executors.newCachedThreadPool</code>使用了这个队列.</li>
<li><code>PriorityBlockingQueue</code>：一个具有优先级的无限阻塞队列.</li>
</ul>
<h3 id="线程工厂-ThreadFactory"><a href="#线程工厂-ThreadFactory" class="headerlink" title="线程工厂 ThreadFactory"></a>线程工厂 ThreadFactory</h3><p>设置创建线程的工厂, 通过线程工厂给每个创建出来的线程设置更有意义的名字. 使用开源框架guava提供的<code>ThreadFactoryBuilder</code>可以快速给线程池里的线程设置有意义的名字, 代码如下.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">newThreadFactoryBuilder().setNameFormat(<span class="string">&quot;XX-task-%d&quot;</span>).build();</span><br></pre></td></tr></table></figure>


<h3 id="RejectedExecutionHandler（饱和策略）"><a href="#RejectedExecutionHandler（饱和策略）" class="headerlink" title="RejectedExecutionHandler（饱和策略）"></a>RejectedExecutionHandler（饱和策略）</h3><p>当队列和线程池都满了, 说明线程池处于饱和状态, 那么必须采取一种策略处理提交的新任务. 这个策略默认情况下是 <code>AbortPolicy</code> , 表示无法 处理新任务时抛出异常. 在JDK 1.5中Java线程池框架提供了以下4种策略.</p>
<ul>
<li><p><code>AbortPolicy</code> ：直接抛出异常.</p>
</li>
<li><p><code>CallerRunsPolicy</code> ：只用调用者所在线程来运行任务.</p>
</li>
<li><p><code>DiscardOldestPolicy</code> ：丢弃队列里最近的一个任务, 并执行当前任务.</p>
</li>
<li><p><code>DiscardPolicy</code> ：不处理, 丢弃掉.</p>
</li>
</ul>
<p>当然, 也可以根据应用场景需要来实现<code>RejectedExecutionHandler</code>接口自定义策略. 如记录日志或持久化存储不能处理的任务.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 线程池异常处理类:</span></span><br><span class="line"><span class="comment"> * 任务执行失败, 持久化到数据库</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>  averyzhang</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyRejectedExecutionHandler</span> <span class="keyword">implements</span> <span class="title">RejectedExecutionHandler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable task, ThreadPoolExecutor executor)</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Begin exception handler-----------&quot;</span>);</span><br><span class="line">    <span class="comment">//执行失败任务</span></span><br><span class="line">    CachingOnFirstOpenRunnable coor = (CachingOnFirstOpenJob)task;</span><br><span class="line">    List&lt;CachingEntity&gt; list = coor.getLastData();</span><br><span class="line">    CachingDaoUtils.save(list);</span><br><span class="line">    <span class="comment">//打印线程池的对象</span></span><br><span class="line">    System.out.println(<span class="string">&quot;The pool RejectedExecutionHandler = &quot;</span>+executor.toString());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="提交任务-submit与execute"><a href="#提交任务-submit与execute" class="headerlink" title="提交任务: submit与execute"></a>提交任务: submit与execute</h3><p><code>execute</code> 没有返回值</p>
<p><code>submit</code> 可以通过 <code>Future</code> 接口, 获取任务执行的结果: 线程池会返回一个future类型的对象, 通过这个 future对象可以判断任务是否执行成功, 并且可以通过future的<code>get()</code>方法来获取返回值, <code>get()</code>方法会阻塞当前线程直到任务完成, 而使用<code>get(long timeout, TimeUnit unit)</code>方法则会阻塞当前线程一段时间后立即返回, 这时候有可能任务没有执行完.</p>
<h3 id="关闭-shutdown与shutdownNow"><a href="#关闭-shutdown与shutdownNow" class="headerlink" title="关闭: shutdown与shutdownNow"></a>关闭: shutdown与shutdownNow</h3><p>原理是遍历线程池中的工作线程, 然后逐个调用线程的<code>interrupt</code>方法来中断线程, 所以无法响应中断的任务可能永远无法终止.</p>
<ul>
<li><code>shutdownNow</code>首先将线程池的状态设置成 <code>STOP</code>, 然后尝试停止所有的正在执行或暂停任务的线程, 并返回等待执行任务的列表</li>
<li> <code>shutdown</code>只是将线程池的状态设置成<code>SHUTDOWN</code>状态, 然后中断所有没有正在执行任务的线程</li>
</ul>
<p>获取线程的关闭状态:</p>
<p>调用两个关闭方法, <code>isShutdown</code>方法就会返回<code>true</code>. 当所有的任务都已关闭后, 才表示线程池关闭成功, 这时调用<code>isTerminaed</code>方法会返回<code>true</code>.</p>
<p>至于应该调用哪一种方法来关闭线程池, 应该由提交到线程池的任务特性决定, 通常调用<code>shutdown</code>方法来关闭线程池, 如果任务不一定要执行完, 则可以调用<code>shutdownNow</code>方法.</p>
<h2 id="优化配置"><a href="#优化配置" class="headerlink" title="优化配置"></a>优化配置</h2><p>性质不同的任务可以用不同规模的线程池分开处理:</p>
<ul>
<li><code>CPU密集型任务</code>应配置尽可能小的线程, 如配置<code>Ncpu+1</code>个线程的线程池</li>
<li><code>IO密集型任务线程</code>并不是一直在执行任务, 则应配置尽可能多的线程, 如<code>2*Ncpu</code></li>
<li>混合型的任务, 如果可以拆分, 将其拆分成一个CPU密集型任务和一个IO密集型任务, 只要这两个任务执行的时间相差不是太大, 那么分解后执行的吞吐量将高于串行执行的吞吐量. 如果这两个任务执行时间相差太大, 则没必要进行分解.</li>
<li>可以通过 <code>Runtime.getRuntime().availableProcessors()</code>方法获得当前设备的CPU个数</li>
<li>如果任务很多, 并且每个任务执行的时间比较短, 可以调大<code>keepAliveTime</code>时间, 提高线程的利用率.</li>
<li>优先级不同的任务可以使用优先级队列<code>PriorityBlockingQueue</code>来处理. 它可以让优先级高的任务先执行.  优先级低的任务可能永远不能执行.</li>
<li>建议使用有界队列. 有界队列能增加系统的稳定性和预警能力, 可以根据需要设大一点：如果采用无解队列, 当任务无法处理引起堆积, 系统撑爆, 殃及其他业务</li>
</ul>
<p>通常基于几个维度进行：待处理工作job数、线程池定义的最大最小工作线程数、工作线程闲置时间.</p>
<h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>通过线程池提供的参数进行监控, 在监控线程池的时候可以使用以下属性.</p>
<ul>
<li><p><code>taskCount</code>：线程池需要执行的任务数量.</p>
</li>
<li><p><code>completedTaskCount</code>：线程池在运行过程中已完成的任务数量, 小于或等于<code>taskCount</code>.</p>
</li>
<li><p><code>largestPoolSize</code>：线程池里曾经创建过的最大线程数量. 通过这个数据可以知道线程池是否曾经满过. 如该数值等于线程池的最大大小, 则表示线程池曾经满过.</p>
</li>
<li><p><code>getPoolSize</code>：线程池的线程数量. 如果线程池不销毁的话, 线程池里的线程不会自动销 毁, 所以这个大小只增不减.</p>
</li>
<li><p><code>getActiveCount</code>：获取活动的线程数.  通过扩展线程池进行监控.</p>
</li>
<li><p>通过继承线程池来自定义线程池, 重写线程池的 <code>beforeExecute</code>、<code>afterExecute</code>和<code>terminated</code>方法, 可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控. 例如, 监控任务的平均执行时间、最大执行时间和最小执行时间等. 这几个方法在线程池里是空方法.</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">beforeExecute</span><span class="params">(Thread t,Runnable r)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>sample</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyScheduledExecutorService</span> <span class="keyword">extends</span> <span class="title">ScheduledThreadPoolExecutor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(MyScheduledExecutorService.class);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TableauScheduledExecutorService</span><span class="params">(<span class="keyword">int</span> corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(corePoolSize, threadFactory, handler);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TableauScheduledExecutorService</span><span class="params">(<span class="keyword">int</span> corePoolSize, ThreadFactory threadFactory)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(corePoolSize, threadFactory);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">beforeExecute</span><span class="params">(Thread t, Runnable r)</span> </span>&#123;</span><br><span class="line">        logger.info(<span class="string">&quot;############# before execute \n&quot;</span> + currentStatus());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">afterExecute</span><span class="params">(Runnable r, Throwable t)</span> </span>&#123;</span><br><span class="line">        logger.info(<span class="string">&quot;############# after execute \n&quot;</span> + currentStatus());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">terminated</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        logger.info(<span class="string">&quot;############# terminated \n&quot;</span> + currentStatus());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> String <span class="title">currentStatus</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 需要执行的任务数目</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> taskCount = getTaskCount();</span><br><span class="line">        <span class="comment">// 执行完成的任务数目</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> completedTaskCount = getCompletedTaskCount();</span><br><span class="line">        <span class="comment">// 线程池最大线程数量</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> largestPoolSize = getLargestPoolSize();</span><br><span class="line">        <span class="comment">// 线程池线程数量</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> poolSize = getPoolSize();</span><br><span class="line">        <span class="comment">// 活动线程数量</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> activeCount = getActiveCount();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;[要执行任务:&quot;</span> + taskCount + <span class="string">&quot;,完成:&quot;</span> + completedTaskCount + <span class="string">&quot;,线程池最大数量:&quot;</span> + largestPoolSize +</span><br><span class="line">                <span class="string">&quot;,当前线程数量:&quot;</span> + poolSize + <span class="string">&quot;,活动线程数量:&quot;</span> + activeCount + <span class="string">&quot;]&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>TODO 等待关闭</p>
</blockquote>
<h2 id="Alibaba-Java-规约"><a href="#Alibaba-Java-规约" class="headerlink" title="Alibaba Java 规约"></a>Alibaba Java 规约</h2><p>线程池不允许使用Executors去创建, 而是通过ThreadPoolExecutor的方式, 这样的处理方式让写的同学更加明确线程池的运行规则, 规避资源耗尽的风险.  说明：Executors各个方法的弊端：<br>1）<code>newFixedThreadPool和newSingleThreadExecutor:</code><br>  主要问题是堆积的请求处理队列可能会耗费非常大的内存, 甚至OOM.<br>2）<code>newCachedThreadPool和newScheduledThreadPool:</code><br>  主要问题是线程数最大数是Integer.MAX_VALUE, 可能会创建数量非常多的线程, 甚至OOM.</p>
<p>Positive example 1：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//org.apache.commons.lang3.concurrent.BasicThreadFactory</span></span><br><span class="line">ScheduledExecutorService executorService = <span class="keyword">new</span> ScheduledThreadPoolExecutor(<span class="number">1</span>, <span class="keyword">new</span> BasicThreadFactory.Builder().namingPattern(<span class="string">&quot;example-schedule-pool-%d&quot;</span>).daemon(<span class="keyword">true</span>).build());</span><br></pre></td></tr></table></figure>

<p>Positive example 2：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ThreadFactory namedThreadFactory = <span class="keyword">new</span> ThreadFactoryBuilder()</span><br><span class="line">.setNameFormat(<span class="string">&quot;demo-pool-%d&quot;</span>).build();</span><br><span class="line"></span><br><span class="line"><span class="comment">//Common Thread Pool</span></span><br><span class="line">ExecutorService pool = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">5</span>, <span class="number">200</span>,<span class="number">0L</span>, TimeUnit.MILLISECONDS,<span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;(<span class="number">1024</span>), namedThreadFactory, <span class="keyword">new</span> ThreadPoolExecutor.AbortPolicy());</span><br><span class="line"></span><br><span class="line">pool.execute(()-&gt; System.out.println(Thread.currentThread().getName()));</span><br><span class="line">pool.shutdown();<span class="comment">//gracefully shutdown</span></span><br></pre></td></tr></table></figure>

<p>Positive example 3：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;userThreadPool&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">class</span>=<span class="string">&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;corePoolSize&quot;</span> <span class="attr">value</span>=<span class="string">&quot;10&quot;</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;maxPoolSize&quot;</span> <span class="attr">value</span>=<span class="string">&quot;100&quot;</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;queueCapacity&quot;</span> <span class="attr">value</span>=<span class="string">&quot;2000&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;threadFactory&quot;</span> <span class="attr">value</span>= <span class="string">threadFactory</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;rejectedExecutionHandler&quot;</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">ref</span> <span class="attr">local</span>=<span class="string">&quot;rejectedExecutionHandler&quot;</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//in code</span></span><br><span class="line">    userThreadPool.execute(thread);</span><br></pre></td></tr></table></figure>
<p>线程池的关闭</p>
<p>等待关闭超时</p>
<h1 id="next…TODO"><a href="#next…TODO" class="headerlink" title="next…TODO"></a>next…TODO</h1><ol>
<li>Future接口</li>
<li>任务队列的实现</li>
<li><code>ArrayBlockingQueue</code></li>
<li><code>LinkedBlockingQueue</code></li>
<li><code>SynchronousQueue</code></li>
<li><code>PriorityBlockingQueue</code></li>
<li>线程池的底层实现</li>
<li>guava与线程工厂的使用</li>
<li>线程关闭与中断: 强制关闭与响应中断</li>
<li>Java获取设备参数的API</li>
<li>连接池</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程5: 线程池使用</title>
    <url>/Java/multithread/05.ThreadPool/</url>
    <content><![CDATA[<p>Sun在Java5中, 对Java线程的类库做了大量的扩展, 其中 <a href="/Java/multithread/05.ThreadPool/">线程池</a> 就是Java5的新特征之一</p>
<h1 id="线程池使用"><a href="#线程池使用" class="headerlink" title="线程池使用"></a>线程池使用</h1><ul>
<li>线程池的作用:<br>   线程池作用就是限制系统中执行线程的数量. 根据系统的环境情况, 可以自动或手动设置线程数量, 达到运行的最佳效果;<br>   少了浪费系统资源, 多了造成系统拥挤效率不高. 用线程池控制线程数量, 其他线程排队等候.<br>   一个任务执行完毕, 再从队列的中取最前面的任务开始执行. 若队列中没有等待进程, 线程池的这一资源处于等待.<br>   当一个新任务需要运行时, 如果线程池中有等待的工作线程, 就可以开始运行了; 否则进入等待队列. </li>
<li>为什么要用线程池:<ol>
<li>减少了创建和销毁线程的次数, 每个工作线程都可以被重复利用, 可执行多个任务. </li>
<li>可以根据系统的承受能力, 调整线程池中工作线线程的数目, 防止因为消耗过多的内存, 而把服务器累趴下(每个线程需要大约1MB内存, 线程开的越多, 消耗的内存也就越大, 最后死机). </li>
</ol>
</li>
</ul>
<p>在Java5中, 需要了解<code>java.util.concurrent.Executors</code>类的API, 这个类提供大量创建线程池的静态方法, 是必须掌握的.<br>Java里面线程池的顶级接口是<code>Executor</code>, 但是严格意义上讲 <code>Executor</code> 并不是一个线程池, 而只是一个执行线程的工具. 真正的线程池接口是 <code>ExecutorService</code>. </p>
<p>比较重要的几个类: </p>
<ul>
<li><code>ExecutorService</code> 真正的线程池接口. </li>
<li><code>ScheduledExecutorService</code> 能和Timer/TimerTask类似, 解决那些需要任务重复执行的问题. </li>
<li><code>ThreadPoolExecutor ExecutorService</code>的默认实现. </li>
<li><code>ScheduledThreadPoolExecutor</code> 继承<code>ThreadPoolExecutor</code>的<code>ScheduledExecutorService</code>接口实现, 周期性任务调度的类实现. </li>
</ul>
<p>要配置一个线程池是比较复杂的, 在<code>Executors</code>类里面提供了一些 <a href="/designPattern/factory/">静态工厂</a> 用于简便的生成一些常用的线程池. </p>
<ol>
<li>newSingleThreadExecutor<br>创建一个单线程的线程池. 这个线程池只有一个线程在工作, 也就是相当于单线程串行执行所有任务. 如果这个唯一的线程因为异常结束, 那么会有一个新的线程来替代它. 此线程池保证所有任务的执行顺序按照任务的提交顺序执行. </li>
<li>newFixedThreadPool<br>创建固定大小的线程池. 每次提交一个任务就创建一个线程, 直到线程达到线程池的最大大小. 线程池的大小一旦达到最大值就会保持不变, 如果某个线程因为执行异常而结束, 那么线程池会补充一个新线程. </li>
<li>newCachedThreadPool<br>创建一个可缓存的线程池. 如果线程池的大小超过了处理任务所需要的线程, 那么就会回收部分空闲（60秒不执行任务）的线程, 当任务数增加时, 此线程池又可以智能的添加新线程来处理任务. 此线程池不会对线程池大小做限制, 线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小. </li>
<li>newScheduledThreadPool<br>创建一个大小无限的线程池. 此线程池支持定时以及周期性执行任务的需求. </li>
</ol>
<h2 id="可重用固定线程数的线程池"><a href="#可重用固定线程数的线程池" class="headerlink" title="可重用固定线程数的线程池"></a>可重用固定线程数的线程池</h2><p>Executors.newFixedThreadPool</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建一个可重用固定线程数的线程池</span></span><br><span class="line">ExecutorService pool = Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line"><span class="comment">//创建实现了Runnable接口对象, Thread对象当然也实现了Runnable接口</span></span><br><span class="line">Thread t1 = <span class="keyword">new</span> MyThread();</span><br><span class="line">Thread t2 = <span class="keyword">new</span> MyThread();</span><br><span class="line">Thread t3 = <span class="keyword">new</span> MyThread();</span><br><span class="line">Thread t4 = <span class="keyword">new</span> MyThread();</span><br><span class="line">Thread t5 = <span class="keyword">new</span> MyThread();</span><br><span class="line"><span class="comment">//将线程放入池中进行执行</span></span><br><span class="line">pool.execute(t1);</span><br><span class="line">pool.execute(t2);</span><br><span class="line">pool.execute(t3);</span><br><span class="line">pool.execute(t4);</span><br><span class="line">pool.execute(t5);</span><br><span class="line"><span class="comment">//虽然放入了5个Runnable, 但必须在两个线程中循环执行. </span></span><br><span class="line"><span class="comment">//关闭线程池</span></span><br><span class="line">pool.shutdown();</span><br></pre></td></tr></table></figure>
<h2 id="单个worker线程的Executor"><a href="#单个worker线程的Executor" class="headerlink" title="单个worker线程的Executor"></a>单个<code>worker</code>线程的<code>Executor</code></h2><p>Executors.newSingleThreadExecutor</p>
<p>创建一个使用单个 <code>worker</code> 线程的 Executor, 以无界队列方式来运行该线程.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ExecutorService pool = Executors.newSingleThreadExecutor();</span><br></pre></td></tr></table></figure>
<p>以上两种连接池, 大小都是固定的, 当要加入的池的线程（或者任务）超过池最大尺寸时候, 则入此线程池需要排队等待.<br>一旦池中有线程完毕, 则排队等待的某个线程会入池执行. 如果当前线程在执行任务时突然中断, 则会创建一个新的线程替代它继续执行任务</p>
<h2 id="可变尺寸的线程池"><a href="#可变尺寸的线程池" class="headerlink" title="可变尺寸的线程池"></a>可变尺寸的线程池</h2><p>Executors.newCachedThreadPool</p>
<p>创建一个可根据需要创建新线程的线程池, 但是在以前构造的线程可用时将重用它们.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ExecutorService pool = Executors.newCachedThreadPool();</span><br></pre></td></tr></table></figure>
<h2 id="延迟连接池"><a href="#延迟连接池" class="headerlink" title="延迟连接池"></a>延迟连接池</h2><p>Executors.newScheduledThreadPool</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建一个线程池, 它可安排在给定延迟后运行命令或者定期地执行.</span></span><br><span class="line">ScheduledExecutorService pool = Executors.newScheduledThreadPool(<span class="number">2</span>);</span><br><span class="line">Thread t1 = <span class="keyword">new</span> MyThread();</span><br><span class="line">Thread t2 = <span class="keyword">new</span> MyThread();</span><br><span class="line">Thread t3 = <span class="keyword">new</span> MyThread();</span><br><span class="line">Thread t4 = <span class="keyword">new</span> MyThread();</span><br><span class="line">Thread t5 = <span class="keyword">new</span> MyThread();</span><br><span class="line"><span class="comment">//将线程放入池中进行执行</span></span><br><span class="line">pool.execute(t1);</span><br><span class="line">pool.execute(t2);</span><br><span class="line">pool.execute(t3);</span><br><span class="line"></span><br><span class="line"><span class="comment">//使用延迟执行风格的方法</span></span><br><span class="line">pool.schedule(t4, <span class="number">10</span>, TimeUnit.MILLISECONDS);</span><br><span class="line">pool.schedule(t5, <span class="number">10</span>, TimeUnit.MILLISECONDS);</span><br><span class="line"></span><br><span class="line"><span class="comment">//关闭线程池</span></span><br><span class="line">pool.shutdown();</span><br></pre></td></tr></table></figure>
<h2 id="单任务延迟连接池"><a href="#单任务延迟连接池" class="headerlink" title="单任务延迟连接池"></a>单任务延迟连接池</h2><p>Executors.newSingleThreadScheduledExecutor</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建一个单线程执行程序, 它可安排在给定延迟后运行命令或者定期地执行.</span></span><br><span class="line">ScheduledExecutorService pool = Executors.newSingleThreadScheduledExecutor();</span><br></pre></td></tr></table></figure>




<h1 id="线程池原理"><a href="#线程池原理" class="headerlink" title="线程池原理"></a>线程池原理</h1><p>在实现上, 线程池包含两个部分: <code>worker</code>线程组和等待队列. 当没有等待队列时, 线程都不能等待或缓冲, 所有的线程在放入的时候, 即决定开始执行或不执行. 其他情况下, 均是<code>worker</code>线程组从等待队列中取”任务”.</p>
<h2 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建等待队列</span></span><br><span class="line">BlockingQueue&lt;Runnable&gt; bqueue = <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">20</span>);</span><br><span class="line"><span class="comment">//创建一个单线程执行程序, 它可安排在给定延迟后运行命令或者定期地执行.</span></span><br><span class="line">ThreadPoolExecutor pool = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,TimeUnit.MILLISECONDS,bqueue);</span><br></pre></td></tr></table></figure>
<p>创建自定义线程池的构造方法很多, 本例中参数的含义如下: </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ThreadPoolExecutor</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">int</span> maximumPoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">long</span> keepAliveTime,</span></span></span><br><span class="line"><span class="function"><span class="params">                          TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">                          BlockingQueue&lt;Runnable&gt; workQueue)</span></span></span><br></pre></td></tr></table></figure>
<p>用给定的初始参数和默认的线程工厂及处理程序创建新的 <code>ThreadPoolExecutor</code>.<br>使用 <code>Executors</code> 工厂方法之一比使用此通用构造方法方便得多.</p>
<ul>
<li>参数: <ul>
<li>corePoolSize - 池中所保存的线程数, 包括空闲线程.</li>
<li>maximumPoolSize - 池中允许的最大线程数.</li>
<li>keepAliveTime - 当线程数大于核心时, 此为终止前多余的空闲线程等待新任务的最长时间.</li>
<li>unit - keepAliveTime参数的时间单位.</li>
<li>workQueue - 执行前用于保持任务的队列. 此队列仅保持由 <code>execute</code> 方法提交的 <code>Runnable</code> 任务.</li>
</ul>
</li>
<li>抛出: <ul>
<li>IllegalArgumentException - 如果 corePoolSize 或 keepAliveTime 小于零, 或者 maximumPoolSize 小于或等于零, 或者 corePoolSize 大于 maximumPoolSize.</li>
<li>NullPointerException - 如果 workQueue 为 null</li>
</ul>
</li>
</ul>
<p>自定义连接池稍微麻烦些, 不过通过创建的<code>ThreadPoolExecutor</code>线程池对象, 可以获取到当前线程池的尺寸、正在执行任务的线程数、工作队列等等</p>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>下面介绍一下几个类的源码: </p>
<ol>
<li><code>ExecutorService  newFixedThreadPool(int nThreads)</code>: 固定大小线程池.<br> 可以看到, <code>corePoolSize</code> 和 <code>maximumPoolSize</code>的大小是一样的（实际上, 后面会介绍, 如果使用无界<code>queue</code>的话<code>maximumPoolSize</code>参数是没有意义的）, <code>keepAliveTime</code>和<code>unit</code>的设值表明什么？-就是该实现不想<code>keep alive</code>！最后的<code>BlockingQueue</code>选择了<code>LinkedBlockingQueue</code>, 该queue有一个特点, 他是无界的. <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newFixedThreadPool</span><span class="params">(<span class="keyword">int</span> nThreads)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(nThreads, nThreads,</span><br><span class="line">                                            <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                            <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><code>ExecutorService  newSingleThreadExecutor()</code>: 单线程<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newSingleThreadExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> FinalizableDelegatedExecutorService</span><br><span class="line">                (<span class="keyword">new</span> ThreadPoolExecutor(<span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">                                         <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                         <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><code>ExecutorService newCachedThreadPool()</code>: 无界线程池, 可以进行自动线程回收<br>这个实现就有意思了. 首先是无界的线程池, 所以我们可以发现maximumPoolSize为big big. 其次BlockingQueue的选择上使用<code>SynchronousQueue</code>. 可能对于该<code>BlockingQueue</code>有些陌生, 简单说: 该QUEUE中, 每个插入操作必须等待另一个线程的对应移除操作. <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newCachedThreadPool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">0</span>, Integer.MAX_VALUE,</span><br><span class="line">                                          <span class="number">60L</span>, TimeUnit.SECONDS,</span><br><span class="line">                                          <span class="keyword">new</span> SynchronousQueue&lt;Runnable&gt;());</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h2 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h2></li>
</ol>
<p>先从<code>BlockingQueue&lt;Runnable&gt; workQueue</code>这个入参开始说起. 在JDK中, 其实已经说得很清楚了, 一共有三种类型的queue. </p>
<p>所有 <code>BlockingQueue</code> 都可用于传输和保持提交的任务. 可以使用此队列与池大小进行交互: </p>
<p>如果运行的线程少于 <code>corePoolSize</code>, 则 <code>Executor</code>始终首选添加新的线程, 而不进行排队. （如果当前运行的线程小于<code>corePoolSize</code>, 则任务根本不会存放, 添加到queue中, 而是直接抄家伙（thread）开始运行）</p>
<p>如果运行的线程等于或多于 <code>corePoolSize</code>, 则 <code>Executor</code> 始终首选将请求加入队列, 而不添加新的线程.<br>如果无法将请求加入队列, 则创建新的线程, 除非创建此线程超出 <code>maximumPoolSize</code>, 在这种情况下, 任务将被拒绝.<br>queue上的三种类型. </p>
<p>排队有三种通用策略: </p>
<ul>
<li>直接提交. 工作队列的默认选项是 <code>SynchronousQueue</code>, 它将任务直接提交给线程而不保持它们. 在此, 如果不存在可用于立即运行任务的线程, 则试图把任务加入队列将失败, 因此会构造一个新的线程. 此策略可以避免在处理可能具有内部依赖性的请求集时出现锁. 直接提交通常要求无界 <code>maximumPoolSizes</code> 以避免拒绝新提交的任务. 当命令以超过队列所能处理的平均数连续到达时, 此策略允许无界线程具有增长的可能性. </li>
<li>无界队列. 使用无界队列（例如, 不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待. 这样, 创建的线程就不会超过 corePoolSize. （因此, maximumPoolSize的值也就无效了. ）当每个任务完全独立于其他任务, 即任务执行互不影响时, 适合于使用无界队列; 例如, 在 Web页服务器中. 这种排队可用于处理瞬态突发请求, 当命令以超过队列所能处理的平均数连续到达时, 此策略允许无界线程具有增长的可能性. </li>
<li>有界队列. 当使用有限的 maximumPoolSizes时, 有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽, 但是可能较难调整和控制. 队列大小和最大池大小可能需要相互折衷: 使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销, 但是可能导致人工降低吞吐量. 如果任务频繁阻塞（例如, 如果它们是 I/O边界）, 则系统可能为超过您许可的更多线程安排时间. 使用小型队列通常要求较大的池大小, CPU使用率较高, 但是可能遇到不可接受的调度开销, 这样也会降低吞吐量. </li>
</ul>
<h3 id="BlockingQueue的选择"><a href="#BlockingQueue的选择" class="headerlink" title="BlockingQueue的选择."></a>BlockingQueue的选择.</h3><ul>
<li>例子一: 使用直接提交策略, 也即SynchronousQueue.<br>首先SynchronousQueue是无界的, 也就是说他存数任务的能力是没有限制的, 但是由于该Queue本身的特性, 在某次添加元素后必须等待其他线程取走后才能继续添加. 在这里不是核心线程便是新创建的线程, 但是我们试想一样下, 下面的场景.<br>我们使用一下参数构造ThreadPoolExecutor: </li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> ThreadPoolExecutor(</span><br><span class="line">        <span class="number">2</span>, <span class="number">3</span>, <span class="number">30</span>, TimeUnit.SECONDS,</span><br><span class="line">                 <span class="keyword">new</span>  SynchronousQueue&lt;Runnable&gt;(),</span><br><span class="line">                <span class="keyword">new</span> RecorderThreadFactory(<span class="string">&quot;CookieRecorderPool&quot;</span>),</span><br><span class="line">         <span class="keyword">new</span> ThreadPoolExecutor.CallerRunsPolicy());</span><br></pre></td></tr></table></figure>
<p> 当核心线程已经有2个正在运行.</p>
<ul>
<li>此时继续来了一个任务（A）, 根据前面介绍的“如果运行的线程等于或多于 corePoolSize, 则 Executor始终首选将请求加入队列, 而不添加新的线程. ”,所以A被添加到queue中. </li>
<li>又来了一个任务（B）, 且核心2个线程还没有忙完, OK, 接下来首先尝试1中描述, 但是由于使用的SynchronousQueue, 所以一定无法加入进去. <ul>
<li>此时便满足了上面提到的“如果无法将请求加入队列, 则创建新的线程, 除非创建此线程超出maximumPoolSize, 在这种情况下, 任务将被拒绝. ”, 所以必然会新建一个线程来运行这个任务. </li>
<li>暂时还可以, 但是如果这三个任务都还没完成, 连续来了两个任务, 第一个添加入queue中, 后一个呢？queue中无法插入, 而线程数达到了maximumPoolSize, 所以只好执行异常策略了. </li>
</ul>
</li>
</ul>
<p>所以在使用SynchronousQueue通常要求maximumPoolSize是无界的, 这样就可以避免上述情况发生（如果希望限制就直接使用有界队列）. 对于使用SynchronousQueue的作用jdk中写的很清楚: 此策略可以避免在处理可能具有内部依赖性的请求集时出现锁.<br>什么意思？如果你的任务A1, A2有内部关联, A1需要先运行, 那么先提交A1, 再提交A2, 当使用SynchronousQueue我们可以保证, A1必定先被执行, 在A1么有被执行前, A2不可能添加入queue中. </p>
<ul>
<li><p>例子二: 使用无界队列策略, 即LinkedBlockingQueue<br>这个就拿newFixedThreadPool来说, 根据前文提到的规则:<br>如果运行的线程少于 corePoolSize, 则 Executor 始终首选添加新的线程, 而不进行排队. 那么当任务继续增加, 会发生什么呢？<br>如果运行的线程等于或多于 corePoolSize, 则 Executor 始终首选将请求加入队列, 而不添加新的线程. OK, 此时任务变加入队列之中了, 那什么时候才会添加新线程呢？<br>如果无法将请求加入队列, 则创建新的线程, 除非创建此线程超出 maximumPoolSize, 在这种情况下, 任务将被拒绝. 这里就很有意思了, 可能会出现无法加入队列吗？不像SynchronousQueue那样有其自身的特点, 对于无界队列来说, 总是可以加入的（资源耗尽, 当然另当别论）. 换句说, 永远也不会触发产生新的线程！corePoolSize大小的线程数会一直运行, 忙完当前的, 就从队列中拿任务开始运行. 所以要防止任务疯长, 比如任务运行的实行比较长, 而添加任务的速度远远超过处理任务的时间, 而且还不断增加, 不一会儿就爆了. </p>
</li>
<li><p>例子三: 有界队列, 使用ArrayBlockingQueue.<br>这个是最为复杂的使用, 所以JDK不推荐使用也有些道理. 与上面的相比, 最大的特点便是可以防止资源耗尽的情况发生.<br>举例来说, 请看如下构造方法: </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> ThreadPoolExecutor(</span><br><span class="line">    <span class="number">2</span>, <span class="number">4</span>, <span class="number">30</span>, TimeUnit.SECONDS,</span><br><span class="line">    <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">2</span>),</span><br><span class="line">    <span class="keyword">new</span> RecorderThreadFactory(<span class="string">&quot;CookieRecorderPool&quot;</span>),</span><br><span class="line">    <span class="keyword">new</span> ThreadPoolExecutor.CallerRunsPolicy());</span><br></pre></td></tr></table></figure>
<p>假设, 所有的任务都永远无法执行完.<br>对于首先来的A,B来说直接运行, 接下来, 如果来了C,D, 他们会被放到queue中, 如果接下来再来E,F, 则增加线程运行E, F. 但是如果再来任务, 队列无法再接受了, 线程数也到达最大的限制了, 所以就会使用拒绝策略来处理. </p>
</li>
</ul>
<h3 id="keepAliveTime"><a href="#keepAliveTime" class="headerlink" title="keepAliveTime"></a>keepAliveTime</h3><p>jdk中的解释是: 当线程数大于核心时, 此为终止前多余的空闲线程等待新任务的最长时间.<br>有点拗口, 其实这个不难理解, 在使用了“池”的应用中, 大多都有类似的参数需要配置. 比如数据库连接池, DBCP中的maxIdle, minIdle参数.<br>什么意思？接着上面的解释, 后来向老板派来的工人始终是“借来的”, 俗话说“有借就有还”, 但这里的问题就是什么时候还了, 如果借来的工人刚完成一个任务就还回去, 后来发现任务还有, 那岂不是又要去借？这一来一往, 老板肯定头也大死了. </p>
<p>合理的策略: 既然借了, 那就多借一会儿. 直到“某一段”时间后, 发现再也用不到这些工人时, 便可以还回去了. 这里的某一段时间便是keepAliveTime的含义, TimeUnit为keepAliveTime值的度量. </p>
<p>RejectedExecutionHandler<br>另一种情况便是, 即使向老板借了工人, 但是任务还是继续过来, 还是忙不过来, 这时整个队伍只好拒绝接受了.<br>RejectedExecutionHandler接口提供了对于拒绝任务的处理的自定方法的机会. 在ThreadPoolExecutor中已经默认包含了4中策略, 因为源码非常简单, 这里直接贴出来.<br>CallerRunsPolicy: 线程调用运行该任务的 execute 本身. 此策略提供简单的反馈控制机制, 能够减缓新任务的提交速度. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">           <span class="keyword">if</span> (!e.isShutdown()) &#123;</span><br><span class="line">               r.run();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>
<p>这个策略显然不想放弃执行任务. 但是由于池中已经没有任何资源了, 那么就直接使用调用该execute的线程本身来执行. </p>
<p>AbortPolicy:<br>处理程序遭到拒绝将抛出运行时RejectedExecutionException</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> RejectedExecutionException();</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>
<p> 这种策略直接抛出异常, 丢弃任务. </p>
<p>DiscardPolicy: 不能执行的任务将被删除</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>
<p> 这种策略和AbortPolicy几乎一样, 也是丢弃任务, 只不过他不抛出异常.<br>DiscardOldestPolicy: 如果执行程序尚未关闭, 则位于工作队列头部的任务将被删除, 然后重试执行程序（如果再次失败, 则重复此过程）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">           <span class="keyword">if</span> (!e.isShutdown()) &#123;</span><br><span class="line">               e.getQueue().poll();</span><br><span class="line">               e.execute(r);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>
<p>该策略就稍微复杂一些, 在pool没有关闭的前提下首先丢掉缓存在队列中的最早的任务, 然后重新尝试运行该任务. 这个策略需要适当小心.<br>设想:如果其他线程都还在运行, 那么新来任务踢掉旧任务, 缓存在queue中, 再来一个任务又会踢掉queue中最老任务. </p>
<p>总结:<br>keepAliveTime和maximumPoolSize及BlockingQueue的类型均有关系. 如果BlockingQueue是无界的, 那么永远不会触发maximumPoolSize, 自然keepAliveTime也就没有了意义.<br>反之, 如果核心数较小, 有界BlockingQueue数值又较小, 同时keepAliveTime又设的很小, 如果任务频繁, 那么系统就会频繁的申请回收线程. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newFixedThreadPool</span><span class="params">(<span class="keyword">int</span> nThreads)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(nThreads, nThreads,</span><br><span class="line">                                     <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                     <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;());</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<h2 id="有返回值的线程池"><a href="#有返回值的线程池" class="headerlink" title="有返回值的线程池"></a>有返回值的线程池</h2><p>可返回值的任务必须实现<code>Callable</code>接口, 类似的, 无返回值的任务必须<code>Runnable</code>接口.<br>执行<code>Callable</code>取到<code>Callable</code>任务返回的<code>Object</code>了.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建一个线程池</span></span><br><span class="line">ExecutorService pool = Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line"><span class="comment">//创建两个有返回值的任务</span></span><br><span class="line">Callable c1 = <span class="keyword">new</span> MyCallable(<span class="string">&quot;A&quot;</span>);</span><br><span class="line">Callable c2 = <span class="keyword">new</span> MyCallable(<span class="string">&quot;B&quot;</span>);</span><br><span class="line"><span class="comment">//执行任务并获取Future对象</span></span><br><span class="line">Future f1 = pool.submit(c1);</span><br><span class="line">Future f2 = pool.submit(c2);</span><br><span class="line"><span class="comment">//从Future对象上获取任务的返回值, 并输出到控制台</span></span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&quot;</span>+f1.get().toString());</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&quot;</span>+f2.get().toString());</span><br><span class="line"><span class="comment">//关闭线程池</span></span><br><span class="line">pool.shutdown();</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCallable</span> <span class="keyword">implements</span> <span class="title">Callable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p>【参考文献】:</p>
<ol>
<li><a href="http://blog.csdn.net/sd0902/article/details/8395677">Java线程池使用说明</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程6: Java阻塞队列</title>
    <url>/Java/multithread/06.BlockingQueue/</url>
    <content><![CDATA[<p><a href="/Java/advanced-engineer-outline/">&lt;Java高级软件工程师知识结构</a></p>
<blockquote>
<p>   Java多线程是Java基础的重要的一部分，支持多线程是Java的重要特性之一. 主要包括如下内容:</p>
<ol>
<li><a href="/Java/multithread/01.base/">Java多线程1: 线程生命周期和多线程基础</a></li>
<li><a href="/Java/multithread/02.Lock-Semaphore-Atomic/">Java多线程2: Lock、信号量、原子量与队列</a></li>
<li><a href="/Java/multithread/03.volatile/">Java多线程3: volatile</a></li>
<li><a href="/Java/multithread/04.thread-synchronization/">Java多线程4: 同步锁与Java线程同步方法比较</a></li>
<li><a href="/Java/multithread/05.ThreadPool/">Java多线程5: 线程池</a></li>
<li><a href="/Java/multithread/06.BlockingQueue/">Java多线程6: Java阻塞队列与生产者消费者模式</a></li>
</ol>
</blockquote>
<hr>
<h1 id="阻塞队列与阻塞栈"><a href="#阻塞队列与阻塞栈" class="headerlink" title="阻塞队列与阻塞栈"></a>阻塞队列与阻塞栈</h1><p><img src="images/20191201214259668_108772893.png"></p>
<p>Java定义了阻塞队列的接口<code>java.util.concurrent.BlockingQueue</code>,<br>阻塞队列的概念是, 一个指定长度的队列, 如果队列满了, 添加新元素的操作会被阻塞等待, 直到有空位为止. 同样, 当队列为空时候, 请求队列元素的操作同样会阻塞等待, 直到有可用元素为止.<br>阻塞队列还有更多实现类, 用来满足各种复杂的需求：<code>ArrayBlockingQueue</code>, <code>DelayQueue</code>, <code>LinkedBlockingQueue</code>, <code>PriorityBlockingQueue</code>, <code>SynchronousQueue</code> , 具体的API差别也很小.</p>
<p>对于阻塞栈, 与阻塞队列相似. 不同点在于栈是<code>“后入先出”</code>的结构, 每次操作的是栈顶, 而队列是“先进先出”的结构, 每次操作的是队列头.<br>Java为阻塞栈定义了接口：<code>java.util.concurrent.BlockingDeque</code></p>
<h1 id="1、核心方法"><a href="#1、核心方法" class="headerlink" title="1、核心方法"></a>1、核心方法</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">BlockingQueue</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">Queue</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将给定元素设置到队列中，如果设置成功返回true, 否则返回false。如果是往限定了长度的队列中设置值，推荐使用offer()方法。</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将给定的元素设置到队列中，如果设置成功返回true, 否则返回false. e的值不能为空，否则抛出空指针异常。</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将元素设置到队列中，如果队列中没有多余的空间，该方法会一直阻塞，直到队列中有多余的空间。</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">put</span><span class="params">(E e)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将给定元素在给定的时间内设置到队列中，如果设置成功返回true, 否则返回false.</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e, <span class="keyword">long</span> timeout, TimeUnit unit)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//从队列中获取值，如果队列中没有值，线程会一直阻塞，直到队列中有值，并且该方法取得了该值。</span></span><br><span class="line">    <span class="function">E <span class="title">take</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在给定的时间里，从队列中获取值，时间到了直接调用普通的poll方法，为null则直接返回null。</span></span><br><span class="line">    <span class="function">E <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit unit)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取队列中剩余的空间。</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">remainingCapacity</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//从队列中移除指定的值。</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//判断队列中是否拥有该值。</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Object o)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将队列中值，全部移除，并发设置到给定的集合中。</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">drainTo</span><span class="params">(Collection&lt;? <span class="keyword">super</span> E&gt; c)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定最多数量限制将队列中值，全部移除，并发设置到给定的集合中。</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">drainTo</span><span class="params">(Collection&lt;? <span class="keyword">super</span> E&gt; c, <span class="keyword">int</span> maxElements)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="2、阻塞队列的成员"><a href="#2、阻塞队列的成员" class="headerlink" title="2、阻塞队列的成员"></a>2、阻塞队列的成员</h1><p>方法\处理方式 抛出异常 返回特殊值 一直阻塞 超时退出</p>
<p>插入方法 add(e) offer(e) put(e) offer(e,time,unit)</p>
<p>移除方法 remove() poll() take() poll(time,unit)</p>
<p>检查方法 element() peek() 不可用 不可用</p>
<p><img src="images/20191201214440080_637429054.png"></p>
<h1 id="3、成员详解"><a href="#3、成员详解" class="headerlink" title="3、成员详解"></a>3、成员详解</h1><h2 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a>ArrayBlockingQueue</h2><pre><code>   基于数组的阻塞队列实现，在ArrayBlockingQueue内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。  </code></pre>
<p>　　ArrayBlockingQueue在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于LinkedBlockingQueue；按照实现原理来分析，ArrayBlockingQueue完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea之所以没这样去做，也许是因为ArrayBlockingQueue的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。 ArrayBlockingQueue和LinkedBlockingQueue间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。而在创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。</p>
<h2 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a>LinkedBlockingQueue</h2><pre><code>   基于链表的阻塞队列，同ArrayListBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。  </code></pre>
<p>作为开发者，我们需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。</p>
<h2 id="DelayQueue"><a href="#DelayQueue" class="headerlink" title="DelayQueue"></a>DelayQueue</h2><pre><code>   DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。  </code></pre>
<p>使用场景：<br>       DelayQueue使用场景较少，但都相当巧妙，常见的例子比如使用一个DelayQueue来管理一个超时未响应的连接队列。</p>
<h2 id="PriorityBlockingQueue"><a href="#PriorityBlockingQueue" class="headerlink" title="PriorityBlockingQueue"></a>PriorityBlockingQueue</h2><pre><code>   基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现PriorityBlockingQueue时，内部控制线程同步的锁采用的是公平锁。</code></pre>
<h2 id="SynchronousQueue"><a href="#SynchronousQueue" class="headerlink" title="SynchronousQueue"></a>SynchronousQueue</h2><pre><code>   一种无缓冲的等待队列，类似于无中介的直接交易，有点像原始社会中的生产者和消费者，生产者拿着产品去集市销售给产品的最终消费者，而消费者必须亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么对不起，大家都在集市等待。相对于有缓冲的BlockingQueue来说，少了一个中间经销商的环节（缓冲区），如果有经销商，生产者直接把产品批发给经销商，而无需在意经销商最终会将这些产品卖给那些消费者，由于经销商可以库存一部分商品，因此相对于直接交易模式，总体来说采用中间经销商的模式会吞吐量高一些（可以批量买卖）；但另一方面，又因为经销商的引入，使得产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时响应性能可能会降低。  </code></pre>
<p>　　声明一个SynchronousQueue有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式的区别:<br>　　如果采用公平模式：SynchronousQueue会采用公平锁，并配合一个FIFO队列来阻塞多余的生产者和消费者，从而体系整体的公平策略；<br>　　但如果是非公平模式（SynchronousQueue默认）：SynchronousQueue采用非公平锁，同时配合一个LIFO队列来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。</p>
<h1 id="4、秒杀demo"><a href="#4、秒杀demo" class="headerlink" title="4、秒杀demo"></a>4、秒杀demo</h1><h2 id="秒杀对列"><a href="#秒杀对列" class="headerlink" title="秒杀对列"></a>秒杀对列</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsshy.beam.queue.jvm;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.hsshy.beam.queue.entity.SuccessKilled;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.BlockingQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.LinkedBlockingQueue;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 秒杀队列(固定长度为100)</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> 科帮网 By https://blog.52itstyle.com</span></span><br><span class="line"><span class="comment"> * 创建时间   2018年5月10日</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SeckillQueue</span> </span>&#123;</span><br><span class="line">     <span class="comment">//队列大小</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> QUEUE_MAX_SIZE   = <span class="number">100</span>;</span><br><span class="line">    <span class="comment">/** 用于多线程间下单的队列 */</span></span><br><span class="line">    <span class="keyword">static</span> BlockingQueue&lt;SuccessKilled&gt; blockingQueue = <span class="keyword">new</span> LinkedBlockingQueue&lt;SuccessKilled&gt;(QUEUE_MAX_SIZE);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 私有的默认构造子，保证外界无法直接实例化</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SeckillQueue</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 类级的内部类，也就是静态的成员式内部类，该内部类的实例与外部类的实例</span></span><br><span class="line"><span class="comment">     * 没有绑定关系，而且只有被调用到才会装载，从而实现了延迟加载</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span></span>&#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 静态初始化器，由JVM来保证线程安全</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">private</span>  <span class="keyword">static</span> SeckillQueue queue = <span class="keyword">new</span> SeckillQueue();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//单例队列</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SeckillQueue <span class="title">getMailQueue</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SingletonHolder.queue;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 生产入队</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> kill</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     * add(e) 队列未满时，返回true；队列满则抛出IllegalStateException(“Queue full”)异常——AbstractQueue </span></span><br><span class="line"><span class="comment">     * put(e) 队列未满时，直接插入没有返回值；队列满时会阻塞等待，一直等到队列未满时再插入。</span></span><br><span class="line"><span class="comment">     * offer(e) 队列未满时，返回true；队列满时返回false。非阻塞立即返回。</span></span><br><span class="line"><span class="comment">     * offer(e, time, unit) 设定等待的时间，如果在指定时间内还不能往队列中插入数据则返回false，插入成功返回true。 </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  Boolean  <span class="title">produce</span><span class="params">(SuccessKilled kill)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> blockingQueue.offer(kill);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 消费出队</span></span><br><span class="line"><span class="comment">     * poll() 获取并移除队首元素，在指定的时间内去轮询队列看有没有首元素有则返回，否者超时后返回null</span></span><br><span class="line"><span class="comment">     * take() 与带超时时间的poll类似不同在于take时候如果当前队列空了它会一直等待其他线程调用notEmpty.signal()才会被唤醒</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  SuccessKilled <span class="title">consume</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> blockingQueue.take();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 获取队列大小</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> blockingQueue.size();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="springboot启动时执行类"><a href="#springboot启动时执行类" class="headerlink" title="springboot启动时执行类"></a>springboot启动时执行类</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsshy.beam.queue.jvm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.hsshy.beam.queue.entity.SuccessKilled;</span><br><span class="line"><span class="keyword">import</span> com.hsshy.beam.queue.service.ISeckillService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.ApplicationArguments;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.ApplicationRunner;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费秒杀队列</span></span><br><span class="line"><span class="comment"> * 创建者 科帮网</span></span><br><span class="line"><span class="comment"> * 创建时间 2018年4月3日</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TaskRunner</span> <span class="keyword">implements</span> <span class="title">ApplicationRunner</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ISeckillService seckillService;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(ApplicationArguments <span class="keyword">var</span>)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            <span class="comment">//进程内队列</span></span><br><span class="line">            SuccessKilled kill = SeckillQueue.getMailQueue().consume();</span><br><span class="line">            <span class="keyword">if</span>(kill!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                seckillService.startSeckil(kill.getId(), kill.getUserId());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="controller层"><a href="#controller层" class="headerlink" title="controller层"></a>controller层</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ApiOperation(value=&quot;秒杀柒(进程内队列)&quot;,nickname=&quot;科帮网&quot;)</span></span><br><span class="line">   <span class="meta">@PostMapping(&quot;/startQueue&quot;)</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> R <span class="title">startQueue</span><span class="params">(<span class="keyword">long</span> seckillId)</span></span>&#123;</span><br><span class="line">       seckillService.deleteSeckill(seckillId);</span><br><span class="line">       <span class="keyword">final</span> <span class="keyword">long</span> killId =  seckillId;</span><br><span class="line">       LOGGER.info(<span class="string">&quot;开始秒杀柒(正常)&quot;</span>);</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1000</span>;i++)&#123;</span><br><span class="line">           <span class="keyword">final</span> <span class="keyword">long</span> userId = i;</span><br><span class="line">           Runnable task = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">               <span class="meta">@Override</span></span><br><span class="line">               <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                   SuccessKilled kill = <span class="keyword">new</span> SuccessKilled();</span><br><span class="line">                   kill.setId(killId);</span><br><span class="line">                   kill.setUserId(userId);</span><br><span class="line">                   <span class="keyword">try</span> &#123;</span><br><span class="line">                       Boolean flag = SeckillQueue.getMailQueue().produce(kill);</span><br><span class="line">                       <span class="keyword">if</span>(flag)&#123;</span><br><span class="line">                           LOGGER.info(<span class="string">&quot;用户:&#123;&#125;&#123;&#125;&quot;</span>,kill.getUserId(),<span class="string">&quot;秒杀成功&quot;</span>);</span><br><span class="line">                       &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                           LOGGER.info(<span class="string">&quot;用户:&#123;&#125;&#123;&#125;&quot;</span>,userId,<span class="string">&quot;秒杀失败&quot;</span>);</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                       e.printStackTrace();</span><br><span class="line">                       LOGGER.info(<span class="string">&quot;用户:&#123;&#125;&#123;&#125;&quot;</span>,userId,<span class="string">&quot;秒杀失败&quot;</span>);</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;;</span><br><span class="line">           executor.execute(task);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">           Long  seckillCount = seckillService.getSeckillCount(seckillId);</span><br><span class="line">           LOGGER.info(<span class="string">&quot;一共秒杀出&#123;&#125;件商品&quot;</span>,seckillCount);</span><br><span class="line">       &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> R.ok();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="5、延时队列demo"><a href="#5、延时队列demo" class="headerlink" title="5、延时队列demo"></a>5、延时队列demo</h1><h2 id="消息体"><a href="#消息体" class="headerlink" title="消息体"></a>消息体</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsshy.beam.queue.delay;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Delayed;  </span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 消息体定义 实现Delayed接口就是实现两个方法即compareTo 和 getDelay最重要的就是getDelay方法，这个方法用来判断是否到期…… </span></span><br><span class="line"><span class="comment"> *  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Message</span> <span class="keyword">implements</span> <span class="title">Delayed</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;  </span><br><span class="line">    <span class="keyword">private</span> String body; <span class="comment">// 消息内容  </span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> excuteTime;<span class="comment">// 延迟时长，这个是必须的属性因为要按照这个判断延时时长。  </span></span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getId</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">return</span> id;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getBody</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">return</span> body;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getExcuteTime</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">return</span> excuteTime;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Message</span><span class="params">(<span class="keyword">int</span> id, String body, <span class="keyword">long</span> delayTime)</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">this</span>.id = id;  </span><br><span class="line">        <span class="keyword">this</span>.body = body;  </span><br><span class="line">        <span class="keyword">this</span>.excuteTime = TimeUnit.NANOSECONDS.convert(delayTime, TimeUnit.MILLISECONDS) + System.nanoTime();  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 自定义实现比较方法返回 1 0 -1三个参数  </span></span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(Delayed delayed)</span> </span>&#123;  </span><br><span class="line">        Message msg = (Message) delayed;  </span><br><span class="line">        <span class="keyword">return</span> Integer.valueOf(<span class="keyword">this</span>.id) &gt; Integer.valueOf(msg.id) ? <span class="number">1</span>  </span><br><span class="line">                : (Integer.valueOf(<span class="keyword">this</span>.id) &lt; Integer.valueOf(msg.id) ? -<span class="number">1</span> : <span class="number">0</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 延迟任务是否到时就是按照这个方法判断如果返回的是负数则说明到期否则还没到期  </span></span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getDelay</span><span class="params">(TimeUnit unit)</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">return</span> unit.convert(<span class="keyword">this</span>.excuteTime - System.nanoTime(), TimeUnit.NANOSECONDS);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsshy.beam.queue.delay;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.DelayQueue;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;  </span><br><span class="line">    <span class="comment">// 延时队列 ,消费者从其中获取消息进行消费  </span></span><br><span class="line">    <span class="keyword">private</span> DelayQueue&lt;Message&gt; queue;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Consumer</span><span class="params">(DelayQueue&lt;Message&gt; queue)</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">this</span>.queue = queue;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;  </span><br><span class="line">            <span class="keyword">try</span> &#123;  </span><br><span class="line">                Message take = queue.take();  </span><br><span class="line">                System.out.println(<span class="string">&quot;消费消息id：&quot;</span> + take.getId() + <span class="string">&quot; 消息体：&quot;</span> + take.getBody());  </span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;  </span><br><span class="line">                e.printStackTrace();  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="测试类"><a href="#测试类" class="headerlink" title="测试类"></a>测试类</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hsshy.beam.queue.delay;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.DelayQueue;  </span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;  </span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DelayQueueTest</span> </span>&#123;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;    </span><br><span class="line">            <span class="comment">// 创建延时队列    </span></span><br><span class="line">            DelayQueue&lt;Message&gt; queue = <span class="keyword">new</span> DelayQueue&lt;Message&gt;();    </span><br><span class="line">            <span class="comment">// 添加延时消息,m1 延时3s    </span></span><br><span class="line">            Message m1 = <span class="keyword">new</span> Message(<span class="number">1</span>, <span class="string">&quot;world&quot;</span>, <span class="number">3000</span>);    </span><br><span class="line">            <span class="comment">// 添加延时消息,m2 延时10s    </span></span><br><span class="line">            Message m2 = <span class="keyword">new</span> Message(<span class="number">2</span>, <span class="string">&quot;hello&quot;</span>, <span class="number">10000</span>);    </span><br><span class="line">            <span class="comment">//将延时消息放到延时队列中  </span></span><br><span class="line">            queue.offer(m2);    </span><br><span class="line">            queue.offer(m1);    </span><br><span class="line">            <span class="comment">// 启动消费线程 消费添加到延时队列中的消息，前提是任务到了延期时间   </span></span><br><span class="line">            ExecutorService exec = Executors.newFixedThreadPool(<span class="number">1</span>);  </span><br><span class="line">            exec.execute(<span class="keyword">new</span> Consumer(queue));  </span><br><span class="line">            exec.shutdown();  </span><br><span class="line">        &#125;    </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p>【参考文献】：</p>
<p><a href="https://links.jianshu.com/go?to=https://www.cnblogs.com/KingIceMou/p/8075343.html">https://www.cnblogs.com/KingIceMou/p/8075343.html</a><br><a href="https://links.jianshu.com/go?to=http://www.cnblogs.com/WangHaiMing/p/8798709.html">http://www.cnblogs.com/WangHaiMing/p/8798709.html</a><br><a href="https://links.jianshu.com/go?to=https://gitee.com/52itstyle/spring-boot-seckill">https://gitee.com/52itstyle/spring-boot-seckill</a></p>
<p><a href="http://wsmajunfeng.iteye.com/blog/1629354">BlockingQueue（阻塞队列）详解</a></p>
<p><a href="https://www.jianshu.com/p/ed2b56bcba3d">ArrayBlockingQueue源码解析</a></p>
<p><a href="http://ifeve.com/java-blocking-queue/">Java中的阻塞队列</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发7: Fork/Join</title>
    <url>/Java/multithread/07.Fork-Join/</url>
    <content><![CDATA[<h2 id="1-什么是Fork-Join框架"><a href="#1-什么是Fork-Join框架" class="headerlink" title="1. 什么是Fork/Join框架"></a>1. 什么是Fork/Join框架</h2><p>Fork/Join框架是Java7提供了的一个用于并行执行任务的框架， 是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。</p>
<p>我们再通过Fork和Join这两个单词来理解下Fork/Join框架，Fork就是把一个大任务切分为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。比如计算1+2+。。＋10000，可以分割成10个子任务，每个子任务分别对1000个数进行求和，最终汇总这10个子任务的结果。Fork/Join的运行流程图如下：</p>
<p><img src="http://cdn2.infoqstatic.com/statics_s2_20170411-0445/resource/articles/fork-join-introduction/zh/resources/21.png" alt="img"></p>
<h2 id="2-工作窃取算法"><a href="#2-工作窃取算法" class="headerlink" title="2. 工作窃取算法"></a>2. 工作窃取算法</h2><p>工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。工作窃取的运行流程图如下：</p>
<p><img src="http://cdn2.infoqstatic.com/statics_s2_20170411-0445/resource/articles/fork-join-introduction/zh/resources/image3.png" alt="img"></p>
<p>那么为什么需要使用工作窃取算法呢？假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。</p>
<p>工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。</p>
<h2 id="3-Fork-Join框架的介绍"><a href="#3-Fork-Join框架的介绍" class="headerlink" title="3. Fork/Join框架的介绍"></a>3. Fork/Join框架的介绍</h2><p>我们已经很清楚Fork/Join框架的需求了，那么我们可以思考一下，如果让我们来设计一个Fork/Join框架，该如何设计？这个思考有助于你理解Fork/Join框架的设计。</p>
<p>第一步分割任务。首先我们需要有一个fork类来把大任务分割成子任务，有可能子任务还是很大，所以还需要不停的分割，直到分割出的子任务足够小。</p>
<p>第二步执行任务并合并结果。分割的子任务分别放在双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都统一放在一个队列里，启动一个线程从队列里拿数据，然后合并这些数据。</p>
<p>Fork/Join使用两个类来完成以上两件事情：</p>
<ul>
<li>ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制，通常情况下我们不需要直接继承ForkJoinTask类，而只需要继承它的子类，Fork/Join框架提供了以下两个子类：    <ul>
<li>RecursiveAction：用于没有返回结果的任务。</li>
<li>RecursiveTask ：用于有返回结果的任务。</li>
</ul>
</li>
<li>ForkJoinPool ：ForkJoinTask需要通过ForkJoinPool来执行，任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。</li>
</ul>
<h2 id="4-使用Fork-Join框架"><a href="#4-使用Fork-Join框架" class="headerlink" title="4. 使用Fork/Join框架"></a>4. 使用Fork/Join框架</h2><p>让我们通过一个简单的需求来使用下Fork／Join框架，需求是：计算1+2+3+4的结果。</p>
<p>使用Fork／Join框架首先要考虑到的是如何分割任务，如果我们希望每个子任务最多执行两个数的相加，那么我们设置分割的阈值是2，由于是4个数字相加，所以Fork／Join框架会把这个任务fork成两个子任务，子任务一负责计算1+2，子任务二负责计算3+4，然后再join两个子任务的结果。</p>
<p>因为是有结果的任务，所以必须继承RecursiveTask，实现代码如下：</p>
<p><img src="http://cdn2.infoqstatic.com/statics_s2_20170411-0445/resource/articles/fork-join-introduction/zh/resources/31.png" alt="img"></p>
<p><img src="http://cdn2.infoqstatic.com/statics_s2_20170411-0445/resource/articles/fork-join-introduction/zh/resources/eeeee.png" alt="img"></p>
<p>通过这个例子让我们再来进一步了解ForkJoinTask，ForkJoinTask与一般的任务的主要区别在于它需要实现compute方法，在这个方法里，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果不足够小，就必须分割成两个子任务，每个子任务在调用fork方法时，又会进入compute方法，看看当前子任务是否需要继续分割成孙任务，如果不需要继续分割，则执行当前子任务并返回结果。使用join方法会等待子任务执行完并得到其结果。</p>
<h2 id="5-Fork-Join框架的异常处理"><a href="#5-Fork-Join框架的异常处理" class="headerlink" title="5. Fork/Join框架的异常处理"></a>5. Fork/Join框架的异常处理</h2><p>ForkJoinTask在执行的时候可能会抛出异常，但是我们没办法在主线程里直接捕获异常，所以ForkJoinTask提供了isCompletedAbnormally()方法来检查任务是否已经抛出异常或已经被取消了，并且可以通过ForkJoinTask的getException方法获取异常。使用如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if(task.isCompletedAbnormally())</span><br><span class="line">&#123;</span><br><span class="line">    System.out.println(task.getException());</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>getException方法返回Throwable对象，如果任务被取消了则返回CancellationException。如果任务没有完成或者没有抛出异常则返回null。</p>
<h2 id="6-Fork-Join框架的实现原理"><a href="#6-Fork-Join框架的实现原理" class="headerlink" title="6. Fork/Join框架的实现原理"></a>6. Fork/Join框架的实现原理</h2><p>ForkJoinPool由ForkJoinTask数组和ForkJoinWorkerThread数组组成，ForkJoinTask数组负责存放程序提交给ForkJoinPool的任务，而ForkJoinWorkerThread数组负责执行这些任务。</p>
<p>ForkJoinTask的fork方法实现原理。当我们调用ForkJoinTask的fork方法时，程序会调用ForkJoinWorkerThread的pushTask方法异步的执行这个任务，然后立即返回结果。代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final ForkJoinTask fork() &#123;         ((ForkJoinWorkerThread) Thread.currentThread())             .pushTask(this);         return this; &#125; </span><br></pre></td></tr></table></figure>
<p>pushTask方法把当前任务存放在ForkJoinTask 数组queue里。然后再调用ForkJoinPool的signalWork()方法唤醒或创建一个工作线程来执行任务。代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">final void pushTask(ForkJoinTask t) &#123;</span><br><span class="line">        ForkJoinTask[] q; int s, m;</span><br><span class="line">        if ((q &#x3D; queue) !&#x3D; null) &#123;    &#x2F;&#x2F; ignore if queue removed</span><br><span class="line">            long u &#x3D; (((s &#x3D; queueTop) &amp; (m &#x3D; q.length - 1)) &lt;&lt; ASHIFT) + ABASE;</span><br><span class="line">            UNSAFE.putOrderedObject(q, u, t);</span><br><span class="line">            queueTop &#x3D; s + 1;         &#x2F;&#x2F; or use putOrderedInt</span><br><span class="line">            if ((s -&#x3D; queueBase) &lt;&#x3D; 2)</span><br><span class="line">                pool.signalWork();</span><br><span class="line">	else if (s &#x3D;&#x3D; m)</span><br><span class="line">                growQueue();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>ForkJoinTask的join方法实现原理。Join方法的主要作用是阻塞当前线程并等待获取结果。让我们一起看看ForkJoinTask的join方法的实现，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final V join() &#123;</span><br><span class="line">        if (doJoin() !&#x3D; NORMAL)</span><br><span class="line">            return reportResult();</span><br><span class="line">        else</span><br><span class="line">            return getRawResult();</span><br><span class="line">&#125;</span><br><span class="line">private V reportResult() &#123;</span><br><span class="line">        int s; Throwable ex;</span><br><span class="line">        if ((s &#x3D; status) &#x3D;&#x3D; CANCELLED)</span><br><span class="line">            throw new CancellationException();</span><br><span class="line">if (s &#x3D;&#x3D; EXCEPTIONAL &amp;&amp; (ex &#x3D; getThrowableException()) !&#x3D; null)</span><br><span class="line">            UNSAFE.throwException(ex);</span><br><span class="line">        return getRawResult();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>首先，它调用了doJoin()方法，通过doJoin()方法得到当前任务的状态来判断返回什么结果，任务状态有四种：已完成（NORMAL），被取消（CANCELLED），信号（SIGNAL）和出现异常（EXCEPTIONAL）。</p>
<ul>
<li>如果任务状态是已完成，则直接返回任务结果。</li>
<li>如果任务状态是被取消，则直接抛出CancellationException。</li>
<li>如果任务状态是抛出异常，则直接抛出对应的异常。</li>
</ul>
<p>让我们再来分析下doJoin()方法的实现代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private int doJoin() &#123;</span><br><span class="line">        Thread t; ForkJoinWorkerThread w; int s; boolean completed;</span><br><span class="line">        if ((t &#x3D; Thread.currentThread()) instanceof ForkJoinWorkerThread) &#123;</span><br><span class="line">            if ((s &#x3D; status) &lt; 0)</span><br><span class="line"> return s;</span><br><span class="line">            if ((w &#x3D; (ForkJoinWorkerThread)t).unpushTask(this)) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    completed &#x3D; exec();</span><br><span class="line">                &#125; catch (Throwable rex) &#123;</span><br><span class="line">                    return setExceptionalCompletion(rex);</span><br><span class="line">                &#125;</span><br><span class="line">                if (completed)</span><br><span class="line">                    return setCompletion(NORMAL);</span><br><span class="line">            &#125;</span><br><span class="line">            return w.joinTask(this);</span><br><span class="line">        &#125;</span><br><span class="line">        else</span><br><span class="line">            return externalAwaitDone();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在doJoin()方法里，首先通过查看任务的状态，看任务是否已经执行完了，如果执行完了，则直接返回任务状态，如果没有执行完，则从任务数组里取出任务并执行。如果任务顺利执行完成了，则设置任务状态为NORMAL，如果出现异常，则纪录异常，并将任务状态设置为EXCEPTIONAL。</p>
<h2 id="7-参考资料"><a href="#7-参考资料" class="headerlink" title="7. 参考资料"></a>7. 参考资料</h2><ul>
<li>JDK1.7源码</li>
<li><a href="http://ifeve.com/fork-join-5/">http://ifeve.com/fork-join-5/</a></li>
</ul>
<h2 id="8-作者介绍"><a href="#8-作者介绍" class="headerlink" title="8. 作者介绍"></a>8. 作者介绍</h2><p><strong>方腾飞</strong>，花名清英，并发编程网站站长。目前在阿里巴巴微贷事业部工作。并发编程网：<a href="http://ifeve.com/">http://ifeve.com</a>，个人微博：<a href="http://weibo.com/kirals">http://weibo.com/kirals</a>，欢迎通过我的微博进行技术交流。</p>
<p>感谢<a href="http://www.infoq.com/cn/bycategory.action?authorName=%E5%BC%A0%E9%BE%99">张龙</a>对本文的审校。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
        <tag>Fork-Join</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Thread与系统线程对应关系</title>
    <url>/Java/multithread/08.Thread-Native/</url>
    <content><![CDATA[<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SecurityManager securityManager = <span class="keyword">new</span> SecurityManager();</span><br><span class="line">ThreadInfo[] infos = ManagementFactory.getThreadMXBean().dumpAllThreads(<span class="keyword">true</span>,<span class="keyword">true</span>);</span><br><span class="line">Stream.of(infos).forEach(info-&gt;&#123; System.out.println(info.getThreadName()+<span class="string">&quot;\t&quot;</span>+info.getThreadId()+<span class="string">&quot;\t&quot;</span>+info.getThreadState());</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a href="https://blog.csdn.net/qq_27035123/article/details/77651534">Java线程与内核线程</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
        <tag>Fork-Join</tag>
      </tags>
  </entry>
  <entry>
    <title>Java栈分析与调优</title>
    <url>/Java/multithread/09.JStack/</url>
    <content><![CDATA[<h1 id="JStack"><a href="#JStack" class="headerlink" title="JStack"></a>JStack</h1><h2 id="寻找问题线程的过程"><a href="#寻找问题线程的过程" class="headerlink" title="寻找问题线程的过程"></a>寻找问题线程的过程</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">top -Hp  1704</span><br></pre></td></tr></table></figure>
<p>![top thread](_v_images/20190728100942815_354006932.png =690x)</p>
<ol>
<li>目标线程的id转换为16进制</li>
<li>jstack dump线程栈</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[deploy@centos ~]$ printf &#x27;%x&#x27; 1721</span><br><span class="line">6b9</span><br><span class="line">[deploy@centos ~]$ jstack -l 1704 | grep  6b9 -A 20</span><br><span class="line">&quot;handler-0&quot; #9 prio=5 os_prio=0 tid=0x00007fa21c14e000 nid=0x6b9 waiting on condition [0x00007fa1f2884000]</span><br><span class="line">   java.lang.Thread.State: TIMED_WAITING (sleeping)</span><br><span class="line">	at java.lang.Thread.sleep(Native Method)</span><br><span class="line">	at com.lk.optimization.demo.Worker.run(DemoTest.java:34)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:748)</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">	- None</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jstack [ option ] pid</span><br><span class="line">基本参数：</span><br><span class="line">-F 当’jstack [-l] pid’没有响应的时候强制打印栈信息</span><br><span class="line">-l 长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表.</span><br><span class="line">-m 打印java和native c/c++框架的所有栈信息. -h | -help打印帮助信息</span><br><span class="line">pid 需要被打印配置信息的java进程id,可以用jps工具查询. </span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kill -3 &lt;pid&gt;</span><br></pre></td></tr></table></figure>

<h2 id="线程的状态"><a href="#线程的状态" class="headerlink" title="线程的状态"></a>线程的状态</h2><h3 id="RUNNABLE"><a href="#RUNNABLE" class="headerlink" title="RUNNABLE"></a>RUNNABLE</h3><p>为了把runnable打出来，写了个死循环</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> Thread()&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            i++;</span><br><span class="line">            <span class="keyword">if</span>(i&gt;<span class="number">100000000</span>)&#123;</span><br><span class="line">                i=<span class="number">0</span>;</span><br><span class="line">                System.out.println(<span class="string">&quot;hha&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;.start();</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&quot;Thread-0&quot; #19 prio=5 os_prio=0 tid=0x00007f2810152000 nid=0x7aa runnable [0x00007f27f8a73000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line">    at java.io.FileOutputStream.writeBytes(Native Method)</span><br><span class="line">    at java.io.FileOutputStream.write(FileOutputStream.java:<span class="number">326</span>)</span><br><span class="line">    at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:<span class="number">82</span>)</span><br><span class="line">    at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:<span class="number">140</span>)</span><br><span class="line">    - locked &lt;<span class="number">0x00000000e0c1d7e8</span>&gt; (a java.io.BufferedOutputStream)</span><br><span class="line">    at java.io.PrintStream.write(PrintStream.java:<span class="number">482</span>)</span><br><span class="line">    - locked &lt;<span class="number">0x00000000e0c02988</span>&gt; (a java.io.PrintStream)</span><br><span class="line">    at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:<span class="number">221</span>)</span><br><span class="line">    at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:<span class="number">291</span>)</span><br><span class="line">    at sun.nio.cs.StreamEncoder.flushBuffer(StreamEncoder.java:<span class="number">104</span>)</span><br><span class="line">    - locked &lt;<span class="number">0x00000000e0c02940</span>&gt; (a java.io.OutputStreamWriter)</span><br><span class="line">    at java.io.OutputStreamWriter.flushBuffer(OutputStreamWriter.java:<span class="number">185</span>)</span><br><span class="line">    at java.io.PrintStream.newLine(PrintStream.java:<span class="number">546</span>)</span><br><span class="line">    - eliminated &lt;<span class="number">0x00000000e0c02988</span>&gt; (a java.io.PrintStream)</span><br><span class="line">    at java.io.PrintStream.println(PrintStream.java:<span class="number">807</span>)</span><br><span class="line">    - locked &lt;<span class="number">0x00000000e0c02988</span>&gt; (a java.io.PrintStream)</span><br><span class="line">    at com.lk.optimization.demo.DemoTest$<span class="number">1.</span>run(DemoTest.java:<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">    - None</span><br></pre></td></tr></table></figure>
<h3 id="TIMED-WAITING"><a href="#TIMED-WAITING" class="headerlink" title="TIMED_WAITING"></a>TIMED_WAITING</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&quot;handler-0&quot; #9 prio=5 os_prio=0 tid=0x00007fa21c14e000 nid=0x6b9 waiting on condition [0x00007fa1f2884000]</span><br><span class="line">   java.lang.Thread.State: TIMED_WAITING (sleeping)</span><br><span class="line">    at java.lang.Thread.sleep(Native Method)</span><br><span class="line">    at com.lk.optimization.demo.Worker.run(DemoTest.java:<span class="number">34</span>)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br><span class="line"></span><br><span class="line">   Locked ownable synchronizers:</span><br><span class="line">    - None</span><br></pre></td></tr></table></figure>
<p>JVM线程<tid>对应的系统线程<nid>, 16进制的<br>正等待&lt;0x00007fa1f2884000&gt;</p>
<h3 id="Blocked"><a href="#Blocked" class="headerlink" title="Blocked"></a>Blocked</h3><h4 id="多线程竞争synchronized锁"><a href="#多线程竞争synchronized锁" class="headerlink" title="多线程竞争synchronized锁"></a>多线程竞争synchronized锁</h4><p>![stack-blocked](_v_images/20190728105849426_741235393.png =778x)</p>
<p>很明显：线程1获取到锁，处于RUNNABLE状态，线程2处于BLOCK状态<br>1、locked &lt;0x000000076bf62208&gt;说明线程1对地址为0x000000076bf62208对象进行了加锁；<br>2、waiting to lock &lt;0x000000076bf62208&gt; 说明线程2在等待地址为0x000000076bf62208对象上的锁；<br>3、waiting for monitor entry [0x000000001e21f000]说明线程1是通过synchronized关键字进入了监视器的临界区，并处于”Entry Set”队列，等待monitor，具体实现可以参考<a href="https://www.jianshu.com/p/c5058b6fe8e5">深入分析synchronized的JVM实现</a>；</p>
<h4 id="通过wait挂起线程"><a href="#通过wait挂起线程" class="headerlink" title="通过wait挂起线程"></a>通过wait挂起线程</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Task</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                lock.wait();</span><br><span class="line">                <span class="comment">//TimeUnit.SECONDS.sleep(100000);</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>![stack wait](_v_images/20190728110132556_948612836.png =778x)</p>
<p>线程1和2都处于WAITING状态<br>1、线程1和2都是先locked &lt;0x000000076bf62500&gt;，再waiting on &lt;0x000000076bf62500&gt;，之所以先锁再等同一个对象，是因为wait方法需要先通过synchronized获得该地址对象的monitor；<br>2、waiting on &lt;0x000000076bf62500&gt;说明线程执行了wait方法之后，释放了monitor，进入到”Wait Set”队列，等待其它线程执行地址为0x000000076bf62500对象的notify方法，并唤醒自己，具体实现可以参考<a href="https://www.jianshu.com/p/f4454164c017">深入分析Object.wait/notify实现机制</a>；</p>
<h3 id="Wait-on-condition"><a href="#Wait-on-condition" class="headerlink" title="Wait on condition"></a>Wait on condition</h3><p>该状态出现在线程等待某个条件的发生。具体是什么原因，可以结合stacktrace来分析。最常见的情况是线程在等待网络的读写，比如当网络数据没有准备好读时，线程处于这种等待状态，而一旦有数据准备好读之后，线程会重新激活，读取并处理数据。在 Java引入 NIO之前，对于每个网络连接，都有一个对应的线程来处理网络的读写操作，即使没有可读写的数据，线程仍然阻塞在读写操作上，这样有可能造成资源浪费，而且给操作系统的线程调度也带来压力。在 NIO里采用了新的机制，编写的服务器程序的性能和可扩展性都得到提高。 </p>
<p>如果发现有大量的线程都在处在 Wait on condition，从线程 stack看， 正等待网络读写，这可能是一个网络瓶颈的征兆。因为网络阻塞导致线程无法执行。一种情况是网络非常忙，几乎消耗了所有的带宽，仍然有大量数据等待网络读写；另一种情况也可能是网络空闲，但由于路由等问题，导致包无法正常的到达。所以要结合系统的一些性能观察工具来综合分析，比如 netstat统计单位时间的发送包的数目，如果很明显超过了所在网络带宽的限制 ; 观察 cpu的利用率，如果系统态的 CPU时间，相对于用户态的 CPU时间比例较高；如果程序运行在 Solaris 10平台上，可以用 dtrace工具看系统调用的情况，如果观察到 read/write的系统调用的次数或者运行时间遥遥领先；这些都指向由于网络带宽所限导致的网络瓶颈。 </p>
<p>另外一种出现 Wait on condition的常见情况是该线程在 sleep，等待 sleep的时间到了时候，将被唤醒</p>
<h3 id="Waitingfor-monitor-entry-和-in-Object-wait"><a href="#Waitingfor-monitor-entry-和-in-Object-wait" class="headerlink" title="Waitingfor monitor entry 和 in Object.wait()"></a>Waitingfor monitor entry 和 in Object.wait()</h3><p>在多线程的 JAVA程序中，实现线程之间的同步，就要说说Monitor。Monitor是Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 Class的锁。每一个对象都有，也仅有一个 monitor。下面这个图，描述了线程和 Monitor之间关系，以及线程的状态转换图</p>
<p><img src="_v_images/20190728111407141_1843885222.png" alt="a Java monitor"></p>
<p>从图中可以看出，每个 Monitor在某个时刻，只能被一个线程拥有，该线程就是 “Active Thread”，而其它线程都是 “Waiting Thread”，分别在两个队列 “ Entry Set”和 “Wait Set”里面等候。在 “Entry Set”中等待的线程状态是 “Waiting for monitorentry”，而在 “Wait Set”中等待的线程状态是“in Object.wait()”。 </p>
<p>先看 “Entry Set”里面的线程。我们称被 synchronized保护起来的代码段为临界区。当一个线程申请进入临界区时，它就进入了 “Entry Set”队列。对应的 code就像： </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(obj)&#123; </span><br><span class="line"></span><br><span class="line">......... </span><br><span class="line"></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>这时有两种可能性： </p>
<ul>
<li><p>该 monitor不被其它线程拥有，Entry Set里面也没有其它等待线程。本线程即成为相应类或者对象的 Monitor的 Owner，执行临界区的代码 。此时线程将处于Runnable状态；</p>
</li>
<li><p>该 monitor被其它线程拥有，本线程在 Entry Set队列中等待。此时dump的信息显示“waiting for monitor entry”。</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;Thread-0&quot;</span> prio=<span class="number">10</span> tid=<span class="number">0x08222eb0</span> nid=<span class="number">0x9</span> waiting <span class="keyword">for</span> monitor entry [<span class="number">0xf927b000</span>..<span class="number">0xf927bdb8</span>] </span><br><span class="line"></span><br><span class="line">at testthread.WaitThread.run(WaitThread.java:<span class="number">39</span>) </span><br><span class="line">- waiting to lock &lt;<span class="number">0xef63bf08</span>&gt; (a java.lang.Object) </span><br><span class="line">- locked &lt;<span class="number">0xef63beb8</span>&gt; (a java.util.ArrayList) </span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">595</span>) </span><br></pre></td></tr></table></figure>
<p>临界区的设置，是为了保证其内部的代码执行的原子性和完整性。但是因为临界区在任何时间只允许线程串行通过，这和我们多线程的程序的初衷是相反的。如果在多线程的程序中，大量使用 synchronized，或者不适当的使用了它，会造成大量线程在临界区的入口等待，造成系统的性能大幅下降。如果在线程 DUMP中发现了这个情况，应该审查源码，改进程序。 </p>
<p>现在我们再来看现在线程为什么会进入 “Wait Set”。当线程获得了 Monitor，进入了临界区之后，如果发现线程继续运行的条件没有满足，它则调用对象（一般就是被 synchronized 的对象）的 wait() 方法，放弃了 Monitor，进入 “Wait Set”队列。只有当别的线程在该对象上调用了 notify() 或者 notifyAll() ， “ Wait Set”队列中线程才得到机会去竞争，但是只有一个线程获得对象的Monitor，恢复到运行态。在 “Wait Set”中的线程， DUMP中表现为： in Object.wait()，类似于： </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;Thread-1&quot;</span> prio=<span class="number">10</span> tid=<span class="number">0x08223250</span> nid=<span class="number">0xa</span> in Object.wait() [<span class="number">0xef47a000</span>..<span class="number">0xef47aa38</span>] </span><br><span class="line"></span><br><span class="line">at java.lang.Object.wait(Native Method) </span><br><span class="line"></span><br><span class="line">- waiting on &lt;<span class="number">0xef63beb8</span>&gt; (a java.util.ArrayList) </span><br><span class="line"></span><br><span class="line">at java.lang.Object.wait(Object.java:<span class="number">474</span>) </span><br><span class="line"></span><br><span class="line">at testthread.MyWaitThread.run(MyWaitThread.java:<span class="number">40</span>) </span><br><span class="line"></span><br><span class="line">- locked &lt;<span class="number">0xef63beb8</span>&gt; (a java.util.ArrayList) </span><br><span class="line"></span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">595</span>) </span><br></pre></td></tr></table></figure>
<p>仔细观察上面的 DUMP信息，你会发现它有以下两行： </p>
<p>² locked &lt;0xef63beb8&gt; (ajava.util.ArrayList) </p>
<p>² waiting on &lt;0xef63beb8&gt; (ajava.util.ArrayList) </p>
<p>这里需要解释一下，为什么先 lock了这个对象，然后又 waiting on同一个对象呢？让我们看看这个线程对应的代码： </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(obj)&#123;</span><br><span class="line"></span><br><span class="line">......... </span><br><span class="line"></span><br><span class="line">obj.wait();</span><br><span class="line"></span><br><span class="line">......... </span><br><span class="line"></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>线程的执行中，先用 synchronized 获得了这个对象的 Monitor（对应于 locked &lt;0xef63beb8&gt; ）。当执行到 obj.wait(), 线程即放弃了 Monitor的所有权，进入 “wait set”队列（对应于 waiting on&lt;0xef63beb8&gt; ）。 </p>
<p>往在你的程序中，会出现多个类似的线程，他们都有相似的 dump也可能是正常的。比如，在程序中有多个服务线程，设计成从一个队列里面读取请求数据。这个队列就是 lock以及 waiting on的对象。当队列为空的时候，这些线程都会在这个队列上等待，直到队列有了数据，这些线程被notify，当然只有一个线程获得了 lock，继续执行，而其它线程继续等待。 </p>
<h2 id="JVM的一些重要线程"><a href="#JVM的一些重要线程" class="headerlink" title="JVM的一些重要线程"></a>JVM的一些重要线程</h2><h3 id="Attach-Listener"><a href="#Attach-Listener" class="headerlink" title="Attach Listener"></a>Attach Listener</h3><p>JVM</p>
<p>Attach Listener 线程是负责接收到外部的命令，而对该命令进行执行的并且吧结果返回给发送者。通常我们会用一些命令去要求jvm给我们一些反馈信息，如：java -version、jmap、jstack等等。 如果该线程在jvm启动的时候没有初始化，那么，则会在用户第一次执行jvm命令时，得到启动。</p>
<h3 id="Signal-Dispatcher"><a href="#Signal-Dispatcher" class="headerlink" title="Signal Dispatcher"></a>Signal Dispatcher</h3><p>JVM</p>
<p>前面我们提到第一个Attach Listener线程的职责是接收外部jvm命令，当命令接收成功后，会交给signal dispather 线程去进行分发到各个不同的模块处理命令，并且返回处理结果。 signal dispather线程也是在第一次接收外部jvm命令时，进行初始化工作。</p>
<h3 id="CompilerThread0"><a href="#CompilerThread0" class="headerlink" title="CompilerThread0"></a>CompilerThread0</h3><p>JVM</p>
<p>用来调用JITing，实时编译装卸class 。 通常，jvm会启动多个线程来处理这部分工作，线程名称后面的数字也会累加，例如：CompilerThread1</p>
<h3 id="Concurrent-Mark-Sweep-GC-Thread"><a href="#Concurrent-Mark-Sweep-GC-Thread" class="headerlink" title="Concurrent Mark-Sweep GC Thread"></a>Concurrent Mark-Sweep GC Thread</h3><p>JVM</p>
<p>并发标记清除垃圾回收器（就是通常所说的CMS GC）线程， 该线程主要针对于老年代垃圾回收。ps：启用该垃圾回收器，需要在jvm启动参数中加上： -XX:+UseConcMarkSweepGC </p>
<h3 id="DestroyJavaVM"><a href="#DestroyJavaVM" class="headerlink" title="DestroyJavaVM"></a>DestroyJavaVM</h3><p>JVM</p>
<p>执行main()的线程在main执行完后调用JNI中的 jni_DestroyJavaVM() 方法唤起DestroyJavaVM 线程。</p>
<p>ps：</p>
<p>扩展一下：</p>
<p>1.如果线程退出时判断自己不为最后一个非deamon线程，那么调用thread-&gt;exit(false) ，并在其中抛出thread_end事件，jvm不退出。</p>
<p>2.如果线程退出时判断自己为最后一个非deamon线程，那么调用before_exit() 方法，抛出两个事件： </p>
<p>事件1：thread_end 线程结束事件；</p>
<p>事件2：VM的death事件。</p>
<p>然后调用thread-&gt;exit(true) 方法，接下来把线程从active list卸下，删除线程等等一系列工作执行完成后，则通知正在等待的DestroyJavaVM 线程执行卸载JVM操作。</p>
<h3 id="Dispatcher-Thread-3-线程"><a href="#Dispatcher-Thread-3-线程" class="headerlink" title="Dispatcher-Thread-3  线程"></a>Dispatcher-Thread-3  线程</h3><p>Log4j</p>
<p>Log4j具有异步打印日志的功能，需要异步打印日志的Appender都需要注册到 AsyncAppender对象里面去，由AsyncAppender进行监听，决定何时触发日志打印操作。<br>AsyncAppender如果监听到它管辖范围内的Appender有打印日志的操作，则给这个Appender生成一个相应的event，并将该event保存在一个buffuer区域内。</p>
<p>Dispatcher-Thread-3线程负责判断这个event缓存区是否已经满了，如果已经满了，则将缓存区内的所有event分发到Appender容器里面去，那些注册上来的Appender收到自己的event后，则开始处理自己的日志打印工作。 Dispatcher-Thread-3线程是一个守护线程。</p>
<h3 id="Finalizer线程"><a href="#Finalizer线程" class="headerlink" title="Finalizer线程"></a>Finalizer线程</h3><p>JVM</p>
<p>这个线程也是在main线程之后创建的，其优先级为10，主要用于在垃圾收集前，调用对象的finalize()方法；关于Finalizer线程的几点：</p>
<ol>
<li><p>只有当开始一轮垃圾收集时，才会开始调用finalize()方法；因此并不是所有对象的finalize()方法都会被执行；</p>
</li>
<li><p>该线程也是daemon线程，因此如果虚拟机中没有其他非daemon线程，不管该线程有没有执行完finalize()方法，JVM也会退出；</p>
</li>
<li><p>JVM在垃圾收集时会将失去引用的对象包装成Finalizer对象（Reference的实现），并放入ReferenceQueue，由Finalizer线程来处理；最后将该Finalizer对象的引用置为null，由垃圾收集器来回收；</p>
</li>
<li><p>JVM为什么要单独用一个线程来执行finalize()方法呢？如果JVM的垃圾收集线程自己来做，很有可能由于在finalize()方法中误操作导致GC线程停止或不可控，这对GC线程来说是一种灾难；</p>
</li>
</ol>
<h3 id="Gang-worker-0"><a href="#Gang-worker-0" class="headerlink" title="Gang worker#0"></a>Gang worker#0</h3><p>JVM</p>
<p>JVM 用于做新生代垃圾回收（monir gc）的一个线程。#号后面是线程编号，例如：Gang worker#1</p>
<h3 id="GC-Daemon"><a href="#GC-Daemon" class="headerlink" title="GC Daemon"></a>GC Daemon</h3><p>JVM</p>
<p>GC Daemon 线程是JVM为RMI提供远程分布式GC使用的，GC Daemon线程里面会主动调用System.gc()方法，对服务器进行Full GC。 其初衷是当 RMI 服务器返回一个对象到其客户机（远程方法的调用方）时，其跟踪远程对象在客户机中的使用。当再没有更多的对客户机上远程对象的引用时，或者如果引用的“租借”过期并且没有更新，服务器将垃圾回收远程对象。</p>
<p>不过，我们现在jvm启动参数都加上了-XX:+DisableExplicitGC配置，所以，这个线程只有打酱油的份了。</p>
<h3 id="Java2D-Disposer"><a href="#Java2D-Disposer" class="headerlink" title="Java2D Disposer"></a>Java2D Disposer</h3><p>JVM</p>
<p>这个线程主要服务于awt的各个组件。 说起该线程的主要工作职责前，需要先介绍一下Disposer类是干嘛的。 Disposer提供一个addRecord方法。 如果你想在一个对象被销毁前再做一些善后工作，那么，你可以调用Disposer#addRecord方法，将这个对象和一个自定义的DisposerRecord接口实现类，一起传入进去，进行注册。  </p>
<p>Disposer类会唤起“Java2D Disposer”线程，该线程会扫描已注册的这些对象是否要被回收了，如果是，则调用该对象对应的DisposerRecord实现类里面的dispose方法。</p>
<p>Disposer实际上不限于在awt应用场景，只是awt里面的很多组件需要访问很多操作系统资源，所以，这些组件在被回收时，需要先释放这些资源。</p>
<h3 id="InsttoolCacheScheduler-QuartzSchedulerThread"><a href="#InsttoolCacheScheduler-QuartzSchedulerThread" class="headerlink" title="InsttoolCacheScheduler_QuartzSchedulerThread"></a>InsttoolCacheScheduler_QuartzSchedulerThread</h3><p>Quartz</p>
<p>InsttoolCacheScheduler_QuartzSchedulerThread是Quartz的主线程，它主要负责实时的获取下一个时间点要触发的触发器，然后执行触发器相关联的作业 。 </p>
<p>原理大致如下：</p>
<p>   Spring和Quartz结合使用的场景下，Spring IOC容器初始化时会创建并初始化Quartz线程池（TreadPool），并启动它。刚启动时线程池中每个线程都处于等待状态，等待外界给他分配Runnable（持有作业对象的线程）。</p>
<p>   继而接着初始化并启动Quartz的主线程</p>
<p>（InsttoolCacheScheduler_QuartzSchedulerThread），该线程自启动后就会处于等待状态。等待外界给出工作信号之后，该主线程的run方法才实质上开始工作。run中会获取JobStore中下一次要触发的作业，拿到之后会一直等待到该作业的真正触发时间，然后将该作业包装成一个JobRunShell对象（该对象实现了Runnable接口，其实看是上面TreadPool中等待外界分配给他的Runnable），然后将刚创建的JobRunShell交给线程池，由线程池负责执行作业。</p>
<p>线程池收到Runnable后，从线程池一个线程启动Runnable，反射调用JobRunShell中的run方法，run方法执行完成之后， TreadPool将该线程回收至空闲线程中。</p>
<h3 id="InsttoolCacheScheduler-Worker-2"><a href="#InsttoolCacheScheduler-Worker-2" class="headerlink" title="InsttoolCacheScheduler_Worker-2"></a>InsttoolCacheScheduler_Worker-2</h3><p>Quartz</p>
<p>InsttoolCacheScheduler_Worker-2线程就是ThreadPool线程的一个简单实现，它主要负责分配线程资源去执行</p>
<p>InsttoolCacheScheduler_QuartzSchedulerThread线程交给它的调度任务（也就是JobRunShell）。</p>
<p>JBossLifeThread</p>
<p>Jboss</p>
<p>Jboss主线程启动成功，应用程序部署完毕之后将JBossLifeThread线程实例化并且start，JBossLifeThread线程启动成功之后就处于等待状态，以保持Jboss Java进程处于存活中。  所得比较通俗一点，就是Jboss启动流程执行完毕之后，为什么没有结束？ 就是因为有这个线程hold主了它。</p>
<h3 id="JDWP-Event-Helper-Thread"><a href="#JDWP-Event-Helper-Thread" class="headerlink" title="JDWP Event Helper Thread"></a>JDWP Event Helper Thread</h3><p>JVM</p>
<p>JDWP是通讯交互协议，它定义了调试器和被调试程序之间传递信息的格式。它详细完整地定义了请求命令、回应数据和错误代码，保证了前端和后端的JVMTI和JDI的通信通畅。  该线程主要负责将JDI事件映射成JVMTI信号，以达到调试过程中操作JVM的目的。   </p>
<h3 id="JDWP-Transport-Listener"><a href="#JDWP-Transport-Listener" class="headerlink" title="JDWP Transport Listener:"></a>JDWP Transport Listener:</h3><p> dt_socket</p>
<p>JVM</p>
<p>该线程是一个Java Debugger的监听器线程，负责受理客户端的debug请求。 通常我们习惯将它的监听端口设置为8787。</p>
<h3 id="Low-Memory-Detector"><a href="#Low-Memory-Detector" class="headerlink" title="Low Memory Detector"></a>Low Memory Detector</h3><p>JVM</p>
<p>这个线程是负责对可使用内存进行检测，如果发现可用内存低，分配新的内存空间。</p>
<h3 id="process-reaper"><a href="#process-reaper" class="headerlink" title="process reaper"></a>process reaper</h3><p>JVM</p>
<p>该线程负责去执行一个 OS 命令行的操作。</p>
<h3 id="Reference-Handler"><a href="#Reference-Handler" class="headerlink" title="Reference Handler"></a>Reference Handler</h3><p>JVM</p>
<p>JVM在创建main线程后就创建Reference Handler线程，其优先级最高，为10，它主要用于处理引用对象本身（软引用、弱引用、虚引用）的垃圾回收问题 。</p>
<h3 id="Surrogate-Locker-Thread-CMS"><a href="#Surrogate-Locker-Thread-CMS" class="headerlink" title="Surrogate Locker Thread (CMS)"></a>Surrogate Locker Thread (CMS)</h3><p>JVM</p>
<p>这个线程主要用于配合CMS垃圾回收器使用，它是一个守护线程，其主要负责处理GC过程中，Java层的Reference（指软引用、弱引用等等）与jvm 内部层面的对象状态同步。 这里对它们的实现稍微做一下介绍：这里拿 WeakHashMap做例子，将一些关键点先列出来（我们后面会将这些关键点全部串起来）：</p>
<p>1.我们知道HashMap用Entry[]数组来存储数据的，WeakHashMap也不例外, 内部有一个Entry[]数组。</p>
<ol start="2">
<li>WeakHashMap的Entry比较特殊，它的继承体系结构为</li>
</ol>
<p>Entry-&gt;WeakReference-&gt;Reference 。</p>
<p>3.Reference 里面有一个全局锁对象：Lock，</p>
<p>它也被称为pending_lock.注意：它是静态对象。</p>
<ol start="4">
<li><p>Reference  里面有一个静态变量：pending。</p>
</li>
<li><p>Reference里面有一个静态内部类：ReferenceHandler的线程，它在static块里面被初始化并且启动，启动完成后处于wait状态，它在一个Lock同步锁模块中等待。</p>
</li>
</ol>
<p>6.另外，WeakHashMap里面还实例化了一个ReferenceQueue列队，这个列队的作用，后面会提到。</p>
<p>7.上面关键点就介绍完毕了，下面我们把他们串起来。</p>
<p>假设，WeakHashMap对象里面已经保存了很多对象的引用。</p>
<p>JVM 在进行CMS GC的时候，会创建一个ConcurrentMarkSweepThread（简称CMST）线程去进行GC，ConcurrentMarkSweepThread线程被创建的同时会创建一个SurrogateLockerThread（简称SLT）线程并且启动它，SLT启动之后，处于等待阶段。CMST开始GC时，会发一个消息给SLT让它去获取Java层Reference对象的全局锁：Lock。 直到CMS GC完毕之后，JVM 会将WeakHashMap中所有被回收的对象所属的WeakReference容器对象放入到Reference 的pending属性当中（每次GC完毕之后，pending属性基本上都不会为null了），然后通知SLT释放并且notify全局锁:Lock。此时激活了ReferenceHandler线程的run方法，使其脱离wait状态，开始工作了。ReferenceHandler这个线程会将pending中的所有WeakReference对象都移动到它们各自的列队当中，比如当前这个WeakReference属于某个WeakHashMap对象，那么它就会被放入相应的ReferenceQueue列队里面（该列队是链表结构）。 当我们下次从WeakHashMap对象里面get、put数据或者调用size方法的时候，WeakHashMap就会将ReferenceQueue列队中的WeakReference依依poll出来去和Entry[]数据做比较，如果发现相同的，则说明这个Entry所保存的对象已经被GC掉了，那么将Entry[]内的Entry对象剔除掉。</p>
<h3 id="taskObjectTimerFactory"><a href="#taskObjectTimerFactory" class="headerlink" title="taskObjectTimerFactory"></a>taskObjectTimerFactory</h3><p>JVM</p>
<p>顾名思义，该线程就是用来执行任务的。 当我们把一个认为交给Timer对象，并且告诉它执行时间，周期时间后，Timer就会将该任务放入任务列队，并且通知taskObjectTimerFactory线程去处理任务，taskObjectTimerFactory线程会将状态为取消的任务从任务列队中移除，如果任务是非重复执行类型的，则在执行完该任务后，将它从任务列队中移除，如果该任务是需要重复执行的，则计算出它下一次执行的时间点。</p>
<h3 id="VM-Periodic-Task-Thread"><a href="#VM-Periodic-Task-Thread" class="headerlink" title="VM Periodic Task Thread"></a>VM Periodic Task Thread</h3><p>JVM</p>
<p>该线程是JVM周期性任务调度的线程，它由WatcherThread创建，是一个单例对象。 该线程在JVM内使用得比较频繁，比如：定期的内存监控、JVM运行状况监控，还有我们经常需要去执行一些jstat 这类命令查看gc的情况，如下：</p>
<p>jstat -gcutil 23483 250 7   这个命令告诉jvm在控制台打印PID为：23483的gc情况，间隔250毫秒打印一次，一共打印7次。</p>
<h3 id="VM-Thread"><a href="#VM-Thread" class="headerlink" title="VM Thread"></a>VM Thread</h3><p>JVM</p>
<p>这个线程就比较牛b了，是jvm里面的线程母体，根据hotspot源码（vmThread.hpp）里面的注释，它是一个单例的对象（最原始的线程）会产生或触发所有其他的线程，这个单个的VM线程是会被其他线程所使用来做一些VM操作（如，清扫垃圾等）。</p>
<p>在 VMThread 的结构体里有一个VMOperationQueue列队，所有的VM线程操作(vm_operation)都会被保存到这个列队当中，VMThread 本身就是一个线程，它的线程负责执行一个自轮询的loop函数(具体可以参考：</p>
<p>VMThread.cpp里面的</p>
<p>void VMThread::loop()) ，该loop函数从VMOperationQueue列队中按照优先级取出当前需要执行的操作对象(VM_Operation)，</p>
<p>并且调用VM_Operation-&gt;evaluate函数去执行该操作类型本身的业务逻辑。</p>
<p>ps：VM操作类型被定义在</p>
<p>vm_operations.hpp文件内，列举几个：ThreadStop、ThreadDump、PrintThreads、GenCollectFull、GenCollectFullConcurrent、CMS_Initial_Mark、CMS_Final_Remark…..</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
        <tag>JStack</tag>
      </tags>
  </entry>
  <entry>
    <title>使用CountLatch实现异步等待</title>
    <url>/Java/multithread/10.async-wait-with-latch/</url>
    <content><![CDATA[<h1 id="10-async-wait-with-latch"><a href="#10-async-wait-with-latch" class="headerlink" title="10.async-wait-with-latch"></a>10.async-wait-with-latch</h1><p>利用CountLatch异步等待</p>
<blockquote>
<p>摘自JavaFx源码</p>
<p>com.sun.javafx.application.LauncherImpl#launchApplication(java.lang.Class&lt;? extends javafx.application.Application&gt;, java.lang.Class&lt;? extends javafx.application.Preloader&gt;, java.lang.String[])</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 接收异常</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> RuntimeException launchException = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> CountDownLatch launchLatch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line">Thread launcherThread = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        launchApplication1(appClass, preloaderClass, args);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RuntimeException rte) &#123;</span><br><span class="line">        launchException = rte;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">        launchException =</span><br><span class="line">            <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Application launch exception&quot;</span>, ex);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Error err) &#123;</span><br><span class="line">        launchException =</span><br><span class="line">            <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Application launch error&quot;</span>, err);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// countDown</span></span><br><span class="line">        launchLatch.countDown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">launcherThread.setName(<span class="string">&quot;JavaFX-Launcher&quot;</span>);</span><br><span class="line">launcherThread.start();</span><br><span class="line"><span class="comment">// 异步线程启动</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Wait for FX launcher thread to finish before returning to user</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    launchLatch.await();</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException ex) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Unexpected exception: &quot;</span>, ex);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (launchException != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> launchException;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
        <tag>CountLatch</tag>
      </tags>
  </entry>
  <entry>
    <title>使用CycleBarrier实现异步等待</title>
    <url>/Java/multithread/11.async-wait-with-cycleBarrier/</url>
    <content><![CDATA[<ul>
<li>可循环利用的屏障  </li>
<li>每个线程执行时，都会碰到一个屏障，直到所有线程执行结束，然后屏障便会打开，使所有线程继续往下执行</li>
</ul>
<p><code>CyclicBarrier(int parties)</code>和<code>CyclicBarrier(int parties, Runnable barrierAction)</code></p>
<ul>
<li>前者只需要声明需要拦截的线程数即可</li>
<li>后者还需要定义一个等待所有线程到达屏障优先执行的Runnable对象</li>
</ul>
<p>实现原理：</p>
<p>在CyclicBarrier的内部定义了一个Lock对象，每当一个线程调用await方法时，将拦截的线程数减1，然后判断剩余拦截数是否为初始值parties，如果不是，进入Lock对象的条件队列等待。如果是，执行barrierAction对象的Runnable方法，然后将锁的条件队列中的所有线程放入锁等待队列中，这些线程会依次的获取锁、释放锁。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
        <tag>CountLatch</tag>
      </tags>
  </entry>
  <entry>
    <title>Guava并发库</title>
    <url>/Java/multithread/12.google-guava-concurrency/</url>
    <content><![CDATA[<h1 id="disruptor"><a href="#disruptor" class="headerlink" title="disruptor"></a>disruptor</h1>]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>Java BlockingQueue</title>
    <url>/Java/multithread/13.BlockingQueue/</url>
    <content><![CDATA[<h1 id="1-BlockingQueue-简介"><a href="#1-BlockingQueue-简介" class="headerlink" title="1. BlockingQueue 简介"></a>1. BlockingQueue 简介</h1><p>在实际编程中，会经常使用到 JDK 中 Collection 集合框架中的各种容器类如实现 List,Map,Queue 接口的容器类，但是这些容器类基本上不是线程安全的，除了使用 Collections 可以将其转换为线程安全的容器，Doug Lea 大师为我们都准备了对应的线程安全的容器，如实现 List 接口的 CopyOnWriteArrayList（<a href="https://juejin.im/post/5aeeb55f5188256715478c21">关于 CopyOnWriteArrayList 可以看这篇文章</a>），实现 Map 接口的 ConcurrentHashMap（<a href="https://juejin.im/post/5aeeaba8f265da0b9d781d16">关于 ConcurrentHashMap 可以看这篇文章</a>），实现 Queue 接口的 ConcurrentLinkedQueue（<a href="https://juejin.im/post/5aeeae756fb9a07ab11112af">关于 ConcurrentLinkedQueue 可以看这篇文章</a>）。</p>
<p>最常用的”<strong>生产者-消费者</strong>“问题中，队列通常被视作线程间操作的数据容器，这样，可以对各个模块的业务功能进行解耦，生产者将“生产”出来的数据放置在数据容器中，而消费者仅仅只需要在“数据容器”中进行获取数据即可，这样生产者线程和消费者线程就能够进行解耦，只专注于自己的业务功能即可。阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是 BlockingQueue 提供了可阻塞的插入和移除的方法。<strong>当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。</strong></p>
<h1 id="2-基本操作"><a href="#2-基本操作" class="headerlink" title="2. 基本操作"></a>2. 基本操作</h1><p>BlockingQueue 基本操作总结如下（此图来源于 JAVA API 文档）：</p>
<table>
<thead>
<tr>
<th></th>
<th>Throws exception</th>
<th>Special value</th>
<th>Blocks</th>
<th>Times out</th>
</tr>
</thead>
<tbody><tr>
<td>Insert</td>
<td>add(e)</td>
<td>offser(e)</td>
<td>put(e)</td>
<td>offser(e,time,unit)</td>
</tr>
<tr>
<td>Remove</td>
<td>remove()</td>
<td>poll()</td>
<td>take()</td>
<td>poll(time,unit)</td>
</tr>
<tr>
<td>Examine</td>
<td>element()</td>
<td>peek()</td>
<td>-</td>
<td>-</td>
</tr>
</tbody></table>
<p>BlockingQueue 继承于 Queue 接口，因此，对数据元素的基本操作有：</p>
<blockquote>
<p>插入元素</p>
</blockquote>
<ol>
<li><code>add(E e)</code> ：往队列插入数据，当队列满时，插入元素时会抛出 <code>IllegalStateException</code> 异常；</li>
<li><code>offer(E e)</code>：当往队列插入数据时，插入成功返回<code>true</code>，否则则返回<code>false</code>。当队列满时不会抛出异常；</li>
</ol>
<blockquote>
<p>删除元素</p>
</blockquote>
<ol>
<li><code>remove(Object o)</code>：从队列中删除数据，成功则返回<code>true</code>，否则为<code>false</code></li>
<li><code>poll()</code>：删除数据，当队列为空时，返回 null；</li>
</ol>
<blockquote>
<p>查看元素</p>
</blockquote>
<ol>
<li><code>element()</code>：获取队头元素，如果队列为空时则抛出 <code>NoSuchElementException</code> 异常；</li>
<li><code>peek()</code>：获取队头元素，如果队列为空则抛出 <code>NoSuchElementException</code> 异常</li>
</ol>
<p>BlockingQueue 具有的特殊操作：</p>
<blockquote>
<p>插入数据：</p>
</blockquote>
<ol>
<li><code>put(E e)</code>：当阻塞队列容量已经满时，往阻塞队列插入数据的线程会被阻塞，直至阻塞队列已经有空余的容量可供使用；</li>
<li><code>offer(E e, long timeout, TimeUnit unit)</code>：若阻塞队列已经满时，同样会阻塞插入数据的线程，直至阻塞队列已经有空余的地方，与 <code>put</code> 方法不同的是，该方法会有一个超时时间，若超过当前给定的超时时间，插入数据的线程会退出；</li>
</ol>
<blockquote>
<p>删除数据</p>
</blockquote>
<ol>
<li><code>take()</code>：当阻塞队列为空时，获取队头数据的线程会被阻塞；</li>
<li><code>poll(long timeout, TimeUnit unit)</code>：当阻塞队列为空时，获取数据的线程会被阻塞，另外，如果被阻塞的线程超过了给定的时长，该线程会退出</li>
</ol>
<h1 id="3-常用的-BlockingQueue"><a href="#3-常用的-BlockingQueue" class="headerlink" title="3. 常用的 BlockingQueue"></a>3. 常用的 BlockingQueue</h1><p>实现 BlockingQueue 接口的有<code>ArrayBlockingQueue</code>, <code>DelayQueue</code>, <code>LinkedBlockingDeque</code>, <code>LinkedBlockingQueue</code>, <code>LinkedTransferQueue</code>, <code>PriorityBlockingQueue</code>, <code>SynchronousQueue</code>，而这几种常见的阻塞队列也是在实际编程中会常用的，下面对这几种常见的阻塞队列进行说明：</p>
<blockquote>
<p>1.<code>ArrayBlockingQueue</code></p>
</blockquote>
<p>**<code>ArrayBlockingQueue</code>**是由数组实现的有界阻塞队列。该队列命令元素 FIFO（先进先出）。因此，对头元素时队列中存在时间最长的数据元素，而对尾数据则是当前队列最新的数据元素。<code>ArrayBlockingQueue</code> 可作为“有界数据缓冲区”，生产者插入数据到队列容器中，并由消费者提取。<code>ArrayBlockingQueue</code> 一旦创建，容量不能改变。</p>
<p>当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。</p>
<p><code>ArrayBlockingQueue</code> 默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 <code>ArrayBlockingQueue</code>。而非公平性则是指访问 <code>ArrayBlockingQueue</code> 的顺序不是遵守严格的时间顺序，有可能存在，一旦 <code>ArrayBlockingQueue</code> 可以被访问时，长时间阻塞的线程依然无法访问到 <code>ArrayBlockingQueue</code>。<strong>如果保证公平性，通常会降低吞吐量</strong>。如果需要获得公平性的 <code>ArrayBlockingQueue</code>，可采用如下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> ArrayBlockingQueue&lt;Integer&gt; blockingQueue = <span class="keyword">new</span> ArrayBlockingQueue&lt;Integer&gt;(<span class="number">10</span>,<span class="keyword">true</span>);</span><br></pre></td></tr></table></figure>
<p>关于 <code>ArrayBlockingQueue</code> 的实现原理，可以<a href="https://juejin.im/post/5aeebdb26fb9a07aa83ea17e">看这篇文章</a>。</p>
<blockquote>
<p>2.<code>LinkedBlockingQueue</code></p>
</blockquote>
<p><code>LinkedBlockingQueue</code> 是用链表实现的有界阻塞队列，同样满足 FIFO 的特性，与 <code>ArrayBlockingQueue</code> 相比起来具有更高的吞吐量，为了防止 <code>LinkedBlockingQueue</code> 容量迅速增，损耗大量内存。通常在创建 <code>LinkedBlockingQueue</code> 对象时，会指定其大小，如果未指定，容量等于 <code>Integer.MAX_VALUE</code></p>
<blockquote>
<p>3.<code>PriorityBlockingQueue</code></p>
</blockquote>
<p><code>PriorityBlockingQueue</code> 是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 <code>compareTo()</code>方法来指定元素排序规则，或者初始化时通过构造器参数 <code>Comparator</code> 来指定排序规则。</p>
<blockquote>
<p>4.<code>SynchronousQueue</code></p>
</blockquote>
<p><code>SynchronousQueue</code> 每个插入操作必须等待另一个线程进行相应的删除操作，因此，<code>SynchronousQueue</code> 实际上没有存储任何数据元素，因为只有线程在删除数据时，其他线程才能插入数据，同样的，如果当前有线程在插入数据时，线程才能删除数据。<code>SynchronousQueue</code> 也可以通过构造器参数来为其指定公平性。</p>
<blockquote>
<p>5.<code>LinkedTransferQueue</code></p>
</blockquote>
<p><code>LinkedTransferQueue</code> 是一个由链表数据结构构成的无界阻塞队列，由于该队列实现了 <code>TransferQueue</code> 接口，与其他阻塞队列相比主要有以下不同的方法：</p>
<p><strong><code>transfer(E e)</code></strong> 如果当前有线程（消费者）正在调用 <code>take()</code>方法或者可延时的 <code>poll()</code>方法进行消费数据时，生产者线程可以调用 <code>transfer</code> 方法将数据传递给消费者线程。如果当前没有消费者线程的话，生产者线程就会将数据插入到队尾，直到有消费者能够进行消费才能退出；</p>
<p><strong><code>tryTransfer(E e)</code></strong> <code>tryTransfer</code> 方法如果当前有消费者线程（调用 <code>take</code> 方法或者具有超时特性的 <code>poll</code> 方法）正在消费数据的话，该方法可以将数据立即传送给消费者线程，如果当前没有消费者线程消费数据的话，就立即返回<code>false</code>。因此，与 <code>transfer</code> 方法相比，<code>transfer</code> 方法是必须等到有消费者线程消费数据时，生产者线程才能够返回。而 <code>tryTransfer</code> 方法能够立即返回结果退出。</p>
<p><strong><code>tryTransfer(E e,long timeout,imeUnit unit)</code></strong><br>与 <code>transfer</code> 基本功能一样，只是增加了超时特性，如果数据才规定的超时时间内没有消费者进行消费的话，就返回<code>false</code>。</p>
<blockquote>
<p>6.<code>LinkedBlockingDeque</code></p>
</blockquote>
<p><code>LinkedBlockingDeque</code> 是基于链表数据结构的有界阻塞双端队列，如果在创建对象时为指定大小时，其默认大小为 <code>Integer.MAX_VALUE</code>。与 <code>LinkedBlockingQueue</code> 相比，主要的不同点在于，<code>LinkedBlockingDeque</code> 具有双端队列的特性。<code>LinkedBlockingDeque</code> 基本操作如下图所示（来源于 java 文档）</p>
<p><img src="_v_images/20200721125024527_1529598628" alt="`LinkedBlockingDeque`的基本操作.png"></p>
<p><code>LinkedBlockingDeque</code>的基本操作.png</p>
<p>如上图所示，<code>LinkedBlockingDeque</code> 的基本操作可以分为四种类型：</p>
<p>1.特殊情况，抛出异常；<br>2.特殊情况，返回特殊值如 null 或者 false；<br>3.当线程不满足操作条件时，线程会被阻塞直至条件满足；<br>4. 操作具有超时特性。</p>
<p>另外，<code>LinkedBlockingDeque</code> 实现了 BlockingDueue 接口<br>而 <code>LinkedBlockingQueue</code> 实现的是 BlockingQueue，</p>
<p>这两个接口的主要区别如下图所示（来源于 java 文档）：</p>
<p><img src="_v_images/20200721125024023_871236957" alt="BlockingQueue和BlockingDeque的区别.png"></p>
<p>BlockingQueue和BlockingDeque的区别</p>
<p>从上图可以看出，两个接口的功能是可以等价使用的，比如 BlockingQueue 的 add 方法和 BlockingDeque 的 addLast 方法的功能是一样的。</p>
<blockquote>
<p>7.<code>DelayQueue</code></p>
</blockquote>
<p><code>DelayQueue</code> 是一个存放实现 <code>Delayed</code> 接口的数据的无界阻塞队列，只有当数据对象的延时时间达到时才能插入到队列进行存储。如果当前所有的数据都还没有达到创建时所指定的延时期，则队列没有队头，并且线程通过 <code>poll</code> 等方法获取数据元素则返回 <code>null</code>。所谓数据延时期满时，则是通过 <code>Delayed</code> 接口的<code>getDelay(TimeUnit.NANOSECONDS)</code>来进行判定，如果该方法返回的是小于等于 0 则说明该数据元素的延时期已满。</p>
<h1 id="ArrayBlockingQueue-实现原理"><a href="#ArrayBlockingQueue-实现原理" class="headerlink" title="ArrayBlockingQueue 实现原理"></a>ArrayBlockingQueue 实现原理</h1><p>阻塞队列最核心的功能是，能够可阻塞式的插入和删除队列元素。当前队列为空时，会阻塞消费数据的线程，直至队列非空时，通知被阻塞的线程；当队列满时，会阻塞插入数据的线程，直至队列未满时，通知插入数据的线程（生产者线程）。那么，多线程中消息通知机制最常用的是 lock 的 condition 机制，关于 condition 可以<a href="https://juejin.im/post/5aeea5e951882506a36c67f0">看这篇文章的详细介绍</a>。那么 ArrayBlockingQueue 的实现是不是也会采用 Condition 的通知机制呢？下面来看看。</p>
<h2 id="2-1-ArrayBlockingQueue-的主要属性"><a href="#2-1-ArrayBlockingQueue-的主要属性" class="headerlink" title="2.1 ArrayBlockingQueue 的主要属性"></a><strong>2.1 ArrayBlockingQueue 的主要属性</strong></h2><p>ArrayBlockingQueue 的主要属性如下:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** The queued items */</span></span><br><span class="line"><span class="keyword">final</span> Object[] items;</span><br><span class="line"><span class="comment">/** items index for next take, poll, peek or remove */</span></span><br><span class="line"><span class="keyword">int</span> takeIndex;</span><br><span class="line"><span class="comment">/** items index for next put, offer, or add */</span></span><br><span class="line"><span class="keyword">int</span> putIndex;</span><br><span class="line"><span class="comment">/** Number of elements in the queue */</span></span><br><span class="line"><span class="keyword">int</span> count;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Concurrency control uses the classic two-condition algorithm</span></span><br><span class="line"><span class="comment">found in any textbook.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/** Main lock guarding all access */</span></span><br><span class="line"><span class="keyword">final</span> ReentrantLock lock;</span><br><span class="line"><span class="comment">/** Condition for waiting takes */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Condition notEmpty;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>从源码中可以看出 ArrayBlockingQueue 内部是采用数组进行数据存储的（<code>属性items</code>），为了保证线程安全，采用的是<code>ReentrantLock lock</code>，为了保证可阻塞式的插入删除数据利用的是 Condition，当获取数据的消费者线程被阻塞时会将该线程放置到 notEmpty 等待队列中，当插入数据的生产者线程被阻塞时，会将该线程放置到 notFull 等待队列中。而 notEmpty 和 notFull 等中要属性在构造方法中进行创建：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayBlockingQueue</span><span class="params">(<span class="keyword">int</span> capacity, <span class="keyword">boolean</span> fair)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (capacity &lt;= <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">    <span class="keyword">this</span>.items = <span class="keyword">new</span> Object[capacity];</span><br><span class="line">    lock = <span class="keyword">new</span> ReentrantLock(fair);</span><br><span class="line">    notEmpty = lock.newCondition();</span><br><span class="line">    notFull =  lock.newCondition();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>接下来，主要看看可阻塞式的 put 和 take 方法是怎样实现的。</p>
<h2 id="2-2-put-方法详解"><a href="#2-2-put-方法详解" class="headerlink" title="2.2 put 方法详解"></a><strong>2.2 put 方法详解</strong></h2><p><code>put(E e)</code>方法源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(E e)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    checkNotNull(e);</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">    lock.lockInterruptibly();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//如果当前队列已满，将线程移入到notFull等待队列中</span></span><br><span class="line">        <span class="keyword">while</span> (count == items.length)</span><br><span class="line">            notFull.await();</span><br><span class="line">     <span class="comment">//满足插入数据的要求，直接进行入队操作</span></span><br><span class="line">        enqueue(e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>
<p>该方法的逻辑很简单，当队列已满时（<code>count == items.length</code>）将线程移入到 notFull 等待队列中，如果当前满足插入数据的条件，就可以直接调用<code>enqueue(e)</code>插入数据元素。enqueue 方法源码为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">enqueue</span><span class="params">(E x)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// assert lock.getHoldCount() == 1;</span></span><br><span class="line">    <span class="comment">// assert items[putIndex] == null;</span></span><br><span class="line">    <span class="keyword">final</span> Object[] items = <span class="keyword">this</span>.items;</span><br><span class="line">   <span class="comment">//插入数据</span></span><br><span class="line">    items[putIndex] = x;</span><br><span class="line">    <span class="keyword">if</span> (++putIndex == items.length)</span><br><span class="line">        putIndex = <span class="number">0</span>;</span><br><span class="line">    count++;</span><br><span class="line">   <span class="comment">//通知消费者线程，当前队列中有数据可供消费</span></span><br><span class="line">    notEmpty.signal();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>enqueue 方法的逻辑同样也很简单，先完成插入数据，即往数组中添加数据（<code>items[putIndex] = x</code>），然后通知被阻塞的消费者线程，当前队列中有数据可供消费（<code>notEmpty.signal()</code>）。</p>
<h2 id="2-3-take-方法详解"><a href="#2-3-take-方法详解" class="headerlink" title="2.3 take 方法详解"></a><strong>2.3 take 方法详解</strong></h2><p>take 方法源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">take</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;</span><br><span class="line">    lock.lockInterruptibly();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="comment">//如果队列为空，没有数据，将消费者线程移入等待队列中</span></span><br><span class="line">        <span class="keyword">while</span> (count == <span class="number">0</span>)</span><br><span class="line">            notEmpty.await();</span><br><span class="line">		<span class="comment">//获取数据</span></span><br><span class="line">        <span class="keyword">return</span> dequeue();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>take 方法也主要做了两步：1. 如果当前队列为空的话，则将获取数据的消费者线程移入到等待队列中；2. 若队列不为空则获取数据，即完成出队操作<code>dequeue</code>。dequeue 方法源码为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> E <span class="title">dequeue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// assert lock.getHoldCount() == 1;</span></span><br><span class="line">    <span class="comment">// assert items[takeIndex] != null;</span></span><br><span class="line">    <span class="keyword">final</span> Object[] items = <span class="keyword">this</span>.items;</span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">	<span class="comment">//获取数据</span></span><br><span class="line">    E x = (E) items[takeIndex];</span><br><span class="line">    items[takeIndex] = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (++takeIndex == items.length)</span><br><span class="line">        takeIndex = <span class="number">0</span>;</span><br><span class="line">    count--;</span><br><span class="line">    <span class="keyword">if</span> (itrs != <span class="keyword">null</span>)</span><br><span class="line">        itrs.elementDequeued();</span><br><span class="line">    <span class="comment">//通知被阻塞的生产者线程</span></span><br><span class="line">	notFull.signal();</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>dequeue 方法也主要做了两件事情：1. 获取队列中的数据，即获取数组中的数据元素（<code>(E) items[takeIndex]</code>）；2. 通知 notFull 等待队列中的线程，使其由等待队列移入到同步队列中，使其能够有机会获得 lock，并执行完成功退出。</p>
<p>从以上分析，可以看出 put 和 take 方法主要是通过 condition 的通知机制来完成可阻塞式的插入数据和获取数据。在理解 ArrayBlockingQueue 后再去理解 LinkedBlockingQueue 就很容易了。</p>
<h1 id="3-LinkedBlockingQueue-实现原理"><a href="#3-LinkedBlockingQueue-实现原理" class="headerlink" title="3. LinkedBlockingQueue 实现原理"></a>3. LinkedBlockingQueue 实现原理</h1><p>LinkedBlockingQueue 是用链表实现的有界阻塞队列，当构造对象时为指定队列大小时，队列默认大小为<code>Integer.MAX_VALUE</code>。从它的构造方法可以看出：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedBlockingQueue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(Integer.MAX_VALUE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-1-LinkedBlockingQueue-的主要属性"><a href="#3-1-LinkedBlockingQueue-的主要属性" class="headerlink" title="3.1 LinkedBlockingQueue 的主要属性"></a><strong>3.1 LinkedBlockingQueue 的主要属性</strong></h2><p>LinkedBlockingQueue 的主要属性有：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** Current number of elements */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger count = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Head of linked list.</span></span><br><span class="line"><span class="comment">Invariant: head.item == null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">transient</span> Node&lt;E&gt; head;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Tail of linked list.</span></span><br><span class="line"><span class="comment">Invariant: last.next == null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> Node&lt;E&gt; last;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Lock held by take, poll, etc */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock takeLock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line"><span class="comment">/** Wait queue for waiting takes */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Condition notEmpty = takeLock.newCondition();</span><br><span class="line"><span class="comment">/** Lock held by put, offer, etc */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock putLock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>
<p>可以看出与 ArrayBlockingQueue 主要的区别是，LinkedBlockingQueue 在插入数据和删除数据时分别是由两个不同的 lock（<code>takeLock</code>和<code>putLock</code>）来控制线程安全的，因此，也由这两个 lock 生成了两个对应的 condition（<code>notEmpty</code>和<code>notFull</code>）来实现可阻塞的插入和删除数据。并且，采用了链表的数据结构来实现队列，Node 结点的定义为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line">    E item;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * One of:</span></span><br><span class="line"><span class="comment"> * - the real successor Node</span></span><br><span class="line"><span class="comment"> * - this Node, meaning the successor is head.next</span></span><br><span class="line"><span class="comment"> * - null, meaning there is no successor (this is the last node)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Node&amp;lt;E&amp;gt; next;</span><br><span class="line"></span><br><span class="line">Node(E x) &#123; item = x; &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>接下来，我们也同样来看看 put 方法和 take 方法的实现。</p>
<h2 id="3-2-put-方法详解"><a href="#3-2-put-方法详解" class="headerlink" title="3.2 put 方法详解"></a><strong>3.2 put 方法详解</strong></h2><p>put 方法源码为:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(E e)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="comment">// Note: convention in all put/take/etc is to preset local var</span></span><br><span class="line">    <span class="comment">// holding count negative to indicate failure unless set.</span></span><br><span class="line">    <span class="keyword">int</span> c = -<span class="number">1</span>;</span><br><span class="line">    Node&lt;E&gt; node = <span class="keyword">new</span> Node&lt;E&gt;(e);</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock putLock = <span class="keyword">this</span>.putLock;</span><br><span class="line">    <span class="keyword">final</span> AtomicInteger count = <span class="keyword">this</span>.count;</span><br><span class="line">    putLock.lockInterruptibly();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Note that count is used in wait guard even though it is</span></span><br><span class="line"><span class="comment">         * not protected by lock. This works because count can</span></span><br><span class="line"><span class="comment">         * only decrease at this point (all other puts are shut</span></span><br><span class="line"><span class="comment">         * out by lock), and we (or some other waiting put) are</span></span><br><span class="line"><span class="comment">         * signalled if it ever changes from capacity. Similarly</span></span><br><span class="line"><span class="comment">         * for all other uses of count in other wait guards.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">		<span class="comment">//如果队列已满，则阻塞当前线程，将其移入等待队列</span></span><br><span class="line">        <span class="keyword">while</span> (count.get() == capacity) &#123;</span><br><span class="line">            notFull.await();</span><br><span class="line">        &#125;</span><br><span class="line">		<span class="comment">//入队操作，插入数据</span></span><br><span class="line">        enqueue(node);</span><br><span class="line">        c = count.getAndIncrement();</span><br><span class="line">		<span class="comment">//若队列满足插入数据的条件，则通知被阻塞的生产者线程</span></span><br><span class="line">        <span class="keyword">if</span> (c + <span class="number">1</span> &lt; capacity)</span><br><span class="line">            notFull.signal();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        putLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (c == <span class="number">0</span>)</span><br><span class="line">        signalNotEmpty();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>put 方法的逻辑也同样很容易理解，可见注释。基本上和 ArrayBlockingQueue 的 put 方法一样。take 方法的源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">take</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    E x;</span><br><span class="line">    <span class="keyword">int</span> c = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">final</span> AtomicInteger count = <span class="keyword">this</span>.count;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock takeLock = <span class="keyword">this</span>.takeLock;</span><br><span class="line">    takeLock.lockInterruptibly();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="comment">//当前队列为空，则阻塞当前线程，将其移入到等待队列中，直至满足条件</span></span><br><span class="line">        <span class="keyword">while</span> (count.get() == <span class="number">0</span>) &#123;</span><br><span class="line">            notEmpty.await();</span><br><span class="line">        &#125;</span><br><span class="line">		<span class="comment">//移除队头元素，获取数据</span></span><br><span class="line">        x = dequeue();</span><br><span class="line">        c = count.getAndDecrement();</span><br><span class="line">        <span class="comment">//如果当前满足移除元素的条件，则通知被阻塞的消费者线程</span></span><br><span class="line">		<span class="keyword">if</span> (c &gt; <span class="number">1</span>)</span><br><span class="line">            notEmpty.signal();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        takeLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (c == capacity)</span><br><span class="line">        signalNotFull();</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>take 方法的主要逻辑请见于注释，也很容易理解。</p>
<h1 id="4-ArrayBlockingQueue-与-LinkedBlockingQueue-的比较"><a href="#4-ArrayBlockingQueue-与-LinkedBlockingQueue-的比较" class="headerlink" title="4. ArrayBlockingQueue 与 LinkedBlockingQueue 的比较"></a>4. ArrayBlockingQueue 与 LinkedBlockingQueue 的比较</h1><p><strong>相同点</strong>：ArrayBlockingQueue 和 LinkedBlockingQueue 都是通过 condition 通知机制来实现可阻塞式插入和删除元素，并满足线程安全的特性；</p>
<p><strong>不同点</strong>：1. ArrayBlockingQueue 底层是采用的数组进行实现，而 LinkedBlockingQueue 则是采用链表数据结构；</p>
<ol start="2">
<li>ArrayBlockingQueue 插入和删除数据，只采用了一个 lock，而 LinkedBlockingQueue 则是在插入和删除分别采用了<code>putLock</code>和<code>takeLock</code>，这样可以降低线程由于线程无法获取到 lock 而进入 WAITING 状态的可能性，从而提高了线程并发执行的效率。</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程等待的N种打开方式(第一篇)</title>
    <url>/Java/multithread/31.multithreadWaitedSample01/</url>
    <content><![CDATA[<p>单核CPU就是”一根筋”，只是简单的一条一条的串行执行机器指令，且每个时钟周期内只执行一条指令，如果一个进程不间断的运行，那么就只能运行一个任务；</p>
<p>将CPU的运行时间划分成一个个的时间段，这就是时间片(time slice)，进程通过抢占时间片，以达到交替执行的效果，宏观上，多个任务同时运行，JVM正是采用抢占式调度的方式根据优先级来”有限”的控制线程的运行。</p>
<p>为了提高代码的执行效率，编译器会在编译时做指令重排等优化，这就造成了在多线程运行时，出现与单线程运行不一致的情况。再加上，为了优化多核执行效率，造成各个线程访问的变量值与内存主存的值不一致的情况，就出现<strong>内存可见性</strong>问题。</p>
<p>JMM通过内存屏障、CAS和mutex lock指令等手段，实现各种各样的锁，究竟Java提供了哪些方法可以实现线程的等待呢，接下来以一个样例场景打开”Java多线程等待的N中方式”。</p>
<h2 id="题目与约定"><a href="#题目与约定" class="headerlink" title="题目与约定"></a>题目与约定</h2><blockquote>
<p> 假设有A、B、C三个线程，C必须等待A和B都结束时才能运行，</p>
<p> 约定每个线程的耗时操作为方法<code>doWork(String threadName)</code></p>
</blockquote>
<p>接下来将以此样例分析实现方法和Java实现的原理：</p>
<ol>
<li>第一篇: monitor</li>
</ol>
<ul>
<li>Thread.join等待线程完成</li>
<li>Object.wait-notify等待唤醒</li>
<li>LockSupport</li>
</ul>
<ol start="2">
<li>第二篇: AQS</li>
</ol>
<ul>
<li>CountDownLatch</li>
<li>ReentrantLock</li>
<li>Semaphore</li>
<li>CyclicBarrier循环屏障</li>
</ul>
<ol start="3">
<li>第三篇: 队列</li>
</ol>
<ul>
<li>Future</li>
<li>BlockingDeque</li>
<li>ListenableFuture</li>
</ul>
<h2 id="Thread-Join等待线程完成"><a href="#Thread-Join等待线程完成" class="headerlink" title="Thread.Join等待线程完成"></a>Thread.Join等待线程完成</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">join</span><span class="params">(<span class="keyword">long</span> millis,<span class="keyword">int</span> nanos)</span> <span class="keyword">throws</span> InterruptedException</span></span><br></pre></td></tr></table></figure>
<p>等待最多<code>millis</code>毫秒+<code>nanos</code>纳秒等待完成完成，通过循环调用<code>this.wait</code>等待<code>this.isAlive</code>条件完成，当调用<code>this.notifyAll</code>方法时，此线程终止。建议应用程序不要在线程实例上使用<code>wait</code>、<code>notify</code>或<code>notifyAll</code>。</p>
<h3 id="解题"><a href="#解题" class="headerlink" title="解题"></a>解题</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Thread threadA = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;A&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">final</span> Thread threadB = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;B&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">final</span> Thread threadC = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    threadA.join(); <span class="comment">// 等待A结束</span></span><br><span class="line">    threadB.join(); <span class="comment">// 等待B结束</span></span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  doWork(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 启动A、B两个线程</span></span><br><span class="line">threadA.start();</span><br><span class="line">threadB.start();</span><br><span class="line"><span class="comment">// 启动C线程</span></span><br><span class="line">threadC.start();</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Thread A starting </span><br><span class="line">Thread B starting </span><br><span class="line">Thread B finished</span><br><span class="line">Thread A finished</span><br><span class="line">Thread C starting </span><br><span class="line">Thread C finished</span><br></pre></td></tr></table></figure>
<h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Thread</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">join</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        join(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">join</span><span class="params">(<span class="keyword">long</span> millis)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> base = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">long</span> now = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (millis &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;timeout value is negative&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (millis == <span class="number">0</span>) &#123; <span class="comment">// 0表示没有设置超时时间</span></span><br><span class="line">            <span class="keyword">while</span> (isAlive()) &#123;<span class="comment">//isAlive获取线程状态，无限等待直到previousThread线程结束</span></span><br><span class="line">                wait(<span class="number">0</span>); <span class="comment">//调用Object中的wait方法实现线程的阻塞</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">//阻塞直到超时</span></span><br><span class="line">            <span class="keyword">while</span> (isAlive()) &#123; </span><br><span class="line">                <span class="keyword">long</span> delay = millis - now;</span><br><span class="line">                <span class="keyword">if</span> (delay &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                wait(delay);</span><br><span class="line">                now = System.currentTimeMillis() - base;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 测试此线程是否存活，如果此线程started并且还没有死亡，则存活</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span>  &lt;code&gt;true&lt;/code&gt; 如果此线程存活;</span></span><br><span class="line"><span class="comment">     *          &lt;code&gt;false&lt;/code&gt; 否则.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">isAlive</span><span class="params">()</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;      </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Object</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 导致当前线程等待，直到另一个线程调用此对象的notify()方法或notifyAll()方法</span></span><br><span class="line"><span class="comment">     * 当前线程必须拥有此对象的监视器。当前线程释放此监视器的所有权，并等待，直到另一个线程通过调用notify方法或notifyAll方法唤通知等待此对象的监视器的线程唤醒。然后，线程等待，直到它可以重新获得监视器的所有权并继续执行</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">wait</span><span class="params">(<span class="keyword">long</span> timeout)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">JavaThread::exit</span><span class="params">(<span class="keyword">bool</span> destroy_vm, ExitType exit_type)</span> </span>&#123;</span><br><span class="line">  assert(<span class="keyword">this</span> == JavaThread::current(),  <span class="string">&quot;thread consistency check&quot;</span>);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 在线程对象上通知等待者。必须在线程上调用exit()之后执行此操作（如果该线程是守护线程组中的最后一个线程，则通知等待对象之前，线程组应设置已破坏的位）。</span></span><br><span class="line">  ensure_join(<span class="keyword">this</span>); </span><br><span class="line">  assert(!<span class="keyword">this</span>-&gt;has_pending_exception(), <span class="string">&quot;ensure_join should have cleared&quot;</span>);</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure>


<p><code>join</code>方法本质是调用的<code>Object</code>中的<code>wait</code>方法实现线程的阻塞，调用wait方法必须要获取锁，所以<code>join</code>方法是被<code>synchronized</code>修饰的，<code>synchronized</code>修饰在方法层面相当于<code>synchronized(this)</code>,<code>this</code>就是<code>previousThread</code>本身的实例，两次调用join的<code>previousThread</code>分别是A和B两个线程，此时<code>previousThread</code>线程对象的监视器也就只有一个C线程在等待，因此当<code>previousThread</code>执行完的时候，通过<code>notify</code>和<code>notifyAll</code>会立即唤醒(只有一个线程嘛)。</p>
<p>此例子中，有两把锁存在，分别等待<code>threadA</code>和<code>threadB</code>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">threadA.join(); <span class="comment">// 调用threadA.wait(),threadA运行完后,默认会唤醒threadA对象上等待的threadC</span></span><br><span class="line">threadB.join(); <span class="comment">// 调用threadB.wait(),threadB运行完后,默认会唤醒threadB对象上等待的threadC</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：建议调用<code>Thread.join</code>的时候，不要在线程实例上同时调用<code>wait</code>、<code>nofity</code>和<code>notifyAll</code>方法</p>
</blockquote>
<h2 id="Object-wait-notify等待唤醒"><a href="#Object-wait-notify等待唤醒" class="headerlink" title="Object.wait-notify等待唤醒"></a>Object.wait-notify等待唤醒</h2><p><code>wait-nofity</code>是Object中的等待唤醒组合，实现等待两个线程完成，可以使用一把锁，也可以使用两把锁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 一把锁的解法</span></span><br><span class="line"><span class="comment">// finishedCount是一个数组对象，可以通过这个对象实现C等待A和B完成，C循环扫描完成个数</span></span><br><span class="line"><span class="keyword">int</span>[] finishedCount = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">Thread aThread = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;A&quot;</span>);</span><br><span class="line">  <span class="keyword">synchronized</span> (finishedCount) &#123;</span><br><span class="line">    <span class="comment">// 完成一个，加一</span></span><br><span class="line">    finishedCount[<span class="number">0</span>]++;</span><br><span class="line">    <span class="comment">// 唤醒C</span></span><br><span class="line">    finishedCount.notify();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line">Thread bThread = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;B&quot;</span>);</span><br><span class="line">  <span class="keyword">synchronized</span> (finishedCount) &#123;</span><br><span class="line">    <span class="comment">// 完成一个，加一</span></span><br><span class="line">    finishedCount[<span class="number">0</span>]++;</span><br><span class="line">    <span class="comment">// 唤醒C</span></span><br><span class="line">    finishedCount.notify();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line">Thread cThread = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  <span class="comment">// 循环扫描完成个数，只到两个都完成</span></span><br><span class="line">  <span class="keyword">while</span> (finishedCount[<span class="number">0</span>] &lt; <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (finishedCount) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        finishedCount.wait();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  doWork(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line">aThread.start();</span><br><span class="line">bThread.start();</span><br><span class="line">cThread.start();</span><br></pre></td></tr></table></figure>
<p>C在对象<code>finishedCount</code>上等待，A和B完成时，首先把<code>finishedCount</code>加一，然后唤醒C</p>
<p>C被唤醒时，判断A和B已经完成（<code>finishedCount</code>是否为2），完成则开始执行C的任务</p>
<h3 id="Object-wait-notify实现原理"><a href="#Object-wait-notify实现原理" class="headerlink" title="Object.wait-notify实现原理"></a>Object.wait-notify实现原理</h3><p><img src="/Users/averyzhang/yun_sync/wiki-own/images/java/multithread/monitor/monitor_lock_diy.png"></p>
<p>在HotSpot虚拟机中，<code>monitor</code>采用<code>ObjectMonitor</code>实现。</p>
<p><code>ObjectMonitor</code>对象中有两个队列，都用来保存<code>ObjectWaiter</code>对象，分别是<code>WaitSet</code> 和 <code>EntrySet</code>。<code>_owner</code>用来指向获得ObjectMonitor对象的线程</p>
<p><code>ObjectWaiter</code>对象是双向链表结构，保存了<code>_thread</code>（当前线程）以及当前的状态<code>TState</code>等数据， 每个等待锁的线程都会被封装成<code>ObjectWaiter</code>对象。<br><code>_WaitSet</code> ：处于wait状态的线程，会被加入到wait set；</p>
<p><code>_EntrySet</code>：处于等待锁block状态的线程，会被加入到entry set；</p>
<h4 id="wait方法实现"><a href="#wait方法实现" class="headerlink" title="wait方法实现"></a>wait方法实现</h4><p><code>lock.wait()</code>方法最终通过<code>ObjectMonitor</code>的 <code>wait(jlong millis, bool interruptable, TRAPS)</code>实现</p>
<ol>
<li><p>将当前线程封装成<code>ObjectWaiter</code>对象node</p>
</li>
<li><p>通过<code>ObjectMonitor::AddWaiter</code>方法将node添加到<code>_WaitSet</code>列表中</p>
</li>
<li><p>通过<code>ObjectMonitor::exit</code>方法释放当前的<code>ObjectMonitor</code>对象，这样其它竞争线程就可以获取该<code>ObjectMonitor</code>对象</p>
</li>
<li><p>最终底层的<code>park</code>方法会挂起线程</p>
</li>
</ol>
<p><code>ObjectSynchorizer::wait</code>方法通过<code>Object</code>对象找到<code>ObjectMonitor</code>对象来调用方法 <code>ObjectMonitor::wait()</code>，通过调用<code>ObjectMonitor::AddWaiter()</code>可以把新建的<code>ObjectWaiter</code>对象，放入到<code>_WaitSet</code>队列的末尾，然后在<code>ObjectMonitor::exit</code>释放锁，接着通过执行<code>thread_ParkEvent-&gt;park</code>来挂起线程，也就是进行<code>wait</code>。</p>
<h4 id="notify方法实现"><a href="#notify方法实现" class="headerlink" title="notify方法实现"></a>notify方法实现</h4><p><code>lock.notify()</code>方法最终通过ObjectMonitor的<code>void notify(TRAPS)</code>实现：<br>1、如果当前<em>WaitSet为空，即没有正在等待的线程，则直接返回；<br>2、通过<code>ObjectMonitor::DequeueWaiter</code>方法，获取</em><code>WaitSet</code>列表中的第一个<code>ObjectWaiter</code>节点，实现也很简单。</p>
<blockquote>
<p>这里需要注意的是，在jdk的notify方法注释是随机唤醒一个线程，其实是第一个ObjectWaiter节点</p>
</blockquote>
<p>3、根据不同的策略，将取出来的<code>ObjectWaiter</code>节点，加入到<code>_EntryList</code>或则通过<code>Atomic::cmpxchg_ptr</code>指令进行自旋操作cxq，具体代码实现有点长，这里就不贴了，有兴趣的同学可以看objectMonitor::notify方法；</p>
<h4 id="notifyAll方法实现"><a href="#notifyAll方法实现" class="headerlink" title="notifyAll方法实现"></a>notifyAll方法实现</h4><p><code>lock.notifyAll()</code>方法最终通过<code>ObjectMonitor</code>的<code>void notifyAll(TRAPS)</code>实现：<br>通过<code>for</code>循环取出<code>_WaitSet</code>的<code>ObjectWaiter</code>节点，并根据不同策略，加入到<code>_EntryList</code>或则进行自旋操作。</p>
<p>从JVM的方法实现中，可以发现：<code>notify</code>和<code>notifyAll</code>并不会释放所占有的<code>ObjectMonitor</code>对象，其实真正释放<code>ObjectMonitor</code>对象的时间点是在执行<code>monitorexit</code>指令，一旦释放<code>ObjectMonitor</code>对象了，entry set中<code>ObjectWaiter</code>节点所保存的线程就可以开始竞争ObjectMonitor对象进行加锁操作了。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a href="https://docs.oracle.com/javase/8/docs/">https://docs.oracle.com/javase/8/docs/</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程等待的N种打开方式(2)</title>
    <url>/Java/multithread/32.multithreadWaitedSample02/</url>
    <content><![CDATA[<h2 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h2><h2 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h2><p><code>CountDownLatch</code> 的作用：当一个线程需要另外一个或多个线程完成后，再开始执行</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(<span class="number">2</span>); <span class="comment">//等待2次countdown</span></span><br><span class="line"><span class="keyword">final</span> Thread ta = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;A&quot;</span>);</span><br><span class="line">  countDownLatch.countDown();</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">final</span> Thread tb = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;B&quot;</span>);</span><br><span class="line">  countDownLatch.countDown();</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">final</span> Thread tc = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    countDownLatch.await();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (<span class="keyword">final</span> InterruptedException e1) &#123;</span><br><span class="line">    e1.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  doWork(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line">ta.start();</span><br><span class="line">tb.start();</span><br><span class="line">tc.start();</span><br></pre></td></tr></table></figure>
<h3 id="CountDownLatch实现原理"><a href="#CountDownLatch实现原理" class="headerlink" title="CountDownLatch实现原理"></a>CountDownLatch实现原理</h3><p><code>CountDownLatch</code>是通过<code>AQS</code>实现的。 <code>AQS</code> 全称 <code>AbstractQueuedSynchronizer</code>，是 <code>java.util.concurrent</code> 中提供的一种高效且可扩展的同步机制。它可以用来实现依赖 int 状态(<code>state</code>)的同步器，除了<code>CountDownLatch</code>，<code>ReentrantLock</code>、<code>Semaphore</code> 等功能实现都使用了它。</p>
<p>在调用 <code>awit()</code>和<code>countDown()</code>的时候，发生了几个关键的调用关系</p>
<p><img src="https://images2018.cnblogs.com/blog/273364/201806/273364-20180608074920780-931190535.png" alt="img"></p>
<p>首先在 <code>CountDownLatch</code> 类内部定义了一个 <code>Sync</code> 内部类，这个内部类就是继承自 <code>AbstractQueuedSynchronizer</code> 的，并且重写了方法 <code>tryAcquireShared</code>和<code>tryReleaseShared</code>。当调用 <code>awit()</code>方法时，<code>CountDownLatch</code> 会调用内部类<code>Sync</code> 的 <code>acquireSharedInterruptibly()</code> 方法，然后在这个方法中会调用 <code>tryAcquireShared</code> 方法，这个方法就是 <code>CountDownLatch</code> 的内部类 <code>Sync</code> 里重写的 <code>AbstractQueuedSynchronizer</code> 的方法。调用 <code>countDown()</code> 方法同理。</p>
<h4 id="AQS的使用方法"><a href="#AQS的使用方法" class="headerlink" title="AQS的使用方法"></a>AQS的使用方法</h4><p>使用 <code>AbstractQueuedSynchronizer</code> 的标准化方式，大致分为两步：</p>
<ol>
<li><p>内部持有继承自 <code>AbstractQueuedSynchronizer</code> 的对象 <code>Sync</code>；</p>
</li>
<li><p>并在 <code>Sync</code> 内重写 <code>AbstractQueuedSynchronizer</code> 的<code>protected</code> 部分或全部方法，这些方法包括如下几个：</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">tryAcquire</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">tryRelease</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">tryAcquireShared</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">tryReleaseShared</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">isHeldExclusively</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用者可以通过重写这些方法，加入自己的判断逻辑，例如 <code>CountDownLatch</code> 在 <code>tryAcquireShared</code>中加入了判断，判断 <code>state</code> 是否不为0，如果不为0，才符合调用条件。</p>
<ul>
<li><p><code>tryAcquire</code>和<code>tryRelease</code>是对应的，前者是独占模式获取，后者是独占模式释放。</p>
</li>
<li><p><code>tryAcquireShared</code>和<code>tryReleaseShared</code>是对应的，前者是共享模式获取，后者是共享模式释放。</p>
<p><code>CountDownLatch</code> 重写的方法 <code>tryAcquireShared</code> 实现如下：</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">tryAcquireShared</span><span class="params">(<span class="keyword">int</span> acquires)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (getState() == <span class="number">0</span>) ? <span class="number">1</span> : -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>判断 <code>state</code> 值是否为0，为0 返回1，否则返回 -1。<code>state</code> 值是 <code>AbstractQueuedSynchronizer</code> 类中的一个 <code>volatile</code> 变量。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state;</span><br></pre></td></tr></table></figure>
<p>在 <code>CountDownLatch</code> 中这个 <code>state</code> 值就是计数器，在调用 <code>await</code> 方法的时候，将值赋给 <code>state</code> 。</p>
<h2 id="等待线程入队"><a href="#等待线程入队" class="headerlink" title="等待线程入队"></a><strong>等待线程入队</strong></h2><p>调用 <code>await()</code> 方法时，先去获取 <code>state</code> 的值，当计数器不为0的时候，说明还有需要等待的线程在运行，则调用 <code>doAcquireSharedInterruptibly</code> 方法，尝试加入等待队列 ，即调用 <code>addWaiter()</code>方法， 源码如下：</p>
<p><strong>AQS 的核心部分</strong>: AQS 用内部的一个 Node 类维护一个 CHL Node FIFO 队列。将当前线程加入等待队列，并通过 <code>parkAndCheckInterrupt（）</code>方法实现当前线程的阻塞。下面一大部分都是在说明 CHL 队列的实现，里面用 CAS 实现队列出入不会发生阻塞。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doAcquireSharedInterruptibly</span><span class="params">(<span class="keyword">int</span> arg)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    	<span class="comment">//加入等待队列 				      </span></span><br><span class="line">        <span class="keyword">final</span> Node node = addWaiter(Node.SHARED);</span><br><span class="line">        <span class="keyword">boolean</span> failed = <span class="keyword">true</span>;</span><br><span class="line">    	<span class="comment">// 进入 CAS 循环</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                <span class="comment">//当一个节点(关联一个线程)进入等待队列后， 获取此节点的 prev 节点 </span></span><br><span class="line">                <span class="keyword">final</span> Node p = node.predecessor();</span><br><span class="line">                <span class="comment">// 如果获取到的 prev 是 head，也就是队列中第一个等待线程</span></span><br><span class="line">                <span class="keyword">if</span> (p == head) &#123;</span><br><span class="line">                    <span class="comment">// 再次尝试申请 反应到 CountDownLatch 就是查看是否还有线程需要等待(state是否为0)</span></span><br><span class="line">                    <span class="keyword">int</span> r = tryAcquireShared(arg);</span><br><span class="line">                    <span class="comment">// 如果 r &gt;=0 说明 没有线程需要等待了 state==0</span></span><br><span class="line">                    <span class="keyword">if</span> (r &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                        <span class="comment">//尝试将第一个线程关联的节点设置为 head </span></span><br><span class="line">                        setHeadAndPropagate(node, r);</span><br><span class="line">                        p.next = <span class="keyword">null</span>; <span class="comment">// help GC</span></span><br><span class="line">                        failed = <span class="keyword">false</span>;</span><br><span class="line">                        <span class="keyword">return</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//经过自旋tryAcquireShared后，state还不为0，就会到这里，第一次的时候，waitStatus是0，那么node的waitStatus就会被置为SIGNAL，第二次再走到这里，就会用LockSupport的park方法把当前线程阻塞住</span></span><br><span class="line">                <span class="keyword">if</span> (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                    parkAndCheckInterrupt())</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> InterruptedException();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (failed)</span><br><span class="line">                cancelAcquire(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>我看看到上面先执行了 addWaiter() 方法，就是将当前线程加入等待队列，源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** Marker to indicate a node is waiting in shared mode */</span></span><br><span class="line"> <span class="keyword">static</span> <span class="keyword">final</span> Node SHARED = <span class="keyword">new</span> Node();</span><br><span class="line"> <span class="comment">/** Marker to indicate a node is waiting in exclusive mode */</span></span><br><span class="line"> <span class="keyword">static</span> <span class="keyword">final</span> Node EXCLUSIVE = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">addWaiter</span><span class="params">(Node mode)</span> </span>&#123;</span><br><span class="line">        Node node = <span class="keyword">new</span> Node(Thread.currentThread(), mode);</span><br><span class="line">        <span class="comment">// 尝试快速入队操作，因为大多数时候尾节点不为 null</span></span><br><span class="line">        Node pred = tail;</span><br><span class="line">        <span class="keyword">if</span> (pred != <span class="keyword">null</span>) &#123;</span><br><span class="line">            node.prev = pred;</span><br><span class="line">            <span class="keyword">if</span> (compareAndSetTail(pred, node)) &#123;</span><br><span class="line">                pred.next = node;</span><br><span class="line">                <span class="keyword">return</span> node;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    	<span class="comment">//如果尾节点为空(也就是队列为空) 或者尝试CAS入队失败(由于并发原因)，进入enq方法</span></span><br><span class="line">        enq(node);</span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>上面是向等待队列中添加等待者（waiter）的方法。首先构造一个 Node 实体，参数为当前线程和一个mode，这个mode有两种形式，一个是 SHARED ，一个是 EXCLUSIVE，请看上面的代码。然后执行下面的入队操作 addWaiter，和 enq() 方法的 else 分支操作是一样的，这里的操作如果成功了，就不用再进到 enq() 方法的循环中去了，可以提高性能。如果没有成功，再调用 enq() 方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">enq</span><span class="params">(<span class="keyword">final</span> Node node)</span> </span>&#123;</span><br><span class="line">    	<span class="comment">// 死循环+CAS保证所有节点都入队</span></span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            Node t = tail;</span><br><span class="line">            <span class="comment">// 如果队列为空 设置一个空节点作为 head</span></span><br><span class="line">            <span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123; <span class="comment">// Must initialize</span></span><br><span class="line">                <span class="keyword">if</span> (compareAndSetHead(<span class="keyword">new</span> Node()))</span><br><span class="line">                    tail = head;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//加入队尾</span></span><br><span class="line">                node.prev = t;</span><br><span class="line">                <span class="keyword">if</span> (compareAndSetTail(t, node)) &#123;</span><br><span class="line">                    t.next = node;</span><br><span class="line">                    <span class="keyword">return</span> t;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>说明：循环加 CAS 操作是实现乐观锁的标准方式，CAS 是为了实现原子操作而出现的，所谓的原子操作指操作执行期间，不会受其他线程的干扰。Java 实现的 CAS 是调用 unsafe 类提供的方法，底层是调用 c++ 方法，直接操作内存，在 cpu 层面加锁，直接对内存进行操作。</p>
<p>上面是 AQS 等待队列入队方法，操作在无限循环中进行，如果入队成功则返回新的队尾节点，否则一直自旋，直到入队成功。假设入队的节点为 node ，上来直接进入循环，在循环中，先拿到尾节点。</p>
<p>1、if 分支，如果尾节点为 null，说明现在队列中还没有等待线程，则尝试 CAS 操作将头节点初始化，然后将尾节点也设置为头节点，因为初始化的时候头尾是同一个，这和 AQS 的设计实现有关， AQS 默认要有一个虚拟节点。此时，尾节点不在为空，循环继续，进入 else 分支；</p>
<p>2、else 分支，如果尾节点不为 null， node.prev = t ，也就是将当前尾节点设置为待入队节点的前置节点。然后又是利用 CAS 操作，将待入队的节点设置为队列的尾节点，如果 CAS 返回 false，表示未设置成功，继续循环设置，直到设置成功，接着将之前的尾节点（也就是倒数第二个节点）的 next 属性设置为当前尾节点，对应 t.next = node 语句，然后返回当前尾节点，退出循环。</p>
<p>setHeadAndPropagate 方法负责将自旋等待或被 LockSupport 阻塞的线程唤醒。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setHeadAndPropagate</span><span class="params">(Node node, <span class="keyword">int</span> propagate)</span> </span>&#123;</span><br><span class="line">    	<span class="comment">//备份现在的 head</span></span><br><span class="line">        Node h = head;  </span><br><span class="line">    	<span class="comment">//抢到锁的线程被唤醒 将这个节点设置为head</span></span><br><span class="line">        setHead(node)</span><br><span class="line">    	<span class="comment">// propagate 一般都会大于0 或者存在可被唤醒的线程</span></span><br><span class="line">        <span class="keyword">if</span> (propagate &gt; <span class="number">0</span> || h == <span class="keyword">null</span> || h.waitStatus &lt; <span class="number">0</span> ||</span><br><span class="line">            (h = head) == <span class="keyword">null</span> || h.waitStatus &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            Node s = node.next;</span><br><span class="line">            <span class="comment">// 只有一个节点 或者是共享模式 释放所有等待线程 各自尝试抢占锁</span></span><br><span class="line">            <span class="keyword">if</span> (s == <span class="keyword">null</span> || s.isShared())</span><br><span class="line">                doReleaseShared();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>Node 对象中有一个属性是 waitStatus ，它有四种状态，分别是：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//线程已被 cancelled ，这种状态的节点将会被忽略，并移出队列</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CANCELLED =  <span class="number">1</span>;</span><br><span class="line"><span class="comment">// 表示当前线程已被挂起，并且后继节点可以尝试抢占锁</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> SIGNAL    = -<span class="number">1</span>;</span><br><span class="line"><span class="comment">//线程正在等待某些条件</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CONDITION = -<span class="number">2</span>;</span><br><span class="line"><span class="comment">//共享模式下 无条件所有等待线程尝试抢占锁</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PROPAGATE = -<span class="number">3</span>;</span><br></pre></td></tr></table></figure>
<h3 id="等待线程被唤醒"><a href="#等待线程被唤醒" class="headerlink" title="等待线程被唤醒"></a><strong>等待线程被唤醒</strong></h3><p>当执行 CountDownLatch 的 countDown（）方法，将计数器减一，也就是state减一，当减到0的时候，等待队列中的线程被释放。是调用 AQS 的 releaseShared 方法来实现的，下面代码中的方法是按顺序调用的，摘到了一起，方便查看：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// AQS类</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">releaseShared</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">    	<span class="comment">// arg 为固定值 1</span></span><br><span class="line">    	<span class="comment">// 如果计数器state 为0 返回true，前提是调用 countDown() 之前不能已经为0</span></span><br><span class="line">        <span class="keyword">if</span> (tryReleaseShared(arg)) &#123;</span><br><span class="line">            <span class="comment">// 唤醒等待队列的线程</span></span><br><span class="line">            doReleaseShared();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CountDownLatch 重写的方法</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">tryReleaseShared</span><span class="params">(<span class="keyword">int</span> releases)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// Decrement count; signal when transition to zero</span></span><br><span class="line">    		<span class="comment">// 依然是循环+CAS配合 实现计数器减1</span></span><br><span class="line">            <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                <span class="keyword">int</span> c = getState();</span><br><span class="line">                <span class="keyword">if</span> (c == <span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                <span class="keyword">int</span> nextc = c-<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">if</span> (compareAndSetState(c, nextc))</span><br><span class="line">                    <span class="keyword">return</span> nextc == <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// AQS类</span></span><br><span class="line"> <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doReleaseShared</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            Node h = head;</span><br><span class="line">            <span class="keyword">if</span> (h != <span class="keyword">null</span> &amp;&amp; h != tail) &#123;</span><br><span class="line">                <span class="keyword">int</span> ws = h.waitStatus;</span><br><span class="line">                <span class="comment">// 如果节点状态为SIGNAL，则他的next节点也可以尝试被唤醒</span></span><br><span class="line">                <span class="keyword">if</span> (ws == Node.SIGNAL) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (!compareAndSetWaitStatus(h, Node.SIGNAL, <span class="number">0</span>))</span><br><span class="line">                        <span class="keyword">continue</span>;            <span class="comment">// loop to recheck cases</span></span><br><span class="line">                    unparkSuccessor(h);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 将节点状态设置为PROPAGATE，表示要向下传播，依次唤醒</span></span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (ws == <span class="number">0</span> &amp;&amp;</span><br><span class="line">                         !compareAndSetWaitStatus(h, <span class="number">0</span>, Node.PROPAGATE))</span><br><span class="line">                    <span class="keyword">continue</span>;                <span class="comment">// loop on failed CAS</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (h == head)                   <span class="comment">// loop if head changed</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>因为这是共享型的，当计数器为 0 后，会唤醒等待队列里的所有线程，所有调用了 await() 方法的线程都被唤醒，并发执行。这种情况对应到的场景是，有多个线程需要等待一些动作完成，比如一个线程完成初始化动作，其他5个线程都需要用到初始化的结果，那么在初始化线程调用 countDown 之前，其他5个线程都处在等待状态。一旦初始化线程调用了 countDown ，其他5个线程都被唤醒，开始执行。</p>
<h2 id="Lock-condition"><a href="#Lock-condition" class="headerlink" title="Lock.condition"></a>Lock.condition</h2><h2 id="CyclicBarrier循环屏障"><a href="#CyclicBarrier循环屏障" class="headerlink" title="CyclicBarrier循环屏障"></a>CyclicBarrier循环屏障</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> CyclicBarrier cyclicBarrier = <span class="keyword">new</span> CyclicBarrier(<span class="number">2</span>, () -&gt; doWork(<span class="string">&quot;C&quot;</span>));</span><br><span class="line"><span class="keyword">final</span> Thread ta = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;A&quot;</span>);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    cyclicBarrier.await();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (<span class="keyword">final</span> InterruptedException | BrokenBarrierException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">final</span> Thread tb = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;B&quot;</span>);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    cyclicBarrier.await();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException | BrokenBarrierException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">ta.start();</span><br><span class="line">tb.start();</span><br></pre></td></tr></table></figure>
<h2 id="Semaphore信号量"><a href="#Semaphore信号量" class="headerlink" title="Semaphore信号量"></a>Semaphore信号量</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Semaphore semaphore = <span class="keyword">new</span> Semaphore(<span class="number">2</span>);</span><br><span class="line">Thread ta = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    semaphore.acquire();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e1) &#123;</span><br><span class="line">    e1.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  doWork(<span class="string">&quot;A&quot;</span>);</span><br><span class="line">  semaphore.release();</span><br><span class="line">&#125;);</span><br><span class="line">Thread tb = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    semaphore.acquire();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e1) &#123;</span><br><span class="line">    e1.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  doWork(<span class="string">&quot;B&quot;</span>);</span><br><span class="line">  semaphore.release();</span><br><span class="line">&#125;);</span><br><span class="line">Thread tc = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    semaphore.acquire(<span class="number">2</span>);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e1) &#123;</span><br><span class="line">    e1.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  doWork(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line">ta.start();</span><br><span class="line">tb.start();</span><br><span class="line">tc.start();</span><br></pre></td></tr></table></figure>
<h2 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ThreadPoolExecutor executor = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, TimeUnit.MINUTES, <span class="keyword">new</span> LinkedBlockingDeque&lt;&gt;());</span><br><span class="line">Future&lt;Boolean&gt; aFuture = executor.submit(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;A&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;);</span><br><span class="line">Future&lt;Boolean&gt; bFuture = executor.submit(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;B&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;);</span><br><span class="line">executor.execute(() -&gt; &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    aFuture.get();</span><br><span class="line">    bFuture.get();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException | ExecutionException e1) &#123;</span><br><span class="line">    e1.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  doWork(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">LinkedBlockingDeque&lt;Integer&gt; queue = <span class="keyword">new</span> LinkedBlockingDeque&lt;&gt;(<span class="number">2</span>);</span><br><span class="line">Thread ta = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;A&quot;</span>);</span><br><span class="line">  queue.add(<span class="number">1</span>);</span><br><span class="line">&#125;);</span><br><span class="line">Thread tb = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  doWork(<span class="string">&quot;B&quot;</span>);</span><br><span class="line">  queue.add(<span class="number">1</span>);</span><br><span class="line">&#125;);</span><br><span class="line">Thread tc = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    queue.take();</span><br><span class="line">    queue.take();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  doWork(<span class="string">&quot;C&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line">ta.start();</span><br><span class="line">tb.start();</span><br><span class="line">tc.start();</span><br></pre></td></tr></table></figure>
<h2 id="LockSupport"><a href="#LockSupport" class="headerlink" title="LockSupport"></a>LockSupport</h2><h2 id="ListenableFuture"><a href="#ListenableFuture" class="headerlink" title="ListenableFuture"></a>ListenableFuture</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a href="https://docs.oracle.com/javase/8/docs/">https://docs.oracle.com/javase/8/docs/</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Atomic原子变量</title>
    <url>/Java/multithread/Atomic/</url>
    <content><![CDATA[<blockquote>
<p>转载自<a href="https://blog.csdn.net/qq_34871626/article/details/81411815">Java并发编程之原子性-Atomic详解</a></p>
</blockquote>
<h1 id="Atomic"><a href="#Atomic" class="headerlink" title="Atomic"></a>Atomic</h1><h2 id="atomic包"><a href="#atomic包" class="headerlink" title="atomic包"></a>atomic包</h2><p>JUC中的Atomic包详解：</p>
<p>Atomic包中提供了很多Atomicxxx的类：</p>
<p><img src="images/20191201183741334_611136175.png"></p>
<p>它们都是CAS（compareAndSwap）来实现原子性。</p>
<h2 id="AtomicInteger样例"><a href="#AtomicInteger样例" class="headerlink" title="AtomicInteger样例"></a>AtomicInteger样例</h2><p>先写一个简单示例如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicExample1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 请求总数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> clientTotal = <span class="number">5000</span>;</span><br><span class="line">    <span class="comment">// 同时并发执行的线程数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> threadTotal = <span class="number">200</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> AtomicInteger count = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ExecutorService executorService = Executors.newCachedThreadPool();</span><br><span class="line">        <span class="keyword">final</span> Semaphore semaphore = <span class="keyword">new</span> Semaphore(threadTotal);</span><br><span class="line">        <span class="keyword">final</span> CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(clientTotal);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; clientTotal ; i++) &#123;</span><br><span class="line">            executorService.execute(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    semaphore.acquire();</span><br><span class="line">                    add();</span><br><span class="line">                    semaphore.release();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;exception&quot;</span>, e);</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        executorService.shutdown();</span><br><span class="line">        log.info(<span class="string">&quot;count:&#123;&#125;&quot;</span>, count.get());</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        count.incrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以发下每次的运行结果总是我们想要的预期结果5000。<br>说明该计数方法是线程安全的。</p>
<h2 id="AtomicInteger实现原理"><a href="#AtomicInteger实现原理" class="headerlink" title="AtomicInteger实现原理"></a>AtomicInteger实现原理</h2><p>我们查看下<code>count.incrementAndGet()</code>方法，它的第一个参数为对象本身，第二个参数为valueOffset是用来记录value本身在内存的编译地址的，这个记录，也主要是为了在更新操作在内存中找到value的位置，方便比较，第三个参数为常量1。：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicInteger</span> <span class="keyword">extends</span> <span class="title">Number</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">6214790243416807050L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// setup to use Unsafe.compareAndSwapInt for updates</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> valueOffset;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            valueOffset = unsafe.objectFieldOffset</span><br><span class="line">                (AtomicInteger.class.getDeclaredField(<span class="string">&quot;value&quot;</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123; <span class="keyword">throw</span> <span class="keyword">new</span> Error(ex); &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> value;</span><br><span class="line">    ... 此处省略多个方法...</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Atomically increments by one the current value.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> the updated value</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">incrementAndGet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> unsafe.getAndAddInt(<span class="keyword">this</span>, valueOffset, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AtomicInteger源码里使用了一个Unsafe的类,它提供了一个<strong>getAndAddInt</strong>的方法，我们继续点看查看它的源码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Unsafe</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe theUnsafe;</span><br><span class="line"></span><br><span class="line">    ....此处省略很多方法及成员变量....</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndAddInt</span><span class="params">(Object var1, <span class="keyword">long</span> var2, <span class="keyword">int</span> var4)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> var5;</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            var5 = <span class="keyword">this</span>.getIntVolatile(var1, var2);</span><br><span class="line">        &#125; <span class="keyword">while</span>(!<span class="keyword">this</span>.compareAndSwapInt(var1, var2, var5, var5 + var4));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> var5;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">compareAndSwapInt</span><span class="params">(Object var1, <span class="keyword">long</span> var2, <span class="keyword">int</span> var4, <span class="keyword">int</span> var5)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">int</span> <span class="title">getIntVolatile</span><span class="params">(Object var1, <span class="keyword">long</span> var2)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到这里使用了一个do while语句来做主体实现的。而在while语句里它的核心是调用了一个<code>compareAndSwapInt()</code>的方法。它是一个native方法，它是一个底层的方法，不是使用Java来实现的。</p>
<p>假设我们要执行0+1=0的操作，下面是单线程情况下各参数的值：</p>
<p><img src="images/20191201180435146_205936933.png"><br><img src="images/20191201180445132_1585877614.png"><br>更新后：</p>
<p><img src="images/20191201180454442_1425515581.png"></p>
<p>compareAndSwapInt()方法的第一个参数（var1）是当前的对象，就是代码示例中的count。此时它的值为0（期望值）。<br>第二个值（var2）是传递的valueOffset值，它的值为12。<br>第三个参数（var4）就为常量1。方法中的变量参数（var5）是根据参数一和参数二valueOffset，调用底层getIntVolatile方法得到的值，此时它的值为0 。<br>compareAndSwapInt()想要达到的目标是对于count这个对象，如果当前的期望值var1里的value跟底层的返回的值（var5）相同的话，那么把它更新成var5+var4这个值。<br>不同的话重新循环取期望值（var5）直至当前值与期望值相同才做更新。compareAndSwap方法的核心也就是我们通常所说的CAS。</p>
<p>Atomic包下其他的类如AtomicLong等的实现原理基本与上述一样。</p>
<h3 id="AtomicInteger的代码"><a href="#AtomicInteger的代码" class="headerlink" title="AtomicInteger的代码"></a>AtomicInteger的代码</h3><p><img src="images/20191201191519348_1356001936" title="image.png"></p>
<p>他的值是存在一个volatile的int里面。volatile只能保证这个变量的可见性。不能保证他的原子性。</p>
<p>可以看看getAndIncrement这个类似i++的函数，可以发现，是调用了UnSafe中的getAndAddInt。  </p>
<p><img src="images/20191201191518930_1459996071" title="image.png"></p>
<h3 id="UnSafe"><a href="#UnSafe" class="headerlink" title="UnSafe"></a>UnSafe</h3><p>UnSafe是何方神圣？UnSafe提供了java可以直接操作底层的能力。</p>
<p>进一步，我们可以发现实现方式：  </p>
<p><img src="images/20191201191518602_784980377" title="image.png"></p>
<p>如何保证原子性：<strong>自旋 + <a href="http://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&mid=2650121285&idx=1&sn=7cf9b5badd6d38b57ccfbfed63d3aad1&chksm=f36bb964c41c307218914cab6c1592f649281460e4ec1f85627c1311441c8a43ee1854440552&scene=21#wechat_redirect">CAS</a>（乐观锁）</strong>。在这个过程中，通过compareAndSwapInt比较更新value值，如果更新失败，重新获取旧值，然后更新。</p>
<p><strong>优缺点</strong></p>
<p>CAS相对于其他锁，不会进行内核态操作，有着一些性能的提升。但同时引入自旋，<strong>当锁竞争较大的时候，自旋次数会增多。cpu资源会消耗很高</strong>。  </p>
<p>换句话说，CAS+自旋适合使用在低并发有同步数据的应用场景。</p>
<h3 id="Java-8做出的改进和努力"><a href="#Java-8做出的改进和努力" class="headerlink" title="Java 8做出的改进和努力"></a>Java 8做出的改进和努力</h3><p>在Java 8中引入了4个新的计数器类型，<code>LongAdder</code>、<code>LongAccumulator</code>、<code>DoubleAdder</code>、<code>DoubleAccumulator</code>。他们都是继承于<code>Striped64</code></p>
<h4 id="在LongAdder-与AtomicLong有什么区别"><a href="#在LongAdder-与AtomicLong有什么区别" class="headerlink" title="在LongAdder 与AtomicLong有什么区别?"></a>在LongAdder 与AtomicLong有什么区别?</h4><p>这里再介绍下LongAdder这个类，通过上述的分析，我们已经知道了AtomicLong使用CAS：<br><strong>在一个死循环内不断尝试修改目标值直到修改成功。如果在竞争不激烈的情况下，它修改成功概率很高。反之，如果在竞争激烈的情况下，修改失败的概率会很高，它就会进行多次的循环尝试，因此性能会受到一些影响。</strong><br>对于普通类型的long和double变量，jvm允许将64位的读操作或写操作拆成两个32位的操作。</p>
<p>LongAdder的核心思想是将热点数据分离，它可以将AtomicLong内部核心数据value分离成一个数组，每个线程访问时通过hash等算法映射到其中一个数字进行计数。而最终的计数结果则为这个数组的求和累加，其中热点数据value，它会被分离成多个单元的cell，每个cell独自维护内部的值,当前对象的实际值由所有的cell累计合成。这样,热点就进行了有效的分离,提高了并行度。LongAdder相当于在AtomicLong的基础上将单点的更新压力分散到各个节点上，在低并发的时候对base的直接更新可以很好的保障跟Atomic的性能基本一致。而在高并发的时候，通过分散提高了性能。但是如果在统计的时候有并发更新，可能会导致统计的数据有误差。</p>
<p>在实际高并发计数的时候，可以优先使用LongAdder。在低并行度或者需要准确数值的时候可以优先使用AtomicLong，这样反而效率更高。</p>
<p>下面简单的演示下Atomic包下AtomicReference简单的用法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicExample4</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AtomicReference&lt;Integer&gt; count = <span class="keyword">new</span> AtomicReference&lt;&gt;(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        count.compareAndSet(<span class="number">0</span>, <span class="number">2</span>);</span><br><span class="line">        count.compareAndSet(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">        log.info(<span class="string">&quot;count:&#123;&#125;&quot;</span>, count.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>compareAndSet()分别传入的是预期值跟更新值，只有当预期值跟当前值相等时，才会将值更新为更新值；</p>
<p>上面的第一个方法可以将值更新为2，而第二个步中无法将值更新为1。</p>
<p>Atomic*遇到的问题是，只能运用于低并发场景。因此LongAddr在这基础上引入了<strong>分段锁</strong>的概念。可以参考《JDK8系列之LongAdder解析》一起看看做了什么。</p>
<p>**大概就是当竞争不激烈的时候，所有线程都是通过CAS对同一个变量（Base）进行修改，当竞争激烈的时候，会将根据当前线程哈希到对于Cell上进行修改（多段锁）。  **</p>
<p><img src="images/20191201191517305_1368784593" title="image.png"></p>
<p>可以看到大概实现原理是：通过<strong>CAS乐观锁</strong>保证原子性，通过<strong>自旋</strong>保证当次修改的最终修改成功，通过<strong>降低锁粒度（多段锁）</strong>增加并发性能。</p>
<h2 id="AtomicIntegerFieldUpdater"><a href="#AtomicIntegerFieldUpdater" class="headerlink" title="AtomicIntegerFieldUpdater"></a>AtomicIntegerFieldUpdater</h2><p>下面简单介绍下AtomicIntegerFieldUpdater 用法（利用原子性去更新某个类的实例）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicExample5</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AtomicIntegerFieldUpdater&lt;AtomicExample5&gt; updater =</span><br><span class="line">            AtomicIntegerFieldUpdater.newUpdater(AtomicExample5.class, <span class="string">&quot;count&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> count = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        AtomicExample5 example5 = <span class="keyword">new</span> AtomicExample5();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (updater.compareAndSet(example5, <span class="number">100</span>, <span class="number">120</span>)) &#123;</span><br><span class="line">            log.info(<span class="string">&quot;update success 1, &#123;&#125;&quot;</span>, example5.getCount());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (updater.compareAndSet(example5, <span class="number">100</span>, <span class="number">120</span>)) &#123;</span><br><span class="line">            log.info(<span class="string">&quot;update success 2, &#123;&#125;&quot;</span>, example5.getCount());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            log.info(<span class="string">&quot;update failed, &#123;&#125;&quot;</span>, example5.getCount());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它可以更新某个类中指定成员变量的值。注意：修改的成员变量需要用volatile关键字来修饰，并且不能是static描述的字段。</p>
<h2 id="AtomicStampReference"><a href="#AtomicStampReference" class="headerlink" title="AtomicStampReference"></a>AtomicStampReference</h2><p>AtomicStampReference 这个类它的核心是要解决CAS的ABA问题（CAS操作的时候，其他线程将变量的值A改成了B，接着又改回了A，等线程使用期望值A与当前变量进行比较的时候，发现A变量没有变，于是CAS就将A值进行了交换操作。实际上该值已经被其他线程改变过）。ABA问题的解决思路就是每次变量变更的时候，就将版本号加一。看一下它的一个核心方法compareAndSet()：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicStampedReference</span>&lt;<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> T reference;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> stamp;</span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="title">Pair</span><span class="params">(T reference, <span class="keyword">int</span> stamp)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.reference = reference;</span><br><span class="line">            <span class="keyword">this</span>.stamp = stamp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">static</span> &lt;T&gt; <span class="function">Pair&lt;T&gt; <span class="title">of</span><span class="params">(T reference, <span class="keyword">int</span> stamp)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Pair&lt;T&gt;(reference, stamp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">   ... 此处省略多个方法 ....</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(V   expectedReference,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 V   newReference,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">int</span> expectedStamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">int</span> newStamp)</span> </span>&#123;</span><br><span class="line">        Pair&lt;V&gt; current = pair;</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">            expectedReference == current.reference &amp;&amp;</span><br><span class="line">            expectedStamp == current.stamp &amp;&amp;</span><br><span class="line">            ((newReference == current.reference &amp;&amp;</span><br><span class="line">              newStamp == current.stamp) ||</span><br><span class="line">             casPair(current, Pair.of(newReference, newStamp)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到它多了一个stamp的比较，stamp的值是由每次更新的时候进行维护的。</p>
<h2 id="AtomicLongArray"><a href="#AtomicLongArray" class="headerlink" title="AtomicLongArray"></a>AtomicLongArray</h2><p>再介绍下 AtomicLongArray ， 它维护了一个数组。在该数组下，我们可以选择性的已原子性操作更新某个索引对应的值。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicLongArray</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">2308431214976778248L</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class="line"> </span><br><span class="line">    ...此处省略....</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Atomically sets the element at position &#123;<span class="doctag">@code</span> i&#125; to the given value</span></span><br><span class="line"><span class="comment">     * and returns the old value.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> i the index</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> newValue the new value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> the previous value</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">getAndSet</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">long</span> newValue)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> unsafe.getAndSetLong(array, checkedByteOffset(i), newValue);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Atomically sets the element at position &#123;<span class="doctag">@code</span> i&#125; to the given</span></span><br><span class="line"><span class="comment">     * updated value if the current value &#123;<span class="doctag">@code</span> ==&#125; the expected value.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> i the index</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> expect the expected value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> update the new value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> &#123;<span class="doctag">@code</span> true&#125; if successful. False return indicates that</span></span><br><span class="line"><span class="comment">     * the actual value was not equal to the expected value.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">long</span> expect, <span class="keyword">long</span> update)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> compareAndSetRaw(checkedByteOffset(i), expect, update);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="AtomcBoolean"><a href="#AtomcBoolean" class="headerlink" title="AtomcBoolean"></a>AtomcBoolean</h2><p>最后再写一个AtomcBoolean的简单使用：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicExample6</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AtomicBoolean isHappened = <span class="keyword">new</span> AtomicBoolean(<span class="keyword">false</span>);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 请求总数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> clientTotal = <span class="number">5000</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 同时并发执行的线程数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> threadTotal = <span class="number">200</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ExecutorService executorService = Executors.newCachedThreadPool();</span><br><span class="line">        <span class="keyword">final</span> Semaphore semaphore = <span class="keyword">new</span> Semaphore(threadTotal);</span><br><span class="line">        <span class="keyword">final</span> CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(clientTotal);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; clientTotal ; i++) &#123;</span><br><span class="line">            executorService.execute(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    semaphore.acquire();</span><br><span class="line">                    test();</span><br><span class="line">                    semaphore.release();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;exception&quot;</span>, e);</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        executorService.shutdown();</span><br><span class="line">        log.info(<span class="string">&quot;isHappened:&#123;&#125;&quot;</span>, isHappened.get());</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (isHappened.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">            log.info(<span class="string">&quot;execute&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>总结：以上就是Atomic包的基本原理及主要的使用方法。它是使用CAS来保证原子性操作，从而达到线程安全的目的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.Semaphore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RunningInTurn</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="title">extendsThread</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Semaphore thisSemaphore;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Semaphore nextSemaphore;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> value;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Worker</span><span class="params">(String name, Semaphore thisSemaphore, Semaphore nextSemaphore, <span class="keyword">int</span> initialValue)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.name= name;</span><br><span class="line"><span class="keyword">this</span>.thisSemaphore= thisSemaphore;</span><br><span class="line"><span class="keyword">this</span>.nextSemaphore= nextSemaphore;</span><br><span class="line"><span class="keyword">this</span>.value= initialValue;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">while</span>(value &lt;= <span class="number">100</span>) &#123;</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">thisSemaphore.acquire();</span><br><span class="line">System.out.println(name + <span class="string">&quot;:\t&quot;</span>+ value);</span><br><span class="line">value += <span class="number">2</span>;</span><br><span class="line">nextSemaphore.release();</span><br><span class="line">&#125; <span class="keyword">catch</span>(InterruptedExceptione) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException</span>&#123;</span><br><span class="line"></span><br><span class="line">Semaphorea Semaphore = newSemaphore(<span class="number">1</span>);</span><br><span class="line">Semaphore bSemaphore = newSemaphore(<span class="number">1</span>);</span><br><span class="line">Worker workerA = newWorker(<span class="string">&quot;a&quot;</span>, aSemaphore, bSemaphore, <span class="number">1</span>);</span><br><span class="line">Worker workerB = newWorker(<span class="string">&quot;b&quot;</span>, bSemaphore, aSemaphore, <span class="number">2</span>);</span><br><span class="line">bSemaphore.acquire();</span><br><span class="line">workerA.start();</span><br><span class="line">workerB.start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrimeNumberWithRoll</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> rowNum = <span class="number">21</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> colNum = <span class="number">10000_0000</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">byte</span>[][] bytes = newbyte[rowNum][colNum];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">init();</span><br><span class="line">start();</span><br><span class="line">print();</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">intcount = <span class="number">0</span>;</span><br><span class="line">longi;</span><br><span class="line"><span class="keyword">for</span>(i = <span class="number">1</span>; count &lt;= <span class="number">10000_0000</span>&amp;&amp; i &lt;= rowNum * colNum; i++) &#123;</span><br><span class="line"><span class="keyword">if</span>(getValue(i)) &#123;</span><br><span class="line">count++;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(count - <span class="number">1</span>+ <span class="string">&quot;\t&quot;</span>+ i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">byte</span>[] aByte :bytes) &#123;</span><br><span class="line">Arrays.fill(aByte, (<span class="keyword">byte</span>) <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">longindex = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">while</span>(index * index &lt; (<span class="keyword">long</span>) rowNum * colNum) &#123;</span><br><span class="line"><span class="keyword">boolean</span> prime = getValue(index);</span><br><span class="line">System.out.println(index + <span class="string">&quot;\t&quot;</span>+ prime);</span><br><span class="line"><span class="keyword">if</span>(prime) &#123;</span><br><span class="line">setPrimeRoll(index, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line">index++;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setPrimeRoll</span><span class="params">(longindex, booleanpri)</span> </span>&#123;</span><br><span class="line"><span class="keyword">for</span>(longi = index + index; i &lt; bytes.length* bytes[<span class="number">0</span>].length; i += index) &#123;</span><br><span class="line">setValue(i, pri);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setValue</span><span class="params">(longindex, booleanpri)</span> </span>&#123;</span><br><span class="line"><span class="keyword">long</span> localIndex = index - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">long</span> rowNo = localIndex / colNum;</span><br><span class="line"><span class="keyword">long</span> colNo = localIndex % colNum;</span><br><span class="line">bytes[(<span class="keyword">int</span>) rowNo][(<span class="keyword">int</span>) colNo] = pri ?(<span class="keyword">byte</span>) <span class="number">1</span>:(<span class="keyword">byte</span>) <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">getValue</span><span class="params">(longindex)</span> </span>&#123;</span><br><span class="line"><span class="keyword">long</span> localIndex = index - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span>(localIndex == <span class="number">1</span>|| localIndex == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">long</span> rowNo = localIndex / colNum;</span><br><span class="line"><span class="keyword">long</span> colNo = localIndex % colNum;</span><br><span class="line"><span class="keyword">return</span> bytes[(<span class="keyword">int</span>) rowNo][(<span class="keyword">int</span>) colNo] == <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>无锁队列与Disruptor</title>
    <url>/Java/multithread/lockless-disruptor/</url>
    <content><![CDATA[<p>转自<a href="http://www.importnew.com/19877.html">剖析Disruptor为什么会这么快</a></p>
<p><strong>Disruptor如何解决这些问题。</strong></p>
<p>首先，Disruptor根本就不用锁。</p>
<p>取而代之的是，在需要确保操作是线程安全的（特别是，在<a href="http://mechanitis.blogspot.com/2011/07/dissecting-disruptor-writing-to-ring.html">多生产者</a>的环境下，更新下一个可用的序列号）地方，我们使用<a href="http://en.wikipedia.org/wiki/Compare-and-swap">CAS</a>（Compare And Swap/Set）操作。这是一个CPU级别的指令，在我的意识中，它的工作方式有点像乐观锁——CPU去更新一个值，但如果想改的值不再是原来的值，操作就失败，因为很明显，有其它操作先改变了这个值。</p>
<p><a href="http://ifeve.com/wp-content/uploads/2013/01/ConcurrencyCAS.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/ConcurrencyCAS.png" alt="img"></a></p>
<p>注意，这可以是CPU的两个不同的核心，但不会是两个独立的CPU。</p>
<p>CAS操作比锁消耗资源少的多，因为它们不牵涉操作系统，它们直接在CPU上操作。但它们并非没有代价——在上面的试验中，单线程无锁耗时300ms，单线程有锁耗时10000ms，单线程使用CAS耗时5700ms。所以它比使用锁耗时少，但比不需要考虑竞争的单线程耗时多。</p>
<p>回到Disruptor，在我<a href="http://ifeve.com/disruptor-writing-ringbuffer/">讲生产者</a>时讲过<a href="https://github.com/LMAX-Exchange/disruptor/blob/version-2.x/code/src/main/com/lmax/disruptor/ClaimStrategy.java">ClaimStrategy</a>。在这些代码中，你可以看见两个策略，一个是SingleThreadedStrategy（单线程策略）另一个是MultiThreadedStrategy（多线程策略）。你可能会有疑问，为什么在只有单个生产者时不用多线程的那个策略？它是否能够处理这种场景？当然可以。但多线程的那个使用了<a href="http://download.oracle.com/javase/6/docs/api/java/util/concurrent/atomic/AtomicLong.html">AtomicLong</a>（Java提供的CAS操作），而单线程的使用long，没有锁也没有CAS。这意味着单线程版本会非常快，因为它只有一个生产者，不会产生序号上的冲突。</p>
<p>我知道，你可能在想：把一个数字转成AtomicLong不可能是Disruptor速度快的唯一秘密。当然，它不是，否则它不可能称为“为什么这么快（第一部分）”。</p>
<p>但这是非常重要的一点</p>
<p>——在整个复杂的框架中，只有这一个地方出现多线程竞争修改同一个变量值。这就是秘密。还记得所有的访问对象都拥有序号吗？如果只有一个生产者，那么系统中的每一个序列号只会由一个线程写入。这意味着没有竞争、不需要锁、甚至不需要CAS。在ClaimStrategy中，如果存在多个生产者，唯一会被多线程竞争写入的序号就是 ClaimStrategy 对象里的那个。</p>
<p>这也是为什么Entry中的每一个变量都<a href="http://ifeve.com/dissecting-disruptor-wiring-up/">只能被一个消费者写</a>。它确保了没有写竞争，因此不需要锁或者CAS。</p>
<p><strong>回到为什么队列不能胜任这个工作</strong></p>
<p>因此你可能会有疑问，为什么队列底层用RingBuffer来实现，仍然在性能上无法与 Disruptor 相比。队列和<a href="http://en.wikipedia.org/wiki/Circular_buffer">最简单的ring buffer</a>只有两个指针——一个指向队列的头，一个指向队尾：</p>
<p><a href="http://ifeve.com/wp-content/uploads/2013/01/QueueMultiple.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueMultiple.png" alt="img"></a></p>
<p>如果有超过一个生产者想要往队列里放东西，尾指针就将成为一个冲突点，因为有多个线程要更新它。如果有多个消费者，那么头指针就会产生竞争，因为元素被消费之后，需要更新指针，所以不仅有读操作还有写操作了。</p>
<p>等等，我听到你喊冤了！因为我们已经知道这些了，所以队列常常是单生产者和单消费者（或者至少在我们的测试里是）。<br>队列的目的就是为生产者和消费者提供一个地方存放要交互的数据，帮助缓冲它们之间传递的消息。这意味着缓冲常常是满的（生产者比消费者快）或者空的（消费者比生产者快）。生产者和消费者能够步调一致的情况非常少见。</p>
<p>所以，这就是事情的真面目。一个空的队列：</p>
<p><a href="http://ifeve.com/wp-content/uploads/2013/01/QueueEmpty.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueEmpty.png" alt="img"></a></p>
<p>…</p>
<p>一个满的队列：</p>
<p><a href="http://ifeve.com/wp-content/uploads/2013/01/QueueFull.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueFull.png" alt="img"></a></p>
<p><em>(校对注：这应该是一个双向队列)</em></p>
<p>队列需要保存一个关于大小的变量，以便区分队列是空还是满。否则，它需要根据队列中的元素的内容来判断，这样的话，消费一个节点（Entry）后需要做一次写入来清除标记，或者标记节点已经被消费过了。无论采用何种方式实现，在头、尾和大小变量上总是会有很多竞争，或者如果消费操作移除元素时需要使用一个写操作，那元素本身也包含竞争。</p>
<p>基于以上，这三个变量常常在一个<a href="http://en.wikipedia.org/wiki/CPU_cache">cache line</a>里面，有可能导致伪分享<a href="http://en.wikipedia.org/wiki/False_sharing">false sharing</a>。因此，不仅要担心生产者和消费者同时写size变量（或者元素），还要注意由于头指针尾指针在同一位置，当头指针更新时，更新尾指针会导致缓存不命中。这篇文章已经很长了，所以我就不再详述细节了。</p>
<p>这就是我们所说的“分离竞争点问题”或者队列的“合并竞争点问题”。通过将所有的东西都赋予私有的序列号，并且只允许一个消费者写Entry对象中的变量来消除竞争，Disruptor 唯一需要处理访问冲突的地方，是多个生产者写入 Ring Buffer 的场景。</p>
<p><strong>总结</strong></p>
<p>Disruptor相对于传统方式的优点：</p>
<ol>
<li>没有竞争=没有锁=非常快。</li>
<li>所有访问者都记录自己的序号的实现方式，允许多个生产者与多个消费者共享相同的数据结构。</li>
<li>在每个对象中都能跟踪序列号（ring buffer，claim Strategy，生产者和消费者），加上神奇的<a href="http://code.google.com/p/disruptor/source/browse/trunk/code/src/main/com/lmax/disruptor/RingBuffer.java">cache line padding</a>，就意味着没有为伪共享和非预期的竞争。</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>disruptor</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程等待的N中打开方式</title>
    <url>/Java/multithread/running-in-turn/</url>
    <content><![CDATA[<h1 id="2个线程轮流输出"><a href="#2个线程轮流输出" class="headerlink" title="2个线程轮流输出"></a>2个线程轮流输出</h1><p> A、B两个线程轮流输出1~100的数字<br/><br> A线程输出: 1、3、5…47、49、    52、54…98、100 <br/><br> B线程输出: 2、4、6…48、50、51、53、55…97、99 两个线程输出个数相同</p>
<blockquote>
<p>分析：</p>
<ol>
<li>每个线程持有一把锁，运行时，首先获取自己的锁，运行完释放另一个线程的锁</li>
</ol>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.Semaphore;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A、B两个线程轮流输出1~100的数字&lt;br/&gt;</span></span><br><span class="line"><span class="comment"> * A线程输出: 1、3、5...47、49、    52、54...98、100 &lt;br/&gt;</span></span><br><span class="line"><span class="comment"> * B线程输出: 2、4、6...48、50、51、53、55...97、99 两个线程输出个数相同</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RunningInTurn</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 每个线程 </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> Semaphore thisSemaphore;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> Semaphore nextSemaphore;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> value;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Worker</span><span class="params">(String name, Semaphore thisSemaphore, Semaphore nextSemaphore, <span class="keyword">int</span> initialValue)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.name = name;</span><br><span class="line">            <span class="keyword">this</span>.thisSemaphore = thisSemaphore;</span><br><span class="line">            <span class="keyword">this</span>.nextSemaphore = nextSemaphore;</span><br><span class="line">            <span class="keyword">this</span>.value = initialValue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> cnt = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span> (value &lt;= <span class="number">100</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    thisSemaphore.acquire();</span><br><span class="line">                    System.out.println(name + <span class="string">&quot;:\t&quot;</span> + value);</span><br><span class="line">                    cnt++;</span><br><span class="line">                    <span class="keyword">if</span> (value == <span class="number">50</span>) &#123;</span><br><span class="line">                        value = <span class="number">51</span>;</span><br><span class="line">                        System.out.println(name + <span class="string">&quot;:\t&quot;</span> + value);</span><br><span class="line">                        cnt++;</span><br><span class="line">                        value += <span class="number">2</span>;</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (value == <span class="number">49</span>) &#123;</span><br><span class="line">                        value = <span class="number">52</span>;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        value += <span class="number">2</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    nextSemaphore.release();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(name + <span class="string">&quot; cnt : &quot;</span> + cnt);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        Semaphore aSemaphore = <span class="keyword">new</span> Semaphore(<span class="number">1</span>);</span><br><span class="line">        Semaphore bSemaphore = <span class="keyword">new</span> Semaphore(<span class="number">1</span>);</span><br><span class="line">        Worker workerA = <span class="keyword">new</span> Worker(<span class="string">&quot;a&quot;</span>, aSemaphore, bSemaphore, <span class="number">1</span>);</span><br><span class="line">        Worker workerB = <span class="keyword">new</span> Worker(<span class="string">&quot;b&quot;</span>, bSemaphore, aSemaphore, <span class="number">2</span>);</span><br><span class="line">        bSemaphore.acquire();</span><br><span class="line">        workerA.start();</span><br><span class="line">        workerB.start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Java图片处理二--合成圆形头像(类似于QQ群聊)</title>
    <url>/Java/skill/Image-round-protrait/</url>
    <content><![CDATA[<blockquote>
<p> <a href="/Java/Image-zip-square-portrait/">上一篇</a> 介绍了Java合成方形群头像的方法，方形群头像由于易于定位且不涉及形状填充和拼接，实现起来相对简单，本篇介绍的圆形头像方案则复杂很多。</p>
</blockquote>
<p>先看一下圆形头像的样子</p>
<p><img src="/images/java/image/round-portrait.png" alt="圆形头像样例"></p>
<p>从例子可以看出有如下几个特性:</p>
<ol>
<li>每张图片都是圆形的，涉及图片的剪切和图片填充到形状</li>
<li>当图片的个数多于1时，就要考虑图片的遮盖。</li>
<li>图片个数多余1时，需考虑图片的位置：2个是正对角线方向，3、4、5分别是正三角形、正四边形和正五边形</li>
</ol>
<p>接下来，从上面的三点介绍：</p>
<h1 id="图片的形状填充"><a href="#图片的形状填充" class="headerlink" title="图片的形状填充"></a>图片的形状填充</h1><p>在Java图形库(<code>java.awt</code>)中，存在图片形状填充的API，提供了<a href="http://tool.oschina.net/apidocs/apidoc?api=jdk-zh">Area</a>工具，通过Area可以方便的实现图片的填充.  Area 类可以根据指定的 Shape 对象创建区域几何形状。如果 Shape 还不是封闭的，则显式地封闭几何形状。由 Shape 的几何形状指定的填充规则（奇偶或缠绕）用于确定得到的封闭区域。 </p>
<h2 id="Area填充"><a href="#Area填充" class="headerlink" title="Area填充"></a>Area填充</h2><p>步骤如下:</p>
<ul>
<li>创建Shape</li>
<li>创建Area</li>
<li>建立画板，设置与Area的交集</li>
<li>绘制待填充的图片</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> objectImageSize = <span class="number">260</span>;</span><br><span class="line"><span class="keyword">int</span> originImageSize = <span class="number">260</span>;</span><br><span class="line"><span class="comment">// 1. 创建Shape，这里定义了一个Polygon的Shape</span></span><br><span class="line"><span class="keyword">int</span> xpoints[] = &#123; <span class="number">20</span>, <span class="number">70</span>, <span class="number">130</span>, <span class="number">240</span> &#125;;</span><br><span class="line"><span class="keyword">int</span> ypoints[] = &#123; <span class="number">20</span>, <span class="number">150</span>, <span class="number">100</span>, <span class="number">130</span> &#125;;</span><br><span class="line">Polygon polygon = <span class="keyword">new</span> Polygon(xpoints, ypoints, <span class="number">4</span>);</span><br><span class="line"><span class="comment">// 2. 创建Area，并将Shape添加到Area</span></span><br><span class="line">Area tempArea = <span class="keyword">new</span> Area();</span><br><span class="line">tempArea.add(<span class="keyword">new</span> Area(polygon));</span><br><span class="line"><span class="comment">// 3. 建立画板</span></span><br><span class="line">BufferedImage tempBufferImage = <span class="keyword">new</span> BufferedImage(objectImageSize, objectImageSize, BufferedImage.TYPE_INT_RGB); <span class="comment">// 定义画板的大小和颜色</span></span><br><span class="line">Graphics2D g2d = tempBufferImage.createGraphics(); <span class="comment">// 创建</span></span><br><span class="line"></span><br><span class="line">g2d.setColor(Color.pink);</span><br><span class="line">g2d.fillRect(<span class="number">0</span>, <span class="number">0</span>, objectImageSize, objectImageSize); <span class="comment">//使用颜色填充，作为背景色</span></span><br><span class="line"><span class="comment">// 消除锯齿</span></span><br><span class="line">g2d.setRenderingHint(RenderingHints.KEY_TEXT_ANTIALIASING, RenderingHints.VALUE_TEXT_ANTIALIAS_ON);</span><br><span class="line">g2d.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);</span><br><span class="line"><span class="comment">// 设置与Area的交集</span></span><br><span class="line">g2d.setClip(tempArea);</span><br><span class="line"><span class="comment">// 4. 绘制待填充的图片：设置了与Area的交集之后，绘制图片将只在交集内绘制</span></span><br><span class="line">BufferedImage bufferedImage = ImageUtil.resize2(<span class="string">&quot;lt.png&quot;</span>, originImageSize, originImageSize, <span class="keyword">true</span>);</span><br><span class="line">g2d.drawImage(bufferedImage, <span class="number">0</span>, <span class="number">0</span>, <span class="keyword">null</span>);</span><br><span class="line">g2d.dispose(); <span class="comment">// 关闭绘图区</span></span><br><span class="line"><span class="comment">// 5. 输出绘图区</span></span><br><span class="line">String format = <span class="string">&quot;JPG&quot;</span>;</span><br><span class="line">ImageIO.write(tempBufferImage, format, <span class="keyword">new</span> File(<span class="string">&quot;result.jpg&quot;</span>));</span><br></pre></td></tr></table></figure>
<p>见上面的结果:<br><img src="/images/java/image/area-clip.jpg"></p>
<h2 id="Area剪切"><a href="#Area剪切" class="headerlink" title="Area剪切"></a>Area剪切</h2><p>Area可以实现区域的交集、并集、互减和组合区域并减去其交集， 本例使用Area互减实现圆形的互减。下面演示</p>
<p>实现月牙形状</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Ellipse2D.Double circle1 = <span class="keyword">new</span> Ellipse2D.Double(<span class="number">50</span>, <span class="number">50</span>, <span class="number">200</span>, <span class="number">200</span>);</span><br><span class="line">tempArea.add(<span class="keyword">new</span> Area(circle1)); <span class="comment">// 定义Area 1</span></span><br><span class="line">Ellipse2D.Double circle2 = <span class="keyword">new</span> Ellipse2D.Double(<span class="number">100</span>, <span class="number">100</span>, <span class="number">200</span>, <span class="number">200</span>);</span><br><span class="line">tempArea.subtract(<span class="keyword">new</span> Area(circle2)); <span class="comment">// 减去Area 2</span></span><br></pre></td></tr></table></figure>
<p>看效果</p>
<p><img src="/images/java/image/area-crescent.jpg"></p>
<h1 id="圆形头像"><a href="#圆形头像" class="headerlink" title="圆形头像"></a>圆形头像</h1><p>接下来实现圆形头像，基本上就是图片的定位，亲，高中几何学的怎么样？</p>
<h2 id="图形Item坐标信息"><a href="#图形Item坐标信息" class="headerlink" title="图形Item坐标信息"></a>图形Item坐标信息</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ItemConfig &#123;</span><br><span class="line">		&#x2F;**</span><br><span class="line">		 * item的大小, 圆的最小外切矩形</span><br><span class="line">		 *&#x2F;</span><br><span class="line">		int itemSize;</span><br><span class="line">		&#x2F;**</span><br><span class="line">		 * 留白区域大小</span><br><span class="line">		 *&#x2F;</span><br><span class="line">		int whiteSize;</span><br><span class="line">		&#x2F;**</span><br><span class="line">		 * item起始坐标</span><br><span class="line">		 *&#x2F;</span><br><span class="line">		int[][] itemLoaction;</span><br><span class="line">		&#x2F;**</span><br><span class="line">		 * 切口圆的坐标</span><br><span class="line">		 *&#x2F;</span><br><span class="line">		int[][] subtractLocation;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h2 id="计算坐标"><a href="#计算坐标" class="headerlink" title="计算坐标"></a>计算坐标</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ItemConfig itemConfig = <span class="keyword">new</span> ItemConfig();</span><br><span class="line">iconCount = iconCount &gt; <span class="number">5</span> ? <span class="number">5</span> : iconCount;<span class="comment">// 图标最多五个</span></span><br><span class="line"><span class="keyword">int</span> borderWidth = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span> whiteSize = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span> r;</span><br><span class="line"><span class="keyword">switch</span> (iconCount) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">      <span class="keyword">int</span> itemSize = imageSize - <span class="number">2</span> * borderWidth;</span><br><span class="line">      <span class="keyword">int</span> x = borderWidth, y = borderWidth;</span><br><span class="line">      itemConfig.itemSize = itemSize;</span><br><span class="line">      itemConfig.whiteSize = <span class="number">10</span>;</span><br><span class="line">      itemConfig.itemLoaction = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">1</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>] = x;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>] = y;</span><br><span class="line">      itemConfig.subtractLocation = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">      itemConfig.whiteSize = <span class="number">10</span>;</span><br><span class="line">      r = (<span class="keyword">int</span>) ((imageSize - <span class="number">2</span> * borderWidth + <span class="number">2</span> * itemConfig.whiteSize) / (<span class="number">2</span> + Math.sqrt(<span class="number">2</span>)));</span><br><span class="line">      itemConfig.itemSize = r * <span class="number">2</span>;</span><br><span class="line">      itemConfig.itemLoaction = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">2</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>] = borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>] = borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>] = imageSize - <span class="number">2</span> * r - itemConfig.whiteSize - borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>] = imageSize - <span class="number">2</span> * r - itemConfig.whiteSize - borderWidth;</span><br><span class="line"></span><br><span class="line">      itemConfig.subtractLocation = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">2</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">0</span>][<span class="number">0</span>] = (<span class="keyword">int</span>) (itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>] - <span class="number">1.5</span> * itemConfig.whiteSize);</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">0</span>][<span class="number">1</span>] = (<span class="keyword">int</span>) (itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>] - <span class="number">1.5</span> * itemConfig.whiteSize);</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">1</span>] = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">      itemConfig.whiteSize = whiteSize;</span><br><span class="line">      r = (<span class="keyword">int</span>) ((imageSize - <span class="number">2</span> * borderWidth) / (<span class="number">2</span> + Math.sqrt(<span class="number">3</span>))) + itemConfig.whiteSize / <span class="number">2</span>;</span><br><span class="line">      itemConfig.itemSize = <span class="number">2</span> * r;</span><br><span class="line"></span><br><span class="line">      itemConfig.itemLoaction = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>] = (imageSize - <span class="number">2</span> * borderWidth) / <span class="number">2</span> + borderWidth - r;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>] = borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>] = borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>] = imageSize - borderWidth - <span class="number">2</span> * r;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>] = imageSize - borderWidth - <span class="number">2</span> * r;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>] = imageSize - borderWidth - <span class="number">2</span> * r;</span><br><span class="line"></span><br><span class="line">      itemConfig.subtractLocation = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">0</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">0</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">1</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">1</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">2</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">2</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">4</span>:</span><br><span class="line">      whiteSize = <span class="number">10</span>;</span><br><span class="line">      itemConfig.whiteSize = whiteSize;</span><br><span class="line">      r = (<span class="keyword">int</span>) ((imageSize - <span class="number">2.0</span> * borderWidth) / <span class="number">4</span> + whiteSize);</span><br><span class="line">      itemConfig.itemSize = <span class="number">2</span> * r;</span><br><span class="line"></span><br><span class="line">      itemConfig.itemLoaction = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">4</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>] = borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>] = borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>] = imageSize - borderWidth - whiteSize - <span class="number">2</span> * r;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>] = imageSize - borderWidth - whiteSize - <span class="number">2</span> * r;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">      itemConfig.subtractLocation = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">4</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">0</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">1</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">2</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">2</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">3</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">3</span>][<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">5</span>:</span><br><span class="line">      whiteSize = <span class="number">10</span>;</span><br><span class="line">      itemConfig.whiteSize = whiteSize;</span><br><span class="line">      r = (<span class="keyword">int</span>) ((imageSize - <span class="number">2.0</span> * borderWidth)</span><br><span class="line">      / (<span class="number">2</span> * (Math.cos(Math.toRadians(<span class="number">18</span>)) + Math.cos(Math.toRadians(<span class="number">54</span>))) + <span class="number">2</span>)) + whiteSize;</span><br><span class="line">      itemConfig.itemSize = <span class="number">2</span> * r;</span><br><span class="line"></span><br><span class="line">      itemConfig.itemLoaction = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">5</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>] = (imageSize - <span class="number">2</span> * borderWidth) / <span class="number">2</span> - r + borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>] = borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>] = borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>] = (<span class="keyword">int</span>) (<span class="number">2</span> * r * Math.cos(Math.toRadians(<span class="number">54</span>))) + borderWidth;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>] = (<span class="keyword">int</span>) (borderWidth + <span class="number">2</span> * r * Math.sin(Math.toRadians(<span class="number">18</span>)));</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>] = imageSize - borderWidth - <span class="number">2</span> * r;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">0</span>] = (<span class="keyword">int</span>) (imageSize - borderWidth - <span class="number">2</span> * r</span><br><span class="line">      - <span class="number">2</span> * r * Math.sin(Math.toRadians(<span class="number">18</span>)));</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">4</span>][<span class="number">0</span>] = imageSize - borderWidth - <span class="number">2</span> * r;</span><br><span class="line">      itemConfig.itemLoaction[<span class="number">4</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">      itemConfig.subtractLocation = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">5</span>][<span class="number">2</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">0</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">0</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">1</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">1</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">1</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">2</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">2</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">2</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">3</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">4</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">3</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">4</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">3</span>][<span class="number">1</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">4</span>][<span class="number">0</span>] = itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">0</span>] - itemConfig.itemLoaction[<span class="number">4</span>][<span class="number">0</span>];</span><br><span class="line">      itemConfig.subtractLocation[<span class="number">4</span>][<span class="number">1</span>] = itemConfig.itemLoaction[<span class="number">0</span>][<span class="number">1</span>] - itemConfig.itemLoaction[<span class="number">4</span>][<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="绘制圆形头像"><a href="#绘制圆形头像" class="headerlink" title="绘制圆形头像"></a>绘制圆形头像</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ItemConfig itemConfig = calcLocation(<span class="number">480</span>, <span class="number">5</span>);</span><br><span class="line">BufferedImage imageNew = <span class="keyword">new</span> BufferedImage(<span class="number">480</span>, <span class="number">480</span>, BufferedImage.TYPE_INT_RGB);</span><br><span class="line">Graphics2D graphics2DNew = imageNew.createGraphics();</span><br><span class="line">graphics2DNew.setColor(Color.white);</span><br><span class="line">graphics2DNew.fillRect(<span class="number">0</span>, <span class="number">0</span>, <span class="number">480</span>, <span class="number">480</span>);</span><br><span class="line">graphics2DNew.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);</span><br><span class="line">graphics2DNew.setRenderingHint(RenderingHints.KEY_TEXT_ANTIALIASING, RenderingHints.VALUE_TEXT_ANTIALIAS_ON);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; itemConfig.itemLoaction.length; i++) &#123;</span><br><span class="line">  String fileName = urls.get(i);</span><br><span class="line">  Area tempArea = <span class="keyword">new</span> Area();</span><br><span class="line">  Ellipse2D.Double circle0 = <span class="keyword">new</span> Ellipse2D.Double(<span class="number">10</span>, <span class="number">10</span>, itemConfig.itemSize - <span class="number">2</span> * itemConfig.whiteSize,</span><br><span class="line">  itemConfig.itemSize - <span class="number">2</span> * itemConfig.whiteSize);</span><br><span class="line">  tempArea.add(<span class="keyword">new</span> Area(circle0));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (itemConfig.subtractLocation != <span class="keyword">null</span> &amp;&amp; itemConfig.subtractLocation[i] != <span class="keyword">null</span>) &#123;</span><br><span class="line">    Ellipse2D.Double circle1 = <span class="keyword">new</span> Ellipse2D.Double(itemConfig.subtractLocation[i][<span class="number">0</span>],</span><br><span class="line">    itemConfig.subtractLocation[i][<span class="number">1</span>], itemConfig.itemSize, itemConfig.itemSize);</span><br><span class="line">    tempArea.subtract(<span class="keyword">new</span> Area(circle1));</span><br><span class="line">  &#125;</span><br><span class="line">  graphics2DNew.drawImage(fillImageToModel(fileName, itemConfig.itemSize, tempArea),</span><br><span class="line">  itemConfig.itemLoaction[i][<span class="number">0</span>], itemConfig.itemLoaction[i][<span class="number">1</span>], <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line">graphics2DNew.dispose();</span><br><span class="line"><span class="keyword">return</span> imageNew;</span><br></pre></td></tr></table></figure>


<p>效果上面已经有了…</p>
<hr>
<p>参考文献:</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
      </tags>
  </entry>
  <entry>
    <title>JDBC-根据数据表生成Entity</title>
    <url>/Java/skill/JDBC-generate-entity/</url>
    <content><![CDATA[<p><a href="/Java/jdbc/">上文</a> 主要介绍了JDBC的使用和目前框架中的优化等，本上主要介绍一个非常实用的例子: <strong>根据数据表生成Entity</strong></p>
<h1 id="Entity"><a href="#Entity" class="headerlink" title="Entity"></a>Entity</h1><p><code>Entity</code>或者<code>DTO</code>是Java中与数据表相对应的实体，将对象的属性封装有利于数据操作(如从数据库中读取某个实体，对这个实体操作，修改，新增等)，根据数据表生成Entity是必须应对的问题（当然可以选择手动敲），目前常用的方法有：</p>
<ul>
<li>Hibernate工具: Eclipse和Intellij IDEA有相应的插件</li>
<li>Mybatis-generator: 是生成Mybatis的Mapper、Entity和Dao的工具，<a href="JavaWeb/MyBatis/generator/">关于如何与Maven结合使用请参考</a></li>
</ul>
<p>本文编写的工具，直接使用JDBC API编写，不依赖IDE和ORM。</p>
<h1 id="DatabaseMetaData"><a href="#DatabaseMetaData" class="headerlink" title="DatabaseMetaData"></a>DatabaseMetaData</h1><p><a href="http://tool.oschina.net/uploads/apidocs/jdk-zh/java/sql/DatabaseMetaData.html"><code>DatabaseMetaData</code></a>是<code>java.sql</code>中提供的关于数据库整体信息的API，这个接口使用驱动程序实现的，数据库的开发商对这个接口提供支持并使用不同的方式实现。在本例中使用的是<code>MySQL</code>数据库，也是由<code>mysql-connector-java.jar</code>提供的。</p>
<p><a href="http://tool.oschina.net/uploads/apidocs/jdk-zh/java/sql/DatabaseMetaData.html"><code>DatabaseMetaData</code></a> 提高了数据库的整体信息，包括了数据表的信息。一个重要的方法:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">getColumns</span><br><span class="line"></span><br><span class="line"><span class="function">ResultSet <span class="title">getColumns</span><span class="params">(String catalog,</span></span></span><br><span class="line"><span class="function"><span class="params">                     String schemaPattern,</span></span></span><br><span class="line"><span class="function"><span class="params">                     String tableNamePattern,</span></span></span><br><span class="line"><span class="function"><span class="params">                     String columnNamePattern)</span></span></span><br><span class="line"><span class="function">                     <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">获取可在指定类别中使用的表列的描述。</span></span><br><span class="line"><span class="function">仅返回与类别、模式、表和列名称标准匹配的列描述。它们根据 TABLE_CAT、TABLE_SCHEM、TABLE_NAME 和 ORDINAL_POSITION 进行排序。</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">每个列描述都有以下列：</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  TABLE_CAT String </span>=&gt; 表类别（可为 <span class="keyword">null</span>）</span><br><span class="line">  TABLE_SCHEM String =&gt; 表模式（可为 <span class="keyword">null</span>）</span><br><span class="line">  TABLE_NAME String =&gt; 表名称</span><br><span class="line">  COLUMN_NAME String =&gt; 列名称</span><br><span class="line">  DATA_TYPE <span class="keyword">int</span> =&gt; 来自 java.sql.Types 的 SQL 类型</span><br><span class="line">  TYPE_NAME String =&gt; 数据源依赖的类型名称，对于 UDT，该类型名称是完全限定的</span><br><span class="line">  COLUMN_SIZE <span class="keyword">int</span> =&gt; 列的大小。</span><br><span class="line">  BUFFER_LENGTH 未被使用。</span><br><span class="line">  DECIMAL_DIGITS <span class="keyword">int</span> =&gt; 小数部分的位数。对于 DECIMAL_DIGITS 不适用的数据类型，则返回 Null。</span><br><span class="line">  NUM_PREC_RADIX <span class="keyword">int</span> =&gt; 基数（通常为 <span class="number">10</span> 或 <span class="number">2</span>）</span><br><span class="line">  NULLABLE <span class="keyword">int</span> =&gt; 是否允许使用 NULL。</span><br><span class="line">  columnNoNulls - 可能不允许使用 NULL 值</span><br><span class="line">  columnNullable - 明确允许使用 NULL 值</span><br><span class="line">  columnNullableUnknown - 不知道是否可使用 <span class="keyword">null</span></span><br><span class="line">  REMARKS String =&gt; 描述列的注释（可为 <span class="keyword">null</span>）</span><br><span class="line">  COLUMN_DEF String =&gt; 该列的默认值，当值在单引号内时应被解释为一个字符串（可为 <span class="keyword">null</span>）</span><br><span class="line">  SQL_DATA_TYPE <span class="keyword">int</span> =&gt; 未使用</span><br><span class="line">  SQL_DATETIME_SUB <span class="keyword">int</span> =&gt; 未使用</span><br><span class="line">  CHAR_OCTET_LENGTH <span class="keyword">int</span> =&gt; 对于 <span class="keyword">char</span> 类型，该长度是列中的最大字节数</span><br><span class="line">  ORDINAL_POSITION <span class="keyword">int</span> =&gt; 表中的列的索引（从 <span class="number">1</span> 开始）</span><br><span class="line">  IS_NULLABLE String =&gt; ISO 规则用于确定列是否包括 <span class="keyword">null</span>。</span><br><span class="line">  YES --- 如果参数可以包括 NULL</span><br><span class="line">  NO --- 如果参数不可以包括 NULL</span><br><span class="line">  空字符串 --- 如果不知道参数是否可以包括 <span class="keyword">null</span></span><br><span class="line">  SCOPE_CATLOG String =&gt; 表的类别，它是引用属性的作用域（如果 DATA_TYPE 不是 REF，则为 <span class="keyword">null</span>）</span><br><span class="line">  SCOPE_SCHEMA String =&gt; 表的模式，它是引用属性的作用域（如果 DATA_TYPE 不是 REF，则为 <span class="keyword">null</span>）</span><br><span class="line">  SCOPE_TABLE String =&gt; 表名称，它是引用属性的作用域（如果 DATA_TYPE 不是 REF，则为 <span class="keyword">null</span>）</span><br><span class="line">  SOURCE_DATA_TYPE <span class="keyword">short</span> =&gt; 不同类型或用户生成 Ref 类型、来自 java.sql.Types 的 SQL 类型的源类型（如果 DATA_TYPE 不是 DISTINCT 或用户生成的 REF，则为 <span class="keyword">null</span>）</span><br><span class="line">  IS_AUTOINCREMENT String =&gt; 指示此列是否自动增加</span><br><span class="line">    YES --- 如果该列自动增加</span><br><span class="line">    NO --- 如果该列不自动增加</span><br><span class="line">    空字符串 --- 如果不能确定该列是否是自动增加参数</span><br><span class="line">  COLUMN_SIZE 列表示给定列的指定列大小。对于数值数据，这是最大精度。对于字符数据，这是字符长度。对于日期时间数据类型，这是 String 表示形式的字符长度（假定允许的最大小数秒组件的精度）。对于二进制数据，这是字节长度。对于 ROWID 数据类型，这是字节长度。对于列大小不适用的数据类型，则返回 Null。</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line">  catalog - 类别名称；它必须与存储在数据库中的类别名称匹配；该参数为 <span class="string">&quot;&quot;</span> 表示获取没有类别的那些描述；为 <span class="keyword">null</span> 则表示该类别名称不应该用于缩小搜索范围</span><br><span class="line">  schemaPattern - 模式名称的模式；它必须与存储在数据库中的模式名称匹配；该参数为 <span class="string">&quot;&quot;</span> 表示获取没有模式的那些描述；为 <span class="keyword">null</span> 则表示该模式名称不应该用于缩小搜索范围</span><br><span class="line">  tableNamePattern - 表名称模式；它必须与存储在数据库中的表名称匹配</span><br><span class="line">  columnNamePattern - 列名称模式；它必须与存储在数据库中的列名称匹配</span><br><span class="line">返回：</span><br><span class="line">	ResultSet - 每一行都是一个列描述</span><br><span class="line">抛出：</span><br><span class="line">	SQLException - 如果发生数据库访问错误</span><br><span class="line">另请参见：</span><br><span class="line">	getSearchStringEscape()</span><br></pre></td></tr></table></figure>


<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Connection conn = DatabaseUtils.openConnection(); <span class="comment">// 得到数据库连接</span></span><br><span class="line">DatabaseMetaData databaseMetaData = conn.getMetaData();<span class="comment">// 获取数据库 MetaData</span></span><br><span class="line"><span class="comment">//获取数据表的表列描述,存放到 ResultSet</span></span><br><span class="line">ResultSet resultSet = databaseMetaData.getColumns(<span class="keyword">null</span>, <span class="string">&quot;%&quot;</span>, tableName, <span class="string">&quot;%&quot;</span>);</span><br><span class="line"><span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">  String columnName = resultSet.getString(<span class="string">&quot;COLUMN_NAME&quot;</span>); <span class="comment">//获取列名</span></span><br><span class="line">  String dataType = resultSet.getString(<span class="string">&quot;TYPE_NAME&quot;</span>); <span class="comment">//列的数据类型</span></span><br><span class="line">  <span class="keyword">int</span> columnSize = resultSet.getInt(<span class="string">&quot;COLUMN_SIZE&quot;</span>); <span class="comment">//列的大小</span></span><br><span class="line">  String remarks = resultSet.getString(<span class="string">&quot;REMARKS&quot;</span>); <span class="comment">//列的备注</span></span><br><span class="line">  colnames.add(getCamelStr(columnName));</span><br><span class="line">  colTypes.add(dataType);</span><br><span class="line">  colSizes.add(columnSize);</span><br><span class="line">  comments.add(remarks);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="生成类"><a href="#生成类" class="headerlink" title="生成类"></a>生成类</h1><p>生成POJO，包含字段和Setter和Getter</p>
<h2 id="生成字段"><a href="#生成字段" class="headerlink" title="生成字段"></a>生成字段</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解析输出属性</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processAllAttrs</span><span class="params">(StringBuffer sb)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colnames.size(); i++) &#123;</span><br><span class="line">    String colName = colnames.get(i);</span><br><span class="line">    String colType = colTypes.get(i);</span><br><span class="line">    String comment = comments.get(i);</span><br><span class="line">    <span class="keyword">if</span> (comments != <span class="keyword">null</span> &amp;&amp; colName != <span class="keyword">null</span>) &#123;</span><br><span class="line">      sb.append(<span class="string">&quot;\t/**\n\t *  &quot;</span> + comment + <span class="string">&quot;\n\t **/\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    sb.append(<span class="string">&quot;\tprivate &quot;</span> + sqlType2JavaType(colType) + <span class="string">&quot; &quot;</span> + colName + <span class="string">&quot;;\r\n&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="生成Getter和Setter"><a href="#生成Getter和Setter" class="headerlink" title="生成Getter和Setter"></a>生成Getter和Setter</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colnames.size(); i++) &#123;</span><br><span class="line">  String colName = colnames.get(i);</span><br><span class="line">  String colType = colTypes.get(i);</span><br><span class="line">  sb.append(<span class="string">&quot;\tpublic void set&quot;</span> + initcap(colName) + <span class="string">&quot;(&quot;</span> + sqlType2JavaType(colType) + <span class="string">&quot; &quot;</span> + colName</span><br><span class="line">            + <span class="string">&quot;)&#123;\r\n&quot;</span>);</span><br><span class="line">  sb.append(<span class="string">&quot;\t\tthis.&quot;</span> + colName + <span class="string">&quot;=&quot;</span> + colName + <span class="string">&quot;;\r\n&quot;</span>);</span><br><span class="line">  sb.append(<span class="string">&quot;\t&#125;\r\n\r\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">  sb.append(<span class="string">&quot;\tpublic &quot;</span> + sqlType2JavaType(colType) + <span class="string">&quot; get&quot;</span> + initcap(colName) + <span class="string">&quot;()&#123;\r\n&quot;</span>);</span><br><span class="line">  sb.append(<span class="string">&quot;\t\treturn &quot;</span> + colName + <span class="string">&quot;;\r\n&quot;</span>);</span><br><span class="line">  sb.append(<span class="string">&quot;\t&#125;\r\n\r\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="组合成类文件"><a href="#组合成类文件" class="headerlink" title="组合成类文件"></a>组合成类文件</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">sb.append(<span class="string">&quot;package &quot;</span> + packagePath + <span class="string">&quot;;\r\n\r\n&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (needUtilPacket) &#123;</span><br><span class="line">	sb.append(<span class="string">&quot;import java.util.Date;\r\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (needSqlPacket) &#123;</span><br><span class="line">	sb.append(<span class="string">&quot;import java.sql.*;\r\n\r\n\r\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">sb.append(<span class="string">&quot;public class &quot;</span> + initcap(tableName) + <span class="string">&quot; &#123;\r\n\r\n&quot;</span>);</span><br><span class="line">processAllAttrs(sb);<span class="comment">//生成字段</span></span><br><span class="line">sb.append(<span class="string">&quot;\r\n&quot;</span>);</span><br><span class="line">generatGetterSetter(sb);<span class="comment">//生成getter和setter</span></span><br><span class="line">sb.append(<span class="string">&quot;&#125;\r\n&quot;</span>);</span><br><span class="line">System.out.println(sb.toString());</span><br><span class="line"><span class="keyword">return</span> sb.toString();</span><br></pre></td></tr></table></figure>


<hr>
<p>【参考文献】</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>Java图片处理一(压缩图片与生成微信头像)</title>
    <url>/Java/skill/Image-zip-square-portrait/</url>
    <content><![CDATA[<h1 id="读入图片-本地图片和网络图片"><a href="#读入图片-本地图片和网络图片" class="headerlink" title="读入图片(本地图片和网络图片)"></a>读入图片(本地图片和网络图片)</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">InputStream <span class="title">readImageFromPath</span><span class="params">(String filePath)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (filePath.startsWith(<span class="string">&quot;http&quot;</span>)) &#123;</span><br><span class="line">            URL url = <span class="keyword">null</span>;</span><br><span class="line">            HttpURLConnection conn;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                url = <span class="keyword">new</span> URL(filePath);</span><br><span class="line">                conn = (HttpURLConnection) url.openConnection();</span><br><span class="line">                conn.setDoInput(<span class="keyword">true</span>);</span><br><span class="line">                conn.connect();</span><br><span class="line">                InputStream inputStream = conn.getInputStream();</span><br><span class="line">                <span class="keyword">return</span> inputStream;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (MalformedURLException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(filePath));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// BufferedImage bi = ImageIO.read(readImageFromPath(filePath));</span></span><br></pre></td></tr></table></figure>
<h1 id="压缩图像"><a href="#压缩图像" class="headerlink" title="压缩图像"></a>压缩图像</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 图片缩放</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> filePath</span></span><br><span class="line"><span class="comment"> *            图片路径</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> height</span></span><br><span class="line"><span class="comment"> *            高度</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> width</span></span><br><span class="line"><span class="comment"> *            宽度</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> bb</span></span><br><span class="line"><span class="comment"> *            比例不对时是否需要补白</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">BufferedImage <span class="title">resize2</span><span class="params">(String filePath, <span class="keyword">int</span> height, <span class="keyword">int</span> width, <span class="keyword">boolean</span> bb)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="keyword">double</span> ratio = <span class="number">0</span>; <span class="comment">// 缩放比例</span></span><br><span class="line">		BufferedImage bi = ImageIO.read(readImageFromPath(filePath));</span><br><span class="line">		Image itemp = bi.getScaledInstance(width, height,</span><br><span class="line">				Image.SCALE_SMOOTH);</span><br><span class="line">		<span class="comment">// 计算比例</span></span><br><span class="line">		<span class="keyword">if</span> ((bi.getHeight() &gt; height) || (bi.getWidth() &gt; width)) &#123;</span><br><span class="line">			<span class="keyword">if</span> (bi.getHeight() &gt; bi.getWidth()) &#123;</span><br><span class="line">				ratio = (<span class="keyword">new</span> Integer(height)).doubleValue()</span><br><span class="line">						/ bi.getHeight();</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				ratio = (<span class="keyword">new</span> Integer(width)).doubleValue() / bi.getWidth();</span><br><span class="line">			&#125;</span><br><span class="line">			AffineTransformOp op = <span class="keyword">new</span> AffineTransformOp(</span><br><span class="line">					AffineTransform.getScaleInstance(ratio, ratio), <span class="keyword">null</span>);</span><br><span class="line">			itemp = op.filter(bi, <span class="keyword">null</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (bb) &#123;</span><br><span class="line">			BufferedImage image = <span class="keyword">new</span> BufferedImage(width, height,</span><br><span class="line">					BufferedImage.TYPE_INT_RGB);</span><br><span class="line">			Graphics2D g = image.createGraphics();</span><br><span class="line">			g.setColor(Color.white);</span><br><span class="line">			g.fillRect(<span class="number">0</span>, <span class="number">0</span>, width, height);</span><br><span class="line">			<span class="keyword">if</span> (width == itemp.getWidth(<span class="keyword">null</span>))</span><br><span class="line">				g.drawImage(itemp, <span class="number">0</span>, (height - itemp.getHeight(<span class="keyword">null</span>)) / <span class="number">2</span>,</span><br><span class="line">						itemp.getWidth(<span class="keyword">null</span>), itemp.getHeight(<span class="keyword">null</span>),</span><br><span class="line">						Color.white, <span class="keyword">null</span>);</span><br><span class="line">			<span class="keyword">else</span></span><br><span class="line">				g.drawImage(itemp, (width - itemp.getWidth(<span class="keyword">null</span>)) / <span class="number">2</span>, <span class="number">0</span>,</span><br><span class="line">						itemp.getWidth(<span class="keyword">null</span>), itemp.getHeight(<span class="keyword">null</span>),</span><br><span class="line">						Color.white, <span class="keyword">null</span>);</span><br><span class="line">			g.dispose();</span><br><span class="line">			itemp = image;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> (BufferedImage) itemp;</span><br><span class="line">	&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">		e.printStackTrace();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="生成微信头像"><a href="#生成微信头像" class="headerlink" title="生成微信头像"></a>生成微信头像</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImageElement</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> left;</span><br><span class="line">	<span class="keyword">int</span> top;</span><br><span class="line">	BufferedImage bufferedImage;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 最多行列数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> MAX_GRIDS = <span class="number">3</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 行间距</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> spacing = <span class="number">5</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 边距</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> border = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 图片的目标大小</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> width = <span class="number">200</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">ImageCombinationUtil</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 生成组合头像</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> paths</span></span><br><span class="line"><span class="comment"> *            用户图像</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getCombinationOfhead</span><span class="params">(List&lt;String&gt; paths)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> pathSize = paths.size();</span><br><span class="line">	<span class="keyword">if</span> (pathSize == <span class="number">0</span>) &#123;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">final</span> <span class="keyword">int</span> maxImageCount = MAX_GRIDS * MAX_GRIDS;</span><br><span class="line">	<span class="keyword">int</span> imageCount = pathSize &gt; maxImageCount ? maxImageCount : pathSize;</span><br><span class="line">	<span class="keyword">int</span> grids = (<span class="keyword">int</span>) Math.ceil(Math.sqrt(imageCount));</span><br><span class="line">	grids = grids &gt; MAX_GRIDS ? MAX_GRIDS : grids;</span><br><span class="line">	<span class="keyword">int</span> hrow = imageCount / grids;</span><br><span class="line">	<span class="keyword">int</span> rows = hrow + (imageCount - hrow * grids &gt; <span class="number">0</span> ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">	<span class="keyword">int</span> columnCountOfLastRow = imageCount - (rows - <span class="number">1</span>) * grids;</span><br><span class="line">	<span class="keyword">int</span> columns = imageCount / rows;</span><br><span class="line">	columns = imageCount - columns * rows &gt; <span class="number">0</span> ? columns + <span class="number">1</span> : columns;</span><br><span class="line">	System.out.println(<span class="string">&quot;imageCount :&quot;</span> + pathSize + <span class="string">&quot;\t grids :&quot;</span> + grids</span><br><span class="line">			+ <span class="string">&quot;\trows:&quot;</span> + rows + <span class="string">&quot;\t columns:&quot;</span> + columns</span><br><span class="line">			+ <span class="string">&quot;\t columnsOfLastRow:&quot;</span> + columnCountOfLastRow);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span>[] matrix = <span class="keyword">new</span> <span class="keyword">int</span>[rows];</span><br><span class="line">	Arrays.fill(matrix, grids);</span><br><span class="line">	matrix[<span class="number">0</span>] = columnCountOfLastRow;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 计算每个图片的尺寸</span></span><br><span class="line">	<span class="keyword">int</span> imageMeasure = (width - <span class="number">2</span> * border - (grids - <span class="number">1</span>)</span><br><span class="line">			* spacing)</span><br><span class="line">			/ grids;</span><br><span class="line"></span><br><span class="line">	List&lt;ImageElement&gt; imageElements = <span class="keyword">new</span> ArrayList&lt;ImageElement&gt;();</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; imageCount; i++) &#123;</span><br><span class="line">		ImageElement imageMatrix = <span class="keyword">new</span> ImageElement();</span><br><span class="line">		imageMatrix.bufferedImage = ImageCombinationUtil.resize2(paths.get(i),</span><br><span class="line">				imageMeasure, imageMeasure, <span class="keyword">true</span>);</span><br><span class="line">		imageElements.add(imageMatrix);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 计算坐标</span></span><br><span class="line">	<span class="keyword">int</span> top = border;</span><br><span class="line">	top = rows &lt; grids ? top + (spacing + imageMeasure) * (grids - rows)</span><br><span class="line">			/ <span class="number">2</span> : top;</span><br><span class="line">	<span class="keyword">int</span> imageIndex = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> row = <span class="number">0</span>; row &lt; matrix.length; row++) &#123;</span><br><span class="line">		<span class="keyword">int</span> column = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">int</span> left = border;</span><br><span class="line">		left = matrix[row] &lt; grids ? left + (spacing + imageMeasure)</span><br><span class="line">				* (grids - matrix[row])/<span class="number">2</span> : left;</span><br><span class="line">		<span class="keyword">while</span> (column &lt; matrix[row]) &#123;</span><br><span class="line">			imageElements.get(imageIndex).left = left + column</span><br><span class="line">					* (imageMeasure + spacing);</span><br><span class="line">			imageElements.get(imageIndex).top = top + row</span><br><span class="line">					* (imageMeasure + spacing);</span><br><span class="line">			imageIndex++;</span><br><span class="line">			column++;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 创建画板</span></span><br><span class="line">	BufferedImage outImage1 = <span class="keyword">new</span> BufferedImage(width,</span><br><span class="line">			width, BufferedImage.TYPE_INT_RGB);</span><br><span class="line">	<span class="comment">// 生成画布</span></span><br><span class="line">	Graphics g = outImage1.getGraphics();</span><br><span class="line">	Graphics2D g2d = (Graphics2D) g;</span><br><span class="line">	<span class="comment">// 设置背景色</span></span><br><span class="line">	g2d.setBackground(<span class="keyword">new</span> Color(<span class="number">231</span>, <span class="number">231</span>, <span class="number">231</span>));</span><br><span class="line">	<span class="comment">// 通过使用当前绘图表面的背景色进行填充来清除指定的矩形。</span></span><br><span class="line">	g2d.clearRect(<span class="number">0</span>, <span class="number">0</span>, width, width);</span><br><span class="line">	<span class="comment">// 绘制</span></span><br><span class="line">	<span class="keyword">for</span> (ImageElement imageElement : imageElements) &#123;</span><br><span class="line">		g2d.drawImage(imageElement.bufferedImage, imageElement.left,</span><br><span class="line">				imageElement.top, <span class="keyword">null</span>);</span><br><span class="line">		<span class="comment">// 需要改变颜色的话在这里绘上颜色。可能会用到AlphaComposite类</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	String outPath = <span class="string">&quot;d:\\&quot;</span> + System.currentTimeMillis() + <span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">	String format = <span class="string">&quot;JPG&quot;</span>;</span><br><span class="line">	ImageIO.write(outImage1, format, <span class="keyword">new</span> File(outPath));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>效果</p>
<p><img src="/images/java/util/imageCombinResult.png"></p>
<h1 id="图像转化为InputStream"><a href="#图像转化为InputStream" class="headerlink" title="图像转化为InputStream"></a>图像转化为InputStream</h1><p>方便直接从内存上传到服务器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">InputStream <span class="title">image2InputStream</span><span class="params">(BufferedImage bufferedImage)</span> </span>&#123;</span><br><span class="line">	InputStream inputStream = <span class="keyword">null</span>;</span><br><span class="line">	ByteArrayOutputStream outputStream = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">	ImageOutputStream imageOutputStream = <span class="keyword">null</span>;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		imageOutputStream = ImageIO.createImageOutputStream(outputStream);</span><br><span class="line">		ImageIO.write(bufferedImage, <span class="string">&quot;JPG&quot;</span>, imageOutputStream);</span><br><span class="line">		inputStream = <span class="keyword">new</span> ByteArrayInputStream(outputStream.toByteArray());</span><br><span class="line">	&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">		e.printStackTrace();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> inputStream;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
      </tags>
  </entry>
  <entry>
    <title>pinyin4j</title>
    <url>/Java/skill/pinyin4j/</url>
    <content><![CDATA[<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">String <span class="title">cn2Spell</span><span class="params">(String chinese)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (chinese == <span class="keyword">null</span> || chinese.equals(<span class="string">&quot;&quot;</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        StringBuffer pybf = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        <span class="keyword">char</span>[] arr = chinese.toCharArray();</span><br><span class="line">        HanyuPinyinOutputFormat defaultFormat = <span class="keyword">new</span> HanyuPinyinOutputFormat();</span><br><span class="line">        defaultFormat.setCaseType(HanyuPinyinCaseType.LOWERCASE);</span><br><span class="line">        defaultFormat.setToneType(HanyuPinyinToneType.WITHOUT_TONE);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; arr.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[i] &gt; <span class="number">128</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    String[] str = PinyinHelper.toHanyuPinyinStringArray(</span><br><span class="line">                            arr[i], defaultFormat);</span><br><span class="line">                    <span class="keyword">if</span> (str == <span class="keyword">null</span> || str.length == <span class="number">0</span>) &#123;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    pybf.append(PinyinHelper.toHanyuPinyinStringArray(</span><br><span class="line">                            arr[i], defaultFormat)[<span class="number">0</span>]);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (BadHanyuPinyinOutputFormatCombination e) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                pybf.append(arr[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> pybf.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>pinyin</tag>
      </tags>
  </entry>
  <entry>
    <title>正则表达式</title>
    <url>/Java/tool/01.%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="01-正则表达式"><a href="#01-正则表达式" class="headerlink" title="01.正则表达式"></a>01.正则表达式</h1><p>To use regular expressions effectively in Java, you need to know the syntax. The syntax is extensive, enabling you to write very advanced regular expressions. It may take a lot of exercise to fully master the syntax.</p>
<p>In this text I will go through the basics of the syntax with examples. I will not cover every little detail of the syntax, but focus on the main concepts you need to understand, in order to work with regular expressions. For a full explanation, see the <a href="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html"><code>Pattern</code> class JavaDoc page</a>.</p>
<p>Before showing all the advanced options you can use in Java regular expressions, I will give you a quick run-down of the Java regular expression syntax basics.</p>
<p>The most basic form of regular expressions is an expression that simply matches certain characters. Here is an example:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>This simple regular expression will match occurences of the text “John” in a given input text.</p>
<p>You can use any characters in the alphabet in a regular expression.</p>
<p>You can also refer to characters via their octal, hexadecimal or unicode codes. Here are two examples:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>These three expressions all refer to the uppercase <code>A</code> character. The first uses the octal code (<code>101</code>) for <code>A</code>, the second uses the hexadecimal code (<code>41</code>) and the third uses the unicode code (<code>0041</code>).</p>
<p>Character classes are constructst that enable you to specify a match against multiple characters instead of just one. In other words, a character class matches a single character in the input text against multiple allowed characters in the character class. For instance, you can match either of the characters <code>a</code>, <code>b</code> or <code>c</code> like this:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>Character classes are nested inside a pair of square brackets <code>[]</code>. The brackets themselves are not part of what is being matched.</p>
<p>You can use character classes for many things. For instance, this example finds all occurrences of the word <code>John</code>, with either a lowercase or uppercase <code>J</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The character class <code>[Jj]</code> will match either a <code>J</code> or a <code>j</code>, and the rest of the expression will match the characters <code>ohn</code> in that exact sequence.</p>
<p>There are several other character classes you can use. See the character class table later in this text.</p>
<p>The Java regular expression syntax has a few predefined character classes you can use. For instance, the <code>\d</code> character class matches any digit, the <code>\s</code> character class matches any white space character, and the <code>\w</code> character matches any word character.</p>
<p>The predefined character classes do not have to be enclosed in square brackets, but you can if you want to combine them. Here are a few examples:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The first example matches any digit character. The second example matches any digit or any white space character.</p>
<p>The predefined character classes are listed in a table later in this text.</p>
<p>The syntax also include matchers for matching boundaries, like boundaries between words, the beginning and end of the input text etc. For instance, the <code>\w</code> matches boundaries between words, the <code>^</code> matches the beginning of a line, and the <code>$</code> matches the end of a line.</p>
<p>Here is a boundary matcher example:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>This expression matches a line of text with only the text <code>This is a single line</code>. Notice the start-of-line and end-of-line matchers in the expression. These state that there can be nothing before or after the text, except the beginning and end of a line.</p>
<p>There is a full list of boundary matchers later in this text.</p>
<p>Quantifiers enables you to match a given expression or subexpression multiple times. For instance, the following expression matches the letter <code>A</code> zero or more times:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The <code>*</code> character is a quantifier that means “zero or more times”. There is also a <code>+</code> quantifier meaning “one or more times”, a <code>?</code> quantifier meaning “zero or one time”, and a few others which you can see in the quantifier table later in this text.</p>
<p>Quantifiers can be either “reluctant”, “greedy” or “possesive”. A reluctant quantifier will match as little as possible of the input text. A greedy quantifier will match as much as possible of the input text. A possesive quantifier will match as much as possible, even if it makes the rest of the expression not match anything, and the expression to fail finding a match.</p>
<p>I will illustrate the difference between reluctant, greedy and possesive quantifiers with an example. Here is an input text:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>Then look at the following expression with a reluctant quantifier:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>This expression will match the word <code>John</code> followed by zero or more characters The <code>.</code> means “any character”, and the <code>*</code> means “zero or more times”. The <code>?</code> after the <code>*</code> makes the <code>*</code> a reluctant quantifier.</p>
<p>Being a reluctant quantifier, the quantifier will match as little as possible, meaning zero characters. The expression will thus find the word <code>John</code> with zero characters after, 3 times in the above input text.</p>
<p>If we change the quantifier to a greedy quantifier, the expression will look like this:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The greedy quantifier will match as many characters as possible. Now the expression will only match the first occurrence of <code>John</code>, and the greedy quantifier will match the rest of the characters in the input text. Thus, only a single match is found.</p>
<p>Finally, lets us change the expression a bit to contain a possesive quantifier:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The <code>+</code> after the <code>*</code> makes it a possesive quantifier.</p>
<p>This expression will not match the input text given above, even if both the words <code>John</code> and <code>hurt</code> are found in the input text. Why is that? Because the <code>.*+</code> is possesive. Instead of matching as much as possible to make the expression match, as a greedy quantifier would have done, the possesive quantifier matches as much as possible, regardless of whether the expression will match or not.</p>
<p>The <code>.*+</code> will match all characters after the first occurrence of <code>John</code> in the input text, including the word <code>hurt</code>. Thus, there is no <code>hurt</code> word left to match, when the possesive quantifier has claimed its match.</p>
<p>If you change the quantifier to a greedy quantifier, the expression will match the input text one time. Here is how the expression looks with a greedy quantifier:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>You will have to play around with the different quantifiers and types to understand how they work. See the table later in this text for a full list of quantifiers.</p>
<p>The Java regular expression syntax also has support for a few logical operators (and, or, not).</p>
<p>The <code>and</code> operator is implicit. When you write the expression <code>John</code>, then it means “<code>J</code> and <code>o</code> and <code>h</code> and <code>n</code>“.</p>
<p>The <code>or</code> operator is explicit, and is written with a <code>|</code>. For instance, the expression <code>John|hurt</code> will match either the word <code>John</code>, or the word <code>hurt</code>.</p>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>x</code></td>
<td>The character x. Any character in the alphabet can be used in place of x.</td>
</tr>
<tr>
<td><code>\\</code></td>
<td>The backslash character. A single backslash is used as escape character in conjunction with other characters to signal special matching, so to match just the backslash character itself, you need to escape with a backslash character. Hence the double backslash to match a single backslash character.</td>
</tr>
<tr>
<td><code>\0n</code></td>
<td>The character with octal value <code>0n</code>. n has to be between 0 and 7.</td>
</tr>
<tr>
<td><code>\0nn</code></td>
<td>The character with octal value <code>0nn</code>. n has to be between 0 and 7.</td>
</tr>
<tr>
<td><code>\0mnn</code></td>
<td>The character with octal value <code>0mnn</code>. m has to be between 0 and 3, n has to be between 0 and 7.</td>
</tr>
<tr>
<td><code>\xhh</code></td>
<td>The character with the hexadecimal value <code>0xhh</code>.</td>
</tr>
<tr>
<td><code>\uhhhh</code></td>
<td>The character with the hexadecimal value <code>0xhhhh</code>. This construct is used to match unicode characters.</td>
</tr>
<tr>
<td><code>\t</code></td>
<td>The tab character.</td>
</tr>
<tr>
<td><code>\n</code></td>
<td>The newline (line feed) character (unicode: <code>&#39;\u000A&#39;</code>).</td>
</tr>
<tr>
<td><code>\r</code></td>
<td>The carriage-return character (unicode: <code>&#39;\u000D&#39;</code>).</td>
</tr>
<tr>
<td><code>\f</code></td>
<td>The form-feed character (unicode: <code>&#39;\u000C&#39;</code>).</td>
</tr>
<tr>
<td><code>\a</code></td>
<td>The alert (bell) character (unicode: <code>&#39;\u0007&#39;</code>).</td>
</tr>
<tr>
<td><code>\e</code></td>
<td>The escape character (unicode: <code>&#39;\u001B&#39;</code>).</td>
</tr>
<tr>
<td><code>\cx</code></td>
<td>The control character corresponding to <code>x</code></td>
</tr>
<tr>
<td>``</td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>[abc]</code></td>
<td>Matches <code>a</code>, or <code>b</code> or <code>c</code>. This is called a simple class, and it matches any of the characters in the class.</td>
</tr>
<tr>
<td><code>[^abc]</code></td>
<td>Matches any character except <code>a</code>, <code>b</code>, and <code>c</code>. This is a negation.</td>
</tr>
<tr>
<td><code>[a-zA-Z]</code></td>
<td>Matches any character from <code>a</code> to <code>z</code>, or <code>A</code> to <code>Z</code>, including <code>a</code>, <code>A</code>, <code>z</code> and <code>Z</code>. This called a range.</td>
</tr>
<tr>
<td><code>[a-d[m-p]]</code></td>
<td>Matches any character from <code>a</code> to <code>d</code>, or from <code>m</code> to <code>p</code>. This is called a union.</td>
</tr>
<tr>
<td><code>[a-z&amp;&amp;[def]]</code></td>
<td>Matches <code>d</code>, <code>e</code>, or <code>f</code>. This is called an intersection (here between the range <code>a-z</code> and the characters <code>def</code>).</td>
</tr>
<tr>
<td><code>[a-z&amp;&amp;[^bc]]</code></td>
<td>Matches all characters from <code>a</code> to <code>z</code> except <code>b</code> and <code>c</code>. This is called a subtraction.</td>
</tr>
<tr>
<td><code>[a-z&amp;&amp;[^m-p]]</code></td>
<td>Matches all characters from <code>a</code> to <code>z</code> except the characters from <code>m</code> to <code>p</code>. This is also called a subtraction.</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>.</code></td>
<td>Matches any single character. May or may not match line terminators, depending on what flags were used to compile the <code>Pattern</code>.</td>
</tr>
<tr>
<td><code>\d</code></td>
<td>Matches any digit [0-9]</td>
</tr>
<tr>
<td><code>\D</code></td>
<td>Matches any non-digit character [^0-9]</td>
</tr>
<tr>
<td><code>\s</code></td>
<td>Matches any white space character (space, tab, line break, carriage return)</td>
</tr>
<tr>
<td><code>\S</code></td>
<td>Matches any non-white space character.</td>
</tr>
<tr>
<td><code>\w</code></td>
<td>Matches any word character.</td>
</tr>
<tr>
<td><code>\W</code></td>
<td>Matches any non-word character.</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>^</code></td>
<td>Matches the beginning of a line.</td>
</tr>
<tr>
<td><code>$</code></td>
<td>Matches then end of a line.</td>
</tr>
<tr>
<td><code>\b</code></td>
<td>Matches a word boundary.</td>
</tr>
<tr>
<td><code>\B</code></td>
<td>Matches a non-word boundary.</td>
</tr>
<tr>
<td><code>\A</code></td>
<td>Matches the beginning of the input text.</td>
</tr>
<tr>
<td><code>\G</code></td>
<td>Matches the end of the previous match</td>
</tr>
<tr>
<td><code>\Z</code></td>
<td>Matches the end of the input text except the final terminator if any.</td>
</tr>
<tr>
<td><code>\z</code></td>
<td>Matches the end of the input text.</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Greedy</th>
<th>Reluctant</th>
<th>Possessive</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>X?</code></td>
<td><code>X??</code></td>
<td><code>X?+</code></td>
<td>Matches X once, or not at all (0 or 1 time).</td>
</tr>
<tr>
<td><code>X*</code></td>
<td><code>X*?</code></td>
<td><code>X*+</code></td>
<td>Matches X zero or more times.</td>
</tr>
<tr>
<td><code>X+</code></td>
<td><code>X+?</code></td>
<td><code>X++</code></td>
<td>Matches X one or more times.</td>
</tr>
<tr>
<td><code>X&#123;n&#125;</code></td>
<td><code>X&#123;n&#125;?</code></td>
<td><code>X&#123;n&#125;+</code></td>
<td>Matches X exactly n times.</td>
</tr>
<tr>
<td><code>X&#123;n,&#125;</code></td>
<td><code>X&#123;n,&#125;?</code></td>
<td><code>X&#123;n,&#125;+</code></td>
<td>Matches X at least n times.</td>
</tr>
<tr>
<td><code>X&#123;n, m)</code></td>
<td><code>X&#123;n, m)?</code></td>
<td><code>X&#123;n, m)+</code></td>
<td>Matches X at least n time, but at most m times.</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>XY</code></td>
<td>Matches X and Y (X followed by Y).</td>
</tr>
<tr>
<td>`X</td>
<td>Y`</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title>磁盘Raid机制</title>
    <url>/Java/tool/02.RAID/</url>
    <content><![CDATA[<h1 id="Raid"><a href="#Raid" class="headerlink" title="Raid"></a>Raid</h1>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOS操作经验</title>
    <url>/Java/tool/04.Mac/</url>
    <content><![CDATA[<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><p>因为苹果在OS X 10.11中引入的SIP特性使得即使加了sudo（也就是具有root权限）也无法修改系统级的目录，其中就包括了/usr/bin。要解决这个问题有两种做法：</p>
<p>一种是比较不安全的就是关闭SIP，也就是rootless特性；</p>
<p>另一种是将本要链接到/usr/bin下的改链接到/usr/local/bin下就好了。</p>
<p>解决办法</p>
<p>sudo ln -s /usr/local/mysql/bin/mysql /usr/local/bin</p>
<p>mysql 启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqld --user mysql</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/Java/tool/JavaFx-3D/</url>
    <content><![CDATA[<h1 id="JavaFX-3D"><a href="#JavaFX-3D" class="headerlink" title="JavaFX 3D"></a>JavaFX 3D</h1><p><a href="https://www.genuinecoder.com/javafx-3d-transform-objects-with-keyboard-input/">JavaFX 3D Tutorial</a></p>
<p><a href="https://www.youtube.com/watch?v=TRJ0GqDBDac&list=PLhs1urmduZ295Ryetga7CNOqDymN_rhB_&index=12">more surface detail with bump mapping</a></p>
]]></content>
  </entry>
  <entry>
    <title>Linux常用shell</title>
    <url>/Java/tool/Linux-shell/</url>
    <content><![CDATA[<h1 id="Linux-shell"><a href="#Linux-shell" class="headerlink" title="Linux-shell"></a>Linux-shell</h1><h2 id="curl"><a href="#curl" class="headerlink" title="curl"></a>curl</h2><p>curl是一个很棒的命令.<br>例如目标网站Url:</p>
<pre><code>127.0.0.1:8080/check_your_status?user=Summer&amp;passwd=12345678</code></pre>
<h3 id="通过Get方法请求"><a href="#通过Get方法请求" class="headerlink" title="通过Get方法请求:"></a>通过Get方法请求:</h3><pre><code>curl protocol://address:port/url?args
curl http://127.0.0.1:8080/check_your_status?user=Summer&amp;passwd=12345678</code></pre>
<p>发送数组参数</p>
<pre><code>curl http://127.0.0.1:8080/check_yours_status?user[]=avery&amp;user[]=zhangsan</code></pre>
<p>发送包含特殊字符的参数</p>
<pre><code>curl -G --data-urlencode &#39;user[]=avery@tencent#td&#39; --data-urlencode &#39;user[]=zhangsan@tencent#bf&#39; -d &#39;tableId=913&#39; http://127.0.0.1:8080/check_yours_status</code></pre>
<p>“-G”等价于”—get”，”-d”等价于”—data”</p>
<p>从文件中获取参数</p>
<pre><code>curl --get --data @data.txt http://aiezu.com/test.php</code></pre>
<h3 id="通过Post方法请求"><a href="#通过Post方法请求" class="headerlink" title="通过Post方法请求:"></a>通过Post方法请求:</h3><pre><code>curl -d “args” “protocol://address:port/url”
curl -d “user=Summer&amp;passwd=12345678” “http://127.0.0.1:8080/check_your_status“</code></pre>
<h3 id="自定义header"><a href="#自定义header" class="headerlink" title="自定义header"></a>自定义header</h3><p>这种方法是参数直接在header里面的<br>如需将输出指定到文件可以通过重定向进行操作.</p>
<pre><code>curl -H &quot;Content-Type:application/json&quot; -X POST --data (json.data) URL
curl -H &quot;Content-Type:application/json&quot; -X POST --data &#39;&#123;&quot;message&quot;: &quot;sunshine&quot;&#125;&#39; http://localhost:8000/</code></pre>
<p>这种方法是json数据直接在body里面的</p>
<h3 id="输出到文件"><a href="#输出到文件" class="headerlink" title="输出到文件"></a>输出到文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -o tank_pos_meta.json &#x27;http://9.22.24.233:8080/ec/v1/listTable?pageNum=1&amp;pageSize=999&amp;type=hippo&amp;dbName=bank-pos-info&amp;name=t_bank_pos_yyyymmdd&#x27;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>URL必须带分号</p>
</blockquote>
<h2 id="date"><a href="#date" class="headerlink" title="date"></a>date</h2><p>两天前</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/Java/tool/Maven/</url>
    <content><![CDATA[<h1 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 打印插件的所有命令详情</span></span><br><span class="line">mvn help:describe -Dplugin=javafx -Ddetail</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>typesafe.config与HOCON</title>
    <url>/Java/tool/typesafe.config/</url>
    <content><![CDATA[<h1 id="typesafe-config"><a href="#typesafe-config" class="headerlink" title="typesafe.config"></a>typesafe.config</h1><h1 id="Typesafe-Config介绍"><a href="#Typesafe-Config介绍" class="headerlink" title="Typesafe Config介绍"></a>Typesafe Config介绍</h1><h3 id="Why-Typesafe-Config"><a href="#Why-Typesafe-Config" class="headerlink" title="Why Typesafe Config"></a>Why Typesafe Config</h3><p><strong>THE config library</strong> 非常好用的API，用过之后不会再想使用其他配置工具</p>
<ul>
<li>纯java实现，无任何依赖</li>
<li>支持各种格式配置的融合: Java properties, JSON, and a human-friendly JSON superset</li>
<li>可以通过文件、urls、classpath加载配置</li>
<li>支持多层嵌套的配置方式：树形配置</li>
<li>识别Java system properties, 如java -Dmyapp.foo.bar=10</li>
<li>可以转换时间，大小等单位。如 “512k”、”10 seconds”</li>
<li>类型转换，比如yes可以转换为true，数字之间也可以在内部做转换</li>
<li>JSON superset features:<ul>
<li>comments</li>
<li>includes</li>
<li>substitutions (“foo” : ${bar}, “foo” : Hello ${who})</li>
<li>properties-like notation (a.b=c)</li>
<li>less noisy, more lenient syntax</li>
<li>substitute environment variables (logdir=${HOME}/logs)</li>
</ul>
</li>
<li>基于不可变对象，不用担心多线程问题</li>
</ul>
<h4 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h4><p>使用gradle</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">compile &#39;com.typesafe:config:1.2.1&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="HOCON-Human-Optimized-Config-Object-Notation"><a href="#HOCON-Human-Optimized-Config-Object-Notation" class="headerlink" title="HOCON (Human-Optimized Config Object Notation)"></a>HOCON (Human-Optimized Config Object Notation)</h3><p>config使用的是HOCON的文件格式，这种文件格式类似于json，很灵活但没有歧义，能引用，能替换，能注释，能兼容老的properties等格式</p>
<p>The following features are desirable, to support human usage:</p>
<ul>
<li>less noisy / less pedantic syntax</li>
<li>ability to refer to another part of the configuration (set a value to another value)</li>
<li>import/include another configuration file into the current file</li>
<li>a mapping to a flat properties list such as Java’s system properties</li>
<li>ability to get values from environment variables</li>
<li>ability to write comments</li>
</ul>
<p>约束：utf8编码</p>
<h4 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 单行注释</span><br><span class="line">a &#x3D; 1 &#x2F;&#x2F; 单行注释</span><br><span class="line">b &#x3D; 2 # 单行注释</span><br><span class="line">c &#x3D; [3, # 行内注释 # 4]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="赋值与嵌套"><a href="#赋值与嵌套" class="headerlink" title="赋值与嵌套"></a>赋值与嵌套</h4><h5 id="普通赋值"><a href="#普通赋值" class="headerlink" title="普通赋值"></a>普通赋值</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a : 1</span><br><span class="line">a &#x3D; 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="（对象）嵌套赋值"><a href="#（对象）嵌套赋值" class="headerlink" title="（对象）嵌套赋值"></a>（对象）嵌套赋值</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;foo&quot; : &#123; &quot;a&quot; : 42 &#125;,</span><br><span class="line">    &quot;foo&quot; : &#123; &quot;b&quot; : 43 &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;foo&quot; : &#123; &quot;a&quot; : 42, &quot;b&quot; : 43 &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo.bar : 42</span><br><span class="line">foo &#123; bar : 42 &#125;</span><br><span class="line"></span><br><span class="line">foo.bar.baz : 42</span><br><span class="line">foo &#123; bar &#123; baz : 42 &#125; &#125;</span><br><span class="line"></span><br><span class="line">a.x : 42, a.y : 43</span><br><span class="line">a &#123; x : 42, y : 43 &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="多种格式"><a href="#多种格式" class="headerlink" title="多种格式"></a>多种格式</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;foo&quot; : &#123;</span><br><span class="line">        &quot;bar&quot; : 10,</span><br><span class="line">        &quot;baz&quot; : 12</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo : &#123;</span><br><span class="line">    bar : 10,</span><br><span class="line">    baz : 12</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo &#123;</span><br><span class="line">    bar &#x3D; 10</span><br><span class="line">    baz &#x3D; 12</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo.bar&#x3D;10</span><br><span class="line">foo.baz&#x3D;12</span><br><span class="line"></span><br><span class="line">foo.bar&#x3D;10, foo.baz&#x3D;12</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="多行赋值"><a href="#多行赋值" class="headerlink" title="多行赋值"></a>多行赋值</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">logo &#x3D; &quot;&quot;&quot;hello</span><br><span class="line">world&quot;&quot;&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="数组与对象合并"><a href="#数组与对象合并" class="headerlink" title="数组与对象合并"></a>数组与对象合并</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; one object</span><br><span class="line">a : &#123; b : 1, c : 2 &#125;</span><br><span class="line">&#x2F;&#x2F; two objects that are merged via concatenation rules</span><br><span class="line">a : &#123; b : 1 &#125; &#123; c : 2 &#125;</span><br><span class="line">&#x2F;&#x2F; two fields that are merged</span><br><span class="line">a : &#123; b : 1 &#125;</span><br><span class="line">a : &#123; c : 2 &#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; one array</span><br><span class="line">a : [ 1, 2, 3, 4 ]</span><br><span class="line">&#x2F;&#x2F; two arrays that are concatenated</span><br><span class="line">a : [ 1, 2 ] [ 3, 4 ]</span><br><span class="line">&#x2F;&#x2F; a later definition referring to an earlier</span><br><span class="line">&#x2F;&#x2F; (see &quot;self-referential substitutions&quot; below)</span><br><span class="line">a : [ 1, 2 ]</span><br><span class="line">a : $&#123;a&#125; [ 3, 4 ]</span><br><span class="line"></span><br><span class="line">path &#x3D; [ &#x2F;bin ]</span><br><span class="line">path &#x3D; $&#123;path&#125; [ &#x2F;usr&#x2F;bin ]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="对象的继承"><a href="#对象的继承" class="headerlink" title="对象的继承"></a>对象的继承</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data-center-generic &#x3D; &#123; cluster-size &#x3D; 6 &#125;</span><br><span class="line">data-center-east &#x3D; $&#123;data-center-generic&#125; &#123; name &#x3D; &quot;east&quot; &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="合并还是覆盖"><a href="#合并还是覆盖" class="headerlink" title="合并还是覆盖"></a>合并还是覆盖</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123; a : &#123; x : 1 &#125; &#125; (first priority)</span><br><span class="line">&#123; a : 42 &#125; (fallback)</span><br><span class="line">&#123; a : &#123; y : 2 &#125; &#125; (another fallback)</span><br><span class="line"># result in &#123; a : &#123; x : 1 &#125; &#125;</span><br><span class="line"></span><br><span class="line">&#123; a : &#123; x : 1 &#125; &#125; (first priority)</span><br><span class="line">&#123; a : &#123; y : 2 &#125; &#125; (fallback)</span><br><span class="line">&#123; a : 42 &#125; (another fallback)</span><br><span class="line"># result in &#123; a : &#123; x : 1, y : 2 &#125; &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h4><p>使用这样的语法 <code>$&#123;pathexpression&#125; or $&#123;?pathexpression&#125;</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">animal.favorite &#x3D; dog</span><br><span class="line">key : $&#123;animal.favorite&#125; is my favorite animal</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>pathexpression</code>是绝对路径，替换是config对象构建的最后一步。</p>
<h4 id="Include"><a href="#Include" class="headerlink" title="Include"></a>Include</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">include &quot;foo&quot;</span><br><span class="line"></span><br><span class="line">include &quot;foo.properties&quot;</span><br><span class="line">include &quot;foo.json&quot;</span><br><span class="line">include &quot;foo.conf&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="内置转换API"><a href="#内置转换API" class="headerlink" title="内置转换API"></a>内置转换API</h4><p>自动转换，<a href="https://github.com/typesafehub/config/blob/master/HOCON.md#duration-format">时间单位</a>（ns、ms、s、m、h etc），<a href="https://github.com/typesafehub/config/blob/master/HOCON.md#size-in-bytes-format">文件大小</a>（kB、MB etc）</p>
<h3 id="文件载入顺序"><a href="#文件载入顺序" class="headerlink" title="文件载入顺序"></a>文件载入顺序</h3><p>依次载入合并</p>
<ul>
<li>引用 jar 包中的 reference.conf 库引用配置</li>
<li>引用 jar 包中的 application.{conf,json,properties} 应用配置</li>
<li>本地 reference.conf 库引用配置</li>
<li>本地 application.{conf,json,properties} 应用配置</li>
<li>system properties</li>
</ul>
<h3 id="在java代码中使用"><a href="#在java代码中使用" class="headerlink" title="在java代码中使用"></a>在java代码中使用</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 配置内容</span><br><span class="line">foo&#x3D;42</span><br><span class="line">dev.foo&#x3D;57</span><br><span class="line">prod.foo&#x3D;10</span><br><span class="line"></span><br><span class="line">import com.typesafe.config.ConfigFactory</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 载入根配置</span><br><span class="line">Config conf &#x3D; ConfigFactory.load();</span><br><span class="line">int foo1 &#x3D; conf.getInt(&quot;dev.foo&quot;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 载入某个对象</span><br><span class="line">Config prod &#x3D; conf.getConfig(&quot;prod&quot;);</span><br><span class="line">int foo2 &#x3D; foo.getInt(&quot;foo&quot;);</span><br><span class="line"></span><br><span class="line">Config devConfig &#x3D; conf</span><br><span class="line">                     .getConfig(&quot;dev&quot;)</span><br><span class="line">                     .withFallback(originalConfig)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; handle default</span><br><span class="line">&#x2F;&#x2F; boolean getBoolean(String path, boolean fallback)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h3><p>使用下面的方法，会把最终所有的配置信息打印出来</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">logger.debug(myConfig.root().render())</span><br></pre></td></tr></table></figure>
<p>输出结果中包含所有载入的配置，如果使用了conf文件，会将对应文件的行信息也打印出来：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    # system properties</span><br><span class="line">    &quot;awt&quot; : &#123;</span><br><span class="line">        # system properties</span><br><span class="line">        &quot;toolkit&quot; : &quot;sun.awt.windows.WToolkit&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    # complex1.conf: 2</span><br><span class="line">    # these are our own config values defined by the app</span><br><span class="line">    &quot;complex-app&quot; : &#123;</span><br><span class="line">        # complex1.conf: 3</span><br><span class="line">        &quot;something&quot; : &quot;This value comes from complex-app&#39;s complex1.conf&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h3><ul>
<li><a href="https://github.com/typesafehub/config">https://github.com/typesafehub/config</a></li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>tool</tag>
        <tag>HOCON</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中优雅的加解密</title>
    <url>/Java/tool/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86/</url>
    <content><![CDATA[<h1 id="加密与解密"><a href="#加密与解密" class="headerlink" title="加密与解密"></a>加密与解密</h1><h2 id="AES"><a href="#AES" class="headerlink" title="AES"></a>AES</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.security.InvalidKeyException;</span><br><span class="line"><span class="keyword">import</span> java.security.NoSuchAlgorithmException;</span><br><span class="line"><span class="keyword">import</span> java.security.SecureRandom;</span><br><span class="line"><span class="keyword">import</span> java.util.Base64;</span><br><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.crypto.BadPaddingException;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.Cipher;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.IllegalBlockSizeException;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.KeyGenerator;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.NoSuchPaddingException;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.SecretKey;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.spec.SecretKeySpec;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sun.misc.BASE64Decoder;</span><br><span class="line"><span class="keyword">import</span> sun.misc.BASE64Encoder;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * AES对称加密和解密</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SymmetricEncoder</span> </span>&#123;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * 加密</span></span><br><span class="line"><span class="comment">   * 1.构造密钥生成器</span></span><br><span class="line"><span class="comment">   * 2.根据ecnodeRules规则初始化密钥生成器</span></span><br><span class="line"><span class="comment">   * 3.产生密钥</span></span><br><span class="line"><span class="comment">   * 4.创建和初始化密码器</span></span><br><span class="line"><span class="comment">   * 5.内容加密</span></span><br><span class="line"><span class="comment">   * 6.返回字符串</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">AESEncode</span><span class="params">(String encodeRules,String content)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1.构造密钥生成器，指定为AES算法,不区分大小写</span></span><br><span class="line">            KeyGenerator keygen=KeyGenerator.getInstance(<span class="string">&quot;AES&quot;</span>);</span><br><span class="line">            <span class="comment">//2.根据ecnodeRules规则初始化密钥生成器</span></span><br><span class="line">            <span class="comment">//生成一个128位的随机源,根据传入的字节数组</span></span><br><span class="line">            keygen.init(<span class="number">128</span>, <span class="keyword">new</span> SecureRandom(encodeRules.getBytes()));</span><br><span class="line">              <span class="comment">//3.产生原始对称密钥</span></span><br><span class="line">            SecretKey original_key=keygen.generateKey();</span><br><span class="line">              <span class="comment">//4.获得原始对称密钥的字节数组</span></span><br><span class="line">            <span class="keyword">byte</span> [] raw=original_key.getEncoded();</span><br><span class="line">            <span class="comment">//5.根据字节数组生成AES密钥</span></span><br><span class="line">            SecretKey key=<span class="keyword">new</span> SecretKeySpec(raw, <span class="string">&quot;AES&quot;</span>);</span><br><span class="line">              <span class="comment">//6.根据指定算法AES自成密码器</span></span><br><span class="line">            Cipher cipher=Cipher.getInstance(<span class="string">&quot;AES&quot;</span>);</span><br><span class="line">              <span class="comment">//7.初始化密码器，第一个参数为加密(Encrypt_mode)或者解密解密(Decrypt_mode)操作，第二个参数为使用的KEY</span></span><br><span class="line">            cipher.init(Cipher.ENCRYPT_MODE, key);</span><br><span class="line">            <span class="comment">//8.获取加密内容的字节数组(这里要设置为utf-8)不然内容中如果有中文和英文混合中文就会解密为乱码</span></span><br><span class="line">            <span class="keyword">byte</span> [] byte_encode=content.getBytes(<span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">            <span class="comment">//9.根据密码器的初始化方式--加密：将数据加密</span></span><br><span class="line">            <span class="keyword">byte</span> [] byte_AES=cipher.doFinal(byte_encode);</span><br><span class="line">          <span class="comment">//10.将加密后的数据转换为字符串</span></span><br><span class="line">            <span class="comment">//这里用Base64Encoder中会找不到包</span></span><br><span class="line">            <span class="comment">//解决办法：</span></span><br><span class="line">            <span class="comment">//在项目的Build path中先移除JRE System Library，再添加库JRE System Library，重新编译后就一切正常了。</span></span><br><span class="line">            String AES_encode=<span class="keyword">new</span> String(<span class="keyword">new</span> BASE64Encoder().encode(byte_AES));</span><br><span class="line">          <span class="comment">//11.将字符串返回</span></span><br><span class="line">            <span class="keyword">return</span> AES_encode;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchPaddingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InvalidKeyException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalBlockSizeException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (BadPaddingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果有错就返加nulll</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 解密</span></span><br><span class="line"><span class="comment">     * 解密过程：</span></span><br><span class="line"><span class="comment">     * 1.同加密1-4步</span></span><br><span class="line"><span class="comment">     * 2.将加密后的字符串反纺成byte[]数组</span></span><br><span class="line"><span class="comment">     * 3.将加密内容解密</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">AESDncode</span><span class="params">(String encodeRules,String content)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1.构造密钥生成器，指定为AES算法,不区分大小写</span></span><br><span class="line">            KeyGenerator keygen=KeyGenerator.getInstance(<span class="string">&quot;AES&quot;</span>);</span><br><span class="line">            <span class="comment">//2.根据ecnodeRules规则初始化密钥生成器</span></span><br><span class="line">            <span class="comment">//生成一个128位的随机源,根据传入的字节数组</span></span><br><span class="line">            keygen.init(<span class="number">128</span>, <span class="keyword">new</span> SecureRandom(encodeRules.getBytes()));</span><br><span class="line">              <span class="comment">//3.产生原始对称密钥</span></span><br><span class="line">            SecretKey original_key=keygen.generateKey();</span><br><span class="line">              <span class="comment">//4.获得原始对称密钥的字节数组</span></span><br><span class="line">            <span class="keyword">byte</span> [] raw=original_key.getEncoded();</span><br><span class="line">            <span class="comment">//5.根据字节数组生成AES密钥</span></span><br><span class="line">            SecretKey key=<span class="keyword">new</span> SecretKeySpec(raw, <span class="string">&quot;AES&quot;</span>);</span><br><span class="line">              <span class="comment">//6.根据指定算法AES自成密码器</span></span><br><span class="line">            Cipher cipher=Cipher.getInstance(<span class="string">&quot;AES&quot;</span>);</span><br><span class="line">              <span class="comment">//7.初始化密码器，第一个参数为加密(Encrypt_mode)或者解密(Decrypt_mode)操作，第二个参数为使用的KEY</span></span><br><span class="line">            cipher.init(Cipher.DECRYPT_MODE, key);</span><br><span class="line">            <span class="comment">//8.将加密并编码后的内容解码成字节数组</span></span><br><span class="line">            <span class="keyword">byte</span> [] byte_content= <span class="keyword">new</span> BASE64Decoder().decodeBuffer(content);</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 解密</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">byte</span> [] byte_decode=cipher.doFinal(byte_content);</span><br><span class="line">            String AES_decode=<span class="keyword">new</span> String(byte_decode,<span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> AES_decode;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchPaddingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InvalidKeyException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalBlockSizeException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (BadPaddingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果有错就返加nulll</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SymmetricEncoder se=<span class="keyword">new</span> SymmetricEncoder();</span><br><span class="line">        Scanner scanner=<span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 加密</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        System.out.println(<span class="string">&quot;使用AES对称加密，请输入加密的规则&quot;</span>);</span><br><span class="line">        String encodeRules=scanner.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;请输入要加密的内容:&quot;</span>);</span><br><span class="line">        String content = scanner.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;根据输入的规则&quot;</span>+encodeRules+<span class="string">&quot;加密后的密文是:&quot;</span>+se.AESEncode(encodeRules, content));</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 解密</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        System.out.println(<span class="string">&quot;使用AES对称解密，请输入加密的规则：(须与加密相同)&quot;</span>);</span><br><span class="line">         encodeRules=scanner.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;请输入要解密的内容（密文）:&quot;</span>);</span><br><span class="line">         content = scanner.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;根据输入的规则&quot;</span>+encodeRules+<span class="string">&quot;解密后的明文是:&quot;</span>+se.AESDncode(encodeRules, content));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Apache-commons-codec"><a href="#Apache-commons-codec" class="headerlink" title="Apache commons codec"></a>Apache commons codec</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-codec<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-codec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、MD5加密</span></span><br><span class="line">String md5Str = DigestUtils.md5Hex(str);</span><br><span class="line">System.out.println(<span class="string">&quot;MD5--&gt;&quot;</span> + md5Str);</span><br><span class="line"></span><br><span class="line"><span class="comment">//SHA1加密</span></span><br><span class="line">String sha1Str = DigestUtils.sha1Hex(str);</span><br><span class="line">System.out.println(<span class="string">&quot;SHA1--&gt;&quot;</span> + sha1Str);</span><br><span class="line"></span><br><span class="line"><span class="comment">//Base64加密</span></span><br><span class="line">String base64Str = Base64.encodeBase64String(str.getBytes());</span><br><span class="line">System.out.println(<span class="string">&quot;base64加密--&gt;&quot;</span> + base64Str);</span><br><span class="line"></span><br><span class="line"><span class="comment">//Base64解密</span></span><br><span class="line">String base64DecodeStr = <span class="keyword">new</span> String(Base64.decodeBase64(base64Str));</span><br><span class="line">System.out.println(<span class="string">&quot;base64解密--&gt;&quot;</span> + base64DecodeStr);</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>tool</tag>
        <tag>加密</tag>
        <tag>解密</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOS中MySQL密码丢失处理</title>
    <url>/database/MySQL/01.MySQL/</url>
    <content><![CDATA[<h1 id="01-MySQL"><a href="#01-MySQL" class="headerlink" title="01.MySQL"></a>01.MySQL</h1><h2 id="修改root密码-不成功"><a href="#修改root密码-不成功" class="headerlink" title="修改root密码 不成功"></a>修改root密码 不成功</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Open &amp; Edit /etc/my.cnf or /etc/mysql/my.cnf, depending on your distro.</span><br><span class="line">Add skip-grant-tables under [mysqld]</span><br><span class="line">Restart Mysql</span><br><span class="line">You should be able to login to mysql now using the below command mysql -u root -p</span><br><span class="line">Run mysql&gt; flush privileges;</span><br><span class="line">Set new password by ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;NewPassword&#x27;;</span><br><span class="line">Go back to /etc/my.cnf and remove/comment skip-grant-tables</span><br><span class="line">Restart Mysql</span><br><span class="line">Now you will be able to login with the new password mysql -u root -p</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> drop user root@localhost;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> flush privileges;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> create user root@localhost identified by <span class="string">&#x27;abc.123&#x27;</span>;</span></span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"></span><br><span class="line">grant all privileges on *.* to root@localhost;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<h2 id="mac-brew重装-不成功"><a href="#mac-brew重装-不成功" class="headerlink" title="mac brew重装 不成功"></a>mac brew重装 不成功</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">brew uninstall mysql --ignore-dependencies</span><br><span class="line">sudo rm -rf /usr/local/Cellar/mysql</span><br><span class="line">brew cleanup</span><br><span class="line">sudo rm -rf /usr/local/var/mysql</span><br><span class="line">brew install mysql</span><br></pre></td></tr></table></figure>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_zxg_hot_news_result <span class="keyword">add</span> index</span><br><span class="line"> idx_hot_news_cnt (ftype,fcnt,ftime,fnews_id,fmsg_type);</span><br></pre></td></tr></table></figure>
<h3 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_zxg_hot_news_result <span class="keyword">drop</span> index idx_hot_news_cnt ;</span><br></pre></td></tr></table></figure>
<h3 id="查询索引"><a href="#查询索引" class="headerlink" title="查询索引"></a>查询索引</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> index <span class="keyword">from</span> t_zxg_hot_news_result;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">Table</span>                 <span class="operator">|</span> Non_unique <span class="operator">|</span> Key_name         <span class="operator">|</span> Seq_in_index <span class="operator">|</span> Column_name <span class="operator">|</span> <span class="keyword">Collation</span> <span class="operator">|</span> <span class="keyword">Cardinality</span> <span class="operator">|</span> Sub_part <span class="operator">|</span> Packed <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Index_type <span class="operator">|</span> Comment <span class="operator">|</span> Index_comment <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">0</span>          <span class="operator">|</span> <span class="keyword">PRIMARY</span>          <span class="operator">|</span> <span class="number">1</span>            <span class="operator">|</span> fid         <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">765715</span>      <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">1</span>            <span class="operator">|</span> ftype       <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">5</span>           <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">2</span>            <span class="operator">|</span> fcnt        <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">4072</span>        <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">3</span>            <span class="operator">|</span> ftime       <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">49236</span>       <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> YES  <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">4</span>            <span class="operator">|</span> fnews_id    <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">800020</span>      <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">5</span>            <span class="operator">|</span> fmsg_type   <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">792176</span>      <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span></span><br></pre></td></tr></table></figure>




]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL</title>
    <url>/database/MySQL/base/</url>
    <content><![CDATA[<ol>
<li>语法<ul>
<li><a href="/database/MySQL/syntax_1">基础语法1</a></li>
<li><a href="/database/MySQL/syntax_2_in_or">in与or</a></li>
<li><a href="/database/MySQL/syntax_3_multitable_join">多表join</a></li>
<li><a href="/database/MySQL/syntax_4_advanced">高级语法</a></li>
<li><a href="/database/MySQL/syntax_5_sample">使用样例</a></li>
</ul>
</li>
<li>最佳实践<ul>
<li><a href="/database/MySQL/best_practices">最佳实践</a></li>
</ul>
</li>
<li>架构<ul>
<li><a href="/database/MySQL/struct_1">架构</a></li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL数据库设计总结</title>
    <url>/database/MySQL/best_practices/</url>
    <content><![CDATA[<h1 id="MySQL数据库设计总结"><a href="#MySQL数据库设计总结" class="headerlink" title="MySQL数据库设计总结"></a>MySQL数据库设计总结</h1><blockquote>
<p><a href="https://www.qcloud.com/community/article/119">参考文献: MySQL数据库设计总结</a></p>
</blockquote>
<h2 id="常用规则"><a href="#常用规则" class="headerlink" title="常用规则"></a>常用规则</h2><p><strong>规则1</strong>：一般情况可以选择<code>MyISAM</code>存储引擎，如果需要事务支持必须使用<code>InnoDB</code>存储引擎。</p>
<p>注意：<code>MyISAM</code>存储引擎 <code>B-tree索引</code>有一个很大的限制：参与一个<strong>索引的所有字段的长度之和不能超过1000字节</strong>。另外<strong>MyISAM数据和索引是分开</strong>，而<code>InnoDB</code>的数据存储是按<strong>聚簇(cluster)索引有序排列</strong>的，主键是默认的<strong>聚簇(cluster)索引</strong>，因此<code>MyISAM</code>虽然在一般情况下，查询性能比<code>InnoDB</code>高，但<code>InnoDB</code>的以主键为条件的查询性能是非常高的。</p>
<p><strong>规则2</strong>：命名规则。</p>
<ol>
<li>数据库和表名应尽可能和所服务的业务模块名一致</li>
<li>服务与同一个子模块的一类表应尽量以子模块名(或部分单词)为前缀或后缀</li>
<li>表名应尽量包含与所存放数据对应的单词</li>
<li>字段名称也应尽量保持和实际数据相对应</li>
<li>联合索引名称应尽量包含所有索引键字段名或缩写，且各字段名在索引名中的顺序应与索引键在索引中的索引顺序一致，并尽量包含一个类似idx的前缀或后缀，以表明期对象类型是索引。</li>
<li>约束等其他对象也应该尽可能包含所属表或其他对象的名称，以表明各自的关系</li>
</ol>
<p><strong>规则3</strong>：数据库字段类型定义</p>
<ol>
<li>经常需要计算和排序等消耗CPU的字段,应该尽量选择更为迅速的字段，如用<code>TIMESTAMP</code>(4个字节，最小值<code>1970-01-01 00:00:00</code>)代替<code>Datetime</code>（8个字节，最小值<code>1001-01-01 00:00:00</code>）,通过整型替代浮点型和字符型</li>
<li>变长字段使用<code>varchar</code>，不要使用<code>char</code></li>
<li>对于二进制多媒体数据，流水队列数据(如日志)，超大文本数据不要放在数据库字段中</li>
</ol>
<p><strong>规则4</strong>：业务逻辑执行过程必须读到的表中必须要有初始的值。避免业务读出为负或无穷大的值导致程序失败</p>
<p><strong>规则5</strong>：并不需要一定遵守范式理论，适度的冗余，让Query尽量减少Join</p>
<p><strong>规则6</strong>：访问频率较低的大字段拆分出数据表。有些大字段占用空间多，访问频率较其他字段明显要少很多，这种情况进行拆分，频繁的查询中就不需要读取大字段，造成IO资源的浪费。</p>
<p><strong>规则7</strong>：大表可以考虑水平拆分。大表影响查询效率，根据业务特性有很多拆分方式，像根据时间递增的数据，可以根据时间来分。以id划分的数据，可根据id%数据库个数的方式来拆分。</p>
<h2 id="一-数据库索引"><a href="#一-数据库索引" class="headerlink" title="一.数据库索引"></a>一.数据库索引</h2><p><strong>规则8</strong>：业务需要的相关索引是根据实际的设计所构造sql语句的**<em>where条件**</em>来确定的，<br>业务不需要的字段不要建索引，不允许在联合索引（或主键）中存在多余的字段。特别是该字段根本不会在条件语句中出现。</p>
<p><strong>规则9</strong>：唯一确定一条记录的一个字段或多个字段要建立主键或者唯一索引，不能唯一确定一条记录，为了提高查询效率建普通索引</p>
<p><strong>规则10</strong>：业务使用的表，有些记录数很少，甚至只有一条记录，为了<strong>约束</strong>的需要，也要建立索引或者设置主键。</p>
<p><strong>规则11</strong>：对于取值不能重复，经常作为查询条件的字段，应该建唯一索引(主键默认唯一索引)，并且将查询条件中该字段的条件置于第一个位置。没有必要再建立与该字段有关的联合索引。</p>
<p><strong>规则12</strong>：对于经常查询的字段，其<strong>值不唯一</strong>，也应该考虑建立<strong>普通索引</strong>，查询语句中该字段条件置于第一个位置，对联合索引处理的方法同样。</p>
<p><strong>规则13</strong>：业务通过不唯一索引访问数据时，需要考虑通过该索引值返回的记录稠密度，原则上可能的<strong>稠密度最大不能高于0.2</strong>，如果稠密度太大，则不合适建立索引了。</p>
<blockquote>
<p>当通过这个索引查找得到的数据量占到表内所有数据的20%以上时，则需要考虑建立该索引的代价，同时由于索引扫描产生的都是随机I/O，生成效率比全表顺序扫描的顺序I/O低很多。数据库系统优化query的时候有可能不会用到这个索引。</p>
</blockquote>
<p><strong>规则14</strong>：需要联合索引(或联合主键)的数据库要注意索引的顺序。SQL语句中的匹配条件也要跟索引的顺序保持一致。</p>
<p>注意：索引的顺势不正确也可能导致严重的后果。</p>
<p><strong>规则15</strong>：表中的多个字段查询作为查询条件，不含有其他索引，并且字段联合值不重复，可以在这多个字段上建唯一的联合索引，假设索引字段为 (a1,a2,…an),则查询条件<code>(a1 op val1,a2 op val2,...am op valm)m&lt;=n</code>,可以用到索引，查询条件中字段的位置与索引中的字段位置是一致的。</p>
<p><strong>规则16</strong>：联合索引的建立原则(以下均假设在数据库表的字段a,b,c上建立联合索引(<code>a,b,c</code>))</p>
<ol>
<li>联合索引中的字段应尽量满足过滤数据从多到少的顺序，也就是说差异最大的字段应该放在第一个字段</li>
<li>建立索引尽量与SQL语句的条件顺序一致，使SQL语句尽量以整个索引为条件，尽量避免以索引的一部分(特别是首个条件与索引的首个字段不一致时)作为查询的条件</li>
<li><code>Where a=1</code>, <code>where a&gt;=12 and a&lt;15</code>, <code>where a=1 and b&lt;5</code> , <code>where a=1 and b=7 and c&gt;=40</code>为条件可以用到此联合索引；而这些语句<code>where b=10</code>, <code>where c=221</code>, <code>where b&gt;=12 and c=2</code>则无法用到这个联合索引。</li>
<li>当需要查询的数据库字段全部在索引中体现时，数据库可以直接查询索引得到查询信息无须对整个表进行扫描(这就是所谓的key-only)，能大大的提高查询效率。<br>当a，ab，abc与其他表字段关联查询时可以用到索引</li>
<li>当a，ab，abc顺序而不是b，c，bc，ac为顺序执行Order by或者group不要时可以用到索引</li>
<li>以下情况时，进行表扫描然后排序可能比使用联合索引更加有效<ul>
<li>a. 表已经按照索引组织好了</li>
<li>b. 被查询的数据占所有数据的很多比例。</li>
</ul>
</li>
</ol>
<p><strong>规则17</strong>：重要业务访问数据表时。但不能通过索引访问数据时，应该确保顺序访问的记录数目是有限的，原则上不得多于10.</p>
<h2 id="二-Query语句与应用系统优化"><a href="#二-Query语句与应用系统优化" class="headerlink" title="二. Query语句与应用系统优化"></a>二. Query语句与应用系统优化</h2><p><strong>规则18</strong>：合理构造Query语句</p>
<ol>
<li><p>Insert语句中，根据测试，批量一次插入1000条时效率最高，多于1000条时，要拆分，多次进行同样的插入，应该合并批量进行。注意query语句的长度要小于mysqld的参数 max_allowed_packet</p>
</li>
<li><p>查询条件中各种逻辑操作符性能顺序是and,or,in,因此在查询条件中应该尽量避免使用在大集合中使用in</p>
</li>
<li><p>永远用小结果集驱动大记录集，因为在mysql中，只有Nested Join一种Join方式，就是说mysql的join是通过嵌套循环来实现的。通过小结果集驱动大记录集这个原则来减少嵌套循环的循环次数，以减少IO总量及CPU运算次数</p>
</li>
<li><p>尽量优化Nested Join内层循环。</p>
</li>
<li><p>只取需要的columns，尽量不要使用<code>select *</code></p>
</li>
<li><p>仅仅使用最有效的过滤字段，where 字句中的过滤条件少为好</p>
</li>
<li><p>尽量避免复杂的Join和子查询</p>
<p>Mysql在并发这块做得并不是太好，当并发量太高的时候，整体性能会急剧下降，这主要与Mysql内部资源的争用锁定控制有关，<code>MyIsam</code>用表锁，<code>InnoDB</code>好一些用行锁。</p>
</li>
</ol>
<p><strong>规则19</strong>：应用系统的优化</p>
<ol>
<li>合理使用<code>cache</code>，对于变化较少的部分活跃数据通过应用层的<code>cache</code>缓存到内存中，对性能的提升是成数量级的。</li>
<li>对重复执行相同的query进行合并，减少IO次数。</li>
<li>事务相关性最小原则</li>
</ol>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>MySQL</tag>
        <tag>SQL</tag>
        <tag>index</tag>
        <tag>join</tag>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>InnoDB中的锁机制</title>
    <url>/database/MySQL/02.InnoDBLocks/</url>
    <content><![CDATA[<h1 id="InnoDB中的锁机制"><a href="#InnoDB中的锁机制" class="headerlink" title="InnoDB中的锁机制"></a>InnoDB中的锁机制</h1><p>获取锁争用情况</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql root<span class="variable">@localhost</span>:dlock<span class="operator">&gt;</span> <span class="keyword">show</span> status <span class="keyword">like</span> <span class="string">&#x27;innodb_row_lock%&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name                 <span class="operator">|</span> <span class="keyword">Value</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_current_waits <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time          <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time_avg      <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time_max      <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_waits         <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"><span class="type">Time</span>: <span class="number">0.012</span>s</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL information_schema数据库</title>
    <url>/database/MySQL/information_schema/</url>
    <content><![CDATA[<p>information_schema这这个数据库中保存了MySQL服务器所有数据库的信息。<br>如数据库名，数据库的表，表栏的数据类型与访问权限等。<br>再简单点，这台MySQL服务器上，到底有哪些数据库、各个数据库有哪些表，<br>每张表的字段类型是什么，各个数据库要什么权限才能访问，等等信息都保存在information_schema里面。</p>
<p>选用MySQL版本 5.6.25</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> version();</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="operator">|</span> version()  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5.6</span><span class="number">.25</span><span class="operator">-</span>log <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">use information_schema;</span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Tables_in_information_schema          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> CHARACTER_SETS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLLATIONS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLLATION_CHARACTER_SET_APPLICABILITY <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLUMNS                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLUMN_PRIVILEGES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ENGINES                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> EVENTS                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> FILES                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> GLOBAL_STATUS                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> GLOBAL_VARIABLES                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> KEY_COLUMN_USAGE                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OPTIMIZER_TRACE                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PARAMETERS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PARTITIONS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PLUGINS                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PROCESSLIST                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PROFILING                             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> REFERENTIAL_CONSTRAINTS               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ROUTINES                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SCHEMATA                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SCHEMA_PRIVILEGES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SESSION_STATUS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SESSION_VARIABLES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> STATISTICS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLES                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLESPACES                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLE_CONSTRAINTS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLE_PRIVILEGES                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TRIGGERS                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> USER_PRIVILEGES                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> VIEWS                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_LOCKS                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_TRX                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_DATAFILES                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_LOCK_WAITS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLESTATS                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_METRICS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_RESET                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_PER_INDEX                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMPMEM_RESET                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_DELETED                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_PAGE_LRU                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FOREIGN                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_COLUMNS                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_INDEXES                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_DEFAULT_STOPWORD            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FIELDS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_PER_INDEX_RESET            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_PAGE                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMPMEM                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_INDEX_TABLE                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_BEING_DELETED               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLESPACES                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_INDEX_CACHE                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FOREIGN_COLS               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_POOL_STATS              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_CONFIG                      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="number">59</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure>
<p>information_schema 数据库中有59张表， 分别存储了如下的信息:<br><a href="https://dev.mysql.com/doc/refman/5.6/en/information-schema.html">参考官方文档</a></p>
<table>
<thead>
<tr>
<th>SCHEMATA</th>
<th>提供了当前mysql实例中所有数据库的信息，show databases的结果取之此表。</th>
</tr>
</thead>
<tbody><tr>
<td>TABLES</td>
<td>提供了关于数据库中的表的信息（包括视图），详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息，show tables from schemaname的结果取之此表。</td>
</tr>
<tr>
<td>COLUMNS</td>
<td>提供了表中的列信息，详细表述了某张表的所有列以及每个列的信息，show columns from  schemaname.tablename的结果取之此表。</td>
</tr>
<tr>
<td>STATISTICS</td>
<td>提供了关于表索引的信息，show index from schemaname.tablename的结果取之此表。</td>
</tr>
<tr>
<td>USER_PRIVILEGES（用户权限）</td>
<td>给出了关于全程权限的信息，该信息源自mysql.user授权表，是非标准表。</td>
</tr>
<tr>
<td>SCHEMA_PRIVILEGES（方案权限）</td>
<td>给出了关于方案（数据库）权限的信息，该信息来自mysql.db授权表，是非标准表。</td>
</tr>
<tr>
<td>TABLE_PRIVILEGES（表权限）</td>
<td>给出了关于表权限的信息，该信息源自mysql.tables_priv授权表，是非标准表。</td>
</tr>
<tr>
<td>COLUMN_PRIVILEGES（列权限）</td>
<td>给出了关于列权限的信息，该信息源自mysql.columns_priv授权表，是非标准表。</td>
</tr>
<tr>
<td>CHARACTER_SETS（字符集）</td>
<td>提供了mysql实例可用字符集的信息，SHOW CHARACTER SET结果集取之此表。</td>
</tr>
<tr>
<td>COLLATIONS</td>
<td>提供了关于各字符集的对照信息。</td>
</tr>
<tr>
<td>COLLATION_CHARACTER_SET_APPLICABILITY</td>
<td>指明了可用于校对的字符集，这些列等效于SHOW COLLATION的前两个显示字段。</td>
</tr>
<tr>
<td>TABLE_CONSTRAINTS</td>
<td>描述了存在约束的表，以及表的约束类型。</td>
</tr>
<tr>
<td>KEY_COLUMN_USAGE</td>
<td>描述了具有约束的键列。</td>
</tr>
<tr>
<td>ROUTINES</td>
<td>提供了关于存储子程序（存储程序和函数）的信息，此时，ROUTINES表不包含自定义函数（UDF），名为</td>
</tr>
<tr>
<td>VIEWS</td>
<td>给出了关于数据库中的视图的信息，需要有show views权限，否则无法查看视图信息。</td>
</tr>
<tr>
<td>TRIGGERS</td>
<td>提供了关于触发程序的信息，必须有super权限才能查看该表。</td>
</tr>
</tbody></table>
<p>information_schema的表schemata中的列schema_name记录了所有数据库的名字<br>information_schema的表tables中的列table_schema记录了所有数据库的名字<br>information_schema的表tables中的列table_name记录了所有数据库的表的名字<br>information_schema的表columns中的列table_schema记录了所有数据库的名字<br>information_schema的表columns中的列table_name记录了所有数据库的表的名字<br>information_schema的表columns中的列column_name记录了所有数据库的表的列的名字</p>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/database/MySQL/mac_install/</url>
    <content><![CDATA[<h1 id="mac-install"><a href="#mac-install" class="headerlink" title="mac_install"></a>mac_install</h1><p><a href="https://stackoverflow.com/questions/4359131/brew-install-mysql-on-macos">brew install mysql in macos</a></p>
]]></content>
  </entry>
  <entry>
    <title>MySQL架构1 主从复制</title>
    <url>/database/MySQL/struct_1/</url>
    <content><![CDATA[<p><strong>主从复制的几种方式</strong></p>
<p><strong>同步复制</strong></p>
<p>所谓的同步复制，意思是master的变化，必须等待slave-1,slave-2,…,slave-n完成后才能返回。</p>
<p>这样，显然不可取，也不是MYSQL复制的默认设置。比如，在WEB前端页面上，用户增加了条记录，需要等待很长时间。</p>
<p><strong>异步复制</strong></p>
<p>如同AJAX请求一样。master只需要完成自己的数据库操作即可。至于slaves是否收到二进制日志，是否完成操作，不用关心。MYSQL的默认设置。</p>
<p><strong>半同步复制</strong></p>
<p>master只保证slaves中的一个操作成功，就返回，其他slave不管。这个功能，是由google为MYSQL引入的。</p>
<p><img src="/images/database/MySQL/master_slave_01.png"></p>
<p>当master的二进制日志每产生一个事件，都需要发往slave，如果我们有N个slave,那是发N次，还是只发一次？</p>
<p>如果只发一次，发给了slave-1，那slave-2,slave-3,…它们怎么办？</p>
<p>显然，应该发N次。实际上，在MYSQL   master内部，维护N个线程，每一个线程负责将二进制日志文件发往对应的slave。master既要负责写操作，还的维护N个线程，负担会很重。可以这样，slave-1是master的从，slave-1又是slave-2,slave-3,…的主，同时slave-1不再负责select。slave-1将master的复制线程的负担，转移到自己的身上。这就是所谓的多级复制的概念。</p>
]]></content>
      <categories>
        <category>DataStruct</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>DataStruct</tag>
        <tag>algrithom</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL in or优化</title>
    <url>/database/MySQL/syntax_2_in_or/</url>
    <content><![CDATA[<p>MySQL会对sql语句做优化， </p>
<ol>
<li>in 后面的条件不超过一定数量仍然会使用索引。mysql 会根据索引长度和in后面条件数量判断是否使用索引。</li>
<li>如果是in后面是子查询，则不会使用索引。此时采用<code>join</code>来替换</li>
<li>使用<code>union all</code>代替<code>in</code>和<code>or</code></li>
</ol>
<h1 id="使用union-all优化的样例"><a href="#使用union-all优化的样例" class="headerlink" title="使用union all优化的样例"></a>使用<code>union all</code>优化的样例</h1><p>一个文章库，里面有两个表：category和article。category里面有10条分类数据。article里面有 20万条。article里面有一个”article_category”字段是与category里的”category_id”字段相对应的。 article表里面已经把 article_category字义为了索引。数据库大小为1.3G。</p>
<p><strong>问题描述：</strong></p>
<p>执行一个很普通的查询： </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Select</span> <span class="operator">*</span> <span class="keyword">FROM</span> `article` <span class="keyword">Where</span> article_category<span class="operator">=</span><span class="number">11</span> <span class="keyword">orDER</span> <span class="keyword">BY</span> article_id <span class="keyword">DESC</span> LIMIT <span class="number">5</span> </span><br></pre></td></tr></table></figure>
<p>执行时间大约要5秒左右</p>
<p><strong>解决方案：</strong><br>建一个索引：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> index idx_u <span class="keyword">on</span> article (article_category,article_id);</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Select</span> <span class="operator">*</span> <span class="keyword">FROM</span> `article` <span class="keyword">Where</span> article_category<span class="operator">=</span><span class="number">11</span> <span class="keyword">orDER</span> <span class="keyword">BY</span> article_id <span class="keyword">DESC</span> LIMIT <span class="number">5</span> </span><br></pre></td></tr></table></figure>
<p>减少到0.0027秒</p>
<p><strong>继续问题：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Select</span> <span class="operator">*</span> <span class="keyword">FROM</span> `article` <span class="keyword">Where</span> article_category <span class="keyword">IN</span> (<span class="number">2</span>,<span class="number">3</span>) <span class="keyword">orDER</span> <span class="keyword">BY</span> article_id <span class="keyword">DESC</span> LIMIT <span class="number">5</span> </span><br></pre></td></tr></table></figure>
<p>执行时间要11.2850秒。</p>
<p><strong>使用OR:</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> article</span><br><span class="line"><span class="keyword">where</span> article_category<span class="operator">=</span><span class="number">2</span></span><br><span class="line"><span class="keyword">or</span> article_category<span class="operator">=</span><span class="number">3</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> article_id <span class="keyword">desc</span></span><br><span class="line">limit <span class="number">5</span></span><br></pre></td></tr></table></figure>
<p>执行时间：11.0777</p>
<p><strong>解决方案：</strong><br>避免使用in 或者 or (or会导致扫表)，使用union all</p>
<p><strong>使用UNION ALL：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">(<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> article <span class="keyword">where</span> article_category<span class="operator">=</span><span class="number">2</span> <span class="keyword">order</span> <span class="keyword">by</span> article_id <span class="keyword">desc</span> limit <span class="number">5</span>)</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> (<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> article <span class="keyword">where</span> article_category<span class="operator">=</span><span class="number">3</span> <span class="keyword">order</span> <span class="keyword">by</span> article_id <span class="keyword">desc</span> limit <span class="number">5</span>)</span><br><span class="line"><span class="keyword">orDER</span> <span class="keyword">BY</span> article_id <span class="keyword">desc</span></span><br><span class="line">limit <span class="number">5</span></span><br></pre></td></tr></table></figure>
<p>执行时间：0.0261</p>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>SQL</tag>
        <tag>in</tag>
        <tag>or</tag>
      </tags>
  </entry>
  <entry>
    <title>【基础】MySQL语法基础</title>
    <url>/database/MySQL/syntax_1/</url>
    <content><![CDATA[<p>本文主要介绍SQL语言以及部分MySQL的基础知识。</p>
<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><p>MySQL的默认的端口号是3306 超级用户是<code>root</code></p>
<p>MySql引擎</p>
<p><img src="/images/j2ee/MySQL/MySql-Engine.png"></p>
<h1 id="MySQL提示符-命令与语法规范"><a href="#MySQL提示符-命令与语法规范" class="headerlink" title="MySQL提示符 命令与语法规范"></a>MySQL提示符 命令与语法规范</h1><p>MySQL的所有的指令都是以结束符结束的, 回车提交命令. 默认的提示符是<code>;</code>号.</p>
<h2 id="修改提示符"><a href="#修改提示符" class="headerlink" title="修改提示符"></a>修改提示符</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">prompt localhost;</span><br><span class="line">将提示符修改为localhost</span><br></pre></td></tr></table></figure>
<p>之后每一行的提示符由<code>mysql&gt;</code>变为<code>localhost&gt;</code>， 还可以使用通配符修改提示符。</p>
<h2 id="常用指令"><a href="#常用指令" class="headerlink" title="常用指令"></a>常用指令</h2><p>通过<code>SELECT</code>执行内置函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> VERSION(); <span class="operator">/</span><span class="operator">/</span>显示当前服务器版本</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="operator">|</span> VERSION()  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5.5</span><span class="number">.19</span><span class="operator">-</span>log <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> NOW(); <span class="operator">/</span><span class="operator">/</span>显示当前日期时间</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------+</span></span><br><span class="line"><span class="operator">|</span> NOW()               <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2016</span><span class="number">-04</span><span class="number">-12</span> <span class="number">08</span>:<span class="number">51</span>:<span class="number">44</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">USER</span>(); <span class="operator">/</span><span class="operator">/</span>显示当前用户</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">USER</span>()         <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> root<span class="variable">@localhost</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br></pre></td></tr></table></figure>
<h2 id="语法规范："><a href="#语法规范：" class="headerlink" title="语法规范："></a>语法规范：</h2><ul>
<li>关键字和函数名称必须全部大写</li>
<li>数据库名称 表名称 字段名称全部小写</li>
<li>SQL语句必须以分号结尾</li>
</ul>
<p>命名规则：</p>
<ul>
<li>可读性原则：驼峰提高可读性</li>
<li>表意性原则：对象的名字能反应对象的意义</li>
<li>长名原则：少用缩写</li>
</ul>
<h1 id="操作数据库"><a href="#操作数据库" class="headerlink" title="操作数据库"></a>操作数据库</h1><p>创建数据库</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">CREATE &#123;DATABASE|SCHEMA&#125;[IF NOT EXISTS] db_name</span><br><span class="line">[<span class="keyword">DEFAULT</span>] <span class="type">CHARACTER</span> <span class="keyword">SET</span> [<span class="operator">=</span>] charset_name</span><br><span class="line"><span class="comment">--- MySQL中SCHEMA与DATABASE名称相同</span></span><br></pre></td></tr></table></figure>
<p>查看当前MySql服务器下的数据库</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">SHOW &#123;DATABASES|SCHEMAS&#125;</span><br><span class="line">[<span class="keyword">LIKE</span> <span class="string">&#x27;pattern&#x27;</span><span class="operator">|</span><span class="keyword">WHERE</span> EXPR]</span><br></pre></td></tr></table></figure>
<p>修改数据库</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">ALTER &#123;DATABASE|SCHEMA&#125;[db_name]</span><br><span class="line">[<span class="keyword">DEFAULT</span>]<span class="type">CHARACTER</span> <span class="keyword">SET</span> [<span class="operator">=</span>] charset_name</span><br></pre></td></tr></table></figure>
<p>删除数据库</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">DROP &#123;DATABASE|SCHEMA&#125;[IF NOT EXISTS] db_name</span><br></pre></td></tr></table></figure>
<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><p>MySQL中的数据类型主要有整形 浮点型 字符型和日期时间型.<br>字段的类型影响着存储容量和数据查询性能。当可以选择多种类型时，优先选择数字类型，<br>其次是日期和二进制类型，最后是字符类型。相同级别的类型优先选择省空间的类型。</p>
<p><img src="/images/j2ee/MySQL/MySql-DataType.png"></p>
<p>对于上述原则主要从下面两个方面考虑：</p>
<ol>
<li>在对数据进行比较时(查询条件、JOIN条件及排序)操作时，<br><strong>同样的数据，字符处理往往比数字处理慢</strong></li>
<li>在数据库中，数据处理以页为单位，<strong>列的长度越小，利于性能提升</strong></li>
</ol>
<p>char与varchar选择:</p>
<ol>
<li>如果列中要存储的数据长度差不多是一致的，则应该考虑用char；否则应该用varchar。</li>
<li>如果列中的最大数据长度小于50Byte，则一般也考虑用char.(当然，如果这个列很少用，<br>则基于节省空间和较少I/O的考虑，还是可以选择用varchar)</li>
<li>一般不宜定义大于50Byte的char类型列。</li>
</ol>
<h2 id="整形"><a href="#整形" class="headerlink" title="整形"></a>整形</h2><p><img src="/images/j2ee/MySQL/MySql-DataType-Number.png"></p>
<h2 id="浮点型"><a href="#浮点型" class="headerlink" title="浮点型"></a>浮点型</h2><p><img src="/images/j2ee/MySQL/MySql-DataType-Float.png"></p>
<h2 id="日期时间型"><a href="#日期时间型" class="headerlink" title="日期时间型"></a>日期时间型</h2><p><img src="/images/j2ee/MySQL/MySql-DataType-DateTime.png"></p>
<h2 id="字符型"><a href="#字符型" class="headerlink" title="字符型"></a>字符型</h2><p><img src="/images/j2ee/MySQL/MySql-DataType-String.png"></p>
<h1 id="操作数据表"><a href="#操作数据表" class="headerlink" title="操作数据表"></a>操作数据表</h1><h2 id="打开数据库"><a href="#打开数据库" class="headerlink" title="打开数据库"></a>打开数据库</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">USE db_name; <span class="operator">/</span><span class="operator">/</span>打开数据库</span><br></pre></td></tr></table></figure>
<h2 id="创建数据表"><a href="#创建数据表" class="headerlink" title="创建数据表"></a>创建数据表</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name(</span><br><span class="line">  column_name data_type,</span><br><span class="line">  ....</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>查看创建当前数据库的语句:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> provinces(</span><br><span class="line">    id <span class="type">SMALLINT</span> UNSIGNED <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> AUTO_INCREMENT,</span><br><span class="line">    pname <span class="type">VARCHAR</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">  );</span><br><span class="line">显示创建数据库的语句</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> provinces;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">Table</span>     <span class="operator">|</span> <span class="keyword">Create</span> <span class="keyword">Table</span>                                                                                                                                                                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> provinces <span class="operator">|</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `provinces` (</span><br><span class="line">  `id` <span class="type">smallint</span>(<span class="number">5</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `pname` <span class="type">varchar</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (`id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>latin1 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>以表格的形式显示列和列的属性</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> columns <span class="keyword">from</span> provinces;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Field <span class="operator">|</span> Type                 <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> id    <span class="operator">|</span> <span class="type">smallint</span>(<span class="number">5</span>) unsigned <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> auto_increment <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> pname <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">20</span>)          <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.03</span> sec)</span><br><span class="line"><span class="keyword">desc</span> provinces;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Field <span class="operator">|</span> Type                 <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> id    <span class="operator">|</span> <span class="type">smallint</span>(<span class="number">5</span>) unsigned <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> auto_increment <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> pname <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">20</span>)          <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>


<h2 id="查看数据库中的数据表列表"><a href="#查看数据库中的数据表列表" class="headerlink" title="查看数据库中的数据表列表"></a>查看数据库中的数据表列表</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> TABLES [<span class="keyword">FROM</span> db_name]</span><br><span class="line">[<span class="keyword">LIKE</span> <span class="string">&#x27;pattern&#x27;</span><span class="operator">|</span><span class="keyword">WHERE</span> expr]</span><br></pre></td></tr></table></figure>
<h2 id="插入记录"><a href="#插入记录" class="headerlink" title="插入记录"></a>插入记录</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> [<span class="keyword">INTO</span>] table_name [(column_name,...)] <span class="keyword">VALUES</span>(var,...)</span><br></pre></td></tr></table></figure>
<h2 id="记录查找"><a href="#记录查找" class="headerlink" title="记录查找"></a>记录查找</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> expr,... <span class="keyword">FROM</span> table_name</span><br></pre></td></tr></table></figure>
<p>select 子句中可以包含子查询</p>
<h2 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h2><ol>
<li>约束保证数据的完整性和一致性</li>
<li>约束分为表级约束和列级约束</li>
<li>约束类型包括:<ul>
<li>NOT NULL 非空元素</li>
<li>PRIMARY KEY 主键约束</li>
<li>UNIQUE KEY 唯一约束</li>
<li>DEFAULT 默认约束</li>
<li>FOREIGN KEY 外键约束.</li>
</ul>
</li>
</ol>
<h3 id="自增长-AUTO-INCREMENT"><a href="#自增长-AUTO-INCREMENT" class="headerlink" title="自增长 AUTO_INCREMENT"></a>自增长 AUTO_INCREMENT</h3><ol>
<li>自动编号，且该字段必须是主键：<br>AUTO_INCREMENT必须是主键，主键不一定AUTO_INCREMENT</li>
<li>默认情况下，其实值是1，每次增量是1</li>
</ol>
<p>插入数据时可以使用<code>DEFAULT</code>或者<code>NULL</code>为自增长字段赋值，以生成自增长数据。</p>
<p>例如在上面的<code>provinces</code>表中, 插入数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> provinces <span class="keyword">values</span>(<span class="keyword">null</span>,<span class="string">&#x27;&#x27;</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.08</span> sec)</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> provinces <span class="keyword">values</span>(<span class="keyword">DEFAULT</span>,<span class="string">&#x27;&#x27;</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.08</span> sec)</span><br><span class="line"> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> provinces;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------+</span></span><br><span class="line"><span class="operator">|</span> id <span class="operator">|</span> pname <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">1</span> <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">2</span> <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<h3 id="主键约束-PRIMARY-KEY"><a href="#主键约束-PRIMARY-KEY" class="headerlink" title="主键约束 PRIMARY KEY"></a>主键约束 PRIMARY KEY</h3><ol>
<li>主键约束</li>
<li>每张数据表只能存在一个主键</li>
<li>主键保证记录的唯一性</li>
<li>主键自动为<code>NOT NULL</code></li>
</ol>
<h3 id="唯一约束"><a href="#唯一约束" class="headerlink" title="唯一约束"></a>唯一约束</h3><ol>
<li>保证记录的唯一性</li>
<li>字段可以为空值(NULL) 且可以多个为空</li>
<li>每张表可以有多个唯一约束</li>
</ol>
<h3 id="默认值约束-DEFAULT"><a href="#默认值约束-DEFAULT" class="headerlink" title="默认值约束 DEFAULT"></a>默认值约束 DEFAULT</h3><p>当插入记录时， 如果没有明确为字段赋值，则自动赋值为默认值。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tb6(</span><br><span class="line">    id <span class="type">SMALLINT</span> UNSIGNED AUTO_INCREMENT <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span>,</span><br><span class="line">    username <span class="type">VARCHAR</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">UNIQUE</span> KEY,</span><br><span class="line">    sex ENUM(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>查看表格结构</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> COLUMNS <span class="keyword">FROM</span> tb6;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Field    <span class="operator">|</span> Type                 <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> id       <span class="operator">|</span> <span class="type">smallint</span>(<span class="number">5</span>) unsigned <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> auto_increment <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> username <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">20</span>)          <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> UNI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> sex      <span class="operator">|</span> enum(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>)    <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------+------+-----+---------+----------------+</span></span><br></pre></td></tr></table></figure>
<p>使用默认值插入记录</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>使用<span class="keyword">DEFAULT</span>来生成AUTO_INCREMENT</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> tb6 <span class="keyword">VALUES</span>(<span class="keyword">Default</span>,&quot;李四&quot;,<span class="keyword">DEFAULT</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.08</span> sec)</span><br><span class="line"></span><br><span class="line"><span class="keyword">Select</span> <span class="operator">*</span>  <span class="keyword">from</span> tb6;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+----------+------+</span></span><br><span class="line"><span class="operator">|</span> id <span class="operator">|</span> username <span class="operator">|</span> sex  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----------+------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">1</span> <span class="operator">|</span> 李四   <span class="operator">|</span> <span class="number">3</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----------+------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>指定字段为枚举类型: 与Java中的枚举类型不同, sql中的枚举只是限制取值范围.</p>
<h3 id="外键约束"><a href="#外键约束" class="headerlink" title="外键约束"></a>外键约束</h3><p>要求</p>
<ol>
<li>父表和字表必须使用相同的存储引擎, 而且禁止使用临时表</li>
<li>数据表的引擎必须只能是InnoDB</li>
<li>外键列和参照列必须具有相似的数据类型, 其中数字的长度或是否有符号位必须相同;<br> 而字符的长度则可以不同.</li>
<li>外键列和参照列必须创建索引.如果外键列不存在索引, MySQL将自动创建索引.</li>
</ol>
<p>实例</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> provinces(</span><br><span class="line">    id <span class="type">SMALLINT</span> UNSIGNED <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> AUTO_INCREMENT,</span><br><span class="line">    pname <span class="type">VARCHAR</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> users(</span><br><span class="line">   id <span class="type">SMALLINT</span> UNSIGNED <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> AUTO_INCREMENT,</span><br><span class="line">   username <span class="type">VARCHAR</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">   pid <span class="type">SMALLINT</span> UNSIGNED,</span><br><span class="line">   <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span>(pid) <span class="keyword">REFERENCES</span> provinces(id) );</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.08</span> sec)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> INDEXES <span class="keyword">FROM</span> provinces\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">       <span class="keyword">Table</span>: provinces</span><br><span class="line">  Non_unique: <span class="number">0</span></span><br><span class="line">    Key_name: <span class="keyword">PRIMARY</span></span><br><span class="line">Seq_in_index: <span class="number">1</span></span><br><span class="line"> Column_name: id</span><br><span class="line">   <span class="keyword">Collation</span>: A</span><br><span class="line"> <span class="keyword">Cardinality</span>: <span class="number">0</span></span><br><span class="line">    Sub_part: <span class="keyword">NULL</span></span><br><span class="line">      Packed: <span class="keyword">NULL</span></span><br><span class="line">        <span class="keyword">Null</span>:</span><br><span class="line">  Index_type: BTREE</span><br><span class="line">     Comment:</span><br><span class="line">Index_comment:</span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>外键约束的操作操作</p>
<ol>
<li>CASCADE: 从父表删除或更新且自动删除或更新子表中匹配的行</li>
<li>SET NULL: 从父表删除或更新行, 并设置子表中的外键列为NULL.  如果使用该选项, 必须保证子表列没有指定NOT NULL</li>
<li>RESTRICT: 拒绝对父表的删除或更新操作</li>
<li>NO ACTION: 标准SQL关键字, 在MySQL中与RESTRICT相同</li>
</ol>
<h3 id="表级约束与列级约束"><a href="#表级约束与列级约束" class="headerlink" title="表级约束与列级约束 ??"></a>表级约束与列级约束 ??</h3><p>对于一个数据列建立的约束, 称为列级约束.<br>对多个数据列建立的约束, 称为表级约束.<br>列级约束既可以在列定义时声明,也可以在列定义后声明.<br>表级约束只能在列级约束后声明.</p>
<h2 id="修改数据表"><a href="#修改数据表" class="headerlink" title="修改数据表"></a>修改数据表</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> [<span class="keyword">COLUMN</span>] column_name</span><br><span class="line">  column_definition [<span class="keyword">FIRST</span><span class="operator">|</span>AFTER column_name]</span><br><span class="line">添加多列</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> [<span class="keyword">COLUMN</span>]</span><br><span class="line">  (column_name column_definition, ....)</span><br><span class="line">删除列</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">DROP</span> [<span class="keyword">COLUMN</span>] column_name</span><br><span class="line">添加主键约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> [<span class="keyword">CONSTRAINT</span> [symbol]]</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> [Index_type](index_column_name,...)</span><br><span class="line">添加唯一约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> [<span class="keyword">CONSTRAINT</span> [symbol]]</span><br><span class="line">  <span class="keyword">UNIQUE</span> [INDEX<span class="operator">|</span>KEY][index_name][index_type]</span><br><span class="line">  (index_column_name,...)</span><br><span class="line">添加<span class="operator">/</span>删除默认约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ALTER</span> [<span class="keyword">COLUMN</span>] column_name</span><br><span class="line">&#123;SET DEFAULT litera&#125;</span><br><span class="line">如:</span><br><span class="line">  <span class="keyword">ALTER</span> <span class="keyword">TABLE</span> users2 <span class="keyword">ALTER</span> age <span class="keyword">DROP</span> <span class="keyword">DEFAULT</span>;</span><br><span class="line">删除主键约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">DROP</span> <span class="keyword">PRIMARY</span> <span class="keyword">Key</span></span><br><span class="line">删除唯一约束</span><br><span class="line">ALTER TABLE table_name DROP &#123;INDEX|KEY&#125; index_name</span><br><span class="line">删除外键约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">DROP</span> <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> fk_symbol</span><br><span class="line">修改列定义</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name MODIFY [<span class="keyword">COLUMN</span>] column_name</span><br><span class="line">  column_definition [<span class="keyword">FIRST</span><span class="operator">|</span>AFTER column_name]</span><br><span class="line">修改列名称</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name CHANGE [<span class="keyword">COLUMN</span>] old_column_name</span><br><span class="line">  new_column_name column_definition [<span class="keyword">FIRST</span><span class="operator">|</span>AFTER column_name]</span><br><span class="line">数据表更名</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name RENAME [<span class="keyword">TO</span><span class="operator">|</span><span class="keyword">AS</span>] new_table_name</span><br><span class="line">或</span><br><span class="line">RENAME <span class="keyword">TABLE</span> table_name <span class="keyword">TO</span> new_table_name</span><br><span class="line">  [, table_name2 <span class="keyword">TO</span> new_table_name2] ...</span><br></pre></td></tr></table></figure>
<h1 id="操作数据表中的记录"><a href="#操作数据表中的记录" class="headerlink" title="操作数据表中的记录"></a>操作数据表中的记录</h1><h2 id="插入记录-1"><a href="#插入记录-1" class="headerlink" title="插入记录"></a>插入记录</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">INSERT [INTO] table_name [(column_name,....)] &#123;VALUES|VALUE&#125;</span><br><span class="line">(&#123;expr|DEFAULT&#125;,...),(...),...</span><br><span class="line"></span><br><span class="line">INSERT [INTO] table_name SET column_name=&#123;expr|DEFAULT&#125;,...</span><br><span class="line">此方法可以使用子查询</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> [<span class="keyword">INTO</span>] table_name [(column_name,...)] <span class="keyword">SELECT</span> ...</span><br></pre></td></tr></table></figure>
<h2 id="单表更新"><a href="#单表更新" class="headerlink" title="单表更新"></a>单表更新</h2><p>单表更新，可以根据字段的当前值，进行判断。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 将user_info表中，user_id&gt;1000的信息状态置反。</span></span><br><span class="line"><span class="keyword">UPDATE</span> user_info</span><br><span class="line"><span class="keyword">SET</span> `status`<span class="operator">=</span> (<span class="keyword">CASE</span> <span class="keyword">WHEN</span> <span class="string">&#x27;status&#x27;</span><span class="operator">=</span><span class="number">1</span> <span class="keyword">THEN</span> <span class="number">0</span> <span class="keyword">WHEN</span> `status`<span class="operator">=</span><span class="number">0</span> <span class="keyword">THEN</span> <span class="number">1</span> <span class="keyword">END</span>)</span><br><span class="line"><span class="keyword">WHERE</span> `user_id` <span class="operator">&gt;</span> <span class="number">1000</span> ;</span><br><span class="line"><span class="comment">-- 将user_info表中的real_name去掉空格</span></span><br><span class="line"><span class="keyword">UPDATE</span> user_info</span><br><span class="line"><span class="keyword">SET</span> real_name<span class="operator">=</span><span class="built_in">TRIM</span>(real_name);</span><br></pre></td></tr></table></figure>




<h2 id="单表删除"><a href="#单表删除" class="headerlink" title="单表删除"></a>单表删除</h2><h2 id="查询表达式解析"><a href="#查询表达式解析" class="headerlink" title="查询表达式解析"></a>查询表达式解析</h2><h2 id="where语句进行条件查询"><a href="#where语句进行条件查询" class="headerlink" title="where语句进行条件查询"></a>where语句进行条件查询</h2><h2 id="group-by语句对查询结果分组"><a href="#group-by语句对查询结果分组" class="headerlink" title="group by语句对查询结果分组"></a>group by语句对查询结果分组</h2><h2 id="having语句设置分组条件"><a href="#having语句设置分组条件" class="headerlink" title="having语句设置分组条件"></a>having语句设置分组条件</h2><h2 id="order-by语句对查询结果排序"><a href="#order-by语句对查询结果排序" class="headerlink" title="order by语句对查询结果排序"></a>order by语句对查询结果排序</h2><h2 id="limit语句限制查询数量"><a href="#limit语句限制查询数量" class="headerlink" title="limit语句限制查询数量"></a>limit语句限制查询数量</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--语法：</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> LIMIT [<span class="keyword">offset</span>,] <span class="keyword">rows</span> <span class="operator">|</span> <span class="keyword">rows</span> <span class="keyword">OFFSET</span> <span class="keyword">offset</span></span><br><span class="line"><span class="comment">--举例：</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> limit <span class="number">5</span>; <span class="comment">--返回前5行</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> limit <span class="number">0</span>,<span class="number">5</span>; <span class="comment">--同上，返回前5行</span></span><br><span class="line"><span class="comment">---为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1：</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> LIMIT <span class="number">95</span>,<span class="number">-1</span>; <span class="comment">--- 检索记录行 96-last.</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> limit <span class="number">5</span>,<span class="number">10</span>; <span class="comment">--返回6-15行</span></span><br></pre></td></tr></table></figure>
<p>当一个查询语句偏移量offset很大的时候，如<code>select * from table limit 10000,10 </code>,<br>最好不要直接使用limit，而是先获取到offset的id后，再直接使用limit size来获取数据。<br>效果会好很多。** 想办法减少offset **</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">From</span> customers <span class="keyword">Where</span> customer_id <span class="operator">&gt;=</span>(</span><br><span class="line">  <span class="comment">--- 查找第1000条记录对应的id, id是索引, 检索速度快</span></span><br><span class="line">  <span class="keyword">select</span> customer_id <span class="keyword">From</span> customers <span class="keyword">Order</span> <span class="keyword">By</span> customer_id limit <span class="number">10000</span>,<span class="number">1</span></span><br><span class="line">) limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure>
<p>** 通过将查询条件(即where子句)的字段加索引,可以大大提高查询速度. **</p>
<h1 id="子查询与连接"><a href="#子查询与连接" class="headerlink" title="子查询与连接"></a>子查询与连接</h1><h2 id="内连接-join从句"><a href="#内连接-join从句" class="headerlink" title="内连接 join从句"></a>内连接 join从句</h2><p>SQL标准中有5种连接：</p>
<ul>
<li>内连接 inner</li>
<li>全外连接 full outer</li>
<li>左外连接 left outer</li>
<li>右外连接 right outer</li>
<li>交叉连接 cross</li>
</ul>
<h3 id="内连接-inner-join"><a href="#内连接-inner-join" class="headerlink" title="内连接 inner join"></a>内连接 inner join</h3><p>取两个表的交集， 即公共部分</p>
<p><img src="/images/j2ee/MySQL/inner-join.png"></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.`column1`, a.`column2`, b.`column3`</span><br><span class="line"><span class="keyword">FROM</span> `table_name1` <span class="keyword">AS</span> a</span><br><span class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> `table_name2` <span class="keyword">AS</span> b</span><br><span class="line"><span class="keyword">ON</span> a.`column4`<span class="operator">=</span>b.`column5`;</span><br></pre></td></tr></table></figure>
<h3 id="左外连接-left-outer-join"><a href="#左外连接-left-outer-join" class="headerlink" title="左外连接 left outer join"></a>左外连接 left outer join</h3><p><img src="/images/j2ee/MySQL/left-outer-join.png"></p>
<p>右图中的部分， 可以用于替换<code>NOT IN</code></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.`column1`, a.`column2`, b.`column3`</span><br><span class="line"><span class="keyword">FROM</span> `table_name1` <span class="keyword">AS</span> a</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> `table_name2` <span class="keyword">AS</span> b</span><br><span class="line"><span class="keyword">ON</span> a.`column4`<span class="operator">=</span>b.`column5`</span><br><span class="line"><span class="keyword">WHERE</span> b.`column3` <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>
<h3 id="右外连接-right-outer-join"><a href="#右外连接-right-outer-join" class="headerlink" title="右外连接 right outer join"></a>右外连接 right outer join</h3><p><img src="/images/j2ee/MySQL/right-outer-join.png"></p>
<p>右图中的部分， 可以用于替换<code>NOT IN</code></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.`column1`, a.`column2`, b.`column3`</span><br><span class="line"><span class="keyword">FROM</span> `table_name1` <span class="keyword">AS</span> a</span><br><span class="line"><span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> `table_name2` <span class="keyword">AS</span> b</span><br><span class="line"><span class="keyword">ON</span> a.`column4`<span class="operator">=</span>b.`column5`</span><br><span class="line"><span class="keyword">WHERE</span> a.`column3` <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>
<h3 id="全外连接-FULL-OUTER-JOIN"><a href="#全外连接-FULL-OUTER-JOIN" class="headerlink" title="全外连接 FULL OUTER JOIN"></a>全外连接 FULL OUTER JOIN</h3><p><img src="/images/j2ee/MySQL/full-outer-join.png"></p>
<p>MySQL 中默认是不包含全外连接查询的， 可以通过其他方式实现同样的效果。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.`column1`, a.`column2`, b.`column3`</span><br><span class="line"><span class="keyword">FROM</span> `table_name1` <span class="keyword">AS</span> a</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> `table_name2` <span class="keyword">AS</span> b</span><br><span class="line"><span class="keyword">ON</span> a.`column4`<span class="operator">=</span>b.`column5`</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> a.`column1`, a.`column2`, b.`column3`</span><br><span class="line"><span class="keyword">FROM</span> `table_name1` <span class="keyword">AS</span> a</span><br><span class="line"><span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> `table_name2` <span class="keyword">AS</span> b</span><br><span class="line"><span class="keyword">ON</span> a.`column4`<span class="operator">=</span>b.`column5`</span><br></pre></td></tr></table></figure>
<h3 id="交叉连接-CROSS-JOIN"><a href="#交叉连接-CROSS-JOIN" class="headerlink" title="交叉连接 CROSS JOIN"></a>交叉连接 CROSS JOIN</h3><p>笛卡尔积<br>A表中的每一条记录和B表中的每一条记录组合: 结果的长度为A的长度×B的长度.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.`column1`, a.`column2`, b.`column3`</span><br><span class="line"><span class="keyword">FROM</span> `table_name1` <span class="keyword">AS</span> a</span><br><span class="line"><span class="keyword">CROSS</span> <span class="keyword">JOIN</span> `table_name2` <span class="keyword">AS</span> b</span><br></pre></td></tr></table></figure>


<h1 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h1><p>函数主要分为字符函数 数值函数 日期时间函数 加密函数</p>
<h2 id="字符函数"><a href="#字符函数" class="headerlink" title="字符函数"></a>字符函数</h2><p><img src="/images/j2ee/MySQL/MySQL-function-String01.png"><br><img src="/images/j2ee/MySQL/MySQL-function-String02.png"></p>
<p>对特殊字符的Escape</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test <span class="keyword">WHERE</span> first_name <span class="keyword">LIKE</span> <span class="string">&#x27;%1%%&#x27;</span> <span class="keyword">ESCAPE</span> <span class="string">&#x27;1&#x27;</span></span><br><span class="line">表示<span class="number">1</span>后面的<span class="operator">%</span>是真实的字符而不是转意字符</span><br></pre></td></tr></table></figure>
<h3 id="substring"><a href="#substring" class="headerlink" title="substring"></a>substring</h3><p><code>SUBSTR (str, pos)</code></p>
<p>由 <str> 中，选出所有从第 <pos> 位置开始的字元。请注意，这个语法不适用于 SQL Server 上。</p>
<p><code>SUBSTR (str, pos, len)</code></p>
<p>由 <str> 中的第 <pos> 位置开始，选出接下去的 <len> 个字元。</p>
<h2 id="数值函数"><a href="#数值函数" class="headerlink" title="数值函数"></a>数值函数</h2><p><img src="/images/j2ee/MySQL/MySQL-function-Number01.png"></p>
<h2 id="比较运算符和函数"><a href="#比较运算符和函数" class="headerlink" title="比较运算符和函数"></a>比较运算符和函数</h2><p><img src="/images/j2ee/MySQL/MySQL-function-Compare01.png"></p>
<h2 id="日期时间函数"><a href="#日期时间函数" class="headerlink" title="日期时间函数"></a>日期时间函数</h2><p><img src="/images/j2ee/MySQL/MySQL-function-DateTime01.png"></p>
<p><a href="http://www.cnblogs.com/zeroone/archive/2010/05/05/1727659.html">详细请看</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> DATE_ADD(<span class="string">&#x27;2016-04-12&#x27;</span>, <span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">YEAR</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> DATE_ADD(<span class="string">&#x27;2016-04-12&#x27;</span>, <span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">YEAR</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-12</span>                              <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> DATE_ADD(<span class="string">&#x27;2016-04-12&#x27;</span>, <span class="type">INTERVAL</span> <span class="number">3</span> WEEK);</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> DATE_ADD(<span class="string">&#x27;2016-04-12&#x27;</span>, <span class="type">INTERVAL</span> <span class="number">3</span> WEEK) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2016</span><span class="number">-05</span><span class="number">-03</span>                              <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> DATE_FORMAT(<span class="string">&#x27;2016-3-2&#x27;</span>,<span class="string">&#x27;%m/%d/%Y&#x27;</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> DATE_FORMAT(<span class="string">&#x27;2016-3-2&#x27;</span>,<span class="string">&#x27;%m/%d/%Y&#x27;</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">03</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">2016</span>                         <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br></pre></td></tr></table></figure>


<h3 id="时间与时间戳的转换"><a href="#时间与时间戳的转换" class="headerlink" title="时间与时间戳的转换"></a>时间与时间戳的转换</h3><ol>
<li><p>unix_timestamp</p>
<p>将时间转化为时间戳。（date 类型数据转换成 timestamp 形式整数）</p>
<p>没传时间参数则取当前时间的时间戳</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MySQL<span class="operator">&gt;</span> <span class="keyword">select</span> unix_timestamp();</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+</span></span><br><span class="line"><span class="operator">|</span> unix_timestamp() <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">1361586358</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> unix_timestamp(<span class="string">&#x27;2013-01-01 10:10:10&#x27;</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> unix_timestamp(<span class="string">&#x27;2013-01-01 10:10:10&#x27;</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                            <span class="number">1357006210</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure></li>
<li><p>from_unixtime</p>
<p>将timestamp 形式整数 转化为 date类型</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span>  <span class="keyword">select</span> from_unixtime(<span class="number">1355272360</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+</span></span><br><span class="line"><span class="operator">|</span> from_unixtime(<span class="number">1355272360</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2012</span><span class="number">-12</span><span class="number">-12</span> <span class="number">08</span>:<span class="number">32</span>:<span class="number">40</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>当然也可以指定输出的时间格式：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span>  <span class="keyword">select</span> from_unixtime(<span class="number">1355272360</span>,<span class="string">&#x27;%Y%m%d&#x27;</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> from_unixtime(<span class="number">1355272360</span>,<span class="string">&#x27;%Y%m%d&#x27;</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20121212</span>                           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------+</span></span><br></pre></td></tr></table></figure></li>
<li><p>关于mysql 时间戳的限制</p>
<p>  目前timestamp 所能表示的范围在 1970年  -  2038年之间 。</p>
<p>  超过这个范围 得到的时间将会溢出 得到的时间是null.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span>  <span class="keyword">select</span> from_unixtime(<span class="number">0</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------+</span></span><br><span class="line"><span class="operator">|</span> from_unixtime(<span class="number">0</span>)    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------+</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> from_unixtime(<span class="number">2147483647</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+</span></span><br><span class="line"><span class="operator">|</span> from_unixtime(<span class="number">2147483647</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2038</span><span class="number">-01</span><span class="number">-19</span> <span class="number">11</span>:<span class="number">14</span>:<span class="number">07</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure></li>
<li><p>SQL中的timestamp与Java中的转换</p>
<p>SQL中的时间戳是从1970年1月1日 8:00:00 开始的毫秒数</p>
<table>
<thead>
<tr>
<th>SQL中的时间戳</th>
<th>1970-1-1 8:00:00 开始的毫秒数</th>
</tr>
</thead>
<tbody><tr>
<td>java.util.Date()</td>
<td>内置时间 getYear()是从1900年开始的</td>
</tr>
<tr>
<td>java.util.Date().getTime()</td>
<td>从1970-1-1 8:00:00 开始的微妙数</td>
</tr>
<tr>
<td>java.sql.Timestamp()</td>
<td>与java.util.Date()相同</td>
</tr>
<tr>
<td>java.sql.Date</td>
<td>只保存年月日，没有时分秒</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
</li>
</ol>
   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Timestamp是一个与 java.util.Date 类有关的瘦包装器 (thin wrapper)，它允许 JDBC API 将该类标识为 SQL TIMESTAMP 值。它添加保存 SQL TIMESTAMP 毫微秒值和提供支持时间戳值的 JDBC 转义语法的格式化和解析操作的能力。</span><br></pre></td></tr></table></figure>
<p>   因此，在SQL中的时间戳与Java中传递进来的long型时间比较时，需要乘以1000.</p>
<h2 id="信息函数"><a href="#信息函数" class="headerlink" title="信息函数"></a>信息函数</h2><p><img src="/images/j2ee/MySQL/MySQL-function-Information01.png"></p>
<h2 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h2><p><img src="/images/j2ee/MySQL/MySQL-function-Aggregate01.png"></p>
<h2 id="加密函数"><a href="#加密函数" class="headerlink" title="加密函数"></a>加密函数</h2><p><img src="/images/j2ee/MySQL/MySQL-function-Encryption01.png"></p>
<p>password函数只适用于设置MySQL的密码</p>
<h2 id="XML支持"><a href="#XML支持" class="headerlink" title="XML支持"></a>XML支持</h2><p><a href="https://dev.mysql.com/doc/refman/5.5/en/xml-functions.html">xml支持</a> :xml的函数主要有两个 ExtractValue 和  UpdateXML</p>
<h3 id="ExtractValue"><a href="#ExtractValue" class="headerlink" title="ExtractValue"></a>ExtractValue</h3><p>​```sql<br>mysql&gt; SELECT<br>    -&gt;   ExtractValue(‘<a>ccc<b>ddd</b></a>‘, ‘/a’) AS val1,<br>    -&gt;   ExtractValue(‘<a>ccc<b>ddd</b></a>‘, ‘/a/b’) AS val2,<br>    -&gt;   ExtractValue(‘<a>ccc<b>ddd</b></a>‘, ‘//b’) AS val3,<br>    -&gt;   ExtractValue(‘<a>ccc<b>ddd</b></a>‘, ‘/b’) AS val4,<br>    -&gt;   ExtractValue(‘<a>ccc<b>ddd</b><b>eee</b></a>‘, ‘//b’) AS val5;</p>
<p>+——+——+——+——+———+<br>| val1 | val2 | val3 | val4 | val5    |<br>+——+——+——+——+———+<br>| ccc  | ddd  | ddd  |      | ddd eee |<br>+——+——+——+——+———+<br>   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">### UpdateXML</span><br><span class="line"></span><br><span class="line">​&#96;&#96;&#96;sql</span><br><span class="line">mysql&gt; SELECT</span><br><span class="line">    -&gt;   UpdateXML(&#39;&lt;a&gt;&lt;b&gt;ccc&lt;&#x2F;b&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;&#x2F;a&gt;&#39;, &#39;&#x2F;a&#39;, &#39;&lt;e&gt;fff&lt;&#x2F;e&gt;&#39;) AS val1,</span><br><span class="line">    -&gt;   UpdateXML(&#39;&lt;a&gt;&lt;b&gt;ccc&lt;&#x2F;b&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;&#x2F;a&gt;&#39;, &#39;&#x2F;b&#39;, &#39;&lt;e&gt;fff&lt;&#x2F;e&gt;&#39;) AS val2,</span><br><span class="line">    -&gt;   UpdateXML(&#39;&lt;a&gt;&lt;b&gt;ccc&lt;&#x2F;b&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;&#x2F;a&gt;&#39;, &#39;&#x2F;&#x2F;b&#39;, &#39;&lt;e&gt;fff&lt;&#x2F;e&gt;&#39;) AS val3,</span><br><span class="line">    -&gt;   UpdateXML(&#39;&lt;a&gt;&lt;b&gt;ccc&lt;&#x2F;b&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;&#x2F;a&gt;&#39;, &#39;&#x2F;a&#x2F;d&#39;, &#39;&lt;e&gt;fff&lt;&#x2F;e&gt;&#39;) AS val4,</span><br><span class="line">    -&gt;   UpdateXML(&#39;&lt;a&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;b&gt;ccc&lt;&#x2F;b&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;&#x2F;a&gt;&#39;, &#39;&#x2F;a&#x2F;d&#39;, &#39;&lt;e&gt;fff&lt;&#x2F;e&gt;&#39;) AS val5</span><br><span class="line">    -&gt; \G</span><br><span class="line"></span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">val1: &lt;e&gt;fff&lt;&#x2F;e&gt;</span><br><span class="line">val2: &lt;a&gt;&lt;b&gt;ccc&lt;&#x2F;b&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;&#x2F;a&gt;</span><br><span class="line">val3: &lt;a&gt;&lt;e&gt;fff&lt;&#x2F;e&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;&#x2F;a&gt;</span><br><span class="line">val4: &lt;a&gt;&lt;b&gt;ccc&lt;&#x2F;b&gt;&lt;e&gt;fff&lt;&#x2F;e&gt;&lt;&#x2F;a&gt;</span><br><span class="line">val5: &lt;a&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;b&gt;ccc&lt;&#x2F;b&gt;&lt;d&gt;&lt;&#x2F;d&gt;&lt;&#x2F;a&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h1><p>自定义函数(user-defined function,UDF)是一种对MySQL扩展的途径,<br>其用法与内置函数相同. 自定义函数的两个必要条件:<br><code>参数</code>和<code>返回值</code>. 函数可以返回任意类型的值, 同样也可以接受这些类型的参数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> function_name</span><br><span class="line">RETURNS &#123;STRING|INTEGER|REAL|DECIMAL&#125;</span><br><span class="line">routine_body</span><br></pre></td></tr></table></figure>
<p>函数体</p>
<ol>
<li>由合法SQL语句构成</li>
<li>可以是简单的SELECT或INSERT语句</li>
<li>如果是复合结构,必须使用<code>BEGIN</code>…<code>END</code>语句</li>
<li>复合结构可以包括声明,循环,控制结构</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> f1()</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="type">VARCHAR</span>(<span class="number">30</span>)</span><br><span class="line"><span class="keyword">RETURN</span> DATE_FORMAT(NOW(),<span class="string">&#x27;%Y年%m月%d日 %H点%i分%s秒&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> f1();</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------------------+</span></span><br><span class="line"><span class="operator">|</span> f1()                           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2016</span>年<span class="number">04</span>月<span class="number">12</span>日 <span class="number">10</span>点<span class="number">51</span>分<span class="number">24</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------------------+</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> f2(num1 <span class="type">SMALLINT</span> UNSIGNED, num2 <span class="type">SMALLINT</span> UNSIGNED)</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="type">FLOAT</span>(<span class="number">10</span>,<span class="number">2</span>) UNSIGNED</span><br><span class="line"><span class="keyword">RETURN</span> (num1<span class="operator">+</span>num2)<span class="operator">/</span><span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> f2(<span class="number">35</span>,<span class="number">46</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"><span class="operator">|</span> f2(<span class="number">35</span>,<span class="number">46</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"><span class="operator">|</span>     <span class="number">40.50</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"></span><br><span class="line">DELIMITER <span class="operator">/</span><span class="operator">/</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> adduser(username <span class="type">VARCHAR</span>(<span class="number">20</span>))</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="type">INT</span> UNSIGNED</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line"><span class="keyword">INSERT</span> test(username) <span class="keyword">VALUES</span>(username);</span><br><span class="line"><span class="keyword">RETURN</span> LAST_INSERT_ID();</span><br><span class="line"><span class="keyword">END</span></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span></span><br><span class="line">DELIMITER ;</span><br></pre></td></tr></table></figure>

<h1 id="存储过程"><a href="#存储过程" class="headerlink" title="存储过程"></a>存储过程</h1><p>SQL命令的执行过程</p>
<p><img src="/images/j2ee/MySQL/MySQL-execute.png"></p>
<p>存储过程是SQL语句和控制语句的预编译集合, 以一个名称存储并作为一个单元处理. 其优点有:</p>
<ol>
<li>增强SQL语句的功能和灵活性</li>
<li>实现较快的执行速度</li>
<li>减少网络流量</li>
</ol>
<p>语法格式为:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span></span><br><span class="line">[DEFINER=&#123;USER|CURRENT_USER&#125;]</span><br><span class="line"><span class="keyword">PROCEDURE</span> sp_name ([proc_parameter[,...]])</span><br><span class="line">[characteristic ...] routine_body</span><br><span class="line"></span><br><span class="line">proc_parameter:</span><br><span class="line">[<span class="keyword">IN</span><span class="operator">|</span><span class="keyword">OUT</span><span class="operator">|</span><span class="keyword">INOUT</span>]parameter_name type</span><br><span class="line"></span><br><span class="line">调用</span><br><span class="line"><span class="keyword">CALL</span> sp_name([<span class="keyword">parameter</span>[,...]])</span><br><span class="line"><span class="keyword">CALL</span> sp_name[()]</span><br></pre></td></tr></table></figure>
<p>参数</p>
<ul>
<li>IN 表示该参数的值必须在调用存储过程时指定</li>
<li>OUT 表示该参数的值可以被存储过程改变, 并且可以返回</li>
<li>INOUT 表示该参数的调用时指定,并且可以被改变和返回</li>
</ul>
<p>过程体</p>
<ul>
<li>过程体由合法的SQL语句构成</li>
<li>过程体可以是任意SQL语句</li>
<li>过程体如果为复合结构则使用BEGIN…END语句</li>
<li>复合结构可以包含声明,循环,控制结果</li>
</ul>
<p>实例</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> delimiter <span class="operator">/</span><span class="operator">/</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> removeUserById(<span class="keyword">IN</span> ppid <span class="type">INT</span> UNSIGNED)</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">BEGIN</span></span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">DELETE</span> <span class="keyword">FROM</span> users <span class="keyword">WHERE</span> id<span class="operator">=</span>ppid;</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">END</span></span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="operator">/</span><span class="operator">/</span></span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> DELIMITER ;</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">delimiter <span class="operator">/</span><span class="operator">/</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">procedure</span> removeUserAndReturnUserNums(<span class="keyword">in</span> pid <span class="type">int</span> unsigned,<span class="keyword">out</span> useNums <span class="type">int</span> unsigned)</span><br><span class="line">	<span class="keyword">begin</span></span><br><span class="line">	<span class="keyword">delete</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id<span class="operator">=</span>pid;</span><br><span class="line">	<span class="keyword">select</span> <span class="built_in">count</span>(id) <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">into</span> useNums;</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="operator">/</span><span class="operator">/</span></span><br><span class="line">delimiter ;</span><br><span class="line"></span><br><span class="line">调用</span><br><span class="line"><span class="keyword">call</span> removeUserAndReturnUserNums(<span class="number">27</span>,<span class="variable">@nums</span>);</span><br><span class="line"><span class="keyword">select</span> <span class="variable">@nums</span>;</span><br><span class="line">通过<span class="keyword">declare</span>语句声明的变量是局部变量, 作用域只能在<span class="keyword">begin</span>和<span class="keyword">end</span>之间.</span><br><span class="line"><span class="keyword">select</span> <span class="variable">@nums</span>;</span><br><span class="line"><span class="keyword">set</span> <span class="variable">@num</span><span class="operator">=</span><span class="number">7</span>;</span><br><span class="line">这种声明方式声明的变量成为用户变量. 作用域是客户端,只在当前的客户端有效.</span><br></pre></td></tr></table></figure>
<p>获取插入 删除 更新的记录总数.<br>select row_count();</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">delimiter <span class="operator">/</span><span class="operator">/</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">procedure</span> removeUserAndReturnInfos(<span class="keyword">in</span> p_age <span class="type">smallint</span> unsigned,</span><br><span class="line">    <span class="keyword">out</span> deleteUsers <span class="type">smallint</span> unsigned, <span class="keyword">out</span> userCounts <span class="type">smallint</span> unsigned)</span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> age<span class="operator">=</span>p_age;</span><br><span class="line"><span class="keyword">select</span> row_count() <span class="keyword">into</span> deleteUsers;</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(id) <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">into</span> userCounts;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span></span><br><span class="line">delimiter ;</span><br><span class="line"></span><br><span class="line"><span class="keyword">call</span> removeUserAndReturnInfos(<span class="number">20</span>,<span class="variable">@rm</span>,<span class="variable">@rl</span>);</span><br><span class="line"><span class="keyword">select</span> <span class="variable">@rm</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="variable">@rl</span>;</span><br></pre></td></tr></table></figure>
<p>删除存储过程</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">PROCEDURE</span> [IF <span class="keyword">EXISTS</span>] sp_name</span><br></pre></td></tr></table></figure>
<p>存储过程与自定义函数的区别</p>
<ol>
<li>存储过程实现的功能更复杂一些 而函数的针对性更强</li>
<li>存储过程可以返回多个值;函数只能有一个返回值</li>
<li>存储过程一般独立的执行;而函数可以作为其他SQL语句的组成部分来出现.</li>
</ol>
<p>创建存储过程或者自定义函数时需要通过<code>delimiter</code>语句修改定界符.</p>
<h1 id="用户权限"><a href="#用户权限" class="headerlink" title="用户权限"></a>用户权限</h1><p>在 MySQL5.7 中 user 表的 password 已换成了authentication_string。<br>注意：在注意需要执行 FLUSH PRIVILEGES 语句。 这个命令执行后会重新载入授权表。<br>如果你不使用该命令，你就无法使用新创建的用户来连接mysql服务器，除非你重启mysql服务器。<br>你可以在创建用户时，为用户指定权限，在对应的权限列中，在插入语句中设置为 ‘Y’ 即可，用户权限列表如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Select_priv</span><br><span class="line">Insert_priv</span><br><span class="line">Update_priv</span><br><span class="line">Delete_priv</span><br><span class="line">Create_priv</span><br><span class="line">Drop_priv</span><br><span class="line">Reload_priv</span><br><span class="line">Shutdown_priv</span><br><span class="line">Process_priv</span><br><span class="line">File_priv</span><br><span class="line">Grant_priv</span><br><span class="line">References_priv</span><br><span class="line">Index_priv</span><br><span class="line">Alter_priv</span><br></pre></td></tr></table></figure>
<p>  除非你使用 LIKE 来比较字符串，否则MySQL的WHERE子句的字符串比较是不区分大小写的。 你可以使用 BINARY 关键字来设定WHERE子句的字符串比较是区分大小写的。<br>如下实例</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">root@host#</span><span class="bash"> mysql -u root -p password;</span></span><br><span class="line">Enter password:*******</span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> use RUNOOB;</span></span><br><span class="line">Database changed</span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> SELECT * from runoob_tbl \</span></span><br><span class="line"><span class="bash">          WHERE BINARY runoob_author=<span class="string">&#x27;sanjay&#x27;</span>;</span></span><br><span class="line">Empty set (0.02 sec)</span><br></pre></td></tr></table></figure>
<p>为了处理这种情况，MySQL提供了三大运算符:</p>
<ul>
<li>IS NULL: 当列的值是NULL,此运算符返回true。</li>
<li>IS NOT NULL: 当列的值不为NULL, 运算符返回true。</li>
<li>&lt;=&gt;: 比较操作符（不同于=运算符），当比较的的两个值为NULL时返回true。<br>关于 NULL 的条件比较运算是比较特殊的。你不能使用 = NULL 或 != NULL 在列中查找 NULL 值 。<br>在MySQL中，NULL值与任何其它值的比较（即使是NULL）永远返回false，即 NULL = NULL 返回false 。<br>MySQL中处理NULL使用IS NULL和IS NOT NULL运算符。</li>
</ul>
<h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><p><a href="http://www.runoob.com/mysql/mysql-regexp.html">http://www.runoob.com/mysql/mysql-regexp.html</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> name <span class="keyword">FROM</span> person_tbl <span class="keyword">WHERE</span> name REGEXP <span class="string">&#x27;^st&#x27;</span>;</span><br></pre></td></tr></table></figure>
<h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p>索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索包含多个列。<br>创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)。<br>实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。<br>上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。<br>建立索引会占用磁盘空间的索引文件。</p>
<h2 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h2><p>有四种方式来添加数据表的索引：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tbl_name <span class="keyword">ADD</span> <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (column_list):</span><br><span class="line"></span><br><span class="line">该语句添加一个主键，这意味着索引值必须是唯一的，且不能为<span class="keyword">NULL</span>。</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tbl_name <span class="keyword">ADD</span> <span class="keyword">UNIQUE</span> index_name (column_list): 这条语句创建索引的值必须是唯一的（除了<span class="keyword">NULL</span>外，<span class="keyword">NULL</span>可能会出现多次）。</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tbl_name <span class="keyword">ADD</span> INDEX index_name (column_list): 添加普通索引，索引值可出现多次。</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tbl_name <span class="keyword">ADD</span> FULLTEXT index_name (column_list):该语句指定了索引为 FULLTEXT ，用于全文索引。</span><br></pre></td></tr></table></figure>
<h2 id="创建临时表"><a href="#创建临时表" class="headerlink" title="创建临时表"></a>创建临时表</h2><p>如果你退出当前MySQL会话，再使用 SELECT命令来读取原先创建的临时表数据，那你会发现数据库中没有该表的存在，因为在你退出时该临时表已经被销毁了。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">TABLE</span> SalesSummary (</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> product_name <span class="type">VARCHAR</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> , total_sales <span class="type">DECIMAL</span>(<span class="number">12</span>,<span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="number">0.00</span></span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> , avg_unit_price <span class="type">DECIMAL</span>(<span class="number">7</span>,<span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="number">0.00</span></span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> , total_units_sold <span class="type">INT</span> UNSIGNED <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="number">0</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h1 id="复制表"><a href="#复制表" class="headerlink" title="复制表"></a>复制表</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> runoob_tbl \G;</span><br></pre></td></tr></table></figure>
<p>修改数据表名，执行SQL语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> clone_tbl (runoob_id,</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span>                        runoob_title,</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span>                        runoob_author,</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span>                        submission_date)</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> runoob_id,runoob_title,</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span>        runoob_author,submission_date</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">FROM</span> runoob_tbl;</span><br></pre></td></tr></table></figure>
<h1 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h1><p>查询结果信息  数据库和数据表的信息 服务器信息</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> VERSION( ) 服务器版本信息</span><br><span class="line"><span class="keyword">SELECT</span> DATABASE( )  当前数据库名 (或者返回空)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">USER</span>( )  当前用户名</span><br><span class="line"><span class="keyword">SHOW</span> STATUS 服务器状态</span><br><span class="line"><span class="keyword">SHOW</span> VARIABLES  服务器配置变量</span><br><span class="line"><span class="keyword">show</span> processList; 连接MySQL的所有线程的信息</span><br><span class="line"><span class="keyword">SHOW</span>  <span class="keyword">OPEN</span> TABLES  <span class="keyword">WHERE</span> In_use<span class="operator">&gt;</span><span class="number">0</span> 所有打开的数据表</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="自增序列"><a href="#自增序列" class="headerlink" title="自增序列"></a>自增序列</h1><p>在MySQL的客户端中你可以使用 SQL中的LAST_INSERT_ID( ) 函数来获取最后的插入表中的自增列的值 Java如何获取</p>
<h2 id="重置序列"><a href="#重置序列" class="headerlink" title="重置序列"></a>重置序列</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> ALTER TABLE insect DROP id;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> ALTER TABLE insect</span></span><br><span class="line">    -&gt; ADD id INT UNSIGNED NOT NULL AUTO_INCREMENT FIRST,</span><br><span class="line">    -&gt; ADD PRIMARY KEY (id);</span><br></pre></td></tr></table></figure>
<h2 id="设置序列的开始值"><a href="#设置序列的开始值" class="headerlink" title="设置序列的开始值"></a>设置序列的开始值</h2><p>一般情况下序列的开始值为1，但如果你需要指定一个开始值100，那我们可以通过以下语句来实现：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> insect</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> (</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> id <span class="type">INT</span> UNSIGNED <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT <span class="operator">=</span> <span class="number">100</span>,</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (id),</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> name <span class="type">VARCHAR</span>(<span class="number">30</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>, # type <span class="keyword">of</span> insect</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="type">date</span> <span class="type">DATE</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>, # <span class="type">date</span> collected</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> origin <span class="type">VARCHAR</span>(<span class="number">30</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> # <span class="keyword">where</span> collected</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>或者你也可以在表创建成功后，通过以下语句来实现：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER</span> <span class="keyword">TABLE</span> t AUTO_INCREMENT <span class="operator">=</span> <span class="number">100</span>;</span><br></pre></td></tr></table></figure>


<h1 id="防止数据重复"><a href="#防止数据重复" class="headerlink" title="防止数据重复"></a>防止数据重复</h1><p>设置字段为primary key或者unique索引</p>
<h2 id="INSERT-IGNORE"><a href="#INSERT-IGNORE" class="headerlink" title="INSERT IGNORE"></a>INSERT IGNORE</h2><p>INTO当插入数据时，在设置了记录的唯一性后，如果插入重复数据，将不返回错误，只以警告形式返回。 而REPLACE INTO into如果存在primary 或 unique相同的记录，则先删除掉。再插入新记录。</p>
<h2 id="添加一个UNIQUE索引，如下所示："><a href="#添加一个UNIQUE索引，如下所示：" class="headerlink" title="添加一个UNIQUE索引，如下所示："></a>添加一个UNIQUE索引，如下所示：</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> person_tbl</span><br><span class="line">(</span><br><span class="line">   first_name <span class="type">CHAR</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">   last_name <span class="type">CHAR</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">   sex <span class="type">CHAR</span>(<span class="number">10</span>)</span><br><span class="line">   <span class="keyword">UNIQUE</span> (last_name, first_name)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>


<h1 id="统计重复数据"><a href="#统计重复数据" class="headerlink" title="统计重复数据"></a>统计重复数据</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">as</span> repetitions, last_name, first_name <span class="keyword">FROM</span> person_tbl <span class="keyword">GROUP</span> <span class="keyword">BY</span> last_name, first_name <span class="keyword">HAVING</span> repetitions <span class="operator">&gt;</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<h1 id="过滤重复数据"><a href="#过滤重复数据" class="headerlink" title="过滤重复数据"></a>过滤重复数据</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> last_name, first_name</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">FROM</span> person_tbl</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> last_name;</span><br></pre></td></tr></table></figure>
<p>你也可以使用 GROUP BY 来读取数据表中不重复的数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> last_name, first_name</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">FROM</span> person_tbl</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> (last_name, first_name);</span><br></pre></td></tr></table></figure>
<h2 id="删除重复数据"><a href="#删除重复数据" class="headerlink" title="删除重复数据"></a>删除重复数据</h2><p>如果你想删除数据表中的重复数据，你可以使用以下的SQL语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tmp <span class="keyword">SELECT</span> last_name, first_name, sex</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span>                  <span class="keyword">FROM</span> person_tbl;</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span>                  <span class="keyword">GROUP</span> <span class="keyword">BY</span> (last_name, first_name);</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">DROP</span> <span class="keyword">TABLE</span> person_tbl;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tmp RENAME <span class="keyword">TO</span> person_tbl;</span><br></pre></td></tr></table></figure>
<p>当然你也可以在数据表中添加 INDEX（索引） 和 PRIMAY KEY（主键）这种简单的方法来删除表中的重复记录。方法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER</span> IGNORE <span class="keyword">TABLE</span> person_tbl</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">ADD</span> <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (last_name, first_name);</span><br></pre></td></tr></table></figure>



<h1 id="SQL注入"><a href="#SQL注入" class="headerlink" title="SQL注入"></a>SQL注入</h1><p>防止SQL注入，我们需要注意以下几个要点：</p>
<ol>
<li>永远不要信任用户的输入。对用户的输入进行校验，可以通过正则表达式，或限制长度；对单引号和 双”-“进行转换等。</li>
<li>永远不要使用动态拼装sql，可以使用参数化的sql或者直接使用存储过程进行数据查询存取。</li>
<li>永远不要使用管理员权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。</li>
<li>不要把机密信息直接存放，加密或者hash掉密码和敏感的信息。</li>
<li>应用的异常信息应该给出尽可能少的提示，最好使用自定义的错误信息对原始错误信息进行包装</li>
<li>sql注入的检测方法一般采取辅助软件或网站平台来检测，软件一般采用sql注入检测工具jsky，网站平台就有亿思网站安全平台检测工具。MDCSOFT SCAN等。采用MDCSOFT-IPS可以有效的防御SQL注入，XSS攻击等。</li>
</ol>
<h2 id="SQL-like语句注入"><a href="#SQL-like语句注入" class="headerlink" title="SQL like语句注入"></a>SQL like语句注入</h2><p>like查询时，如果用户输入的值有”<em>“和”%”，则会出现这种情况：用户本来只是想查询”abcd</em>“，查询结果中却有”abcd_”、”abcde”、”abcdf”等等；用户要查询”30%”（注：百分之三十）时也会出现问题。</p>
<h1 id="备份与导入"><a href="#备份与导入" class="headerlink" title="备份与导入"></a>备份与导入</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysqldump <span class="operator">-</span>u <span class="operator">&lt;</span>USER_HOME<span class="operator">&gt;</span> <span class="operator">-</span>p <span class="operator">&lt;</span>DATABASE_NAME <span class="operator">&gt;</span> news.sql   <span class="comment">-- 输入后会让你输入进入MySQL的密码</span></span><br><span class="line"><span class="comment">-- 登陆</span></span><br><span class="line">mysql<span class="operator">&gt;</span> use <span class="operator">&lt;</span>DATABASE_NAME<span class="operator">&gt;</span>;</span><br><span class="line">mysql<span class="operator">&gt;</span> source news.sql;</span><br><span class="line"><span class="comment">-- 或者</span></span><br><span class="line">mysql <span class="operator">-</span>u <span class="operator">&lt;</span>USER_HOME<span class="operator">&gt;</span> <span class="operator">-</span>p <span class="operator">&lt;</span>DATABASE_NAME<span class="operator">&gt;</span> <span class="operator">&lt;</span> news.sql</span><br><span class="line"><span class="comment">-- 输入密码即可</span></span><br></pre></td></tr></table></figure>


<blockquote>
<p>更新记录：</p>
<ol>
<li>创建 2016-04-11</li>
<li>添加 时间戳与Java中时间的区别  2016-12-27</li>
</ol>
</blockquote>
<hr>
<p>[参考文献]:</p>
<ol>
<li><a href="http://www.cnblogs.com/zeroone/archive/2010/05/05/1727659.html">MySQL日期时间函数大全</a></li>
</ol>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL多表关联与笛卡尔积</title>
    <url>/database/MySQL/syntax_3_multitable_join/</url>
    <content><![CDATA[<h1 id="多表关联"><a href="#多表关联" class="headerlink" title="多表关联"></a>多表关联</h1><p>内联接 外联接 左外联接 右外连接 全外连接 自然联接</p>
<h1 id="笛卡尔"><a href="#笛卡尔" class="headerlink" title="笛卡尔"></a>笛卡尔</h1><p>笛卡尔（Descartes）乘积又叫直积。假设集合A={a,b}，集合B={0,1,2}，则两个集合的笛卡尔积为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">(a,0),</span><br><span class="line">(a,1),</span><br><span class="line">(a,2),</span><br><span class="line">(b,0),</span><br><span class="line">(b,1),</span><br><span class="line">(b,2)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以扩展到多个集合的情况。</p>
<h2 id="内连接"><a href="#内连接" class="headerlink" title="内连接"></a>内连接</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a,b <span class="keyword">where</span> a.x <span class="operator">=</span> b.x; <span class="operator">/</span><span class="operator">/</span>内连接</span><br></pre></td></tr></table></figure>
<p>与</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">inner</span> <span class="keyword">join</span> b <span class="keyword">on</span> a.x<span class="operator">=</span>b.x; <span class="operator">/</span><span class="operator">/</span>内连接</span><br></pre></td></tr></table></figure>
<p>效果是一样的，都是计算笛卡尔积，对上面笛卡尔积的每一条记录看它是否满足限制条件，如果满足，则它在结果集中。</p>
<h2 id="外连接"><a href="#外连接" class="headerlink" title="外连接"></a>外连接</h2><p>当外连接，不加任何条件时，也会计算笛卡尔积。如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">left</span> <span class="keyword">join</span> b <span class="keyword">on</span> <span class="number">1</span><span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<h2 id="交叉连接-CROSS-JOIN"><a href="#交叉连接-CROSS-JOIN" class="headerlink" title="交叉连接(CROSS JOIN)"></a>交叉连接(CROSS JOIN)</h2><p>没有WHERE 子句，它返回<code>连接表</code>中所有数据行的笛卡尔积<br>先返回 左表所有行，左表行在与右表行一一组合，等于两个表相乘.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">cross</span> <span class="keyword">join</span> b <span class="keyword">where</span> a.x<span class="operator">=</span>b.x;</span><br></pre></td></tr></table></figure>
<p>等同于</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">inner</span> <span class="keyword">join</span> b <span class="keyword">on</span> a.x<span class="operator">=</span>b.x;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>MySQL中不存在交叉连接</p>
</blockquote>
<h2 id="避免笛卡尔积的方法"><a href="#避免笛卡尔积的方法" class="headerlink" title="避免笛卡尔积的方法"></a>避免笛卡尔积的方法</h2><p>由于笛卡尔积的结果集是各个查询表规模之积，往往是数量级的差别。</p>
<h3 id="转换为子查询"><a href="#转换为子查询" class="headerlink" title="转换为子查询"></a>转换为子查询</h3><p>假设存在如下三个表:</p>
<p>查询方式一:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span></span><br><span class="line">	u.user_id <span class="keyword">AS</span> recommendUserId</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">	user_info u</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">	<span class="number">1</span> <span class="operator">=</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">AND</span> u.user_id <span class="keyword">IN</span> (</span><br><span class="line">	<span class="keyword">SELECT</span></span><br><span class="line">		a.entity_id</span><br><span class="line">	<span class="keyword">FROM</span></span><br><span class="line">		address_info a</span><br><span class="line">	<span class="keyword">WHERE</span></span><br><span class="line">		a.city_code <span class="operator">=</span> <span class="number">10010</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>查询方式二：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span></span><br><span class="line">	u.user_id <span class="keyword">AS</span> recommendUserId</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">	user_info u,</span><br><span class="line">	address_info a</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">	<span class="number">1</span> <span class="operator">=</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">AND</span> a.city_code <span class="operator">=</span> <span class="string">&#x27;10010&#x27;</span></span><br></pre></td></tr></table></figure>
<p>对比发现： ‘查询方式一’使用了子查询，查询是分两步进行的，第一步先从<code>address_info</code>选出一个结果，然后在<code>user_info</code>中查询，规模为<code>user_info</code>的大小。<br>而<code>查询方式二</code>查询规模是笛卡尔积，即<code>user_info</code>与<code>address_info</code>规模之积。</p>
<h1 id="内连接-1"><a href="#内连接-1" class="headerlink" title="内连接"></a>内连接</h1><p>内连 接只保留交叉积中满足连接条件的那些行。如果某行在一个表中存在，但在另一个表中不存在，则结果表中不包括该信息。</p>
<h1 id="外连接-1"><a href="#外连接-1" class="headerlink" title="外连接"></a>外连接</h1><p>左外连 接包括内连 接和左表中未包括在内连 接中的那些行。</p>
<p>右外连 接包括内连 接和右表中未包括在内连 接中的那些行。</p>
<p>全外连 接包括内连 接以及左表和右表中未包括在内连 接中的行。<br>内连 接一般是检索两个表里连接字段都存在的数据。<br>左连接的意思是，查询左（语句前面）表里的所有内容，无论右边表里有没有。右边表里没有的内容用NULL代替。<br>右连接和左连接相反。</p>
<h2 id="左外连接"><a href="#左外连接" class="headerlink" title="左外连接"></a>左外连接</h2><h2 id="右外连接"><a href="#右外连接" class="headerlink" title="右外连接"></a>右外连接</h2><h2 id="全外连接"><a href="#全外连接" class="headerlink" title="全外连接"></a>全外连接</h2><h1 id="交叉连接"><a href="#交叉连接" class="headerlink" title="交叉连接"></a>交叉连接</h1><hr>
<p>[参考文献]：</p>
<ol>
<li><a href="http://blog.sina.com.cn/s/blog_8250c39a0101k74c.html">SQL中—-SELECT语句中内连接,左连接,右连接,自连接和全连接 </a></li>
</ol>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>MySQL</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL高级语法</title>
    <url>/database/MySQL/syntax_4_advanced/</url>
    <content><![CDATA[<h1 id="replace-into"><a href="#replace-into" class="headerlink" title="replace into"></a>replace into</h1><p><code>replace into t(id, update_time) values(1, now());</code><br>或<br><code>replace into t(id, update_time) select 1, now();</code></p>
<p><code>replace into</code> 跟 <code>insert</code> 功能类似，不同点在于：<br><code>replace into</code> 首先尝试插入数据到表中，</p>
<ol>
<li>如果发现表中已经有此行数据（根据主键或者唯一索引判断）则先删除此行数据，然后插入新的数据。</li>
<li>否则，直接插入新数据。</li>
</ol>
<p>要注意的是：插入数据的表必须有主键或者是唯一索引！否则的话，<code>replace into</code> 会直接插入数据，这将导致表中出现重复的数据。<br>MySQL replace into 有三种形式：</p>
<ol>
<li><code>replace into tbl_name(col_name, ...) values(...)</code></li>
<li><code>replace into tbl_name(col_name, ...) select ...</code></li>
<li><code>replace into tbl_name set col_name=value, ...</code></li>
</ol>
<p>前两种形式用的多些。其中 “into” 关键字可以省略，不过最好加上 “into”，这样意思更加直观。另外，对于那些没有给予值的列，MySQL 将自动为这些列赋上默认值。</p>
<h1 id="MySQL高级"><a href="#MySQL高级" class="headerlink" title="MySQL高级"></a>MySQL高级</h1><h1 id="理解SQL语句"><a href="#理解SQL语句" class="headerlink" title="理解SQL语句"></a>理解SQL语句</h1><h1 id="创建外键的SQL语句"><a href="#创建外键的SQL语句" class="headerlink" title="创建外键的SQL语句"></a>创建外键的SQL语句</h1><h2 id="创建数据表"><a href="#创建数据表" class="headerlink" title="创建数据表"></a>创建数据表</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> a(</span><br><span class="line">  id <span class="type">INT</span> <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span>,</span><br><span class="line">  b_id <span class="type">INT</span>,</span><br><span class="line">  <span class="keyword">CONSTRAINT</span> b_fk <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> (b_id) <span class="keyword">REFERENCES</span> b(id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h2 id="修改数据表"><a href="#修改数据表" class="headerlink" title="修改数据表"></a>修改数据表</h2><figure class="highlight"><table><tr><td class="code"><pre><span class="line">[<span class="keyword">CONSTRAINT</span> symbol] <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> [id] (index_col_name, ...)  </span><br><span class="line">    <span class="keyword">REFERENCES</span> tbl_name (index_col_name, ...)  </span><br><span class="line">    [ON DELETE &#123;RESTRICT | CASCADE | SET NULL | NO ACTION&#125;]  </span><br><span class="line">    [ON UPDATE &#123;RESTRICT | CASCADE | SET NULL | NO ACTION&#125;]  </span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">ALTERT <span class="keyword">TABLE</span> a</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> b_fk <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> b_id <span class="keyword">REFERENCES</span> b(id);</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">ALTERT <span class="keyword">TABLE</span> a</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> b_fk(b_id)  <span class="keyword">REFERENCES</span> b(id);</span><br></pre></td></tr></table></figure>
<h2 id="删除外键"><a href="#删除外键" class="headerlink" title="删除外键"></a>删除外键</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">ALTERT <span class="keyword">TABLE</span> a <span class="keyword">DROP</span> <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> b_fk;</span><br></pre></td></tr></table></figure>
<p>MySQL <code>KEY...REFERENCES</code>修饰符添加一个<code>ON DELETE</code> 或<code>ON UPDATE</code>子句简化任务，它告诉了数据库在这种情况如何处理孤立任务</p>
<table>
<thead>
<tr>
<th>关键字</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>CASCADE</td>
<td>删除包含与已删除键值有参照关系的所有记录</td>
</tr>
<tr>
<td>SET NULL</td>
<td>修改包含与已删除键值有参照关系的所有记录，使用NULL值替换（只能用于已标记为NOT NULL的字段）</td>
</tr>
<tr>
<td>RESTRICT</td>
<td>拒绝删除要求，直到使用删除键值的辅助表被手工删除，并且没有参照时(这是默认设置，也是最安全的设置)</td>
</tr>
<tr>
<td>NO ACTION</td>
<td>啥也不做</td>
</tr>
</tbody></table>
<p>请注意，通过ON UPDATE 和 ON DELETE规则，设置MySQL能够实现自动操作时，如果键的关系没有设置好，可能会导致严重的数据破坏，<br>例如：如果一系列的表通过外键关系和ON DELETE CASCADE 规则连接时，任意一个主表的变化都会导致甚至只和原始删除有一些将要联系的记录在没有警告的情况被删除，所以，我们在操作之前还要检查这些规则的，操作之后还要再次检查.</p>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p>事务回滚</p>
<h1 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h1><h1 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h1><h1 id="序列号"><a href="#序列号" class="headerlink" title="序列号"></a>序列号</h1><h1 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h1><h2 id="使用技巧"><a href="#使用技巧" class="headerlink" title="使用技巧"></a>使用技巧</h2><ol>
<li><p>如何更新使用过滤条件中包括自身的表?<br>在MySQL中, 不允许更新的表不能出现在FROM从句中, 但是可以使用JOIN从句中.</p>
<p>联合更新</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> user1 a <span class="keyword">JOIN</span>(</span><br><span class="line">  <span class="keyword">SELECT</span> b.`user_name`</span><br><span class="line">  <span class="keyword">FROM</span> user1 a <span class="keyword">INNER</span> <span class="keyword">JOIN</span> user2 b</span><br><span class="line">  <span class="keyword">ON</span> a.`user_name`<span class="operator">=</span> b.`user_name`</span><br><span class="line">) b <span class="keyword">ON</span> a.`user_name`<span class="operator">=</span>b.`user_name`</span><br><span class="line"><span class="keyword">SET</span> a.`<span class="keyword">over</span>`<span class="operator">=</span>`齐天大圣`;</span><br></pre></td></tr></table></figure>
<ol>
<li>优化子查询</li>
<li>优化聚合查询</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> a.user_name, b.timestr,b.kills  </span><br><span class="line"><span class="keyword">from</span> <span class="keyword">user</span> a  </span><br><span class="line"><span class="keyword">join</span> user_kills b</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>b.user_id</span><br><span class="line"><span class="keyword">where</span> b.kills<span class="operator">=</span>(</span><br><span class="line">  <span class="keyword">select</span> <span class="built_in">max</span>(c.kills) <span class="keyword">from</span> user_kills c <span class="keyword">where</span> c.user_id<span class="operator">=</span>b.user_id</span><br><span class="line">);  </span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.user_name,b.timestr,b.kills</span><br><span class="line"><span class="keyword">FROM</span> user1 a</span><br><span class="line"><span class="keyword">JOIN</span> user_kills b <span class="keyword">ON</span> a.id<span class="operator">=</span>b.user_id</span><br><span class="line"><span class="keyword">JOIN</span> user_kills c <span class="keyword">ON</span> c.user_id<span class="operator">=</span>b.user_id</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> a.user_name,b.timestr,c.kills</span><br><span class="line"><span class="keyword">HAVING</span> b.kills<span class="operator">=</span><span class="built_in">MAX</span>(c.kills);</span><br></pre></td></tr></table></figure>
<ol>
<li>如何实现分组选择</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> d.user_name, c.timestr , kills</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span> user_id,timestr,kills,</span><br><span class="line">  (<span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> user_kills b <span class="keyword">WHERE</span></span><br><span class="line">    b.user_id<span class="operator">=</span>a.user_id <span class="keyword">AND</span> a.kills<span class="operator">&lt;=</span>b.kills) <span class="keyword">AS</span> cnt</span><br><span class="line">    <span class="keyword">FROM</span> user_kills a</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> user_id,timestr,kills</span><br><span class="line">) c <span class="keyword">JOIN</span> user1 d <span class="keyword">ON</span> c.user_id<span class="operator">=</span>d.id</span><br><span class="line"><span class="keyword">WHERE</span> cnt<span class="operator">&lt;=</span><span class="number">2</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p>删除重复记录</p>
</li>
<li><p>行列转换</p>
</li>
</ol>
<p>MySQL</p>
<h1 id="SQL语句类型"><a href="#SQL语句类型" class="headerlink" title="SQL语句类型:"></a>SQL语句类型:</h1><ol>
<li>DDL 数据定义语言</li>
<li>TPL 事务处理语言</li>
<li>DCL 数据控制语言</li>
<li>DML 数据操作语言</li>
</ol>
<h1 id="事务-1"><a href="#事务-1" class="headerlink" title="事务"></a>事务</h1><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h1 id="JOIN"><a href="#JOIN" class="headerlink" title="JOIN"></a>JOIN</h1><p>只写JOIN, 默认是inner join</p>
<ol>
<li>更新使用过滤条件中包括自身的表?<br>不能更新from从句的表</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> user1 <span class="keyword">set</span> <span class="keyword">over</span><span class="operator">=</span><span class="string">&#x27;齐天大圣&#x27;</span> <span class="keyword">where</span> user1.user_name <span class="keyword">in</span> (</span><br><span class="line">        <span class="keyword">select</span> b.user_name <span class="keyword">from</span> user1 a <span class="keyword">join</span> user2 b <span class="keyword">on</span> a.user_name<span class="operator">=</span>b.user_name</span><br><span class="line">        );</span><br></pre></td></tr></table></figure>
<p>会报错!</p>
<p>使用JOIN可以解决此问题</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> user1 a <span class="keyword">join</span>(</span><br><span class="line">        <span class="keyword">select</span> b.user_name</span><br><span class="line">        <span class="keyword">from</span> user1 a</span><br><span class="line">        <span class="keyword">join</span> user2 b</span><br><span class="line">        <span class="keyword">on</span> a.user_name<span class="operator">=</span>b.user_name</span><br><span class="line">        ) b</span><br><span class="line"><span class="keyword">on</span> a.user_name<span class="operator">=</span>b.user_name</span><br><span class="line"><span class="keyword">set</span> a.over<span class="operator">=</span><span class="string">&#x27;齐天大圣&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>表结构：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [dbo].[Exam](</span><br><span class="line">    [S_date] [datetime] <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    [Order_Id] [<span class="type">varchar</span>](<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    [Product_Id] [<span class="type">varchar</span>](<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    [Amt] [<span class="type">numeric</span>](<span class="number">18</span>, <span class="number">0</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">) <span class="keyword">ON</span> [<span class="keyword">PRIMARY</span>]</span><br></pre></td></tr></table></figure>
<p>题目一: 写一条Sql语句查询前出100到199的记录<br>题目二: 写一条Sql语句删除重复[除时间外的所有字段字段相同]的记录,保留重复记录中时间最大的记录<br>题目三: 一条Sql语句查出年份,1月,2月,3月….12月的订单总数列表<br>题目四: 一条sql语句查询出年份,本月销量,上月销量,环比%,去年同期销量,同比%列表</p>
<p>1:</p>
<pre><code>select * from Exam limit 100,100</code></pre>
<p>2 :</p>
<p>3 :</p>
<p>   select year(s_date) as ‘年’ ,month(s_date) as ‘月’, count(Amt) as ‘订单数’ from Exam group by year(s_date),Month(s_date);</p>
<h2 id="导入-导出"><a href="#导入-导出" class="headerlink" title="导入/导出"></a>导入/导出</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">#导出整个库的表结构如下：</span><br><span class="line">mysqldump <span class="operator">-</span>uroot <span class="operator">-</span>p <span class="operator">-</span>d databasename <span class="operator">&gt;</span> createtab.sql，</span><br><span class="line"></span><br><span class="line">#如果只想导出 表 test1，test2，test3 的 表结构 和 数据呢？</span><br><span class="line">#该如何导出？</span><br><span class="line"></span><br><span class="line">mysqldump <span class="operator">-</span>uroot <span class="operator">-</span>p <span class="operator">-</span>d databasename test1 test2 test3 <span class="operator">&gt;</span> createtab.sql</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 上面的是导出指定表结构，下面这个可以导出指定表结构和数据</span></span><br><span class="line">mysqldump <span class="operator">-</span>uroot <span class="operator">-</span>p <span class="comment">--tables databasename &gt; createtab.sql</span></span><br><span class="line"></span><br><span class="line">mysqldump <span class="operator">-</span>uroot <span class="operator">-</span>p <span class="operator">-</span>d databasename test1 test2 test3 <span class="operator">&gt;</span> createtab.sql</span><br></pre></td></tr></table></figure>
<h1 id="exist-与-in的区别"><a href="#exist-与-in的区别" class="headerlink" title="exist 与 in的区别"></a>exist 与 in的区别</h1><h1 id="union与union-all"><a href="#union与union-all" class="headerlink" title="union与union all"></a>union与union all</h1><h1 id="in的长度"><a href="#in的长度" class="headerlink" title="in的长度"></a>in的长度</h1><h1 id="in-与exist是否使用索引"><a href="#in-与exist是否使用索引" class="headerlink" title="in 与exist是否使用索引"></a>in 与exist是否使用索引</h1><h1 id="select-distinct-只能单个字段"><a href="#select-distinct-只能单个字段" class="headerlink" title="select  distinct  只能单个字段"></a>select  distinct  只能单个字段</h1>]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL SQL语法样例</title>
    <url>/database/MySQL/syntax_5_sample/</url>
    <content><![CDATA[<p>建立如下的表格:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tdb_goods;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------------------------------+---------------+------------+-------------+---------+------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id <span class="operator">|</span> goods_name                                                             <span class="operator">|</span> goods_cate    <span class="operator">|</span> brand_name <span class="operator">|</span> goods_price <span class="operator">|</span> is_show <span class="operator">|</span> is_saleoff <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------------------------------------------------------+---------------+------------+-------------+---------+------------+</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">1</span> <span class="operator">|</span> R510VC <span class="number">15.6</span>英寸笔记本                                                  <span class="operator">|</span> 笔记本        <span class="operator">|</span> 华硕       <span class="operator">|</span>    <span class="number">3399.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">2</span> <span class="operator">|</span> Y400N <span class="number">14.0</span>英寸笔记本电脑                                               <span class="operator">|</span> 笔记本        <span class="operator">|</span> 联想       <span class="operator">|</span>    <span class="number">4899.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">3</span> <span class="operator">|</span> G150TH <span class="number">15.6</span>英寸游戏本                                                  <span class="operator">|</span> 游戏本        <span class="operator">|</span> 雷神       <span class="operator">|</span>    <span class="number">8499.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">4</span> <span class="operator">|</span> X550CC <span class="number">15.6</span>英寸笔记本                                                  <span class="operator">|</span> 笔记本        <span class="operator">|</span> 华硕       <span class="operator">|</span>    <span class="number">2799.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">5</span> <span class="operator">|</span> X240(<span class="number">20</span>ALA0EYCD) <span class="number">12.5</span>英寸超极本                                        <span class="operator">|</span> 超级本        <span class="operator">|</span> 联想       <span class="operator">|</span>    <span class="number">4999.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">6</span> <span class="operator">|</span> U330P <span class="number">13.3</span>英寸超极本                                                   <span class="operator">|</span> 超级本        <span class="operator">|</span> 联想       <span class="operator">|</span>    <span class="number">4299.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">7</span> <span class="operator">|</span> SVP13226SCB <span class="number">13.3</span>英寸触控超极本                                         <span class="operator">|</span> 超级本        <span class="operator">|</span> 索尼       <span class="operator">|</span>    <span class="number">7999.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">8</span> <span class="operator">|</span> iPad mini MD531CH<span class="operator">/</span>A <span class="number">7.9</span>英寸平板电脑                                    <span class="operator">|</span> 平板电脑      <span class="operator">|</span> 苹果       <span class="operator">|</span>    <span class="number">1998.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">9</span> <span class="operator">|</span> iPad Air MD788CH<span class="operator">/</span>A <span class="number">9.7</span>英寸平板电脑 （<span class="number">16</span>G WiFi版）                      <span class="operator">|</span> 平板电脑      <span class="operator">|</span> 苹果       <span class="operator">|</span>    <span class="number">3388.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">10</span> <span class="operator">|</span>  iPad mini ME279CH<span class="operator">/</span>A 配备 Retina 显示屏 <span class="number">7.9</span>英寸平板电脑 （<span class="number">16</span>G WiFi版） <span class="operator">|</span> 平板电脑      <span class="operator">|</span> 苹果       <span class="operator">|</span>    <span class="number">2788.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">11</span> <span class="operator">|</span> IdeaCentre C340 <span class="number">20</span>英寸一体电脑                                         <span class="operator">|</span> 台式机        <span class="operator">|</span> 联想       <span class="operator">|</span>    <span class="number">3499.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">12</span> <span class="operator">|</span> Vostro <span class="number">3800</span><span class="operator">-</span>R1206 台式电脑                                             <span class="operator">|</span> 台式机        <span class="operator">|</span> 戴尔       <span class="operator">|</span>    <span class="number">2899.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">13</span> <span class="operator">|</span> iMac ME086CH<span class="operator">/</span>A <span class="number">21.5</span>英寸一体电脑                                        <span class="operator">|</span> 台式机        <span class="operator">|</span> 苹果       <span class="operator">|</span>    <span class="number">9188.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">14</span> <span class="operator">|</span> AT7<span class="number">-7414</span>LP 台式电脑 （i5<span class="number">-3450</span>四核 <span class="number">4</span>G <span class="number">500</span>G <span class="number">2</span>G独显 DVD 键鼠 Linux ）     <span class="operator">|</span> 台式机        <span class="operator">|</span> 宏碁       <span class="operator">|</span>    <span class="number">3699.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">15</span> <span class="operator">|</span> Z220SFF F4F06PA工作站                                                  <span class="operator">|</span> 服务器<span class="operator">/</span>工作站 <span class="operator">|</span> 惠普       <span class="operator">|</span>    <span class="number">4288.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">16</span> <span class="operator">|</span> PowerEdge T110 II服务器                                                <span class="operator">|</span> 服务器<span class="operator">/</span>工作站 <span class="operator">|</span> 戴尔       <span class="operator">|</span>    <span class="number">5388.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">17</span> <span class="operator">|</span> Mac Pro MD878CH<span class="operator">/</span>A 专业级台式电脑                                       <span class="operator">|</span> 服务器<span class="operator">/</span>工作站 <span class="operator">|</span> 苹果       <span class="operator">|</span>   <span class="number">28888.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">18</span> <span class="operator">|</span>  HMZ<span class="operator">-</span>T3W 头戴显示设备                                                  <span class="operator">|</span> 笔记本配件    <span class="operator">|</span> 索尼       <span class="operator">|</span>    <span class="number">6999.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">19</span> <span class="operator">|</span> 商务双肩背包                                                           <span class="operator">|</span> 笔记本配件    <span class="operator">|</span> 索尼       <span class="operator">|</span>      <span class="number">99.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">20</span> <span class="operator">|</span> X3250 M4机架式服务器 <span class="number">2583</span>i14                                           <span class="operator">|</span> 服务器<span class="operator">/</span>工作站 <span class="operator">|</span> IBM        <span class="operator">|</span>    <span class="number">6888.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">21</span> <span class="operator">|</span> 玄龙精英版 笔记本散热器                                                <span class="operator">|</span> 笔记本配件    <span class="operator">|</span> 九州风神   <span class="operator">|</span>       <span class="number">0.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">22</span> <span class="operator">|</span>  HMZ<span class="operator">-</span>T3W 头戴显示设备                                                  <span class="operator">|</span> 笔记本配件    <span class="operator">|</span> 索尼       <span class="operator">|</span>    <span class="number">6999.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">23</span> <span class="operator">|</span> 商务双肩背包                                                           <span class="operator">|</span> 笔记本配件    <span class="operator">|</span> 索尼       <span class="operator">|</span>      <span class="number">99.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-----------------------------------------------+---------------+------------+-------------+---------+------------+</span></span><br></pre></td></tr></table></figure>
<p>计算所有商品的平均价格</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(goods_price) <span class="keyword">AS</span> &quot;average price&quot; <span class="keyword">FROM</span> tdb_goods;</span><br></pre></td></tr></table></figure>
<p>评价价格保留两位小数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ROUND(<span class="built_in">AVG</span>(goods_price),<span class="number">2</span>) <span class="keyword">AS</span> &quot;average price&quot; <span class="keyword">FROM</span> tdb_goods;</span><br></pre></td></tr></table></figure>
<p>计算高于平均价格的商品</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> goods_id,goods_name,goods_price <span class="keyword">FROM</span> tdb_goods <span class="keyword">WHERE</span> goods_price<span class="operator">&gt;=</span><span class="number">5635.36</span>;</span><br></pre></td></tr></table></figure>
<p>使用子查询查询价格高于平均价格的商品信息</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> goods_id,goods_name,goods_price <span class="keyword">FROM</span> tdb_goods <span class="keyword">WHERE</span> goods_price<span class="operator">&gt;=</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(goods_price) <span class="keyword">FROM</span> tdb_goods</span><br><span class="line">    );</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id <span class="operator">|</span> goods_name                       <span class="operator">|</span> goods_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">3</span> <span class="operator">|</span> G150TH <span class="number">15.6</span>英寸游戏本            <span class="operator">|</span>    <span class="number">8499.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">7</span> <span class="operator">|</span> SVP13226SCB <span class="number">13.3</span>英寸触控超极本   <span class="operator">|</span>    <span class="number">7999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">13</span> <span class="operator">|</span> iMac ME086CH<span class="operator">/</span>A <span class="number">21.5</span>英寸一体电脑  <span class="operator">|</span>    <span class="number">9188.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">17</span> <span class="operator">|</span> Mac Pro MD878CH<span class="operator">/</span>A 专业级台式电脑 <span class="operator">|</span>   <span class="number">28888.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">18</span> <span class="operator">|</span>  HMZ<span class="operator">-</span>T3W 头戴显示设备            <span class="operator">|</span>    <span class="number">6999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">20</span> <span class="operator">|</span> X3250 M4机架式服务器 <span class="number">2583</span>i14     <span class="operator">|</span>    <span class="number">6888.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">22</span> <span class="operator">|</span>  HMZ<span class="operator">-</span>T3W 头戴显示设备            <span class="operator">|</span>    <span class="number">6999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>使用子查询 计算高于平均价格的所有商品的评价价格</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(goods_price) <span class="keyword">FROM</span> tdb_goods <span class="keyword">WHERE</span> goods_price<span class="operator">&gt;=</span>(<span class="keyword">SELECT</span> <span class="built_in">AVG</span>(goods_price) <span class="keyword">FROM</span> tdb_goods);</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="built_in">AVG</span>(goods_price) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">10780.0000000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+</span></span><br><span class="line"></span><br><span class="line">使用avg函数时, 只有一条记录, 其他字段的信息只显示第一条.</span><br><span class="line"><span class="keyword">SELECT</span> goods_id,goods_name,goods_price,<span class="built_in">AVG</span>(goods_price) <span class="keyword">FROM</span> tdb_goods <span class="keyword">WHERE</span> goods_price<span class="operator">&gt;=</span>(<span class="keyword">SELECT</span> <span class="built_in">AVG</span>(goods_price) <span class="keyword">FROM</span> tdb_goods);</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-----------------------+-------------+------------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id <span class="operator">|</span> goods_name            <span class="operator">|</span> goods_price <span class="operator">|</span> <span class="built_in">AVG</span>(goods_price) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-----------------------+-------------+------------------+</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">3</span> <span class="operator">|</span> G150TH <span class="number">15.6</span>英寸游戏本 <span class="operator">|</span>    <span class="number">8499.000</span> <span class="operator">|</span>    <span class="number">10780.0000000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-----------------------+-------------+------------------+</span></span><br></pre></td></tr></table></figure>
<p>利用子查询查询比”超极本”贵的商品信息(这里的”贵”就体现于多条记录比较时的处理)</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> goods_price <span class="keyword">from</span> tdb_goods <span class="keyword">where</span> goods_cate<span class="operator">=</span><span class="string">&#x27;超级本&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"><span class="operator">|</span> goods_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">4999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">4299.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">7999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> goods_id,goods_name,goods_price <span class="keyword">FROM</span> tdb_goods </span><br><span class="line"><span class="keyword">WHERE</span> goods_price <span class="operator">&gt;</span><span class="keyword">ANY</span> (</span><br><span class="line">    <span class="keyword">select</span> goods_price <span class="keyword">from</span> tdb_goods <span class="keyword">where</span> goods_cate<span class="operator">=</span><span class="string">&#x27;超级本&#x27;</span></span><br><span class="line">    );</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id <span class="operator">|</span> goods_name                       <span class="operator">|</span> goods_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">2</span> <span class="operator">|</span> Y400N <span class="number">14.0</span>英寸笔记本电脑         <span class="operator">|</span>    <span class="number">4899.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">3</span> <span class="operator">|</span> G150TH <span class="number">15.6</span>英寸游戏本            <span class="operator">|</span>    <span class="number">8499.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">5</span> <span class="operator">|</span> X240(<span class="number">20</span>ALA0EYCD) <span class="number">12.5</span>英寸超极本  <span class="operator">|</span>    <span class="number">4999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">7</span> <span class="operator">|</span> SVP13226SCB <span class="number">13.3</span>英寸触控超极本   <span class="operator">|</span>    <span class="number">7999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">13</span> <span class="operator">|</span> iMac ME086CH<span class="operator">/</span>A <span class="number">21.5</span>英寸一体电脑  <span class="operator">|</span>    <span class="number">9188.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">16</span> <span class="operator">|</span> PowerEdge T110 II服务器          <span class="operator">|</span>    <span class="number">5388.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">17</span> <span class="operator">|</span> Mac Pro MD878CH<span class="operator">/</span>A 专业级台式电脑 <span class="operator">|</span>   <span class="number">28888.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">18</span> <span class="operator">|</span>  HMZ<span class="operator">-</span>T3W 头戴显示设备            <span class="operator">|</span>    <span class="number">6999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">20</span> <span class="operator">|</span> X3250 M4机架式服务器 <span class="number">2583</span>i14     <span class="operator">|</span>    <span class="number">6888.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">22</span> <span class="operator">|</span>  HMZ<span class="operator">-</span>T3W 头戴显示设备            <span class="operator">|</span>    <span class="number">6999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> goods_id,goods_name,goods_price <span class="keyword">FROM</span> tdb_goods <span class="keyword">WHERE</span> goods_price <span class="operator">&gt;</span> <span class="keyword">ALL</span> (</span><br><span class="line">    <span class="keyword">select</span> goods_price <span class="keyword">from</span> tdb_goods <span class="keyword">where</span> goods_cate<span class="operator">=</span><span class="string">&#x27;超级本&#x27;</span></span><br><span class="line">    );</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id <span class="operator">|</span> goods_name                       <span class="operator">|</span> goods_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">3</span> <span class="operator">|</span> G150TH <span class="number">15.6</span>英寸游戏本            <span class="operator">|</span>    <span class="number">8499.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">13</span> <span class="operator">|</span> iMac ME086CH<span class="operator">/</span>A <span class="number">21.5</span>英寸一体电脑  <span class="operator">|</span>    <span class="number">9188.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">17</span> <span class="operator">|</span> Mac Pro MD878CH<span class="operator">/</span>A 专业级台式电脑 <span class="operator">|</span>   <span class="number">28888.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------------------------------+-------------+</span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">SELECT</span> goods_id,goods_name,goods_price <span class="keyword">FROM</span> tdb_goods <span class="keyword">WHERE</span> goods_price <span class="operator">=</span> <span class="keyword">ANY</span> (</span><br><span class="line">    <span class="keyword">select</span> goods_price <span class="keyword">from</span> tdb_goods <span class="keyword">where</span> goods_cate<span class="operator">=</span><span class="string">&#x27;超级本&#x27;</span></span><br><span class="line">    );</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+---------------------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id <span class="operator">|</span> goods_name                      <span class="operator">|</span> goods_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+---------------------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">5</span> <span class="operator">|</span> X240(<span class="number">20</span>ALA0EYCD) <span class="number">12.5</span>英寸超极本 <span class="operator">|</span>    <span class="number">4999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">6</span> <span class="operator">|</span> U330P <span class="number">13.3</span>英寸超极本            <span class="operator">|</span>    <span class="number">4299.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">7</span> <span class="operator">|</span> SVP13226SCB <span class="number">13.3</span>英寸触控超极本  <span class="operator">|</span>    <span class="number">7999.000</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+---------------------------------+-------------+</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>多表更新:<br>参照分类表更新商品表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> tdb_goods_cates(</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> cate_id <span class="type">SMALLINT</span> UNSIGNED <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> AUTO_INCREMENT,</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> cate_name <span class="type">VARCHAR</span>(<span class="number">40</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> );</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> COLUMNS <span class="keyword">FROM</span> tdb_goods_cates;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Field     <span class="operator">|</span> Type                 <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> cate_id   <span class="operator">|</span> <span class="type">smallint</span>(<span class="number">5</span>) unsigned <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> auto_increment <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> cate_name <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">40</span>)          <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+----------------------+------+-----+---------+----------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tdb_goods_cates(cate_name)  <span class="keyword">select</span> goods_cate <span class="keyword">from</span> tdb_goods </span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> goods_cate;</span><br><span class="line">Query OK, <span class="number">7</span> <span class="keyword">rows</span> affected (<span class="number">0.07</span> sec)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tdb_goods_cates;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------+---------------+</span></span><br><span class="line"><span class="operator">|</span> cate_id <span class="operator">|</span> cate_name     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------+---------------+</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span> 台式机        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">2</span> <span class="operator">|</span> 游戏本        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">3</span> <span class="operator">|</span> 平板电脑      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">4</span> <span class="operator">|</span> 笔记本        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">5</span> <span class="operator">|</span> 笔记本配件    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">6</span> <span class="operator">|</span> 超级本        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">7</span> <span class="operator">|</span> 服务器<span class="operator">/</span>工作站 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------+---------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">UPDATE</span> tdb_goods</span><br><span class="line">  <span class="keyword">INNER</span> <span class="keyword">JOIN</span> tdb_goods_cates</span><br><span class="line">    <span class="keyword">ON</span> goods_cate <span class="operator">=</span> cate_name</span><br><span class="line">    <span class="keyword">SET</span> goods_cate<span class="operator">=</span>cate_id;</span><br><span class="line">Query OK, <span class="number">23</span> <span class="keyword">rows</span> affected (<span class="number">0.08</span> sec)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tdb_goods\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">   goods_id: <span class="number">1</span></span><br><span class="line"> goods_name: R510VC <span class="number">15.6</span>英寸笔记本</span><br><span class="line"> goods_cate: <span class="number">4</span></span><br><span class="line"> brand_name: 华硕</span><br><span class="line">goods_price: <span class="number">3399.000</span></span><br><span class="line">    is_show: <span class="number">1</span></span><br><span class="line"> is_saleoff: <span class="number">0</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">   goods_id: <span class="number">2</span></span><br><span class="line"> goods_name: Y400N <span class="number">14.0</span>英寸笔记本电脑</span><br><span class="line"> goods_cate: <span class="number">4</span></span><br><span class="line"> brand_name: 联想</span><br><span class="line">goods_price: <span class="number">4899.000</span></span><br><span class="line">    is_show: <span class="number">1</span></span><br><span class="line"> is_saleoff: <span class="number">0</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">   goods_id: <span class="number">3</span></span><br><span class="line"> goods_name: G150TH <span class="number">15.6</span>英寸游戏本</span><br><span class="line"> goods_cate: <span class="number">2</span></span><br><span class="line"> brand_name: 雷神</span><br><span class="line">goods_price: <span class="number">8499.000</span></span><br><span class="line">    is_show: <span class="number">1</span></span><br><span class="line"> is_saleoff: <span class="number">0</span></span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> goods_brands(</span><br><span class="line">    id TINYINT AUTO_INCREMENT <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span>,</span><br><span class="line">    brand_name <span class="type">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">SELECT</span> brand_name <span class="keyword">FROM</span> tdb_goods <span class="keyword">GROUP</span> <span class="keyword">BY</span> brand_name;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> goods_brands;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+------------+</span></span><br><span class="line"><span class="operator">|</span> id <span class="operator">|</span> brand_name <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+------------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">1</span> <span class="operator">|</span> 联想       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">2</span> <span class="operator">|</span> 雷神       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">3</span> <span class="operator">|</span> 索尼       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">4</span> <span class="operator">|</span> IBM        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">5</span> <span class="operator">|</span> 苹果       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">6</span> <span class="operator">|</span> 戴尔       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">7</span> <span class="operator">|</span> 宏碁       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">8</span> <span class="operator">|</span> 惠普       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">9</span> <span class="operator">|</span> 华硕       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span> <span class="operator">|</span> 九州风神   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">update</span> tdb_goods <span class="keyword">INNER</span> <span class="keyword">JOIN</span> goods_brands</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">on</span> tdb_goods.brand_name<span class="operator">=</span>goods_brands.brand_name</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">set</span> tdb_goods.brand_name<span class="operator">=</span>goods_brands.id;</span><br><span class="line">Query OK, <span class="number">23</span> <span class="keyword">rows</span> affected (<span class="number">0.09</span> sec)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tdb_goods\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">   goods_id: <span class="number">1</span></span><br><span class="line"> goods_name: R510VC <span class="number">15.6</span>英寸笔记本</span><br><span class="line"> goods_cate: <span class="number">4</span></span><br><span class="line"> brand_name: <span class="number">9</span></span><br><span class="line">goods_price: <span class="number">3399.000</span></span><br><span class="line">    is_show: <span class="number">1</span></span><br><span class="line"> is_saleoff: <span class="number">0</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">   goods_id: <span class="number">2</span></span><br><span class="line"> goods_name: Y400N <span class="number">14.0</span>英寸笔记本电脑</span><br><span class="line"> goods_cate: <span class="number">4</span></span><br><span class="line"> brand_name: <span class="number">1</span></span><br><span class="line">goods_price: <span class="number">4899.000</span></span><br><span class="line">    is_show: <span class="number">1</span></span><br><span class="line"> is_saleoff: <span class="number">0</span></span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">DESC</span> tdb_goods;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+------------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Field       <span class="operator">|</span> Type                   <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+------------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id    <span class="operator">|</span> <span class="type">smallint</span>(<span class="number">5</span>) unsigned   <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> auto_increment <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> goods_name  <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">150</span>)           <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> goods_cate  <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">40</span>)            <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> brand_name  <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">40</span>)            <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> goods_price <span class="operator">|</span> <span class="type">decimal</span>(<span class="number">15</span>,<span class="number">3</span>) unsigned <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="number">0.000</span>   <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> is_show     <span class="operator">|</span> tinyint(<span class="number">1</span>)             <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> is_saleoff  <span class="operator">|</span> tinyint(<span class="number">1</span>)             <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="number">0</span>       <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+------------------------+------+-----+---------+----------------+</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tdb_goods</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> CHANGE goods_cate cate_id <span class="type">SMALLINT</span> UNSIGNED <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> CHANGE brand_name brand_id <span class="type">SMALLINT</span> UNSIGNED <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br><span class="line">Query OK, <span class="number">23</span> <span class="keyword">rows</span> affected (<span class="number">0.17</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">DESC</span> tdb_goods;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+------------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Field       <span class="operator">|</span> Type                   <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+------------------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id    <span class="operator">|</span> <span class="type">smallint</span>(<span class="number">5</span>) unsigned   <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> auto_increment <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> goods_name  <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">150</span>)           <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> cate_id     <span class="operator">|</span> <span class="type">smallint</span>(<span class="number">5</span>) unsigned   <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> brand_id    <span class="operator">|</span> <span class="type">smallint</span>(<span class="number">5</span>) unsigned   <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> goods_price <span class="operator">|</span> <span class="type">decimal</span>(<span class="number">15</span>,<span class="number">3</span>) unsigned <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="number">0.000</span>   <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> is_show     <span class="operator">|</span> tinyint(<span class="number">1</span>)             <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> is_saleoff  <span class="operator">|</span> tinyint(<span class="number">1</span>)             <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="number">0</span>       <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+------------------------+------+-----+---------+----------------+</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改类名</span><br><span class="line"><span class="keyword">desc</span> tdb_goods_brands;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Field      <span class="operator">|</span> Type        <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> id         <span class="operator">|</span> tinyint(<span class="number">4</span>)  <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> auto_increment <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> brand_name <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">20</span>) <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------------+------+-----+---------+----------------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tdb_goods_brands change id brand_id tinyint(<span class="number">4</span>) <span class="keyword">not</span> <span class="keyword">null</span> ;</span><br><span class="line">Query OK, <span class="number">13</span> <span class="keyword">rows</span> affected (<span class="number">0.20</span> sec)</span><br><span class="line"></span><br><span class="line"><span class="keyword">desc</span> tdb_goods_brands;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="operator">|</span> Field      <span class="operator">|</span> Type        <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="operator">|</span> brand_id   <span class="operator">|</span> tinyint(<span class="number">4</span>)  <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> brand_name <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">20</span>) <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------------+------+-----+---------+-------+</span></span><br></pre></td></tr></table></figure>
<p>删除商品名称重复记录</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">查找名称相同的记录</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tdb_goods <span class="keyword">as</span> t1 <span class="keyword">group</span> <span class="keyword">by</span> t1.goods_name <span class="keyword">having</span> <span class="built_in">count</span>(t1.goods_name)<span class="operator">&gt;=</span><span class="number">2</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-----------------------+---------+----------+-------------+---------+------------+</span></span><br><span class="line"><span class="operator">|</span> goods_id <span class="operator">|</span> goods_name            <span class="operator">|</span> cate_id <span class="operator">|</span> brand_id <span class="operator">|</span> goods_price <span class="operator">|</span> is_show <span class="operator">|</span> is_saleoff <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-----------------------+---------+----------+-------------+---------+------------+</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">18</span> <span class="operator">|</span>  HMZ<span class="operator">-</span>T3W 头戴显示设备 <span class="operator">|</span>       <span class="number">5</span> <span class="operator">|</span>        <span class="number">3</span> <span class="operator">|</span>    <span class="number">6999.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       <span class="number">19</span> <span class="operator">|</span> 商务双肩背包          <span class="operator">|</span>       <span class="number">5</span> <span class="operator">|</span>        <span class="number">3</span> <span class="operator">|</span>      <span class="number">99.000</span> <span class="operator">|</span>       <span class="number">1</span> <span class="operator">|</span>          <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-----------------------+---------+----------+-------------+---------+------------+</span></span><br><span class="line"></span><br><span class="line">错误的写法:</span><br><span class="line"><span class="keyword">delete</span> tt1 <span class="keyword">from</span> tdb_goods <span class="keyword">as</span> tt1 <span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line"> (<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tdb_goods <span class="keyword">as</span> t1 <span class="keyword">group</span> <span class="keyword">by</span> t1.goods_name <span class="keyword">having</span> <span class="built_in">count</span>(t1.goods_name)<span class="operator">&gt;=</span><span class="number">2</span>) <span class="keyword">as</span> tt2</span><br><span class="line"> <span class="keyword">on</span> tt1.goods_name<span class="operator">=</span>tt2.goods_name <span class="keyword">and</span> tt1.goods_id<span class="operator">&gt;</span>tt2.goods_id;</span><br><span class="line">Query OK, <span class="number">24</span> <span class="keyword">rows</span> affected (<span class="number">0.07</span> sec)</span><br><span class="line"></span><br><span class="line">正确的写法:</span><br><span class="line"><span class="keyword">delete</span> tt1 <span class="keyword">from</span> tdb_goods <span class="keyword">as</span> tt1 <span class="keyword">left</span> <span class="keyword">join</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tdb_goods <span class="keyword">as</span> t1 <span class="keyword">group</span> <span class="keyword">by</span> t1.goods_name </span><br><span class="line">    <span class="keyword">having</span> <span class="built_in">count</span>(t1.goods_name)<span class="operator">&gt;=</span><span class="number">2</span>) <span class="keyword">as</span> tt2 </span><br><span class="line">    <span class="keyword">on</span> tt1.goods_name<span class="operator">=</span>tt2.goods_name </span><br><span class="line">    <span class="keyword">where</span> tt1.goods_id<span class="operator">&gt;</span>tt2.goods_id;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<h2 id="Delete中包含left-join"><a href="#Delete中包含left-join" class="headerlink" title="Delete中包含left join"></a>Delete中包含left join</h2><ol>
<li>左侧的表是待删除的表</li>
<li>不能关联成功的要过滤掉</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> tbl_pps_nc_group_member</span><br><span class="line"><span class="keyword">WHERE</span> user_id <span class="operator">=</span> #fromUserId#</span><br><span class="line"><span class="keyword">and</span> group_id <span class="keyword">in</span> (<span class="keyword">SELECT</span> group_id <span class="keyword">FROM</span> tbl_pps_nc_group <span class="keyword">where</span> user_id <span class="operator">=</span> #myUserId# );</span><br></pre></td></tr></table></figure>
<p>与</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_pps_nc_group_member nm</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tbl_pps_nc_group ng <span class="keyword">ON</span> nm.user_id <span class="operator">=</span> <span class="string">&#x27;&#x27;</span> <span class="keyword">AND</span> nm.group_id<span class="operator">=</span>ng.group_id <span class="keyword">AND</span> ng.user_id <span class="operator">=</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> ng.group_id <span class="keyword">is</span> <span class="keyword">NOT</span> <span class="keyword">null</span></span><br></pre></td></tr></table></figure>

<h1 id="在好友关系中获取对方的信息"><a href="#在好友关系中获取对方的信息" class="headerlink" title="在好友关系中获取对方的信息"></a>在好友关系中获取对方的信息</h1><p>对于好友关系来说，是彼此的关系，可以不分先后，如果要区分邀请和被邀请，就必须考虑。<br>假设存在两个表格:<br>第一个表格是用户信息表<code>t_user_info</code>，用于记录用户的信息。<br>第二个表格是好友关系表<code>t_friend</code>, 用于记录用户的好友关系。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_user_info (</span><br><span class="line">	user_id <span class="type">INT</span> <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> auto_increment,</span><br><span class="line">	`name` <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">	phone <span class="type">VARCHAR</span>(<span class="number">11</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_friend (</span><br><span class="line">	 friend_ref_id <span class="type">INT</span> <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> auto_increment,</span><br><span class="line"> 	 from_user_id <span class="type">int</span>,</span><br><span class="line">     to_user_id <span class="type">int</span>,</span><br><span class="line">	 `status` TINYINT(<span class="number">1</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>如果要获取对方的信息，邀请者获取得到的是被邀请者的信息，而被邀请者获取得到的是邀请者的信息。<br>状态值<code>status</code>代表 0：待验证，1：已添加，2：已拒绝，4：待对方验证，5: 对方已添加，6：对方已拒绝</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">	u.`name` <span class="keyword">AS</span> userName,</span><br><span class="line">	u.phone <span class="keyword">AS</span> userPhone,</span><br><span class="line">	u.user_id <span class="keyword">AS</span> userId,</span><br><span class="line">	<span class="keyword">CASE</span> <span class="keyword">WHEN</span> f.from_user_id <span class="operator">=</span> <span class="string">&#x27;1018&#x27;</span> <span class="keyword">THEN</span> 	f.`status` <span class="operator">+</span> <span class="number">4</span> <span class="keyword">ELSE</span> f.`status` <span class="keyword">END</span> <span class="keyword">AS</span> `status`</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">	t_friend f</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> t_user_info u </span><br><span class="line">	<span class="keyword">ON</span> (u.user_id <span class="operator">=</span> f.from_user_id 	<span class="keyword">AND</span> f.to_user_id <span class="operator">=</span> <span class="string">&#x27;1018&#x27;</span> )</span><br><span class="line">		<span class="keyword">OR</span> (u.user_id <span class="operator">=</span> f.to_user_id <span class="keyword">AND</span> f.from_user_id <span class="operator">=</span> <span class="string">&#x27;1018&#x27;</span> )</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">	u.user_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br></pre></td></tr></table></figure>
<p><strong>[总结]</strong></p>
<ol>
<li><code>left join</code>中的<code>on</code>语句, 是在被关联表满足<code>on</code>条件才会关联，否则显示为<code>null</code>, 因此通过判断右侧是否为空，可以判断是否满足条件</li>
<li>关联条件是另一个技巧, 取对方的<code>id</code>条件</li>
</ol>
<h1 id="Explain解析查询"><a href="#Explain解析查询" class="headerlink" title="Explain解析查询"></a>Explain解析查询</h1><p><a href="http://blog.csdn.net/zhuxineli/article/details/14455029">MYSQL explain详解</a></p>
]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>MySQL</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/database/MySQL/upsert/</url>
    <content><![CDATA[<h1 id="upsert-on-duplicate-key-update"><a href="#upsert-on-duplicate-key-update" class="headerlink" title="upsert: on duplicate key update"></a>upsert: on duplicate key update</h1><p><a href="https://www.cnblogs.com/better-farther-world2099/articles/11737376.html">MySQL upsert语法</a></p>
<h2 id="不能加where条件"><a href="#不能加where条件" class="headerlink" title="不能加where条件"></a>不能加where条件</h2><p>因为这是个插入语句，所以不能加where条件。</p>
<h2 id="影响的行数"><a href="#影响的行数" class="headerlink" title="影响的行数"></a>影响的行数</h2><ul>
<li>如果是插入操作，受到影响行的值为1；</li>
<li>如果更新操作，受到影响行的值为2；</li>
<li>如果更新的数据和已有的数据一样（就相当于没变，所有值保持不变），受到影响的行的值为0。</li>
</ul>
<h2 id="样例一"><a href="#样例一" class="headerlink" title="样例一"></a>样例一</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">desc</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------+------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Field <span class="operator">|</span> Type <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+------+------+-----+---------+----------------+</span></span><br><span class="line"><span class="operator">|</span> f1    <span class="operator">|</span> <span class="type">int</span>  <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>  <span class="operator">|</span> auto_increment <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> f2    <span class="operator">|</span> <span class="type">int</span>  <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>  <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> f3    <span class="operator">|</span> <span class="type">int</span>  <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>  <span class="operator">|</span>                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+------+------+-----+---------+----------------+</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2     <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> t1(f1,f3) <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">7</span>) <span class="keyword">on</span> duplicate key <span class="keyword">update</span> f3<span class="operator">=</span>f3<span class="operator">+</span><span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">2</span> <span class="keyword">rows</span> affected</span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2     <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> <span class="number">3</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> <span class="number">7</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> t1(f1,f3) <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">7</span>) <span class="keyword">on</span> duplicate key <span class="keyword">update</span> f3<span class="operator">=</span>f3<span class="operator">+</span><span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected</span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2     <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> <span class="number">4</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> <span class="number">8</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> t1(f1,f3) <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">7</span>) <span class="keyword">on</span> duplicate key <span class="keyword">update</span> f3<span class="operator">=</span>f3<span class="operator">+</span><span class="number">1</span>;</span><br><span class="line"><span class="comment">-- 同一行冲突两次，会执行两次更新语句</span></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2     <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> <span class="number">6</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> <span class="number">8</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2     <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> <span class="number">6</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> <span class="number">8</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+--------+----+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="VALUES引用"><a href="#VALUES引用" class="headerlink" title="VALUES引用"></a>VALUES引用</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">truncate</span> t1;</span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 (f1,f2,f3) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)  <span class="keyword">ON</span> DUPLICATE KEY <span class="keyword">UPDATE</span> f3<span class="operator">=</span><span class="keyword">VALUES</span>(f1)<span class="operator">+</span><span class="keyword">VALUES</span>(f2);</span><br><span class="line">Query OK, <span class="number">2</span> <span class="keyword">rows</span> affected</span><br><span class="line"><span class="type">Time</span>: <span class="number">0.003</span>s</span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="comment">-- 没有出现冲突，直接赋值</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2 <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="number">3</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>  <span class="operator">|</span> <span class="number">5</span>  <span class="operator">|</span> <span class="number">6</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"><span class="type">Time</span>: <span class="number">0.008</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 再执行一次，冲突了.执行冲突后的处理语句</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 (f1,f2,f3) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)  <span class="keyword">ON</span> DUPLICATE KEY <span class="keyword">UPDATE</span> f3<span class="operator">=</span><span class="keyword">VALUES</span>(f1)<span class="operator">+</span><span class="keyword">VALUES</span>(f2);</span><br><span class="line">Query OK, <span class="number">2</span> <span class="keyword">rows</span> affected</span><br><span class="line"><span class="type">Time</span>: <span class="number">0.002</span>s</span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2 <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="number">3</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>  <span class="operator">|</span> <span class="number">5</span>  <span class="operator">|</span> <span class="number">9</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"><span class="type">Time</span>: <span class="number">0.008</span>s</span><br></pre></td></tr></table></figure>
<h2 id="ALAIS引用"><a href="#ALAIS引用" class="headerlink" title="ALAIS引用"></a>ALAIS引用</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">truncate</span> <span class="keyword">table</span> t1;</span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 (f1,f2,f3) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>) <span class="keyword">AS</span> <span class="keyword">new</span>  <span class="keyword">ON</span> DUPLICATE KEY <span class="keyword">UPDATE</span> f3 <span class="operator">=</span> new.f1<span class="operator">+</span>new.f2;</span><br><span class="line"><span class="comment">-- 空表没有冲突，直接添加了</span></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2 <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="number">3</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>  <span class="operator">|</span> <span class="number">5</span>  <span class="operator">|</span> <span class="number">6</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"><span class="type">Time</span>: <span class="number">0.008</span>s</span><br><span class="line"><span class="comment">-- 再来</span></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 (f1,f2,f3) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>) <span class="keyword">AS</span> <span class="keyword">new</span>  <span class="keyword">ON</span> DUPLICATE KEY <span class="keyword">UPDATE</span> f3 <span class="operator">=</span> new.f1<span class="operator">+</span>new.f2;</span><br><span class="line"><span class="comment">-- 出现冲突了, 两行更新</span></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2 <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="number">3</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>  <span class="operator">|</span> <span class="number">5</span>  <span class="operator">|</span> <span class="number">9</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br></pre></td></tr></table></figure>
<p>等价写法</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 (f1,f2,f3) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>) <span class="keyword">AS</span> <span class="keyword">new</span>(m,n,p)</span><br><span class="line">  <span class="keyword">ON</span> DUPLICATE KEY <span class="keyword">UPDATE</span> c <span class="operator">=</span> m<span class="operator">+</span>n;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">SET</span> f1<span class="operator">=</span><span class="number">1</span>,f2<span class="operator">=</span><span class="number">2</span>,f3<span class="operator">=</span><span class="number">3</span> <span class="keyword">AS</span> <span class="keyword">new</span></span><br><span class="line">  <span class="keyword">ON</span> DUPLICATE KEY <span class="keyword">UPDATE</span> c <span class="operator">=</span> new.a<span class="operator">+</span>new.b;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">SET</span> f1<span class="operator">=</span><span class="number">1</span>,f2<span class="operator">=</span><span class="number">2</span>,f3<span class="operator">=</span><span class="number">3</span> <span class="keyword">AS</span> <span class="keyword">new</span>(m,n,p)</span><br><span class="line">  <span class="keyword">ON</span> DUPLICATE KEY <span class="keyword">UPDATE</span> c <span class="operator">=</span> m<span class="operator">+</span>n;</span><br></pre></td></tr></table></figure>
<h2 id="UNION引用"><a href="#UNION引用" class="headerlink" title="UNION引用"></a>UNION引用</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 (f1, f2)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span></span><br><span class="line">  (<span class="keyword">SELECT</span> c, d <span class="keyword">FROM</span> t2</span><br><span class="line">   <span class="keyword">UNION</span></span><br><span class="line">   <span class="keyword">SELECT</span> e, f <span class="keyword">FROM</span> t3) <span class="keyword">AS</span> dt</span><br><span class="line"><span class="keyword">ON</span> DUPLICATE KEY <span class="keyword">UPDATE</span> f2 <span class="operator">=</span> f2 <span class="operator">+</span> f3;</span><br></pre></td></tr></table></figure>

<h2 id="key自增情况"><a href="#key自增情况" class="headerlink" title="key自增情况"></a>key自增情况</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">truncate</span> <span class="keyword">table</span> t1;</span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2 <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> t1(f2,f3) <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">7</span>) <span class="keyword">on</span> duplicate key <span class="keyword">update</span> f3<span class="operator">=</span>f2<span class="operator">+</span>f3;</span><br><span class="line">Query OK, <span class="number">2</span> <span class="keyword">rows</span> affected</span><br><span class="line"><span class="type">Time</span>: <span class="number">0.002</span>s</span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> t1(f2,f3) <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">7</span>) <span class="keyword">on</span> duplicate key <span class="keyword">update</span> f3<span class="operator">=</span>f2<span class="operator">+</span>f3;</span><br><span class="line">Query OK, <span class="number">2</span> <span class="keyword">rows</span> affected</span><br><span class="line"><span class="type">Time</span>: <span class="number">0.002</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 不存在主键冲突，连续可以插入两次</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> f1 <span class="operator">|</span> f2 <span class="operator">|</span> f3 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">3</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>  <span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">7</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">3</span>  <span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">3</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>  <span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> <span class="number">7</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+----+----+</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/database/MySQL/%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="慢查询优化"><a href="#慢查询优化" class="headerlink" title="慢查询优化"></a>慢查询优化</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqldumpslow -s t -t 10  ~/Downloads/慢日志/mysql-slow.log</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Count: <span class="number">2</span>  <span class="type">Time</span><span class="operator">=</span><span class="number">1238.48</span>s (<span class="number">2476</span>s)  Lock<span class="operator">=</span><span class="number">0.00</span>s (<span class="number">0</span>s)  <span class="keyword">Rows</span><span class="operator">=</span><span class="number">90750.0</span> (<span class="number">181500</span>), cdw[cdw]<span class="variable">@2hosts</span></span><br><span class="line">  <span class="keyword">select</span> t3.PRODUCT_CHANNEL_CODE,t3.MAIN_PROJECT_NAME ,</span><br><span class="line">  t3.MAIN_PROJECT_CODE ,t3.SUB_PROJECT_NAME,t3.SUB_PROJECT_CODE,</span><br><span class="line">  t3.CHANNEL_TYPE,t3.CHANNEL_NAME,t3.CHANNEL_ID,t3.CHANNEL_SUB_CODE,</span><br><span class="line">  t3.CHANNEL_SUB_TYPE,</span><br><span class="line">  t4.FRIST_CHANNEL,</span><br><span class="line">  t4.SECOND_CHANNEL,</span><br><span class="line">  t4.thrid_channel</span><br><span class="line">  <span class="keyword">from</span> (<span class="keyword">SELECT</span> t1.PRODUCT_CHANNEL_CODE,t1.MAIN_PROJECT_NAME ,</span><br><span class="line">  t1.MAIN_PROJECT_CODE ,t1.SUB_PROJECT_NAME,t1.SUB_PROJECT_CODE,</span><br><span class="line">  t1.CHANNEL_TYPE,t1.CHANNEL_NAME,t1.CHANNEL_ID,t2.CHANNEL_SUB_CODE,</span><br><span class="line">  t2.CHANNEL_SUB_TYPE <span class="keyword">FROM</span> qd_dz_db.qd_prochannel t1 <span class="keyword">left</span> <span class="keyword">join</span> qd_channel t2</span><br><span class="line">  <span class="keyword">on</span> t1.CHANNEL_ID<span class="operator">=</span>t2.CHANNEL_ID ) t3 <span class="keyword">join</span></span><br><span class="line">  (</span><br><span class="line">  <span class="keyword">SELECT</span></span><br><span class="line">  a.PRODUCT_CHANNEL_CODE,</span><br><span class="line">  b.FRIST_CHANNEL,</span><br><span class="line">  b.SECOND_CHANNEL,</span><br><span class="line">  b.THIRD_CHANNEL <span class="keyword">AS</span> thrid_channel</span><br><span class="line">  <span class="keyword">FROM</span></span><br><span class="line">  qd_dz_db.qd_prochannel a</span><br><span class="line">  <span class="keyword">JOIN</span></span><br><span class="line">  qd_dz_db.qd_channel b <span class="keyword">ON</span> a.CHANNEL_ID <span class="operator">=</span> b.CHANNEL_ID</span><br><span class="line">  )t4 <span class="keyword">on</span> t3.PRODUCT_CHANNEL_CODE<span class="operator">=</span>t4.PRODUCT_CHANNEL_CODE</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">explain</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    t3.PRODUCT_CHANNEL_CODE,</span><br><span class="line">    t3.MAIN_PROJECT_NAME ,</span><br><span class="line">    t3.MAIN_PROJECT_CODE ,</span><br><span class="line">    t3.SUB_PROJECT_NAME,</span><br><span class="line">    t3.SUB_PROJECT_CODE,</span><br><span class="line">    t3.CHANNEL_TYPE,</span><br><span class="line">    t3.CHANNEL_NAME,</span><br><span class="line">    t3.CHANNEL_ID,</span><br><span class="line">    t3.CHANNEL_SUB_CODE,</span><br><span class="line">    t3.CHANNEL_SUB_TYPE,</span><br><span class="line">    t4.FRIST_CHANNEL,</span><br><span class="line">    t4.SECOND_CHANNEL,</span><br><span class="line">    t4.thrid_channel</span><br><span class="line">  <span class="keyword">from</span> (</span><br><span class="line">      <span class="keyword">SELECT</span></span><br><span class="line">          t1.PRODUCT_CHANNEL_CODE,</span><br><span class="line">          t1.MAIN_PROJECT_NAME ,</span><br><span class="line">          t1.MAIN_PROJECT_CODE ,</span><br><span class="line">          t1.SUB_PROJECT_NAME,</span><br><span class="line">          t1.SUB_PROJECT_CODE,</span><br><span class="line">          t1.CHANNEL_TYPE,</span><br><span class="line">          t1.CHANNEL_NAME,</span><br><span class="line">          t1.CHANNEL_ID,</span><br><span class="line">          t2.CHANNEL_SUB_CODE,</span><br><span class="line">          t2.CHANNEL_SUB_TYPE</span><br><span class="line">      <span class="keyword">FROM</span></span><br><span class="line">          qd_dz_db.qd_prochannel t1</span><br><span class="line">      <span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line">          qd_channel t2</span><br><span class="line">      <span class="keyword">on</span> t1.CHANNEL_ID<span class="operator">=</span>t2.CHANNEL_ID</span><br><span class="line">  ) t3</span><br><span class="line">  <span class="keyword">join</span></span><br><span class="line">  (</span><br><span class="line">      <span class="keyword">SELECT</span></span><br><span class="line">          a.PRODUCT_CHANNEL_CODE,</span><br><span class="line">          b.FRIST_CHANNEL,</span><br><span class="line">          b.SECOND_CHANNEL,</span><br><span class="line">          b.THIRD_CHANNEL <span class="keyword">AS</span> thrid_channel</span><br><span class="line">      <span class="keyword">FROM</span></span><br><span class="line">          qd_dz_db.qd_prochannel a</span><br><span class="line">      <span class="keyword">JOIN</span></span><br><span class="line">          qd_dz_db.qd_channel b</span><br><span class="line">      <span class="keyword">ON</span> a.CHANNEL_ID <span class="operator">=</span> b.CHANNEL_ID</span><br><span class="line">  )t4</span><br><span class="line">  <span class="keyword">on</span> t3.PRODUCT_CHANNEL_CODE<span class="operator">=</span>t4.PRODUCT_CHANNEL_CODE</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>id</th>
<th>select_type</th>
<th>table</th>
<th>partitions</th>
<th>type</th>
<th>possible_keys</th>
<th>key</th>
<th>key_len</th>
<th>ref</th>
<th>rows</th>
<th>filtered</th>
<th>Extra</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>SIMPLE</td>
<td>b</td>
<td>null</td>
<td>ALL</td>
<td>PRIMARY,index_qd_channel</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>212</td>
<td>100.0</td>
<td>null</td>
</tr>
<tr>
<td>1</td>
<td>SIMPLE</td>
<td>a</td>
<td>null</td>
<td>ref</td>
<td>index_qd_prochannel</td>
<td>index_qd_prochannel</td>
<td>4</td>
<td>qd_dz_db.b.CHANNEL_ID</td>
<td>43</td>
<td>100.0</td>
<td>null</td>
</tr>
<tr>
<td>1</td>
<td>SIMPLE</td>
<td>t1</td>
<td>null</td>
<td>ALL</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>56367</td>
<td>10.0</td>
<td>Using where; Using join buffer (Block Nested Loop)</td>
</tr>
<tr>
<td>1</td>
<td>SIMPLE</td>
<td>t2</td>
<td>null</td>
<td>eq_ref</td>
<td>PRIMARY,index_qd_channel</td>
<td>PRIMARY</td>
<td>4</td>
<td>qd_dz_db.t1.CHANNEL_ID</td>
<td>1</td>
<td>100.0</td>
<td>null</td>
</tr>
</tbody></table>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> index <span class="keyword">from</span> qd_prochannel</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>Table</th>
<th>Non_unique</th>
<th>Key_name</th>
<th>Seq_in_index</th>
<th>Column_name</th>
<th>Collation</th>
<th>Cardinality</th>
<th>Sub_part</th>
<th>Packed</th>
<th>Null</th>
<th>Index_type</th>
<th>CommentIndex_comment</th>
</tr>
</thead>
<tbody><tr>
<td>qd_prochannel</td>
<td>0</td>
<td>PRIMARY</td>
<td>1</td>
<td>PR_CHANNEL_ID</td>
<td>A</td>
<td>56367</td>
<td>null</td>
<td>null</td>
<td></td>
<td>BTREE</td>
<td></td>
</tr>
<tr>
<td>qd_prochannel</td>
<td>1</td>
<td>index_qd_prochannel</td>
<td>1</td>
<td>CHANNEL_ID</td>
<td>A</td>
<td>1311</td>
<td>null</td>
<td>null</td>
<td></td>
<td>BTREE</td>
<td></td>
</tr>
<tr>
<td>qd_prochannel</td>
<td>1</td>
<td>index_qd_prochannel</td>
<td>2</td>
<td>MAIN_PROJECT_CODE</td>
<td>A</td>
<td>3316</td>
<td>null</td>
<td>null</td>
<td>YES</td>
<td>BTREE</td>
<td></td>
</tr>
<tr>
<td>qd_prochannel</td>
<td>1</td>
<td>index_qd_prochannel</td>
<td>3</td>
<td>CREATE_TIME</td>
<td>A</td>
<td>14092</td>
<td>null</td>
<td>null</td>
<td>YES</td>
<td>BTREE</td>
<td></td>
</tr>
<tr>
<td>qd_prochannel</td>
<td>1</td>
<td>index_qd_prochannel_MAIN_PROJECT_CODE</td>
<td>1</td>
<td>MAIN_PROJECT_CODE</td>
<td>A</td>
<td>613</td>
<td>null</td>
<td>null</td>
<td>YES</td>
<td>BTREE</td>
<td></td>
</tr>
</tbody></table>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> index <span class="keyword">from</span> qd_channel</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>Table</th>
<th>Non_unique</th>
<th>Key_name</th>
<th>Seq_in_index</th>
<th>Column_name</th>
<th>Collation</th>
<th>Cardinality</th>
<th>Sub_part</th>
<th>Packed</th>
<th>Null</th>
<th>Index_type</th>
<th>Comment Index_comment</th>
</tr>
</thead>
<tbody><tr>
<td>qd_channel</td>
<td>0</td>
<td>PRIMARY</td>
<td>1</td>
<td>CHANNEL_ID</td>
<td>A</td>
<td>212</td>
<td>null</td>
<td>null</td>
<td></td>
<td>BTREE</td>
<td></td>
</tr>
<tr>
<td>qd_channel</td>
<td>1</td>
<td>index_qd_channel</td>
<td>1</td>
<td>CHANNEL_ID</td>
<td>A</td>
<td>212</td>
<td>null</td>
<td>null</td>
<td></td>
<td>BTREE</td>
<td></td>
</tr>
<tr>
<td>qd_channel</td>
<td>1</td>
<td>index_qd_channel</td>
<td>2</td>
<td>CHANNEL_CODE</td>
<td>A</td>
<td>212</td>
<td>null</td>
<td>null</td>
<td>YES</td>
<td>BTREE</td>
<td></td>
</tr>
</tbody></table>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>Redis</title>
    <url>/database/Redis/base/</url>
    <content><![CDATA[<h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><p>一致哈希</p>
<p>构建一个存储数据集群的关键是有一个有效的数据存储和复制机制。我希望<font color="#FF0000">通过一个行之有效的方法来说明建造一个数据集群，在这个过程中你可以随意添加或移除一个Redis节点，同时保证你的数据仍然存在，而不会消失。这个方法称为一致哈希</font></p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><ul>
<li>String：缓存、限流、计数器、分布式锁、分布式Session</li>
<li>Hash：存储用户信息、用户主页访问量、组合查询</li>
<li>List：微博关注人时间轴列表、简单队列</li>
<li>Set：赞、踩、标签、好友关系</li>
<li>Zset：排行榜</li>
</ul>
<p>IO多路复用</p>
<p>I/O多路复用技术，是为了解决进程或线程阻塞到某个I/O系统调用而出现的技术，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪，就是这个文件描述符进行读写操作之前），能够通知程序进行相应的读写操作。</p>
<p>在Redis中一个字符串最大的容量为512MB</p>
<p>对于Hash结构存储，由于Hash结构会在单个Hash元素在不足一定数量时进行压缩存储，所以可以大量节约内存。这一点在String结构里是不存在的。</p>
<p><strong>数据一致性</strong></p>
<p>真正意义上来讲数据库的数据和缓存的数据是不可能一致的，数据分为最终一致和强一致两类。如果业务中对数据的要求必须强一致那么就不能使用缓存。缓存能做的只能保证数据的最终一致性。</p>
<p>我们能做的只能是尽可能地保证数据的一致性。不管是先删库再删缓存还是先删缓存再删库，都可能出现数据不一致的情况，因为读和写操作是并发的，</p>
<p><strong>Redis的过期和内存淘汰</strong></p>
<p>Redis存储数据时我们可以设置他的过期时间。</p>
<p>Redis过期删除采用的是定期删除，默认是每100ms检测一次，遇到过期的Key则进行删除，这里的检测并不是顺序检测，而是随机检测。</p>
<p>那这样会不会有漏网之鱼？显然Redis也考虑到了这一点，当我们去读/写一个已经过期的Key时，会触发Redis的惰性删除策略，直接回干掉过期的Key。</p>
<p>内存淘汰是指用户存储的一部分Key是可以被Redis自动的删除，从而会出现从缓存中查不到数据的情况。加入我们的服务器内存为2G、但是随着业务的发展缓存的数据已经超过2G了。</p>
<p>但是这并不影响我们程序的运行，因为操作系统的可见内存并不受物理内存的限制。物理内存不够用没关系，计算机会从硬盘中划出一片空间来作为虚拟内存。这就是Redis设计两种应用场景的初衷：缓存、持久存储。</p>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p><strong>解决方案：</strong></p>
<p>1、后台设置定时任务，主动地去更新缓存数据。这种方案容易理解，但是当Key比较分散的时候，操作起来还是比较复杂的。</p>
<p>2、分级缓存。比如设置两层缓存保护层，1级缓存失效时间短，2级缓存失效时间长。有请求过来优先从1级缓存中去查找，如果在1级缓存中没有找到相应数据，则对该线程进行加锁，这个线程再从数据库中取到数据，更新至1级和2级缓存。其他线程则直接从2级线程中获取。</p>
<p>3、提供一个拦截机制，内部维护一系列合法的Key值。当请求的Key不合法时，直接返回。</p>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p><strong>如何避免雪崩：</strong></p>
<p>1、给缓存加上一定区间内的随机生效时间，不同的Key设置不同的失效时间，避免同一时间集体失效。</p>
<p>2、和缓存击穿解决方案类似，做二级缓存，原始缓存失效时从拷贝缓存中读取数据。</p>
<p>3、利用加锁或者队列方式避免过多请求同时对服务器进行读写操作。</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>Redis的性能极高，读的速度是110000次/s，写的速度是81000次/s，支持事务，支持备份，丰富的数据类型。</p>
<p>任何事情都是两面性，Redis也是有缺点的：</p>
<p>1、由于是内存数据库，所以单台机器存储的数据量是有限的，需要开发者提前预估，需要及时删除不需要的数据。</p>
<p>2、当修改Redis的数据之后需要将持久化到硬盘的数据重新加入到内容中，时间比较久，这个时候Redis是无法正常运行的。</p>
<h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><h3 id="生产环境禁用命令"><a href="#生产环境禁用命令" class="headerlink" title="生产环境禁用命令"></a>生产环境禁用命令</h3><h4 id="keys"><a href="#keys" class="headerlink" title="keys"></a>keys</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 禁止使用Keys正则匹配</span></span><br><span class="line">keys * wxdb（此处省略）cf8*</span><br></pre></td></tr></table></figure>
<p>1、redis是单线程的，其所有操作都是原子的，不会因并发产生数据异常；</p>
<p>2、使用高耗时的Redis命令是很危险的，会占用唯一的一个线程的大量处理时间，导致所有的请求都被拖慢。（例如时间复杂度为O(N)的KEYS命令，严格禁止在生产环境中使用）；</p>
<ul>
<li>运维人员进行keys *操作，该操作比较耗时，又因为redis是单线程的，所以redis被锁住；</li>
<li>此时QPS比较高，又来了几万个对redis的读写请求，因为redis被锁住，所以全部Hang在那；</li>
<li>因为太多线程Hang在那，CPU严重飙升，造成redis所在的服务器宕机；</li>
<li>所有的线程在redis那取不到数据，一瞬间全去数据库取数据，数据库就宕机了；</li>
</ul>
<h4 id="flushdb-flushall-config"><a href="#flushdb-flushall-config" class="headerlink" title="flushdb flushall config"></a>flushdb flushall config</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flushdb 清空当前数据库的所有的key</span><br><span class="line">flushall 清空整个redis服务器的所有的key</span><br><span class="line">config 客户端连接后可配置服务器</span><br></pre></td></tr></table></figure>
<p>禁用命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rename-command FLUSHALL &quot;&quot;</span><br><span class="line">rename-command FLUSHDB &quot;&quot;</span><br><span class="line">rename-command CONFIG &quot;&quot;</span><br><span class="line">rename-command KEYS &quot;&quot;</span><br></pre></td></tr></table></figure>
<p>对于FLUSHALL命令，需要设置配置文件中appendonly no，否则服务器是无法启动。</p>
<p>时间复杂度高于O(N)的命令: hgetall、lrange、smembers、zrange、sinter等，它们并非不能使用，但这些命令的时间复杂度都为O(N)，使用这些命令需要明确N的值，否则也会出现缓存宕机。</p>
<p>Redis2.8版本以后有了一个新命令scan，可以用来分批次扫描redis记录，这样肯定会导致整个查询消耗的总时间变大，但不会影响redis服务卡顿，影响服务使用。</p>
<p><strong>分层架构设计，有一条准则</strong>：站点层、服务层要做到无数据无状态，这样才能任意的加节点水平扩展，数据和状态尽量存储到后端的数据存储服务，例如数据库服务或者缓存服务。</p>
<h2 id="Redis-or-Memcached"><a href="#Redis-or-Memcached" class="headerlink" title="Redis or Memcached"></a>Redis or Memcached</h2><p>value是哈希，列表，集合，有序集合这类复杂的数据结构时，会选择redis，因为mc无法满足这些需求，最典型的场景，用户订单列表，用户消息，帖子评论列表等。</p>
<p>Redis支持持久化</p>
<p>千万不要把redis当作数据库用：</p>
<p>（1）redis的定期快照不能保证数据不丢失</p>
<p>（2）redis的AOF会降低效率，并且不能支持太大的数据量</p>
<p><strong>缓存场景，开启固化功能，有什么利弊？</strong></p>
<p>如果只是缓存场景，数据存放在数据库，缓存在redis，此时如果开启固化功能： </p>
<p><strong>优点</strong>是，redis挂了再重启，内存里能够快速恢复热数据，不会瞬时将压力压到数据库上，没有一个cache预热的过程。</p>
<p><strong>缺点</strong>是，在redis挂了的过程中，如果数据库中有数据的修改，可能导致redis重启后，数据库与redis的数据不一致。</p>
<p>redis天然支持集群功能，可以实现主动复制，读写分离。</p>
<p>redis官方也提供了sentinel集群管理工具，能够实现主从服务监控，故障自动转移，这一切，对于客户端都是透明的，无需程序改动，也无需人工介入。</p>
<p>memcache的value存储，最大为1M，如果存储的value很大，只能使用redis</p>
<p><strong>什么时候倾向于memcache？</strong></p>
<p>纯KV，数据量非常大，并发量非常大的业务，使用memcache或许更适合。</p>
<p><strong>内存分配</strong></p>
<p>memcache使用预分配内存池的方式管理内存，能够省去内存分配时间。Redis则是临时申请空间，可能导致碎片。mc会更快一些。</p>
<p><strong>虚拟内存使用</strong></p>
<p>memcache把所有的数据存储在物理内存里。redis有自己的VM机制，理论上能够存储比物理内存更多的数据，当数据超量时，会引发swap，把冷数据刷到磁盘上。数据量大时，mc会更快一些。</p>
<p><strong>网络模型</strong></p>
<p>memcache使用非阻塞IO复用模型，redis也是使用非阻塞IO复用模型。但由于redis还提供一些非KV存储之外的排序，聚合功能，在执行这些功能时，复杂的CPU计算，会阻塞整个IO调度。</p>
<p>由于redis提供的功能较多，mc会更快一些。 </p>
<p><strong>线程模型</strong></p>
<p>memcache使用多线程，主线程监听，worker子线程接受请求，执行读写，这个过程中，可能存在锁冲突。redis使用单线程，虽无锁冲突，但难以利用多核的特性提升整体吞吐量。</p>
<p>从这一点上，mc会快一些。</p>
<p><em>画外音：理论上，mc只支持kv，而redis支持了这么多功能，mc性能应该高非常多非常多，但实际并非如此，真的可能和代码质量有关。</em></p>
<p><strong>水平扩展的支持</strong></p>
<p>不管是mc和redis，服务端集群没有天然支持水平扩展，需要在客户端进行分片，这其实对调用方并不友好。如果能服务端集群能够支持水平扩展，会更完美一些。</p>
]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title>Memcached(迭代更新)</title>
    <url>/database/memcached/base/</url>
    <content><![CDATA[<h1 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h1><h1 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h1>]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>Memcached</tag>
      </tags>
  </entry>
  <entry>
    <title>The Little Redis Book</title>
    <url>/database/Redis/the-little-Redis-book/</url>
    <content><![CDATA[<p><img src="/images/NOSQL/Redis/title.png"></p>
<h2 id="关于此书"><a href="#关于此书" class="headerlink" title="关于此书"></a>关于此书</h2><h3 id="最新版本"><a href="#最新版本" class="headerlink" title="最新版本"></a>最新版本</h3><p>此书的最新有效资源在：<br><a href="http://github.com/karlseguin/the-little-redis-book">http://github.com/karlseguin/the-little-redis-book</a></p>
<p>中文版是英文版的一个分支，最新的中文版本在：<br><a href="https://github.com/JasonLai256/the-little-redis-book">https://github.com/JasonLai256/the-little-redis-book</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>最近几年来，关于持久化和数据查询的相关技术，其需求已经增长到了让人惊讶的程度。可以断言，关系型数据库再也不是放之四海皆准。换一句话说，围绕数据的解决方案不可能再只有唯一一种。</p>
<p>对于我来说，在众多新出现的解决方案和工具里，最让人兴奋的，无疑是Redis。为什么？首先是因为其让人不可思议的容易学习，只需要简短的几个小时学习时间，就能对Redis有个大概的认识。还有，Redis在处理一组特定的问题集的同时能保持相当的通用性。更准确地说就是，Redis不会尝试去解决关于数据的所有事情。在你足够了解Redis后，事情就会变得越来越清晰，什么是可行的，什么是不应该由Redis来处理的。作为一名开发人员，如此的经验当是相当的美妙。</p>
<p>当你能仅使用Redis去构建一个完整系统时，我想大多数人将会发现，Redis能使得他们的许多数据方案变得更为通用，不论是一个传统的关系型数据库，一个面向文档的系统，或是其它更多的东西。这是一种用来实现某些特定特性的解决方法。就类似于一个索引引擎，你不会在 Lucene 上构建整个程序，但当你需要足够好的搜索，为什么不使用它呢？这对你和你的用户都有好处。当然，关于Redis和索引引擎之间相似性的讨论到此为止。</p>
<p>本书的目的是向读者传授掌握Redis所需要的基本知识。我们将会注重于学习Redis的5种数据结构，并研究各种数据建模方法。我们还会接触到一些主要的管理细节和调试技巧。</p>
<h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><p>每个人的学习方式都不一样，有的人喜欢亲自实践学习，有的喜欢观看教学视频，还有的喜欢通过阅读来学习。对于Redis，没有什么比亲自实践学习来得效果更好的了。Redis的安装非常简单。而且通过随之安装的一个简单的命令解析程序，就能处理我们想做的一切事情。让我们先花几分钟的时间把Redis安装到我们的机器上。</p>
<h3 id="Windows平台"><a href="#Windows平台" class="headerlink" title="Windows平台"></a>Windows平台</h3><p>Redis并没有官方支持Windows平台，但还是可供选择。你不会想在这里配置实际的生产环境，不过在我过往的开发经历里并没有感到有什么限制。</p>
<p>首先进入<a href="https://github.com/dmajkic/redis/downloads">https://github.com/dmajkic/redis/downloads</a>，然后下载最新的版本（应该会在列表的最上方）。</p>
<p>获取zip文件，然后根据你的系统架构，打开<code>64bit</code>或<code>32bit</code>文件夹。</p>
<h3 id="nix和MacOSX平台"><a href="#nix和MacOSX平台" class="headerlink" title="*nix和MacOSX平台"></a><code>*nix和MacOSX平台</code></h3><p>对于*nix和MacOSX平台的用户，从源文件来安装是你的最佳选择。通过最新的版本号来选择，有效地址于<a href="http://redis.io/download">http://redis.io/download</a>。在编写此书的时候，最新的版本是2.4.6，我们可以运行下面的命令来安装该版本：</p>
<pre><code>wget http://redis.googlecode.com/files/redis-2.4.6.tar.gz
tar xzf redis-2.4.6.tar.gz
cd redis-2.4.6
make</code></pre>
<p>（当然，Redis同样可以通过套件管理程序来安装。例如，使用Homebrew的MaxOSX用户可以只键入<code>brew install redis</code>即可。）</p>
<p>如果你是通过源文件来安装，二进制可执行文件会被放置在<code>src</code>目录里。通过运行<code>cd src</code>可跳转到<code>src</code>目录。</p>
<h3 id="运行和连接Redis"><a href="#运行和连接Redis" class="headerlink" title="运行和连接Redis"></a>运行和连接Redis</h3><p>如果一切都工作正常，那Redis的二进制文件应该已经可以曼妙地跳跃于你的指尖之下。Redis只有少量的可执行文件，我们将着重于Redis的服务器和命令行界面（一个类DOS的客户端）。首先，让我们来运行服务器。在Windows平台，双击<code>redis-server</code>，在*nix/MacOSX平台则运行<code>./redis-server</code>.</p>
<p>如果你仔细看了启动信息，你会看到一个警告，指没能找到<code>redis.conf</code>文件。Redis将会采用内置的默认设置，这对于我们将要做的已经足够了。</p>
<p>然后，通过双击<code>redis-cli</code>（Windows平台）或者运行<code>./redis-cli</code>（<code>*nix/MacOSX</code>平台），启动Redis的控制台。控制台将会通过默认的端口（6379）来连接本地运行的服务器。</p>
<p>可以在命令行界面键入<code>info</code>命令来查看一切是不是都运行正常。你会很乐意看到这么一大组关键字-值（key-value）对的显示，这为我们查看服务器的状态提供了大量有效信息。</p>
<p>如果在上面的启动步骤里遇到什么问题，我建议你到<a href="https://groups.google.com/forum/#!forum/redis-db">Redis的官方支持组</a>里获取帮助。</p>
<h2 id="驱动Redis"><a href="#驱动Redis" class="headerlink" title="驱动Redis"></a>驱动Redis</h2><p>很快你就会发现，Redis的API就如一组定义明确的函数那般容易理解。Redis具有让人难以置信的简单性，其操作过程也同样如此。这意味着，无论你是使用命令行程序，或是使用你喜欢的语言来驱动，整体的感觉都不会相差多少。因此，相对于命令行程序，如果你更愿意通过一种编程语言去驱动Redis，你不会感觉到有任何适应的问题。如果真想如此，可以到Redis的<a href="http://redis.io/clients">客户端推荐页面</a>下载适合的Redis载体。</p>
<h2 id="第1章-基础知识"><a href="#第1章-基础知识" class="headerlink" title="第1章 - 基础知识"></a>第1章 - 基础知识</h2><p>是什么使Redis显得这么特别？Redis具体能解决什么类型的问题？要实际应用Redis，开发者必须储备什么知识？在我们能回答这么一些问题之前，我们需要明白Redis到底是什么。</p>
<p>Redis通常被人们认为是一种持久化的存储器关键字-值型存储（in-memory persistent key-value store）。我认为这种对Redis的描述并不太准确。Redis的确是将所有的数据存放于存储器（更多是是按位存储），而且也确实通过将数据写入磁盘来实现持久化，但是<strong>Redis的实际意义比单纯的关键字-值型存储要来得深远</strong>。纠正脑海里的这种误解观点非常关键，否则你对于Redis之道以及其应用的洞察力就会变得越发狭义。</p>
<p>事实是，Redis引入了5种不同的数据结构，只有一个是典型的关键字-值型结构。理解Redis的关键就在于搞清楚这5种数据结构，其工作的原理都是如何，有什么关联方法以及你能怎样应用这些数据结构去构建模型。首先，让我们来弄明白这些数据结构的实际意义。</p>
<p>应用上面提及的数据结构概念到我们熟悉的关系型数据库里，我们可以认为其引入了一个单独的数据结构——表格。表格既复杂又灵活，基于表格的存储和管理，没有多少东西是你不能进行建模的。然而，这种通用性并不是没有缺点。具体来说就是，事情并不是总能达到假设中的简单或者快速。相对于这种普遍适用（one-size-fits-all）的结构体系，我们可以使用更为专门化的结构体系。当然，因此可能有些事情我们会完成不了(至少，达不到很好的程度）。但话说回来，这样做就能确定我们可以获得想象中的简单性和速度吗？</p>
<p>针对特定类型的问题使用特定的数据结构？我们不就是这样进行编程的吗？你不会使用一个散列表去存储每份数据，也不会使用一个标量变量去存储。对我来说，这正是Redis的做法。如果你需要处理标量、列表、散列或者集合，为什么不直接就用标量、列表、散列和集合去存储他们？为什么不是直接调用<code>exists(key)</code>去检测一个已存在的值，而是要调用其他比O(1)（常量时间查找，不会因为待处理元素的增长而变慢）慢的操作？</p>
<h3 id="数据库（Databases）"><a href="#数据库（Databases）" class="headerlink" title="数据库（Databases）"></a>数据库（Databases）</h3><p>与你熟悉的关系型数据库一致，Redis有着相同的数据库基本概念，即一个数据库包含一组数据。典型的数据库应用案例是，将一个程序的所有数据组织起来，使之与另一个程序的数据保持独立。</p>
<p>在Redis里，数据库简单的使用一个数字编号来进行辨认，默认数据库的数字编号是<code>0</code>。如果你想切换到一个不同的数据库，你可以使用<code>select</code>命令来实现。在命令行界面里键入<code>select 1</code>，Redis应该会回复一条<code>OK</code>的信息，然后命令行界面里的提示符会变成类似<code>redis 127.0.0.1:6379[1]&gt;</code>这样。如果你想切换回默认数据库，只要在命令行界面键入<code>select 0</code>即可。</p>
<h3 id="命令、关键字和值（Commands-Keys-and-Values）"><a href="#命令、关键字和值（Commands-Keys-and-Values）" class="headerlink" title="命令、关键字和值（Commands, Keys and Values）"></a>命令、关键字和值（Commands, Keys and Values）</h3><p>Redis不仅仅是一种简单的关键字-值型存储，从其核心概念来看，Redis的5种数据结构中的每一个都至少有一个关键字和一个值。在转入其它关于Redis的有用信息之前，我们必须理解关键字和值的概念。</p>
<p>关键字（Keys）是用来标识数据块。我们将会经常跟关键字打交道，不过在现在，明白关键字就是类似于<code>users:leto</code>这样的表述就足够了。一般都能很好地理解到，这样关键字包含的信息是一个名为<code>leto</code>的用户。这个关键字里的冒号没有任何特殊含义，对于Redis而言，使用分隔符来组织关键字是很常见的方法。</p>
<p>值（Values）是关联于关键字的实际值，可以是任何东西。有时候你会存储字符串，有时候是整数，还有时候你会存储序列化对象（使用JSON、XML或其他格式）。在大多数情况下，Redis会把值看做是一个字节序列，而不会关注它们实质上是什么。要注意，不同的Redis载体处理序列化会有所不同（一些会让你自己决定）。因此，在这本书里，我们将仅讨论字符串、整数和JSON。</p>
<p>现在让我们活动一下手指吧。在命令行界面键入下面的命令：</p>
<pre><code>set users:leto &quot;&#123;name: leto, planet: dune, likes: [spice]&#125;&quot;</code></pre>
<p>这就是Redis命令的基本构成。首先我们要有一个确定的命令，在上面的语句里就是<code>set</code>。然后就是相应的参数，<code>set</code>命令接受两个参数，包括要设置的关键字，以及相应要设置的值。很多的情况是，命令接受一个关键字（当这种情况出现，其经常是第一个参数）。你能想到如何去获取这个值吗？我想你会说（当然一时拿不准也没什么）：</p>
<pre><code>get users:leto</code></pre>
<p>关键字和值的是Redis的基本概念，而<code>get</code>和<code>set</code>命令是对此最简单的使用。你可以创建更多的用户，去尝试不同类型的关键字以及不同的值，看看一些不同的组合。</p>
<h3 id="查询（Querying）"><a href="#查询（Querying）" class="headerlink" title="查询（Querying）"></a>查询（Querying）</h3><p>随着学习的持续深入，两件事情将变得清晰起来。对于Redis而言, <code>key</code>就是一切，而值是没有任何意义。更通俗来看就是，Redis不允许你通过值来进行查询。回到上面的例子，我们就不能查询生活在<code>dune</code>行星上的用户。</p>
<p>对许多人来说，这会引起一些担忧。在我们生活的世界里，数据查询是如此的灵活和强大，而Redis的方式看起来是这么的原始和不高效。不要让这些扰乱你太久。要记住，Redis不是一种普遍使用（one-size-fits-all）的解决方案，确实存在这么一些事情是不应该由Redis来解决的（因为其查询的限制）。事实上，在考虑了这些情况后，你会找到新的方法去构建你的数据。</p>
<p>很快，我们就能看到更多实际的用例。很重要的一点是，我们要明白关于Redis的这些基本事实。这能帮助我们弄清楚: 为什么<code>value</code>可以是任何东西，因为Redis从来不需要去读取或理解它们。而且，这也可以帮助我们理清思路，然后去思考如何在这个新世界里建立模型。</p>
<h3 id="存储器和持久化（Memory-and-Persistence）"><a href="#存储器和持久化（Memory-and-Persistence）" class="headerlink" title="存储器和持久化（Memory and Persistence）"></a>存储器和持久化（Memory and Persistence）</h3><p>我们之前提及过，Redis是一种持久化的存储器内存储（in-memory persistent store）。对于持久化，默认情况下，Redis会根据已变更的关键字数量来进行判断，然后在磁盘里创建数据库的快照（snapshot）。你可以对此进行设置，如果X个关键字已变更，那么每隔Y秒存储数据库一次。默认情况下，如果1000个或更多的关键字已变更，Redis会每隔60秒存储数据库；而如果9个或更少的关键字已变更，Redis会每隔15分钟存储数据库。</p>
<p>除了创建磁盘快照外，Redis可以在附加模式下运行。任何时候，如果有一个关键字变更，一个单一附加（append-only）的文件会在磁盘里进行更新。在一些情况里，虽然硬件或软件可能发生错误，但用那60秒有效数据存储去换取更好性能是可以接受的。而在另一些情况里，这种损失就难以让人接受，Redis为你提供了选择。在第5章里，我们将会看到第三种选择，其将持久化任务减荷到一个从属数据库里。</p>
<p>至于存储器，Redis会将所有数据都保留在存储器中。显而易见，运行Redis具有不低的成本：因为RAM仍然是最昂贵的服务器硬件部件。</p>
<p>我很清楚有一些开发者对即使是一点点的数据空间都是那么的敏感。一本《威廉·莎士比亚全集》需要近5.5MB的存储空间。对于缩放的需求，其它的解决方案趋向于IO-bound或者CPU-bound。这些限制（RAM或者IO）将会需要你去理解更多机器实际依赖的数据类型，以及应该如何去进行存储和查询。除非你是存储大容量的多媒体文件到Redis中，否则存储器内存储应该不会是一个问题。如果这对于一个程序是个问题，你就很可能不会用IO-bound的解决方案。</p>
<p>Redis有虚拟存储器的支持。然而，这个功能已经被认为是失败的了（通过Redis的开发者），而且它的使用已经被废弃了。</p>
<p>（从另一个角度来看，一本5.5MB的《威廉·莎士比亚全集》可以通过压缩减小到近2MB。当然，Redis不会自动对值进行压缩，但是因为其将所有值都看作是字节，没有什么限制让你不能对数据进行压缩/解压，通过牺牲处理时间来换取存储空间。）</p>
<h3 id="整体来看（Putting-It-Together）"><a href="#整体来看（Putting-It-Together）" class="headerlink" title="整体来看（Putting It Together）"></a>整体来看（Putting It Together）</h3><p>我们已经接触了好几个高层次的主题。在继续深入Redis之前，我想做的最后一件事情是将这些主题整合起来。这些主题包括，查询的限制，数据结构以及Redis在存储器内存储数据的方法。</p>
<p>当你将这3个主题整合起来，你最终会得出一个绝妙的结论：速度。一些人可能会想，当然Redis会很快速，要知道所有的东西都在存储器里。但这仅仅是其中的一部分，让Redis闪耀的真正原因是其不同于其它解决方案的特殊数据结构。</p>
<p>能有多快速？这依赖于很多东西，包括你正在使用着哪个命令，数据的类型等等。但Redis的性能测试是趋向于数万或数十万次操作<strong>每秒</strong>。你可以通过运行<code>redis-benchmark</code>（就在<code>redis-server</code>和<code>redis-cli</code>的同一个文件夹里）来进行测试。</p>
<p>我曾经试过将一组使用传统模型的代码转向使用Redis。在传统模型里，运行一个我写的载入测试，需要超过5分钟的时间来完成。而在Redis里，只需要150毫秒就完成了。你不会总能得到这么好的收获，但希望这能让你对我们所谈的东西有更清晰的理解。</p>
<p>理解Redis的这个特性很重要，因为这将影响到你如何去与Redis进行交互。拥有SQL背景的程序员通常会致力于让数据库的数据往返次数减至最小。这对于任何系统都是个好建议，包括Redis。然而，考虑到我们是在处理比较简单的数据结构，有时候我们还是需要与Redis服务器频繁交互，以达到我们的目的。刚开始的时候，可能会对这种数据访问模式感到不太自然。实际上，相对于我们通过Redis获得的高性能而言，这仅仅是微不足道的损失。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>虽然我们只接触和摆弄了Redis的冰山一角，但我们讨论的主题已然覆盖了很大范围内的东西。如果觉得有些事情还是不太清楚（例如查询），不用为此而担心，在下一章我们将会继续深入探讨，希望你的问题都能得到解答。</p>
<p>这一章的要点包括：</p>
<ul>
<li><p>关键字（Keys）是用于标识一段数据的一个字符串</p>
</li>
<li><p>值（Values）是一段任意的字节序列，Redis不会关注它们实质上是什么</p>
</li>
<li><p>Redis展示了（也实现了）5种专门的数据结构</p>
</li>
<li><p>上面的几点使得Redis快速而且容易使用，但要知道Redis并不适用于所有的应用场景</p>
</li>
</ul>
<h2 id="第2章-数据结构"><a href="#第2章-数据结构" class="headerlink" title="第2章 - 数据结构"></a>第2章 - 数据结构</h2><p>现在开始将探究Redis的5种数据结构，我们会解释每种数据结构都是什么，包含了什么有效的方法（Method），以及你能用这些数据结构处理哪些类型的特性和数据。</p>
<p>目前为止，我们所知道的Redis构成仅包括命令、关键字和值，还没有接触到关于数据结构的具体概念。当我们使用<code>set</code>命令时，Redis是怎么知道我们是在使用哪个数据结构？其解决方法是，每个命令都相对应于一种特定的数据结构。例如，当你使用<code>set</code>命令，你就是将值存储到一个字符串数据结构里。而当你使用<code>hset</code>命令，你就是将值存储到一个散列数据结构里。考虑到Redis的关键字集很小，这样的机制具有相当的可管理性。</p>
<p><strong><a href="http://redis.io/commands">Redis的网站</a>里有着非常优秀的参考文档，没有任何理由去重造轮子。但为了搞清楚这些数据结构的作用，我们将会覆盖那些必须知道的重要命令。</strong></p>
<p>没有什么事情比高兴的玩和试验有趣的东西来得更重要的了。在任何时候，你都能通过键入<code>flushdb</code>命令将你数据库里的所有值清除掉，因此，不要再那么害羞了，去尝试做些疯狂的事情吧！</p>
<h3 id="字符串（Strings"><a href="#字符串（Strings" class="headerlink" title="字符串（Strings)"></a>字符串（Strings)</h3><p>在Redis里，字符串是最基本的数据结构。当你在思索着关键字-值对时，你就是在思索着字符串数据结构。不要被名字给搞混了，如之前说过的，你的值可以是任何东西。我更喜欢将他们称作“标量”（Scalars），但也许只有我才这样想。</p>
<p>我们已经看到了一个常见的字符串使用案例，即通过关键字存储对象的实例。有时候，你会频繁地用到这类操作：</p>
<pre><code>set users:leto &quot;&#123;name: leto, planet: dune, likes: [spice]&#125;&quot;</code></pre>
<p>除了这些外，Redis还有一些常用的操作。例如，<code>strlen &lt;key&gt;</code>能用来获取一个关键字对应值的长度；<code>getrange &lt;key&gt; &lt;start&gt; &lt;end&gt;</code>将返回指定范围内的关键字对应值；<code>append &lt;key&gt; &lt;value&gt;</code>会将value附加到已存在的关键字对应值中（如果该关键字并不存在，则会创建一个新的关键字-值对）。不要犹豫，去试试看这些命令吧。下面是我得到的：</p>
<pre><code>&gt; strlen users:leto
(integer) 42

&gt; getrange users:leto 27 40
&quot;likes: [spice]&quot;

&gt; append users:leto &quot; OVER 9000!!&quot;
(integer) 54</code></pre>
<p>现在你可能会想，这很好，但似乎没有什么意义。你不能有效地提取出一段范围内的JSON文件，或者为其附加一些值。你是对的，这里的经验是，一些命令，尤其是关于字符串数据结构的，只有在给定了明确的数据类型后，才会有实际意义。</p>
<p>之前我们知道了，Redis不会去关注你的值是什么东西。通常情况下，这没有错。然而，一些字符串命令是专门为一些类型或值的结构而设计的。作为一个有些含糊的用例，我们可以看到，对于一些自定义的空间效率很高的（space-efficient）串行化对象，<code>append</code>和<code>getrange</code>命令将会很有用。对于一个更为具体的用例，我们可以再看一下<code>incr</code>、<code>incrby</code>、<code>decr</code>和<code>decrby</code>命令。这些命令会增长或者缩减一个字符串数据结构的值：</p>
<pre><code>&gt; incr stats:page:about
(integer) 1
&gt; incr stats:page:about
(integer) 2

&gt; incrby ratings:video:12333 5
(integer) 5
&gt; incrby ratings:video:12333 3
(integer) 8</code></pre>
<p>由此你可以想象到，Redis的字符串数据结构能很好地用于分析用途。你还可以去尝试增长<code>users:leto</code>（一个不是整数的值），然后看看会发生什么（应该会得到一个错误）。</p>
<p>更为进阶的用例是<code>setbit</code>和<code>getbit</code>命令。“今天我们有多少个独立用户访问”是个在Web应用里常见的问题，有一篇<a href="http://blog.getspool.com/2011/11/29/fast-easy-realtime-metrics-using-redis-bitmaps/">精彩的博文</a>，在里面可以看到Spool是如何使用这两个命令有效地解决此问题。对于1.28亿个用户，一部笔记本电脑在不到50毫秒的时间里就给出了答复，而且只用了16MB的存储空间。</p>
<p>最重要的事情不是在于你是否明白位图（Bitmaps)的工作原理，或者Spool是如何去使用这些命令，而是应该要清楚Redis的字符串数据结构比你当初所想的要有用许多。然而，最常见的应用案例还是上面我们给出的：存储对象（简单或复杂）和计数。同时，由于通过关键字来获取一个值是如此之快，字符串数据结构很常被用来缓存数据。</p>
<h3 id="散列（Hashes）"><a href="#散列（Hashes）" class="headerlink" title="散列（Hashes）"></a>散列（Hashes）</h3><p>我们已经知道把Redis称为一种关键字-值型存储是不太准确的，散列数据结构是一个很好的例证。你会看到，在很多方面里，散列数据结构很像字符串数据结构。两者显著的区别在于，散列数据结构提供了一个额外的间接层：一个域（Field）。因此，散列数据结构中的<code>set</code>和<code>get</code>是：</p>
<pre><code>hset users:goku powerlevel 9000
hget users:goku powerlevel</code></pre>
<p>相关的操作还包括在同一时间设置多个域、同一时间获取多个域、获取所有的域和值、列出所有的域或者删除指定的一个域：</p>
<pre><code>hmset users:goku race saiyan age 737
hmget users:goku race powerlevel
hgetall users:goku
hkeys users:goku
hdel users:goku age</code></pre>
<p>如你所见，散列数据结构比普通的字符串数据结构具有更多的可操作性。我们可以使用一个散列数据结构去获得更精确的描述，是存储一个用户，而不是一个序列化对象。从而得到的好处是能够提取、更新和删除具体的数据片段，而不必去获取或写入整个值。</p>
<p>对于散列数据结构，可以从一个经过明确定义的对象的角度来考虑，例如一个用户，关键之处在于要理解他们是如何工作的。从性能上的原因来看，这是正确的，更具粒度化的控制可能会相当有用。在下一章我们将会看到，如何用散列数据结构去组织你的数据，使查询变得更为实效。在我看来，这是散列真正耀眼的地方。</p>
<h3 id="列表（Lists）"><a href="#列表（Lists）" class="headerlink" title="列表（Lists）"></a>列表（Lists）</h3><p>对于一个给定的关键字，列表数据结构让你可以存储和处理一组值。你可以添加一个值到列表里、获取列表的第一个值或最后一个值以及用给定的索引来处理值。列表数据结构维护了值的顺序，提供了基于索引的高效操作。为了跟踪在网站里注册的最新用户，我们可以维护一个<code>newusers</code>的列表：</p>
<pre><code>lpush newusers goku
ltrim newusers 0 50</code></pre>
<p><strong>（译注：<code>ltrim</code>命令的具体构成是<code>LTRIM Key start stop</code>。要理解<code>ltrim</code>命令，首先要明白Key所存储的值是一个列表，理论上列表可以存放任意个值。对于指定的列表，根据所提供的两个范围参数start和stop，<code>ltrim</code>命令会将指定范围外的值都删除掉，只留下范围内的值。）</strong></p>
<p>首先，我们将一个新用户推入到列表的前端，然后对列表进行调整，使得该列表只包含50个最近被推入的用户。这是一种常见的模式。<code>ltrim</code>是一个具有O(N)时间复杂度的操作，N是被删除的值的数量。从上面的例子来看，我们总是在插入了一个用户后再进行列表调整，实际上，其将具有O(1)的时间复杂度（因为N将永远等于1）的常数性能。</p>
<p>这是我们第一次看到一个关键字的对应值索引另一个值。如果我们想要获取最近的10个用户的详细资料，我们可以运行下面的组合操作：</p>
<pre><code>keys = redis.lrange(&#39;newusers&#39;, 0, 10)
redis.mget(*keys.map &#123;|u| &quot;users:#&#123;u&#125;&quot;&#125;)</code></pre>
<p>我们之前谈论过关于多次往返数据的模式，上面的两行Ruby代码为我们进行了很好的演示。</p>
<p>当然，对于存储和索引关键字的功能，并不是只有列表数据结构这种方式。值可以是任意的东西，你可以使用列表数据结构去存储日志，也可以用来跟踪用户浏览网站时的路径。如果你过往曾构建过游戏，你可能会使用列表数据结构去跟踪用户的排队活动。</p>
<h3 id="集合（Sets）"><a href="#集合（Sets）" class="headerlink" title="集合（Sets）"></a>集合（Sets）</h3><p>集合数据结构常常被用来存储只能唯一存在的值，并提供了许多的基于集合的操作，例如并集。集合数据结构没有对值进行排序，但是其提供了高效的基于值的操作。使用集合数据结构的典型用例是朋友名单的实现：</p>
<pre><code>sadd friends:leto ghanima paul chani jessica
sadd friends:duncan paul jessica alia</code></pre>
<p>不管一个用户有多少个朋友，我们都能高效地（O(1)时间复杂度）识别出用户X是不是用户Y的朋友：</p>
<pre><code>sismember friends:leto jessica
sismember friends:leto vladimir</code></pre>
<p>而且，我们可以查看两个或更多的人是不是有共同的朋友：</p>
<pre><code>sinter friends:leto friends:duncan</code></pre>
<p>甚至可以在一个新的关键字里存储结果：</p>
<pre><code>sinterstore friends:leto_duncan friends:leto friends:duncan</code></pre>
<p>有时候需要对值的属性进行标记和跟踪处理，但不能通过简单的复制操作完成，集合数据结构是解决此类问题的最好方法之一。当然，对于那些需要运用集合操作的地方（例如交集和并集），集合数据结构就是最好的选择。</p>
<h3 id="分类集合（Sorted-Sets）"><a href="#分类集合（Sorted-Sets）" class="headerlink" title="分类集合（Sorted Sets）"></a>分类集合（Sorted Sets）</h3><p>最后也是最强大的数据结构是分类集合数据结构。如果说散列数据结构类似于字符串数据结构，主要区分是域（field）的概念；那么分类集合数据结构就类似于集合数据结构，主要区分是标记（score）的概念。标记提供了排序（sorting）和秩划分（ranking）的功能。如果我们想要一个秩分类的朋友名单，可以这样做：</p>
<pre><code>zadd friends:duncan 70 ghanima 95 paul 95 chani 75 jessica 1 vladimir</code></pre>
<p>对于<code>duncan</code>的朋友，要怎样计算出标记（score）为90或更高的人数？</p>
<pre><code>zcount friends:duncan 90 100</code></pre>
<p>如何获取<code>chani</code>在名单里的秩（rank）？</p>
<pre><code>zrevrank friends:duncan chani</code></pre>
<p><strong>（译注：<code>zrank</code>命令的具体构成是<code>ZRANK Key menber</code>，要知道Key存储的Sorted Set默认是根据Score对各个menber进行升序的排列，该命令就是用来获取menber在该排列里的次序，这就是所谓的秩。）</strong></p>
<p>我们使用了<code>zrevrank</code>命令而不是<code>zrank</code>命令，这是因为Redis的默认排序是从低到高，但是在这个例子里我们的秩划分是从高到低。对于分类集合数据结构，最常见的应用案例是用来实现排行榜系统。事实上，对于一些基于整数排序，且能以标记（score）来进行有效操作的东西，使用分类集合数据结构来处理应该都是不错的选择。</p>
<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>对于Redis的5种数据结构，我们进行了高层次的概述。一件有趣的事情是，相对于最初构建时的想法，你经常能用Redis创造出一些更具实效的事情。对于字符串数据结构和分类集合数据结构的使用，很有可能存在一些构建方法是还没有人想到的。当你理解了那些常用的应用案例后，你将发现Redis对于许多类型的问题，都是很理想的选择。还有，不要因为Redis展示了5种数据结构和相应的各种方法，就认为你必须要把所有的东西都用上。只使用一些命令去构建一个特性是很常见的。</p>
<h2 id="第3章-使用数据结构"><a href="#第3章-使用数据结构" class="headerlink" title="第3章 - 使用数据结构"></a>第3章 - 使用数据结构</h2><p>在上一章里，我们谈论了Redis的5种数据结构，对于一些可能的用途也给出了用例。现在是时候来看看一些更高级，但依然很常见的主题和设计模式。</p>
<h3 id="大O表示法（Big-O-Notation）"><a href="#大O表示法（Big-O-Notation）" class="headerlink" title="大O表示法（Big O Notation）"></a>大O表示法（Big O Notation）</h3><p>在本书中，我们之前就已经看到过大O表示法，包括O(1)和O(N)的表示。大O表示法的惯常用途是，描述一些用于处理一定数量元素的行为的综合表现。在Redis里，对于一个要处理一定数量元素的命令，大O表示法让我们能了解该命令的大概运行速度。</p>
<p>在Redis的文档里，每一个命令的时间复杂度都用大O表示法进行了描述，还能知道各命令的具体性能会受什么因素影响。让我们来看看一些用例。</p>
<p>常数时间复杂度O(1)被认为是最快速的，无论我们是在处理5个元素还是5百万个元素，最终都能得到相同的性能。对于<code>sismember</code>命令，其作用是告诉我们一个值是否属于一个集合，时间复杂度为O(1)。<code>sismember</code>命令很强大，很大部分的原因是其高效的性能特征。许多Redis命令都具有O(1)的时间复杂度。</p>
<p>对数时间复杂度O(log(N))被认为是第二快速的，其通过使需扫描的区间不断皱缩来快速完成处理。使用这种“分而治之”的方式，大量的元素能在几个迭代过程里被快速分解完整。<code>zadd</code>命令的时间复杂度就是O(log(N))，其中N是在分类集合中的元素数量。</p>
<p>再下来就是线性时间复杂度O(N)，在一个表格的非索引列里进行查找就需要O(N)次操作。<code>ltrim</code>命令具有O(N)的时间复杂度，但是，在<code>ltrim</code>命令里，N不是列表所拥有的元素数量，而是被删除的元素数量。从一个具有百万元素的列表里用<code>ltrim</code>命令删除1个元素，要比从一个具有一千个元素的列表里用<code>ltrim</code>命令删除10个元素来的快速（实际上，两者很可能会是一样快，因为两个时间都非常的小）。</p>
<p>根据给定的最小和最大的值的标记，<code>zremrangebyscore</code>命令会在一个分类集合里进行删除元素操作，其时间复杂度是O(log(N)+M)。这看起来似乎有点儿杂乱，通过阅读文档可以知道，这里的N指的是在分类集合里的总元素数量，而M则是被删除的元素数量。可以看出，对于性能而言，被删除的元素数量很可能会比分类集合里的总元素数量更为重要。</p>
<p><strong>（译注：<code>zremrangebyscore</code>命令的具体构成是<code>ZREMRANGEBYSCORE Key max mix</code>。）</strong></p>
<p>对于<code>sort</code>命令，其时间复杂度为O(N+M*log(M))，我们将会在下一章谈论更多的相关细节。从<code>sort</code>命令的性能特征来看，可以说这是Redis里最复杂的一个命令。</p>
<p>还存在其他的时间复杂度描述，包括O(N^2)和O(C^N)。随着N的增大，其性能将急速下降。在Redis里，没有任何一个命令具有这些类型的时间复杂度。</p>
<p>值得指出的一点是，在Redis里，当我们发现一些操作具有O(N)的时间复杂度时，我们可能可以找到更为好的方法去处理。</p>
<p><strong>（译注：对于Big O Notation，相信大家都非常的熟悉，虽然原文仅仅是对该表示法进行简单的介绍，但限于个人的算法知识和文笔水平实在有限，此小节的翻译让我头痛颇久，最终成果也确实难以让人满意，望见谅。）</strong></p>
<h3 id="仿多关键字查询（Pseudo-Multi-Key-Queries）"><a href="#仿多关键字查询（Pseudo-Multi-Key-Queries）" class="headerlink" title="仿多关键字查询（Pseudo Multi Key Queries）"></a>仿多关键字查询（Pseudo Multi Key Queries）</h3><p>时常，你会想通过不同的关键字去查询相同的值。例如，你会想通过电子邮件（当用户开始登录时）去获取用户的具体信息，或者通过用户id（在用户登录后）去获取。有一种很不实效的解决方法，其将用户对象分别放置到两个字符串值里去：</p>
<pre><code>set users:leto@dune.gov &quot;&#123;id: 9001, email: &#39;leto@dune.gov&#39;, ...&#125;&quot;
set users:9001 &quot;&#123;id: 9001, email: &#39;leto@dune.gov&#39;, ...&#125;&quot;</code></pre>
<p>这种方法很糟糕，如此不但会产生两倍数量的内存，而且这将会成为数据管理的恶梦。</p>
<p>如果Redis允许你将一个关键字链接到另一个的话，可能情况会好很多，可惜Redis并没有提供这样的功能（而且很可能永远都不会提供）。Redis发展到现在，其开发的首要目的是要保持代码和API的整洁简单，关键字链接功能的内部实现并不符合这个前提（对于关键字，我们还有很多相关方法没有谈论到）。其实，Redis已经提供了解决的方法：散列。</p>
<p>使用散列数据结构，我们可以摆脱重复的缠绕：</p>
<pre><code>set users:9001 &quot;&#123;id: 9001, email: leto@dune.gov, ...&#125;&quot;
hset users:lookup:email leto@dune.gov 9001</code></pre>
<p>我们所做的是，使用域来作为一个二级索引，然后去引用单个用户对象。要通过id来获取用户信息，我们可以使用一个普通的<code>get</code>命令：</p>
<pre><code>get users:9001</code></pre>
<p>而如果想通过电子邮箱来获取用户信息，我们可以使用<code>hget</code>命令再配合使用<code>get</code>命令（Ruby代码）：</p>
<pre><code>id = redis.hget(&#39;users:lookup:email&#39;, &#39;leto@dune.gov&#39;)
user = redis.get(&quot;users:#&#123;id&#125;&quot;)</code></pre>
<p>你很可能将会经常使用这类用法。在我看来，这就是散列真正耀眼的地方。在你了解这类用法之前，这可能不是一个明显的用例。</p>
<h3 id="引用和索引（References-and-Indexes）"><a href="#引用和索引（References-and-Indexes）" class="headerlink" title="引用和索引（References and Indexes）"></a>引用和索引（References and Indexes）</h3><blockquote>
<p> Redis必须手动的管理索引和引用</p>
</blockquote>
<p>我们已经看过几个关于值引用的用例，包括介绍列表数据结构时的用例，以及在上面使用散列数据结构来使查询更灵活一些。进行归纳后会发现，对于那些值与值间的索引和引用，我们都必须手动的去管理。诚实来讲，这确实会让人有点沮丧，尤其是当你想到那些引用相关的操作，如管理、更新和删除等，都必须手动的进行时。在Redis里，这个问题还没有很好的解决方法。</p>
<p>我们已经看到，集合数据结构常常被用来实现这类索引：</p>
<pre><code>sadd friends:leto ghanima paul chani jessica</code></pre>
<p>这个集合里的每一个成员都是一个Redis字符串数据结构的引用，而每一个引用的值则包含着用户对象的具体信息。那么如果<code>chani</code>改变了她的名字，或者删除了她的帐号，应该如何处理？从整个朋友圈的关系结构来看可能会更好理解，我们知道，<code>chani</code>也有她的朋友：</p>
<pre><code>sadd friends_of:chani leto paul</code></pre>
<p>如果你有什么待处理情况像上面那样，那在维护成本之外，还会有对于额外索引值的处理和存储空间的成本。这可能会令你感到有点退缩。在下一小节里，我们将会谈论减少使用额外数据交互的性能成本的一些方法（在第1章我们粗略地讨论了下）。</p>
<blockquote>
<p>在上一节实现引用的技巧中，当一个集合的每个成员都对应一个引用时，如果这个成员的名称发生变化时，需要手动的更新索引对应的值，这需要额外的工作</p>
</blockquote>
<blockquote>
<p>即使是在传统的关系型数据库中，也需要维护索引，不过这些工作是由数据库自身维护的</p>
</blockquote>
<p>如果你确实在担忧着这些情况，其实，关系型数据库也有同样的开销。索引需要一定的存储空间，必须通过扫描或查找，然后才能找到相应的记录。其开销也是存在的，当然他们对此做了很多的优化工作，使之变得更为有效。</p>
<p>再次说明，需要在Redis里手动地管理引用确实是颇为棘手。但是，对于你关心的那些问题，包括性能或存储空间等，应该在经过测试后，才会有真正的理解。我想你会发现这不会是一个大问题。</p>
<h3 id="数据交互和流水线（Round-Trips-and-Pipelining）"><a href="#数据交互和流水线（Round-Trips-and-Pipelining）" class="headerlink" title="数据交互和流水线（Round Trips and Pipelining）"></a>数据交互和流水线（Round Trips and Pipelining）</h3><p>我们已经提到过，与服务器频繁交互是Redis的一种常见模式。这类情况可能很常出现，为了使我们能获益更多，值得仔细去看看我们能利用哪些特性。</p>
<p>许多命令能接受一个或更多的参数，也有一种关联命令（sister-command）可以接受多个参数。例如早前我们看到过<code>mget</code>命令，接受多个关键字，然后返回值：</p>
<pre><code>keys = redis.lrange(&#39;newusers&#39;, 0, 10)
redis.mget(*keys.map &#123;|u| &quot;users:#&#123;u&#125;&quot;&#125;)</code></pre>
<p>或者是<code>sadd</code>命令，能添加一个或多个成员到集合里：</p>
<pre><code>sadd friends:vladimir piter
sadd friends:paul jessica leto &quot;leto II&quot; chani</code></pre>
<p>Redis还支持流水线功能。通常情况下，当一个客户端发送请求到Redis后，在发送下一个请求之前必须等待Redis的答复。使用流水线功能，你可以发送多个请求，而不需要等待Redis响应。这不但减少了网络开销，还能获得性能上的显著提高。</p>
<p>值得一提的是，Redis会使用存储器去排列命令，因此批量执行命令是一个好主意。至于具体要多大的批量，将取决于你要使用什么命令（更明确来说，该参数有多大）。另一方面来看，如果你要执行的命令需要差不多50个字符的关键字，你大概可以对此进行数千或数万的批量操作。</p>
<p>对于不同的Redis载体，在流水线里运行命令的方式会有所差异。在Ruby里，你传递一个代码块到<code>pipelined</code>方法：</p>
<pre><code>redis.pipelined do
  9001.times do
    redis.incr(&#39;powerlevel&#39;)
  end
end</code></pre>
<p>正如你可能猜想到的，流水线功能可以实际地加速一连串命令的处理。</p>
<h3 id="事务（Transactions）"><a href="#事务（Transactions）" class="headerlink" title="事务（Transactions）"></a>事务（Transactions）</h3><p>每一个Redis命令都具有原子性，包括那些一次处理多项事情的命令。此外，对于使用多个命令，Redis支持事务功能。</p>
<p>你可能不知道，但Redis实际上是单线程运行的，这就是为什么每一个Redis命令都能够保证具有原子性。当一个命令在执行时，没有其他命令会运行（我们会在往后的章节里简略谈论一下Scaling）。在你考虑到一些命令去做多项事情时，这会特别的有用。例如：</p>
<p><code>incr</code>命令实际上就是一个<code>get</code>命令然后紧随一个<code>set</code>命令。</p>
<p><code>getset</code>命令设置一个新的值然后返回原始值。</p>
<p><code>setnx</code>命令首先测试关键字是否存在，只有当关键字不存在时才设置值</p>
<p>虽然这些都很有用，但在实际开发时，往往会需要运行具有原子性的一组命令。若要这样做，首先要执行<code>multi</code>命令，紧随其后的是所有你想要执行的命令（作为事务的一部分），最后执行<code>exec</code>命令去实际执行命令，或者使用<code>discard</code>命令放弃执行命令。Redis的事务功能保证了什么？</p>
<ul>
<li><p>事务中的命令将会按顺序地被执行</p>
</li>
<li><p>事务中的命令将会如单个原子操作般被执行（没有其它的客户端命令会在中途被执行）</p>
</li>
<li><p>事务中的命令要么全部被执行，要么不会执行</p>
</li>
</ul>
<p>你可以（也应该）在命令行界面对事务功能进行一下测试。还有一点要注意到，没有什么理由不能结合流水线功能和事务功能。</p>
<pre><code>multi
hincrby groups:1percent balance -9000000000
hincrby groups:99percent balance 9000000000
exec</code></pre>
<p>最后，Redis能让你指定一个关键字（或多个关键字），当关键字有改变时，可以查看或者有条件地应用一个事务。这是用于当你需要获取值，且待运行的命令基于那些值时，所有都在一个事务里。对于上面展示的代码，我们不能去实现自己的<code>incr</code>命令，因为一旦<code>exec</code>命令被调用，他们会全部被执行在一块。我们不能这么做：</p>
<pre><code>redis.multi()
current = redis.get(&#39;powerlevel&#39;)
redis.set(&#39;powerlevel&#39;, current + 1)
redis.exec()</code></pre>
<p><strong>（译注：虽然Redis是单线程运行的，但是我们可以同时运行多个Redis客户端进程，常见的并发问题还是会出现。像上面的代码，在<code>get</code>运行之后，<code>set</code>运行之前，<code>powerlevel</code>的值可能会被另一个Redis客户端给改变，从而造成错误。）</strong></p>
<p>这些不是Redis的事务功能的工作。但是，如果我们增加一个<code>watch</code>到<code>powerlevel</code>，我们可以这样做：</p>
<pre><code>redis.watch(&#39;powerlevel&#39;)
current = redis.get(&#39;powerlevel&#39;)
redis.multi()
redis.set(&#39;powerlevel&#39;, current + 1)
redis.exec()</code></pre>
<p>在我们调用<code>watch</code>后，如果另一个客户端改变了<code>powerlevel</code>的值，我们的事务将会运行失败。如果没有客户端改变<code>powerlevel</code>的值，那么事务会继续工作。我们可以在一个循环里运行这些代码，直到其能正常工作。</p>
<h3 id="关键字反模式（Keys-Anti-Pattern）"><a href="#关键字反模式（Keys-Anti-Pattern）" class="headerlink" title="关键字反模式（Keys Anti-Pattern）"></a>关键字反模式（Keys Anti-Pattern）</h3><p>在下一章中，我们将会谈论那些没有确切关联到数据结构的命令，其中的一些是管理或调试工具。然而有一个命令我想特别地在这里进行谈论：<code>keys</code>命令。这个命令需要一个模式，然后查找所有匹配的关键字。这个命令看起来很适合一些任务，但这不应该用在实际的产品代码里。为什么？因为这个命令通过线性扫描所有的关键字来进行匹配。或者，简单地说，这个命令太慢了。</p>
<p>人们会如此去使用这个命令？一般会用来构建一个本地的Bug追踪服务。每一个帐号都有一个<code>id</code>，你可能会通过一个看起来像<code>bug:account_id:bug_id</code>的关键字，把每一个Bug存储到一个字符串数据结构值中去。如果你在任何时候需要查询一个帐号的Bug（显示它们，或者当用户删除了帐号时删除掉这些Bugs），你可能会尝试去使用<code>keys</code>命令：</p>
<pre><code>keys bug:1233:*</code></pre>
<p>更好的解决方法应该使用一个散列数据结构，就像我们可以使用散列数据结构来提供一种方法去展示二级索引，因此我们可以使用域来组织数据：</p>
<pre><code>hset bugs:1233 1 &quot;&#123;id:1, account: 1233, subject: &#39;...&#39;&#125;&quot;
hset bugs:1233 2 &quot;&#123;id:2, account: 1233, subject: &#39;...&#39;&#125;&quot;</code></pre>
<p>从一个帐号里获取所有的Bug标识，可以简单地调用<code>hkeys bugs:1233</code>。去删除一个指定的Bug，可以调用<code>hdel bugs:1233 2</code>。如果要删除了一个帐号，可以通过<code>del bugs:1233</code>把关键字删除掉。</p>
<h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><p>结合这一章以及前一章，希望能让你得到一些洞察力，了解如何使用Redis去支持（Power）实际项目。还有其他的模式可以让你去构建各种类型的东西，但真正的关键是要理解基本的数据结构。你将能领悟到，这些数据结构是如何能够实现你最初视角之外的东西。</p>
<h2 id="第4章-超越数据结构"><a href="#第4章-超越数据结构" class="headerlink" title="第4章 超越数据结构"></a>第4章 超越数据结构</h2><p>5种数据结构组成了Redis的基础，其他没有关联特定数据结构的命令也有很多。我们已经看过一些这样的命令：<code>info</code>, <code>select</code>, <code>flushdb</code>, <code>multi</code>, <code>exec</code>, <code>discard</code>, <code>watch</code>和<code>keys </code>。这一章将看看其他的一些重要命令。</p>
<h3 id="使用期限（Expiration）"><a href="#使用期限（Expiration）" class="headerlink" title="使用期限（Expiration）"></a>使用期限（Expiration）</h3><p>Redis允许你标记一个关键字的使用期限。你可以给予一个Unix时间戳形式（自1970年1月1日起）的绝对时间，或者一个基于秒的存活时间。这是一个基于关键字的命令，因此其不在乎关键字表示的是哪种类型的数据结构。</p>
<pre><code>expire pages:about 30
expireat pages:about 1356933600</code></pre>
<p>第一个命令将会在30秒后删除掉关键字（包括其关联的值）。第二个命令则会在2012年12月31日上午12点删除掉关键字。</p>
<p>这让Redis能成为一个理想的缓冲引擎。通过<code>ttl</code>命令，你可以知道一个关键字还能够存活多久。而通过<code>persist</code>命令，你可以把一个关键字的使用期限删除掉。</p>
<pre><code>ttl pages:about
persist pages:about</code></pre>
<p>最后，有个特殊的字符串命令，<code>setex</code>命令让你可以在一个单独的原子命令里设置一个字符串值，同时里指定一个生存期（这比任何事情都要方便）。</p>
<pre><code>setex pages:about 30 &#39;&lt;h1&gt;about us&lt;/h1&gt;....&#39;</code></pre>
<h3 id="发布和订阅（Publication-and-Subscriptions）"><a href="#发布和订阅（Publication-and-Subscriptions）" class="headerlink" title="发布和订阅（Publication and Subscriptions）"></a>发布和订阅（Publication and Subscriptions）</h3><p>Redis的列表数据结构有<code>blpop</code>和<code>brpop</code>命令，能从列表里返回且删除第一个（或最后一个）元素，或者被堵塞，直到有一个元素可供操作。这可以用来实现一个简单的队列。</p>
<p><strong>（译注：对于<code>blpop</code>和<code>brpop</code>命令，如果列表里没有关键字可供操作，连接将被堵塞，直到有另外的Redis客户端使用<code>lpush</code>或<code>rpush</code>命令推入关键字为止。）</strong></p>
<p>此外，Redis对于消息发布和频道订阅有着一流的支持。你可以打开第二个<code>redis-cli</code>窗口，去尝试一下这些功能。在第一个窗口里订阅一个频道（我们会称它为<code>warnings</code>）：</p>
<pre><code>subscribe warnings</code></pre>
<p>其将会答复你订阅的信息。现在，在另一个窗口，发布一条消息到<code>warnings</code>频道：</p>
<pre><code>publish warnings &quot;it&#39;s over 9000!&quot;</code></pre>
<p>如果你回到第一个窗口，你应该已经接收到<code>warnings</code>频道发来的消息。</p>
<p>你可以订阅多个频道（<code>subscribe channel1 channel2 ...</code>），订阅一组基于模式的频道（<code>psubscribe warnings:*</code>），以及使用<code>unsubscribe</code>和<code>punsubscribe</code>命令停止监听一个或多个频道，或一个频道模式。</p>
<p>最后，可以注意到<code>publish</code>命令的返回值是1，这指出了接收到消息的客户端数量。</p>
<h3 id="监控和延迟日志（Monitor-and-Slow-Log）"><a href="#监控和延迟日志（Monitor-and-Slow-Log）" class="headerlink" title="监控和延迟日志（Monitor and Slow Log）"></a>监控和延迟日志（Monitor and Slow Log）</h3><p><code>monitor</code>命令可以让你查看Redis正在做什么。这是一个优秀的调试工具，能让你了解你的程序如何与Redis进行交互。在两个<code>redis-cli</code>窗口中选一个（如果其中一个还处于订阅状态，你可以使用<code>unsubscribe</code>命令退订，或者直接关掉窗口再重新打开一个新窗口）键入<code>monitor</code>命令。在另一个窗口，执行任何其他类型的命令（例如<code>get</code>或<code>set</code>命令）。在第一个窗口里，你应该可以看到这些命令，包括他们的参数。</p>
<p>在实际生产环境里，你应该谨慎运行<code>monitor</code>命令，这真的仅仅就是一个很有用的调试和开发工具。除此之外，没有更多要说的了。</p>
<p>随同<code>monitor</code>命令一起，Redis拥有一个<code>slowlog</code>命令，这是一个优秀的性能剖析工具。其会记录执行时间超过一定数量<strong>微秒</strong>的命令。在下一章节，我们会简略地涉及如何配置Redis，现在你可以按下面的输入配置Redis去记录所有的命令：</p>
<pre><code>config set slowlog-log-slower-than 0</code></pre>
<p>然后，执行一些命令。最后，你可以检索到所有日志，或者检索最近的那些日志：</p>
<pre><code>slowlog get
slowlog get 10</code></pre>
<p>通过键入<code>slowlog len</code>，你可以获取延迟日志里的日志数量。</p>
<p>对于每个被你键入的命令，你应该查看4个参数：</p>
<ul>
<li><p>一个自动递增的id</p>
</li>
<li><p>一个Unix时间戳，表示命令开始运行的时间</p>
</li>
<li><p>一个微妙级的时间，显示命令运行的总时间</p>
</li>
<li><p>该命令以及所带参数</p>
</li>
</ul>
<p>延迟日志保存在存储器中，因此在生产环境中运行（即使有一个低阀值）也应该不是一个问题。默认情况下，它将会追踪最近的1024个日志。</p>
<h3 id="排序（Sort）"><a href="#排序（Sort）" class="headerlink" title="排序（Sort）"></a>排序（Sort）</h3><p><code>sort</code>命令是Redis最强大的命令之一。它让你可以在一个列表、集合或者分类集合里对值进行排序（分类集合是通过标记来进行排序，而不是集合里的成员）。下面是一个<code>sort</code>命令的简单用例：</p>
<pre><code>rpush users:leto:guesses 5 9 10 2 4 10 19 2
sort users:leto:guesses</code></pre>
<p>这将返回进行升序排序后的值。这里有一个更高级的例子：</p>
<pre><code>sadd friends:ghanima leto paul chani jessica alia duncan
sort friends:ghanima limit 0 3 desc alpha</code></pre>
<p>上面的命令向我们展示了，如何对已排序的记录进行分页（通过<code>limit</code>），如何返回降序排序的结果（通过<code>desc</code>），以及如何用字典序排序代替数值序排序（通过<code>alpha</code>）。</p>
<p><code>sort</code>命令的真正力量是其基于引用对象来进行排序的能力。早先的时候，我们说明了列表、集合和分类集合很常被用于引用其他的Redis对象，<code>sort</code>命令能够解引用这些关系，而且通过潜在值来进行排序。例如，假设我们有一个Bug追踪器能让用户看到各类已存在问题。我们可能使用一个集合数据结构去追踪正在被监视的问题：</p>
<pre><code>sadd watch:leto 12339 1382 338 9338</code></pre>
<p>你可能会有强烈的感觉，想要通过id来排序这些问题（默认的排序就是这样的），但是，我们更可能是通过问题的严重性来对这些问题进行排序。为此，我们要告诉Redis将使用什么模式来进行排序。首先，为了可以看到一个有意义的结果，让我们添加多一点数据：</p>
<pre><code>set severity:12339 3
set severity:1382 2
set severity:338 5
set severity:9338 4</code></pre>
<p>要通过问题的严重性来降序排序这些Bug，你可以这样做：</p>
<pre><code>sort watch:leto by severity:* desc</code></pre>
<p>Redis将会用存储在列表（集合或分类集合）中的值去替代模式中的<code>*</code>（通过<code>by</code>）。这会创建出关键字名字，Redis将通过查询其实际值来排序。</p>
<p>在Redis里，虽然你可以有成千上万个关键字，类似上面展示的关系还是会引起一些混乱。幸好，<code>sort</code>命令也可以工作在散列数据结构及其相关域里。相对于拥有大量的高层次关键字，你可以利用散列：</p>
<pre><code>hset bug:12339 severity 3
hset bug:12339 priority 1
hset bug:12339 details &quot;&#123;id: 12339, ....&#125;&quot;

hset bug:1382 severity 2
hset bug:1382 priority 2
hset bug:1382 details &quot;&#123;id: 1382, ....&#125;&quot;

hset bug:338 severity 5
hset bug:338 priority 3
hset bug:338 details &quot;&#123;id: 338, ....&#125;&quot;

hset bug:9338 severity 4
hset bug:9338 priority 2
hset bug:9338 details &quot;&#123;id: 9338, ....&#125;&quot;</code></pre>
<p>所有的事情不仅变得更为容易管理，而且我们能通过<code>severity</code>或<code>priority</code>来进行排序，还可以告诉<code>sort</code>命令具体要检索出哪一个域的数据：</p>
<pre><code>sort watch:leto by bug:*-&gt;priority get bug:*-&gt;details</code></pre>
<p>相同的值替代出现了，但Redis还能识别<code>-&gt;</code>符号，用它来查看散列中指定的域。里面还包括了<code>get</code>参数，这里也会进行值替代和域查看，从而检索出Bug的细节（details域的数据）。</p>
<p>对于太大的集合，<code>sort</code>命令的执行可能会变得很慢。好消息是，<code>sort</code>命令的输出可以被存储起来：</p>
<pre><code>sort watch:leto by bug:*-&gt;priority get bug:*-&gt;details store watch_by_priority:leto</code></pre>
<p>使用我们已经看过的<code>expiration</code>命令，再结合<code>sort</code>命令的<code>store</code>能力，这是一个美妙的组合。</p>
<h3 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h3><p>这一章主要关注那些非特定数据结构关联的命令。和其他事情一样，它们的使用依情况而定。构建一个程序或特性时，可能不会用到使用期限、发布和订阅或者排序等功能。但知道这些功能的存在是很好的。而且，我们也只接触到了一些命令。还有更多的命令，当你消化理解完这本书后，非常值得去浏览一下<a href="http://redis.io/commands">完整的命令列表</a>。</p>
<h2 id="第5章-管理"><a href="#第5章-管理" class="headerlink" title="第5章 - 管理"></a>第5章 - 管理</h2><p>在最后一章里，我们将集中谈论Redis运行中的一些管理方面内容。这是一个不完整的Redis管理指南，我们将会回答一些基本的问题，初接触Redis的新用户可能会很感兴趣。</p>
<h3 id="配置（Configuration）"><a href="#配置（Configuration）" class="headerlink" title="配置（Configuration）"></a>配置（Configuration）</h3><p>当你第一次运行Redis的服务器，它会向你显示一个警告，指<code>redis.conf</code>文件没有被找到。这个文件可以被用来配置Redis的各个方面。一个充分定义（well-documented）的<code>redis.conf</code>文件对各个版本的Redis都有效。范例文件包含了默认的配置选项，因此，对于想要了解设置在干什么，或默认设置是什么，都会很有用。你可以在<a href="https://github.com/antirez/redis/raw/2.4.6/redis.conf">https://github.com/antirez/redis/raw/2.4.6/redis.conf</a>找到这个文件。</p>
<p><strong>这个配置文件针对的是Redis 2.4.6，你应该用你的版本号替代上面URL里的”2.4.6”。运行<code>info</code>命令，其显示的第一个值就是Redis的版本号。</strong></p>
<p>因为这个文件已经是充分定义（well-documented），我们就不去再进行设置了。</p>
<p>除了通过<code>redis.conf</code>文件来配置Redis，<code>config set</code>命令可以用来对个别值进行设置。实际上，在将<code>slowlog-log-slower-than</code>设置为0时，我们就已经使用过这个命令了。</p>
<p>还有一个<code>config get</code>命令能显示一个设置值。这个命令支持模式匹配，因此如果我们想要显示关联于日志（logging）的所有设置，我们可以这样做：</p>
<pre><code>config get *log*</code></pre>
<h3 id="验证（Authentication）"><a href="#验证（Authentication）" class="headerlink" title="验证（Authentication）"></a>验证（Authentication）</h3><p>通过设置<code>requirepass</code>（使用<code>config set</code>命令或<code>redis.conf</code>文件），可以让Redis需要一个密码验证。当<code>requirepass</code>被设置了一个值（就是待用的密码），客户端将需要执行一个<code>auth password</code>命令。</p>
<p>一旦一个客户端通过了验证，就可以在任意数据库里执行任何一条命令，包括<code>flushall</code>命令，这将会清除掉每一个数据库里的所有关键字。通过配置，你可以重命名一些重要命令为混乱的字符串，从而获得一些安全性。</p>
<pre><code>rename-command CONFIG 5ec4db169f9d4dddacbfb0c26ea7e5ef
rename-command FLUSHALL 1041285018a942a4922cbf76623b741e</code></pre>
<p>或者，你可以将新名字设置为一个空字符串，从而禁用掉一个命令。</p>
<h3 id="大小限制（Size-Limitations）"><a href="#大小限制（Size-Limitations）" class="headerlink" title="大小限制（Size Limitations）"></a>大小限制（Size Limitations）</h3><p>当你开始使用Redis，你可能会想知道，我能使用多少个关键字？还可能想知道，一个散列数据结构能有多少个域（尤其是当你用它来组织数据时），或者是，一个列表数据结构或集合数据结构能有多少个元素？对于每一个实例，实际限制都能达到亿万级别（hundreds of millions）。</p>
<h3 id="复制（Replication）"><a href="#复制（Replication）" class="headerlink" title="复制（Replication）"></a>复制（Replication）</h3><p>Redis支持复制功能，这意味着当你向一个Redis实例（Master）进行写入时，一个或多个其他实例（Slaves）能通过Master实例来保持更新。可以在配置文件里设置<code>slaveof</code>，或使用<code>slaveof</code>命令来配置一个Slave实例。对于那些没有进行这些设置的Redis实例，就可能一个Master实例。</p>
<p>为了更好保护你的数据，复制功能拷贝数据到不同的服务器。复制功能还能用于改善性能，因为读取请求可以被发送到Slave实例。他们可能会返回一些稍微滞后的数据，但对于大多数程序来说，这是一个值得做的折衷。</p>
<p>遗憾的是，Redis的复制功能还没有提供自动故障恢复。如果Master实例崩溃了，一个Slave实例需要手动的进行升级。如果你想使用Redis去达到某种高可用性，对于使用心跳监控（heartbeat monitoring）和脚本自动开关（scripts to automate the switch）的传统高可用性工具来说，现在还是一个棘手的难题。</p>
<h3 id="备份文件（Backups）"><a href="#备份文件（Backups）" class="headerlink" title="备份文件（Backups）"></a>备份文件（Backups）</h3><p>备份Redis非常简单，你可以将Redis的快照（snapshot）拷贝到任何地方，包括S3、FTP等。默认情况下，Redis会把快照存储为一个名为<code>dump.rdb</code>的文件。在任何时候，你都可以对这个文件执行<code>scp</code>、<code>ftp</code>或<code>cp</code>等常用命令。</p>
<p>有一种常见情况，在Master实例上会停用快照以及单一附加文件（aof），然后让一个Slave实例去处理备份事宜。这可以帮助减少Master实例的载荷。在不损害整体系统响应性的情况下，你还可以在Slave实例上设置更多主动存储的参数。</p>
<h3 id="缩放和Redis集群（Scaling-and-Redis-Cluster）"><a href="#缩放和Redis集群（Scaling-and-Redis-Cluster）" class="headerlink" title="缩放和Redis集群（Scaling and Redis Cluster）"></a>缩放和Redis集群（Scaling and Redis Cluster）</h3><p>复制功能（Replication）是一个成长中的网站可以利用的第一个工具。有一些命令会比另外一些来的昂贵（例如<code>sort</code>命令），将这些运行载荷转移到一个Slave实例里，可以保持整体系统对于查询的快速响应。</p>
<p>此外，通过分发你的关键字到多个Redis实例里，可以达到真正的缩放Redis（记住，Redis是单线程的，这些可以运行在同一个逻辑框里）。随着时间的推移，你将需要特别注意这些事情（尽管许多的Redis载体都提供了consistent-hashing算法）。对于数据水平分布（horizontal distribution）的考虑不在这本书所讨论的范围内。这些东西你也很可能不需要去担心，但是，无论你使用哪一种解决方案，有一些事情你还是必须意识到。</p>
<p>好消息是，这些工作都可在Redis集群下进行。不仅提供水平缩放（包括均衡），为了高可用性，还提供了自动故障恢复。</p>
<p>高可用性和缩放是可以达到的，只要你愿意为此付出时间和精力，Redis集群也使事情变得简单多了。</p>
<h3 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h3><p>在过去的一段时间里，已经有许多的计划和网站使用了Redis，毫无疑问，Redis已经可以应用于实际生产中了。然而，一些工具还是不够成熟，尤其是一些安全性和可用性相关的工具。对于Redis集群，我们希望很快就能看到其实现，这应该能为一些现有的管理挑战提供处理帮忙。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在许多方面，Redis体现了一种简易的数据处理方式，其剥离掉了大部分的复杂性和抽象，并可有效的在不同系统里运行。不少情况下，选择Redis不是最佳的选择。在另一些情况里，Redis就像是为你的数据提供了特别定制的解决方案。</p>
<p>最终，回到我最开始所说的：Redis很容易学习。现在有许多的新技术，很难弄清楚哪些才真正值得我们花时间去学习。如果你从实际好处来考虑，Redis提供了他的简单性。我坚信，对于你和你的团队，学习Redis是最好的技术投资之一。</p>
<hr>
]]></content>
      <categories>
        <category>NOSQL</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>【转】基于协议和配置的优化</title>
    <url>/network/HTTPS/optimization/</url>
    <content><![CDATA[<p>RTT(Round-Trip Time): 往返时延。表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。</p>
<h2 id="HTTPS-访问速度优化"><a href="#HTTPS-访问速度优化" class="headerlink" title="HTTPS 访问速度优化"></a>HTTPS 访问速度优化</h2><h3 id="Tcp-fast-open"><a href="#Tcp-fast-open" class="headerlink" title="Tcp fast open"></a>Tcp fast open</h3><p>HTTPS 和 HTTP 使用 TCP 协议进行传输，也就意味着必须通过三次握手建立 TCP 连接，但一个 RTT 的时间内只传输一个 syn 包是不是太浪费？能不能在 syn 包发出的同时捎上应用层的数据？其实是可以的，这也是 tcp fast open 的思路，简称 TFO。具体原理可以参考 rfc7413。</p>
<p>遗憾的是 TFO 需要高版本内核的支持，linux 从 3.7 以后支持 TFO，但是目前的 windows 系统还不支持 TFO，所以只能在公司内部服务器之间发挥作用。</p>
<h3 id="HSTS"><a href="#HSTS" class="headerlink" title="HSTS"></a>HSTS</h3><p>前面提到过将用户 HTTP 请求 302 跳转到 HTTPS，这会有两个影响：</p>
<blockquote>
<p>1、不安全，302 跳转不仅暴露了用户的访问站点，也很容易被中间者支持。</p>
<p>2、降低访问速度，302 跳转不仅需要一个 RTT，浏览器执行跳转也需要执行时间。</p>
</blockquote>
<p>由于 302 跳转事实上是由浏览器触发的，服务器无法完全控制，这个需求导致了 HSTS 的诞生：</p>
<p>HSTS(HTTP Strict Transport Security)。服务端返回一个 HSTS 的 http header，浏览器获取到 HSTS 头部之后，在一段时间内，不管用户输入<a href="http://www.baidu.com还是http//www.baidu.com%EF%BC%8C%E9%83%BD%E4%BC%9A%E9%BB%98%E8%AE%A4%E5%B0%86%E8%AF%B7%E6%B1%82%E5%86%85%E9%83%A8%E8%B7%B3%E8%BD%AC%E6%88%90https://www.baidu.com%E3%80%82">www.baidu.com还是http://www.baidu.com，都会默认将请求内部跳转成https://www.baidu.com。</a></p>
<p>Chrome, firefox, ie 都支持了 HSTS（<a href="http://caniuse.com/#feat=stricttransportsecurity%EF%BC%89%E3%80%82">http://caniuse.com/#feat=stricttransportsecurity）。</a></p>
<h3 id="Session-resume"><a href="#Session-resume" class="headerlink" title="Session resume"></a>Session resume</h3><p>Session resume 顾名思义就是复用 session，实现简化握手。复用 session 的好处有两个：</p>
<blockquote>
<p>1、减少了 CPU 消耗，因为不需要进行非对称密钥交换的计算。</p>
<p>2、提升访问速度，不需要进行完全握手阶段二，节省了一个 RTT 和计算耗时。</p>
</blockquote>
<p>TLS 协议目前提供两种机制实现 session resume，分别介绍一下。</p>
<h4 id="Session-cache"><a href="#Session-cache" class="headerlink" title="Session cache"></a>Session cache</h4><p>Session cache 的原理是使用 client hello 中的 session id 查询服务端的 session cache, 如果服务端有对应的缓存，则直接使用已有的 session 信息提前完成握手，称为简化握手。</p>
<p>Session cache 有两个缺点：</p>
<blockquote>
<p>1、需要消耗服务端内存来存储 session 内容。</p>
<p>2、目前的开源软件包括 nginx,apache 只支持单机多进程间共享缓存，不支持多机间分布式缓存，对于百度或者其他大型互联网公司而言，单机 session cache 几乎没有作用。</p>
</blockquote>
<p>Session cache 也有一个非常大的优点：</p>
<blockquote>
<p>session id 是 TLS 协议的标准字段，市面上的浏览器全部都支持 session cache。</p>
</blockquote>
<p>百度通过对 TLS 握手协议及服务器端实现的优化，已经支持全局的 session cache，能够明显提升用户的访问速度，节省服务器计算资源。</p>
<h4 id="Session-ticket"><a href="#Session-ticket" class="headerlink" title="Session ticket"></a>Session ticket</h4><p>上节提到了 session cache 的两个缺点，session ticket 能够弥补这些不足。</p>
<p>Session ticket 的原理参考 RFC4507。简述如下：</p>
<blockquote>
<p>server 将 session 信息加密成 ticket 发送给浏览器，浏览器后续握手请求时会发送 ticket，server 端如果能成功解密和处理 ticket，就能完成简化握手。</p>
</blockquote>
<p>显然，session ticket 的优点是不需要服务端消耗大量资源来存储 session 内容。</p>
<p>Session ticket 的缺点：</p>
<blockquote>
<p>1、session ticket 只是 TLS 协议的一个扩展特性，目前的支持率不是很广泛，只有 60% 左右。</p>
<p>2、session ticket 需要维护一个全局的 key 来加解密，需要考虑 KEY 的安全性和部署效率。</p>
</blockquote>
<p>总体来讲，session ticket 的功能特性明显优于 session cache。希望客户端实现优先支持 session ticket。</p>
<h3 id="OCSP-stapling"><a href="#OCSP-stapling" class="headerlink" title="OCSP stapling"></a>OCSP stapling</h3><p>OCSP 全称在线证书状态检查协议 (rfc6960)，用来向 CA 站点查询证书状态，比如是否撤销。通常情况下，浏览器使用 OCSP 协议发起查询请求，CA 返回证书状态内容，然后浏览器接受证书是否可信的状态。</p>
<p>这个过程非常消耗时间，因为 CA 站点有可能在国外，网络不稳定，RTT 也比较大。那有没有办法不直接向 CA 站点请求 OCSP 内容呢？ocsp stapling 就能实现这个功能。</p>
<p>详细介绍参考 RFC6066 第 8 节。简述原理就是浏览器发起 client hello 时会携带一个 certificate status request 的扩展，服务端看到这个扩展后将 OCSP 内容直接返回给浏览器，完成证书状态检查。</p>
<p>由于浏览器不需要直接向 CA 站点查询证书状态，这个功能对访问速度的提升非常明显。</p>
<p>Nginx 目前已经支持这个 ocsp stapling file，只需要配置 ocsp stapling file 的指令就能开启这个功能：</p>
<blockquote>
<ul>
<li>ssl_stapling on;ssl_stapling_file ocsp.staple;</li>
</ul>
</blockquote>
<h3 id="False-start"><a href="#False-start" class="headerlink" title="False start"></a>False start</h3><p>通常情况下，应用层数据必须等完全握手全部结束之后才能传输。这个其实比较浪费时间，那能不能类似 TFO 一样，在完全握手的第二个阶段将应用数据一起发出来呢？google 提出了 false start 来实现这个功能。详细介绍参考<a href="https://tools.ietf.org/html/draft-bmoeller-tls-falsestart-00%E3%80%82">https://tools.ietf.org/html/draft-bmoeller-tls-falsestart-00。</a></p>
<p>简单概括 False start 的原理就是在 client_key_exchange 发出时将应用层数据一起发出来，能够节省一个 RTT。</p>
<p>False start 依赖于 PFS（perfect forward secrecy 完美前向加密），而 PFS 又依赖于 DHE 密钥交换系列算法（DHE_RSA, ECDHE_RSA, DHE_DSS, ECDHE_ECDSA），所以尽量优先支持 ECDHE 密钥交换算法实现 false start。</p>
<h3 id="使用-SPDY-或者-HTTP2"><a href="#使用-SPDY-或者-HTTP2" class="headerlink" title="使用 SPDY 或者 HTTP2"></a>使用 SPDY 或者 HTTP2</h3><p>SPDY 是 google 推出的优化 HTTP 传输效率的协议（<a href="https://www.chromium.org/spdy%EF%BC%89%EF%BC%8C%E5%AE%83%E5%9F%BA%E6%9C%AC%E4%B8%8A%E6%B2%BF%E7%94%A8%E4%BA%86">https://www.chromium.org/spdy），它基本上沿用了</a> HTTP 协议的语义, 但是通过使用帧控制实现了多个特性，显著提升了 HTTP 协议的传输效率。</p>
<p>SPDY 最大的特性就是多路复用，能将多个 HTTP 请求在同一个连接上一起发出去，不像目前的 HTTP 协议一样，只能串行地逐个发送请求。Pipeline 虽然支持多个请求一起发送，但是接收时依然得按照顺序接收，本质上无法解决并发的问题。</p>
<p>HTTP2 是 IETF 2015 年 2 月份通过的 HTTP 下一代协议，它以 SPDY 为原型，经过两年多的讨论和完善最终确定。</p>
<p>本文就不过多介绍 SPDY 和 HTTP2 的收益，需要说明两点：</p>
<blockquote>
<p>1、SPDY 和 HTTP2 目前的实现默认使用 HTTPS 协议。</p>
<p>2、SPDY 和 HTTP2 都支持现有的 HTTP 语义和 API，对 WEB 应用几乎是透明的。</p>
</blockquote>
<p>Google 宣布 chrome 浏览器 2016 年将放弃 SPDY 协议，全面支持 HTTP2，但是目前国内部分浏览器厂商进度非常慢，不仅不支持 HTTP2，连 SPDY 都没有支持过。</p>
<p>百度服务端和百度手机浏览器现在都已经支持 SPDY3.1 协议。</p>
<h2 id="HTTPS-计算性能优化"><a href="#HTTPS-计算性能优化" class="headerlink" title="HTTPS 计算性能优化"></a>HTTPS 计算性能优化</h2><h3 id="优先使用-ECC"><a href="#优先使用-ECC" class="headerlink" title="优先使用 ECC"></a>优先使用 ECC</h3><p>ECC 椭圆加密算术相比普通的离散对数计算速度性能要强很多。下表是 NIST 推荐的密钥长度对照表。</p>
<p><img src="http://upload.chinaz.com/2015/0505/1430805926143.png" alt="HTTPS HTTPS协议 https和http有什么区别 HTTPS证书申请"></p>
<p>表格 2 NIST 推荐使用的密钥长度</p>
<p>对于 RSA 算法来讲，目前至少使用 2048 位以上的密钥长度才能保证安全性。ECC 只需要使用 224 位长度的密钥就能实现 RSA2048 位长度的安全强度。在进行相同的模指数运算时速度显然要快很多。</p>
<h3 id="使用最新版的-openssl"><a href="#使用最新版的-openssl" class="headerlink" title="使用最新版的 openssl"></a>使用最新版的 openssl</h3><p>一般来讲，新版的 openssl 相比老版的计算速度和安全性都会有提升。比如 openssl1.0.2 采用了 intel 最新的优化成果，椭圆曲线 p256 的计算性能提升了 4 倍。(<a href="https://eprint.iacr.org/2013/816.pdf">https://eprint.iacr.org/2013/816.pdf</a>)</p>
<p>Openssl 2014 年就升级了 5 次，基本都是为了修复实现上的 BUG 或者算法上的漏洞而升级的。所以尽量使用最新版本，避免安全上的风险。</p>
<h3 id="硬件加速方案"><a href="#硬件加速方案" class="headerlink" title="硬件加速方案"></a>硬件加速方案</h3><p>现在比较常用的 TLS 硬件加速方案主要有两种：</p>
<blockquote>
<p>1、SSL 专用加速卡。</p>
<p>2、GPU SSL 加速。</p>
</blockquote>
<p>上述两个方案的主流用法都是将硬件插入到服务器的 PCI 插槽中，由硬件完成最消耗性能的计算。但这样的方案有如下缺点：</p>
<p>1、支持算法有限。比如不支持 ECC，不支持 GCM 等。</p>
<p>2、升级成本高。</p>
<blockquote>
<p>a)  出现新的加密算法或者协议时，硬件加速方案无法及时升级。</p>
<p>b)  出现比较大的安全漏洞时，部分硬件方案在无法在短期内升级解决。比如 2014 年暴露的 heartbleed 漏洞。</p>
</blockquote>
<p>3、无法充分利用硬件加速性能。硬件加速程序一般都运行在内核态，计算结果传递到应用层需要 IO 和内存拷贝开销，即使硬件计算性能非常好，上层的同步等待和 IO 开销也会导致整体性能达不到预期，无法充分利用硬件加速卡的计算能力。</p>
<p>4、维护性差。硬件驱动及应用层 API 大部分是由安全厂家提供，出现问题后还需要厂家跟进。用户无法掌握核心代码，比较被动。不像开源的 openssl，不管算法还是协议，用户都能掌握。</p>
<h3 id="TLS-远程代理计算"><a href="#TLS-远程代理计算" class="headerlink" title="TLS 远程代理计算"></a>TLS 远程代理计算</h3><p>也正是因为上述原因，百度实现了专用的 SSL 硬件加速集群。基本思路是：</p>
<p>1、优化 TLS 协议栈，剥离最消耗 CPU 资源的计算，主要有如下部分：</p>
<blockquote>
<p>a)  RSA 中的加解密计算。</p>
<p>b)  ECC 算法中的公私钥生成。</p>
<p>c)  ECC 算法中的共享密钥生成。</p>
</blockquote>
<p>2、优化硬件计算部分。硬件计算不涉及协议及状态交互，只需要处理大数运算。</p>
<p>3、Web server 到 TLS 计算集群之间的任务是异步的。即 web server 将待计算内容发送给加速集群后，依然可以继续处理其他请求，整个过程是异步非阻塞的。</p>
<h2 id="HTTPS-安全配置"><a href="#HTTPS-安全配置" class="headerlink" title="HTTPS 安全配置"></a>HTTPS 安全配置</h2><h3 id="协议版本选择"><a href="#协议版本选择" class="headerlink" title="协议版本选择"></a>协议版本选择</h3><p>SSL2.0 早就被证明是不安全的协议了，统计发现目前已经没有客户端支持 SSL2.0，所以可以放心地在服务端禁用 SSL2.0 协议。</p>
<p>2014 年爆发了 POODLE 攻击，SSL3.0 因此被证明是不安全的。但是统计发现依然有 0.5% 的流量只支持 SSL3.0。所以只能有选择地支持 SSL3.0。</p>
<p>TLS1.1 及 1.2 目前为止没有发现安全漏洞，建议优先支持。</p>
<h3 id="加密套件选择"><a href="#加密套件选择" class="headerlink" title="加密套件选择"></a>加密套件选择</h3><p>加密套件包含四个部分：</p>
<blockquote>
<p>1、非对称密钥交换算法。建议优先使用 ECDHE，禁用 DHE，次优先选择 RSA。</p>
<p>2、证书签名算法。由于部分浏览器及操作系统不支持 ECDSA 签名，目前默认都是使用 RSA 签名，其中 SHA1 签名已经不再安全，chrome 及微软 2016 年开始不再支持 SHA1 签名的证书 (<a href="http://googleonlinesecurity.blogspot.jp/2014/09/gradually-sunsetting-sha-1.html)%E3%80%82">http://googleonlinesecurity.blogspot.jp/2014/09/gradually-sunsetting-sha-1.html)。</a></p>
<p>3、对称加解密算法。优先使用 AES-GCM 算法，针对 1.0 以上协议禁用 RC4（ rfc7465）。</p>
<p>4、内容一致性校验算法。Md5 和 sha1 都已经不安全，建议使用 sha2 以上的安全哈希函数。</p>
</blockquote>
<h2 id="HTTPS-防攻击"><a href="#HTTPS-防攻击" class="headerlink" title="HTTPS 防攻击"></a>HTTPS 防攻击</h2><h3 id="防止协议降级攻击"><a href="#防止协议降级攻击" class="headerlink" title="防止协议降级攻击"></a>防止协议降级攻击</h3><p>降级攻击一般包括两种：加密套件降级攻击 (cipher suite rollback) 和协议降级攻击（version roll back）。降级攻击的原理就是攻击者伪造或者修改 client hello 消息，使得客户端和服务器之间使用比较弱的加密套件或者协议完成通信。</p>
<p>为了应对降级攻击，现在 server 端和浏览器之间都实现了 SCSV 功能，原理参考<a href="https://tools.ietf.org/html/draft-ietf-tls-downgrade-scsv-00%E3%80%82">https://tools.ietf.org/html/draft-ietf-tls-downgrade-scsv-00。</a></p>
<p>一句话解释就是如果客户端想要降级，必须发送 TLS_SCSV 的信号，服务器如果看到 TLS_SCSV，就不会接受比服务端最高协议版本低的协议。</p>
<h3 id="防止重新协商攻击"><a href="#防止重新协商攻击" class="headerlink" title="防止重新协商攻击"></a>防止重新协商攻击</h3><p>重新协商（tls renegotiation）分为两种：加密套件重协商 (cipher suite renegotiation) 和协议重协商（protocol renegotiation）。</p>
<p>重新协商会有两个隐患：</p>
<blockquote>
<p>1、重协商后使用弱的安全算法。这样的后果就是传输内容很容易泄露。</p>
<p>2、重协商过程中不断发起完全握手请求，触发服务端进行高强度计算并引发服务拒绝。</p>
</blockquote>
<p>对于重协商，最直接的保护手段就是禁止客户端主动重协商，当然出于特殊场景的需求，应该允许服务端主动发起重协商。</p>
<p><strong>结束语</strong></p>
<p>HTTPS 的实践和优化涉及到了非常多的知识点，由于篇幅关系，本文对很多优化策略只是简单介绍了一下. 如果想要了解协议背后的原理，还是需要详细阅读 TLS 协议及 PKI 知识。对于大型站点来说，如果希望做到极致，HTTPS 的部署需要结合产品和基础设施的架构来进行详细的考虑，比起部署支持 HTTPS 的接入和对它的优化，在产品和运维层面上花费的功夫会更多</p>
<hr>
<p>【参考文献】:</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>The Little MongoDB Book</title>
    <url>/database/mongodb/the-little-mongodb-book/</url>
    <content><![CDATA[<p><img src="/images/NOSQL/mongodb/mongodb-the-little-mongodb-book.png"></p>
<h1 id="关于本书"><a href="#关于本书" class="headerlink" title="关于本书"></a>关于本书</h1><h2 id="许可"><a href="#许可" class="headerlink" title="许可"></a>许可</h2><p>本书《 The Little MongoDB Book 》基于 Attribution-NonCommercial 3.0 Unported license. <strong>你无须为本书付款。</strong></p>
<p>你可以自由的复制，分发，修改和传阅本书。但请认可该书属于作者 Karl Seguin，并请勿将本书用于任何商业目的。</p>
<p>你可以在以下链接查看完整的许可文档:</p>
<p><a href="http://creativecommons.org/licenses/by-nc/3.0/legalcode">http://creativecommons.org/licenses/by-nc/3.0/legalcode</a></p>
<h2 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h2><p>Karl Seguin 在多领域有着丰富经验，他是 .NET 和 Ruby 的开发专家。他也参与贡献 OSS 项目, 还是技术文档撰写人而且偶尔做做演讲。MongoDB 方面，他是 C# MongoDB 库 NoRM 的核心开发者，写有互动入门教程 <a href="http://openmymind.net/mongly/">mongly</a> 和 <a href="https://github.com/karlseguin/Mongo-Web-Admin">Mongo Web Admin</a>。他用 MongoDB，为休闲游戏开发者写了一个免费服务, <a href="http://mogade.com/">mogade.com</a>。</p>
<p>Karl 还编写了 <a href="http://openmymind.net/2012/1/23/The-Little-Redis-Book/">The Little Redis Book</a> <em>1</em></p>
<p>你可以在 <a href="http://openmymind.net/">http://openmymind.net</a> 找到他的 Blog，或者通过 <a href="http://twitter.com/karlseguin">@karlseguin</a> 在 Twitter 上关注他。</p>
<h2 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h2><p>特别感谢 <a href="http://twitter.com/perryneal">Perry Neal</a>, 赐予我你的视野，精神，和热情。你赐予了我无尽的力量。感恩。</p>
<h2 id="最新版本"><a href="#最新版本" class="headerlink" title="最新版本"></a>最新版本</h2><p>最新的版本由 Asya Kamsky 更新到了 MongoDB 2.6 。本书最新代码可以在这里获得:</p>
<p><a href="http://github.com/karlseguin/the-little-mongodb-book">http://github.com/karlseguin/the-little-mongodb-book</a>.</p>
<h3 id="中文版本"><a href="#中文版本" class="headerlink" title="中文版本"></a>中文版本</h3><p>Karl 在 <a href="https://github.com/karlseguin/the-little-mongodb-book">the-little-mongodb-book</a> 的 Github 链接中给出了 <a href="https://github.com/justinyhuang">justinyhuang</a> 的 <a href="https://github.com/justinyhuang/the-little-mongodb-book-cn">the-little-mongodb-book-cn</a> 链接。但貌似 justinyhuang 并没有同步更新到 MongoDB 2.6 。内容上也和原文稍微有点出入，并且由于本人水平有限，无法提交自信正确的内容。因此重开一项目。如果你被搜索引擎引导到本工程，在此向你致歉，并希望有能力者且有时间者一同完善和同步本工程。你可以通过我的 邮箱 <a href="mailto:&#103;&#x65;&#109;&#x69;&#110;&#105;&#x79;&#x65;&#x6c;&#108;&#111;&#119;&#x40;&#103;&#109;&#97;&#105;&#x6c;&#46;&#x63;&#111;&#109;">&#103;&#x65;&#109;&#x69;&#110;&#105;&#x79;&#x65;&#x6c;&#108;&#111;&#119;&#x40;&#103;&#109;&#97;&#105;&#x6c;&#46;&#x63;&#111;&#109;</a> 来联系我，或者通过 <a href="https://twitter.com/geminiyellow">@geminiyellow</a> 在 Twitter 上关注我。</p>
<p>最新中文版本基于 <a href="https://github.com/asya999">asya999</a> 在 May 29, 2014 提交的 <a href="https://github.com/karlseguin/the-little-mongodb-book/pull/38">#38</a> SHA 是：6d4dce8ead6a767e1e8de1b59f714510d36d366f</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote>
<p>这章那么短不是我的错，MongoDB 就真的很易学。</p>
</blockquote>
<p>都说技术在飞速发展。确实，有接连不断的新技术新方法出现。但是，我一直认为，程序员用到的基础技术的发展却是相当缓慢的。你可以好几年不学习但还能混得下去。令人惊讶的其实是成熟技术的被替换速度。就像在一夜之间，那些长期稳定成熟的技术发现它们不再被开发者关注。</p>
<p>最好的例子就是 NoSQL 技术的发展，以及它对稳定的关系型数据库市场的蚕食。看起来就像，昨天网络还是由 RDBMS 们来驱动的，而今天，就冒出五种左右的 NoSQL 解决案已经证明了它们都是值得拥有的。</p>
<p>虽然这些转变看起来都是一夜之间发生的，实际上他们他们可能花了数年的时间来取得公众的认可。最开始是由一小波开发者和公司在推动。解决方案被不断细化，吸取教训，然后一个新技术就这样诞生了，慢慢的后来者也开始了尝试。再次重申，NoSQL 的许多解决方案并不是为了取代传统的存储方案，而是解决一些特殊需求，填补了传统解决方案的一些空白。</p>
<p>说了那么多，我们第一件应该解决的事情是解释一下什么是 NoSQL。它是一个宽松的概念，不同的人有不同的见解。就个人而言，我通常认为它是数据存储系统的一部分。换而言之，NoSQL (重申, 就我而言)，的好处是让你的持久层不需要一个独立的系统。历史上，传统的关系数据库厂商尝试把他们的产品当作一揽子解决方案，NoSQL 倾向于扮演，在特定的工作中充当最好的工具这种角色。因此，你的 NoSQL 架构中还是可以用到关系型数据库，比如说 MySQL，但是可以也可以用 Redis 作为系统中某部分的持久层，或者是用到 Hadoop 来处理大数据。简而言之，NoSQL 就是需要用开放的可代替的意识，使用现有的或者未来的方式和工具来管理你的数据。</p>
<p>你会想知道，MongoDB 是不是适用于这一切。作为一个面向文档数据库，MongoDB 是最通用的 NoSQL 解决案。它可以看成是关系型数据库的代替方案。和关系型数据库一样，它也可以和其他的 NoSQL 解决案搭配在一起更好的工作。MongoDB 有优点也有缺点，我们将会在本书后面的章节中介绍。</p>
<h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><p>本书大部分内容将会专注于 MongoDB 的核心功能。我们会用到 MongoDB 的 shell。因为 shell 不但有助于学习，而且还是个很有用的管理工具。实际代码中你需要用到 MongoDB 驱动。</p>
<p>这也引出了关于 MongoDB 你所需要知道的第一件事: 它的驱动。MongoDB 有各种语言的 <a href="http://docs.mongodb.org/ecosystem/drivers/">官方驱动</a>。这些驱动可以认为是和你所熟悉的各种数据库驱动一样的东西。基于这些驱动，开发社区又创建了更多的语言/框架相关库。比如说，<a href="https://github.com/atheken/NoRM">NoRM</a> 是一个 C# 语言库，用 LINQ 实现,而 <a href="https://github.com/jnunemaker/mongomapper">MongoMapper</a> 是一个 Ruby 库，ActiveRecord-friendly。你可以选择直接对 MongoDB 核心进行开发，或选择高级库。之所以要指出，是因为许多新手都觉得迷惑，为什么这里有官方版本和社区版本 - 前者通常关心和 MongoDB 核心的通讯/连接，而后者有更多的语言和框架的实现。</p>
<p>说到这，我希望你可以在 MongoDB 环境中尝试一下我的例子，并且在尝试解决可能遇到的问题。MongoDB 很容易安装和运行，所以让我们花几分钟把所有的东西运行起来。</p>
<ol>
<li><p>先打开 <a href="http://www.mongodb.org/downloads">官方下载页面</a> ，从你选择的操作系统下面的第一行(推荐稳定版本)下载二进制文件。根据开发实际，你可以选择 32位 或者 64位。</p>
</li>
<li><p>解压缩文件 (随便你放哪) 然后进入 <code>bin</code> 子目录。现在还不要执行任何命令，只要记住 <code>mongod</code> 用来打开服务进程，<code>mongo</code> 打开客户端 shell - 大部分时间我们将要使用这两个命令。</p>
</li>
<li><p>在 <code>bin</code> 子目录下创建一个文本文件，命名为 <code>mongodb.config</code>。</p>
</li>
<li><p>在 mongodb.config 中添加一行: <code>dbpath=PATH_TO_WHERE_YOU_WANT_TO_STORE_YOUR_DATABASE_FILES</code>。比如，在 Windows 你可以写 <code>dbpath=c:\mongodb\data</code> ，在 Linux 可能是 <code>dbpath=/var/lib/mongodb/data</code>。</p>
</li>
<li><p>确保你指定的 <code>dbpath</code> 确实存在。</p>
</li>
<li><p>执行 mongod ，带上参数 <code>--config /path/to/your/mongodb.config</code> 。</p>
</li>
</ol>
<p>以 Windows 用户为例，如果你解压下载文档到 <code>c:\mongodb\</code> ，并且你创建了 <code>c:\mongodb\data\</code> ,那么在 <code>c:\mongodb\bin\mongodb.config</code> 你要指定 <code>dbpath=c:\mongodb\data\</code>。 然后你可以在 CMD 执行 <code>mongod</code> 如下命令行 <code>c:\mongodb\bin\mongod --config c:\mongodb\bin\mongodb.config</code>。</p>
<p>为省心你可以把 <code>bin</code> 文件夹路径添加到环境变量 PATH 中，可以简化命令。MacOSX 和 Linux 用户方法几乎一样。唯一需要改变的是路径。</p>
<p>希望你现在已经可以启动 MongoDB 了。如果出现异常，仔细阅读一下异常信息 - 服务器对异常的解释做得非常好。</p>
<p>现在你可以执行 <code>mongo</code> (没有 <em>d</em>) ，链接 shell 到你的服务器上了。尝试输入 <code>db.version()</code> 来确认所有都正确执行了。你应该能拿到一个已安装的版本号。</p>
<h1 id="第一章-基础知识"><a href="#第一章-基础知识" class="headerlink" title="第一章 - 基础知识"></a>第一章 - 基础知识</h1><p>我们通过学习 MongoDB 的基本工作原理，开始我们的 MongoDB 之旅。当然，这是学习 MongoDB 的核心，它也能帮助我们回答诸如，MongoDB 适用于哪些场景这些更高层次的问题。</p>
<p>开始之前，这有六个简单的概念我们需要了解一下。</p>
<ol>
<li><p>MongoDB中的 <code>database</code> 有着和你熟知的”数据库”一样的概念 (对 Oracle 来说就是 schema)。一个 MongoDB 实例中，可以有零个或多个数据库，每个都作为一个高等容器，用于存储数据。</p>
</li>
<li><p>数据库中可以有零个或多个 <code>collections</code> (集合)。集合和传统意义上的 <code>table</code> 基本一致，你可以简单的把两者看成是一样的东西。</p>
</li>
<li><p>集合是由零个或多个 <code>documents</code> (文档)组成。同样，一个文档可以看成是一 <code>row</code>。</p>
</li>
<li><p>文档是由零个或多个 <code>fields</code> (字段)组成。, 没错，它就是 <code>columns</code>。</p>
</li>
<li><p><code>Indexes</code> (索引)在 MongoDB 中扮演着和它们在 RDBMS 中一样的角色。</p>
</li>
<li><p><code>Cursors</code> (游标)和上面的五个概念都不一样，但是它非常重要，并且经常被忽视，因此我觉得它们值得单独讨论一下。其中最重要的你要理解的一点是，游标是，当你问 MongoDB 拿数据的时候，它会给你返回一个结果集的指针而不是真正的数据，这个指针我们叫它游标，我们可以拿游标做我们想做的任何事情，比如说计数或者跨行之类的，而无需把真正的数据拖下来，在真正的数据上操作。</p>
</li>
</ol>
<p>综上，MongoDB 是由包含 <code>collections</code> 的 <code>databases</code> 组成的。而 <code>collection</code> 是由 <code>documents</code>组成。每个 <code>document</code> 是由 <code>fields</code> 组成。 <code>Collections</code> 可以被 <code>indexed</code>，以便提高查找和排序的性能。最后，当我们从 MongoDB 获取数据的时候，我们通过 <code>cursor</code> 来操作，读操作会被延迟到需要实际数据的时候才会执行。</p>
<p>那为什么我们需要新的术语(collection vs. table, document vs. row and field vs. column)？为了让看起来更复杂点？事实上，虽然这些概念和关系型数据中的概念类似，但是还是有差异的。核心差异在于，关系型数据库是在 <code>table</code> 上定义的 <code>columns</code>，而面向文档数据库是在 <code>document</code> 上定义的 <code>fields</code>。也就是说，在 <code>collection</code> 中的每个 <code>document</code> 都可以有它自己独立的 <code>fields</code>。因此，对于 <code>collection</code> 来说是个简化了的 <code>table</code> ，但是一个 <code>document</code> 却比一 <code>row</code> 有更多的信息。</p>
<p>虽然这些概念很重要，但是如果现在搞不明白也不要紧。多插几条数据就明白上面说的到底是什么意思了。反正，要点就是，集合不对存储内容严格限制 (所谓的无模式(schema-less))。字段由每个独立的文档进行跟踪处理。这样做的优点和缺点将在下面章节一一讨论。</p>
<p>好了我们开始吧。如果你还没有运行 MongoDB，那么快去运行 <code>mongod</code> 服务和开启 mongo shell。shell 用的是 JavaScript。你可以试试一些全局命令，比如 <code>help</code> 或者 <code>exit</code>。如果要操作当前数据库，用 <code>db</code> ，比如 <code>db.help()</code> 或者 <code>db.stats()</code>。如果要操作指定集合，大多数情况下我们会操作集合而不是数据库，用 <code>db.COLLECTION_NAME</code> ，比如 <code>db.unicorns.help()</code> 或者 <code>db.unicorns.count()</code>。</p>
<p>我们继续，输入 <code>db.help()</code>，就能拿到一个对 <code>db</code> 能执行的所有的命令的列表。</p>
<p>顺便说一句:因为这是一个 JavaScript shell，如果你输入的命令漏了 <code>()</code>，你会看到这个命令的源码，而不是执行这个命令。我提一下，是为了避免你执行漏了括号的命令，拿到一个以 <code>function (...)&#123;</code> 开头的返回的时候，觉得神奇不可思议。比如说，如果你输入 <code>db.help</code> (不带括号), 你会看到 <code>help</code> 方法的内部实现。</p>
<p>首先我们用全局的 <code>use</code> 来切换数据库，继续，输入 <code>use learn</code>。这个数据库实际存在与否完全没有关系。我们在里面生成集合的时候， <code>learn</code> 数据库会自动建起来。现在，我们在一个数据库里面了，你可以开始尝试一下数据库命令，比如 <code>db.getCollectionNames()</code>。执行之后，你会得到一个空数组 (<code>[ ]</code>)。因为集合是无模式的，我们不需要特地去配置它。我们可以简单的插入一个文档到一个新的集合。像这样，我们用 <code>insert</code> 命令，在文档中插入:</p>
<pre><code>db.unicorns.insert(&#123;name: &#39;Aurora&#39;,
    gender: &#39;f&#39;, weight: 450&#125;)</code></pre>
<p>这行命令对集合 <code>unicorns</code> 执行了 <code>insert</code> 命令，并传入一个参数。MongoDB 内部用二进制序列化 JSON 格式，称为 BSON。外部，也就是说我们多数情况应该用 JSON，就像上面的参数一样。然后我们执行 <code>db.getCollectionNames()</code> ，我们将能拿到两个集合: <code>unicorns</code> 和 <code>system.indexes</code>。在每个数据库中都会有一个 <code>system.indexes</code> 集合，用来保存我们数据的的索引信息。</p>
<p>你现在可以对用 <code>unicorns</code> 执行 <code>find</code> 命令，然后返回文档列表:</p>
<pre><code>db.unicorns.find()</code></pre>
<p>请注意，除你指定的字段之外，会多出一个 <code>_id</code> 字段。每个文档都会有一个唯一 <code>_id</code> 字段。你可以自己生成一个，或者让 MongoDB 帮你生成一个 <code>ObjectId</code> 类型的。多数情况下，你会乐意让 MongoDB 帮你生成的。默认的 <code>_id</code> 字段是已被索引的 - 这就说明了为什么会有 <code>system.indexes</code> 集合。你可以看看 <code>system.indexes</code>:</p>
<pre><code>db.system.indexes.find()</code></pre>
<p>你可以看到索引的名字，被索引的数据库和集合，以及在索引中的字段。</p>
<p>现在，回到我们关于数组无模式的讨论中来。往 <code>unicorns</code> 插入一个完全不同的文档，比如:</p>
<pre><code>db.unicorns.insert(&#123;name: &#39;Leto&#39;,
    gender: &#39;m&#39;,
    home: &#39;Arrakeen&#39;,
    worm: false&#125;)</code></pre>
<p>然后，再用 <code>find</code> 列出文档。等我们理解再深入一点的时候，将会讨论一下 MongoDB 的有趣行为。到这里，我希望你开始理解，为什么那些传统的术语在这里不适用了。</p>
<h2 id="掌握选择器-Selector"><a href="#掌握选择器-Selector" class="headerlink" title="掌握选择器(Selector)"></a>掌握选择器(Selector)</h2><p>除了我们介绍过的六个概念，在开始讨论更深入的话题之前，MongoDB 还有一个应该掌握的实用概念:查询选择器。MongoDB 的查询选择器就像 SQL 语句里面的 <code>where</code> 一样。因此，你会在对集合的文档做查找，计数，更新，删除的时候用到它。选择器是一个 JSON 对象，最简单的是就是用 <code>&#123;&#125;</code> 匹配所有的文档。如果我们想找出所有母独角兽，我们可以用 <code>&#123;gender:&#39;f&#39;&#125;</code>。</p>
<p>开始深入学习选择器之前，让我们先做些准备。首先，把刚才我们插入 <code>unicorns</code> 集合的数据删除，通过: <code>db.unicorns.remove(&#123;&#125;)</code>。现在，再插入一些用来演示的数据 (你不会手打吧):</p>
<pre><code>db.unicorns.insert(&#123;name: &#39;Horny&#39;,
    dob: new Date(1992,2,13,7,47),
    loves: [&#39;carrot&#39;,&#39;papaya&#39;],
    weight: 600,
    gender: &#39;m&#39;,
    vampires: 63&#125;);
db.unicorns.insert(&#123;name: &#39;Aurora&#39;,
    dob: new Date(1991, 0, 24, 13, 0),
    loves: [&#39;carrot&#39;, &#39;grape&#39;],
    weight: 450,
    gender: &#39;f&#39;,
    vampires: 43&#125;);
db.unicorns.insert(&#123;name: &#39;Unicrom&#39;,
    dob: new Date(1973, 1, 9, 22, 10),
    loves: [&#39;energon&#39;, &#39;redbull&#39;],
    weight: 984,
    gender: &#39;m&#39;,
    vampires: 182&#125;);
db.unicorns.insert(&#123;name: &#39;Roooooodles&#39;,
    dob: new Date(1979, 7, 18, 18, 44),
    loves: [&#39;apple&#39;],
    weight: 575,
    gender: &#39;m&#39;,
    vampires: 99&#125;);
db.unicorns.insert(&#123;name: &#39;Solnara&#39;,
    dob: new Date(1985, 6, 4, 2, 1),
    loves:[&#39;apple&#39;, &#39;carrot&#39;,
        &#39;chocolate&#39;],
    weight:550,
    gender:&#39;f&#39;,
    vampires:80&#125;);
db.unicorns.insert(&#123;name:&#39;Ayna&#39;,
    dob: new Date(1998, 2, 7, 8, 30),
    loves: [&#39;strawberry&#39;, &#39;lemon&#39;],
    weight: 733,
    gender: &#39;f&#39;,
    vampires: 40&#125;);
db.unicorns.insert(&#123;name:&#39;Kenny&#39;,
    dob: new Date(1997, 6, 1, 10, 42),
    loves: [&#39;grape&#39;, &#39;lemon&#39;],
    weight: 690,
    gender: &#39;m&#39;,
    vampires: 39&#125;);
db.unicorns.insert(&#123;name: &#39;Raleigh&#39;,
    dob: new Date(2005, 4, 3, 0, 57),
    loves: [&#39;apple&#39;, &#39;sugar&#39;],
    weight: 421,
    gender: &#39;m&#39;,
    vampires: 2&#125;);
db.unicorns.insert(&#123;name: &#39;Leia&#39;,
    dob: new Date(2001, 9, 8, 14, 53),
    loves: [&#39;apple&#39;, &#39;watermelon&#39;],
    weight: 601,
    gender: &#39;f&#39;,
    vampires: 33&#125;);
db.unicorns.insert(&#123;name: &#39;Pilot&#39;,
    dob: new Date(1997, 2, 1, 5, 3),
    loves: [&#39;apple&#39;, &#39;watermelon&#39;],
    weight: 650,
    gender: &#39;m&#39;,
    vampires: 54&#125;);
db.unicorns.insert(&#123;name: &#39;Nimue&#39;,
    dob: new Date(1999, 11, 20, 16, 15),
    loves: [&#39;grape&#39;, &#39;carrot&#39;],
    weight: 540,
    gender: &#39;f&#39;&#125;);
db.unicorns.insert(&#123;name: &#39;Dunx&#39;,
    dob: new Date(1976, 6, 18, 18, 18),
    loves: [&#39;grape&#39;, &#39;watermelon&#39;],
    weight: 704,
    gender: &#39;m&#39;,
    vampires: 165&#125;);</code></pre>
<p>现在我们有数据了，我们可以开始来学习掌握选择器了。<code>&#123;field: value&#125;</code> 用来查找那些 <code>field</code> 的值等于 <code>value</code> 的文档。 <code>&#123;field1: value1, field2: value2&#125;</code> 相当于 <code>and</code> 查询。还有 <code>$lt</code>, <code>$lte</code>, <code>$gt</code>, <code>$gte</code> 和 <code>$ne</code> 被用来处理 小于，小于等于，大于，大于等于，和不等于操作。比如，获取所有体重大于700磅的公独角兽，我们可以这样:</p>
<pre><code>db.unicorns.find(&#123;gender: &#39;m&#39;,
    weight: &#123;$gt: 700&#125;&#125;)
//or (not quite the same thing, but for
//demonstration purposes)
db.unicorns.find(&#123;gender: &#123;$ne: &#39;f&#39;&#125;,
    weight: &#123;$gte: 701&#125;&#125;)</code></pre>
<p><code>$exists</code> 用来匹配字段是否存在，比如:</p>
<pre><code>db.unicorns.find(&#123;
    vampires: &#123;$exists: false&#125;&#125;)</code></pre>
<p>会返回一条文档。’$in’ 被用来匹配查询文档在我们传入的数组参数中是否存在匹配值，比如:</p>
<pre><code>db.unicorns.find(&#123;
    loves: &#123;$in:[&#39;apple&#39;,&#39;orange&#39;]&#125;&#125;)</code></pre>
<p>会返回那些喜欢 <code>apple</code> 或者 <code>orange</code> 的独角兽。</p>
<p>如果我们想要 OR 而不是 AND 来处理选择条件的话，我们可以用 <code>$or</code> 操作符，再给它一个我们要匹配的数组:</p>
<pre><code>db.unicorns.find(&#123;gender: &#39;f&#39;,
    $or: [&#123;loves: &#39;apple&#39;&#125;,
          &#123;weight: &#123;$lt: 500&#125;&#125;]&#125;)</code></pre>
<p>上面的查询会返回那些喜欢 <code>apples</code> 或者 <code>weigh</code> 小于500磅的母独角兽。</p>
<p>在我们最后两个例子里面有个非常赞的特性。你应该已经注意到了，<code>loves</code> 字段是个数组。MongoDB 允许数组作为基本对象(first class objects)处理。这是个令人难以置信的超赞特性。一旦你开始用它，你都不知道没了它你怎么活下去了。最有趣的是，基于数组的查询变得非常简单: <code>&#123;loves: &#39;watermelon&#39;&#125;</code> 会把文档中 <code>loves</code> 中有 <code>watermelon</code> 的值全部查询出来。</p>
<p>除了我们介绍的这些，还有更多可用的操作。所有这些都记载在 MongoDB 手册上的 <a href="http://docs.mongodb.org/manual/reference/operator/query/#query-selectors">Query Selectors</a> 这一章。我们介绍的仅仅是那些你学习时所需要用到的，同时也是你最经常用到的操作。</p>
<p>我们已经学习了选择器是如何配合 <code>find</code> 命令使用的了。还大致介绍了一下如何配合 <code>remove</code> 命令使用，<code>count</code> 命令虽然没介绍，不过你肯定知道应该怎么做，而 <code>update</code> 命令，之后我们会花多点时间来详细学习它。</p>
<p>MongoDB 为我们的 <code>_id</code> 字段生成的 <code>ObjectId</code> 可以这样查询:</p>
<pre><code>db.unicorns.find(
    &#123;_id: ObjectId(&quot;TheObjectId&quot;)&#125;)</code></pre>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我们还没有看到 <code>update</code> , 或是能拿来做更华丽事情的 <code>find</code>。不过，我们已经安装好 MongoDB 并运行起来了, 简略的介绍了一下 <code>insert</code> 和 <code>remove</code> 命令 (完整版也没比我们介绍的多什么)。 我们还介绍了 <code>find</code> 以及了解了 MongoDB <code>selectors</code> 是怎么一回事。 我们起了个很好的头，并为以后的学习奠定了坚实基础。 信不信由你，其实你已经掌握了学习 MongoDB 所必须的大多数知识 - 它真的是易学易用。 我强烈建议你在继续学习之前在本机上多试试多玩玩。 插入不同的文档，可以试试看在不同的集合中，习惯一下使用不同的选择器。试试 <code>find</code>, <code>count</code> 和 <code>remove</code>。 多试几次之后，你会发现原来看起来那么格格不入的东西，用起来居然水到渠成。</p>
<h1 id="第二章-更新"><a href="#第二章-更新" class="headerlink" title="第二章 - 更新"></a>第二章 - 更新</h1><p>在第一章，我们介绍了 CRUD 的四分之三(create, read, update 和 delete) 操作。这章，我们来专门来讨论我们跳过的那个操作: <code>update</code>。 <code>Update</code> 有些独特的行为，这是为什么我们把它独立成章。</p>
<h2 id="Update-覆盖还是-set"><a href="#Update-覆盖还是-set" class="headerlink" title="Update: 覆盖还是 $set"></a>Update: 覆盖还是 $set</h2><p>最简单的情况， <code>update</code> 有两个参数: 选择器 (<code>where</code>) 和需要更新字段的内容。假设 Roooooodles 长胖了，你会希望我们这样操作:</p>
<pre><code>db.unicorns.update(&#123;name: &#39;Roooooodles&#39;&#125;,
    &#123;weight: 590&#125;)</code></pre>
<p>(如果你已经把 <code>unicorns</code> 集合玩坏了，它已经不是原来的数据了的话，再执行一次 <code>remove</code> 删除所有数据，然后重新插入第一章中所有的代码。)</p>
<p>现在，如果你查一下被更新了的记录:</p>
<pre><code>db.unicorns.find(&#123;name: &#39;Roooooodles&#39;&#125;)</code></pre>
<p>你会发现 <code>update</code> 的第一个惊喜，没找到任何文档。因为我们指定的第二个参数没有使用任何的更新选项，因此，它 <strong>replace</strong> 了原始文档。也就是说， <code>update</code> 先根据 <code>name</code> 找到一个文档，然后用新文档(第二个参数)覆盖替换了整个文档。这和 SQL 的 <code>update</code> 命令的完全不一样。在某些情况下，这非常理想，可以用于某些完全动态更新上。但是，如果你只希望改变一个或者几个字段的值的时候，你应该用 MongoDB 的 <code>$set</code> 操作。继续，让我们来更新重置这个丢失的数据:</p>
<pre><code>db.unicorns.update(&#123;weight: 590&#125;, &#123;$set: &#123;
    name: &#39;Roooooodles&#39;,
    dob: new Date(1979, 7, 18, 18, 44),
    loves: [&#39;apple&#39;],
    gender: &#39;m&#39;,
    vampires: 99&#125;&#125;)</code></pre>
<p>这里不会覆盖新字段 <code>weight</code> 因为我们没有指定它。现在让我们来执行:</p>
<pre><code>db.unicorns.find(&#123;name: &#39;Roooooodles&#39;&#125;)</code></pre>
<p>我们拿到了期待的结果。因此，在最开始的时候，我们正确的更新 weight 的方式应该是:</p>
<pre><code>db.unicorns.update(&#123;name: &#39;Roooooodles&#39;&#125;,
    &#123;$set: &#123;weight: 590&#125;&#125;)</code></pre>
<h2 id="Update-操作符"><a href="#Update-操作符" class="headerlink" title="Update 操作符"></a>Update 操作符</h2><p>除了 <code>$set</code>，我们还可以用其他的更新操作符做些有意思的事情。所有的更新操作都是对字段起作用 - 所以你不用担心整个文档被删掉。比如，<code>$inc</code> 可以用来给一个字段增加一个正/负值。假设说 Pilot 获得了非法的两个 vampire kills 点，我们可以这样修正它:</p>
<pre><code>db.unicorns.update(&#123;name: &#39;Pilot&#39;&#125;,
    &#123;$inc: &#123;vampires: -2&#125;&#125;)</code></pre>
<p>假设 Aurora 忽然长牙了，我们可以给她的 <code>loves</code> 字段加一个值，通过 <code>$push</code> 操作:</p>
<pre><code>db.unicorns.update(&#123;name: &#39;Aurora&#39;&#125;,
    &#123;$push: &#123;loves: &#39;sugar&#39;&#125;&#125;)</code></pre>
<p>MongoDB 手册的 <a href="http://docs.mongodb.org/manual/reference/operator/update/#update-operators">Update Operators</a> 这章，可以查到更多可用的更新操作符的信息。</p>
<h2 id="Upserts"><a href="#Upserts" class="headerlink" title="Upserts"></a>Upserts</h2><p>用 <code>update</code> 还有一个最大的惊喜，就是它完全支持 <code>upserts</code>。所谓 <code>upsert</code> 更新，即在文档中找到匹配值时更新它，无匹配时向文档插入新值，你可以这样理解。要使用 upsert 我们需要向 update 写入第三个参数 <code>&#123;upsert:true&#125;</code>。</p>
<p>一个最常见的例子是网站点击计数器。如果我们想保存一个实时点击总数，我们得先看看是否在页面上已经有点击记录，然后基于此再决定执行更新或者插入操作。如果省略 upsert 选项(或者设为 false)，执行下面的操作不会带来任何变化:</p>
<pre><code>db.hits.update(&#123;page: &#39;unicorns&#39;&#125;,
    &#123;$inc: &#123;hits: 1&#125;&#125;);
db.hits.find();</code></pre>
<p>但是，如果我们加上 upsert 选项，结果会大不同:</p>
<pre><code>db.hits.update(&#123;page: &#39;unicorns&#39;&#125;,
    &#123;$inc: &#123;hits: 1&#125;&#125;, &#123;upsert:true&#125;);
db.hits.find();</code></pre>
<p>由于没有找到字段 <code>page</code> 值为 <code>unicorns</code>的文档，一个新的文档被生成插入。当我们第二次执行这句命令的时候，这个既存的文档将会被更新，且 <code>hits</code> 会被增加到 2。</p>
<pre><code>db.hits.update(&#123;page: &#39;unicorns&#39;&#125;,
    &#123;$inc: &#123;hits: 1&#125;&#125;, &#123;upsert:true&#125;);
db.hits.find();</code></pre>
<h2 id="批量-Updates"><a href="#批量-Updates" class="headerlink" title="批量 Updates"></a>批量 Updates</h2><p>关于 <code>update</code> 的最后一个惊喜，默认的，它只更新单个文档。到目前为止，我们的所有例子，看起来都挺符合逻辑的。但是，如果你执行一些像这样的操作的时候:</p>
<pre><code>db.unicorns.update(&#123;&#125;,
    &#123;$set: &#123;vaccinated: true &#125;&#125;);
db.unicorns.find(&#123;vaccinated: true&#125;);</code></pre>
<p>你肯定会希望，你所有的宝贝独角兽都被接种疫苗了。为了达到这个目的， <code>multi</code> 选项需要设为 true:</p>
<pre><code>db.unicorns.update(&#123;&#125;,
    &#123;$set: &#123;vaccinated: true &#125;&#125;,
    &#123;multi:true&#125;);
db.unicorns.find(&#123;vaccinated: true&#125;);</code></pre>
<h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>本章中我们介绍了集合的基本 CRUD 操作。我们详细讲解了 <code>update</code> 及它的三个有趣的行为。 首先，如果你传 MongoDB 一个文档但是不带更新操作, MongoDB 的 <code>update</code> 会默认替换现有文档。因此，你通常要用到 <code>$set</code> 操作 (或者其他各种可用的用于修改文档的操作)。 其次， <code>update</code> 支持 <code>upsert</code> 操作，当你不知道文档是否存在的时候，非常有用。 最后，默认情况下， <code>update</code> 只更新第一个匹配文档，因此当你希望更新所有匹配文档时，你要用 <code>multi</code> 。</p>
<h1 id="第三章-掌握查询"><a href="#第三章-掌握查询" class="headerlink" title="第三章 - 掌握查询"></a>第三章 - 掌握查询</h1><p>在第一章中我们对 <code>find</code> 命令做了一个初步的了解。除了 <code>selectors</code> 以外 <code>find</code> 还有更丰富的功能。我们已经说过，<code>find</code> 返回的结果是一个 <code>cursor</code>。我们将进一步看看它到底是什么意思。</p>
<h2 id="字段选择"><a href="#字段选择" class="headerlink" title="字段选择"></a>字段选择</h2><p>在开始 <code>cursors</code> 的话题之前，你应该知道 <code>find</code> 有第二个可选参数，叫做 “projection”。这个参数是我们要检索或者排除字段的列表。比如，我们可以仅查询返回独角兽的名字而不带别的字段:</p>
<pre><code>db.unicorns.find(&#123;&#125;, &#123;name: 1&#125;);</code></pre>
<p>默认的，<code>_id</code> 字段总是会返回的。我们可以通过这样显式的把它从返回结果中排除 <code>&#123;name:1, _id: 0&#125;</code>。</p>
<p>除了 <code>_id</code> 字段，你不能把检索和排除混合使用。仔细想想，这是有道理的。你只能显式的检索或者排除某些字段。</p>
<h2 id="排序-Ordering"><a href="#排序-Ordering" class="headerlink" title="排序(Ordering)"></a>排序(Ordering)</h2><p>到目前位置我已经提到好多次， <code>find</code> 返回的是一个游标，它只有在需要的时候才会执行。但是，你在 shell 中看确实到的是 <code>find</code> 被立刻执行了。这只是 shell 的行为。 我们可以通过一个 <code>find</code> 的链式方法，观察到 <code>cursors</code> 的真正行为。我们来看看 <code>sort</code>。我们指定我们希望排序的字段，以 JSON 方式，其中 1 表示升序 -1 表示降序。比如:</p>
<pre><code>//heaviest unicorns first
db.unicorns.find().sort(&#123;weight: -1&#125;)

//by unicorn name then vampire kills:
db.unicorns.find().sort(&#123;name: 1,
    vampires: -1&#125;)</code></pre>
<p>就像关系型数据库那样，MongoDB 允许对索引进行排序。我们再稍后将详细讨论索引。那，你应该知道的是，MongoDB 对未经索引的字段进行排序是有大小限制的。就是说，如果你试图对一个非常大的没有经过索引的结果集进行排序的话，你会得到个异常。有些人认为这是一个缺点。说实话，我是多希望更多的数据库可以有这种能力去拒绝未经优化的查询。(我不是把每个 MongoDB 的缺点硬说成优点，但是我已经看够了那些缺乏优化的数据库了，我真心希望他们能有一个 strict-mode。)</p>
<h2 id="分页-Paging"><a href="#分页-Paging" class="headerlink" title="分页(Paging)"></a>分页(Paging)</h2><p>对结果分页可以通过 <code>limit</code> 和 <code>skip</code> 游标方法来实现。比如要获取第二和第三重的独角兽，我们可以这样:</p>
<pre><code>db.unicorns.find()
    .sort(&#123;weight: -1&#125;)
    .limit(2)
    .skip(1)</code></pre>
<p>通过 <code>limit</code> 和 <code>sort</code> 的配合，可以在对非索引字段进行排序时避免引起问题。</p>
<h2 id="计数-Count"><a href="#计数-Count" class="headerlink" title="计数(Count)"></a>计数(Count)</h2><p>shell 中可以直接对一个集合执行 <code>count</code> ，像这样:</p>
<pre><code>db.unicorns.count(&#123;vampires: &#123;$gt: 50&#125;&#125;)</code></pre>
<p>实际上，<code>count</code> 是一个 <code>cursor</code> 的方法，shell 只是简单的提供了一个快捷方式。以不提供快捷方式的方法来执行的时候需要这样(在 shell 中同样可以执行):</p>
<pre><code>db.unicorns.find(&#123;vampires: &#123;$gt: 50&#125;&#125;)
    .count()</code></pre>
<h2 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h2><p>使用 <code>find</code> 和 <code>cursors</code> 非常简单。还讲了一些我们后面章节会用到的或是非常特殊情况才用的命令，不过不管怎样，现在，你应该已经非常熟练使用 mongo shell 以及理解 MongoDB 的基本原则了。</p>
<h1 id="第四章-数据建模"><a href="#第四章-数据建模" class="headerlink" title="第四章 - 数据建模"></a>第四章 - 数据建模</h1><p>让我们换换思维，对 MongoDB 进行一个更抽象的理解。介绍一些新的术语和一些新的语法是非常容易的。而要接受一个以新的范式来建模，是相当不简单的。事实是，当用新技术进行建模的时候，我们中的许多人还在找什么可用的什么不可用。在这里我们只是开始新的开端，而最终你需要去在实战中练习和学习。</p>
<p>与大多数 NoSQL 数据库相比，面向文档型数据库和关系型数据库很相似 - 至少，在建模上是这样的。但是，不同点非常重要。</p>
<h2 id="No-Joins"><a href="#No-Joins" class="headerlink" title="No Joins"></a>No Joins</h2><p>你需要适应的第一个，也是最根本的区别就是 mongoDB 没有链接(join) 。我不知道 MongoDB 中不支持链接的具体原因，但是我知道链接基本上意味着不可扩展。就是说，一旦你把数据水平扩展，无论如何你都要放弃在客户端(应用服务器)使用链接。事实就是，数据 <em>有</em> 关系, 但 MongoDB 不支持链接。</p>
<p>没别的办法，为了在无连接的世界生存下去，我们只能在我们的应用代码中自己实现链接。我们需要进行二次查询 <code>find</code> ，把相关数据保存到另一个集合中。我们设置数据和在关系型数据中声明一个外键没什么区别。先不管我们那美丽的 <code>unicorns</code> 了，让我们来看看我们的 <code>employees</code>。 首先我们来创建一个雇主 (我提供了一个明确的 <code>_id</code> ，这样我们就可以和例子作成一样)</p>
<pre><code>db.employees.insert(&#123;_id: ObjectId(
    &quot;4d85c7039ab0fd70a117d730&quot;),
    name: &#39;Leto&#39;&#125;)</code></pre>
<p>然后让我们加几个工人，把他们的管理者设置为 <code>Leto</code>:</p>
<pre><code>db.employees.insert(&#123;_id: ObjectId(
    &quot;4d85c7039ab0fd70a117d731&quot;),
    name: &#39;Duncan&#39;,
    manager: ObjectId(
    &quot;4d85c7039ab0fd70a117d730&quot;)&#125;);
db.employees.insert(&#123;_id: ObjectId(
    &quot;4d85c7039ab0fd70a117d732&quot;),
    name: &#39;Moneo&#39;,
    manager: ObjectId(
    &quot;4d85c7039ab0fd70a117d730&quot;)&#125;);</code></pre>
<p>(有必要再重复一次， <code>_id</code> 可以是任何形式的唯一值。因为你很可能在实际中使用 <code>ObjectId</code> ，我们也在这里用它。)</p>
<p>当然，要找出 Leto 的所有工人，只需要执行:</p>
<pre><code>db.employees.find(&#123;manager: ObjectId(
    &quot;4d85c7039ab0fd70a117d730&quot;)&#125;)</code></pre>
<p>这没什么神奇的。在最坏的情况下，大多数的时间，为弥补无链接所做的仅仅是增加一个额外的查询(可能是被索引的)。</p>
<h2 id="数组和内嵌文档"><a href="#数组和内嵌文档" class="headerlink" title="数组和内嵌文档"></a>数组和内嵌文档</h2><p>MongoDB 不支持链接不意味着它没优势。还记得我们说过 MongoDB 支持数组作为文档中的基本对象吗？这在处理多对一(many-to-one)或者多对多(many-to-many)的关系的时候非常方便。举个简单的例子，如果一个工人有两个管理者，我们只需要像这样存一下数组:</p>
<pre><code>db.employees.insert(&#123;_id: ObjectId(
    &quot;4d85c7039ab0fd70a117d733&quot;),
    name: &#39;Siona&#39;,
    manager: [ObjectId(
    &quot;4d85c7039ab0fd70a117d730&quot;),
    ObjectId(
    &quot;4d85c7039ab0fd70a117d732&quot;)] &#125;)</code></pre>
<p>有趣的是，对于某些文档，<code>manager</code> 可以是单个不同的值，而另外一些可以是数组。而我们原来的 <code>find</code> 查询依旧可用:</p>
<pre><code>db.employees.find(&#123;manager: ObjectId(
    &quot;4d85c7039ab0fd70a117d730&quot;)&#125;)</code></pre>
<p>你会很快就发现，数组中的值比多对多链接表(many-to-many join-tables)要容易处理得多。</p>
<p>数组之外，MongoDB 还支持内嵌文档。来试试看向文档插入一个内嵌文档，像这样:</p>
<pre><code>db.employees.insert(&#123;_id: ObjectId(
    &quot;4d85c7039ab0fd70a117d734&quot;),
    name: &#39;Ghanima&#39;,
    family: &#123;mother: &#39;Chani&#39;,
        father: &#39;Paul&#39;,
        brother: ObjectId(
    &quot;4d85c7039ab0fd70a117d730&quot;)&#125;&#125;)</code></pre>
<p>像你猜的那样，内嵌文档可以用 dot-notation 查询:</p>
<pre><code>db.employees.find(&#123;
    &#39;family.mother&#39;: &#39;Chani&#39;&#125;)</code></pre>
<p>我们只简单的介绍一下内嵌文档适用情况，以及你怎么使用它们。</p>
<p>结合两个概念，我们甚至可以内嵌文档数组:</p>
<pre><code>db.employees.insert(&#123;_id: ObjectId(
    &quot;4d85c7039ab0fd70a117d735&quot;),
    name: &#39;Chani&#39;,
    family: [ &#123;relation:&#39;mother&#39;,name: &#39;Chani&#39;&#125;,
        &#123;relation:&#39;father&#39;,name: &#39;Paul&#39;&#125;,
        &#123;relation:&#39;brother&#39;, name: &#39;Duncan&#39;&#125;]&#125;)</code></pre>
<h2 id="反规范化-Denormalization"><a href="#反规范化-Denormalization" class="headerlink" title="反规范化(Denormalization)"></a>反规范化(Denormalization)</h2><p>另外一个代替链接的方案是对你的数据做反规范化处理(denormalization)。从历史角度看，反规范化处理是为了解决那些对性能敏感的问题，或是需要做快照的数据(比如说审计日志)。但是，随着日益增长的普及的 NoSQL，对链接的支持的日益丧失，反规范化作为规范化建模的一部分变得越来越普遍了。这不意味着，应该对你文档里的每条数据都做冗余处理。而是说，与其对冗余数据心存恐惧，让它影响你的设计决策，不如在建模的时候考虑什么信息应当属于什么文档。</p>
<p>比如说，假设你要写一个论坛应用。传统的方式是通过 <code>posts</code> 中的 <code>userid</code> 列，来关联一个特定的 <code>user</code> 和一篇 <code>post</code> 。这样的建模，你没法在显示 <code>posts</code> 的时候不查询 (链接到) <code>users</code>。一个代替案是简单的在每篇 <code>post</code> 中把 <code>name</code> 和 <code>userid</code> 一起保存。你可能要用到内嵌文档，比如 <code>user: &#123;id: ObjectId(&#39;Something&#39;), name: &#39;Leto&#39;&#125;</code>。是的，如果你让用户可以更新他们的名字，那么你得对所有的文档都进行更新(一个多重更新)。</p>
<p>适应这种方法不是对任何人都那么简单的。很多情况下这样做甚至是无意义的。不过不要害怕去尝试。它只是在某些情况下不适用而已，但在某些情况下是最好的解决方法。</p>
<h2 id="你的选择是？"><a href="#你的选择是？" class="headerlink" title="你的选择是？"></a>你的选择是？</h2><p>在处理一对多(one-to-many)或者多对多(many-to-many)场景的时候，id 数组通常是一个正确的选择。但通常，新人开发者在面对内嵌文档和 “手工” 引用时，左右为难。</p>
<p>首先，你应该知道的是，一个独立文档的大小当前被限制在 16MB 。知道了文档的大小限制，挺宽裕的，对你考虑怎么用它多少有些影响。在这点上，看起来大多数开发者都愿意手工维护数据引用关系。内嵌文档经常被用到，大多数情况下多是很小的数据块，那些总是被和父节点一起拉取的数据块。现实的例子是为每个用户保存一个 <code>addresses</code> ，看起来像这样:</p>
<pre><code>db.users.insert(&#123;name: &#39;leto&#39;,
    email: &#39;leto@dune.gov&#39;,
    addresses: [&#123;street: &quot;229 W. 43rd St&quot;,
                city: &quot;New York&quot;, state:&quot;NY&quot;,zip:&quot;10036&quot;&#125;,
               &#123;street: &quot;555 University&quot;,
                city: &quot;Palo Alto&quot;, state:&quot;CA&quot;,zip:&quot;94107&quot;&#125;]&#125;)</code></pre>
<p>这并不意味着你要低估内嵌文档的能力，或者仅仅把他们当成小技巧。把你的数据模型直接映射到你的对象，这会使得问题更简单，并且通常也不需要用到链接了。尤其是，当你考虑到 MongoDB 允许你对内嵌文档和数组的字段进行查询和索引时，效果特别明显。</p>
<h2 id="大而全还是小而专的集合？"><a href="#大而全还是小而专的集合？" class="headerlink" title="大而全还是小而专的集合？"></a>大而全还是小而专的集合？</h2><p>由于对集合没做任何的强制要求，完全可以在系统中用一个混合了各种文档的集合，但这绝对是个非常烂的主意。大多数 MongoDB 系统都采用了和关系型数据库类似的结构，分成几个集合。换而言之，如果在关系型数据库中是一个表，那么在 MongoDB 中会被作成一个集合 (many-to-many join tables being an important exception as well as tables that exist only to enable one to many relationships with simple entities)。</p>
<p>当你把内嵌文档考虑进来的时候，这个话题会变的更有趣。常见的例子就是博客。你是应该分成一个 <code>posts</code> 集合和一个 <code>comments</code> 集合呢，还是应该每个 <code>post</code> 下面嵌入一个 <code>comments</code> 数组？ 先不考虑那个 16MB 文档大小限制 ( <em>哈姆雷特</em> 全文也没超过 200KB，所以你的博客是有多人气？)，许多开发者都喜欢把东西划分开来。这样更简洁更明确，给你更好的性能。MongoDB 的灵活架构允许你把这两种方式结合起来，你可以把评论放在独立的集合中，同时在博客帖子下嵌入一小部分评论 (比如说最新评论) ，以便和帖子一同显示。这遵守以下的规则，就是你到想在一次查询中获取到什么内容。</p>
<p>这没有硬性规定(好吧，除了16MB限制)。尝试用不同的方法解决问题，你会知道什么能用什么不能用。</p>
<h2 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h2><p>本章目标是提供一些对你在 MongoDB 中数据建模有帮助的指导, 一个新起点，如果愿意你可以这样认为。在一个面向文档系统中建模，和在面向关系世界中建模，是不一样的，但也没多少不同。你能得到更多的灵活性并且只有一个约束，而对于新系统，一切都很完美。你唯一会做错的就是你不去尝试。</p>
<h1 id="第五章-MongoDB-适用场景"><a href="#第五章-MongoDB-适用场景" class="headerlink" title="第五章 - MongoDB 适用场景"></a>第五章 - MongoDB 适用场景</h1><p>现在你应该有感觉，何时何地把 MongoDB 融入你现有的系统是最棒的了。这有超多的新的类似的存储技术，肯定会让你在选择的时候晕头转向。</p>
<p>对我来说，最重要的教训，跟 MongoDB 无关，是说你不用再依赖单一的解决案来处理你的数据了。毫无疑问，一个单一的解决案有明显的优势，对于许多项目来说 - 或者说大多数 - 单一解决案是一个明智的选择。意思不是说你 <em>必须</em> 使用不同的技术，而是说你 <em>可以</em>。 只有你自己才知道，引进新技术是否利大于弊。</p>
<p>说了那么多，我希望你到目前为止学到知识让你觉得 MongoDB 是一个通用的解决案。我们已经提到很多次了，面向文档的数据库和关系型数据库有很多方面类似。因此，与其绕开这些相同点，不如我们可以简单的这样认为， MongoDB 是关系型数据库的一个代替案。比如说用 Lucene 作为关系型数据库的全文检索索引的加强，或者用 Redis 作为持久型 key-value 存储，MongoDB 就是用来保存你的数据的。</p>
<p>注意，我没有说用 MongoDB <em>取代</em> 关系型数据库，而是 <em>代替</em> 案。它能做的有很多工具也能做。有些事情 MongoDB 可以做的更好，另外一些 MongoDB 做得差点。我们来进一步来讨论一下。</p>
<h2 id="无模式-Flexible-Schema"><a href="#无模式-Flexible-Schema" class="headerlink" title="无模式(Flexible Schema)"></a>无模式(Flexible Schema)</h2><p>面向文档数据库经常吹嘘的一个好处就是，它不需要一个固定的模式。这使得他们比传统的数据库表要灵活得多。我同意无模式是一个很不错的特性，但不是大多数人说的那样。</p>
<p>人们讲到无模式的时候，好像你就会把一堆乱七八糟的数据统统存起来一样。确实有些领域有些数据用关系型数据库来建模很痛苦，不过我觉得这些都是不常见的特例。无模式是酷，可是大多数情况下你的数据结构还是应当好好设计的。真正需要处理混乱时是不错，比如当你添加一个新功能的时候，不过事实是，大多数情况下，一个空列基本可以解决问题。</p>
<p>对我来说，动态模式的真正好处在于无需很多设置以及可以降低在 OOP 中使用的阻力。这在你使用静态语言的时候尤其明显。我在 C# 和 Ruby 中用过 MongoDB ，差异非常明显。Ruby 的动态特性以及它的流行的 ActiveRecord 实现，已经大幅降低面向对象/关系开发之间差异所带来的阻力。这不是说 MongoDB 和 Ruby 不配，而是是说它们太配了。真的，我觉得许多 Ruby 开发者眼中的的 MongoDB 只是有些许改进而已，而在 C# 或者 Java 开发者眼中，MongoDB 带来的是处理数据交互方式的翻天覆地变化。</p>
<p>假设从驱动开发者角度来看这个问题。你想保存一个对象？把它串行化成 JSON (严格来说是 BSON, 不过差不多) 然后把它传给 MongoDB。不需要做任何属性映射或者类型映射。这种简单性的好处就这样传递给了你，终端开发者。</p>
<h2 id="写操作-Writes"><a href="#写操作-Writes" class="headerlink" title="写操作(Writes)"></a>写操作(Writes)</h2><p>MongoDB 可以胜任的一个特殊角色是在日志领域。有两点使得 MongoDB 的写操作非常快。首先，你可以选择发送了写操作命令之后立刻返回，而无须等到操作完成。其次，你可以控制数据持久性的写行为。这些设置，加上，可以定义一个成功的提交，需要在多少台服务器上成功拿到你的数据之后才算成功，并且每个写操作都是可设置, 这就给予你很高的权限用以控制写性能和数据持久性。</p>
<p>除了这些性能因素，日志数据还是这样一种数据集，用无模式集合更有优势。最后，MongoDB 还提供了 <a href="http://docs.mongodb.org/manual/core/capped-collections/">受限集合(capped collection)</a>。到目前为止，所有我们默认创建的集合都是普通集合。我们可以通过 <code>db.createCollection</code> 命令来创建一个受限集合并标记它的限制:</p>
<pre><code>//limit our capped collection to 1 megabyte
db.createCollection(&#39;logs&#39;, &#123;capped: true,
    size: 1048576&#125;)</code></pre>
<p>当我们的受限集合到达 1MB 上限的时候，旧文档会被自动清除。另外一种限制可以基于文档个数，而不是大小，用 <code>max</code> 标记。受限集合有一些非常有趣的属性。比如说，你可以更新文档但是你不能改变它的大小。插入顺序是被设置好了的，因此不需要另外提供一个索引来获取基于时间的排序，你可以 “tail” 一个受限集合，就和你在 Unix 中通过 <code>tail -f &lt;filename&gt;</code> 来处理文件一样，获取最新的数据，如果存在数据的话，而不需要重新查询它。</p>
<p>如果想让你的数据 “过期” ，基于时间而不是整个集合的大小，你可以用 <a href="http://docs.mongodb.org/manual/tutorial/expire-data/">TTL 索引</a> ，所谓 TTL 是 “time-to-live” 的缩写。</p>
<h2 id="持久性-Durability"><a href="#持久性-Durability" class="headerlink" title="持久性(Durability)"></a>持久性(Durability)</h2><p>在 1.8 之前的版本，MongoDB 不支持单服务器持久性。就是说，如果一个服务器崩溃了，可能会导致数据的丢失或者损坏。解决案是在多服务器上运行 MongoDB 副本 (MongoDB 支持复制)。日志(Journaling)是 1.8 版追加的一个非常重要的功能。从 2.0 版的 MongoDB 开始，日志是默认启动的，该功能允许快速恢复服务器，比如遭遇到了服务器崩溃或者停电的情况。</p>
<p>持久性在这里只是提一下，因为围绕 MongoDB 过去缺乏单服务器持久的问题，人们取得了众多成果。这个话题在以后的 Google 检索中也许还会继续出现。但是关于缺少日志功能这一缺点的信息，都是过时了的。</p>
<h2 id="全文检索-Full-Text-Search"><a href="#全文检索-Full-Text-Search" class="headerlink" title="全文检索(Full Text Search)"></a>全文检索(Full Text Search)</h2><p>真正的全文检索是在最近加入到 MongoDB 中的。它支持十五国语言，支持词形变化(stemming)和干扰字(stop words)。除了原生的 MongoDB 的全文检索支持，如果你需要一个更强大更全面的全文检索引擎的话，你需要另找方案。</p>
<h2 id="事务-Transactions"><a href="#事务-Transactions" class="headerlink" title="事务(Transactions)"></a>事务(Transactions)</h2><p>MongoDB 不支持事务。这有两个代替案，一个很好用但有限制，另外一个比较麻烦但灵活。</p>
<p>第一个方案，就是各种原子更新操作。只要能解决你的问题，都挺不错。我们已经看过几个简单的了，比如 <code>$inc</code> 和 <code>$set</code>。还有像 <code>findAndModify</code> 命令，可以更新或删除文档之后，自动返回修改过的文档。</p>
<p>第二个方案，当原子操作不能满足的时候，回到两段提交上来。对于事务，两段提交就好像给链接手工解引用。这是一个和存储无关的解决方案。两段提交实际上在关系型数据库世界中非常常用，用来实现多数据库之间的事务。 MongoDB 网站 <a href="http://docs.mongodb.org/manual/tutorial/perform-two-phase-commits/">有个例子</a> 演示了最典型的场合 (资金转账)。通常的想法是，把事务的状态保存到实际的原子更新的文档中，然后手工的进行 init-pending-commit/rollback 处理。</p>
<p>MongoDB 支持内嵌文档以及它灵活的 schema 设计，让两步提交没那么痛苦，但是它仍然不是一个好处理，特别是当你刚开始接触它的时候。</p>
<h2 id="数据处理-Data-Processing"><a href="#数据处理-Data-Processing" class="headerlink" title="数据处理(Data Processing)"></a>数据处理(Data Processing)</h2><p>在2.2 版本之前的 MongoDB 依赖 MapReduce 来解决大部分数据处理工作。在 2.2 版本，它追加了一个强力的功能，叫做 <a href="http://docs.mongodb.org/manual/core/aggregation-pipeline/">aggregation framework or pipeline</a>，因此你只要对那些尚未支持管道的，需要使用复杂方法的，不常见的聚合使用 MapReduce。下一章我们将看看聚合管道和 MapReduce 的细节。现在，你可以把他们想象成功能强大的，用不同方法实现的 <code>group by</code> (打个比方)。对于非常大的数据的处理，你可能要用到其他的工具，比如 Hadoop。值得庆幸的是，这两个系统是相辅相成的，这里有个 <a href="http://docs.mongodb.org/ecosystem/tools/hadoop/">MongoDB connector for Hadoop</a>。</p>
<p>当然，关系型数据库也不擅长并行数据处理。MongoDB 有计划在未来的版本中，改善增加处理大数据集的能力。</p>
<h2 id="地理空间查询-Geospatial"><a href="#地理空间查询-Geospatial" class="headerlink" title="地理空间查询(Geospatial)"></a>地理空间查询(Geospatial)</h2><p>一个很强大的功能就是 MongoDB 支持 <a href="http://docs.mongodb.org/manual/applications/geospatial-indexes/">geospatial 索引</a>。这允许你保存 geoJSON 或者 x 和 y 坐标到文档，并查询文档，用如 <code>$near</code> 来获取坐标集，或者 <code>$within</code> 来获取一个矩形或圆中的点。这个特性最好通过一些可视化例子来演示，所以如果你想学更多的话，可以试试看 <a href="http://mongly.openmymind.net/geo/index">5 minute geospatial interactive tutorial</a>。</p>
<h2 id="工具和成熟度"><a href="#工具和成熟度" class="headerlink" title="工具和成熟度"></a>工具和成熟度</h2><p>你应该已经知道这个问题的答案了，MongoDB 确实比大多数的关系型数据要年轻很多。这个问题确实是你应当考虑的，但是到底有多重要，这取决于你要做什么，怎么做。不管怎么说，一个好的评估，不可能忽略 MongoDB 年轻这一事实，而可用的工具也不是很好 (虽然成熟的关系型数据库工具有些也非常渣!)。举个例子，它缺乏对十进制浮点数的支持，在处理货币的系统来说，明显是一个问题 (尽管也不是致命的) 。</p>
<p>积极的一方面，它为大多数语言提供了驱动，协议现代而简约，开发速度相当快。MongoDB 被众多公司用到了生产环境中，虽然有所担心，但经过验证后，担心很快就变成了过去。</p>
<h2 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h2><p>本章要说的是，MongoDB，大多数情况下，可以取代关系型数据库。它更简单更直接；更快速并且通常对应用开发者的约束更少。不过缺乏事务支持也许值得慎重考虑。当人们说起 <em>MongoDB 在新的数据库阵营中到底处在什么位置？</em> 时，答案很简单: <strong>中庸</strong>(<em>2</em>)。</p>
<h1 id="第六章-数据聚合"><a href="#第六章-数据聚合" class="headerlink" title="第六章 - 数据聚合"></a>第六章 - 数据聚合</h1><h2 id="聚合管道-Aggregation-Pipeline"><a href="#聚合管道-Aggregation-Pipeline" class="headerlink" title="聚合管道(Aggregation Pipeline)"></a>聚合管道(Aggregation Pipeline)</h2><p>聚合管道提供了一种方法用于转换整合文档到集合。你可以通过管道来传递文档，就像 Unix 的 “pipe” 一样，将一个命令的输出传递到另第二个，第三个，等等。</p>
<p>最简单的聚合，应该是你在 SQL 中早已熟悉的 <code>group by</code> 操作。我们已经看过 <code>count()</code> 方法，那么假设我们怎么才能知道有多少匹公独角兽，有多少匹母独角兽呢？</p>
<pre><code>db.unicorns.aggregate([&#123;$group:&#123;_id:&#39;$gender&#39;,
    total: &#123;$sum:1&#125;&#125;&#125;])</code></pre>
<p>在 shell 中，我们有 <code>aggregate</code> 辅助类，用来执行数组的管道操作。对于简单的对某物进行分组计数，我们只需要简单的调用 <code>$group</code>。这和 SQL 中的 <code>GROUP BY</code> 完全一致，我们用来创建一个新的文档，以 <code>_id</code> 字段表示我们以什么来分组(在这里是以 <code>gender</code>) ，另外的字段通常被分配为聚合的结果，在这里，我们对匹配某一性别的各文档使用了 <code>$sum</code> 1 。你应该注意到了 <code>_id</code> 字段被分配为 <code>&#39;$gender&#39;</code> 而不是 <code>&#39;gender&#39;</code> - 字段前面的 <code>&#39;$&#39;</code> 表示，该字段将会被输入的文档中的有同样名字的值所代替，一个占位符。</p>
<p>我们还可以用其他什么管道操作呢？在 <code>$group</code> 之前(之后也很常用)的一个是 <code>$match</code> - 这和 <code>find</code> 方法完全一样，允许我们获取文档中某个匹配的子集，或者在我们的结果中对文档进行筛选。</p>
<pre><code>db.unicorns.aggregate([&#123;$match: &#123;weight:&#123;$lt:600&#125;&#125;&#125;,
    &#123;$group: &#123;_id:&#39;$gender&#39;,  total:&#123;$sum:1&#125;,
      avgVamp:&#123;$avg:&#39;$vampires&#39;&#125;&#125;&#125;,
    &#123;$sort:&#123;avgVamp:-1&#125;&#125; ])</code></pre>
<p>这里我们介绍另外一个管道操作 <code>$sort</code> ，作用和你想的完全一致，还有和它一起用的 <code>$skip</code> 和 <code>$limit</code>。以及用 <code>$group</code> 操作 <code>$avg</code>。</p>
<p>MongoDB 数组非常强大，并且他们不会阻止我们往保存中的数组中写入内容。我们需要可以 “flatten” 他们以便对所有的东西进行计数:</p>
<pre><code>db.unicorns.aggregate([&#123;$unwind:&#39;$loves&#39;&#125;,
     &#123;$group: &#123;_id:&#39;$loves&#39;,  total:&#123;$sum:1&#125;,
     unicorns:&#123;$addToSet:&#39;$name&#39;&#125;&#125;&#125;,
      &#123;$sort:&#123;total:-1&#125;&#125;,
      &#123;$limit:1&#125; ])</code></pre>
<p>这里我们可以找出独角兽最喜欢吃的食物，以及拿到喜欢这种食物的独角兽的名单。 <code>$sort</code> 和 <code>$limit</code> 的组合能让你拿到 “top N” 这种查询的结果。</p>
<p>还有另外一个强大的管道操作叫做 <a href="http://docs.mongodb.org/manual/reference/operator/aggregation/project/#pipe._S_project"><code>$project</code></a> (类似于 <code>find</code>)，不但允许你拿到指定字段，还可以根据现存字段进行创建或计算一个新字段。比如，可以用数学操作，在做平均运算之前，对几个字段进行加法运算，或者你可以用字符串操作创建一个新的字段，用于拼接现有字段。</p>
<p>这只是用聚合所能做到的众多功能中的皮毛， 2.6 的聚合拥有了更强大的力量，比如聚合命令可以返回结果集的游标(我们已经在第一章学过了) 或者可以将结果写到另外一个新集合中，通过 <code>$out</code> 管道操作。你可以从 <a href="http://docs.mongodb.org/manual/core/aggregation-pipeline/">MongoDB 手册</a> 得到关于管道操作和表达式操作更多的例子。</p>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>MapReduce 分两步进行数据处理。首先是 map，然后 reduce。在 map 步骤中，转换输入文档和输出一个 key=&gt;value 对(key 和/或 value 可以很复杂)。然后, key/value 对以 key 进行分组，有同样的 key 的 value 会被收入一个数组中。在 reduce 步骤中，获取 key 和该 key 的 value 的数组，生成最终结果。map 和 reduce 方法用 JavaScript 来编写。</p>
<p>在 MongoDB 中我们对一个集合使用 <code>mapReduce</code> 命令。 <code>mapReduce</code> 执行 map 方法， reduce 方法和 output 指令。在我们的 shell 中，我们可以创建输入一个 JavaScript 方法。许多库中，支持字符串方法 (有点丑)。第三个参数设置一个附加参数，比如说我们可以过滤，排序和限制那些我们想要分析的文档。我们也可以提供一个 <code>finalize</code> 方法来处理 <code>reduce</code> 步骤之后的结果。</p>
<p>在你的大多数聚合中，也许无需用到 MapReduce , 但如果需要，你可以读到更多关于它的内容，从 <a href="http://openmymind.net/2011/1/20/Understanding-Map-Reduce/">我的 blog</a> 和 <a href="http://docs.mongodb.org/manual/core/map-reduce/">MongoDB 手册</a>。</p>
<h2 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h2><p>在这章中我们介绍了 MongoDB 的 <a href="http://docs.mongodb.org/manual/aggregation/">聚合功能(aggregation capabilities)</a>。 一旦你理解了聚合管道(Aggregation Pipeline)的构造，它还是相对容易编写的，并且它是一个聚合数据的强有力工具。 MapReduce 更难理解一点，不过它强力无边，就像你用 JavaScript 写的代码一样。</p>
<h1 id="第七章-性能和工具"><a href="#第七章-性能和工具" class="headerlink" title="第七章 - 性能和工具"></a>第七章 - 性能和工具</h1><p>在这章中，我们来讲几个关于性能的话题，以及在 MongoDB 开发中用到的一些工具。我们不会深入其中的一个话题，不过我们会指出每个话题中最重要的方面。</p>
<h2 id="索引-Index"><a href="#索引-Index" class="headerlink" title="索引(Index)"></a>索引(Index)</h2><p>首先我们要介绍一个特殊的集合 <code>system.indexes</code> ，它保存了我们数据库中所有的索引信息。索引的作用在 MongoDB 中和关系型数据库基本一致: 帮助改善查询和排序的性能。创建索引用 <code>ensureIndex</code> :</p>
<pre><code>// where &quot;name&quot; is the field name
db.unicorns.ensureIndex(&#123;name: 1&#125;);</code></pre>
<p>删除索引用 <code>dropIndex</code>:</p>
<pre><code>db.unicorns.dropIndex(&#123;name: 1&#125;);</code></pre>
<p>可以创建唯一索引，这需要把第二个参数 <code>unique</code> 设置为 <code>true</code>:</p>
<pre><code>db.unicorns.ensureIndex(&#123;name: 1&#125;,
    &#123;unique: true&#125;);</code></pre>
<p>索引可以内嵌到字段中 (再说一次，用点号) 和任何数组字段。我们可以这样创建复合索引:</p>
<pre><code>db.unicorns.ensureIndex(&#123;name: 1,
    vampires: -1&#125;);</code></pre>
<p>索引的顺序 (1 升序, -1 降序) 对单键索引不起任何影响，但它会在使用复合索引的时候有所不同，比如你用不止一个索引来进行排序的时候。</p>
<p>阅读 <a href="http://docs.mongodb.org/manual/indexes/">indexes page</a> 获取更多关于索引的信息。</p>
<h2 id="Explain"><a href="#Explain" class="headerlink" title="Explain"></a>Explain</h2><p>需要检查你的查询是否用到了索引，你可以通过 <code>explain</code> 方法:</p>
<pre><code>db.unicorns.find().explain()</code></pre>
<p>输出告诉我们，我们用的是 <code>BasicCursor</code> (意思是没索引), 12 个对象被扫描，用了多少时间，什么索引，如果有索引，还会有其他有用信息。</p>
<p>如果我们改变查询索引语句，查询一个有索引的字段，我们可以看到 <code>BtreeCursor</code> 作为索引被用到填充请求中去:</p>
<pre><code>db.unicorns.find(&#123;name: &#39;Pilot&#39;&#125;).explain()</code></pre>
<h2 id="复制-Replication"><a href="#复制-Replication" class="headerlink" title="复制(Replication)"></a>复制(Replication)</h2><p>MongoDB 的复制在某些方面和关系型数据库的复制类似。所有的生产部署应该都是副本集，理想情况下，三个或者多个服务器都保持相同的数据。写操作被发送到单个服务器，也即主服务器，然后从它异步复制到所有的从服务器上。你可以控制是否允许从服务器上进行读操作，这可以让一些特定的查询从主服务器中分离出来，当然，存在读取到旧数据的风险。如果主服务器异常关闭，从服务中的一个将会自动晋升为新的主服务器继续工作。另外，MongoDB 的复制不在本书的讨论范围之内。</p>
<h2 id="分片-Sharding"><a href="#分片-Sharding" class="headerlink" title="分片(Sharding)"></a>分片(Sharding)</h2><p>MongoDB 支持自动分片。分片是实现数据扩展的一种方法，依靠在跨服务器或者集群上进行数据分区来实现。一个最简单的实现是把所有的用户数据，按照名字首字母 A-M 放在服务器 1 ，然后剩下的放在服务器 2。谢天谢地，MongoDB 的拆分能力远比这种分法要强。分片不在本书的讨论范围之内，不过你应当有分片的概念，并且，当你的需求增长超过了使用单一副本集的时候，你应该考虑它。</p>
<p>尽管复制有时候可以提高性能(通过将长时间查询隔离到从服务器，或者降低某些类型的查询的延迟),但它的主要目的是维护高可用性。分片是扩展 MongoDB 集群的主要方法。把复制和分片结合起来实现可扩展和高可用性的通用方法。</p>
<h2 id="状态-Stats"><a href="#状态-Stats" class="headerlink" title="状态(Stats)"></a>状态(Stats)</h2><p>你可以通过 <code>db.stats()</code> 查询数据库的状态。基本上都是关于数据库大小的信息。你还可以查询集合的状态，比如说 <code>unicorns</code> 集合，可以输入 <code>db.unicorns.stats()</code>。基本上都是关于集合大小的信息，以及集合的索引信息。</p>
<h2 id="分析器-Profiler"><a href="#分析器-Profiler" class="headerlink" title="分析器(Profiler)"></a>分析器(Profiler)</h2><p>你可以这样执行 MongoDB profiler :</p>
<pre><code>db.setProfilingLevel(2);</code></pre>
<p>启动之后，我们可以执行一个命令:</p>
<pre><code>db.unicorns.find(&#123;weight: &#123;$gt: 600&#125;&#125;);</code></pre>
<p>然后检查 profiler:</p>
<pre><code>db.system.profile.find()</code></pre>
<p>输出会告诉我们:什么时候执行了什么，有多少文档被扫描，有多少数据被返回。</p>
<p>你要停止 profiler 只需要再调用一次 <code>setProfilingLevel</code> ，不过这次参数是 <code>0</code>。指定 <code>1</code> 作为第一个参数，将会统计那些超过 100 milliseconds 的任务. 100 milliseconds 是默认的阈值，你可以在第二个参数中，指定不同的阈值时间，以 milliseconds 为单位:</p>
<pre><code>//profile anything that takes
//more than 1 second
db.setProfilingLevel(1, 1000);</code></pre>
<h2 id="备份和还原"><a href="#备份和还原" class="headerlink" title="备份和还原"></a>备份和还原</h2><p>在 MongoDB 的 <code>bin</code> 目录下有一个可执行文件 <code>mongodump</code> 。简单执行 <code>mongodump</code> 会链接到 localhost 并备份你所有的数据库到 <code>dump</code> 子目录。你可以用 <code>mongodump --help</code> 查看更多执行参数。常用的参数有 <code>--db DBNAME</code> 备份指定数据库和 <code>--collection COLLECTIONNAME</code> 备份指定集合。你可以用 <code>mongorestore</code> 可执行文件，同样在 <code>bin</code> 目录下，还原之前的备份。同样， <code>--db</code> 和 <code>--collection</code> 可以指定还原的数据库和/或集合。 <code>mongodump</code> 和 <code>mongorestore</code> 使用 BSON，这是 MongoDB 的原生格式。</p>
<p>比如，来备份我们的 <code>learn</code> 数据库导 <code>backup</code> 文件夹，我们需要执行(在控制台或者终端中执行该命令，而不是在 mongo shell 中):</p>
<pre><code>mongodump --db learn --out backup</code></pre>
<p>如果只还原 <code>unicorns</code> 集合，我们可以这样做:</p>
<pre><code>mongorestore --db learn --collection unicorns \
    backup/learn/unicorns.bson</code></pre>
<p>值得一提的是， <code>mongoexport</code> 和 <code>mongoimport</code> 是另外两个可执行文件，用于导出和从 JSON/CSV 格式文件导入数据。比如说，我们可以像这样导出一个 JSON:</p>
<pre><code>mongoexport --db learn --collection unicorns</code></pre>
<p>CSV 格式是这样:</p>
<pre><code>mongoexport --db learn \
    --collection unicorns \
    --csv --fields name,weight,vampires</code></pre>
<p>注意 <code>mongoexport</code> 和 <code>mongoimport</code> 不一定能正确代表数据。真实的备份中，只能使用 <code>mongodump</code> 和 <code>mongorestore</code> 。  你可以从 MongoDB 手册中读到更多的 <a href="http://docs.mongodb.org/manual/core/backups/">备份须知</a> 。</p>
<h2 id="小结-6"><a href="#小结-6" class="headerlink" title="小结"></a>小结</h2><p>在这章中我们介绍了 MongoDB 的各种命令，工具和性能细节。我们没有涉及所有的东西，不过我们已经把常用的都看了一遍。MongoDB 的索引和关系型数据库中的索引非常类似，其他一些工具也一样。不过，在 MongoDB 中，这些更易于使用。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>你现在应该有足够的能力开始在真实项目中使用 MongoDB 了。虽然 MongoDB 远不止我们学到的这些内容，但是你要作的下一步是，把学到的知识融会贯通，熟悉我们需要用到的功能。<a href="http://www.mongodb.org/">MongoDB website</a> 有许多有用的信息。官网的 <a href="http://groups.google.com/group/mongodb-user">MongoDB user group</a> 是个问问题的好地方。</p>
<p>NoSQL 不光是为需求而生，它同时还是不断尝试创新的成果。不得不承认，我们的领域是不断前行的。如果我们不尝试，一旦失败，我们就绝不会取得成功。就是这样的，我认为，这是让你在职业生涯一路走好的方法。</p>
<hr>
<p><em>1</em> :中文版本 <a href="https://github.com/geminiyellow/the-little-redis-book/blob/master/zh-cn/redis.md">the-little-redis-book</a></p>
<p><em>2</em> :参考 <a href="https://github.com/justinyhuang/the-little-mongodb-book-cn/blob/master/mongodb.md">justinyhuang</a> 的翻译。MongoDB 属于 NoSQL，但是和传统关系型数据库类似，且较为通用。</p>
]]></content>
      <categories>
        <category>NOSQL</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTPS与SSL</title>
    <url>/network/security/HTTPS-SSL/</url>
    <content><![CDATA[<h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><p>HTTPS(Hypertext Transfer Protocol Secure)即安全的HTTP. HTTPS的安全基础是安全套接层(Secure Sockets Layer, SSL). HTTP工作在应用层(OSI模型的最高层), SSL协议工作在一个较低的子层, 位于TCP/IP协议和HTTP协议之间. 在HTTP报文传输前对其加密, 并在到达时对其解密. 严格地讲, HTTPS并不是一个单独的协议, 而是工作在SSL协议上的HTTP协议. </p>
<p>HTTPS，即安全的超文本传输协议，采用了SSL技术，被广泛使用以保证Web应用系统的安全性。访问Web应用的编程接口大多封装了 SSL，使得访问 HTTPS 和访问 HTTP 一样简单。</p>
<p><img src="/images/network/security/https-protocal-ssl.png" alt="img"></p>
<p>HTTPS主要作用有两种：(1)确认通讯双方的身份, (2)建立安全通道, 保证数据传输安全. </p>
<h2 id="HTTPS的主要作用"><a href="#HTTPS的主要作用" class="headerlink" title="HTTPS的主要作用"></a>HTTPS的主要作用</h2><h3 id="确认通讯双方的身份"><a href="#确认通讯双方的身份" class="headerlink" title="确认通讯双方的身份"></a>确认通讯双方的身份</h3><p>HTTPS通讯中, 通过签名技术, 通讯双方可以确认对方身份. 身份认证分为单向认证和双向认证.<br>单向认证中只有服务器端有证书, 双向认证中服务器和客户端都有证书. 一般的HTTPS站点只有服务器有证书, 而客户端无证书. </p>
<p>单向认证是双向认证的简化版. </p>
<h3 id="建立安全通道-保证数据传输安全"><a href="#建立安全通道-保证数据传输安全" class="headerlink" title="建立安全通道, 保证数据传输安全"></a>建立安全通道, 保证数据传输安全</h3><p>基于SSL协议通讯双方可以协商一个用于对称加密的密钥, 该密钥是一个难以破解的随机数, 而且依赖通讯双方的证书、私钥等来协商. 密钥协商好后, 通讯双方用该密钥对数据进行加解密, 从而保证数据安全. </p>
<h2 id="HTTPS与HTTP协议的差异"><a href="#HTTPS与HTTP协议的差异" class="headerlink" title="HTTPS与HTTP协议的差异"></a>HTTPS与HTTP协议的差异</h2><ol>
<li>HTTP 的URL是以”http://“开始, HTTPS的URL是以“https://”开始；</li>
<li>HTTP默认端口为80, HTTPS的默认端口为443；</li>
<li>采用HTTPS的Web Server需要到CA申请证书；</li>
<li>HTTPS由HTTP+SSL来实现, 可进行加密传输、身份认证等, 要比HTTP安全</li>
<li>HTTP的信息是明文传输, 而HTTPS的信息是加密传输　　</li>
</ol>
<h1 id="HTTPS的工作原理"><a href="#HTTPS的工作原理" class="headerlink" title="HTTPS的工作原理"></a>HTTPS的工作原理</h1><p>HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL协议不仅仅是一套加密传输的协议，更是一件经过艺术家精心设计的艺术品，TLS/SSL中使用了非对称加密，对称加密以及HASH算法。握手过程的简单描述如下：</p>
<ol>
<li>浏览器将自己支持的一套加密规则发送给网站。</li>
<li>网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。</li>
<li>获得网站证书之后浏览器要做以下工作：<br>a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。<br>b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。<br>c) 使用约定好的HASH计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。</li>
<li>网站接收浏览器发来的数据之后要做以下的操作：<br>a) 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。<br>b) 使用密码加密一段握手消息，发送给浏览器。</li>
<li>浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。</li>
</ol>
<p>这里浏览器与网站互相发送加密的握手消息并验证，目的是为了保证双方都获得了一致的密码，并且可以正常的加密解密数据，为后续真正数据的传输做一次测试。另外，HTTPS一般使用的加密与HASH算法如下：</p>
<p>非对称加密算法：RSA，DSA/DSS</p>
<p>对称加密算法：AES，RC4，3DES</p>
<p>HASH算法：MD5，SHA1，SHA256</p>
<p>其中非对称加密算法用于在握手过程中加密生成的密码，对称加密算法用于对真正传输的数据进行加密，而HASH算法用于验证数据的完整性。由于浏览器生成的密码是整个数据加密的关键，因此在传输的时候使用了非对称加密算法对其加密。非对称加密算法会生成公钥和私钥，公钥只能用于加密数据，因此可以随意传输，而网站的私钥用于对数据进行解密，所以网站都会非常小心的保管自己的私钥，防止泄漏。</p>
<p><img src="/images/network/security/http-ssl.png"></p>
<h1 id="Java中的HTTPS"><a href="#Java中的HTTPS" class="headerlink" title="Java中的HTTPS"></a>Java中的HTTPS</h1><p>Java 包含了访问 Https 链接的 API，会用到一个关键类 <strong>HttpsURLConnection</strong> ;  参见如下实现代码：</p>
<p>代码1</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建URL对象</span></span><br><span class="line">URL myURL = <span class="keyword">new</span> URL(<span class="string">&quot;https://www.sun.com&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建HttpsURLConnection对象，并设置其SSLSocketFactory对象</span></span><br><span class="line">HttpsURLConnection httpsConn = (HttpsURLConnection) myURL.openConnection();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 取得该连接的输入流，以读取响应内容</span></span><br><span class="line">InputStreamReader insr = <span class="keyword">new</span> InputStreamReader(httpsConn.getInputStream());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取服务器的响应内容并显示</span></span><br><span class="line"><span class="keyword">int</span> respInt = insr.read();</span><br><span class="line"><span class="keyword">while</span> (respInt != -<span class="number">1</span>) &#123;</span><br><span class="line">    System.out.print((<span class="keyword">char</span>) respInt);</span><br><span class="line">    respInt = insr.read();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在取得connection的时候和正常浏览器访问一样，仍然会<strong>验证服务端的证书是否被信任</strong>（权威机构发行或者被权威机构签名）; 如果服务端证书不被信任，则默认的实现就会有问题，一般来说，用<strong>SunJSSE</strong>会抛如下异常信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">javax.net.ssl.SSLHandshakeException:</span><br><span class="line">sun.security.validator.ValidatorException: PKIX path building failed:</span><br><span class="line">sun.security.provider.certpath.SunCertPathBuilderException: unable to</span><br><span class="line">find valid certification path to requested target</span><br></pre></td></tr></table></figure>

<h1 id="JSSE"><a href="#JSSE" class="headerlink" title="JSSE"></a>JSSE</h1><p>Java安全套接扩展 (Java Secure Socket Extension, <code>JSSE</code>) 是实现Internet安全通信的一系列包的集合。它是一个<code>SSL</code>和<code>TLS</code>的纯Java实现，可以透明地提供数据加密、服务器认证、信息完整性等功能，可以使我们像使用普通的套接字一样使用JSSE建立的安全套接字。JSSE是一个开放的标准，不只是Sun公司才能实现一个JSSE，事实上其他公司有自己实现的JSSE。</p>
<h2 id="TrustStore文件"><a href="#TrustStore文件" class="headerlink" title="TrustStore文件"></a>TrustStore文件</h2><p>客户端的 TrustStore 文件。客户端的 TrustStore 文件中保存着被客户端所信任的服务器的证书信息。客户端在进行SSL连接时，JSSE将根据这个文件中的证书决定是否信任服务器端的证书。</p>
<p>JSSE中，有一个信任管理器类负责决定是否信任远端的证书，这个类有如下的处理规则：</p>
<ol>
<li>若系统属性 <strong>javax.net.sll.trustStore</strong> 指定了 TrustStore 文件，那么信任管理器就去jre安装路径下的 lib/security/目录中寻找并使用这个文件来检查证书。</li>
<li>若该系统属性没有指定 TrustStore 文件，它就会去jre安装路径下寻找默认的 TrustStore 文件，这个文件的相对路径为：lib/security/<strong>jssecacerts</strong>。</li>
<li>若 jssecacerts 不存在，但是 cacerts 存在（它随J2SDK一起发行，含有数量有限的可信任的基本证书），那么这个默认的 TrustStore 文件就是 lib/security/<strong>cacerts</strong>。</li>
</ol>
<p>那遇到这种情况，怎么处理呢？有以下两种方案：</p>
<ol>
<li>按照以上信任管理器的规则，<strong>将服务端的公钥(证书)导入到jssecacerts</strong>，或者是在系统属性中设置要加载的 trustStore 文件的路径; 证书导入可以用如下命令：<code>keytool -import -file src_cer_file –keystore dest_cer_store</code> ; 证书可以通过浏览器导出获得; </li>
<li>实现自己的证书信任管理器类，比如 <strong>MyX509TrustManager</strong> ，该类必须实现<code>X509TrustManager</code>接口中的三个method; 然后在HttpsURLConnection中加载自定义的类.</li>
</ol>
<p>　　Java提供了一种非常简洁的方法来访问HTTPS网页，即使用类HttpsURLConnection、URL等。这几个类为支持HTTPS对JSSE相关类做了进一步的封装，例子如下所示：</p>
<p>TrustStore文件中导入了 <code>https://www.oracle.com</code> 的证书，运行代码 1 当使用<code>HttpsUrlConnection</code>访问该网址时，可以正常的访问。然而把访问的URL改为 <code>https://login.bjut.edu.cn</code> 时，程序将抛出异常<code>javax.net.ssl.SSLException</code>，这是由于<code>https://login.bjut.edu.cn</code> 站点的安全证书不被<code>JSSE</code>所信任。根据<code>JSSE</code>简介中对信任管理器的分析，一种解决这个问题的方法是按照信任管理器的处理规则，把站点的证书放到证书库文件<code>jssecacerts</code>中，或者把证书存放到任一 <code>TrustStore</code> 文件中，然后设置系统属性 <code>javax.net.sll.trustStore</code> 指向该文件。另一种解决方法则是自己实现信任管理器类，让它信任我们指定的证书。下面分别介绍这两种方法: </p>
<h2 id="将证书导入到TrustStore文件中"><a href="#将证书导入到TrustStore文件中" class="headerlink" title="将证书导入到TrustStore文件中"></a>将证书导入到TrustStore文件中</h2><p>Java提供了命令行工具keytool用于创建证书或者把证书从其它文件中导入到Java自己的TrustStore文件中。把证书从其它文件导入到TrustStore文件中的命令行格式为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">keytool -import -file src_cer_file –keystore dest_cer_store</span><br></pre></td></tr></table></figure>
<p>　　其中，src_cer_file为存有证书信息的源文件名，dest_cer_store为目标TrustStore文件。</p>
<p>　　在使用<code>keytool</code>之前，首先要取得源证书文件，这个源文件可使用IE浏览器获得，IE浏览器会把访问过的<code>HTTPS</code>站点的证书保存到本地。从IE浏览器导出证书的方法是打开“Internet 选项”，选择“内容”选项卡，点击“证书…”按钮，在打开的证书对话框中，选中一个证书，然后点击“导出…”按钮，按提示一步步将该证书保存到一文件中。最后就可利用keytool把该证书导入到Java的TrustStore文件中。为了能使Java程序找到该文件，应该把这个文件复制到jre安装路径下的<code>lib/security/</code>目录中。</p>
<p>　　这样，只需在程序中设置系统属性<code>javax.net.sll.trustStore</code>指向文件dest_cer_store，就能使JSSE信任该证书，从而使程序可以访问使用未经验证的证书的HTTPS站点。</p>
<p>　　使用这种方法，编程非常简单，但需要手工导出服务器的证书。当服务器证书经常变化时，就需要经常进行手工导出证书的操作。下面介绍的实现X509证书信任管理器类的方法将避免手工导出证书的问题。</p>
<h2 id="X509证书信任管理器类的实现及应用"><a href="#X509证书信任管理器类的实现及应用" class="headerlink" title="X509证书信任管理器类的实现及应用"></a>X509证书信任管理器类的实现及应用</h2><p>　　在JSSE中，证书信任管理器类就是实现了接口<code>X509TrustManager</code>的类。可以自己实现该接口，让它信任我们指定的证书。</p>
<p>　　接口<code>X509TrustManager</code>有下述三个公有的方法需要我们实现：</p>
<p>　　1. <code>void checkClientTrusted(X509Certificate[] chain, String authType)      throws CertificateException</code></p>
<p>　　该方法检查客户端的证书，若不信任该证书则抛出异常。由于我们不需要对客户端进行认证，因此我们只需要执行默认的信任管理器的这个方法。JSSE中，默认的信任管理器类为<code>TrustManager</code>。</p>
<p>　　1. <code>void checkServerTrusted(X509Certificate[] chain, String authType)      throws CertificateException</code></p>
<p>　　该方法检查服务器的证书，若不信任该证书同样抛出异常。通过自己实现该方法，可以使之信任我们指定的任何证书。在实现该方法时，也可以简单的不做任何处理，即一个空的函数体，由于不会抛出异常，它就会信任任何证书。</p>
<p>　　1. <code>X509Certificate[] getAcceptedIssuers()</code></p>
<p>　　返回受信任的X509证书数组。</p>
<p>　　自己实现了信任管理器类，如何使用呢？类<code>HttpsURLConnection</code>似乎并没有提供方法设置信任管理器。其实，<code>HttpsURLConnection</code>通过<code>SSLSocket</code>来建立与HTTPS的安全连接，<code>SSLSocket</code>对象是由<code>SSLSocketFactory</code>生成的。<code>HttpsURLConnection</code>提供了方法<code>setSSLSocketFactory(SSLSocketFactory)</code>设置它使用的<code>SSLSocketFactory</code>对象。<code>SSLSocketFactory</code>通过<code>SSLContext</code>对象来获得，在初始化SSLContext对象时，可指定信任管理器对象。下面用一个图简单表示这几个JSSE类的关系：</p>
<p><img src="/images/java/JSSE-classes.gif" alt="img"></p>
<p>　　假设自己实现的X509TrustManager类的类名为：MyX509TrustManager，下面的代码片断说明了如何使用MyX509TrustManager：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> javax.net.ssl.TrustManager;</span><br><span class="line"><span class="keyword">import</span> javax.net.ssl.TrustManagerFactory;</span><br><span class="line"><span class="keyword">import</span> javax.net.ssl.X509TrustManager;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.security.KeyStore;</span><br><span class="line"><span class="keyword">import</span> java.security.cert.CertificateException;</span><br><span class="line"><span class="keyword">import</span> java.security.cert.X509Certificate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyX509TrustManager</span> <span class="keyword">implements</span> <span class="title">X509TrustManager</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    * The default X509TrustManager returned by SunX509.  We’ll delegate</span></span><br><span class="line"><span class="comment">    * decisions to it, and fall back to the logic in this class if the</span></span><br><span class="line"><span class="comment">    * default X509TrustManager doesn’t trust it.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    X509TrustManager sunJSSEX509TrustManager;</span><br><span class="line"></span><br><span class="line">    MyX509TrustManager() <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"><span class="comment">// create a &quot;default&quot; JSSE X509TrustManager.</span></span><br><span class="line"></span><br><span class="line">        KeyStore ks = KeyStore.getInstance(<span class="string">&quot;JKS&quot;</span>);</span><br><span class="line">        ks.load(<span class="keyword">new</span> FileInputStream(<span class="string">&quot;trustedCerts&quot;</span>),</span><br><span class="line">                <span class="string">&quot;passphrase&quot;</span>.toCharArray());</span><br><span class="line">        TrustManagerFactory tmf =</span><br><span class="line">                TrustManagerFactory.getInstance(<span class="string">&quot;SunX509&quot;</span>, <span class="string">&quot;SunJSSE&quot;</span>);</span><br><span class="line">        tmf.init(ks);</span><br><span class="line">        TrustManager tms[] = tmf.getTrustManagers();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* Iterate over the returned trustmanagers, look</span></span><br><span class="line"><span class="comment">* for an instance of X509TrustManager.  If found,</span></span><br><span class="line"><span class="comment">* use that as our &quot;default&quot; trust manager.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; tms.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (tms[i] <span class="keyword">instanceof</span> X509TrustManager) &#123;</span><br><span class="line">                sunJSSEX509TrustManager = (X509TrustManager) tms[i];</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* Find some other way to initialize, or else we have to fail the</span></span><br><span class="line"><span class="comment">* constructor.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">&quot;Couldn’t initialize&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    * Delegate to the default trust manager.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkClientTrusted</span><span class="params">(X509Certificate[] chain, String authType)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> CertificateException </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            sunJSSEX509TrustManager.checkClientTrusted(chain, authType);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (CertificateException excep) &#123;</span><br><span class="line"><span class="comment">// do any special handling here, or rethrow exception.</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    * Delegate to the default trust manager.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkServerTrusted</span><span class="params">(X509Certificate[] chain, String authType)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> CertificateException </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            sunJSSEX509TrustManager.checkServerTrusted(chain, authType);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (CertificateException excep) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        * Possibly pop up a dialog box asking whether to trust the</span></span><br><span class="line"><span class="comment">        * cert chain.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    * Merely pass this through.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">public</span> X509Certificate[] getAcceptedIssuers() &#123;</span><br><span class="line">        <span class="keyword">return</span> sunJSSEX509TrustManager.getAcceptedIssuers();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用信任管理器创建HTTPS连接</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建SSLContext对象，并使用我们指定的信任管理器初始化</span></span><br><span class="line">TrustManager[] tm = &#123;<span class="keyword">new</span> MyX509TrustManager ()&#125;;</span><br><span class="line">SSLContext sslContext = SSLContext.getInstance(<span class="string">&quot;SSL&quot;</span>,<span class="string">&quot;SunJSSE&quot;</span>);</span><br><span class="line">sslContext.init(<span class="keyword">null</span>, tm, <span class="keyword">new</span> java.security.SecureRandom());</span><br><span class="line"></span><br><span class="line"><span class="comment">//从上述SSLContext对象中得到SSLSocketFactory对象</span></span><br><span class="line">SSLSocketFactory ssf = sslContext.getSocketFactory();</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建HttpsURLConnection对象，并设置其SSLSocketFactory对象</span></span><br><span class="line">HttpsURLConnection httpsConn = (HttpsURLConnection)myURL.openConnection();</span><br><span class="line">httpsConn.setSSLSocketFactory(ssf);</span><br></pre></td></tr></table></figure>


<p>这样，HttpsURLConnection对象就可以正常连接HTTPS了，无论其证书是否经权威机构的验证，只要实现了接口X509TrustManager的类MyX509TrustManager信任该证书。</p>
<p>第一种方式<strong>不会破坏JSSE的安全性</strong>，但是要手工导入证书，如果服务器很多，那每台服务器的JRE都必须做相同的操作; 第二种方式<strong>灵活性更高</strong>，但是要小心实现，否则可能会留下安全隐患; </p>
<h2 id="Java-Key-Store"><a href="#Java-Key-Store" class="headerlink" title="Java Key Store"></a>Java Key Store</h2><p>Java Key Store(JKS)是Java语言中给出的一种密码保护的文件, 可存储密钥和证书. JKS文件好比一个仓库, 为防范别人随便乱拿, 仓库可以设置一把锁, 即JKS文件的密码(storepass). 仓库里可存放多种密钥, 如公钥、私钥和密钥对(由配对公钥和私钥组成). 每个密钥都有一个名字, 称为别名(alias). 仓库里的公钥只要你能进入仓库你就可以随便查看拿走, 私钥则是有密码的(keypass), 只允许有权限的人查看拿走. 所以从JKS文件中读取公钥只需要知道JKS文件(仓库)的密码即可, 但读取私钥时则还必须有私钥的密码[1]. </p>
<h1 id="网站支持SSL"><a href="#网站支持SSL" class="headerlink" title="网站支持SSL"></a>网站支持SSL</h1><ol>
<li>将证书上传到服务器</li>
<li>设置Nignx <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 需要注意：证书路径一定要对，将ssl_certificate 和 ssl_certificate_key的值改成你证书实际存放的路径</span><br><span class="line">server &#123;</span><br><span class="line">    listen 443;</span><br><span class="line">    server_name www.w3ctech.com;</span><br><span class="line">    ssl on;</span><br><span class="line">    ssl_certificate &#x2F;home&#x2F;conf&#x2F;1_www.w3ctech.com_cert.crt;</span><br><span class="line">    ssl_certificate_key &#x2F;home&#x2F;conf&#x2F;2_www.w3ctech.com.key;</span><br><span class="line">    ssl_session_timeout 5m;</span><br><span class="line">    ssl_protocols TLSv1;</span><br><span class="line">    ssl_ciphers HIGH:!aNULL:!MD5;</span><br><span class="line">    ssl_prefer_server_ciphers on;</span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        root html;</span><br><span class="line">        index index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>禁掉80端口 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    #省略其他...</span><br><span class="line">    # http访问时，301跳转至https</span><br><span class="line">    if ($scheme &#x3D; http) &#123;</span><br><span class="line">        return 301 https:&#x2F;&#x2F;$server_name$request_uri;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<p>[参考文献]:</p>
<ol>
<li><a href="http://www.blogjava.net/etlan/archive/2006/06/29/55767.html">导入HTTPS证书</a></li>
<li><a href="http://www.binghe.org/2010/03/use-httpsurlconnection-in-java/">Java中用HttpsURLConnection访问Https链接的问题</a></li>
<li><a href="http://toutiao.com/a6346453007501377794/?iid=5952171257">实现HTTPS，原来如此简单</a></li>
<li><a href="http://blog.jobbole.com/48369/">HTTPS连接的前几毫秒发生了什么</a></li>
<li><a href="http://blog.csdn.net/tenfyguo/article/details/40958727">下】安全HTTPS-全面详解对称加密，非对称加密，数字签名，数字证书和HTTPS</a></li>
<li><a href="http://www.codeceo.com/article/https-make-safe.html">详解Https是如何确保安全的？ – 码农网</a></li>
</ol>
]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Job</tag>
      </tags>
  </entry>
  <entry>
    <title>加密/解密/签名/证书及在Java中的使用</title>
    <url>/network/security/encrypt-decrypt-signature-certificate/</url>
    <content><![CDATA[<blockquote>
<p>本文属于安全专题: 旨在介绍加密和解密相关内容。<br>主要包括：加密解密算法的分类、常见的加密和解密算法以及Java API</p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>这是一种与消息认证码结合使用以确保消息完整性的技术。主要使用单向散列函数算法，可用于检验消息的完整性，<br>和通过散列密码直接以文本形式保存等，目前广泛使用的算法有 MD4、MD5、SHA-1，jdk1.5对上面都提供了支持，<br>在java中进行消息摘要很简单， <code>java.security.MessageDigest</code> 提供了一个简易的操作方法：</p>
<h2 id="MD5"><a href="#MD5" class="headerlink" title="MD5"></a>MD5</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取md5摘要</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> info 要加密的信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> String 获取md5摘要</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">digestWithMD5</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">byte</span>[] digesta = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 得到一个md5的消息摘要</span></span><br><span class="line">        MessageDigest messageDigest = MessageDigest.getInstance(<span class="string">&quot;MD5&quot;</span>);</span><br><span class="line">        <span class="comment">// 添加要进行计算摘要的信息</span></span><br><span class="line">        messageDigest.update(info.getBytes());</span><br><span class="line">        <span class="comment">// 得到该摘要</span></span><br><span class="line">        digesta = messageDigest.digest();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将摘要转为字符串</span></span><br><span class="line">    <span class="keyword">return</span> EncodingUtils.byte2hex(digesta);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SHA"><a href="#SHA" class="headerlink" title="SHA"></a>SHA</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 进行SHA加密</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> info 要加密的信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> String 加密后的字符串</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">digestWithSHA</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">byte</span>[] digesta = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 得到一个SHA-1的消息摘要</span></span><br><span class="line">        MessageDigest messageDigest = MessageDigest.getInstance(<span class="string">&quot;SHA-1&quot;</span>);</span><br><span class="line">        <span class="comment">// 添加要进行计算摘要的信息</span></span><br><span class="line">        messageDigest.update(info.getBytes());</span><br><span class="line">        <span class="comment">// 得到该摘要</span></span><br><span class="line">        digesta = messageDigest.digest();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将摘要转为字符串</span></span><br><span class="line">    <span class="keyword">return</span> EncodingUtils.byte2hex(digesta);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h1><p><a href="/Java/io/object-serialization/">之前的文章</a> 介绍Java对象序列化的时候，曾经提到了对序列化后的对象加密来提高安全性。本文重点介绍<strong>Java的加解密API及其运用</strong>。</p>
<p>消息摘要只能检查消息的完整性，但是单向的，对明文消息并不能加密，要加密明文的消息的话，就要使用其他的算法，要确保机密性，我们需要使用私钥密码术来交换私有消息。　</p>
<p>加密，是对原文进行编码生成难以获取原文的乱码的过程。而解密则是对加密后的文本还原成原文的过程。</p>
<h1 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h1><p>A用一个密钥对一个文件加密，而B读取这个文件的话，则需要和A一样的密钥，双方共享一个私钥（而在web环境下，私钥在传递时容易被侦听）：　　</p>
<p>对称加密, 就是在编码时使用的密钥<code>e</code>和解码时一样<code>d</code>(<code>e=d</code>), 统称为密钥<code>k</code> .</p>
<p> <strong>加解密的过程</strong></p>
<p>发送端用共享密钥<code>k</code>对明文<code>p</code>进行加密, 得到密文<code>c</code>, 并将得到的密文发送给接收端, 接收端收到密文后, 并用其相同的共享密钥k对密文进行解密, 得出明文<code>p</code>.</p>
<p><strong>不足</strong></p>
<ol>
<li>共享密钥：发送方和接收方需要首先共享相同的密钥, 即存在密钥<code>k</code>的分发问题, 如何安全的把共享密钥在双方进行分享, 这本身也是一个如何安全通信的问题:</li>
</ol>
<ul>
<li>一种方法是提前双方约定好, 不通过具体的通信进行协商, 避免被监听和截获.</li>
<li>另一种方式是通过非对称加密信道进行对称密码的分发和共享, 即<strong>混合加密系统</strong>.</li>
</ul>
<ol>
<li>每方一个秘钥：密钥管理的复杂度问题. 由于对称加密的密钥是一对一的使用方式, 若一方要跟n方通信, 则需要维护n对密钥.</li>
</ol>
<p><strong>优点</strong></p>
<p>加密和解密的速度要比非对称加密快很多, 因此常用非对称加密建立的安全信道进行共享密钥的分享, 完成后, 具体的加解密则使用对称加密. 即<code>混合加密系统</code>.</p>
<p>密钥<code>k</code>的长度对解密破解的难度有很重大的影响, <code>k</code>的长度越长, 对应的密码空间就越大, 遭到暴力破解或者词典破解的难度就更大, 就更加安全.</p>
<p>使用私钥加密的话，</p>
<ul>
<li>首先需要一个密钥，可用 <code>javax.crypto.KeyGenerator</code> 产生一个密钥 (<code>java.security.Key</code>),</li>
<li>然后传递给一个加密工具(<code>javax.crypto.Cipher</code>), 该工具再使用相应的算法来进行加密，主要 对称算法有 ES（实际密钥只用到56位），AES（支持三种密钥长度：128、192、256位），通常首先128位，其他的还有DESede等，jdk1.5种也 提供了对对称算法的支持，</li>
</ul>
<p><strong>常见的对称加密算法</strong></p>
<p>一般加密和解密的算法是公开的, 需要保持隐秘的是密钥<code>k</code>, 流行的<code>对称加密</code>算法有：<code>DES</code>, <code>Triple-DES</code>, <code>RC2</code>和<code>RC4</code></p>
<h2 id="创建加密密钥"><a href="#创建加密密钥" class="headerlink" title="创建加密密钥"></a>创建加密密钥</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建对称加密的密匙</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> algorithm 加密算法,可用 DES,DESede,Blowfish</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> SecretKey 秘密（对称）密钥</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> SecretKey <span class="title">createSecretKey</span><span class="params">(String algorithm)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 声明KeyGenerator对象</span></span><br><span class="line">    KeyGenerator keygen;</span><br><span class="line">    <span class="comment">// 声明 密钥对象</span></span><br><span class="line">    SecretKey secretKey = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 返回生成指定算法的秘密密钥的 KeyGenerator 对象</span></span><br><span class="line">        keygen = KeyGenerator.getInstance(algorithm);</span><br><span class="line">        <span class="comment">// 生成一个密钥</span></span><br><span class="line">        secretKey = keygen.generateKey();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回密匙</span></span><br><span class="line">    <span class="keyword">return</span> secretKey;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="加密-1"><a href="#加密-1" class="headerlink" title="加密"></a>加密</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 根据密匙进行DES加密</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> key  密匙</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> info 要加密的信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> String 加密后的信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">encryptByDES</span><span class="params">(SecretKey key, String info)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定义 加密算法,可用 DES,DESede,Blowfish</span></span><br><span class="line">    String algorithm = <span class="string">&quot;DES&quot;</span>;</span><br><span class="line">    <span class="comment">// 加密随机数生成器 (RNG),(可以不写)</span></span><br><span class="line">    SecureRandom secureRandom = <span class="keyword">new</span> SecureRandom();</span><br><span class="line">    <span class="comment">// 定义要生成的密文</span></span><br><span class="line">    <span class="keyword">byte</span>[] cipherByte = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 得到加密/解密器</span></span><br><span class="line">        Cipher cipher = Cipher.getInstance(algorithm);</span><br><span class="line">        <span class="comment">// 用指定的密钥和模式初始化Cipher对象</span></span><br><span class="line">        <span class="comment">// 参数:(ENCRYPT_MODE, DECRYPT_MODE, WRAP_MODE,UNWRAP_MODE)</span></span><br><span class="line">        cipher.init(Cipher.ENCRYPT_MODE, key, secureRandom);</span><br><span class="line">        <span class="comment">// 对要加密的内容进行编码处理,</span></span><br><span class="line">        cipherByte = cipher.doFinal(info.getBytes());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回密文的十六进制形式</span></span><br><span class="line">    <span class="keyword">return</span> EncodingUtils.byte2hex(cipherByte);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="解密"><a href="#解密" class="headerlink" title="解密"></a>解密</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 根据密匙进行DES解密</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> key   密匙</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> sInfo 要解密的密文</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> String 返回解密后信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">decryptByDES</span><span class="params">(SecretKey key, String sInfo)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定义 加密算法,</span></span><br><span class="line">    String algorithm = <span class="string">&quot;DES&quot;</span>;</span><br><span class="line">    <span class="comment">// 加密随机数生成器 (RNG)</span></span><br><span class="line">    SecureRandom secureRandom = <span class="keyword">new</span> SecureRandom();</span><br><span class="line">    <span class="keyword">byte</span>[] cipherByte = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 得到加密/解密器</span></span><br><span class="line">        Cipher cipher = Cipher.getInstance(algorithm);</span><br><span class="line">        <span class="comment">// 用指定的密钥和模式初始化Cipher对象</span></span><br><span class="line">        cipher.init(Cipher.DECRYPT_MODE, key, secureRandom);</span><br><span class="line">        <span class="comment">// 对要解密的内容进行编码处理</span></span><br><span class="line">        cipherByte = cipher.doFinal(EncodingUtils.hex2byte(sInfo));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// return byte2hex(cipherByte);</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> String(cipherByte);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="秘钥共享"><a href="#秘钥共享" class="headerlink" title="秘钥共享"></a>秘钥共享</h2><p>不使用随机因子</p>
<p>//TODO 待完善</p>
<h1 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h1><p>加密的密钥<code>e</code>和解密的密钥<code>d</code>是不同的（<code>e!=d</code>）, 并且加密的密钥<code>e</code>是公开的, 叫做 <code>公钥</code>, 而解密的密钥<code>d</code>是保密的, 叫<code>私钥</code>.</p>
<p>速度很慢（比对称加密慢100到1000倍），公钥的主要算法有RSA，还包括Blowfish,Diffie-Helman 等，jdk1.5种提供了对RSA的支持，是一个改进的地方</p>
<p>RSA算法（由发明者Rivest，Shmir和Adleman姓氏首字母缩写而来）是著名的公开密钥加密算法。</p>
<p>非对称加密的另一用途是身份验证：用私钥加密的信息，可以用公钥对其解密，接收者由此可知这条信息确实来自于拥有私钥的某人。私钥加密的过程即数字签名。</p>
<p>用公钥加密的数据只有私钥才能解密；相反的，用私钥加密的数据只有公钥才能解密，正是这种不对称性才使得公用密钥密码系统被广泛应用。</p>
<p><strong>过程</strong></p>
<p>加密一方使用接收方的公钥<code>e</code> <strong>(如何找到呢？大部分的公钥传递工作实际上都是通过数字证书来实现的)</strong>, 然后用公钥<code>e</code>对明文<code>p</code>进行加密后得到密文<code>c</code>, 并将得到的密文发送给接收方, 接收方收到密文后, 用自己保留的私钥<code>d</code>进行解密, 得到明文<code>p</code>, 需要注意的是：用公钥加密的密文, 只有拥有私钥的一方才能解密, 这样就可以解决加密的各方可以统一使用一个公钥即可.</p>
<p><strong>优点</strong></p>
<ol>
<li>不存在密钥分发的问题, 解码方可以自己生成密钥对, 一个做私钥存起来, 另外一个作为公钥进行发布.</li>
<li>解决了密钥管理的复杂度问题, 多个加密方都可以使用一个已知的公钥进行加密, 但只有拥有私钥的一方才能解密.</li>
</ol>
<p><strong>不足</strong></p>
<p>加解密的速度没有对称加密快.</p>
<p><strong>常见的非对称加密算法</strong></p>
<p>最常见的非对称加密算法就是RSA</p>
<h2 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.security.Key;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.Cipher;</span><br><span class="line"><span class="keyword">import</span> java.security.KeyPairGenerator;</span><br><span class="line"><span class="keyword">import</span> java.security.KeyPair;</span><br><span class="line"></span><br><span class="line"><span class="keyword">byte</span>[] plainText=originString.getBytes(<span class="string">&quot;UTF8&quot;</span>);　　</span><br><span class="line"><span class="comment">//构成一个RSA密钥　</span></span><br><span class="line">System.out.println(<span class="string">&quot;Start generating RSA key&quot;</span>);</span><br><span class="line">KeyPairGenerator keyGen=KeyPairGenerator.getInstance(<span class="string">&quot;RSA&quot;</span>);</span><br><span class="line">keyGen.initialize(<span class="number">1024</span>);　　</span><br><span class="line">KeyPair key=keyGen.generateKeyPair();　</span><br><span class="line">System.out.println(<span class="string">&quot;Finish generating RSA key&quot;</span>);　　</span><br><span class="line"><span class="comment">//获得一个RSA的Cipher类，使用公鈅加密　　</span></span><br><span class="line">Cipher cipher=Cipher.getInstance(<span class="string">&quot;RSA/ECB/PKCS1Padding&quot;</span>);　</span><br><span class="line">System.out.println(<span class="string">&quot;\n&quot;</span>+cipher.getProvider().getInfo());　</span><br><span class="line">System.out.println(<span class="string">&quot;\nStart encryption&quot;</span>);　</span><br><span class="line">cipher.init(Cipher.ENCRYPT_MODE,key.getPublic());　　</span><br><span class="line"><span class="keyword">byte</span>[] cipherText=cipher.doFinal(plainText);　　</span><br><span class="line">System.out.println(<span class="string">&quot;Finish encryption:&quot;</span>);　　</span><br><span class="line">System.out.println(<span class="keyword">new</span> String(cipherText,<span class="string">&quot;UTF8&quot;</span>));　　</span><br><span class="line"><span class="comment">//使用私鈅解密　　</span></span><br><span class="line">System.out.println(<span class="string">&quot;\nStart decryption&quot;</span>);　</span><br><span class="line">cipher.init(Cipher.DECRYPT_MODE,key.getPrivate());　　</span><br><span class="line"><span class="keyword">byte</span>[] newPlainText=cipher.doFinal(cipherText);　　</span><br><span class="line">System.out.println(<span class="string">&quot;Finish decryption:&quot;</span>);　　</span><br><span class="line">String(newPlainText,<span class="string">&quot;UTF8&quot;</span>);</span><br></pre></td></tr></table></figure>

<h1 id="混合加密"><a href="#混合加密" class="headerlink" title="混合加密"></a>混合加密</h1><p>混合加密系统, 比如在两个节点间通过便捷的公开密码加密技术建立起安全通信, 然后再用安全的通信产生并发送临时的随机对称密钥, 通过更快的对称加密技术对剩余的数据进行加密.</p>
<h1 id="Cipher"><a href="#Cipher" class="headerlink" title="Cipher"></a>Cipher</h1><p>KeyGenerator</p>
<p>javax.crypto.KeyGenerator<br>public final SecretKey generateKey()<br>//生成一个密钥</p>
<p>public static final KeyGenerator getInstance(String algorithm)<br>//返回生成指定算法的秘密密钥的KeyGenerator对象。</p>
<p>javax.crypto 接口 SecretKey</p>
<p>javax.crypto.Cipher 此类为加密和解密提供密码功能。它构成了 Java Cryptographic Extension (JCE) 框架的核心</p>
<p>public final void init(int opmode,Key key)</p>
<p>public final byte[] doFinal(byte[] input) 按单部分操作加密或解密数据，或者结束一个多部分操作</p>
<p>java.security.KeyPairGenerator</p>
<p>static KeyPairGenerator getInstance(String algorithm)<br>返回生成指定算法的 public/private 密钥对的 KeyPairGenerator 对象。</p>
<p>java.security.Signature</p>
<p>使用 Signature 对象签名数据或验证签名包括以下三个阶段：</p>
<ol>
<li>初始化，使用<br>初始化验证签名的公钥（请参见 initVerify），或使用<br>初始化签署签名的私钥（也可以选择“安全随机数生成器”）initSign(PrivateKey)和initSign(PrivateKey, SecureRandom)）。</li>
<li>更新<br>根据初始化类型，这可更新要签名或验证的字节。请参见 update 方法。</li>
<li>签署或验证所有更新字节的签名。请参见 sign 方法和 verify 方法。</li>
</ol>
<h1 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h1><p>上面讨论了非对称加密技术在编码中的使用, 解决的是传送数据的私密性, 一般是用公钥作为<code>加密key</code>, 而私钥作为解密<code>key</code>, 那假如是用私钥作为加密key, 而公钥作为解密key呢？<br>java中为数字签名提供了良好的支持，<code>java.security.Signature</code> 类提供了消息签名：</p>
<blockquote>
<p>这里要求私钥加密后公钥可解密</p>
</blockquote>
<p>由于私钥只有对应一方才知道, 因此若通过对应的公钥可以验证对方是用对应的私钥进行加密的, 则可以说明对方的身份, 这就是<strong>数字签名</strong>.</p>
<p> 数字签名需要解决的两个任务是：</p>
<ol>
<li>谁编写的报文；</li>
<li>报文的内容是否被篡改过；</li>
</ol>
<p>数字签名的过程一般如下：</p>
<ol>
<li><em>发送方A</em> 首先对变长的报文提取成一个定长的摘要, 一般是<code>md5</code>等</li>
<li><em>A</em> 对摘要应用了一个签名函数, 并且用自己的私钥作为参数, 因为只有<em>A</em>才知道私钥, 所以正确的签名会说明签名者就是其所有者.</li>
<li>一旦计算出签名, 节点<em>A</em>就将其附加到报文的末尾, 并将报文和签名一起都发送给<em>B</em></li>
<li>在<em>接收端B</em>, 首先会按照同样的算法计算出报文的摘要, 然后对签名用<em>A</em>的公钥进行解码, 得出解码后的摘要, 两个摘要进行比较, 则可以<strong>判断是否是<em>A</em>发送的且内容没被篡改过</strong>.</li>
</ol>
<p><img src="/images/network/security/validateSign.png" alt="数字签名"></p>
<h2 id="创建公钥和私钥"><a href="#创建公钥和私钥" class="headerlink" title="创建公钥和私钥"></a>创建公钥和私钥</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建密匙组，并将公匙，私匙放入到指定文件中</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 默认放入mykeys.bat文件中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createPairKeyWithDSA</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 根据特定的算法一个密钥对生成器</span></span><br><span class="line">        KeyPairGenerator keygen = KeyPairGenerator.getInstance(<span class="string">&quot;DSA&quot;</span>);</span><br><span class="line">        <span class="comment">// 加密随机数生成器 (RNG)</span></span><br><span class="line">        SecureRandom random = <span class="keyword">new</span> SecureRandom();</span><br><span class="line">        <span class="comment">// 重新设置此随机对象的种子</span></span><br><span class="line">        random.setSeed(<span class="number">1000</span>);</span><br><span class="line">        <span class="comment">// 使用给定的随机源（和默认的参数集合）初始化确定密钥大小的密钥对生成器</span></span><br><span class="line">        keygen.initialize(<span class="number">512</span>, random);<span class="comment">// keygen.initialize(512);</span></span><br><span class="line">        <span class="comment">// 生成密钥组</span></span><br><span class="line">        KeyPair keys = keygen.generateKeyPair();</span><br><span class="line">        <span class="comment">// 得到公匙</span></span><br><span class="line">        PublicKey pubkey = keys.getPublic();</span><br><span class="line">        <span class="comment">// 得到私匙</span></span><br><span class="line">        PrivateKey prikey = keys.getPrivate();        </span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="DSA签名"><a href="#DSA签名" class="headerlink" title="DSA签名"></a>DSA签名</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 利用私匙对信息进行签名 把签名后的信息放入到指定的文件中</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> info     要签名的信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> signfile 存入的文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">signWithDSA</span><span class="params">(String info, String signfile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 从文件当中读取私匙</span></span><br><span class="line">    PrivateKey myprikey = ...;</span><br><span class="line">    <span class="comment">// 从文件中读取公匙</span></span><br><span class="line">    PublicKey mypubkey = ...;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// Signature 对象可用来生成和验证数字签名</span></span><br><span class="line">        Signature signet = Signature.getInstance(<span class="string">&quot;DSA&quot;</span>);</span><br><span class="line">        <span class="comment">// 初始化签署签名的私钥</span></span><br><span class="line">        signet.initSign(myprikey);</span><br><span class="line">        <span class="comment">// 更新要由字节签名或验证的数据</span></span><br><span class="line">        signet.update(info.getBytes());</span><br><span class="line">        <span class="comment">// 签署或验证所有更新字节的签名，返回签名</span></span><br><span class="line">        <span class="keyword">byte</span>[] signed = signet.sign();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="验证DSA签名"><a href="#验证DSA签名" class="headerlink" title="验证DSA签名"></a>验证DSA签名</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 读取数字签名文件 根据公匙，签名，信息验证信息的合法性</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> true 验证成功 false 验证失败</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">validateSignWithDSA</span><span class="params">(String signfile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 读取公匙</span></span><br><span class="line">    PublicKey mypubkey = ...;</span><br><span class="line">    <span class="comment">// 读取签名</span></span><br><span class="line">    <span class="keyword">byte</span>[] signed =...;</span><br><span class="line">    <span class="comment">// 读取信息</span></span><br><span class="line">    String info = ...;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 初始一个Signature对象,并用公钥和签名进行验证</span></span><br><span class="line">        Signature signetcheck = Signature.getInstance(<span class="string">&quot;DSA&quot;</span>);</span><br><span class="line">        <span class="comment">// 初始化验证签名的公钥</span></span><br><span class="line">        signetcheck.initVerify(mypubkey);</span><br><span class="line">        <span class="comment">// 使用指定的 byte 数组更新要签名或验证的数据</span></span><br><span class="line">        signetcheck.update(info.getBytes());</span><br><span class="line">        System.out.println(info);</span><br><span class="line">        <span class="comment">// 验证传入的签名</span></span><br><span class="line">        <span class="keyword">return</span> signetcheck.verify(signed);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="数字证书和CA"><a href="#数字证书和CA" class="headerlink" title="数字证书和CA"></a>数字证书和CA</h1><h2 id="3-1-确认主机的真实性"><a href="#3-1-确认主机的真实性" class="headerlink" title="3.1. 确认主机的真实性"></a>3.1. 确认主机的真实性</h2><p>**采用https 的server（服务器）必须从CA（Certificate Authority）申请一个用于证明服务器用途类型的数字证书（或者叫CA证书）.该证书只有用于对应的server 时，客户端才信任此主机. **</p>
<p>CA（Certificate Authority）即”认证机构”，是负责签发证书、认证证书、管理已颁发证书的机构，是PKI（Public Key Infrastructure，公钥基础设施）的核心。它要制定政策和具体步骤来验证、识别用户身份，并对用户证书进行签名，以确保证书持有者的身份和公钥的拥有权。</p>
<p><strong>CA 也拥有一个证书（内含公钥）和私钥</strong>。网上的公众用户通过验证 CA 的签字从而信任CA ，任何人都可以得到 CA 的证书（含公钥），用以验证它所签发的证书。</p>
<p> </p>
<h2 id="3-2-什么是数字证书"><a href="#3-2-什么是数字证书" class="headerlink" title="3.2. 什么是数字证书"></a>3.2. 什么是数字证书</h2><p><strong>数字证书（</strong>CA证书是经过认证的数字证书<strong>）</strong>是一个用于互联网通讯中认证身份的工具，由权威机构——CA机构（Certificate Authority）发行。其作用类似于司机的驾驶执照和公民身份证。CA作为公正的第三方来确保证书的有效性[6]。全国存在多个CA机构（只要你有公信力你也可以成立一家CA机构）。</p>
<p><strong>数字证书包含一个公钥以及该密钥所有者的信息。证书还标明有有效期，并通过另一密钥（CA私钥）进行签名，</strong>该密钥能保证这些属性的真实性，最重要的是，保证公钥本身的真实性[14]。最简单的证书包含一个<strong>公钥</strong>、名称以及证书授权中心的数字签名（<strong>公开密钥只是证书的一部分内容</strong>）。目前，证书的格式和验证方法普遍遵循<strong>X.509</strong> 国际标准。</p>
<p>CA机构自身也拥有一个<strong>证书</strong>（<strong>内含公钥</strong>）和一个<strong>私钥。</strong></p>
<p><strong>用户如果想得到一个数字证书，他应先向 CA申请，CA审查申请者的身份后，给他分配一个公钥，并将公钥与申请者的身份信息绑在一起，同时用自己的私钥签字，最终生成一个证书，发给申请者；同时还将一个与公钥关联的私钥也发给申请者。证书的内容主要有：CA信息、CA签字、证书拥有者信息、证书公钥和证书有效期等。</strong></p>
<p>某人需要验证一个证书时，用签发该证书的CA的公钥来解密其签名信息，以验证证书是否可信。CA证书也需要验证，验证CA证书是一个递归上溯的过程，验证过程终止于根证书。<strong>根证书是一份特殊的证书，它的签发者是它本身，下载根证书就表明用户对该根证书，以及其所签发的证书都信任。</strong></p>
<p><img src="http://img.blog.csdn.net/20141109225903192?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdGVuZnlndW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p> </p>
<h2 id="3-3-数字证书基本原理"><a href="#3-3-数字证书基本原理" class="headerlink" title="3.3. 数字证书基本原理"></a>3.3. 数字证书基本原理</h2><p>数字证书采用<strong>公开密钥加密体制</strong>，利用一个强关联的密钥对进行加、解密。证书拥有者保存好自己的私钥，用它进行解密和签名；并把公钥公开，供一组用户所共享，用于加密和验证签名。</p>
<p>1、<strong>加密：</strong>发送数据时，发送方使用接收方的公钥对数据加密，接收方用私钥解密，还原消息。算法保证公钥加密的数据只有对应的<strong>私钥</strong>才能解密。</p>
<p>2、<strong>数字签名：</strong>证书拥有者用私钥对信息进行加密，由于私钥仅为本人所有，这样就生成了别人无法伪造的数据，该数据即<strong>数字签名</strong>。采用数字签名，能够确认以下两点：</p>
<p>（1）保证信息是由签名者所发送，签名者不能否认或者难以否认；</p>
<p>（2）保证信息自签发后到收到为止，未曾做过任何修改，签发的文件是真实的文件。</p>
<p>算法保证只有公钥才能解开私钥加密的信息。</p>
<h2 id="3-4-如何生成数字证书"><a href="#3-4-如何生成数字证书" class="headerlink" title="3.4. 如何生成数字证书"></a>3.4. 如何生成数字证书</h2><p>略</p>
<p> </p>
<p>A用私钥加密了，那么B接受到消息后，用A提供的公钥解密；那么现在有个讨厌的C，他把消息拦截了，然后用自己的私 钥加密，同时把自己的公钥发给B，并告诉B，那是A的公钥，结果….，这时候就需要一个中间机构出来说话了（相信权威，我是正确的），就出现了 Certificate Authority(也即CA），有名的CA机构有Verisign等，目前数字认证的工业标准是：CCITT的X.509：数字证书：它将一个身份标识连同公钥一起进行封装，并由称为认证中心或 CA 的第三方进行数字签名。</p>
<p><strong>实际上, 好多的公钥都是通过数字证书进行发布的</strong>, 数字证书类似一个人的身份证一样, 由对应的官方的颁发结构颁发的, 类似一个人的身份证有姓名, 身份证ID, 有效期, 颁发机构-一般是某某派出所等, 数字证书也有类似的形式.</p>
<p>基本的数字证书包括了一些常见的信息：</p>
<ol>
<li>对象的名称（人, 服务器, 组织等）</li>
<li>过期时间</li>
<li>对象的公钥</li>
<li>证书发布者（由谁为证书担保）</li>
<li>来自证书发布者的数字签名.<br>…</li>
</ol>
<p>需要注意的是, 任何人都可以创建一个证书, 但不是所有人都能够获得受人尊敬的签发权从而为证书信息提供担保, 并用其私人密钥签发证书.</p>
<p>不幸的是, 数字证书没有单一的全球标准, 但现在使用的大多数证书是以一种标准格式– <code>X.509 v3</code>, 来存储它们的信息.</p>
<p>x.509证书格式：</p>
<table>
<thead>
<tr>
<th><strong>字段</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>版本号</td>
<td>这个证书的X.509证书版本号, 现在通常是版本3</td>
</tr>
<tr>
<td>序列号</td>
<td>证书颁发机构CA生成的唯一整数, CA生成的每个证书都要有一个唯一的系列号, 类似身份证号码</td>
</tr>
<tr>
<td>签名算法ID</td>
<td>签名使用是算法, 如用RSA加密的MD2摘要</td>
</tr>
<tr>
<td>证书颁发者</td>
<td>以X.500格式说明的CA的组织名称</td>
</tr>
<tr>
<td>有效期</td>
<td>证书的有效期, 由一个起始日期和一个结束日期来表示</td>
</tr>
<tr>
<td>对象名称</td>
<td>证书中描述的实体, 比如一个人或者一个组织, 对象名称以x.500格式表示</td>
</tr>
<tr>
<td>对象的公开密钥信息</td>
<td>证书对象的公钥, 公钥使用的算法, 以及所有附加的参数</td>
</tr>
<tr>
<td>发布者唯一的ID(可选)</td>
<td>可选的证书发布者唯一ID, 这样可以重用相同的发布者名称了</td>
</tr>
<tr>
<td>对象唯一的ID（可选)</td>
<td>可选的证书对象唯一ID, 这样就可以重用相同的对象名称了</td>
</tr>
<tr>
<td>扩展</td>
<td>一些扩展信息</td>
</tr>
<tr>
<td>证书的颁发机构签名</td>
<td>CA用指定的签名算法对上述所有字段的数字签名</td>
</tr>
</tbody></table>
<p>x.509证书有很多种, 如服务器端证书, 个人证书等. 每个证书均有对应于证书公钥的私钥, 私钥不能被导出, 访问一般需要密码等. 浏览器会默认存储一些受信任的根证书颁发机构的证书.</p>
<h2 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h2><h3 id="客户端对服务器认证"><a href="#客户端对服务器认证" class="headerlink" title="客户端对服务器认证"></a>客户端对服务器认证</h3><p>在支付网站中, 用户需要确认他们输入支付密码的站点是真正的经过认证的站点, 而不是被钓鱼的网站, 因此用户有必要认证对应的服务器, 而这种方式是通过服务器证书来进行的. 过程大概如下：</p>
<ol>
<li><p>通过https建立一个安全web事务之后, 浏览器会自动获取所连服务器的数字证书；</p>
<p> 其中服务器证书包括了：</p>
<p> Web站点名称和主机名<br> Web站点的公钥<br> 颁发机构的名称<br> 颁发机构给证书的签名</p>
</li>
<li><p>若服务器<strong>没有证书</strong>, 则安全连接失败.</p>
</li>
<li><p>浏览器首先检查服务器<strong>证书是否还在有效期</strong>内, 若过期, 则提示失效；</p>
</li>
<li><p>浏览器查看服务器证书对应的CA, 若该CA是很权威的机构, 则浏览器可能已经知道了对应的公钥了（<strong>浏览器会预先安装很多签名颁发机构的证书并认为是受信任的</strong>）, 这时, 浏览器用CA的数字证书里面的公钥来<strong>验证</strong>该CA颁发的服务器<strong>证书</strong>的有效性. 类似去公安局验证某人的身份证是否是真的.</p>
</li>
<li><p>若浏览器对签名颁发机构CA一无所知, 浏览器<strong>无法确定</strong>是否该信任这个签名颁发机构, 它通常会向用户<strong>提示</strong>一个对话框, 看看他是否相信这个签名发布者.</p>
</li>
<li><p>一旦完成了对服务器证书的验证, 接下来就可以<strong>使用服务器证书</strong>里面的<strong>公钥</strong>进行服务器身份的<strong>验证</strong>；</p>
</li>
<li><p>客户端生成一个<strong>随机数</strong>给到服务器, 要求对应服务器用证书的<strong>私钥</strong>进行<strong>签名</strong>.</p>
</li>
<li><p>服务器对随机数进行签名, 并回传给到客户端.</p>
</li>
<li><p>客户端用服务器证书的<strong>公钥</strong>对<strong>随机数</strong>的<strong>签名</strong>进行<strong>验证</strong>, 若验证通过, 则说明对应的服务器确实拥有对应服务器证书的私钥, 因此判断服务器的身份正常. 否则, 则任务服务器身份被伪造.</p>
</li>
</ol>
<h3 id="服务器对客户端认证"><a href="#服务器对客户端认证" class="headerlink" title="服务器对客户端认证"></a>服务器对客户端认证</h3><p>客户端证书和服务器证书类似, 只是服务器证书增加一些对服务器站点名称和主机名等内容的签注, 客户端证书一般是某个机构针对个人颁发的, 用于标识个人的身份. 如财付通提示用户安装对应的数字证书, 就是一个客户端证书, <strong>在安装客户端证书的时候, 实际上会把用户对应该证书的私钥要保存起来.</strong> 客户端用私钥进行签名, 然后第三方用客户端证书的公钥进行验签实现对客户端身份的认证.</p>
<h3 id="双向认证"><a href="#双向认证" class="headerlink" title="双向认证"></a>双向认证</h3><p>在发送已加密的HTTP报文前, 客户端和服务器要进行一次SSL握手, 在这个握手的过程中, 它们要完成以下工作：</p>
<ol>
<li>  交换协议版本号；</li>
<li>  选择一个两端都了解的密码；</li>
<li>  对两端的身份进行验证；</li>
<li>  生成临时的会话密钥, 后续便用该密钥进行加密信道.</li>
</ol>
<h3 id="信任所有的证书"><a href="#信任所有的证书" class="headerlink" title="信任所有的证书"></a>信任所有的证书</h3><h3 id="密钥库"><a href="#密钥库" class="headerlink" title="密钥库"></a>密钥库</h3><p>java平台为你提供了密钥库，用作密钥和证书的资源库。从物理上讲，密钥库是缺省名称为 <code>.keystore</code> 的文件（有一个选项使它成为加密文件）。密钥和证书可以拥有名称（称为别名），每个别名都由唯一的密码保护。密钥库本身也受密码保护；您可以选择让每个别名密码与主密钥库密码匹配。　　</p>
<p>使用工具keytool，我们来做一件自我认证的事情吧（相信我的认证）：　　</p>
<ol>
<li><p>创建密钥库<br><code>keytool -genkey -v -alias feiUserKey -keyalg RSA</code><br>默认在自己的home目录下（windows系统是c:\documents and settings&lt;你的用户名&gt; 目录下的.keystore文件），创建我们用 RSA 算法生成别名为 feiUserKey 的自签名的证书,如果使用了-keystore mm 就在当前目录下创建一个密钥库mm文件来保存密钥和证书。　</p>
</li>
<li><p>查看证书：<br><code>keytool -list</code> 列举了密钥库的所有的证书　　也可以在dos下输入<br><code>keytool -help</code> 查看帮助。</p>
</li>
<li><p>JAR的签名　　</p>
</li>
</ol>
<p>JAR文件在Java中相当于 ZIP 文件，允许将多个 Java 类文件打包到一个具有 .jar 扩展名的文件中，然后可以对这个jar文件进行数字签名，以证实其来源和真实性。该 JAR 文件的接收方可以根据发送方的签名决定是否信任该代码，并可以确信该内容在接收之前没有被篡改过。同时在部署中，可以通过在策略文件中放置访问控制语句根据签名者的身份分配对机器资源的访问权。这样，有些Applet的安全检验访问就得以进行。　　</p>
<p>使用<code>jarsigner</code>工具可以对jar文件进行签名：　　</p>
<p>现在假设我们有个Test.jar文件（可以使用jar命令行工具生成）：　　</p>
<p><code>jarsigner Test.jar feiUserKey</code> (这里我们上面创建了该别名的证书) ，详细信息可以输入<code>jarsigner</code>查看帮助　　</p>
<p>验证其真实性：<code>jarsigner -verify　Test.jar</code><br>(注意，验证的是jar是否被修改了，但不检验减少的，如果增加了新的内容，也提示，但减少的不会提示。）　　</p>
<p>使用Applet中：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&lt;applet code=&quot;Test.class&quot; archive=&quot;Test.jar&quot; width=&quot;150&quot; height=&quot;100&quot;&gt;&lt;/applet&gt;</span><br></pre></td></tr></table></figure>
<p>然后浏览器就会提示你：准许这个会话-拒绝-始终准许-查看证书等。　　</p>
<h2 id="安全套接字层（SSL-Secure-Sockets-Layer）和传输层安全性（TLS-Transport-Layer-Security）"><a href="#安全套接字层（SSL-Secure-Sockets-Layer）和传输层安全性（TLS-Transport-Layer-Security）" class="headerlink" title="安全套接字层（SSL Secure Sockets Layer）和传输层安全性（TLS Transport Layer Security）"></a>安全套接字层（SSL Secure Sockets Layer）和传输层安全性（TLS Transport Layer Security）</h2><p>安全套接字层和传输层安全性是用于在客户机和服务器之间构建安全的通信通道的协议。它也用来为客户机认证服务器，以及（不太常用的）为服务器认证客户机。该协议在浏览器应用程序中比较常见，浏览器窗口底部的锁表明 SSL/TLS 有效：　　</p>
<p>1）当使用 SSL/TLS（通常使用 https:// URL）向站点进行请求时，从服务器向客户机发送一个证书。客户机使用已安装的公共 CA 证书通过这个证书验证服务器的身份，然后检查 IP 名称（机器名）与客户机连接的机器是否匹配。　　</p>
<p>2）客户机生成一些可以用来生成对话的私钥（称为会话密钥）的随机信息，然后用服务器的公钥对它加密并将它发送到服务器。服务器用自己的私钥解密消息，然后用该随机信息派生出和客户机一样的私有会话密钥。通常在这个阶段使用 RSA 公钥算法。　　</p>
<p>3）客户机和服务器使用私有会话密钥和私钥算法（通常是 RC4）进行通信。使用另一个密钥的消息认证码来确保消息的完整性。java中<code>javax.net.ssl.SSLServerSocketFactory</code>类提供了一个很好的SSLServerSocker的工 厂类，熟悉Socket编程的读者可以去练习。当编写完服务器端之后，在浏览器上输入https://主机名:端口就会通过SSL/TLS进行通话了。</p>
<p>注 意：运行服务端的时候要带系统环境变量运行：<br><code>javax.net.ssl.keyStore=密钥库</code>(创建证书时，名字应该为主机名，<br>比如 localhost)和<br><code>javax.net.ssl.keyStorePassword=你的密码</code></p>
<hr>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]:"></a>[参考文献]:</h1><ol>
<li>[安全专题][a-security]</li>
<li><a href="http://blog.csdn.net/tenfyguo/article/details/40922813">安全HTTPS-全面详解对称加密，非对称加密，数字签名，数字证书和HTTPS</a></li>
<li><a href="">Applied Crypotography(Bruce Schneier)</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Job</tag>
      </tags>
  </entry>
  <entry>
    <title>ElasticSearch开发基础</title>
    <url>/bigdata/ElasticSearch/ElasticSearch/</url>
    <content><![CDATA[<h1 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h1><p>Es 基于lucene</p>
<p>Elasticsearch 是一个分布式、可扩展、实时的搜索与数据分析引擎。</p>
<p><a href="https://github.com/oldratlee/useful-scripts">ES分析脚本</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink-outline</title>
    <url>/bigdata/Flink/00.Flink-outline/</url>
    <content><![CDATA[<h1 id="00-Flink-outline"><a href="#00-Flink-outline" class="headerlink" title="00.Flink-outline"></a>00.Flink-outline</h1><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://github.com/crestofwave1/oneFlink">Flink官方文档翻译</a></li>
</ul>
<h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><h2 id="checkpoint与savepoint区别"><a href="#checkpoint与savepoint区别" class="headerlink" title="checkpoint与savepoint区别"></a>checkpoint与savepoint区别</h2><h2 id="flink-report"><a href="#flink-report" class="headerlink" title="flink report"></a>flink report</h2><h2 id="storm-trident"><a href="#storm-trident" class="headerlink" title="storm trident"></a>storm trident</h2><p>微批</p>
<p>barrier对齐</p>
<p><img src="_v_images/20190826164001201_1759200368.png" alt="flink-rm"></p>
<h2 id="算子"><a href="#算子" class="headerlink" title="算子"></a>算子</h2><h3 id="Reduce在流计算的应用"><a href="#Reduce在流计算的应用" class="headerlink" title="Reduce在流计算的应用"></a>Reduce在流计算的应用</h3><p>org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor$LoggingHandler:140 -<br>Timestamp monotony violated: 1568772496000 &lt; 1568772500000</p>
<p>ToDo list</p>
<h1 id="avro-与-kryo-序列化的区别"><a href="#avro-与-kryo-序列化的区别" class="headerlink" title="avro 与 kryo 序列化的区别"></a>avro 与 kryo 序列化的区别</h1><p>使用场景</p>
<h2 id="storm-allGrouping-元素广播"><a href="#storm-allGrouping-元素广播" class="headerlink" title="storm allGrouping 元素广播"></a>storm allGrouping 元素广播</h2><p>flink broadcast how to use </p>
<p>broadcast vaiable value can not be modified</p>
<p>用法<br>1：初始化数据<br>DataSet<Integer> toBroadcast = env.fromElements(1, 2, 3)<br>2：广播数据<br>.withBroadcastSet(toBroadcast, “broadcastSetName”);<br>3：获取数据<br>Collection<Integer> broadcastSet = getRuntimeContext().getBroadcastVariable(“broadcastSetName”);</p>
<ul>
<li>广播变量不能太大</li>
<li>不能修改，保证数据一致性</li>
</ul>
<h1 id="Accumulators-amp-Counters"><a href="#Accumulators-amp-Counters" class="headerlink" title="Accumulators &amp; Counters"></a>Accumulators &amp; Counters</h1><p>累加器与计数器</p>
<h2 id="spark-accumulate"><a href="#spark-accumulate" class="headerlink" title="spark accumulate"></a>spark accumulate</h2><p>用法<br>1：创建累加器<br>private IntCounter numLines = new IntCounter();<br>2：注册累加器<br>getRuntimeContext().addAccumulator(“num-lines”, this.numLines);<br>3：使用累加器<br>this.numLines.add(1);<br>4：获取累加器的结果<br>myJobExecutionResult.getAccumulatorResult(“num-lines”)</p>
<h1 id="Distributed-Cache"><a href="#Distributed-Cache" class="headerlink" title="Distributed Cache"></a>Distributed Cache</h1><blockquote>
<p>Spark 分布式缓存如何使用</p>
</blockquote>
<p>Flink提供了一个分布式缓存，类似于hadoop，可以使用户在并行函数中很方便的读取本地文件<br>此缓存的工作机制如下：程序注册一个文件或者目录(本地或者远程文件系统，例如hdfs或者s3)，通过ExecutionEnvironment注册缓存文件并为它起一个名称。当程序执行，Flink自动将文件或者目录复制到所有taskmanager节点的本地文件系统，用户可以通过这个指定的名称查找文件或者目录，然后从taskmanager节点的本地文件系统访问它<br>用法<br>1：注册一个文件<br>env.registerCachedFile(“hdfs:///path/to/your/file”, “hdfsFile”)<br>2：访问数据<br>File myFile = getRuntimeContext().getDistributedCache().getFile(“hdfsFile”);</p>
<h1 id="at-least-once-amp-exactly-once"><a href="#at-least-once-amp-exactly-once" class="headerlink" title="at least once &amp; exactly once"></a>at least once &amp; exactly once</h1><p>从容错和消息处理的语义上(at least once, exactly once)，Flink引入了state和checkpoint。</p>
<h1 id="state"><a href="#state" class="headerlink" title="state"></a>state</h1><p>默认保存在java堆中<br>checkpoint: 把state持久化存储，全局快照<br>blink做的优化</p>
<p>失败恢复机制 </p>
<p>状态分为原始状态和托管状态</p>
<p>托管状态是由Flink框架管理的状态<br>而原始状态，由用户自行管理状态具体的数据结构，框架在做checkpoint的时候，使用byte[]来读写状态内容，对其内部数据结构一无所知。<br>通常在DataStream上的状态推荐使用托管的状态，当实现一个用户自定义的operator时，会使用到原始状态。</p>
<blockquote>
<p>ReducingState 如何使用</p>
</blockquote>
<h1 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>Flink的checkpoint机制可以与(stream和state)的持久化存储交互的前提：<br>持久化的source，它需要支持在一定时间内重放事件。这种sources的典型例子是持久化的消息队列（比如Apache Kafka，RabbitMQ等）或文件系统（比如HDFS，S3，GFS等）<br>用于state的持久化存储，例如分布式文件系统（比如HDFS，S3，GFS等）</p>
<p>Checkpoint是Flink实现容错机制最核心的功能，它能够根据配置周期性地基于Stream中各个Operator/task的状态来生成快照，从而将这些状态数据定期持久化存储下来，当Flink程序一旦意外崩溃时，重新运行程序时可以有选择地从这些快照进行恢复，从而修正因为故障带来的程序数据异常</p>
<p>checkpoint开启之后，默认的checkPointMode是Exactly-once<br>checkpoint的checkPointMode有两种，Exactly-once和At-least-once<br>Exactly-once对于大多数应用来说是最合适的。At-least-once可能用在某些延迟超低的应用程序（始终延迟为几毫秒）</p>
<p>ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION:表示一旦Flink处理程序被cancel后，会保留Checkpoint数据，以便根据实际需要恢复到指定的Checkpoint<br>ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION: 表示一旦Flink处理程序被cancel后，会删除Checkpoint数据，只有job执行失败的时候才会保存checkpoint</p>
<h1 id="state-backend"><a href="#state-backend" class="headerlink" title="state backend"></a>state backend</h1><p>默认情况下，state会保存在taskmanager的内存中，checkpoint会存储在JobManager的内存中。<br>state 的store和checkpoint的位置取决于State Backend的配置<br>env.setStateBackend(…)<br>一共有三种State Backend<br>MemoryStateBackend<br>FsStateBackend<br>RocksDBStateBackend</p>
<p>MemoryStateBackend<br>state数据保存在java堆内存中，执行checkpoint的时候，会把state的快照数据保存到jobmanager的内存中<br>基于内存的state backend在生产环境下不建议使用<br>FsStateBackend<br>state数据保存在taskmanager的内存中，执行checkpoint的时候，会把state的快照数据保存到配置的文件系统中<br>可以使用hdfs等分布式文件系统<br>RocksDBStateBackend<br>RocksDB跟上面的都略有不同，它会在本地文件系统中维护状态，state会直接写入本地rocksdb中。同时它需要配置一个远端的filesystem uri（一般是HDFS），在做checkpoint的时候，会把本地的数据直接复制到filesystem中。fail over的时候从filesystem中恢复到本地<br>RocksDB克服了state受内存限制的缺点，同时又能够持久化到远端文件系统中，比较适合在生产中使用</p>
<p>修改State Backend的两种方式<br>第一种：单任务调整<br>修改当前任务代码<br>env.setStateBackend(new FsStateBackend(“hdfs://namenode:9000/flink/checkpoints”));<br>或者new MemoryStateBackend()<br>或者new RocksDBStateBackend(filebackend, true);【需要添加第三方依赖】<br>第二种：全局调整<br>修改flink-conf.yaml<br>state.backend: filesystem<br>state.checkpoints.dir: hdfs://namenode:9000/flink/checkpoints<br>注意：state.backend的值可以是下面几种：jobmanager(MemoryStateBackend), filesystem(FsStateBackend), rocksdb(RocksDBStateBackend)</p>
<h1 id="Restart-Strategies-重启策略"><a href="#Restart-Strategies-重启策略" class="headerlink" title="Restart Strategies(重启策略)"></a>Restart Strategies(重启策略)</h1><p>默认重启策略通过 flink-conf.yaml 指定</p>
<p>常用的重启策略<br>固定间隔 (Fixed delay)<br>失败率 (Failure rate)<br>无重启 (No restart)<br>如果没有启用 checkpointing，则使用无重启 (no restart) 策略。<br>如果启用了 checkpointing，但没有配置重启策略，则使用固定间隔 (fixed-delay) 策略，其中 Integer.MAX_VALUE 参数是尝试重启次数<br>重启策略可以在flink-conf.yaml中配置，表示全局的配置。也可以在应用代码中动态指定，会覆盖全局配置</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">第一种：全局配置 flink-conf.yaml</span><br><span class="line">restart-strategy: fixed-delay</span><br><span class="line">restart-strategy.fixed-delay.attempts: <span class="number">3</span></span><br><span class="line">restart-strategy.fixed-delay.delay: <span class="number">10</span> s</span><br><span class="line">第二种：应用代码设置</span><br><span class="line">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 尝试重启的次数</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 间隔</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure>






<h2 id="Flink-table"><a href="#Flink-table" class="headerlink" title="Flink table"></a>Flink table</h2><h3 id="over-window"><a href="#over-window" class="headerlink" title="over window"></a>over window</h3><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul>
<li><input disabled="" type="checkbox"> Flink Table API office</li>
<li><input disabled="" type="checkbox"> 自定义窗口</li>
<li><input disabled="" type="checkbox"> cogroup、connect与 join</li>
<li><input disabled="" type="checkbox"> CDC</li>
<li><input disabled="" type="checkbox"> flink流测试工具</li>
<li><input disabled="" type="checkbox"> 今日活动总申购次数：并发度为1，是否windowAll都会是并发度为1，是否可以先keyBy再合并？</li>
</ul>
<p>If the parallelism of the environment is set to 3 and you are using a WindowAll operator, only the window operator runs in parallelism 1. The sink will still be running with parallelism 3. Hence, the plan looks as follows:</p>
<p>In_1 -\               /- Out_1<br>In_2 — WindowAll_1 — Out_2<br>In_3 -/               - Out_3<br>The WindowAll operator emits its output to its subsequent tasks using a round-robin strategy. That’s the reason for the different threads emitting the result records of program.</p>
<p>When you set the environment parallelism to 1, all operators run with a single task.</p>
<p>keyed-windown —分布式计算—&gt; all-windown</p>
<p>#【亿级流量 秒级统计】</p>
<p>AI、ML、DL、ANN、CNN 蛰伏数十年，就为这个大数据时代。</p>
<p>AI正以前所未有的速度改变世界，影响着我们生活的方方面面，AI走进人们的生活将成为未来的新常态。 而大数据和计算能力像水和氧气一样支撑着AI，我们的数据从手机端、服务器日志</p>
<h1 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://github.com/crestofwave1/oneFlink">Flink官方文档翻译</a></li>
</ul>
<h1 id="todo-1"><a href="#todo-1" class="headerlink" title="todo"></a>todo</h1><h2 id="checkpoint与savepoint区别-1"><a href="#checkpoint与savepoint区别-1" class="headerlink" title="checkpoint与savepoint区别"></a>checkpoint与savepoint区别</h2><h2 id="flink-report-1"><a href="#flink-report-1" class="headerlink" title="flink report"></a>flink report</h2><h2 id="storm-trident-1"><a href="#storm-trident-1" class="headerlink" title="storm trident"></a>storm trident</h2><p>微批</p>
<p>barrier对齐</p>
<p>![flink-rm](_v_images/20190826164001201_1759200368.png =510x)</p>
<h2 id="算子-1"><a href="#算子-1" class="headerlink" title="算子"></a>算子</h2><h3 id="Reduce在流计算的应用-1"><a href="#Reduce在流计算的应用-1" class="headerlink" title="Reduce在流计算的应用"></a>Reduce在流计算的应用</h3><p>org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor$LoggingHandler:140 -<br>Timestamp monotony violated: 1568772496000 &lt; 1568772500000</p>
<p>ToDo list</p>
<h1 id="avro-与-kryo-序列化的区别-1"><a href="#avro-与-kryo-序列化的区别-1" class="headerlink" title="avro 与 kryo 序列化的区别"></a>avro 与 kryo 序列化的区别</h1><p>使用场景</p>
<h1 id="broadcast"><a href="#broadcast" class="headerlink" title="broadcast"></a>broadcast</h1><h2 id="storm-allGrouping-元素广播-1"><a href="#storm-allGrouping-元素广播-1" class="headerlink" title="storm allGrouping 元素广播"></a>storm allGrouping 元素广播</h2><p>flink broadcast how to use </p>
<p>broadcast vaiable value can not be modified</p>
<p>用法<br>1：初始化数据<br>DataSet<Integer> toBroadcast = env.fromElements(1, 2, 3)<br>2：广播数据<br>.withBroadcastSet(toBroadcast, “broadcastSetName”);<br>3：获取数据<br>Collection<Integer> broadcastSet = getRuntimeContext().getBroadcastVariable(“broadcastSetName”);</p>
<ul>
<li>广播变量不能太大</li>
<li>不能修改，保证数据一致性</li>
</ul>
<h1 id="Accumulators-amp-Counters-1"><a href="#Accumulators-amp-Counters-1" class="headerlink" title="Accumulators &amp; Counters"></a>Accumulators &amp; Counters</h1><p>累加器与计数器</p>
<h2 id="spark-accumulate-1"><a href="#spark-accumulate-1" class="headerlink" title="spark accumulate"></a>spark accumulate</h2><p>用法<br>1：创建累加器<br>private IntCounter numLines = new IntCounter();<br>2：注册累加器<br>getRuntimeContext().addAccumulator(“num-lines”, this.numLines);<br>3：使用累加器<br>this.numLines.add(1);<br>4：获取累加器的结果<br>myJobExecutionResult.getAccumulatorResult(“num-lines”)</p>
<h1 id="Distributed-Cache-1"><a href="#Distributed-Cache-1" class="headerlink" title="Distributed Cache"></a>Distributed Cache</h1><blockquote>
<p>Spark 分布式缓存如何使用</p>
</blockquote>
<p>Flink提供了一个分布式缓存，类似于hadoop，可以使用户在并行函数中很方便的读取本地文件<br>此缓存的工作机制如下：程序注册一个文件或者目录(本地或者远程文件系统，例如hdfs或者s3)，通过ExecutionEnvironment注册缓存文件并为它起一个名称。当程序执行，Flink自动将文件或者目录复制到所有taskmanager节点的本地文件系统，用户可以通过这个指定的名称查找文件或者目录，然后从taskmanager节点的本地文件系统访问它<br>用法<br>1：注册一个文件<br>env.registerCachedFile(“hdfs:///path/to/your/file”, “hdfsFile”)<br>2：访问数据<br>File myFile = getRuntimeContext().getDistributedCache().getFile(“hdfsFile”);</p>
<h1 id="at-least-once-amp-exactly-once-1"><a href="#at-least-once-amp-exactly-once-1" class="headerlink" title="at least once &amp; exactly once"></a>at least once &amp; exactly once</h1><p>从容错和消息处理的语义上(at least once, exactly once)，Flink引入了state和checkpoint。</p>
<h1 id="state-1"><a href="#state-1" class="headerlink" title="state"></a>state</h1><p>默认保存在java堆中<br>checkpoint: 把state持久化存储，全局快照<br>blink做的优化</p>
<p>失败恢复机制 </p>
<p>状态分为原始状态和托管状态</p>
<p>托管状态是由Flink框架管理的状态<br>而原始状态，由用户自行管理状态具体的数据结构，框架在做checkpoint的时候，使用byte[]来读写状态内容，对其内部数据结构一无所知。<br>通常在DataStream上的状态推荐使用托管的状态，当实现一个用户自定义的operator时，会使用到原始状态。</p>
<blockquote>
<p>ReducingState 如何使用</p>
</blockquote>
<h1 id="checkpoint-1"><a href="#checkpoint-1" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>Flink的checkpoint机制可以与(stream和state)的持久化存储交互的前提：<br>持久化的source，它需要支持在一定时间内重放事件。这种sources的典型例子是持久化的消息队列（比如Apache Kafka，RabbitMQ等）或文件系统（比如HDFS，S3，GFS等）<br>用于state的持久化存储，例如分布式文件系统（比如HDFS，S3，GFS等）</p>
<p>Checkpoint是Flink实现容错机制最核心的功能，它能够根据配置周期性地基于Stream中各个Operator/task的状态来生成快照，从而将这些状态数据定期持久化存储下来，当Flink程序一旦意外崩溃时，重新运行程序时可以有选择地从这些快照进行恢复，从而修正因为故障带来的程序数据异常</p>
<p>checkpoint开启之后，默认的checkPointMode是Exactly-once<br>checkpoint的checkPointMode有两种，Exactly-once和At-least-once<br>Exactly-once对于大多数应用来说是最合适的。At-least-once可能用在某些延迟超低的应用程序（始终延迟为几毫秒）</p>
<p>ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION:表示一旦Flink处理程序被cancel后，会保留Checkpoint数据，以便根据实际需要恢复到指定的Checkpoint<br>ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION: 表示一旦Flink处理程序被cancel后，会删除Checkpoint数据，只有job执行失败的时候才会保存checkpoint</p>
<h1 id="state-backend-1"><a href="#state-backend-1" class="headerlink" title="state backend"></a>state backend</h1><p>默认情况下，state会保存在taskmanager的内存中，checkpoint会存储在JobManager的内存中。<br>state 的store和checkpoint的位置取决于State Backend的配置<br>env.setStateBackend(…)<br>一共有三种State Backend<br>MemoryStateBackend<br>FsStateBackend<br>RocksDBStateBackend</p>
<p>MemoryStateBackend<br>state数据保存在java堆内存中，执行checkpoint的时候，会把state的快照数据保存到jobmanager的内存中<br>基于内存的state backend在生产环境下不建议使用<br>FsStateBackend<br>state数据保存在taskmanager的内存中，执行checkpoint的时候，会把state的快照数据保存到配置的文件系统中<br>可以使用hdfs等分布式文件系统<br>RocksDBStateBackend<br>RocksDB跟上面的都略有不同，它会在本地文件系统中维护状态，state会直接写入本地rocksdb中。同时它需要配置一个远端的filesystem uri（一般是HDFS），在做checkpoint的时候，会把本地的数据直接复制到filesystem中。fail over的时候从filesystem中恢复到本地<br>RocksDB克服了state受内存限制的缺点，同时又能够持久化到远端文件系统中，比较适合在生产中使用</p>
<p>修改State Backend的两种方式<br>第一种：单任务调整<br>修改当前任务代码<br>env.setStateBackend(new FsStateBackend(“hdfs://namenode:9000/flink/checkpoints”));<br>或者new MemoryStateBackend()<br>或者new RocksDBStateBackend(filebackend, true);【需要添加第三方依赖】<br>第二种：全局调整<br>修改flink-conf.yaml<br>state.backend: filesystem<br>state.checkpoints.dir: hdfs://namenode:9000/flink/checkpoints<br>注意：state.backend的值可以是下面几种：jobmanager(MemoryStateBackend), filesystem(FsStateBackend), rocksdb(RocksDBStateBackend)</p>
<h1 id="Restart-Strategies-重启策略-1"><a href="#Restart-Strategies-重启策略-1" class="headerlink" title="Restart Strategies(重启策略)"></a>Restart Strategies(重启策略)</h1><p>默认重启策略通过 flink-conf.yaml 指定</p>
<p>常用的重启策略<br>固定间隔 (Fixed delay)<br>失败率 (Failure rate)<br>无重启 (No restart)<br>如果没有启用 checkpointing，则使用无重启 (no restart) 策略。<br>如果启用了 checkpointing，但没有配置重启策略，则使用固定间隔 (fixed-delay) 策略，其中 Integer.MAX_VALUE 参数是尝试重启次数<br>重启策略可以在flink-conf.yaml中配置，表示全局的配置。也可以在应用代码中动态指定，会覆盖全局配置</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">第一种：全局配置 flink-conf.yaml</span><br><span class="line">restart-strategy: fixed-delay</span><br><span class="line">restart-strategy.fixed-delay.attempts: <span class="number">3</span></span><br><span class="line">restart-strategy.fixed-delay.delay: <span class="number">10</span> s</span><br><span class="line">第二种：应用代码设置</span><br><span class="line">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 尝试重启的次数</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 间隔</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink-release</title>
    <url>/bigdata/Flink/01.Release_log/</url>
    <content><![CDATA[<h1 id="10-12-0"><a href="#10-12-0" class="headerlink" title="10.12.0"></a>10.12.0</h1><p><a href="https://blog.csdn.net/weixin_44904816/article/details/111027068">reference</a></p>
<ul>
<li>在 DataStream API 上添加了高效的批执行模式的支持。这是批处理和流处理实现真正统一的运行时的一个重要里程碑。</li>
<li>实现了基于Kubernetes的高可用性（HA）方案，作为生产环境中，ZooKeeper方案之外的另外一种选择。</li>
<li>扩展了 Kafka SQL connector，使其可以在 upsert 模式下工作，并且支持在 SQL DDL 中处理 connector 的 metadata。现在，时态表 Join 可以完全用 SQL 来表示，不再依赖于 Table API 了。</li>
<li>PyFlink 中添加了对于 DataStream API 的支持，将 PyFlink 扩展到了更复杂的场景，比如需要对状态或者定时器 timer 进行细粒度控制的场景。除此之外，现在原生支持将 PyFlink 作业部署到 Kubernetes上。</li>
</ul>
<h2 id="DataStream-API支持批量"><a href="#DataStream-API支持批量" class="headerlink" title="DataStream API支持批量"></a>DataStream API支持批量</h2><p>可复用性：作业可以在流和批这两种执行模式之间自由地切换，而无需重写任何代码。因此，用户可以复用同一个作业，来处理实时数据和历史数据。</p>
<p>维护简单：统一的 API 意味着流和批可以共用同一组 connector，维护同一套代码，并能够轻松地实现流批混合执行，例如 backfilling 之类的场景。</p>
<h2 id="Data-Sink-API"><a href="#Data-Sink-API" class="headerlink" title="Data Sink API"></a>Data Sink API</h2><h2 id="Sort-Merge-Shuffle"><a href="#Sort-Merge-Shuffle" class="headerlink" title="Sort-Merge Shuffle"></a>Sort-Merge Shuffle</h2><h2 id="SQL-中-支持-Temporal-Table-Join"><a href="#SQL-中-支持-Temporal-Table-Join" class="headerlink" title="SQL 中 支持 Temporal Table Join"></a>SQL 中 支持 Temporal Table Join</h2>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>亿级流量秒级统计</title>
    <url>/bigdata/Flink/02.%E4%BA%BF%E7%BA%A7%E6%B5%81%E9%87%8F_%E7%A7%92%E7%BA%A7%E7%BB%9F%E8%AE%A1/</url>
    <content><![CDATA[<p>#【亿级流量 秒级统计】</p>
<p><strong>AI、ML、DL、ANN、CNN</strong> 蛰伏数十年，就为这个大数据时代。</p>
<p>AI正以前所未有的速度改变世界，影响着我们生活的方方面面，AI走进人们的生活将成为未来的新常态。<br>而大数据和计算能力像水和氧气一样支撑着AI，我们的数据从手机端、服务器日志</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>rtc</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink AsyncApiScalaSink</title>
    <url>/bigdata/Flink/AsyncApiScalaSink/</url>
    <content><![CDATA[<h1 id="Flink-AsyncApiScalaSink"><a href="#Flink-AsyncApiScalaSink" class="headerlink" title="Flink AsyncApiScalaSink"></a>Flink AsyncApiScalaSink</h1><p>andrew建议：</p>
<ul>
<li>onCompeleted没有把IOException暴露给用户</li>
<li>链接配置之类的参数如何传递进去</li>
<li>反压机制如何做？sink经常遇到的问题，下游抖动会直接导致数据丢失</li>
<li>反压 限流 重试</li>
<li>支持batch，条数控制</li>
<li>checkpoint时，需要batch立即flush出去</li>
</ul>
<h2 id="Http-Client"><a href="#Http-Client" class="headerlink" title="Http Client"></a>Http Client</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.httpcomponents<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>httpclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.httpcomponents<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>httpcore<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.httpcomponents<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>httpcore-nio<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.httpcomponents<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>httpasyncclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="AsyncApiScalaSink"><a href="#AsyncApiScalaSink" class="headerlink" title="AsyncApiScalaSink"></a>AsyncApiScalaSink</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.<span class="type">IOException</span></span><br><span class="line"><span class="keyword">import</span> java.util</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.&#123;<span class="type">RichSinkFunction</span>, <span class="type">SinkFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.http._</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.entity.<span class="type">UrlEncodedFormEntity</span></span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.methods.&#123;<span class="type">HttpEntityEnclosingRequestBase</span>, <span class="type">HttpPost</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.concurrent.<span class="type">FutureCallback</span></span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.client.<span class="type">DefaultConnectionKeepAliveStrategy</span></span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.nio.client.&#123;<span class="type">CloseableHttpAsyncClient</span>, <span class="type">HttpAsyncClients</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.message.<span class="type">BasicNameValuePair</span></span><br><span class="line"><span class="keyword">import</span> org.apache.http.util.<span class="type">EntityUtils</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AsyncApiScalaSink</span>[<span class="type">E</span>](<span class="params">httpInvoker: <span class="type">HttpInvoker</span>[<span class="type">E</span>]</span>) <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[<span class="type">E</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> httpClient: <span class="type">CloseableHttpAsyncClient</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    httpClient = <span class="type">HttpAsyncClients</span>.custom.setKeepAliveStrategy(<span class="type">DefaultConnectionKeepAliveStrategy</span>.<span class="type">INSTANCE</span>).build</span><br><span class="line">    httpClient.start()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(value: <span class="type">E</span>, context: <span class="type">SinkFunction</span>.<span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">var</span> httpEntity: <span class="type">HttpEntityEnclosingRequestBase</span> = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">val</span> method: <span class="type">String</span> = httpInvoker.getMethod</span><br><span class="line">    <span class="keyword">val</span> url: <span class="type">String</span> = httpInvoker.getUrl</span><br><span class="line">    <span class="keyword">if</span> (<span class="string">&quot;GET&quot;</span> == method) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;POST&quot;</span> == method) &#123;</span><br><span class="line">      <span class="keyword">val</span> params1: util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = httpInvoker.getParams(value)</span><br><span class="line">      <span class="keyword">val</span> params: util.<span class="type">List</span>[<span class="type">NameValuePair</span>] = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">NameValuePair</span>]</span><br><span class="line">      <span class="keyword">if</span> (params1 != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line">        <span class="keyword">for</span> (entry &lt;- params1.entrySet) &#123;</span><br><span class="line">          <span class="keyword">val</span> key: <span class="type">String</span> = entry.getKey</span><br><span class="line">          <span class="keyword">val</span> value1: <span class="type">String</span> = entry.getValue</span><br><span class="line">          params.add(<span class="keyword">new</span> <span class="type">BasicNameValuePair</span>(key, value1))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> entity: <span class="type">UrlEncodedFormEntity</span> = <span class="keyword">new</span> <span class="type">UrlEncodedFormEntity</span>(params, <span class="type">Consts</span>.<span class="type">UTF_8</span>)</span><br><span class="line">      httpEntity = <span class="keyword">new</span> <span class="type">HttpPost</span>(url)</span><br><span class="line">      httpEntity.setEntity(entity)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    httpClient.execute(httpEntity, <span class="keyword">new</span> <span class="type">FutureCallback</span>[<span class="type">HttpResponse</span>]() &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">completed</span></span>(response: <span class="type">HttpResponse</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> statusLine: <span class="type">StatusLine</span> = response.getStatusLine</span><br><span class="line">        <span class="keyword">val</span> httpStatusCode: <span class="type">Int</span> = statusLine.getStatusCode</span><br><span class="line">        <span class="keyword">var</span> content: <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> entity: <span class="type">HttpEntity</span> = response.getEntity</span><br><span class="line">          content = <span class="type">EntityUtils</span>.toString(entity)</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt;</span><br><span class="line">            <span class="type">System</span>.err.print(e.getMessage)</span><br><span class="line">        &#125;</span><br><span class="line">        httpInvoker.onCompleted(value, httpStatusCode, content)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span></span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">failed</span></span>(ex: <span class="type">Exception</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        httpInvoker.onFailed(value, ex)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span></span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">cancelled</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        httpInvoker.onCanceled(value)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    httpClient.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="HttpInvoker"><a href="#HttpInvoker" class="headerlink" title="HttpInvoker"></a>HttpInvoker</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.<span class="type">Serializable</span>;</span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Map</span>;</span><br><span class="line"></span><br><span class="line">public interface <span class="type">HttpInvoker</span>&lt;<span class="type">E</span>&gt; <span class="keyword">extends</span> <span class="type">Serializable</span> &#123;</span><br><span class="line">    <span class="type">Map</span>&lt;<span class="type">String</span>, <span class="type">String</span>&gt; getParams(<span class="type">E</span> e);</span><br><span class="line"></span><br><span class="line">    <span class="type">String</span> getMethod();</span><br><span class="line"></span><br><span class="line">    <span class="type">String</span> getUrl();</span><br><span class="line"></span><br><span class="line">    void onCompleted(<span class="type">E</span> value, int httpStatusCode, <span class="type">String</span> content);</span><br><span class="line"></span><br><span class="line">    void onFailed(<span class="type">E</span> value, <span class="type">Exception</span> ex);</span><br><span class="line"></span><br><span class="line">    void onCanceled(<span class="type">E</span> value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink: 数据源重放</title>
    <url>/bigdata/Flink/DataSourceReplay/</url>
    <content><![CDATA[<h1 id="flink-table-api"><a href="#flink-table-api" class="headerlink" title="flink-table-api"></a>flink-table-api</h1><h2 id="Hippo和Tube如何实现重放"><a href="#Hippo和Tube如何实现重放" class="headerlink" title="Hippo和Tube如何实现重放?"></a>Hippo和Tube如何实现重放?</h2><h3 id="FlinkHippoConsumer"><a href="#FlinkHippoConsumer" class="headerlink" title="FlinkHippoConsumer"></a>FlinkHippoConsumer</h3><h2 id="举一反三"><a href="#举一反三" class="headerlink" title="举一反三"></a>举一反三</h2><h3 id="org-apache-flink-streaming-api-functions-source-RichParallelSourceFunction"><a href="#org-apache-flink-streaming-api-functions-source-RichParallelSourceFunction" class="headerlink" title="org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction"></a>org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction</h3><p>构建并行数据流的基础类，在执行时，运行时将执行与源配置的并行一样多的该函数的并行实例。</p>
<h2 id="org-apache-flink-types-Row"><a href="#org-apache-flink-types-Row" class="headerlink" title="org.apache.flink.types.Row"></a>org.apache.flink.types.Row</h2><p>一行数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Object[]  fields</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink:数据类型与序列化</title>
    <url>/bigdata/Flink/DataTypesAndSerialization/</url>
    <content><![CDATA[<h1 id="Flink-Data-Types-amp-Serialization"><a href="#Flink-Data-Types-amp-Serialization" class="headerlink" title="Flink Data Types &amp; Serialization"></a>Flink Data Types &amp; Serialization</h1><h2 id="使用case-class的坑"><a href="#使用case-class的坑" class="headerlink" title="使用case class的坑"></a>使用case class的坑</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">id: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> lb = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">13:00:43,342 INFO  org.apache.flink.api.java.typeutils.TypeExtractor             - class org.myorg.quickstart.Event does not contain a setter for field id</span><br><span class="line">13:00:43,343 INFO  org.apache.flink.api.java.typeutils.TypeExtractor             - Class class org.myorg.quickstart.Event cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on &quot;Data Types &amp; Serialization&quot; for details of the effect on performance.</span><br></pre></td></tr></table></figure>
<p><strong>提示信息：找不到setter，对于POJO类型必须所有的字段必须要有setter和getter</strong><br>命名是case class啊</p>
<p>再看生产环境的例子： 折腾了一下午</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">uin: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 sPid: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 applyId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 bankType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 transactionId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 amount: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 createTime: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 bizType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 modifyTime: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 equ: <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span></span></span><br><span class="line"><span class="class"><span class="params">                </span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(uin: <span class="type">String</span>,</span><br><span class="line">           sPid: <span class="type">String</span>,</span><br><span class="line">           applyId: <span class="type">String</span>,</span><br><span class="line">           bankType: <span class="type">Long</span>,</span><br><span class="line">           transactionId: <span class="type">String</span>,</span><br><span class="line">           amount: <span class="type">Long</span>,</span><br><span class="line">           createTime: <span class="type">Long</span>,</span><br><span class="line">           bizType: <span class="type">Long</span>,</span><br><span class="line">           modifyTime: <span class="type">String</span>,</span><br><span class="line">           equ: <span class="type">List</span>[<span class="type">Int</span>]</span><br><span class="line">          ) = &#123;</span><br><span class="line">    <span class="keyword">this</span>(uin, sPid, applyId, bankType, transactionId, amount, createTime, bizType, modifyTime)</span><br><span class="line">    <span class="keyword">if</span> (equ != <span class="literal">null</span>) &#123;</span><br><span class="line">      equities.appendAll(equ)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> _active = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">val</span> equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addEquity</span></span>(id: <span class="type">Int</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    equities.append(id)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">equityString</span></span>(separator: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    equities.mkString(separator)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(active: <span class="type">String</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="string">&quot;1&quot;</span>.equals(active)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isActive</span></span>() = &#123;</span><br><span class="line">    _active</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用的是flink 1.6版本的，case class识别出来了，但是equities没有传递到下一个算子中，始终没有值</p>
<p>老老实实的修改成普通类</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">_uin: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _sPid: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _applyId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _bankType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _transactionId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _amount: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _createTime: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _bizType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _modifyTime: <span class="type">String</span></span></span></span><br><span class="line"><span class="class"><span class="params">           </span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> uin: <span class="type">String</span> = _uin</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> sPid: <span class="type">String</span> = _sPid</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> applyId: <span class="type">String</span> = _applyId</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> bankType: <span class="type">Long</span> = _bankType</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> transactionId: <span class="type">String</span> = _transactionId</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> amount: <span class="type">Long</span> = _amount</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> createTime: <span class="type">Long</span> = _createTime</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> bizType: <span class="type">Long</span> = _bizType</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> modifyTime: <span class="type">String</span> = _modifyTime</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> _active = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(uin: <span class="type">String</span>,</span><br><span class="line">           sPid: <span class="type">String</span>,</span><br><span class="line">           applyId: <span class="type">String</span>,</span><br><span class="line">           bankType: <span class="type">Long</span>,</span><br><span class="line">           transactionId: <span class="type">String</span>,</span><br><span class="line">           amount: <span class="type">Long</span>,</span><br><span class="line">           createTime: <span class="type">Long</span>,</span><br><span class="line">           bizType: <span class="type">Long</span>,</span><br><span class="line">           modifyTime: <span class="type">String</span>,</span><br><span class="line">           equ: <span class="type">List</span>[<span class="type">Int</span>]</span><br><span class="line">          ) = &#123;</span><br><span class="line">    <span class="keyword">this</span>(uin, sPid, applyId, bankType, transactionId, amount, createTime, bizType, modifyTime)</span><br><span class="line">    <span class="keyword">if</span> (equ != <span class="literal">null</span>) &#123;</span><br><span class="line">      equities.appendAll(equ)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getUin</span></span>: <span class="type">String</span> = uin</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setUin</span></span>(<span class="type">Uin</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.uin = <span class="type">Uin</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getSPid</span></span>: <span class="type">String</span> = sPid</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setSPid</span></span>(<span class="type">SPid</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.sPid = <span class="type">SPid</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getApplyId</span></span>: <span class="type">String</span> = applyId</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setApplyId</span></span>(<span class="type">ApplyId</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.applyId = <span class="type">ApplyId</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getBankType</span></span>: <span class="type">Long</span> = bankType</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setBankType</span></span>(<span class="type">BankType</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.bankType = <span class="type">BankType</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getTransactionId</span></span>: <span class="type">String</span> = transactionId</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setTransactionId</span></span>(<span class="type">TransactionId</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.transactionId = <span class="type">TransactionId</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getAmount</span></span>: <span class="type">Long</span> = amount</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setAmount</span></span>(<span class="type">Amount</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.amount = <span class="type">Amount</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getCreateTime</span></span>: <span class="type">Long</span> = createTime</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setCreateTime</span></span>(<span class="type">CreateTime</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.createTime = <span class="type">CreateTime</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getBizType</span></span>: <span class="type">Long</span> = bizType</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setBizType</span></span>(<span class="type">BizType</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.bizType = <span class="type">BizType</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getModifyTime</span></span>: <span class="type">String</span> = modifyTime</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setModifyTime</span></span>(<span class="type">ModifyTime</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.modifyTime = <span class="type">ModifyTime</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addEquity</span></span>(id: <span class="type">Int</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    equities.append(id)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">equityString</span></span>(separator: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    equities.mkString(separator)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(active: <span class="type">String</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="string">&quot;1&quot;</span>.equals(active)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isActive</span></span>() = &#123;</span><br><span class="line">    _active</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rights</span></span>(split: <span class="type">String</span>) = &#123;</span><br><span class="line">    <span class="type">RightEvent</span>(<span class="keyword">this</span>, equities.mkString(split))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getEquities</span> </span>= equities</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setEquities</span></span>(equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>]) = &#123;</span><br><span class="line">    <span class="keyword">this</span>.equities = equities</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以了</p>
<p>初步估计，序列化除了问题</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink join</title>
    <url>/bigdata/Flink/Flink-DataStream-join/</url>
    <content><![CDATA[<h1 id="flink-join"><a href="#flink-join" class="headerlink" title="flink join"></a>flink join</h1><h2 id="Cogroup"><a href="#Cogroup" class="headerlink" title="Cogroup"></a>Cogroup</h2><p>CoGroupFunction中会返回所有数据，不管有没有匹配上</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;Tuple3&lt;Long, String, String&gt;&gt; input1 = ...;</span><br><span class="line">input1 = input1.assignTimestampsAndWatermarks(<span class="keyword">new</span> AscendingTimestampExtractor&lt;Tuple3&lt;Long, String, String&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(Tuple3&lt;Long, String, String&gt; arg0)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> arg0.f0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Tuple2&lt;Long, String&gt;&gt; input2 = ...;</span><br><span class="line">input2 = input2.assignTimestampsAndWatermarks(<span class="keyword">new</span> AscendingTimestampExtractor&lt;Tuple2&lt;Long, String&gt;&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(Tuple2&lt;Long, String&gt; stringStringTuple2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> stringStringTuple2.f0;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">input1.coGroup(input2).where(<span class="keyword">new</span> KeySelector&lt;Tuple3&lt;Long, String, String&gt;, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getKey</span><span class="params">(Tuple3&lt;Long, String, String&gt; itemEntity)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> itemEntity.f1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.equalTo(<span class="keyword">new</span> KeySelector&lt;Tuple2&lt;Long, String&gt;, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getKey</span><span class="params">(Tuple2&lt;Long, String&gt; value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value.f1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.window(TumblingEventTimeWindows.of(Time.minutes(<span class="number">1</span>)))</span><br><span class="line">.apply(<span class="keyword">new</span> CoGroupFunction&lt;Tuple3&lt;Long, String, String&gt;, Tuple2&lt;Long, String&gt;, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">coGroup</span><span class="params">(Iterable&lt;Tuple3&lt;Long, String, String&gt;&gt; first,</span></span></span><br><span class="line"><span class="function"><span class="params">            Iterable&lt;Tuple2&lt;Long, String&gt;&gt; second, Collector&lt;String&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        StringBuilder buffer = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        buffer.append(<span class="string">&quot;DataStream first:\n&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (Tuple3&lt;Long, String, String&gt; value : first) &#123;</span><br><span class="line">            buffer.append(value).append(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        buffer.append(<span class="string">&quot;DataStream second:\n&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;Long, String&gt; value : second) &#123;</span><br><span class="line">            buffer.append(value.f0).append(<span class="string">&quot;=&gt;&quot;</span>).append(value.f1).append(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        collector.collect(buffer.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.print();</span><br></pre></td></tr></table></figure>
<p>上面的例子，左流有三个元素 <code>Tuple3&lt;String,String,String&gt;</code>，右流有两个元素<code>Tuple2&lt;String,String&gt;</code><br>两个流第一个元素相互关联。分别指定两个流的事件时间字段。<br>两个流关联后，按照EventTime划分窗口。与单流类似。<br>不管元素是否可以关联上，都会输出</p>
<p>用户可以定义CoGroupFunction函数, 可以实现在窗口内，任意组合，如笛卡尔积</p>
<p>举例说明:</p>
<h2 id="window-Join"><a href="#window-Join" class="headerlink" title="window Join"></a>window Join</h2><h2 id="interval-join"><a href="#interval-join" class="headerlink" title="interval join"></a>interval join</h2><h2 id="broadcast-join"><a href="#broadcast-join" class="headerlink" title="broadcast join"></a>broadcast join</h2>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink:数据类型与序列化</title>
    <url>/bigdata/Flink/Flink-DataTypesAndSerialization/</url>
    <content><![CDATA[<h1 id="Flink-Data-Types-amp-Serialization"><a href="#Flink-Data-Types-amp-Serialization" class="headerlink" title="Flink Data Types &amp; Serialization"></a>Flink Data Types &amp; Serialization</h1><h2 id="使用case-class的坑"><a href="#使用case-class的坑" class="headerlink" title="使用case class的坑"></a>使用case class的坑</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">id: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> lb = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">13:00:43,342 INFO  org.apache.flink.api.java.typeutils.TypeExtractor             - class org.myorg.quickstart.Event does not contain a setter for field id</span><br><span class="line">13:00:43,343 INFO  org.apache.flink.api.java.typeutils.TypeExtractor             - Class class org.myorg.quickstart.Event cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on &quot;Data Types &amp; Serialization&quot; for details of the effect on performance.</span><br></pre></td></tr></table></figure>
<p><strong>提示信息：找不到setter，对于POJO类型必须所有的字段必须要有setter和getter</strong><br>命名是case class啊</p>
<p>再看生产环境的例子： 折腾了一下午</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">uin: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 sPid: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 applyId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 bankType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 transactionId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 amount: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 createTime: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 bizType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 modifyTime: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 equ: <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span></span></span><br><span class="line"><span class="class"><span class="params">                </span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(uin: <span class="type">String</span>,</span><br><span class="line">           sPid: <span class="type">String</span>,</span><br><span class="line">           applyId: <span class="type">String</span>,</span><br><span class="line">           bankType: <span class="type">Long</span>,</span><br><span class="line">           transactionId: <span class="type">String</span>,</span><br><span class="line">           amount: <span class="type">Long</span>,</span><br><span class="line">           createTime: <span class="type">Long</span>,</span><br><span class="line">           bizType: <span class="type">Long</span>,</span><br><span class="line">           modifyTime: <span class="type">String</span>,</span><br><span class="line">           equ: <span class="type">List</span>[<span class="type">Int</span>]</span><br><span class="line">          ) = &#123;</span><br><span class="line">    <span class="keyword">this</span>(uin, sPid, applyId, bankType, transactionId, amount, createTime, bizType, modifyTime)</span><br><span class="line">    <span class="keyword">if</span> (equ != <span class="literal">null</span>) &#123;</span><br><span class="line">      equities.appendAll(equ)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> _active = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">val</span> equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addEquity</span></span>(id: <span class="type">Int</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    equities.append(id)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">equityString</span></span>(separator: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    equities.mkString(separator)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(active: <span class="type">String</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="string">&quot;1&quot;</span>.equals(active)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isActive</span></span>() = &#123;</span><br><span class="line">    _active</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用的是flink 1.6版本的，case class识别出来了，但是equities没有传递到下一个算子中，始终没有值</p>
<p>老老实实的修改成普通类</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">_uin: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _sPid: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _applyId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _bankType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _transactionId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _amount: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _createTime: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _bizType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _modifyTime: <span class="type">String</span></span></span></span><br><span class="line"><span class="class"><span class="params">           </span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> uin: <span class="type">String</span> = _uin</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> sPid: <span class="type">String</span> = _sPid</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> applyId: <span class="type">String</span> = _applyId</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> bankType: <span class="type">Long</span> = _bankType</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> transactionId: <span class="type">String</span> = _transactionId</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> amount: <span class="type">Long</span> = _amount</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> createTime: <span class="type">Long</span> = _createTime</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> bizType: <span class="type">Long</span> = _bizType</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> modifyTime: <span class="type">String</span> = _modifyTime</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> _active = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(uin: <span class="type">String</span>,</span><br><span class="line">           sPid: <span class="type">String</span>,</span><br><span class="line">           applyId: <span class="type">String</span>,</span><br><span class="line">           bankType: <span class="type">Long</span>,</span><br><span class="line">           transactionId: <span class="type">String</span>,</span><br><span class="line">           amount: <span class="type">Long</span>,</span><br><span class="line">           createTime: <span class="type">Long</span>,</span><br><span class="line">           bizType: <span class="type">Long</span>,</span><br><span class="line">           modifyTime: <span class="type">String</span>,</span><br><span class="line">           equ: <span class="type">List</span>[<span class="type">Int</span>]</span><br><span class="line">          ) = &#123;</span><br><span class="line">    <span class="keyword">this</span>(uin, sPid, applyId, bankType, transactionId, amount, createTime, bizType, modifyTime)</span><br><span class="line">    <span class="keyword">if</span> (equ != <span class="literal">null</span>) &#123;</span><br><span class="line">      equities.appendAll(equ)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getUin</span></span>: <span class="type">String</span> = uin</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setUin</span></span>(<span class="type">Uin</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.uin = <span class="type">Uin</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getSPid</span></span>: <span class="type">String</span> = sPid</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setSPid</span></span>(<span class="type">SPid</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.sPid = <span class="type">SPid</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getApplyId</span></span>: <span class="type">String</span> = applyId</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setApplyId</span></span>(<span class="type">ApplyId</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.applyId = <span class="type">ApplyId</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getBankType</span></span>: <span class="type">Long</span> = bankType</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setBankType</span></span>(<span class="type">BankType</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.bankType = <span class="type">BankType</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getTransactionId</span></span>: <span class="type">String</span> = transactionId</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setTransactionId</span></span>(<span class="type">TransactionId</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.transactionId = <span class="type">TransactionId</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getAmount</span></span>: <span class="type">Long</span> = amount</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setAmount</span></span>(<span class="type">Amount</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.amount = <span class="type">Amount</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getCreateTime</span></span>: <span class="type">Long</span> = createTime</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setCreateTime</span></span>(<span class="type">CreateTime</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.createTime = <span class="type">CreateTime</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getBizType</span></span>: <span class="type">Long</span> = bizType</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setBizType</span></span>(<span class="type">BizType</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.bizType = <span class="type">BizType</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getModifyTime</span></span>: <span class="type">String</span> = modifyTime</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setModifyTime</span></span>(<span class="type">ModifyTime</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.modifyTime = <span class="type">ModifyTime</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addEquity</span></span>(id: <span class="type">Int</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    equities.append(id)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">equityString</span></span>(separator: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    equities.mkString(separator)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(active: <span class="type">String</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="string">&quot;1&quot;</span>.equals(active)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isActive</span></span>() = &#123;</span><br><span class="line">    _active</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rights</span></span>(split: <span class="type">String</span>) = &#123;</span><br><span class="line">    <span class="type">RightEvent</span>(<span class="keyword">this</span>, equities.mkString(split))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getEquities</span> </span>= equities</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setEquities</span></span>(equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>]) = &#123;</span><br><span class="line">    <span class="keyword">this</span>.equities = equities</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以了</p>
<p>初步估计，序列化除了问题</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>【草稿】FlinkKuduSink</title>
    <url>/bigdata/Flink/Flink-KuduSink/</url>
    <content><![CDATA[<h1 id="FlinkKuduSink"><a href="#FlinkKuduSink" class="headerlink" title="FlinkKuduSink"></a>FlinkKuduSink</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">org.apache.kudu.client.NonRecoverableException: Couldn<span class="string">&#x27;t find a valid master in (9.7.185.196:7050). Exceptions received: [org.apache.kudu.client.RpcRemoteException: [peer master-] server sent error Service unavailable: service kudu.master.MasterService not registered on TabletServer]</span></span><br><span class="line"><span class="string">	at org.apache.kudu.client.KuduException.transformException(KuduException.java:110)</span></span><br><span class="line"><span class="string">	at org.apache.kudu.client.KuduClient.joinAndHandleException(KuduClient.java:413)</span></span><br><span class="line"><span class="string">	at org.apache.kudu.client.KuduClient.tableExists(KuduClient.java:229)</span></span><br><span class="line"><span class="string">	at org.apache.flink.connectors.kudu.connector.writer.KuduWriter.obtainTable(KuduWriter.java:74)</span></span><br><span class="line"><span class="string">	at org.apache.flink.connectors.kudu.connector.writer.KuduWriter.&lt;init&gt;(KuduWriter.java:59)</span></span><br><span class="line"><span class="string">	at org.apache.flink.connectors.kudu.streaming.KuduSink.open(KuduSink.java:62)</span></span><br><span class="line"><span class="string">	at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:36)</span></span><br><span class="line"><span class="string">	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:102)</span></span><br><span class="line"><span class="string">	at org.apache.flink.streaming.api.operators.StreamSink.open(StreamSink.java:48)</span></span><br><span class="line"><span class="string">	at org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:426)</span></span><br><span class="line"><span class="string">	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:292)</span></span><br><span class="line"><span class="string">	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:726)</span></span><br><span class="line"><span class="string">	at java.lang.Thread.run(Thread.java:748)</span></span><br><span class="line"><span class="string">	Suppressed: org.apache.kudu.client.KuduException$OriginalException: Original asynchronous stack trace</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.ConnectToCluster.incrementCountAndCheckExhausted(ConnectToCluster.java:244)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.ConnectToCluster.access$100(ConnectToCluster.java:49)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.ConnectToCluster$ConnectToMasterErrCB.call(ConnectToCluster.java:363)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.ConnectToCluster$ConnectToMasterErrCB.call(ConnectToCluster.java:352)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.doCall(Deferred.java:1280)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.runCallbacks(Deferred.java:1259)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.handleContinuation(Deferred.java:1315)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.doCall(Deferred.java:1286)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.runCallbacks(Deferred.java:1259)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.callback(Deferred.java:1002)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.KuduRpc.handleCallback(KuduRpc.java:275)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.KuduRpc.errback(KuduRpc.java:329)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.RpcProxy.responseReceived(RpcProxy.java:247)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.kudu.client.NonRecoverableException: must specify at least one key column</span><br><span class="line">	at org.apache.kudu.client.KuduException.transformException(KuduException.java:<span class="number">110</span>)</span><br><span class="line">	at org.apache.kudu.client.KuduClient.joinAndHandleException(KuduClient.java:<span class="number">413</span>)</span><br><span class="line">	at org.apache.kudu.client.KuduClient.createTable(KuduClient.java:<span class="number">118</span>)</span><br><span class="line">	at org.apache.flink.connectors.kudu.connector.writer.KuduWriter.obtainTable(KuduWriter.java:<span class="number">78</span>)</span><br><span class="line">	at org.apache.flink.connectors.kudu.connector.writer.KuduWriter.&lt;init&gt;(KuduWriter.java:<span class="number">59</span>)</span><br><span class="line">	at org.apache.flink.connectors.kudu.streaming.KuduSink.open(KuduSink.java:<span class="number">62</span>)</span><br><span class="line">	at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:<span class="number">36</span>)</span><br><span class="line">	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:<span class="number">102</span>)</span><br><span class="line">	at org.apache.flink.streaming.api.operators.StreamSink.open(StreamSink.java:<span class="number">48</span>)</span><br><span class="line">	at org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:<span class="number">426</span>)</span><br><span class="line">	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:<span class="number">292</span>)</span><br><span class="line">	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:<span class="number">726</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br><span class="line">	Suppressed: org.apache.kudu.client.KuduException$OriginalException: Original asynchronous stack trace</span><br><span class="line">		at org.apache.kudu.client.RpcProxy.dispatchMasterError(RpcProxy.java:<span class="number">386</span>)</span><br><span class="line">		at org.apache.kudu.client.RpcProxy.responseReceived(RpcProxy.java:<span class="number">279</span>)</span><br><span class="line">		at org.apache.kudu.client.RpcProxy.access$<span class="number">000</span>(RpcProxy.java:<span class="number">59</span>)</span><br><span class="line">		at org.apache.kudu.client.RpcProxy$<span class="number">1.</span>call(RpcProxy.java:<span class="number">149</span>)</span><br><span class="line">		at org.apache.kudu.client.RpcProxy$<span class="number">1.</span>call(RpcProxy.java:<span class="number">145</span>)</span><br><span class="line">		at org.apache.kudu.client.Connection.messageReceived(Connection.java:<span class="number">390</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:<span class="number">70</span>)</span><br><span class="line">		at org.apache.kudu.client.Connection.handleUpstream(Connection.java:<span class="number">238</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:<span class="number">791</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">296</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:<span class="number">70</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:<span class="number">791</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">296</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:<span class="number">462</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:<span class="number">443</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:<span class="number">303</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:<span class="number">70</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:<span class="number">791</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">296</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:<span class="number">462</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:<span class="number">443</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:<span class="number">303</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:<span class="number">70</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">559</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">268</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">255</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:<span class="number">88</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:<span class="number">108</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:<span class="number">337</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:<span class="number">89</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:<span class="number">178</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:<span class="number">108</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.util.internal.DeadLockProofWorker$<span class="number">1.</span>run(DeadLockProofWorker.java:<span class="number">42</span>)</span><br><span class="line">		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1149</span>)</span><br><span class="line">		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">624</span>)</span><br><span class="line">		... <span class="number">1</span> more</span><br><span class="line"></span><br><span class="line">Rows per page:</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">1</span> - <span class="number">1</span> of <span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/Flink-SQL-Join-Lateral/</url>
    <content><![CDATA[<h1 id="JOIN-LATERAL"><a href="#JOIN-LATERAL" class="headerlink" title="JOIN LATERAL"></a>JOIN LATERAL</h1>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/Flink-SQL-Join/</url>
    <content><![CDATA[<h1 id="Flink-SQL-Join"><a href="#Flink-SQL-Join" class="headerlink" title="Flink SQL Join"></a>Flink SQL Join</h1><h2 id="双流Join"><a href="#双流Join" class="headerlink" title="双流Join"></a>双流Join</h2><h3 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h3><p>从 Flink 1.6 版本开始，社区引入了状态 TTL（Time-To-Live）特性。在通过Flink SQL 实现流处理时，开发者可以为作业 SQL 设置TTL，实现过期状态的自动清理，从而防止作业状态无限膨胀</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    t_date,</span><br><span class="line">    <span class="built_in">COUNT</span> ( <span class="keyword">DISTINCT</span> user_id ) <span class="keyword">AS</span> cnt_login, <span class="comment">-- 今日登录用户数</span></span><br><span class="line">    <span class="built_in">COUNT</span> ( <span class="keyword">DISTINCT</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> t_date <span class="operator">=</span> t_debut <span class="keyword">THEN</span> user_id <span class="keyword">END</span> ) <span class="keyword">AS</span> cnt_new <span class="comment">-- 今日新用户数</span></span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">  (</span><br><span class="line">    <span class="comment">-- 计算每个用户有史以来的最小登录时间</span></span><br><span class="line">    <span class="keyword">SELECT</span></span><br><span class="line">       t_date,</span><br><span class="line">       user_id,</span><br><span class="line">       <span class="built_in">MIN</span> (t_date) <span class="keyword">OVER</span> (</span><br><span class="line">             <span class="keyword">PARTITION</span> <span class="keyword">BY</span> user_id</span><br><span class="line">             <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">             <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">1</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">       ) <span class="keyword">AS</span> t_debut</span><br><span class="line">    <span class="keyword">FROM</span> Login</span><br><span class="line">) <span class="keyword">AS</span> t</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> t_date</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Query-Configuration-查询配置"><a href="#Query-Configuration-查询配置" class="headerlink" title="Query Configuration 查询配置"></a>Query Configuration 查询配置</h3><p><a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/streaming/query_configuration.html">https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/streaming/query_configuration.html</a></p>
<p>Flink Table API 和SQL接口提供参数来调整连续查询的准确性和资源消耗。参数通过 <code>QueryConfig</code> 对象指定。<code>QueryConfig</code> 可以从 <code>TableEnvironment</code> 获得。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取 query configuration</span></span><br><span class="line"><span class="keyword">val</span> qConfig: <span class="type">StreamQueryConfig</span> = tableEnv.queryConfig</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置查询参数</span></span><br><span class="line">qConfig.withIdleStateRetentionTime(<span class="type">Time</span>.hours(<span class="number">12</span>), <span class="type">Time</span>.hours(<span class="number">24</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义查询和 TableSink</span></span><br><span class="line"><span class="keyword">val</span> result: <span class="type">Table</span> = ???</span><br><span class="line"><span class="keyword">val</span> sink: <span class="type">TableSink</span>[<span class="type">Row</span>] = ???</span><br><span class="line"></span><br><span class="line"><span class="comment">// TableSink 发送结果表时传递查询参数</span></span><br><span class="line">result.writeToSink(sink, qConfig)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换为 DataStream 时传递查询参数</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Row</span>] = result.toAppendStream[<span class="type">Row</span>](qConfig)</span><br></pre></td></tr></table></figure>
<p>空闲状态保持时间（Idle State Retention Time）参数定义一个键的状态在一次更新之后保存多久后删除。</p>
<p>通过删除键的状态，连续查询会完全忘记它之前已经看过这个键。如果删除的键再次出现，则被视为具有相应键的第一个记录。对于前面的查询示例，这意味着 sessionId 的计数从0开始。</p>
<p>配置空闲状态保存时间有两个参数：</p>
<pre><code>minimum idle state retention time，定义非活动键的状态在删除前至少保持多少时间。
maximum idle state retention time，定义非活动键的状态在删除前最多保持多少时间。</code></pre>
<p>对于前面的查询示例：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> qConfig: <span class="type">StreamQueryConfig</span> = ???</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置 idle state retention time: min = 12 hours, max = 24 hours</span></span><br><span class="line">qConfig.withIdleStateRetentionTime(<span class="type">Time</span>.hours(<span class="number">12</span>), <span class="type">Time</span>.hours(<span class="number">24</span>))</span><br></pre></td></tr></table></figure>
<p>清理状态需要额外的记录，对于 minTime 和 maxTime 较大差异的情况成本更低，因此 minTime 和 maxTime 直接必须至少相差5分钟。</p>
<h2 id="维表Join"><a href="#维表Join" class="headerlink" title="维表Join"></a>维表Join</h2><h3 id="启用AsyncIO"><a href="#启用AsyncIO" class="headerlink" title="启用AsyncIO"></a>启用AsyncIO</h3><h3 id="时间表Join-Temporal-Table-Join"><a href="#时间表Join-Temporal-Table-Join" class="headerlink" title="时间表Join: Temporal Table Join"></a>时间表Join: Temporal Table Join</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">o.amout, o.currency, r.rate, o.amount <span class="operator">*</span> r.rate</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">Orders <span class="keyword">AS</span> o</span><br><span class="line"><span class="keyword">JOIN</span> LatestRates <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> o.proctime <span class="keyword">AS</span> r</span><br><span class="line"><span class="keyword">ON</span> r.currency <span class="operator">=</span> o.currency</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>Flink-SQL实践</title>
    <url>/bigdata/Flink/Flink-SQL-active/</url>
    <content><![CDATA[<h1 id="Flink-SQL-active"><a href="#Flink-SQL-active" class="headerlink" title="Flink-SQL-active"></a>Flink-SQL-active</h1><p>维表同步脚本:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span></span><br><span class="line"><span class="keyword">into</span></span><br><span class="line">    dim_result_lct_activy_config</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        Fact_id,</span><br><span class="line">        <span class="built_in">LAST_VALUE</span>(Fact_name),</span><br><span class="line">        FROM_UNIXTIME(UNIX_TIMESTAMP(<span class="built_in">LAST_VALUE</span>(Fact_start_time)),</span><br><span class="line">        <span class="string">&#x27;yyyyMMddHHmmss&#x27;</span>) <span class="keyword">as</span> startTime,</span><br><span class="line">        FROM_UNIXTIME(UNIX_TIMESTAMP(<span class="built_in">LAST_VALUE</span>(Fact_end_time)),</span><br><span class="line">        <span class="string">&#x27;yyyyMMddHHmmss&#x27;</span>) <span class="keyword">as</span> endTime,</span><br><span class="line">        <span class="built_in">LAST_VALUE</span>(Fstate)</span><br><span class="line">    <span class="keyword">from</span></span><br><span class="line">        db_act_config_t_act_logic_config</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">        Fact_id</span><br></pre></td></tr></table></figure>
<p><a href="http://apache-flink.147419.n8.nabble.com/FlinkSQL-Upsert-Retraction-MySQL-td2785.html">FlinkSQL Upsert/Retraction 写入 MySQL 的问题 </a></p>
<p> retract流是算子的特性，不同的算子不同，比如group by聚合算子天生就是会发retract流的，比如你之前算出来的是a, 1, 后面变化了，变成了a,2，所以group by算子会发-a,1, +a,2.</p>
<p>像join的话也是有retract流的，比如outer join</p>
<p>当然如果下游sink支持upsert, 这块也会有优化，会优化为update。</p>
<blockquote>
<p>INSERT INTO  mysql_sink SELECT  f1, count(*) FROM kafka_src GROUP BY f1<br>每从 kafka 过来一条新的记录，会生成两条记录 Tuple2&lt;Row, Boolean&gt;, 旧的被删除，新的会添加上。这是query是会一个会产生retract stream的query，可以简单理解成每条kafka的数据过来会产生两条记录，但是最终写入下游的系统。需要看下游的系统支持和实现的sink(现在有三种sink AppendStreamSink, UpsertStreamSink, RetractStreamSink)</p>
</blockquote>
<blockquote>
<p>我看 <a href="https://github.com/apache/flink/tree/master/flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc">https://github.com/apache/flink/tree/master/flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc</a> 没有 Retract 方式<br>实际上使用了 JDBCUpsertTableSink.java 的代码写入 MySQL 吗？<br>现有的sink中，kafka是实现的AppendStreamSink，所以只支持insert 的记录，不支持retract.<br>你用DDL声明的mysql表，对应的jdbc sink 是JDBCUpsertTableSink，所以会按照Upsert的逻辑处理, 也不支持retract。</p>
</blockquote>
<blockquote>
<p>如若不带 group by 直接：<br>INSERT INTO  mysql_sink SELECT  f1,  f2 FROM kafka_src<br>主键冲突写入 mysql 是会出错的，怎么可以用 Upsert 的方式直接覆盖呢？</p>
</blockquote>
<p>不带 group by时无法推导出query的 unique key，没法做按照unique key的更新，<br>只需要将 query的 key （你这里是group by 后的字段）和db中主键保持一致即可</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink-语法糖</title>
    <url>/bigdata/Flink/Flink-SQL-syntactic-sugar/</url>
    <content><![CDATA[<h1 id="Flink-SQL语法"><a href="#Flink-SQL语法" class="headerlink" title="Flink-SQL语法"></a>Flink-SQL语法</h1><p><a href="https://github.com/ververica/sql-training/wiki">Apache Flink SQL training</a></p>
<h2 id="group-window"><a href="#group-window" class="headerlink" title="group window"></a>group window</h2><p>groupByWindow会直接生成回撤流</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span>       </span><br><span class="line"><span class="keyword">into</span></span><br><span class="line">    dim_result_lct_activy_config</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        Fact_id,</span><br><span class="line">        <span class="built_in">LAST_VALUE</span>(Fact_name),</span><br><span class="line">        regexp_Replace( <span class="built_in">LAST_VALUE</span>(Fact_start_time), <span class="string">&#x27;-|:|\s&#x27;</span>,<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> startTime,</span><br><span class="line">        regexp_Replace(<span class="built_in">LAST_VALUE</span>(Fact_end_time),<span class="string">&#x27;-|:|\s&#x27;</span>,<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> endTime,</span><br><span class="line">        <span class="built_in">LAST_VALUE</span>(Fstate)                               </span><br><span class="line">    <span class="keyword">from</span></span><br><span class="line">        db_act_config_t_act_logic_config         </span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">        Fact_id</span><br></pre></td></tr></table></figure>
<p>这是一个同步数据的demo，db_act_config_t_act_logic_config 是kafka数据源，来自源MySQL的变更数据；dim_result_lct_activy_config是目的表，Fact_id为主键。</p>
<h4 id="group-window生成retract-stream"><a href="#group-window生成retract-stream" class="headerlink" title="group window生成retract stream"></a>group window生成retract stream</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> mysql_sink <span class="keyword">select</span> fkey,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> cnt <span class="keyword">from</span> kafka_source <span class="keyword">group</span> <span class="keyword">by</span> fkey</span><br></pre></td></tr></table></figure>
<p>上述语句是一个group window, 每从kafka中过来一条数据，都会产生两条记录(<code>Tuple2&lt;Row,Boolean&gt;</code>), 删除旧记录，添加新记录。</p>
<p>group window会产生 <code>retract stream</code>, 下游系统必须支持<code>retract stream</code>，(目前共有三种sink: <code>AppendStreamSink</code>, <code>UpsertStreamSink</code>, <code>RetractStreamSink</code> )</p>
<p>Flink-connector-JDBC 使用的是<code>JDBCUpsertTableSink.java</code>写入MySQL, 支持Retract</p>
<p> <a href="https://github.com/apache/flink/tree/master/flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc">https://github.com/apache/flink/tree/master/flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc</a> </p>
<p>Flink-connector-kafka 实现的是 <code>AppendStreamSink</code>，只支持insert，不支持retract. 会报错</p>
<p><code>AppendStreamTableSink requires that Table has only insert changes</code></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> mysql_sink <span class="keyword">select</span> fkey,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> cnt <span class="keyword">from</span> kafka_source</span><br></pre></td></tr></table></figure>
<p>如果不带<code>group by</code>, 无法推导出unique key, 无法按照unique key更新</p>
<p><a href="http://apache-flink.147419.n8.nabble.com/FlinkSQL-Upsert-Retraction-MySQL-td2785.html">http://apache-flink.147419.n8.nabble.com/FlinkSQL-Upsert-Retraction-MySQL-td2785.html</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * Get dialect upsert statement, the database has its own upsert syntax, such as Mysql </span></span><br><span class="line"><span class="comment"> * using DUPLICATE KEY UPDATE, and PostgresSQL using ON CONFLICT... DO UPDATE SET.. </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> None if dialect does not support upsert statement, the writer will degrade to </span></span><br><span class="line"><span class="comment"> * the use of select + update/insert, this performance is poor. </span></span><br><span class="line"><span class="comment"> */</span> </span><br><span class="line"><span class="function"><span class="keyword">default</span> Optional&lt;String&gt; <span class="title">getUpsertStatement</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">   String tableName, String[] fieldNames, String[] uniqueKeyFields)</span> </span>&#123; </span><br><span class="line"><span class="keyword">return</span> Optional.empty(); </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>不同的数据库产品有不同的语句，所以默认实现是delete +insert </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">executeBatch</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123; </span><br><span class="line">  <span class="keyword">if</span> (keyToRows.size() &gt; <span class="number">0</span>) &#123; </span><br><span class="line">  <span class="keyword">for</span> (Map.Entry&lt;Row, Tuple2&lt;Boolean, Row&gt;&gt; entry : keyToRows.entrySet()) &#123; </span><br><span class="line">       Row pk = entry.getKey(); </span><br><span class="line">       Tuple2&lt;Boolean, Row&gt; tuple = entry.getValue(); </span><br><span class="line">       <span class="keyword">if</span> (tuple.f0) &#123; </span><br><span class="line">          processOneRowInBatch(pk, tuple.f1); </span><br><span class="line">       &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">          setRecordToStatement(deleteStatement, pkTypes, pk); </span><br><span class="line">          deleteStatement.addBatch(); </span><br><span class="line">       &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     internalExecuteBatch(); </span><br><span class="line">     deleteStatement.executeBatch(); </span><br><span class="line">     keyToRows.clear(); </span><br><span class="line">  &#125; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<h2 id="Over-window"><a href="#Over-window" class="headerlink" title="Over window"></a>Over window</h2><p><a href="https://zhuanlan.zhihu.com/p/92654574">SQL窗口函数</a> 传统SQL窗口函数的介绍</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">	to_char(SYSTIMESTAMP(),<span class="string">&#x27;yyyymmddhh24miss&#x27;</span>) fetl_time,</span><br><span class="line">	<span class="operator">*</span> </span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line">  <span class="keyword">select</span></span><br><span class="line">      <span class="operator">*</span>,</span><br><span class="line">  		<span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> fid <span class="keyword">order</span> <span class="keyword">by</span> fmodify_time <span class="keyword">desc</span>,exp_time_stample_order <span class="keyword">desc</span>) rn </span><br><span class="line">  <span class="keyword">from</span> </span><br><span class="line">  		db.table1 </span><br><span class="line">  <span class="keyword">where</span> </span><br><span class="line">  		fdate<span class="operator">=</span><span class="number">20210101</span></span><br><span class="line">) t</span><br><span class="line"><span class="keyword">where</span> rn<span class="operator">=</span><span class="number">1</span> </span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(amount) <span class="keyword">OVER</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">user</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">  <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span>)</span><br><span class="line"><span class="keyword">FROM</span> Orders;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(amount) <span class="keyword">OVER</span> w, <span class="built_in">SUM</span>(amount) <span class="keyword">OVER</span> w</span><br><span class="line"><span class="keyword">FROM</span> Orders </span><br><span class="line"><span class="keyword">WINDOW</span> w <span class="keyword">AS</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">user</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">  <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span>)  ;</span><br></pre></td></tr></table></figure>

<h3 id="OVER-窗口应用示例"><a href="#OVER-窗口应用示例" class="headerlink" title="OVER 窗口应用示例"></a>OVER 窗口应用示例</h3><p>首先通过 DDL 定义源数据表和结果表，如下输入是用户行为消息，输出到计算结果消息。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `user_action` (</span><br><span class="line">    `user_id` <span class="type">VARCHAR</span>,</span><br><span class="line">    `page_id` <span class="type">VARCHAR</span>,</span><br><span class="line">    `action_type` <span class="type">VARCHAR</span>,</span><br><span class="line">    `event_time` <span class="type">TIMESTAMP</span>,</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> event_time <span class="keyword">AS</span> event_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">&#x27;connector.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;connector.topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;user_action&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;connector.version&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;0.11&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;connector.properties.0.key&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;bootstrap.servers&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;connector.properties.0.value&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;xxx:9092&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;connector.startup-mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;update-mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;append&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;...&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;...&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `agg_result` (</span><br><span class="line">    `user_id` <span class="type">VARCHAR</span>,</span><br><span class="line">    `page_id` <span class="type">VARCHAR</span>,</span><br><span class="line">    `result_type` <span class="type">VARCHAR</span>,</span><br><span class="line">    `result_value` <span class="type">BIGINT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">&#x27;connector.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;connector.topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;agg_result&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;...&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;...&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>场景一，实时触发的最近2小时用户+页面维度的点击量，注意窗口是向前2小时，类似于实时触发的滑动窗口。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span></span><br><span class="line">    agg_result</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    user_id,</span><br><span class="line">    page_id,</span><br><span class="line">    <span class="string">&#x27;click-type1&#x27;</span> <span class="keyword">as</span> result_type</span><br><span class="line">    <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">OVER</span> (</span><br><span class="line">        <span class="keyword">PARTITION</span> <span class="keyword">BY</span> user_id, page_id</span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> event_time </span><br><span class="line">        <span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="type">INTERVAL</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">HOUR</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">    ) <span class="keyword">as</span> result_value</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    user_action</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    action_type <span class="operator">=</span> <span class="string">&#x27;click&#x27;</span></span><br></pre></td></tr></table></figure>
<p>场景二，实时触发的当天用户+页面维度的浏览量，这就是开篇问题解法，其中多了一个日期维度分组条件，这样就做到输出结果从滑动时间转为固定时间（根据时间区间分组），因为 WATERMARK 机制，今天并不会有昨天数据到来（如果有都被自动抛弃），因此只会输出今天的分组结果。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span></span><br><span class="line">    agg_result</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    user_id,</span><br><span class="line">    page_id,</span><br><span class="line">    <span class="string">&#x27;view-type1&#x27;</span> <span class="keyword">as</span> result_type</span><br><span class="line">    <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">OVER</span> (</span><br><span class="line">        <span class="keyword">PARTITION</span> <span class="keyword">BY</span> user_id, page_id, DATE_FORMAT(event_time, <span class="string">&#x27;yyyyMMdd&#x27;</span>)</span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> event_time </span><br><span class="line">        <span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">DAY</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">    ) <span class="keyword">as</span> result_value</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    user_action</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    action_type <span class="operator">=</span> <span class="string">&#x27;view&#x27;</span></span><br></pre></td></tr></table></figure>
<p>场景三，实时触发的当天用户+页面点击率 CTR（Click-Through-Rate），这相比前面增加了多个 OVER 聚合计算，可以将窗口定义写在最后。注意示例中缺少了类型转换，因为除法结果是 decimal，也缺少精度处理函数 ROUND。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span></span><br><span class="line">    agg_result</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    user_id,</span><br><span class="line">    page_id,</span><br><span class="line">    <span class="string">&#x27;ctr-type1&#x27;</span> <span class="keyword">as</span> result_type,</span><br><span class="line">    <span class="built_in">sum</span>(</span><br><span class="line">        <span class="keyword">case</span></span><br><span class="line">            <span class="keyword">when</span> action_type <span class="operator">=</span> <span class="string">&#x27;click&#x27;</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    ) <span class="keyword">OVER</span> w </span><br><span class="line">    <span class="operator">/</span> </span><br><span class="line">    if(</span><br><span class="line">        <span class="built_in">sum</span>(</span><br><span class="line">            <span class="keyword">case</span></span><br><span class="line">                <span class="keyword">when</span> action_type <span class="operator">=</span> <span class="string">&#x27;view&#x27;</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        ) <span class="keyword">OVER</span> w <span class="operator">=</span> <span class="number">0</span>,</span><br><span class="line">        <span class="number">1</span>,</span><br><span class="line">        <span class="built_in">sum</span>(</span><br><span class="line">            <span class="keyword">case</span></span><br><span class="line">                <span class="keyword">when</span> action_type <span class="operator">=</span> <span class="string">&#x27;view&#x27;</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        ) <span class="keyword">OVER</span> w</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">as</span> result_value</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    user_action</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    <span class="number">1</span> <span class="operator">=</span> <span class="number">1</span> </span><br><span class="line"><span class="keyword">WINDOW</span> w <span class="keyword">AS</span> (</span><br><span class="line">        <span class="keyword">PARTITION</span> <span class="keyword">BY</span> user_id, page_id, DATE_FORMAT(event_time,<span class="string">&#x27;yyyyMMdd&#x27;</span>)</span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> event_time </span><br><span class="line">        <span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">DAY</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>此外，OVER 窗口聚合还可以支持查询子句、关联查询、UNION ALL 等组合，并可以实现对关联出来的列进行聚合等复杂情况。</p>
<h3 id="实时TopN"><a href="#实时TopN" class="headerlink" title="实时TopN"></a>实时TopN</h3><p><a href="https://blog.csdn.net/wangpei1949/article/details/105471974">SQL实时TopN</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> source_kafka </span><br><span class="line">( </span><br><span class="line">    userID String, </span><br><span class="line">    eventType String, </span><br><span class="line">    eventTime String, </span><br><span class="line">    productID String </span><br><span class="line">) <span class="keyword">with</span> ( </span><br><span class="line">    <span class="string">&#x27;connector.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;connector.version&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;0.10&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;connector.properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka01:9092&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;connector.properties.zookeeper.connect&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka01:2181&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;connector.topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test_1&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;connector.properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;c1_test_1&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;connector.startup-mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;format.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span> </span><br><span class="line">);</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> sink_mysql</span><br><span class="line">(</span><br><span class="line">    datetime STRING,</span><br><span class="line">    productID STRING,</span><br><span class="line">    userID STRING,</span><br><span class="line">    clickPV <span class="type">BIGINT</span></span><br><span class="line">) <span class="keyword">with</span> (</span><br><span class="line"><span class="string">&#x27;connector.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;connector.url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://localhost:3306/bigdata&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;connector.table&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;t_product_click_topn&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;connector.username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;connector.password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;bigdata&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;connector.write.flush.max-rows&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;50&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;connector.write.flush.interval&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2s&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;connector.write.max-retries&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_mysql </span><br><span class="line"><span class="keyword">SELECT</span> datetime, productID, userID, clickPV </span><br><span class="line"><span class="keyword">FROM</span> ( </span><br><span class="line">  <span class="keyword">SELECT</span> <span class="operator">*</span>, </span><br><span class="line">     <span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> datetime, productID <span class="keyword">ORDER</span> <span class="keyword">BY</span> clickPV <span class="keyword">desc</span>) <span class="keyword">AS</span> rownum </span><br><span class="line">  <span class="keyword">FROM</span> ( </span><br><span class="line">        <span class="keyword">SELECT</span> <span class="built_in">SUBSTRING</span>(eventTime,<span class="number">1</span>,<span class="number">13</span>) <span class="keyword">AS</span> datetime, </span><br><span class="line">            productID, </span><br><span class="line">            userID, </span><br><span class="line">            <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">AS</span> clickPV </span><br><span class="line">        <span class="keyword">FROM</span> source_kafka </span><br><span class="line">        <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="built_in">SUBSTRING</span>(eventTime,<span class="number">1</span>,<span class="number">13</span>), productID, userID </span><br><span class="line">    ) a </span><br><span class="line">) t </span><br><span class="line"><span class="keyword">WHERE</span> rownum <span class="operator">&lt;=</span> <span class="number">3</span>&quot;;               </span><br></pre></td></tr></table></figure>


<h3 id="OVER-窗口问题和优化"><a href="#OVER-窗口问题和优化" class="headerlink" title="OVER 窗口问题和优化"></a>OVER 窗口问题和优化</h3><p>在底层实现中，所有细分 OVER 窗口的数据都是共享的，只存一份，这点不像滑动窗口会保存多份窗口数据。但是 OVER  窗口会把所有数据明细存在状态后端中（内存、RocksDB 或  HDFS），每一次窗口计算后会清除过期数据。因此如果向前窗口时间较大，或数据明细过多，可能会占用大量内存，即使通过 RocksDB  存在磁盘上，也有因为磁盘访问慢导致性能下降进而产生反压问题。在实现源码 <code>RowTimeRangeBoundedPrecedingFunction</code> 可以看到虽然每次窗口计算时新增聚合值和减少过期聚合值是增量式的，不用遍历全部窗口明细，但是为了计算过期数据，即超过 PRECEDING  的数据，仍然需要把存储的那些时间戳全部拿出来遍历，判断是否过期，以及是否要减少聚合值。我们尝试了通过数据有序性减少查询操作，但是效果并不明显，目前主要是配置调优和加大任务分片数进行优化。</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink SQL inside</title>
    <url>/bigdata/Flink/Flink-SQL-inside/</url>
    <content><![CDATA[<p><a href="https://github.com/ververica/sql-training/wiki">Apache Flink® SQL Training</a></p>
<h1 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h1><ul>
<li>Flink SQL/Table 如何转化为Flink graph?</li>
<li>Blink 进行了什么优化?</li>
</ul>
<p>本节将主要从 SQL/Table API 如何转化为真正的 Job Graph 的流程开始，让大家对 Blink Planner 有一个比较清晰的认识，希望对大家阅读 Blink 代码，或者使用 Blink 方面有所帮助。然后介绍 Blink Planner 的改进及优化。</p>
<p><img src="vx_images/5763696502773"> </p>
<p>从上图可以很清楚的看到，解析的过程涉及到了三层：Table API/SQL，Blink Planner，Runtime，下面将对主要的步骤进行讲解：</p>
<p>Table API&amp;SQL 解析验证：在 Flink 1.9 中，Table API 进行了大量的重构，引入了一套新的 Operation，这套 Operation 主要是用来描述任务的 Logic Tree。</p>
<p>当 SQL 传输进来后，首先会去做 SQL 解析，SQL 解析完成之后，会得到 SqlNode Tree(抽象语法树)，然后会紧接着去做 Validator（验证），验证时会去访问 FunctionManger 和 CatalogManger，FunctionManger 主要是查询用户定义的 UDF，以及检查 UDF 是否合法，CatalogManger 主要是检查这个 Table 或者 Database 是否存在，如果验证都通过，就会生成一个 Operation DAG（有向无环图）。</p>
<p>从这一步可以看出，Table API 和 SQL 在 Flink 中最终都会转化为统一的结构，即 Operation DAG。</p>
<p>生成RelNode：Operation DAG 会被转化为 RelNode(关系表达式) DAG。</p>
<p>优化：优化器会对 RelNode 做各种优化，优化器的输入是各种优化的规则，以及各种统计信息。当前，在 Blink Planner 里面，绝大部分的优化规则，Stream 和 Batch 是共享的。差异在于，对 Batch 而言，它没有 state 的概念，而对于 Stream 而言，它是不支持 sort 的，所以目前 Blink Planner 中，还是运行了两套独立的规则集（Rule Set），然后定义了两套独立的 Physical Rel：BatchPhysical Rel 和 StreamPhysical Rel。优化器优化的结果，就是具体的 Physical Rel DAG。</p>
<p>转化：得到 Physical Rel Dag 后，继续会转化为 ExecNode，通过名字可以看出，ExecNode 已经属于执行层的概念了，但是这个执行层是 Blink 的执行层，在 ExecNode 中，会进行大量的 CodeGen 的操作，还有非 Code 的 Operator 操作，最后，将 ExecNode 转化为 Transformation DAG。</p>
<p>**生成可执行 Job Graph：**得到 Transformation DAG 后，最终会被转化成 Job Graph，完成 SQL 或者 Table API 的解析。</p>
<h3 id="Blink-Planner-改进及优化"><a href="#Blink-Planner-改进及优化" class="headerlink" title="Blink Planner 改进及优化"></a>Blink Planner 改进及优化</h3><p>Blink Planner 功能方面改进主要包含如下几个方面：</p>
<ul>
<li>  更完整的 SQL 语法支持：例如，IN，EXISTS，NOT EXISTS，子查询，完整的 Over 语句，Group Sets 等。而且已经跑通了所有的 TPCH，TPCDS 这两个测试集，性能还非常不错。</li>
<li>  提供了更丰富，高效的算子。</li>
<li>  提供了非常完善的 cost 模型，同时能够对接 Catalog 中的统计信息，使 cost 根据统计信息得到更优的执行计划。</li>
<li>  支持 join reorder。</li>
<li>  shuffle service：对 Batch 而言，Blink Planner 还支持 shuffle service，这对 Batch 作业的稳定性有非常大的帮助，如果遇到 Batch 作业失败，通过 shuffle service 能够很快的进行恢复。</li>
</ul>
<p>性能方面，主要包括以下部分：</p>
<ul>
<li><p>  分段优化。</p>
</li>
<li><p>  Sub-Plan Reuse。</p>
</li>
<li><p>  更丰富的优化 Rule：共一百多个 Rule ，并且绝大多数 Rule 是 Stream 和 Batch 共享的。</p>
</li>
<li><p>  更高效的数据结构 BinaryRow：能够节省序列化和反序列化的操作。</p>
</li>
<li><p>  mini-batch 支持（仅 Stream）：节省 state 的访问的操作。</p>
</li>
<li><p>  节省多余的 Shuffle 和 Sort（Batch 模式）：两个算子之间，如果已经按 A 做 Shuffle，紧接着他下的下游也是需要按 A Shuffle 的数据，那中间的这一层 Shuffle，就可以省略，这样就可以省很多网络的开销，Sort 的情况也是类似。Sort 和 Shuffle 如果在整个计算里面是占大头，对整个性能是有很大的提升的。</p>
</li>
</ul>
<h3 id="深入性能优化及实践"><a href="#深入性能优化及实践" class="headerlink" title="深入性能优化及实践"></a>深入性能优化及实践</h3><p>本节中，将使用具体的示例进行讲解，让你深入理解 Blink Planner 性能优化的设计。</p>
<h4 id="分段优化"><a href="#分段优化" class="headerlink" title="分段优化"></a>分段优化</h4><p>示例 5</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> MyView <span class="keyword">as</span> <span class="keyword">select</span> word, <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> freq <span class="keyword">from</span> SourceTable <span class="keyword">group</span> <span class="keyword">by</span> word; <span class="keyword">insert</span> <span class="keyword">into</span> SinkTable1 <span class="keyword">select</span> \<span class="operator">*</span> <span class="keyword">from</span> MyView <span class="keyword">where</span> freq <span class="operator">&gt;</span><span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> SinkTable2 <span class="keyword">select</span> <span class="built_in">count</span>(word) <span class="keyword">as</span> freq2, freq <span class="keyword">from</span> MyView <span class="keyword">group</span> <span class="keyword">by</span> freq; </span><br></pre></td></tr></table></figure>
<p>复制代码</p>
<p>上面的这几个 SQL，转化为 RelNode DAG，大致图形如下：</p>
<p><img src="vx_images/5754200881233">  </p>
<p>图5 示例5 RelNode DAG</p>
<p>如果是使用 Flink Planner，经过优化层后，会生成如下执行层的 DAG：</p>
<p><img src="vx_images/5742768787093">  </p>
<p>图6 示例 5 Flink Planner DAG</p>
<p>可以看到，Flink Planner 只是简单的从 Sink 出发，反向的遍历到 Source，从而形成两个独立的执行链路，从上图也可以清楚的看到，Scan 和第一层 Aggregate 是有重复计算的。</p>
<p>在 Blink Planner 中，经过优化层之后，会生成如下执行层的 DAG：</p>
<p><img src="vx_images/5732658916907">  </p>
<p>图7 示例 5 Blink Planner DAG</p>
<p>Blink Planner 不是在每次调用 insert into 的时候就开始优化，而是先将所有的 insert into 操作缓存起来，等到执行前才进行优化，这样就可以看到完整的执行图，可以知道哪些部分是重复计算的。Blink Planner 通过寻找可以优化的最大公共子图，找到这些重复计算的部分。经过优化后，Blink Planner 会将最大公共子图的部分当做一个临时表，供其他部分直接使用。</p>
<p>这样，上面的图可以分为三部分，最大公共子图部分（临时表），临时表与 Filter 和 SinkTable1 优化，临时表与第二个 Aggregate 和 SinkTable 2 优化。</p>
<p>Blink Planner 其实是通过声明的 View 找到最大公共子图的，因此在开发过程中，如果需要复用某段逻辑，就将其定义为 View，这样就可以充分利用 Blink Planner 的分段优化功能，减少重复计算。</p>
<p>当然，当前的优化也不是最完美的，因为提前对图进行了切割，可能会导致一些优化丢失，今后会持续地对这部分算法进行改进。</p>
<p>总结一下，Blink Planner 的分段优化，其实解的是多 Sink 优化问题（DAG 优化），单 Sink 不是分段优化关心的问题，单 Sink 可以在所有节点上优化，不需要分段。</p>
<h4 id="Sub-Plan-Reuse"><a href="#Sub-Plan-Reuse" class="headerlink" title="Sub-Plan Reuse"></a>Sub-Plan Reuse</h4><p>示例 6</p>
<p>insert into SinkTabl</p>
<p>select freq from (select word, count(1) as freq from SourceTable group by word) t where word like ‘T%’</p>
<p>union all</p>
<p>select count(word) as freq2 from (select word, count(1) as freq from SourceTable group by word) t group by freq; </p>
<p>复制代码</p>
<p>这个示例的 SQL 和分段优化的 SQL 其实是类似的，不同的是，没有将结果 Sink 到两个 Table 里面，而是将结果 Union 起来，Sink 到一个结果表里面。</p>
<p>下面看一下转化为 RelNode 的 DAG 图：</p>
<p><img src="vx_images/5722510102563">  </p>
<p>图 8 示例 6 RelNode DAG</p>
<p>从上图可以看出，Scan 和第一层的 Aggregate 也是有重复计算的，Blink Planner 其实也会将其找出来，变成下面的图：</p>
<p><img src="vx_images/5711511556085">  </p>
<p>图9 示例 6 Blink Planner DAG</p>
<p>Sub-Plan 优化的启用，有两个相关的配置：</p>
<ul>
<li><p>  table.optimizer.reuse-sub-plan-enabled （默认开启）</p>
</li>
<li><p>  table.optimizer.reuse-source-enabled（默认开启）</p>
</li>
</ul>
<p>这两个配置，默认都是开启的，用户可以根据自己的需求进行关闭。这里主要说明一下 table.optimizer.reuse-source-enabled 这个参数。在 Batch 模式下，join 操作可能会导致死锁，具体场景是在执行 hash-join 或者 nested-loop-join 时一定是先读 build 端，然后再读 probe 端，如果启用 reuse-source-enabled，当数据源是同一个 Source 的时候，Source 的数据会同时发送给 build 和 probe 端。这时候，build 端的数据将不会被消费，导致 join 操作无法完成，整个 join 就被卡住了。</p>
<p>为了解决死锁问题，Blink Planner 会先将 probe 端的数据落盘，这样 build 端读数据的操作才会正常，等 build 端的数据全部读完之后，再从磁盘中拉取 probe 端的数据，从而解决死锁问题。但是，落盘会有额外的开销，会多一次写的操作；有时候，读两次 Source 的开销，可能比一次写的操作更快，这时候，可以关闭 reuse-source，性能会更好。当然，如果读两次 Source 的开销，远大于一次落盘的开销，可以保持 reuse-source 开启。需要说明的是，Stream 模式是不存在死锁问题的，因为 Stream 模式 join 不会有选边的问题。</p>
<p>总结而言，sub-plan reuse 解的问题是优化结果的子图复用问题，它和分段优化类似，但他们是一个互补的过程。</p>
<p>注：Hash Join：对于两张待 join 的表 t1, t2。选取其中的一张表按照 join 条件给的列建立hash 表。然后扫描另外一张表，一行一行去建好的 hash 表判断是否有对应相等的行来完成 join 操作，这个操作称之为 probe (探测)。前一张表叫做 build 表，后一张表的叫做 probe 表。</p>
<h4 id="Agg-分类优化"><a href="#Agg-分类优化" class="headerlink" title="Agg 分类优化"></a>Agg 分类优化</h4><p>Blink 中的 Aggregate 操作是非常丰富的：</p>
<ul>
<li><p>  group agg，例如：select count(a) from t group by b</p>
</li>
<li><p>  over agg，例如：select count(a) over (partition by b order by c) from t</p>
</li>
<li><p>  window agg，例如：select count(a) from t group by tumble(ts, interval ‘10’ second), b</p>
</li>
<li><p>  table agg ，例如：tEnv.scan(‘t’).groupBy(‘a’).flatAggregate(flatAggFunc(‘b’ as (‘c’, ‘d’)))</p>
</li>
</ul>
<p>下面主要对 Group Agg 优化进行讲解，主要是两类优化。</p>
<p>1. Local/Global Agg 优化</p>
<p>Local/Global Agg 主要是为了减少网络 Shuffle。要运用 Local/Global 的优化，必要条件如下：</p>
<ul>
<li><p>  Aggregate 的所有 Agg Function 都是 mergeable 的，每个 Aggregate 需要实现 merge 方法，例如 SUM，COUNT，AVG，这些都是可以分多阶段完成，最终将结果合并；但是求中位数，计算 95% 这种类似的问题，无法拆分为多阶段，因此，无法运用 Local/Global 的优化。</p>
</li>
<li><p>  table.optimizer.agg-phase-strategy 设置为 AUTO 或者 TWO_PHASE。</p>
</li>
<li><p>  Stream 模式下，mini-batch 开启 ；Batch 模式下 AUTO 会根据 cost 模型加上统计数据，选择是否进行 Local/Global 优化。</p>
</li>
</ul>
<p>示例 7</p>
<p>select count(*) from t group by color</p>
<p>复制代码</p>
<p>没有优化的情况下，下面的这个 Aggregate 会产生 10 次的 Shuffle 操作。</p>
<p><img src="vx_images/5702882869443">  </p>
<p>图 10 示例 7 未做优化的 Count 操作</p>
<p>使用 Local/Global 优化后，会转化为下面的操作，会在本地先进行聚合，然后再进行 Shuffle 操作，整个 Shuffle 的数据剩下 6 条。在 Stream 模式下，Blink 其实会以 mini-batch 的维度对结果进行预聚合，然后将结果发送给 Global Agg 进行汇总。</p>
<p><img src="vx_images/5692318921039">  </p>
<p>图 11 示例 7 经过 Local/Global 优化的 Count 操作</p>
<p>2. Distinct Agg 优化</p>
<p>Distinct Agg 进行优化，主要是对 SQL 语句进行改写，达到优化的目的。但 Batch 模式和 Stream 模式解决的问题是不同的：</p>
<ul>
<li><p>  Batch 模式下的 Distinct Agg，需要先做 Distinct，再做 Agg，逻辑上需要两步才能实现，直接实现 Distinct Agg 开销太大。</p>
</li>
<li><p>  Stream 模式下，主要是解决热点问题，因为 Stream 需要将所有的输入数据放在 State 里面，如果数据有热点，State 操作会很频繁，这将影响性能。</p>
</li>
</ul>
<p>Batch 模式</p>
<p>第一层，求 distinct 的值和非 distinct agg function 的值，第二层求 distinct agg function 的值</p>
<p>示例 8</p>
<p>select color, count(distinct id), count(*) from t group by color </p>
<p>复制代码</p>
<p>手工改写成：</p>
<p>select color, count(id), min(cnt) from (</p>
<p>select color, id, count(*) filter (where $e=2) as cnt from (</p>
<p>select color, id, 1 as $e from t –for distinct id</p>
<p>union all</p>
<p>select color, null as id, 2 as $e from t – for count(*)</p>
<p>) group by color, id, $e</p>
<p>) group by color </p>
<p>复制代码</p>
<p>转化的逻辑过程，如下图所示：</p>
<p><img src="vx_images/5681295595288">  </p>
<p>图 12 示例 8 Batch 模式 Distinct 改写逻辑</p>
<p>Stream 模式</p>
<p>Stream 模式的启用有一些必要条件：</p>
<ul>
<li><p>  必须是支持的 agg function：avg/count/min/max/sum/first_value/concat_agg/single_value；</p>
</li>
<li><p>  table.optimizer.distinct-agg.split.enabled（默认关闭）</p>
</li>
</ul>
<p>示例 9</p>
<p>select color, count(distinct id), count(*) from t group by color </p>
<p>复制代码</p>
<p>手工改写成：</p>
<p>select color, sum(dcnt), sum(cnt) from (</p>
<p>select color, count(distinct id) as dcnt, count(*) as cnt from t</p>
<p>group by color, mod(hash_code(id), 1024)</p>
<p>) group by color</p>
<p>复制代码</p>
<p>改写前，逻辑图大概如下：</p>
<p><img src="vx_images/5669686806196">  </p>
<p>图 13 示例 9 Stream 模式未优化 Distinct</p>
<p>改写后，逻辑图就会变为下面这样，热点数据被打散到多个中间节点上。</p>
<p><img src="vx_images/5659004248673">  </p>
<p>图14 示例 9 Stream 模式优化 Distinct</p>
<p>需要注意的是，示例 5 的 SQL 中 mod(hash_code(id),1024)中的这个 1024 为打散的维度，这个值建议设置大一些，设置太小产生的效果可能不好。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文首先对新的 TableEnvironment 的整体设计进行了介绍，并且列举了各种模式下TableEnvironment 的选择，然后通过具体的示例，展示了各种模式下代码的写法，以及需要注意的事项。</p>
<p>在新的 Catalog 和 DDL 部分，对 Catalog 的整体设计、DDL 的使用部分也都以实例进行拆分讲解。最后，对 Blink Planner 解析 SQL/Table API 的流程、Blink Planner 的改进以及优化的原理进行了讲解，希望对大家探索和使用 Flink SQL 有所帮助。</p>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p><img src="_v_images/20201030204716034_449053674"></p>
<p>新版本的Table &amp; SQL API在原有的Table API基础上，由Calcite提供SQL解析和优化能力，将Table API调用和SQL查询统一转换成Calcite逻辑执行计划（Calcite RelNode树），并对此进行优化和代码生成，最终同样转化成Flink DataStream/DataSet API调用代码。</p>
<p>一般在使用的时候需要分别注册Source表 和 Sink表，分别对应数据的输入和输出。<br>对于注册Source表，可以<strong>从内部的catalog注册</strong>；也可以从TableSource注册；还可以通过DataSet转换注册。<br>对于SInk表，一般就直接通过TableSink注册了。查询时可以通过Table API执行select或者filter之类，也可以通过env.sqlQuery执行查询。<br>写入时可以通过table.insertInto()执行写操作，也可以通过env.sqlUpdate()执行写入。<br>这里还要吐槽下：弄一个sql()自动判断查询和写入不好么，为什么要区分update和insert?</p>
<h2 id="SQL原理"><a href="#SQL原理" class="headerlink" title="SQL原理"></a>SQL原理</h2><p>Table &amp; SQL API基于scala和java编写，内部基于calcite实现标准sql的解析和校验。跟spark不一样，flink直接基于开源的calcite编写。<br>calcite本身是一个apache的开源项目，它独立于存储和执行，专门负责sql的解析优化、语法树的校验等，并且通过插件的方式可以很方便的扩展优化规则，广泛的应用在hive、solr、flink等中。</p>
<p><img src="_v_images/20201030205455658_1363203717.jpg"></p>
<p>在Flink中通过tableEnv.sqlQuery和tableEnv.sqlUpdate可以看到具体的calcite使用流程。query与update的操作其实内部差不多，都是解析、校验、转换，不过sqlUpdate最后会基于内部的Table增加一个insertInto的操作。</p>
<p><img src="_v_images/20201030205455452_457126200.jpg"></p>
<p>以sqlQuery为例，先来看看整体的流程：</p>
<p><img src="_v_images/20201030205455347_1666287840.jpg"></p>
<p>首先创建FlinkPlannerImpl的执行计划，然后调用parse方法，内部直接使用calcite的SqlParser形成语法树。此时的语法树其实是一个个的SqlNode，这个SqlNode是calcite中定义，不同的sql有不同的sqlNode实现。比如最常见的SqlSelect，SqlJoin，SqlInsert等。每个类中会有自己的一些组件，比如SqlSelect会有group by, from, where, selectList等等。</p>
<p>获得语法树后，会通过一个简单的校验，判断是否为QUERY或者INSERT。然后经过一个通用的validate校验，粗略的看了下有catalog、表达式等的校验。最后通过rel把calcite的SqlNode转换成RelNode即逻辑执行计划。</p>
<p><img src="_v_images/20201030205455242_164668059.png"></p>
<p>Table后续在使用时会通过translate转换成一个DataSet，内部会先进行优化（优化过程既包括calcite提供的默认优化规则，也有Flink扩展的规则），最后生成物理执行计划。物理执行计划会按照node类型的不同将node转换成dataset或datastream的API。</p>
<p><img src="_v_images/20201030205455038_55047340.jpg"></p>
<p>总结来说，Flink SQL通过calcite实现：</p>
<ul>
<li>解析（字符串SQL转AST抽象语法树）</li>
<li>校验（语法、表达式、表信息）</li>
<li>优化（剪枝、谓词下推）</li>
<li>转换（逻辑计划转换成物理执行计划=Node转换成DataSet\DataStream API）</li>
<li>最终把SQL转换成DataSet或DataStream的API。</li>
</ul>
<h2 id="Flink-SQL-的编译及优化过程"><a href="#Flink-SQL-的编译及优化过程" class="headerlink" title="Flink SQL 的编译及优化过程"></a>Flink SQL 的编译及优化过程</h2><ul>
<li>Flink SQL 利用 Apache Calcite 将 SQL 翻译为关系代数表达式，使用表达式折叠（Expression Reduce），下推优化（Predicate / Projection Pushdown ）等优化技术生成物理执行计划（Physical Plan），利用 Codegen 技术生成高效执行代码。</li>
<li>Flink SQL 使用高效的二进制数据存储结构 BinaryRow 加速计算性能；使用 Mini-batch 攒批提高吞吐，降低两层聚合时由 Retraction 引起的数据抖动；聚合场景下数据倾斜处理和 Top-N 排序的优化原理。</li>
</ul>
<h2 id="表注册"><a href="#表注册" class="headerlink" title="表注册"></a>表注册</h2><h3 id="虚表注册"><a href="#虚表注册" class="headerlink" title="虚表注册"></a>虚表注册</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取一个TableEnvironment</span></span><br><span class="line"><span class="type">TableEnvironment</span> tableEnv = ...;</span><br><span class="line"><span class="comment">// table对象，查询的结果集</span></span><br><span class="line"><span class="type">Table</span> projTable = tableEnv.from(<span class="string">&quot;X&quot;</span>).select(...);</span><br><span class="line"><span class="comment">// 注册一个表，名称为 &quot;projectedTable&quot;</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;projectedTable&quot;</span>, projTable);</span><br></pre></td></tr></table></figure>
<h3 id="外部表注册"><a href="#外部表注册" class="headerlink" title="外部表注册"></a>外部表注册</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">tableEnvironment</span><br><span class="line">  .connect(...)</span><br><span class="line">  .withFormat(...)</span><br><span class="line">  .withSchema(...)</span><br><span class="line">  .inAppendMode()</span><br><span class="line">  .createTemporaryTable(<span class="string">&quot;MyTable&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="catalog与db是两个概念"><a href="#catalog与db是两个概念" class="headerlink" title="catalog与db是两个概念"></a>catalog与db是两个概念</h3><p>表的注册总是包含三部分标识属性：catalog、数据库、表名。用户可以在内部设置一个catalog和一个数据库作为当前的catalog和数据库，所以对于catalog和数据库这两个标识属性是可选的，即如果不指定，默认使用的是“current catalog”和 “current database”。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">TableEnvironment tEnv = ...;</span><br><span class="line">tEnv.useCatalog(<span class="string">&quot;custom_catalog&quot;</span>);<span class="comment">//设置catalog</span></span><br><span class="line">tEnv.useDatabase(<span class="string">&quot;custom_database&quot;</span>);<span class="comment">//设置数据库</span></span><br><span class="line">Table table = ...;</span><br><span class="line"><span class="comment">// 注册一个名为exampleView的视图，catalog名为custom_catalog</span></span><br><span class="line"><span class="comment">// 数据库的名为custom_database</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;exampleView&quot;</span>, table);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册一个名为exampleView的视图，catalog的名为custom_catalog</span></span><br><span class="line"><span class="comment">// 数据库的名为other_database</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;other_database.exampleView&quot;</span>, table);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 注册一个名为&#x27;View&#x27;的视图，catalog的名称为custom_catalog</span></span><br><span class="line"><span class="comment">// 数据库的名为custom_database，&#x27;View&#x27;是保留关键字，需要使用``(反引号)</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;`View`&quot;</span>, table);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册一个名为example.View的视图，catalog的名为custom_catalog，</span></span><br><span class="line"><span class="comment">// 数据库名为custom_database</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;`example.View`&quot;</span>, table);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册一个名为&#x27;exampleView&#x27;的视图， catalog的名为&#x27;other_catalog&#x27;</span></span><br><span class="line"><span class="comment">// 数据库名为other_database&#x27; </span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;other_catalog.other_database.exampleView&quot;</span>, table);</span><br></pre></td></tr></table></figure>


<h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><p>以WordCount为例，为了增加sql的复杂度，在外层增加了filter：</p>
<p><img src="_v_images/20201030205601002_1446863552.jpg"></p>
<p>使用System.out.println(tEnv.explain(table));可以输出执行计划：</p>
<p><img src="_v_images/20201030205600897_1720675340.jpg"></p>
<p>通过parse方法获得到抽象语法树，显示一个filter节点，然后跟着Agg和scan。经过优化后，查询条件优化到最底层。最后转换生成真正的物理执行计划。</p>
<p>后续会继续研究下calcite以及optimize部分，到时再做分享。</p>
<h2 id="Retract-mode-和-Append-mode"><a href="#Retract-mode-和-Append-mode" class="headerlink" title="Retract mode 和 Append mode"></a>Retract mode 和 Append mode</h2><p>toAppendStream  只支持insert<br>toRetractStream  其余模式都可以</p>
<p>如果动态表仅只有Insert操作，即之前输出的结果不会被更新，则使用该模式。如果更新或删除操作使用追加模式会失败报错，始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回。</p>
<p>使用flinkSQL处理实时数据当我们把表转化成流的时候，需要用toAppendStream与toRetractStream这两个方法。稍不注意可能直接选择了toAppendStream。</p>
<p>始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回。</p>
<p>当我们使用的sql语句包含：count() group by时，必须使用缩进模式</p>
<p><img src="_v_images/20201111111954370_1165111473.png"><br><img src="_v_images/20201111112036578_1272633365.png"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取StreamTableEnvironment.</span></span><br><span class="line">StreamTableEnvironment tableEnv = ...;</span><br><span class="line"><span class="comment">// 包含两个字段的表(String name, Integer age)</span></span><br><span class="line">Table table = ...</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用Append Mode追加模式，数据类型为Row</span></span><br><span class="line">DataStream&lt;Row&gt; dsRow = tableEnv.toAppendStream(table, Row.class);</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用Append Mode追加模式，数据类型为定义好的TypeInformation</span></span><br><span class="line">TupleTypeInfo&lt;Tuple2&lt;String, Integer&gt;&gt; tupleType = <span class="keyword">new</span> TupleTypeInfo&lt;&gt;(</span><br><span class="line">  Types.STRING(),</span><br><span class="line">  Types.INT());</span><br><span class="line">  DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dsTuple =</span><br><span class="line">  tableEnv.toAppendStream(table, tupleType);</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用的模式为Retract Mode撤回模式，类型为Row</span></span><br><span class="line"><span class="comment">// 对于转换后的DataStream&lt;Tuple2&lt;Boolean, X&gt;&gt;，X表示流的数据类型，</span></span><br><span class="line"><span class="comment">// boolean值表示数据改变的类型，其中INSERT返回true，DELETE返回的是false</span></span><br><span class="line">DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; retractStream</span><br><span class="line">  tableEnv.toRetractStream(table, Row.class);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="如何实现回退更新"><a href="#如何实现回退更新" class="headerlink" title="如何实现回退更新?"></a>如何实现回退更新?</h3><p>flink-connector-jdbc 最终使用的是SQL引擎的upsert语法:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tbl() <span class="keyword">values</span> ( ),( ) <span class="keyword">on</span> duplicate key <span class="keyword">update</span></span><br></pre></td></tr></table></figure>
<p>可以看下 MySQL/upsert 一节</p>
<p>对应flink 源码</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">org.apache.flink.connector.jdbc.dialect.MySQLDialect#getUpsertStatement</span><br></pre></td></tr></table></figure>



<h2 id="keyedBy与group-by区别"><a href="#keyedBy与group-by区别" class="headerlink" title="keyedBy与group by区别"></a>keyedBy与group by区别</h2><h2 id="SQL解析工具"><a href="#SQL解析工具" class="headerlink" title="SQL解析工具"></a>SQL解析工具</h2><p>hive使用了antlr3实现了自己的HQL,<br>Flink使用Apache Calcite,<br>而Calcite的解析器是使用JavaCC实现的,<br>Spark2.x以后采用了antlr4实现自己的解析器,<br>Presto也是使用antlr4。</p>
<h2 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h2><p>在Apache Flink中有2种类型的Window，一种是OverWindow，即传统数据库的标准开窗，每一个元素都对应一个窗口。一种是GroupWindow，目前在SQL中GroupWindow都是基于时间进行窗口划分的。</p>
<h3 id="Over-Window"><a href="#Over-Window" class="headerlink" title="Over Window"></a>Over Window</h3><p>Apache Flink中对OVER Window的定义遵循标准SQL的定义语法。<br>按ROWS和RANGE分类是传统数据库的标准分类方法，在Apache Flink中还可以根据时间类型(ProcTime/EventTime)和窗口的有限和无限(Bounded/UnBounded)进行分类，共计8种类型。为了避免大家对过细分类造成困扰，我们按照确定当前行的不同方式将OVER Window分成两大类进行介绍，如下:</p>
<ul>
<li>  ROWS OVER Window - 每一行元素都视为新的计算行，即，每一行都是一个新的窗口。</li>
<li>  RANGE OVER Window - 具有相同时间值的所有元素行视为同一计算行，即，具有相同时间值的所有行都是同一个窗口。</li>
</ul>
<h4 id="Bounded-ROWS-OVER-Window"><a href="#Bounded-ROWS-OVER-Window" class="headerlink" title="Bounded ROWS OVER Window"></a>Bounded ROWS OVER Window</h4><p>Bounded ROWS OVER Window 每一行元素都视为新的计算行，即，每一行都是一个新的窗口。</p>
<h5 id="语义"><a href="#语义" class="headerlink" title="语义"></a>语义</h5><p>我们以3个元素(2 PRECEDING)的窗口为例，如下图:<br><img src="vx_images/5456982869145.png" alt="image" title="image"></p>
<p>上图所示窗口 user 1 的 w5和w6， user 2的 窗口 w2 和 w3，虽然有元素都是同一时刻到达，但是他们仍然是在不同的窗口，这一点有别于RANGE OVER Window。</p>
<h5 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h5><p>Bounded ROWS OVER Window 语法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    agg1(col1) <span class="keyword">OVER</span>(</span><br><span class="line">     [<span class="keyword">PARTITION</span> <span class="keyword">BY</span> (value_expression1,..., value_expressionN)] </span><br><span class="line">     <span class="keyword">ORDER</span> <span class="keyword">BY</span> timeCol</span><br><span class="line">     <span class="keyword">ROWS</span> </span><br><span class="line">     <span class="keyword">BETWEEN</span> (UNBOUNDED <span class="operator">|</span> rowCount) PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span>) <span class="keyword">AS</span> colName, </span><br><span class="line">... </span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br></pre></td></tr></table></figure>
<ul>
<li>  value_expression - 进行分区的字表达式；</li>
<li>  timeCol - 用于元素排序的时间字段；</li>
<li>  rowCount - 是定义根据当前行开始向前追溯几行元素。</li>
</ul>
<h5 id="SQL-示例"><a href="#SQL-示例" class="headerlink" title="SQL 示例"></a>SQL 示例</h5><p>利用<code>item_tab</code>测试数据，我们统计同类商品中当前和当前商品之前2个商品中的最高价格。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">    itemID,</span><br><span class="line">    itemType, </span><br><span class="line">    onSellTime, </span><br><span class="line">    price,  </span><br><span class="line">    <span class="built_in">MAX</span>(price) <span class="keyword">OVER</span> (</span><br><span class="line">        <span class="keyword">PARTITION</span> <span class="keyword">BY</span> itemType </span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> onSellTime </span><br><span class="line">        <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> preceding <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span>) <span class="keyword">AS</span> maxPrice</span><br><span class="line">  <span class="keyword">FROM</span> item_tab</span><br></pre></td></tr></table></figure>
<h4 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h4><table>
<thead>
<tr>
<th>itemID</th>
<th>itemType</th>
<th>onSellTime</th>
<th>price</th>
<th>maxPrice</th>
</tr>
</thead>
<tbody><tr>
<td>ITEM001</td>
<td>Electronic</td>
<td>2017-11-11 10:01:00</td>
<td>20</td>
<td>20</td>
</tr>
<tr>
<td>ITEM002</td>
<td>Electronic</td>
<td>2017-11-11 10:02:00</td>
<td>50</td>
<td>50</td>
</tr>
<tr>
<td>ITEM003</td>
<td>Electronic</td>
<td>2017-11-11 10:03:00</td>
<td>30</td>
<td>50</td>
</tr>
<tr>
<td>ITEM004</td>
<td>Electronic</td>
<td>2017-11-11 10:03:00</td>
<td>60</td>
<td>60</td>
</tr>
<tr>
<td>ITEM005</td>
<td>Electronic</td>
<td>2017-11-11 10:05:00</td>
<td>40</td>
<td>60</td>
</tr>
<tr>
<td>ITEM006</td>
<td>Electronic</td>
<td>2017-11-11 10:06:00</td>
<td>20</td>
<td>60</td>
</tr>
<tr>
<td>ITEM007</td>
<td>Electronic</td>
<td>2017-11-11 10:07:00</td>
<td>70</td>
<td>70</td>
</tr>
<tr>
<td>ITEM008</td>
<td>Clothes</td>
<td>2017-11-11 10:08:00</td>
<td>20</td>
<td>20</td>
</tr>
</tbody></table>
<h4 id="Bounded-RANGE-OVER-Window"><a href="#Bounded-RANGE-OVER-Window" class="headerlink" title="Bounded RANGE OVER Window"></a>Bounded RANGE OVER Window</h4><p>Bounded RANGE OVER Window 具有相同时间值的所有元素行视为同一计算行，即，具有相同时间值的所有行都是同一个窗口。</p>
<h5 id="语义-1"><a href="#语义-1" class="headerlink" title="语义"></a>语义</h5><p>我们以3秒中数据(INTERVAL ‘2’ SECOND)的窗口为例，如下图：<br><img src="vx_images/5426718920741.png" alt="image" title="image"></p>
<p>注意: 上图所示窗口 user 1 的 w6， user 2的 窗口 w3，元素都是同一时刻到达,他们是在同一个窗口，这一点有别于ROWS OVER Window。</p>
<h5 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h5><p>Bounded RANGE OVER Window的语法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    agg1(col1) <span class="keyword">OVER</span>(</span><br><span class="line">     [<span class="keyword">PARTITION</span> <span class="keyword">BY</span> (value_expression1,..., value_expressionN)] </span><br><span class="line">     <span class="keyword">ORDER</span> <span class="keyword">BY</span> timeCol</span><br><span class="line">     <span class="keyword">RANGE</span> </span><br><span class="line">     <span class="keyword">BETWEEN</span> (UNBOUNDED <span class="operator">|</span> timeInterval) PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span>) <span class="keyword">AS</span> colName, </span><br><span class="line">... </span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br></pre></td></tr></table></figure>
<ul>
<li>  value_expression - 进行分区的字表达式；</li>
<li>  timeCol - 用于元素排序的时间字段；</li>
<li>  timeInterval - 是定义根据当前行开始向前追溯指定时间的元素行；</li>
</ul>
<h5 id="SQL-示例-1"><a href="#SQL-示例-1" class="headerlink" title="SQL 示例"></a>SQL 示例</h5><p>我们统计同类商品中当前和当前商品之前2分钟商品中的最高价格。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">    itemID,</span><br><span class="line">    itemType, </span><br><span class="line">    onSellTime, </span><br><span class="line">    price,  </span><br><span class="line">    <span class="built_in">MAX</span>(price) <span class="keyword">OVER</span> (</span><br><span class="line">        <span class="keyword">PARTITION</span> <span class="keyword">BY</span> itemType </span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> rowtime </span><br><span class="line">        <span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="type">INTERVAL</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">MINUTE</span> preceding <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span>) <span class="keyword">AS</span> maxPrice</span><br><span class="line">  <span class="keyword">FROM</span> item_tab</span><br></pre></td></tr></table></figure>
<h5 id="Result（Bounded-RANGE-OVER-Window）"><a href="#Result（Bounded-RANGE-OVER-Window）" class="headerlink" title="Result（Bounded RANGE OVER Window）"></a>Result（Bounded RANGE OVER Window）</h5><table>
<thead>
<tr>
<th>itemID</th>
<th>itemType</th>
<th>onSellTime</th>
<th>price</th>
<th>maxPrice</th>
</tr>
</thead>
<tbody><tr>
<td>ITEM001</td>
<td>Electronic</td>
<td>2017-11-11 10:01:00</td>
<td>20</td>
<td>20</td>
</tr>
<tr>
<td>ITEM002</td>
<td>Electronic</td>
<td>2017-11-11 10:02:00</td>
<td>50</td>
<td>50</td>
</tr>
<tr>
<td>ITEM003</td>
<td>Electronic</td>
<td><strong><em>2017-11-11 10:03:00</em></strong></td>
<td>30</td>
<td>60</td>
</tr>
<tr>
<td>ITEM004</td>
<td>Electronic</td>
<td><strong><em>2017-11-11 10:03:00</em></strong></td>
<td>60</td>
<td>60</td>
</tr>
<tr>
<td>ITEM005</td>
<td>Electronic</td>
<td>2017-11-11 10:05:00</td>
<td>40</td>
<td>60</td>
</tr>
<tr>
<td>ITEM006</td>
<td>Electronic</td>
<td>2017-11-11 10:06:00</td>
<td>20</td>
<td>40</td>
</tr>
<tr>
<td>ITEM007</td>
<td>Electronic</td>
<td>2017-11-11 10:07:00</td>
<td>70</td>
<td>70</td>
</tr>
<tr>
<td>ITEM008</td>
<td>Clothes</td>
<td>2017-11-11 10:08:00</td>
<td>20</td>
<td>20</td>
</tr>
</tbody></table>
<h4 id="特别说明"><a href="#特别说明" class="headerlink" title="特别说明"></a>特别说明</h4><p>OverWindow最重要是要理解每一行数据都确定一个窗口，同时目前在Apache Flink中只支持按时间字段排序。并且OverWindow开窗与GroupBy方式数据分组最大的不同在于，GroupBy数据分组统计时候，在<code>SELECT</code>中除了GROUP BY的key，不能直接选择其他非key的字段，但是OverWindow没有这个限制，<code>SELECT</code>可以选择任何字段。比如一张表table(a,b,c,d)4个字段，如果按d分组求c的最大值，两种写完如下:</p>
<ul>
<li>  GROUP BY - <code>SELECT d, MAX(c) FROM table GROUP BY d</code></li>
<li>OVER Window = <code>SELECT a, b, c, d, MAX(c) OVER(PARTITION BY d, ORDER BY ProcTime())</code><br>  如上 OVER Window 虽然PARTITION BY d,但SELECT 中仍然可以选择 a,b,c字段。但在GROUPBY中，SELECT 只能选择 d 字段。</li>
</ul>
<h3 id="Group-Window"><a href="#Group-Window" class="headerlink" title="Group Window"></a>Group Window</h3><p>根据窗口数据划分的不同，目前Apache Flink有如下3种Bounded Winodw:</p>
<ul>
<li>  Tumble - 滚动窗口，窗口数据有固定的大小，窗口数据无叠加；</li>
<li>  Hop - 滑动窗口，窗口数据有固定大小，并且有固定的窗口重建频率，窗口数据有叠加；</li>
<li>  Session - 会话窗口，窗口数据没有固定的大小，根据窗口数据活跃程度划分窗口，窗口数据无叠加。</li>
</ul>
<p><strong>说明：</strong> Aapche Flink 还支持UnBounded的 Group Window，也就是全局Window，流上所有数据都在一个窗口里面，语义非常简单，这里不做详细介绍了。</p>
<h4 id="Tumble"><a href="#Tumble" class="headerlink" title="Tumble"></a>Tumble</h4><h5 id="语义-2"><a href="#语义-2" class="headerlink" title="语义"></a>语义</h5><p>Tumble 滚动窗口有固定size，窗口数据不重叠,具体语义如下：<br><img src="vx_images/5385895594990.png" alt="image" title="image"></p>
<h5 id="语法-2"><a href="#语法-2" class="headerlink" title="语法"></a>语法</h5><p>Tumble 滚动窗口对应的语法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    [gk],</span><br><span class="line">    [TUMBLE_START(timeCol, size)], </span><br><span class="line">    [TUMBLE_END(timeCol, size)], </span><br><span class="line">    agg1(col1), </span><br><span class="line">    ... </span><br><span class="line">    aggn(colN)</span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> [gk], TUMBLE(timeCol, size)</span><br></pre></td></tr></table></figure>
<ul>
<li>  [gk] - 决定了流是Keyed还是/Non-Keyed;</li>
<li>  TUMBLE_START - 窗口开始时间;</li>
<li>  TUMBLE_END - 窗口结束时间;</li>
<li>  timeCol - 是流表中表示时间字段；</li>
<li>  size - 表示窗口的大小，如 秒，分钟，小时，天。</li>
</ul>
<h5 id="SQL-示例-2"><a href="#SQL-示例-2" class="headerlink" title="SQL 示例"></a>SQL 示例</h5><p>利用<code>pageAccess_tab</code>测试数据，我们需要按不同地域统计每2分钟的淘宝首页的访问量(PV)。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">    region,</span><br><span class="line">    TUMBLE_START(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winStart,  </span><br><span class="line">    TUMBLE_END(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winEnd,  </span><br><span class="line">    <span class="built_in">COUNT</span>(region) <span class="keyword">AS</span> pv</span><br><span class="line"><span class="keyword">FROM</span> pageAccess_tab </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> region, TUMBLE(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">MINUTE</span>)</span><br></pre></td></tr></table></figure>
<h5 id="Result-1"><a href="#Result-1" class="headerlink" title="Result"></a>Result</h5><table>
<thead>
<tr>
<th>region</th>
<th>winStart</th>
<th>winEnd</th>
<th>pv</th>
</tr>
</thead>
<tbody><tr>
<td>BeiJing</td>
<td>2017-11-11 02:00:00.0</td>
<td>2017-11-11 02:02:00.0</td>
<td>1</td>
</tr>
<tr>
<td>BeiJing</td>
<td>2017-11-11 02:10:00.0</td>
<td>2017-11-11 02:12:00.0</td>
<td>2</td>
</tr>
<tr>
<td>ShangHai</td>
<td>2017-11-11 02:00:00.0</td>
<td>2017-11-11 02:02:00.0</td>
<td>1</td>
</tr>
<tr>
<td>ShangHai</td>
<td>2017-11-11 04:10:00.0</td>
<td>2017-11-11 04:12:00.0</td>
<td>1</td>
</tr>
</tbody></table>
<h4 id="Hop"><a href="#Hop" class="headerlink" title="Hop"></a>Hop</h4><p>Hop 滑动窗口和滚动窗口类似，窗口有固定的size，与滚动窗口不同的是滑动窗口可以通过slide参数控制滑动窗口的新建频率。因此当slide值小于窗口size的值的时候多个滑动窗口会重叠。</p>
<h5 id="语义-3"><a href="#语义-3" class="headerlink" title="语义"></a>语义</h5><p>Hop 滑动窗口语义如下所示：<br><img src="vx_images/5354486805898.png" alt="image" title="image"></p>
<h5 id="语法-3"><a href="#语法-3" class="headerlink" title="语法"></a>语法</h5><p>Hop 滑动窗口对应语法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    [gk], </span><br><span class="line">    [HOP_START(timeCol, slide, size)] ,  </span><br><span class="line">    [HOP_END(timeCol, slide, size)],</span><br><span class="line">    agg1(col1), </span><br><span class="line">    ... </span><br><span class="line">    aggN(colN) </span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> [gk], HOP(timeCol, slide, size)</span><br></pre></td></tr></table></figure>
<ul>
<li>  [gk] 决定了流是Keyed还是/Non-Keyed;</li>
<li>  HOP_START - 窗口开始时间;</li>
<li>  HOP_END - 窗口结束时间;</li>
<li>  timeCol - 是流表中表示时间字段；</li>
<li>  slide - 是滑动步伐的大小；</li>
<li>  size - 是窗口的大小，如 秒，分钟，小时，天；</li>
</ul>
<h5 id="SQL-示例-3"><a href="#SQL-示例-3" class="headerlink" title="SQL 示例"></a>SQL 示例</h5><p>利用<code>pageAccessCount_tab</code>测试数据，我们需要每5分钟统计近10分钟的页面访问量(PV).</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">  HOP_START(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winStart,  </span><br><span class="line">  HOP_END(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winEnd,  </span><br><span class="line">  <span class="built_in">SUM</span>(accessCount) <span class="keyword">AS</span> accessCount  </span><br><span class="line"><span class="keyword">FROM</span> pageAccessCount_tab </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> HOP(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>)</span><br></pre></td></tr></table></figure>
<h5 id="Result-2"><a href="#Result-2" class="headerlink" title="Result"></a>Result</h5><table>
<thead>
<tr>
<th>winStart</th>
<th>winEnd</th>
<th>accessCount</th>
</tr>
</thead>
<tbody><tr>
<td>2017-11-11 01:55:00.0</td>
<td>2017-11-11 02:05:00.0</td>
<td>186</td>
</tr>
<tr>
<td>2017-11-11 02:00:00.0</td>
<td>2017-11-11 02:10:00.0</td>
<td>396</td>
</tr>
<tr>
<td>2017-11-11 02:05:00.0</td>
<td>2017-11-11 02:15:00.0</td>
<td>243</td>
</tr>
<tr>
<td>2017-11-11 02:10:00.0</td>
<td>2017-11-11 02:20:00.0</td>
<td>33</td>
</tr>
<tr>
<td>2017-11-11 04:05:00.0</td>
<td>2017-11-11 04:15:00.0</td>
<td>129</td>
</tr>
<tr>
<td>2017-11-11 04:10:00.0</td>
<td>2017-11-11 04:20:00.0</td>
<td>129</td>
</tr>
</tbody></table>
<h4 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h4><p>Seeeion 会话窗口 是没有固定大小的窗口，通过session的活跃度分组元素。不同于滚动窗口和滑动窗口，会话窗口不重叠,也没有固定的起止时间。一个会话窗口在一段时间内没有接收到元素时，即当出现非活跃间隙时关闭。一个会话窗口 分配器通过配置session gap来指定非活跃周期的时长.</p>
<h5 id="语义-4"><a href="#语义-4" class="headerlink" title="语义"></a>语义</h5><p>Session 会话窗口语义如下所示：</p>
<p><img src="vx_images/5324204248375.png" alt="image" title="image"></p>
<h5 id="语法-4"><a href="#语法-4" class="headerlink" title="语法"></a>语法</h5><p>Seeeion 会话窗口对应语法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    [gk], </span><br><span class="line">    SESSION_START(timeCol, gap) <span class="keyword">AS</span> winStart,  </span><br><span class="line">    SESSION_END(timeCol, gap) <span class="keyword">AS</span> winEnd,</span><br><span class="line">    agg1(col1),</span><br><span class="line">     ... </span><br><span class="line">    aggn(colN)</span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> [gk], SESSION(timeCol, gap)</span><br></pre></td></tr></table></figure>
<ul>
<li>  [gk] 决定了流是Keyed还是/Non-Keyed;</li>
<li>  SESSION_START - 窗口开始时间；</li>
<li>  SESSION_END - 窗口结束时间；</li>
<li>  timeCol - 是流表中表示时间字段；</li>
<li>  gap - 是窗口数据非活跃周期的时长；</li>
</ul>
<h5 id="SQL-示例-4"><a href="#SQL-示例-4" class="headerlink" title="SQL 示例"></a>SQL 示例</h5><p>利用<code>pageAccessSession_tab</code>测试数据，我们按地域统计连续的两个访问用户之间的访问时间间隔不超过3分钟的的页面访问量(PV).</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">    region, </span><br><span class="line">    SESSION_START(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;3&#x27;</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winStart,  </span><br><span class="line">    SESSION_END(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;3&#x27;</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winEnd, </span><br><span class="line">    <span class="built_in">COUNT</span>(region) <span class="keyword">AS</span> pv  </span><br><span class="line"><span class="keyword">FROM</span> pageAccessSession_tab</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> region, SESSION(rowtime, <span class="type">INTERVAL</span> <span class="string">&#x27;3&#x27;</span> <span class="keyword">MINUTE</span>)</span><br></pre></td></tr></table></figure>
<h5 id="Result-3"><a href="#Result-3" class="headerlink" title="Result"></a>Result</h5><table>
<thead>
<tr>
<th>region</th>
<th>winStart</th>
<th>winEnd</th>
<th>pv</th>
</tr>
</thead>
<tbody><tr>
<td>BeiJing</td>
<td>2017-11-11 02:10:00.0</td>
<td>2017-11-11 02:13:00.0</td>
<td>1</td>
</tr>
<tr>
<td>ShangHai</td>
<td>2017-11-11 02:01:00.0</td>
<td>2017-11-11 02:08:00.0</td>
<td>4</td>
</tr>
<tr>
<td>ShangHai</td>
<td>2017-11-11 02:10:00.0</td>
<td>2017-11-11 02:14:00.0</td>
<td>2</td>
</tr>
<tr>
<td>ShangHai</td>
<td>2017-11-11 04:16:00.0</td>
<td>2017-11-11 04:19:00.0</td>
<td>1</td>
</tr>
</tbody></table>
<h2 id="UDX"><a href="#UDX" class="headerlink" title="UDX"></a>UDX</h2><p>Apache Flink 除了提供了大部分ANSI-SQL的核心算子，也为用户提供了自己编写业务代码的机会，那就是User-Defined Function,目前支持如下三种 User-Defined Function：</p>
<ul>
<li>  UDF - User-Defined Scalar Function</li>
<li>  UDTF - User-Defined Table Function</li>
<li>  UDAF - User-Defined Aggregate Funciton</li>
</ul>
<p>UDX都是用户自定义的函数，那么Apache Flink框架为啥将自定义的函数分成三类呢？是根据什么划分的呢？Apache Flink对自定义函数进行分类的依据是根据函数语义的不同，函数的输入和输出不同来分类的，具体如下：</p>
<table>
<thead>
<tr>
<th>UDX</th>
<th>INPUT</th>
<th>OUTPUT</th>
<th>INPUT:OUTPUT</th>
</tr>
</thead>
<tbody><tr>
<td>UDF</td>
<td>单行中的N(N&gt;=0)列</td>
<td>单行中的1列</td>
<td>1:1</td>
</tr>
<tr>
<td>UDTF</td>
<td>单行中的N(N&gt;=0)列</td>
<td>M(M&gt;=0)行</td>
<td>1:N(N&gt;=0)</td>
</tr>
<tr>
<td>UDAF</td>
<td>M(M&gt;=0)行中的每行的N(N&gt;=0)列</td>
<td>单行中的1列</td>
<td>M：1(M&gt;=0)</td>
</tr>
</tbody></table>
<h3 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h3><ul>
<li>定义<br>  用户想自己编写一个字符串联接的UDF，我们只需要实现<code>ScalarFunction#eval()</code>方法即可，简单实现如下：</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyConnect</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="meta">@varargs</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(args: <span class="type">String</span>*): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sb = <span class="keyword">new</span> <span class="type">StringBuilder</span></span><br><span class="line">    <span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; args.length) &#123;</span><br><span class="line">      <span class="keyword">if</span> (args(i) == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">      &#125;</span><br><span class="line">      sb.append(args(i))</span><br><span class="line">      i += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    sb.toString</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>  使用</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> fun = <span class="type">MyConnect</span></span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;myConnect&quot;</span>, fun)</span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;SELECT myConnect(a, b) as str FROM tab&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="UDTF"><a href="#UDTF" class="headerlink" title="UDTF"></a>UDTF</h3><ul>
<li>定义<br>  用户想自己编写一个字符串切分的UDTF，我们只需要实现<code>TableFunction#eval()</code>方法即可，简单实现如下：</li>
</ul>
<p>ScalarFunction#eval()`</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySplit</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>[<span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(str: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (str.contains(<span class="string">&quot;#&quot;</span>))&#123;</span><br><span class="line">      str.split(<span class="string">&quot;#&quot;</span>).foreach(collect)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(str: <span class="type">String</span>, prefix: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (str.contains(<span class="string">&quot;#&quot;</span>)) &#123;</span><br><span class="line">      str.split(<span class="string">&quot;#&quot;</span>).foreach(s =&gt; collect(prefix + s))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>  使用</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> fun = <span class="keyword">new</span> <span class="type">MySplit</span>()</span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;mySplit&quot;</span>, fun)</span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;SELECT c, s FROM MyTable, LATERAL TABLE(mySplit(c)) AS T(s)&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="UDAF"><a href="#UDAF" class="headerlink" title="UDAF"></a>UDAF</h3><ul>
<li>定义<br>  UDAF 要实现的接口比较多，我们以一个简单的CountAGG为例，做简单实现如下：</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountAccumulator</span> <span class="keyword">extends</span> <span class="title">JTuple1</span>[<span class="type">Long</span>] </span>&#123;</span><br><span class="line">  f0 = <span class="number">0</span>L </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCount</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">JLong</span>, <span class="type">CountAccumulator</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(acc: <span class="type">CountAccumulator</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    acc.f0 += <span class="number">1</span>L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">retract</span></span>(acc: <span class="type">CountAccumulator</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    acc.f0 -= <span class="number">1</span>L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(acc: <span class="type">CountAccumulator</span>, value: <span class="type">Any</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (value != <span class="literal">null</span>) &#123;</span><br><span class="line">      acc.f0 += <span class="number">1</span>L</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">retract</span></span>(acc: <span class="type">CountAccumulator</span>, value: <span class="type">Any</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (value != <span class="literal">null</span>) &#123;</span><br><span class="line">      acc.f0 -= <span class="number">1</span>L</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>(acc: <span class="type">CountAccumulator</span>): <span class="type">JLong</span> = &#123;</span><br><span class="line">    acc.f0</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(acc: <span class="type">CountAccumulator</span>, its: <span class="type">JIterable</span>[<span class="type">CountAccumulator</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> iter = its.iterator()</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">      acc.f0 += iter.next().f0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">CountAccumulator</span> = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">CountAccumulator</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">resetAccumulator</span></span>(acc: <span class="type">CountAccumulator</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    acc.f0 = <span class="number">0</span>L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getAccumulatorType</span></span>: <span class="type">TypeInformation</span>[<span class="type">CountAccumulator</span>] = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">TupleTypeInfo</span>(classOf[<span class="type">CountAccumulator</span>], <span class="type">BasicTypeInfo</span>.<span class="type">LONG_TYPE_INFO</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getResultType</span></span>: <span class="type">TypeInformation</span>[<span class="type">JLong</span>] =</span><br><span class="line">    <span class="type">BasicTypeInfo</span>.<span class="type">LONG_TYPE_INFO</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>  使用</li>
</ul>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> fun = <span class="keyword">new</span> <span class="type">MyCount</span>()</span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;myCount&quot;</span>, fun)</span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;SELECT myCount(c) FROM MyTable GROUP BY  a&quot;</span></span><br></pre></td></tr></table></figure>
<p>上面我们介绍了Apache Flink SQL核心算子的语法及语义，这部分将选取Bounded EventTime Tumble Window为例为大家编写一个完整的包括Source和Sink定义的Apache Flink SQL Job。假设有一张淘宝页面访问表(PageAccess_tab)，有地域，用户ID和访问时间。我们需要按不同地域统计每2分钟的淘宝首页的访问量(PV). 具体数据如下：</p>
<table>
<thead>
<tr>
<th>region</th>
<th>userId</th>
<th>accessTime</th>
</tr>
</thead>
<tbody><tr>
<td>ShangHai</td>
<td>U0010</td>
<td>2017-11-11 10:01:00</td>
</tr>
<tr>
<td>BeiJing</td>
<td>U1001</td>
<td>2017-11-11 10:01:00</td>
</tr>
<tr>
<td>BeiJing</td>
<td>U2032</td>
<td>2017-11-11 10:10:00</td>
</tr>
<tr>
<td>BeiJing</td>
<td>U1100</td>
<td>2017-11-11 10:11:00</td>
</tr>
<tr>
<td>ShangHai</td>
<td>U0011</td>
<td>2017-11-11 12:10:00</td>
</tr>
</tbody></table>
<p>大家都知道，在 Flink 中，通过 Table API 和 SQL 实现的流处理逻辑，最终会翻译为基于 DataStreamAPI 实现的 DataStream 作业，返回这个作业输出的 DataStream (writeToSink 本质上也是先得到 DataStream 作业，再为其输出 DataStream 加上一个DataStreamSink) 。</p>
<p>从一段 SQL 到 DataStream 作业，其过程简单描述如下：</p>
<ol>
<li><p> 在 TableEnvironment，即“表环境”，将数据源注册为动态表。例如，通过表环境的接口`registerDataStream`, 作为源的DataStream，即数据流, 在表环境注册为动态表</p>
</li>
<li><p> 通过表环境的接口 `sqlQuery`，将 SQL 构造为 Table 对象</p>
</li>
<li><p> 通过toAppendStream/toRetractedStream接口，即翻译接口，将 Table 对象表达的作业逻辑，翻译为 DataStream 作业。</p>
</li>
</ol>
<p><img src="vx_images/4467647168580" alt="图片"></p>
<p>在调用翻译接口，将 Table 对象翻译为 DataStream 作业时，通过翻译接口传入的 TTL 配置，递归传递到各个计算节点的翻译、构造逻辑里，使得翻译出来的 DataStream 算子的内部状态按照该 TTL 配置及时清理。</p>
<p>【参考文献】</p>
<ol>
<li><p><a href="http://www.10tiao.com/html/157/201707/2653162664/1.html">在数据流中使用SQL查询：Apache Flink中的动态表的持续查询</a></p>
</li>
<li><p><a href="https://jiamaoxiang.top/2020/05/25/Flink-Table-API-SQL%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/">Flink Table API &amp; SQL编程指南</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink-temporal-table-join</title>
    <url>/bigdata/Flink/Flink-SQL-temporal-table-join/</url>
    <content><![CDATA[<h1 id="Flink-temporal-table-join"><a href="#Flink-temporal-table-join" class="headerlink" title="Flink-temporal-table-join"></a>Flink-temporal-table-join</h1><p>Temporal Table记录了表历史上任何时间点所有的数据改动</p>
<h2 id="ANSI-SQL-2011-Temporal-Table示例"><a href="#ANSI-SQL-2011-Temporal-Table示例" class="headerlink" title="ANSI-SQL 2011 Temporal Table示例"></a>ANSI-SQL 2011 Temporal Table示例</h2><p>我们以一个DDL和一套DML示例说明Temporal Table的原理，DDL定义PK是可选的，下面的示例我们以不定义PK的为例进行说明：</p>
<ul>
<li>  DDL 示例</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Emp</span><br><span class="line">ENo <span class="type">INTEGER</span>,</span><br><span class="line">Sys_start <span class="type">TIMESTAMP</span>(<span class="number">12</span>) GENERATED</span><br><span class="line">ALWAYS <span class="keyword">AS</span> <span class="type">ROW</span> <span class="keyword">START</span>,</span><br><span class="line">Sys_end <span class="type">TIMESTAMP</span>(<span class="number">12</span>) GENERATED</span><br><span class="line">ALWAYS <span class="keyword">AS</span> <span class="type">ROW</span> <span class="keyword">END</span>,</span><br><span class="line">EName <span class="type">VARCHAR</span>(<span class="number">30</span>),</span><br><span class="line"><span class="keyword">PERIOD</span> <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> (Sys_start,Sys_end)</span><br><span class="line">) <span class="keyword">WITH</span> <span class="keyword">SYSTEM</span> <span class="keyword">VERSIONING</span></span><br></pre></td></tr></table></figure>
<ul>
<li>DML 示例<ul>
<li>  INSERT</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> Emp (ENo, EName) <span class="keyword">VALUES</span> (<span class="number">22217</span>, <span class="string">&#x27;Joe&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><a href="https://img.colabug.com/2018/06/5ed5fa9fbdc39f3a26b3dec9816bf691.png" title="Blink 漫谈系列 - Temporal Table JOIN"><img src="vx_images/3323646810742.png"></a></p>
<p>说明: 其中Sys_Start和Sys_End是数据库系统默认填充的。</p>
<ul>
<li><ul>
<li>  UPDATE</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> Emp <span class="keyword">SET</span> EName <span class="operator">=</span> <span class="string">&#x27;Tom&#x27;</span> <span class="keyword">WHERE</span> ENo <span class="operator">=</span> <span class="number">22217</span></span><br></pre></td></tr></table></figure>
<p><a href="https://img.colabug.com/2018/06/a7750b4fe6d6d7a9aa6f826a2e2c91e9.png" title="Blink 漫谈系列 - Temporal Table JOIN"><img src="vx_images/3312923484991.png"></a></p>
<p>说明: 假设是在 <code>2012-02-03 10:00:00</code> 执行的UPDATE，执行之后上一个值 <code>&quot;Joe&quot;</code> 的Sys_End值由 <code>9999-12-31 23:59:59</code> 变成了 <code>2012-02-03 10:00:00</code> , 也就是下一个值 <code>&quot;Tom&quot;</code> 生效的开始时间。可见我们执行的是UPDATE但是数据库里面会存在两条数据，数据值和有效期不同，也就是版本不同 。</p>
<ul>
<li>  DELETE (假设执行DELETE之前的表内容如下)</li>
</ul>
<p><a href="https://img.colabug.com/2018/06/d4524993a5a38ee8e41362845e9cab04.png" title="Blink 漫谈系列 - Temporal Table JOIN"><img src="vx_images/3301614695899.png"></a></p>
<p>DELETE FROM Emp WHERE ENo = 22217</p>
<p><a href="https://img.colabug.com/2018/06/f8cd8a5d23000609cbc13cbb17508e84.png" title="Blink 漫谈系列 - Temporal Table JOIN"><img src="vx_images/3291132138376.png"></a></p>
<p>说明: 假设我们是在 <code>2012-06-01 00:00:00</code> 执行的DELETE，则Sys_End值由 <code>9999-12-31 23:59:59</code> 变成了 <code>2012-06-01 00:00:00</code> , 也就是在执行DELETE时候没有真正的删除符合条件的行，而是系统将符合条件的行的Sys_end修改为执行DELETE的事物时间。标识数据的有效期到DELETE执行那一刻为止。</p>
<ul>
<li>  SELECT</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ENo,EName,Sys_Start,Sys_End <span class="keyword">FROM</span> Emp</span><br><span class="line"><span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> <span class="type">TIMESTAMP</span> <span class="string">&#x27;2011-01-02 00:00:00&#x27;</span></span><br></pre></td></tr></table></figure>
<p>说明: 这个查询会返回所有 <code>Sys_start &lt;= 2011-01-02 00:00:00</code> 并且 <code>Sys_end &gt; 2011-01-02 00:00:00</code> 的记录。</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>FlinkSQL与动态表</title>
    <url>/bigdata/Flink/Flink-SQL/</url>
    <content><![CDATA[<h1 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h1><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p><img src="_v_images/20201030204716034_449053674"></p>
<p>新版本的Table &amp; SQL API在原有的Table API基础上，由Calcite提供SQL解析和优化能力，将Table API调用和SQL查询统一转换成Calcite逻辑执行计划（Calcite RelNode树），并对此进行优化和代码生成，最终同样转化成Flink DataStream/DataSet API调用代码。</p>
<p>一般在使用的时候需要分别注册Source表 和 Sink表，分别对应数据的输入和输出。<br>对于注册Source表，可以从内部的catalog注册；也可以从TableSource注册；还可以通过DataSet转换注册。<br>对于SInk表，一般就直接通过TableSink注册了。查询时可以通过Table API执行select或者filter之类，也可以通过env.sqlQuery执行查询。<br>写入时可以通过table.insertInto()执行写操作，也可以通过env.sqlUpdate()执行写入。<br>这里还要吐槽下：弄一个sql()自动判断查询和写入不好么，为什么要区分update和insert?</p>
<h2 id="SQL原理"><a href="#SQL原理" class="headerlink" title="SQL原理"></a>SQL原理</h2><p>Table &amp; SQL API基于scala和java编写，内部基于calcite实现标准sql的解析和校验。跟spark不一样，flink直接基于开源的calcite编写。<br>calcite本身是一个apache的开源项目，它独立于存储和执行，专门负责sql的解析优化、语法树的校验等，并且通过插件的方式可以很方便的扩展优化规则，广泛的应用在hive、solr、flink等中。</p>
<p><img src="_v_images/20201030205455658_1363203717.jpg"></p>
<p>在Flink中通过tableEnv.sqlQuery和tableEnv.sqlUpdate可以看到具体的calcite使用流程。query与update的操作其实内部差不多，都是解析、校验、转换，不过sqlUpdate最后会基于内部的Table增加一个insertInto的操作。</p>
<p><img src="_v_images/20201030205455452_457126200.jpg"></p>
<p>以sqlQuery为例，先来看看整体的流程：</p>
<p><img src="_v_images/20201030205455347_1666287840.jpg"></p>
<p>首先创建FlinkPlannerImpl的执行计划，然后调用parse方法，内部直接使用calcite的SqlParser形成语法树。此时的语法树其实是一个个的SqlNode，这个SqlNode是calcite中定义，不同的sql有不同的sqlNode实现。比如最常见的SqlSelect，SqlJoin，SqlInsert等。每个类中会有自己的一些组件，比如SqlSelect会有group by, from, where, selectList等等。</p>
<p>获得语法树后，会通过一个简单的校验，判断是否为QUERY或者INSERT。然后经过一个通用的validate校验，粗略的看了下有catalog、表达式等的校验。最后通过rel把calcite的SqlNode转换成RelNode即逻辑执行计划。</p>
<p><img src="_v_images/20201030205455242_164668059.png"></p>
<p>Table后续在使用时会通过translate转换成一个DataSet，内部会先进行优化（优化过程既包括calcite提供的默认优化规则，也有Flink扩展的规则），最后生成物理执行计划。物理执行计划会按照node类型的不同将node转换成dataset或datastream的API。</p>
<p><img src="_v_images/20201030205455038_55047340.jpg"></p>
<p>总结来说，Flink SQL通过calcite实现：</p>
<ul>
<li>解析（字符串SQL转AST抽象语法树）</li>
<li>校验（语法、表达式、表信息）</li>
<li>优化（剪枝、谓词下推）</li>
<li>转换（逻辑计划转换成物理执行计划=Node转换成DataSet\DataStream API）</li>
<li>最终把SQL转换成DataSet或DataStream的API。</li>
</ul>
<h2 id="Flink-SQL-的编译及优化过程"><a href="#Flink-SQL-的编译及优化过程" class="headerlink" title="Flink SQL 的编译及优化过程"></a>Flink SQL 的编译及优化过程</h2><ul>
<li>Flink SQL 利用 Apache Calcite 将 SQL 翻译为关系代数表达式，使用表达式折叠（Expression Reduce），下推优化（Predicate / Projection Pushdown ）等优化技术生成物理执行计划（Physical Plan），利用 Codegen 技术生成高效执行代码。</li>
<li>Flink SQL 使用高效的二进制数据存储结构 BinaryRow 加速计算性能；使用 Mini-batch 攒批提高吞吐，降低两层聚合时由 Retraction 引起的数据抖动；聚合场景下数据倾斜处理和 Top-N 排序的优化原理。</li>
</ul>
<h2 id="表注册"><a href="#表注册" class="headerlink" title="表注册"></a>表注册</h2><h3 id="虚表注册"><a href="#虚表注册" class="headerlink" title="虚表注册"></a>虚表注册</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取一个TableEnvironment</span></span><br><span class="line"><span class="type">TableEnvironment</span> tableEnv = ...; </span><br><span class="line"><span class="comment">// table对象，查询的结果集</span></span><br><span class="line"><span class="type">Table</span> projTable = tableEnv.from(<span class="string">&quot;X&quot;</span>).select(...);</span><br><span class="line"><span class="comment">// 注册一个表，名称为 &quot;projectedTable&quot;</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;projectedTable&quot;</span>, projTable);</span><br></pre></td></tr></table></figure>
<h3 id="外部表注册"><a href="#外部表注册" class="headerlink" title="外部表注册"></a>外部表注册</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">tableEnvironment</span><br><span class="line">  .connect(...)</span><br><span class="line">  .withFormat(...)</span><br><span class="line">  .withSchema(...)</span><br><span class="line">  .inAppendMode()</span><br><span class="line">  .createTemporaryTable(<span class="string">&quot;MyTable&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="catalog与db是两个概念"><a href="#catalog与db是两个概念" class="headerlink" title="catalog与db是两个概念"></a>catalog与db是两个概念</h3><p>表的注册总是包含三部分标识属性：catalog、数据库、表名。用户可以在内部设置一个catalog和一个数据库作为当前的catalog和数据库，所以对于catalog和数据库这两个标识属性是可选的，即如果不指定，默认使用的是“current catalog”和 “current database”。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">TableEnvironment tEnv = ...;</span><br><span class="line">tEnv.useCatalog(<span class="string">&quot;custom_catalog&quot;</span>);<span class="comment">//设置catalog</span></span><br><span class="line">tEnv.useDatabase(<span class="string">&quot;custom_database&quot;</span>);<span class="comment">//设置数据库</span></span><br><span class="line">Table table = ...;</span><br><span class="line"><span class="comment">// 注册一个名为exampleView的视图，catalog名为custom_catalog</span></span><br><span class="line"><span class="comment">// 数据库的名为custom_database</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;exampleView&quot;</span>, table);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册一个名为exampleView的视图，catalog的名为custom_catalog</span></span><br><span class="line"><span class="comment">// 数据库的名为other_database</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;other_database.exampleView&quot;</span>, table);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 注册一个名为&#x27;View&#x27;的视图，catalog的名称为custom_catalog</span></span><br><span class="line"><span class="comment">// 数据库的名为custom_database，&#x27;View&#x27;是保留关键字，需要使用``(反引号)</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;`View`&quot;</span>, table);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册一个名为example.View的视图，catalog的名为custom_catalog，</span></span><br><span class="line"><span class="comment">// 数据库名为custom_database</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;`example.View`&quot;</span>, table);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册一个名为&#x27;exampleView&#x27;的视图， catalog的名为&#x27;other_catalog&#x27;</span></span><br><span class="line"><span class="comment">// 数据库名为other_database&#x27; </span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;other_catalog.other_database.exampleView&quot;</span>, table);</span><br></pre></td></tr></table></figure>


<h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><p>以WordCount为例，为了增加sql的复杂度，在外层增加了filter：</p>
<p><img src="_v_images/20201030205601002_1446863552.jpg"></p>
<p>使用System.out.println(tEnv.explain(table));可以输出执行计划：</p>
<p><img src="_v_images/20201030205600897_1720675340.jpg"></p>
<p>通过parse方法获得到抽象语法树，显示一个filter节点，然后跟着Agg和scan。经过优化后，查询条件优化到最底层。最后转换生成真正的物理执行计划。</p>
<p>后续会继续研究下calcite以及optimize部分，到时再做分享。</p>
<h2 id="Retract-mode-和-Append-mode"><a href="#Retract-mode-和-Append-mode" class="headerlink" title="Retract mode 和 Append mode"></a>Retract mode 和 Append mode</h2><p>toAppendStream  只支持insert<br>toRetractStream  其余模式都可以</p>
<p>如果动态表仅只有Insert操作，即之前输出的结果不会被更新，则使用该模式。如果更新或删除操作使用追加模式会失败报错，始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回。</p>
<p>使用flinkSQL处理实时数据当我们把表转化成流的时候，需要用toAppendStream与toRetractStream这两个方法。稍不注意可能直接选择了toAppendStream。</p>
<p>始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回。</p>
<p>当我们使用的sql语句包含：count() group by时，必须使用缩进模式</p>
<p><img src="_v_images/20201111111954370_1165111473.png"><br><img src="_v_images/20201111112036578_1272633365.png"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取StreamTableEnvironment.</span></span><br><span class="line">StreamTableEnvironment tableEnv = ...;</span><br><span class="line"><span class="comment">// 包含两个字段的表(String name, Integer age)</span></span><br><span class="line">Table table = ...</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用Append Mode追加模式，数据类型为Row</span></span><br><span class="line">DataStream&lt;Row&gt; dsRow = tableEnv.toAppendStream(table, Row.class);</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用Append Mode追加模式，数据类型为定义好的TypeInformation</span></span><br><span class="line">TupleTypeInfo&lt;Tuple2&lt;String, Integer&gt;&gt; tupleType = <span class="keyword">new</span> TupleTypeInfo&lt;&gt;(</span><br><span class="line">  Types.STRING(),</span><br><span class="line">  Types.INT());</span><br><span class="line">  DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dsTuple =</span><br><span class="line">  tableEnv.toAppendStream(table, tupleType);</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用的模式为Retract Mode撤回模式，类型为Row</span></span><br><span class="line"><span class="comment">// 对于转换后的DataStream&lt;Tuple2&lt;Boolean, X&gt;&gt;，X表示流的数据类型，</span></span><br><span class="line"><span class="comment">// boolean值表示数据改变的类型，其中INSERT返回true，DELETE返回的是false</span></span><br><span class="line">DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; retractStream</span><br><span class="line">  tableEnv.toRetractStream(table, Row.class);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="如何实现回退更新"><a href="#如何实现回退更新" class="headerlink" title="如何实现回退更新?"></a>如何实现回退更新?</h3><p>flink-connector-jdbc 最终使用的是SQL引擎的upsert语法:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tbl() <span class="keyword">values</span> ( ),( ) <span class="keyword">on</span> duplicate key <span class="keyword">update</span></span><br></pre></td></tr></table></figure>
<p>可以看下 MySQL/upsert 一节</p>
<p>对应flink 源码</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">org.apache.flink.connector.jdbc.dialect.MySQLDialect#getUpsertStatement</span><br></pre></td></tr></table></figure>



<h2 id="keyedBy与group-by区别"><a href="#keyedBy与group-by区别" class="headerlink" title="keyedBy与group by区别"></a>keyedBy与group by区别</h2><h2 id="SQL解析工具"><a href="#SQL解析工具" class="headerlink" title="SQL解析工具"></a>SQL解析工具</h2><p>hive使用了antlr3实现了自己的HQL,<br>Flink使用Apache Calcite,<br>而Calcite的解析器是使用JavaCC实现的,<br>Spark2.x以后采用了antlr4实现自己的解析器,<br>Presto也是使用antlr4。</p>
<h1 id="通过Table-api创建表"><a href="#通过Table-api创建表" class="headerlink" title="通过Table api创建表"></a>通过Table api创建表</h1><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"># create a <span class="type">Table</span> from a <span class="type">Table</span> <span class="type">API</span> query</span><br><span class="line">tapi_result = table_env.from_path(<span class="string">&quot;table1&quot;</span>).select(...)</span><br></pre></td></tr></table></figure>
<h1 id="视图-view"><a href="#视图-view" class="headerlink" title="视图 view"></a>视图 view</h1><p>【参考文献】</p>
<ol>
<li><p><a href="http://www.10tiao.com/html/157/201707/2653162664/1.html">在数据流中使用SQL查询：Apache Flink中的动态表的持续查询</a></p>
</li>
<li><p>[Flink Table API &amp; SQL编程指南(1)]<a href="https://jiamaoxiang.top/2020/05/25/Flink-Table-API-SQL%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/">https://jiamaoxiang.top/2020/05/25/Flink-Table-API-SQL%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/</a>)</p>
</li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink-state-ttl</title>
    <url>/bigdata/Flink/Flink-State-TTL/</url>
    <content><![CDATA[<h1 id="简析Flink状态生存时间（State-TTL）机制的底层实现"><a href="#简析Flink状态生存时间（State-TTL）机制的底层实现" class="headerlink" title="简析Flink状态生存时间（State TTL）机制的底层实现"></a>简析Flink状态生存时间（State TTL）机制的底层实现</h1><p><a href="https://blog.csdn.net/nazeniwaresakini/article/details/106094778">简析Flink状态生存时间（State TTL）机制的底层实现</a></p>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>从Flink 1.6版本开始，社区为状态引入了TTL（time-to-live，生存时间）机制，支持Keyed State的自动过期，有效解决了状态数据在无干预情况下无限增长导致OOM的问题。State TTL的用法很简单，<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/stream/state/state.html#state-time-to-live-ttll">官方文档</a>中给出的示例代码如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StateTtlConfig ttlConfig =</span><br><span class="line"> StateTtlConfig</span><br><span class="line"> .newBuilder(Time.seconds(<span class="number">1</span>))</span><br><span class="line"> .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)</span><br><span class="line"> .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)</span><br><span class="line"> .build();</span><br><span class="line">ValueStateDescriptor&lt;String&gt; stateDescriptor = <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">&quot;text state&quot;</span>, String.class);</span><br><span class="line">stateDescriptor.enableTimeToLive(ttlConfig);</span><br></pre></td></tr></table></figure>
<p>那么State TTL的背后又隐藏着什么样的思路呢？下面就从设置类StateTtlConfig入手开始研究（Flink代码版本为1.9.3）。</p>
<h3 id="StateTtlConfig"><a href="#StateTtlConfig" class="headerlink" title="StateTtlConfig"></a>StateTtlConfig</h3><p>该类中有5个成员属性，它们就是用户需要指定的全部参数了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> UpdateType updateType</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> StateVisibility stateVisibility</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> TtlTimeCharacteristic ttlTimeCharacteristic</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Time ttl</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> CleanupStrategies cleanupStrategies</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中，ttl参数表示用户设定的状态生存时间。而UpdateType、StateVisibility和TtlTimeCharacteristic都是枚举，分别代表状态时间戳的更新方式、过期状态数据的可见性，以及对应的时间特征。它们的含义在注释中已经解释得很清楚了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * This option value configures when to update last access timestamp which prolongs state TTL. </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">UpdateType</span> </span>&#123;    </span><br><span class="line"><span class="comment">/** TTL is disabled. State does not expire. */</span>    </span><br><span class="line">  Disabled,    </span><br><span class="line"><span class="comment">/** Last access timestamp is initialised when state is created and updated on every write operation. </span></span><br><span class="line"><span class="comment">当每次写操作时，更新时间戳</span></span><br><span class="line"><span class="comment"> */</span>    </span><br><span class="line">  OnCreateAndWrite,    </span><br><span class="line"><span class="comment">/** The same as &lt;code&gt;OnCreateAndWrite&lt;/code&gt; but also updated on read.</span></span><br><span class="line"><span class="comment">当每次读写操作时，更新时间戳</span></span><br><span class="line"><span class="comment"> */</span>    </span><br><span class="line">  OnReadAndWrite</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** * This option configures whether expired user value can be returned or not. */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">StateVisibility</span> </span>&#123;    </span><br><span class="line">  <span class="comment">/** Return expired user value if it is not cleaned up yet. */</span>    </span><br><span class="line">  ReturnExpiredIfNotCleanedUp,    </span><br><span class="line">  <span class="comment">/** Never return expired user value. */</span>    </span><br><span class="line">  NeverReturnExpired</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** * This option configures time scale to use for ttl. */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">TtlTimeCharacteristic</span> </span>&#123;    </span><br><span class="line">  <span class="comment">/** Processing time, see also &lt;code&gt;org.apache.flink.streaming.api.TimeCharacteristic.ProcessingTime&lt;/code&gt;. */</span>    </span><br><span class="line">  ProcessingTime</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Flink目前仅支持基于处理时间的State TTL，事件时间会在不久的将来支持。</p>
<p>CleanupStrategies内部类则用来规定过期状态的特殊清理策略，用户在构造StateTtlConfig时，可以通过调用以下方法之一指定。</p>
<ul>
<li><strong><code>cleanupFullSnapshot()</code></strong><br>  当对状态做全量快照时清理过期数据，对开启了增量检查点（incremental checkpoint）的RocksDB状态后端无效，对应源码中的EmptyCleanupStrategy。<br>  为什么叫做“空的”清理策略呢？因为该选项只能保证状态持久化时不包含过期数据，但TaskManager本地的过期状态则不作任何处理，所以无法从根本上解决OOM的问题，需要定期重启作业。</li>
<li><strong><code>cleanupIncrementally(int cleanupSize, boolean runCleanupForEveryRecord)</code></strong><br>  增量清理过期数据，默认在每次访问状态时进行清理，将runCleanupForEveryRecord设为true可以附加在每次写入/删除时清理。cleanupSize指定每次触发清理时检查的状态条数。<br>  仅对基于堆的状态后端有效，对应源码中的IncrementalCleanupStrategy。</li>
<li><strong><code>cleanupInRocksdbCompactFilter(long queryTimeAfterNumEntries)</code></strong><br>  当RocksDB做compaction操作时，通过Flink定制的过滤器（FlinkCompactionFilter）过滤掉过期状态数据。参数queryTimeAfterNumEntries用于指定在写入多少条状态数据后，通过状态时间戳来判断是否过期。<br>  该策略仅对RocksDB状态后端有效，对应源码中的RocksdbCompactFilterCleanupStrategy。CompactionFilter是RocksDB原生提供的机制，其说明可见<a href="https://links.jianshu.com/go?to=https://github.com/facebook/rocksdb/wiki/Compaction-Filter">这里</a>。</li>
</ul>
<p>如果不调用上述方法，则采用默认的后台清理策略，下文有讲。</p>
<h3 id="TtlStateFactory、TtlStateContext"><a href="#TtlStateFactory、TtlStateContext" class="headerlink" title="TtlStateFactory、TtlStateContext"></a>TtlStateFactory、TtlStateContext</h3><p>在所有Keyed State状态后端的抽象基类AbstractKeyedStateBackend中，创建并记录一个状态实例的方法如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="keyword">public</span> &lt;N, S extends State, V&gt; <span class="function">S <span class="title">getOrCreateKeyedState</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">   <span class="keyword">final</span> TypeSerializer&lt;N&gt; namespaceSerializer, StateDescriptor&lt;S, V&gt; stateDescriptor)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  checkNotNull(namespaceSerializer, <span class="string">&quot;Namespace serializer&quot;</span>);</span><br><span class="line">  checkNotNull(keySerializer, <span class="string">&quot;State key serializer has not been configured in the config. &quot;</span> +</span><br><span class="line">  <span class="string">&quot;This operation cannot use partitioned state.&quot;</span>);</span><br><span class="line">  InternalKvState&lt;K, ?, ?&gt; kvState = keyValueStatesByName.get(stateDescriptor.getName());</span><br><span class="line">  <span class="keyword">if</span> (kvState == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!stateDescriptor.isSerializerInitialized()) &#123;</span><br><span class="line">      stateDescriptor.initializeSerializerUnlessSet(executionConfig);</span><br><span class="line">    &#125;</span><br><span class="line">    kvState = TtlStateFactory.createStateAndWrapWithTtlIfEnabled( namespaceSerializer, stateDescriptor, <span class="keyword">this</span>, ttlTimeProvider);</span><br><span class="line">    keyValueStatesByName.put(stateDescriptor.getName(), kvState);</span><br><span class="line">    publishQueryableStateIfEnabled(stateDescriptor, kvState);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> (S) kvState;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见是调用了TtlStateFactory.createStateAndWrapWithTtlIfEnabled()方法来真正创建。顾名思义，TtlStateFactory是产生TTL状态的工厂类。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;K, N, SV, TTLSV, S extends State, IS extends S&gt; <span class="function">IS <span class="title">createStateAndWrapWithTtlIfEnabled</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">    TypeSerializer&lt;N&gt; namespaceSerializer, </span></span></span><br><span class="line"><span class="function"><span class="params">    StateDescriptor&lt;S, SV&gt; stateDesc, </span></span></span><br><span class="line"><span class="function"><span class="params">    KeyedStateBackend&lt;K&gt; stateBackend, </span></span></span><br><span class="line"><span class="function"><span class="params">    TtlTimeProvider timeProvider</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  Preconditions.checkNotNull(namespaceSerializer);</span><br><span class="line">  Preconditions.checkNotNull(stateDesc);</span><br><span class="line">  Preconditions.checkNotNull(stateBackend);</span><br><span class="line">  Preconditions.checkNotNull(timeProvider);</span><br><span class="line">  <span class="keyword">return</span> stateDesc.getTtlConfig().isEnabled() ? <span class="keyword">new</span> TtlStateFactory&lt;K, N, SV, TTLSV, S, IS&gt;( namespaceSerializer, stateDesc, stateBackend, timeProvider) .createState() : stateBackend.createInternalState(namespaceSerializer, stateDesc);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由上可知，如果我们为状态描述符StateDescriptor加入了TTL，那么就会调用TtlStateFactory.createState()方法创建一个带有TTL的状态实例；否则，就调用StateBackend.createInternalState()创建一个普通的状态实例。TtlStateFactory.createState()的代码如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> IS <span class="title">createState</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  SupplierWithException&lt;IS, Exception&gt; stateFactory = stateFactories.get(stateDesc.getClass());</span><br><span class="line">  <span class="keyword">if</span> (stateFactory == <span class="keyword">null</span>) &#123;</span><br><span class="line">    String message = String.format(<span class="string">&quot;State %s is not supported by %s&quot;</span>, stateDesc.getClass(), TtlStateFactory.class);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> FlinkRuntimeException(message);</span><br><span class="line">  &#125;</span><br><span class="line">  IS state = stateFactory.get();</span><br><span class="line">  <span class="keyword">if</span> (incrementalCleanup != <span class="keyword">null</span>) &#123;</span><br><span class="line">    incrementalCleanup.setTtlState((AbstractTtlState&lt;K, N, ?, TTLSV, ?&gt;) state);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> state;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，stateFactories是一个Map结构，维护了各种状态描述符与对应产生该种状态对象的工厂方法映射。所有的工厂方法都被包装成了Supplier（Java 8提供的函数式接口），所以在上述createState()方法中，可以通过Supplier.get()方法来实际执行createTtl.State()工厂方法，并获得新的状态实例。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">this</span>.stateFactories = createStateFactories();</span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;deprecation&quot;)</span></span><br><span class="line"><span class="keyword">private</span> Map&lt;Class&lt;? extends StateDescriptor&gt;, SupplierWithException&lt;IS, Exception&gt;&gt; createStateFactories() &#123;</span><br><span class="line">  <span class="keyword">return</span> Stream.of(</span><br><span class="line">    Tuple2.of(ValueStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createValueState),</span><br><span class="line">    Tuple2.of(ListStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createListState),</span><br><span class="line">    Tuple2.of(MapStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createMapState),</span><br><span class="line">    Tuple2.of(ReducingStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createReducingState),</span><br><span class="line">    Tuple2.of(AggregatingStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createAggregatingState),</span><br><span class="line">    Tuple2.of(FoldingStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createFoldingState)</span><br><span class="line">  ).collect(Collectors.toMap(t -&gt; t.f0, t -&gt; t.f1));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> IS <span class="title">createValueState</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  ValueStateDescriptor&lt;TtlValue&lt;SV&gt;&gt; ttlDescriptor = <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(</span><br><span class="line">      stateDesc.getName(), </span><br><span class="line">      <span class="keyword">new</span> TtlSerializer&lt;&gt;(LongSerializer.INSTANCE, stateDesc.getSerializer())</span><br><span class="line">  );</span><br><span class="line">  <span class="keyword">return</span> (IS) <span class="keyword">new</span> TtlValueState&lt;&gt;(createTtlStateContext(ttlDescriptor));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="function">IS <span class="title">createListState</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  ListStateDescriptor&lt;T&gt; listStateDesc = (ListStateDescriptor&lt;T&gt;) stateDesc;</span><br><span class="line">  ListStateDescriptor&lt;TtlValue&lt;T&gt;&gt; ttlDescriptor = <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(</span><br><span class="line">      stateDesc.getName(), </span><br><span class="line">      <span class="keyword">new</span> TtlSerializer&lt;&gt;(LongSerializer.INSTANCE, listStateDesc.getElementSerializer())</span><br><span class="line">  );</span><br><span class="line">  <span class="keyword">return</span> (IS) <span class="keyword">new</span> TtlListState&lt;&gt;(createTtlStateContext(ttlDescriptor));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 以下略去...</span></span><br></pre></td></tr></table></figure>
<p>可见，带有TTL的状态类名其实就是普通状态类名加上Ttl前缀，只是没有公开给用户而已。并且在生成<code>Ttl$State</code>时，还会通过createTtlStateContext()方法生成TTL状态的上下文。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="keyword">private</span> &lt;OIS extends State, TTLS extends State, V, TTLV&gt; TtlStateContext&lt;OIS, V&gt;</span><br><span class="line">createTtlStateContext(StateDescriptor&lt;TTLS, TTLV&gt; ttlDescriptor) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    ttlDescriptor.enableTimeToLive(stateDesc.getTtlConfig()); </span><br><span class="line">    <span class="comment">// also used by RocksDB backend for TTL compaction filter config</span></span><br><span class="line">    OIS originalState = (OIS) stateBackend.createInternalState(</span><br><span class="line">        namespaceSerializer, </span><br><span class="line">        ttlDescriptor, </span><br><span class="line">        getSnapshotTransformFactory()</span><br><span class="line">    );</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> TtlStateContext&lt;&gt;(</span><br><span class="line">        originalState, </span><br><span class="line">        ttlConfig, </span><br><span class="line">        timeProvider, </span><br><span class="line">        (TypeSerializer&lt;V&gt;) stateDesc.getSerializer(),</span><br><span class="line">        registerTtlIncrementalCleanupCallback((InternalKvState&lt;?, ?, ?&gt;) originalState)</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>TtlStateContext的本质是对以下几个实例做了封装。</p>
<ul>
<li>原始State（通过StateBackend.createInternalState()方法创建）及其序列化器（通过StateDescriptor.getSerializer()方法取得）；</li>
<li>StateTtlConfig，前文已经讲过；</li>
<li>TtlTimeProvider，用来提供判断状态过期标准的时间戳。当前只是简单地代理了System.currentTimeMillis()，没有任何其他代码；</li>
<li>一个Runnable类型的回调方法，通过registerTtlIncrementalCleanupCallback()方法产生，用于状态数据的增量清理，后面会看到它的用途。</li>
</ul>
<p>接下来就具体看看TTL状态是如何实现的。</p>
<h3 id="AbstractTtlState、AbstractTtlDecorator"><a href="#AbstractTtlState、AbstractTtlDecorator" class="headerlink" title="AbstractTtlState、AbstractTtlDecorator"></a>AbstractTtlState、AbstractTtlDecorator</h3><p>在解说之前，先放一幅类图。</p>
<p><img src="_v_images/20200917142252357_1752793097"></p>
<p>所有Ttl.State都是AbstractTtlState的子类，而AbstractTtlState又是装饰器AbstractTtlDecorator的子类。AbstractTtlDecorator提供了最基本的TTL逻辑，代码不长，全部抄录如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractTtlDecorator</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">  <span class="comment">/** Wrapped original state handler. */</span></span><br><span class="line">  <span class="keyword">final</span> T original;</span><br><span class="line">  <span class="keyword">final</span> StateTtlConfig config;</span><br><span class="line">  <span class="keyword">final</span> TtlTimeProvider timeProvider;</span><br><span class="line">  <span class="comment">/** Whether to renew expiration timestamp on state read access. */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> updateTsOnRead;</span><br><span class="line">  <span class="comment">/** Whether to renew expiration timestamp on state read access. */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> returnExpired;</span><br><span class="line">  <span class="comment">/** State value time to live in milliseconds. */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> ttl;</span><br><span class="line">  AbstractTtlDecorator( T original, StateTtlConfig config, TtlTimeProvider timeProvider) &#123;</span><br><span class="line">  <span class="comment">// ......</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 查到已过期数据，返回null</span></span><br><span class="line">  &lt;V&gt; <span class="function">V <span class="title">getUnexpired</span><span class="params">(TtlValue&lt;V&gt; ttlValue)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ttlValue == <span class="keyword">null</span> || (expired(ttlValue) &amp;&amp; !returnExpired) ? <span class="keyword">null</span> : ttlValue.getUserValue();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 过期掉数据</span></span><br><span class="line">  &lt;V&gt; <span class="function"><span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(TtlValue&lt;V&gt; ttlValue)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> TtlUtils.expired(ttlValue, ttl, timeProvider);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 包装数据</span></span><br><span class="line">  &lt;V&gt; <span class="function">TtlValue&lt;V&gt; <span class="title">wrapWithTs</span><span class="params">(V value)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> TtlUtils.wrapWithTs(value, timeProvider.currentTimestamp());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 重新包装数据</span></span><br><span class="line">  &lt;V&gt; <span class="function">TtlValue&lt;V&gt; <span class="title">rewrapWithNewTs</span><span class="params">(TtlValue&lt;V&gt; ttlValue)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> wrapWithTs(ttlValue.getUserValue());</span><br><span class="line">  &#125;</span><br><span class="line">  &lt;SE extends Throwable, CE extends Throwable, CLE extends Throwable, V&gt; <span class="function">V <span class="title">getWithTtlCheckAndUpdate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      SupplierWithException&lt;TtlValue&lt;V&gt;, SE&gt; getter,</span></span></span><br><span class="line"><span class="function"><span class="params">      ThrowingConsumer&lt;TtlValue&lt;V&gt;, CE&gt; updater,</span></span></span><br><span class="line"><span class="function"><span class="params">      ThrowingRunnable&lt;CLE&gt; stateClear</span></span></span><br><span class="line"><span class="function"><span class="params">  )</span> <span class="keyword">throws</span> SE, CE, CLE </span>&#123;</span><br><span class="line">    TtlValue&lt;V&gt; ttlValue = getWrappedWithTtlCheckAndUpdate(getter, updater, stateClear);</span><br><span class="line">    <span class="keyword">return</span> ttlValue == <span class="keyword">null</span> ? <span class="keyword">null</span> : ttlValue.getUserValue();</span><br><span class="line">  &#125;</span><br><span class="line">  &lt;SE extends Throwable, CE extends Throwable, CLE extends Throwable, V&gt; <span class="function">TtlValue&lt;V&gt; <span class="title">getWrappedWithTtlCheckAndUpdate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      SupplierWithException&lt;TtlValue&lt;V&gt;, SE&gt; getter,</span></span></span><br><span class="line"><span class="function"><span class="params">      ThrowingConsumer&lt;TtlValue&lt;V&gt;, CE&gt; updater,</span></span></span><br><span class="line"><span class="function"><span class="params">      ThrowingRunnable&lt;CLE&gt; stateClear</span></span></span><br><span class="line"><span class="function"><span class="params">  )</span> <span class="keyword">throws</span> SE, CE, CLE </span>&#123;</span><br><span class="line">      TtlValue&lt;V&gt; ttlValue = getter.get();</span><br><span class="line">      <span class="keyword">if</span> (ttlValue == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (expired(ttlValue)) &#123;</span><br><span class="line">        stateClear.run();</span><br><span class="line">        <span class="keyword">if</span> (!returnExpired) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (updateTsOnRead) &#123;</span><br><span class="line">          updater.accept(rewrapWithNewTs(ttlValue));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> ttlValue;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它的成员属性比较容易理解，例如，updateTsOnRead表示在读取状态值时也更新时间戳（即UpdateType.OnReadAndWrite），returnExpired表示即使状态过期，在被真正删除之前也返回它的值（即StateVisibility.ReturnExpiredIfNotCleanedUp）。</p>
<p>状态值与TTL的包装（成为TtlValue）以及过期检测都由工具类TtlUtils来负责，思路很简单，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TtlUtils</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> &lt;V&gt; <span class="function"><span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(<span class="meta">@Nullable</span> TtlValue&lt;V&gt; ttlValue, <span class="keyword">long</span> ttl, TtlTimeProvider timeProvider)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> expired(ttlValue, ttl, timeProvider.currentTimestamp());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">static</span> &lt;V&gt; <span class="function"><span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(<span class="meta">@Nullable</span> TtlValue&lt;V&gt; ttlValue, <span class="keyword">long</span> ttl, <span class="keyword">long</span> currentTimestamp)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ttlValue != <span class="keyword">null</span> &amp;&amp; expired(ttlValue.getLastAccessTimestamp(), ttl, currentTimestamp);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(<span class="keyword">long</span> ts, <span class="keyword">long</span> ttl, TtlTimeProvider timeProvider)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> expired(ts, ttl, timeProvider.currentTimestamp());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(<span class="keyword">long</span> ts, <span class="keyword">long</span> ttl, <span class="keyword">long</span> currentTimestamp)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> getExpirationTimestamp(ts, ttl) &lt;= currentTimestamp;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getExpirationTimestamp</span><span class="params">(<span class="keyword">long</span> ts, <span class="keyword">long</span> ttl)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> ttlWithoutOverflow = ts &gt; <span class="number">0</span> ? Math.min(Long.MAX_VALUE - ts, ttl) : ttl;</span><br><span class="line">    <span class="keyword">return</span> ts + ttlWithoutOverflow;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">static</span> &lt;V&gt; <span class="function">TtlValue&lt;V&gt; <span class="title">wrapWithTs</span><span class="params">(V value, <span class="keyword">long</span> ts)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> TtlValue&lt;&gt;(value, ts);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>TtlValue的属性只有两个：状态值和时间戳，代码略去。</p>
<p>AbstractTtlDecorator核心方法是获取状态值的getWrappedWithTtlCheckAndUpdate()，它接受三个参数：</p>
<ul>
<li>getter：一个可抛出异常的Supplier，用于获取状态值；</li>
<li>updater：一个可抛出异常的Consumer，用于更新状态的时间戳；</li>
<li>stateClear：一个可抛出异常的Runnable，用于异步删除过期状态。</li>
</ul>
<p>可见，在默认情况下的后台清理策略是：<strong>只有状态值被读取时，才会做过期检测，并异步清除过期的状态</strong>。这种<strong>惰性清理</strong>的机制会导致<strong>那些实际已经过期但从未被再次访问过的状态无法被删除</strong>，需要特别注意。官方文档中也已有提示：</p>
<blockquote>
<p>By default, expired values are explicitly removed on read, such as ValueState#value, and periodically garbage collected in the background if supported by the configured state backend.</p>
</blockquote>
<p>当确认到状态过期时，会调用stateClear的逻辑进行删除；如果需要在读取时顺便更新状态的时间戳，会调用updater的逻辑重新包装一个TtlValue。</p>
<p>AbstractTtlState的代码更加简单，主要的方法列举如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Runnable accessCallback; &lt;SE extends Throwable, CE extends Throwable, T&gt; <span class="function">T <span class="title">getWithTtlCheckAndUpdate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  SupplierWithException&lt;TtlValue&lt;T&gt;, SE&gt; getter,</span></span></span><br><span class="line"><span class="function"><span class="params">  ThrowingConsumer&lt;TtlValue&lt;T&gt;, CE&gt; updater)</span> <span class="keyword">throws</span> SE, CE </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> getWithTtlCheckAndUpdate(getter, updater, original::clear);&#125; <span class="meta">@Overridepublic</span> <span class="function"><span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  original.clear();</span><br><span class="line">  accessCallback.run();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，accessCallback就是TtlStateContext中注册的增量清理回调。</p>
<p>下面以TtlMapState为例，看看具体的TTL状态如何利用上文所述的这些实现。</p>
<h3 id="TtlMapState"><a href="#TtlMapState" class="headerlink" title="TtlMapState"></a>TtlMapState</h3><p>以下是部分代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TtlMapState</span>&lt;<span class="title">K</span>, <span class="title">N</span>, <span class="title">UK</span>, <span class="title">UV</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">extends</span> <span class="title">AbstractTtlState</span>&lt;<span class="title">K</span>, <span class="title">N</span>, <span class="title">Map</span>&lt;<span class="title">UK</span>, <span class="title">UV</span>&gt;, <span class="title">Map</span>&lt;<span class="title">UK</span>, <span class="title">TtlValue</span>&lt;<span class="title">UV</span>&gt;&gt;, <span class="title">InternalMapState</span>&lt;<span class="title">K</span>, <span class="title">N</span>, <span class="title">UK</span>, <span class="title">TtlValue</span>&lt;<span class="title">UV</span>&gt;&gt;&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">implements</span> <span class="title">InternalMapState</span>&lt;<span class="title">K</span>, <span class="title">N</span>, <span class="title">UK</span>, <span class="title">UV</span>&gt; </span>&#123;</span><br><span class="line">    TtlMapState(TtlStateContext&lt;InternalMapState&lt;K, N, UK, TtlValue&lt;UV&gt;&gt;, Map&lt;UK, UV&gt;&gt; ttlStateContext) &#123;</span><br><span class="line">        <span class="keyword">super</span>(ttlStateContext);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> UV <span class="title">get</span><span class="params">(UK key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        TtlValue&lt;UV&gt; ttlValue = getWrapped(key);</span><br><span class="line">        <span class="keyword">return</span> ttlValue == <span class="keyword">null</span> ? <span class="keyword">null</span> : ttlValue.getUserValue();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> TtlValue&lt;UV&gt; <span class="title">getWrapped</span><span class="params">(UK key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        accessCallback.run();</span><br><span class="line">        <span class="keyword">return</span> getWrappedWithTtlCheckAndUpdate(() -&gt; original.get(key), v -&gt; original.put(key, v), () -&gt; original.remove(key));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(UK key, UV value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        accessCallback.run();</span><br><span class="line">        original.put(key, wrapWithTs(value));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putAll</span><span class="params">(Map&lt;UK, UV&gt; map)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        accessCallback.run();</span><br><span class="line">        <span class="keyword">if</span> (map == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        Map&lt;UK, TtlValue&lt;UV&gt;&gt; ttlMap = <span class="keyword">new</span> HashMap&lt;&gt;(map.size());</span><br><span class="line">        <span class="keyword">long</span> currentTimestamp = timeProvider.currentTimestamp();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;UK, UV&gt; entry : map.entrySet()) &#123;</span><br><span class="line">            UK key = entry.getKey();</span><br><span class="line">            ttlMap.put(key, TtlUtils.wrapWithTs(entry.getValue(), currentTimestamp));</span><br><span class="line">        &#125;</span><br><span class="line">        original.putAll(ttlMap);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(UK key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    accessCallback.run();</span><br><span class="line">    original.remove(key);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(UK key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    TtlValue&lt;UV&gt; ttlValue = getWrapped(key);</span><br><span class="line">    <span class="keyword">return</span> ttlValue != <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见，TtlMapState的增删改查操作都是在原MapState上进行，只是加上了TTL相关的逻辑，这也是装饰器模式的特点。例如，TtlMapState.get()方法调用了上述AbstractTtlDecorator.getWrappedWithTtlCheckAndUpdate()方法，传入的获取（getter）、插入（updater）和删除（stateClear）的逻辑就是原MapState的get()、put()和remove()方法。而TtlMapState.put()只是在调用原MapState的put()方法之前，将状态包装为TtlValue而已。</p>
<h2 id="增量清理策略"><a href="#增量清理策略" class="headerlink" title="增量清理策略"></a>增量清理策略</h2><p>另外需要注意，所有增删改查操作之前都需要执行accessCallback.run()方法。如果启用了增量清理策略，该Runnable会通过在状态数据上维护一个全局迭代器向前清理过期数据。如果未启用增量清理策略，accessCallback为空。前文提到过的<code>TtlStateFactory.registerTtlIncrementalCleanupCallback()</code> 方法如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Runnable <span class="title">registerTtlIncrementalCleanupCallback</span><span class="params">(InternalKvState&lt;?, ?, ?&gt; originalState)</span> </span>&#123;</span><br><span class="line">    StateTtlConfig.IncrementalCleanupStrategy config =</span><br><span class="line">        ttlConfig.getCleanupStrategies().getIncrementalCleanupStrategy();</span><br><span class="line">    <span class="keyword">boolean</span> cleanupConfigured = config != <span class="keyword">null</span> &amp;&amp; incrementalCleanup != <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">boolean</span> isCleanupActive = cleanupConfigured &amp;&amp;</span><br><span class="line">        isStateIteratorSupported(originalState, incrementalCleanup.getCleanupSize());</span><br><span class="line">    Runnable callback = isCleanupActive ? incrementalCleanup::stateAccessed : () -&gt; &#123; &#125;;</span><br><span class="line">    <span class="keyword">if</span> (isCleanupActive &amp;&amp; config.runCleanupForEveryRecord()) &#123;</span><br><span class="line">        stateBackend.registerKeySelectionListener(stub -&gt; callback.run());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> callback;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际清理的代码则位于<code>TtlIncrementalCleanup</code>类中，stateIterator就是状态数据的迭代器。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">stateAccessed</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    initIteratorIfNot();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        runCleanup();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FlinkRuntimeException(<span class="string">&quot;Failed to incrementally clean up state with TTL&quot;</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initIteratorIfNot</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (stateIterator == <span class="keyword">null</span> || !stateIterator.hasNext()) &#123;</span><br><span class="line">        stateIterator = ttlState.original.getStateIncrementalVisitor(cleanupSize);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">runCleanup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> entryNum = <span class="number">0</span>;</span><br><span class="line">    Collection&lt;StateEntry&lt;K, N, S&gt;&gt; nextEntries;</span><br><span class="line">    <span class="keyword">while</span> (    entryNum &lt; cleanupSize &amp;&amp;</span><br><span class="line">    stateIterator.hasNext() &amp;&amp;    !(nextEntries = stateIterator.nextEntries()).isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">for</span> (StateEntry&lt;K, N, S&gt; state : nextEntries) &#123;</span><br><span class="line">            S cleanState = ttlState.getUnexpiredOrNull(state.getState());</span><br><span class="line">            <span class="keyword">if</span> (cleanState == <span class="keyword">null</span>) &#123;</span><br><span class="line">                stateIterator.remove(state);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cleanState != state.getState()) &#123;</span><br><span class="line">                stateIterator.update(state, cleanState);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        entryNum += nextEntries.size();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>RocksDB压缩过滤清理策略</p>
<p>如果启用了该策略，Flink会通过维护一个<code>RocksDbTtlCompactFiltersManager</code>实例来管理<code>FlinkCompactionFilter</code>过滤器。<code>FlinkCompactionFilter</code>并不是在Flink工程中维护的，而是位于Data Artisans为Flink专门维护的FRocksDB库内。<a href="https://links.jianshu.com/go?to=https://issues.apache.org/jira/browse/FLINK-10471">FLINK-10471</a>实现了FlinkCompactionFilter及其附属逻辑，主要为C++代码，通过JNI调用。对应的commit详见<a href="https://links.jianshu.com/go?to=https://github.com/dataArtisans/frocksdb/commit/01dca02244522e405c9258000903fee81496f72c">GitHub</a>，这里就不班门弄斧了。关于RocksDB的compaction相关细节，笔者之前也写过<a href="https://www.jianshu.com/p/e89cd503c9ae">一篇长文</a>做了些分析。</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink状态管理</title>
    <url>/bigdata/Flink/Flink-StateManagement/</url>
    <content><![CDATA[<h1 id="state-management"><a href="#state-management" class="headerlink" title="state-management"></a>state-management</h1><h2 id="org-apache-flink-streaming-api-checkpoint-CheckpointedFunction"><a href="#org-apache-flink-streaming-api-checkpoint-CheckpointedFunction" class="headerlink" title="org.apache.flink.streaming.api.checkpoint.CheckpointedFunction"></a>org.apache.flink.streaming.api.checkpoint.CheckpointedFunction</h2><ul>
<li>CheckpointedFunction是stateful transformation functions的核心接口，用于跨stream维护state<ul>
<li>snapshotState 在checkpoint的时候会被调用，用于snapshot state，通常用于flush、commit、synchronize外部系统</li>
<li>initializeState 在parallel function初始化的时候(<strong>第一次初始化或者从前一次checkpoint recover的时候</strong>)被调用，通常用来初始化state，以及处理state recovery的逻辑</li>
</ul>
</li>
</ul>
<p>从checkpoint中恢复数据时，需要判断snapshot当前的情况，</p>
<p>FunctionSnapshotContext实现了ManagedSnapshotContext, 父类中的方法: <code>getCheckpointId</code>,<code>getCheckpointTimestamp</code><br>FunctionInitializationContext实现了ManagedInitializationContext接口, 实现了<code>isRestored</code>、<code>getOperatorStateStore</code>、<code>getKeyedStateStore</code>方法</p>
<p>在初始化容器之后，我们使用上下文的<code>isrestore()</code>方法检查失败后是否正在恢复。如果是true，即正在恢复，则应用恢复逻辑。</p>
<blockquote>
<p>样例: HBase写入OutPutFormat</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">PortraitOutputFormat</span> <span class="keyword">extends</span> <span class="title">RichOutputFormat</span>&lt;<span class="title">EventItem</span>&gt; <span class="keyword">implements</span> <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 输出阈值，批量写入的条数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> threshold;</span><br><span class="line">    <span class="comment">// 维护在状态中的数据</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> ListState&lt;EventItem&gt; checkpointState;</span><br><span class="line">    <span class="comment">// 内存中的数据</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;EventItem&gt; bufferedEventItem;</span><br><span class="line">    <span class="comment">// HBase客户端</span></span><br><span class="line">    <span class="keyword">private</span> HBaseClient hbaseClient;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PortraitOutputFormat</span><span class="params">(HBaseClient hbaseClient)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.hbaseClient = hbaseClient;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * checkpoint时调用</span></span><br><span class="line"><span class="comment">    * 执行snapshot操作，将内存中的数据写入到内存</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext functionSnapshotContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        checkpointState.clear();</span><br><span class="line">        <span class="keyword">for</span> (EventItem eventItem : bufferedEventItem) &#123;</span><br><span class="line">            checkpointState.add(eventItem);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 创建state，判断是否存在需要恢复的状态，如果有则需要恢复到bufferedEventItem</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ListStateDescriptor&lt;EventItem&gt; descriptor = <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(<span class="string">&quot;buf-p&quot;</span>, EventItem.class);</span><br><span class="line">        checkpointState = context.getOperatorStateStore().getListState(descriptor);</span><br><span class="line">        <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (EventItem eventItem : checkpointState.get()) &#123;</span><br><span class="line">                bufferedEventItem.add(eventItem);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Configuration configuration)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(<span class="keyword">int</span> taskNumber, <span class="keyword">int</span> numTasks)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 将新消息写入到缓存bufferedEventItem，缓存个数大约threshold,则执行sink写入，然后清空bufferedEventItem</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeRecord</span><span class="params">(EventItem value)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (value.getAttachUserId() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        bufferedEventItem.add(value);</span><br><span class="line">        <span class="keyword">int</span> size = bufferedEventItem.size();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (size &gt;= threshold) &#123;</span><br><span class="line">            List&lt;Put&gt; puts = bufferedEventItem</span><br><span class="line">                    .stream()</span><br><span class="line">                    .map(eventItem -&gt; &#123;</span><br><span class="line">                        String rowKey1 = portraitDataGenerator.rowKey(eventItem);</span><br><span class="line">                        Map&lt;String, String&gt; data = portraitDataGenerator.data(eventItem);</span><br><span class="line">                        Put put = <span class="keyword">new</span> Put(rowKey1.getBytes());</span><br><span class="line">                        <span class="keyword">for</span> (String cfc : data.keySet()) &#123;</span><br><span class="line">                            String[] cfcs = cfc.split(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">                            String cf = cfcs[<span class="number">0</span>];</span><br><span class="line">                            String c = cfcs[<span class="number">1</span>];</span><br><span class="line">                            String dataOne = data.get(cfc);</span><br><span class="line">                            put.addColumn(cf.getBytes(), c.getBytes(), dataOne.getBytes());</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> put;</span><br><span class="line">                    &#125;)</span><br><span class="line">                    .collect(Collectors.toList());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                hbaseClient.putAndFlush(puts);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            bufferedEventItem.clear();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hTable != <span class="keyword">null</span>) &#123;</span><br><span class="line">            hTable.flushCommits();</span><br><span class="line">            hTable.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




<h2 id="org-apache-flink-runtime-state-CheckpointListener"><a href="#org-apache-flink-runtime-state-CheckpointListener" class="headerlink" title="org.apache.flink.runtime.state.CheckpointListener"></a>org.apache.flink.runtime.state.CheckpointListener</h2><p>一旦所有checkpoint参与者确认完全，该接口必须由想要接收提交通知的功能/操作来实现。</p>
<h1 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h1><p>1.8 自动清理原理</p>
<p>Apache Flink的1.6.0版本引入了State TTL功能。它使流处理应用程序的开发人员配置过期时间，并在定义时间超时（Time to Live）之后进行清理。在Flink 1.8.0中，该功能得到了扩展，包括对RocksDB和堆状态后端（FSStateBackend和MemoryStateBackend）的历史数据进行持续清理，从而实现旧条目的连续清理过程（根据TTL设置）。</p>
<p>RocksDB后台压缩可以过滤掉过期状态<br>如果你的Flink应用程序使用RocksDB作为状态后端存储，则可以启用另一个基于Flink特定压缩过滤器的清理策略。RocksDB定期运行异步压缩以合并状态更新并减少存储。Flink压缩过滤器使用TTL检查状态条目的到期时间戳，并丢弃所有过期值。</p>
<p>激活此功能的第一步是通过设置以下Flink配置选项来配置RocksDB状态后端：</p>
<p>state.backend.rocksdb.ttl.compaction.filter.enabled</p>
<p>配置RocksDB状态后端后，将为状态启用压缩清理策略，如以下代码示例所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">StateTtlConfig ttlConfig &#x3D; StateTtlConfig</span><br><span class="line">    .newBuilder(Time.days(7))</span><br><span class="line">    .cleanupInRocksdbCompactFilter()</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure>


<h2 id="backend-状态后端"><a href="#backend-状态后端" class="headerlink" title="backend 状态后端"></a>backend 状态后端</h2><table>
<thead>
<tr>
<th>state</th>
<th>保存</th>
<th>snapshot与restore</th>
<th>大小</th>
</tr>
</thead>
<tbody><tr>
<td>keyed state</td>
<td>堆内或堆外(RocksDB)</td>
<td>backend自行实现，用户不关心</td>
<td>大</td>
</tr>
<tr>
<td>operator state</td>
<td>堆内</td>
<td>用户自行实现</td>
<td>小</td>
</tr>
</tbody></table>
<p><img src="_v_images/20201208101748835_1926021392.png"></p>
<p>Flink 的 keyed state 本质上来说就是一个键值对，所以与 RocksDB 的数据模型是吻合的。下图分别是 “window state” 和 “value state” 在 RocksDB 中的存储格式，所有存储的 key，value 均被序列化成 bytes 进行存储。</p>
<p><img src="_v_images/20201208113819762_751391291.png"></p>
<p>在 RocksDB 中，每个 state 独享一个 Column Family，而每个 Column family 使用各自独享的 write buffer 和 block cache，上图中的 window state 和 value state实际上分属不同的 column family。</p>
<h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="operator-state"><a href="#operator-state" class="headerlink" title="operator state"></a>operator state</h4><h5 id="慎重使用长-list"><a href="#慎重使用长-list" class="headerlink" title="慎重使用长 list"></a>慎重使用长 list</h5><p>下图展示的是目前 task 端 operator state 在执行完 checkpoint 返回给 job master 端的 StateMetaInfo 的代码片段。</p>
<p><img src="_v_images/20201208113527702_980726558.png"></p>
<p>由于 operator state 没有 key group 的概念，所以为了实现改并发恢复的功能，需要对 operator state 中的每一个序列化后的元素存储一个位置偏移 offset，也就是构成了上图红框中的 offset 数组。  </p>
<p>那么如果你的 operator state 中的 list 长度达到一定规模时，这个 offset 数组就可能会有几十 MB 的规模，关键这个数组是会返回给 job master，当 operator 的并发数目很大时，很容易触发 job master 的内存超用问题。我们遇到过用户把 operator state 当做黑名单存储，结果这个黑名单规模很大，导致一旦开始执行 checkpoint，job master 就会因为收到 task 发来的“巨大”的 offset 数组，而内存不断增长直到超用无法正常响应。</p>
<h5 id="正确使用-UnionListState"><a href="#正确使用-UnionListState" class="headerlink" title="正确使用 UnionListState"></a>正确使用 UnionListState</h5><p>union list state 目前被广泛使用在 kafka connector 中，不过可能用户日常开发中较少遇到，他的语义是从检查点恢复之后每个并发 task 内拿到的是原先所有operator 上的 state，如下图所示：</p>
<p><img src="_v_images/20201208113559017_2066750174.png"></p>
<p>kafka connector 使用该功能，为的是从检查点恢复时，可以拿到之前的全局信息，如果用户需要使用该功能，需要切记恢复的 task 只取其中的一部分进行处理和用于下一次 snapshot，否则有可能随着作业不断的重启而导致 state 规模不断增长。</p>
<h4 id="Keyed-state-使用建议"><a href="#Keyed-state-使用建议" class="headerlink" title="Keyed state 使用建议"></a>Keyed state 使用建议</h4><h5 id="如何正确清空当前的-state"><a href="#如何正确清空当前的-state" class="headerlink" title="如何正确清空当前的 state"></a>如何正确清空当前的 state</h5><p>state.clear() 实际上只能清理当前 key 对应的 value 值，如果想要清空整个 state，需要借助于 applyToAllKeys 方法，具体代码片段如下：</p>
<p><img src="_v_images/20201208113620034_1338097160.png"></p>
<p>如果你的需求中只是对 state 有过期需求，借助于 state TTL 功能来清理会是一个性能更好的方案。</p>
<h5 id="RocksDB-中考虑-value-值很大的极限场景"><a href="#RocksDB-中考虑-value-值很大的极限场景" class="headerlink" title="RocksDB 中考虑 value 值很大的极限场景"></a>RocksDB 中考虑 value 值很大的极限场景</h5><p>受限于 JNI bridge API 的限制，单个 value 只支持 2^31 bytes 大小，如果存在很极限的情况，可以考虑使用 MapState 来替代 ListState 或者 ValueState，因为RocksDB 的 map state 并不是将整个 map 作为 value 进行存储，而是将 map 中的一个条目作为键值对进行存储。</p>
<h5 id="如何知道当前-RocksDB-的运行情况"><a href="#如何知道当前-RocksDB-的运行情况" class="headerlink" title="如何知道当前 RocksDB 的运行情况"></a>如何知道当前 RocksDB 的运行情况</h5><p>比较直观的方式是打开 RocksDB 的 native metrics ，在默认使用 Flink managed memory 方式的情况下，state.backend.rocksdb.metrics.block-cache-usage ，state.backend.rocksdb.metrics.mem-table-flush-pending，state.backend.rocksdb.metrics.num-running-compactions 以及 state.backend.rocksdb.metrics.num-running-flushes 是比较重要的相关 metrics。</p>
<h4 id="使用-checkpoint-的使用建议"><a href="#使用-checkpoint-的使用建议" class="headerlink" title="使用 checkpoint 的使用建议"></a>使用 checkpoint 的使用建议</h4><h5 id="Checkpoint-间隔不要太短"><a href="#Checkpoint-间隔不要太短" class="headerlink" title="Checkpoint 间隔不要太短"></a>Checkpoint 间隔不要太短</h5><p>虽然理论上 Flink 支持很短的 checkpoint 间隔，但是在实际生产中，过短的间隔对于底层分布式文件系统而言，会带来很大的压力。另一方面，由于检查点的语义，所以实际上 Flink 作业处理 record 与执行 checkpoint 存在互斥锁，过于频繁的 checkpoint，可能会影响整体的性能。当然，这个建议的出发点是底层分布式文件系统的压力考虑。 </p>
<h5 id="合理设置超时时间"><a href="#合理设置超时时间" class="headerlink" title="合理设置超时时间"></a>合理设置超时时间</h5><p>默认的超时时间是 10min，如果 state 规模大，则需要合理配置。最坏情况是分布式地创建速度大于单点（job master 端）的删除速度，导致整体存储集群可用空间压力较大。建议当检查点频繁因为超时而失败时，增大超时时间。</p>
<p>【参考文献】</p>
<ol>
<li><a href="https://www.jianshu.com/p/6ed0ef5e2b74">Flink Streaming状态处理（Working with State）</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink-streaming API</title>
    <url>/bigdata/Flink/Flink-StreamingAPI/</url>
    <content><![CDATA[<h1 id="Flink-Streaming-API"><a href="#Flink-Streaming-API" class="headerlink" title="Flink Streaming API"></a>Flink Streaming API</h1><h2 id="org-apache-flink-streaming-api-functions-source-SourceFunction"><a href="#org-apache-flink-streaming-api-functions-source-SourceFunction" class="headerlink" title="org.apache.flink.streaming.api.functions.source.SourceFunction"></a>org.apache.flink.streaming.api.functions.source.SourceFunction</h2>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink VS Spark</title>
    <url>/bigdata/Flink/Flink-VS-Spark/</url>
    <content><![CDATA[<h1 id="Flink-VS-Spark"><a href="#Flink-VS-Spark" class="headerlink" title="Flink VS Spark"></a>Flink VS Spark</h1><p>Spark Structure Streaming 是什么？</p>
<h3 id="1、抽象-Abstraction"><a href="#1、抽象-Abstraction" class="headerlink" title="1、抽象 Abstraction"></a>1、抽象 Abstraction</h3><p>　　Spark中，对于批处理我们有RDD,对于流式，我们有DStream，不过内部实际还是RDD.所以所有的数据表示本质上还是RDD抽象。在Flink中，对于批处理有DataSet，对于流式我们有DataStreams。看起来和Spark类似，他们的不同点在于：</p>
<p>　　<strong>（一）DataSet在运行时是表现为运行计划(runtime plans)的</strong></p>
<p>　　在Spark中，RDD在运行时是表现为java objects的。通过引入Tungsten，这块有了些许的改变。但是在Flink中是被表现为logical plan(逻辑计划)的, 就是类似于Spark中的dataframes。所以在Flink中你使用的类Dataframe api是被作为第一优先级来优化的。但是相对来说在Spark RDD中就没有了这块的优化了。<br>　　Flink中的Dataset，对标Spark中的Dataframe，在运行前会经过优化。在Spark 1.6，dataset API已经被引入Spark了，也许最终会取代RDD 抽象。</p>
<p>　　<strong>(二）Dataset和DataStream是独立的API</strong></p>
<p>　　在Spark中，所有不同的API，例如DStream，Dataframe都是基于RDD抽象的。但是在Flink中，Dataset和DataStream是同一个公用的引擎之上两个独立的抽象。所以你不能把这两者的行为合并在一起操作，当然，Flink社区目前在朝这个方向努力(<code>https://issues.apache.org/jira/browse/Flink-2320</code>)，但是目前还不能轻易断言最后的结果。</p>
<h3 id="2、内存管理"><a href="#2、内存管理" class="headerlink" title="2、内存管理"></a>2、内存管理</h3><p>　　一直到1.5版本，Spark都是试用java的内存管理来做数据缓存，明显很容易导致OOM或者gc。所以从1.5开始，Spark开始转向精确的控制内存的使用，这就是tungsten项目了。</p>
<p>　　而Flink从第一天开始就坚持自己控制内存试用。这个也是启发了Spark走这条路的原因之一。Flink除了把数据存在自己管理的内存以外，还直接操作二进制数据。在Spark中，从1.5开始，所有的dataframe操作都是直接作用在tungsten的二进制数据上。</p>
<h3 id="3、语言实现"><a href="#3、语言实现" class="headerlink" title="3、语言实现"></a>3、语言实现</h3><ul>
<li><p>实现语言</p>
<p>Spark和Flink均有Scala/Java混合编程实现，Spark的核心逻辑由Scala完成，Flink的主要核心逻辑由Java完成</p>
</li>
<li><p>支持应用语言<br> Flink主要支持Scala，和Java编程，部分API支持python应用<br> Spark主要支持Scala，Java，Python,R语言编程，部分API暂不支持Python和R</p>
</li>
</ul>
<h3 id="4、API"><a href="#4、API" class="headerlink" title="4、API"></a>4、API</h3><table>
<thead>
<tr>
<th>API对比</th>
<th>Flink</th>
<th></th>
<th>Spark</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>应用类型</td>
<td>Batch</td>
<td>Streaming</td>
<td>Batch</td>
<td>Structed Streaming</td>
<td>SparkStreaming</td>
</tr>
<tr>
<td>数据表示</td>
<td>Dataset</td>
<td>datastream</td>
<td>RDD,Dataset</td>
<td>Dataset</td>
<td>Dtream</td>
</tr>
<tr>
<td>主要支持API</td>
<td>map,filter,flatMap等</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>转换后数据类型</td>
<td>Dataset</td>
<td>datastream</td>
<td>RDD,Dataset</td>
<td>Dataset</td>
<td>Dtream</td>
</tr>
</tbody></table>
<h4 id="批处理："><a href="#批处理：" class="headerlink" title="批处理："></a>批处理：</h4><p>Spark批处理的数据表示经历了从<code>RDD -&gt; DataFrame -&gt; Dataset</code>的变化，均具有不可变，lazy执行，可分区等特性，是Spark框架的核心，rdd经过map等函数操作后，并没有改变而是生成新的RDD，Spark的Dataset（DataFrame是一种特殊的Dataset，已经不推荐使用）还包含数据类型信息</p>
<p>Flink批处理的API是Dataset,同样具有不可变，lazy执行，可分区等特性，是Flink框架的核心，Dataset经过map等函数操作后，并没有改变而是生成新的Dataset</p>
<h4 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h4><ul>
<li><p>Spark Streaming</p>
<p>Spark在1.*版本引入的spark streaming作为流处理模块，抽象出Dstream的API来进行流数据处理，同时抽象出通过receiver获取消息数据，然后启动task处理的模式，以及直接启动task消费处理两种方式的流式数据处理。receiver模式由于稳定性不足被遗弃，推荐使用的是直接消费模式；然而本质上讲，Sparkstreaming的流处理是micro-batch的处理模式，将一定时间的流数据作为一个block/RDD，然后使用批处理的rdd的api来完成数据的处理。</p>
</li>
<li><p>Structed streaming</p>
<p>随着Spark在2.*版本的Structed streaming的推出，Spark streaming模块进入了维护模式，从Spark2.*版本以来没有已经没有更新，当前社区主推使用Structed streaming进行流处理。Structed streaming在流处理中有两种流处理模式，一种是microbatch模式；一种是continuous模式；</p>
<ul>
<li><p>microbatch模式与spark streaming的microbatch模式大致相当，分批处理消息，但可通过设置连续的批次处理，即一个批次执行完之后立即进入下一个批次的处理</p>
</li>
<li><p>continuous模式，可以实现真正的流数据处理，端到端的毫秒级，当前处于Experiment状态，也只能支持简单的map,filter操作，当前不支持聚合，<code>current_timestamp</code>，<code>current_date</code>等操作</p>
</li>
<li><p>PS : microbatch &lt;—-&gt; continuous 两种模式可以相互切换且无需改动代码</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>Flink Streaming</p>
<p>Flink Streaming以流的方式处理流数据，可以实现简单map,fliter等操作，也可以实现复杂的聚合，关联操作，以完善的处理模型及high throughout得到了广泛的应用。</p>
</li>
</ul>
<p>　　Spark和Flink都在模仿scala的collection API.所以从表面看起来，两者都很类似。下面是分别用RDD和DataSet API实现的word count</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Spark wordcount</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="keyword">new</span> <span class="type">SparkContext</span>(<span class="string">&quot;local&quot;</span>,<span class="string">&quot;wordCount&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> data = <span class="type">List</span>(<span class="string">&quot;hi&quot;</span>,<span class="string">&quot;how are you&quot;</span>,<span class="string">&quot;hi&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> dataSet = env.parallelize(data)</span><br><span class="line">    <span class="keyword">val</span> words = dataSet.flatMap(value =&gt; value.split(<span class="string">&quot;\\s+&quot;</span>))</span><br><span class="line">    <span class="keyword">val</span> mappedWords = words.map(value =&gt; (value,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">val</span> sum = mappedWords.reduceByKey(_+_)</span><br><span class="line">    println(sum.collect())</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// Flink wordcount</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">　　<span class="keyword">val</span> env = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">　　<span class="keyword">val</span> data = <span class="type">List</span>(<span class="string">&quot;hi&quot;</span>,<span class="string">&quot;how are you&quot;</span>,<span class="string">&quot;hi&quot;</span>)</span><br><span class="line">　　<span class="keyword">val</span> dataSet = env.fromCollection(data)</span><br><span class="line">　　<span class="keyword">val</span> words = dataSet.flatMap(value =&gt; value.split(<span class="string">&quot;\\s+&quot;</span>))</span><br><span class="line">　　<span class="keyword">val</span> mappedWords = words.map(value =&gt; (value,<span class="number">1</span>))</span><br><span class="line">　　<span class="keyword">val</span> grouped = mappedWords.groupBy(<span class="number">0</span>)</span><br><span class="line">　　<span class="keyword">val</span> sum = grouped.sum(<span class="number">1</span>)</span><br><span class="line">　　println(sum.collect())</span><br><span class="line">　&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>　　不知道是偶然还是故意的，API都长得很像，这样很方便开发者从一个引擎切换到另外一个引擎。我感觉以后这种Collection API会成为写data pipeline的标配。</p>
<h3 id="5、Steaming"><a href="#5、Steaming" class="headerlink" title="5、Steaming"></a>5、Steaming</h3><p>　　Spark把streaming看成是更快的批处理，而Flink把批处理看成streaming的special case。这里面的思路决定了各自的方向，其中两者的差异点有如下这些：</p>
<p><strong>实时 vs 近实时的角度</strong></p>
<p>　　Flink提供了基于每个事件的流式处理机制，所以可以被认为是一个真正的流式计算。它非常像storm的model。而Spark，不是基于事件的粒度，而是用小批量来模拟流式，也就是多个事件的集合。所以Spark被认为是近实时的处理系统。</p>
<p>　　Spark streaming 是更快的批处理，而Flink Batch是有限数据的流式计算。虽然大部分应用对准实时是可以接受的，但是也还是有很多应用需要event level的流式计算。这些应用更愿意选择storm而非Spark streaming，现在，Flink也许是一个更好的选择。</p>
<p><strong>流式计算和批处理计算的表示</strong></p>
<p>　　Spark对于批处理和流式计算，都是用的相同的抽象：RDD，这样很方便这两种计算合并起来表示。而Flink这两者分为了DataSet和DataStream，相比Spark，这个设计算是一个糟糕的设计。</p>
<p><strong>对 windowing 的支持</strong></p>
<p>　　因为Spark的小批量机制，Spark对于windowing的支持非常有限。只能基于process time，且只能对batches来做window。而Flink对window的支持非常到位，且Flink对windowing API的支持是相当给力的，允许基于process time,data time,record 来做windowing。我不太确定Spark是否能引入这些API，不过到目前为止，Flink的windowing支持是要比Spark好的。Steaming这部分Flink胜</p>
<table>
<thead>
<tr>
<th>Window 类型</th>
<th>Window 含义</th>
<th>Flink Streaming</th>
<th>SparkStreaming</th>
<th>Structed Streaming</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>tumblingWindow</td>
<td>一个滚动的window</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>Sliding window</td>
<td>滑动的window</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>Global window</td>
<td>全局window</td>
<td>支持</td>
<td>间接实现</td>
<td>间接支持</td>
<td>间接支持的含义是可以时间类似功能，但没有抽象出该window</td>
</tr>
<tr>
<td>Session window</td>
<td>以接收到数据开始，一定时间没有接收到数据，则结束</td>
<td>支持</td>
<td>不支持</td>
<td>不支持</td>
<td></td>
</tr>
</tbody></table>
<p><strong>流join分析：</strong></p>
<p>由于Spark streaming中不支持event time的概念，其只能支持window不同Dstream的RDD的join，不同window间无法join</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>event-time</th>
<th>流join</th>
<th>join实现方式</th>
<th>处理方式</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Spark streaming</td>
<td>不支持</td>
<td>支持</td>
<td>window内</td>
<td>processingTime</td>
<td>micro-batch处理</td>
</tr>
<tr>
<td>FLink1.5之前</td>
<td>支持</td>
<td>支持</td>
<td>window内</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime ／ element Number</td>
</tr>
<tr>
<td>FLink1.6之后</td>
<td>支持</td>
<td>支持</td>
<td>window内，跨window</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime ／ element Number</td>
</tr>
<tr>
<td>Structed Streaming 2.2</td>
<td>支持</td>
<td>不支持</td>
<td>仅支持流数据和静态数据的join</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime</td>
</tr>
<tr>
<td>Structed Streaming 2.3+</td>
<td>支持</td>
<td>支持</td>
<td>跨window</td>
<td>native处理，join时（proocessingTime（interval）触发）</td>
<td>Processing Time／ EventTime</td>
</tr>
</tbody></table>
<p>PS:</p>
<ul>
<li>Flink／structed streaming开发难度相当，FLink略复杂，但灵活度更高</li>
<li>Flink的inteval join</li>
<li>Structed Streaming支持数据去重（同个imsi的数据的多个不同join结果的去重）</li>
<li>FLink的窗口操作相当于structed streaming的update模式</li>
<li>Flink的单流的watermark更新时实时的，有专门线程处理</li>
<li>Structed streaming的watermark更新时间基于批的，每个批次共用同一个watermark，如果有多个流，多个流共用一个watermark</li>
<li>structed Streaming的watermark更新方法：<br> 基于每个流找出该流的watermark：Max_event_time - lateness<br> 找出所有流中最小/最大的watermark设置为batch的watermark</li>
<li>Flink专门抽象了类以便不同场景下使用自定义的eventTime的waterMark获取/设置方法,且提供了一般场景下的的类以便使用</li>
<li>Flink抽象了trigger和evictor来实现触发计算和清理数据的逻辑，以便自定义相关逻辑</li>
<li>FLink 支持sideoutput输出，如迟到的数据可以单独输出</li>
</ul>
<h3 id="6、SQL-interface"><a href="#6、SQL-interface" class="headerlink" title="6、SQL interface"></a>6、SQL interface</h3><p>　　目前Spark-sql是Spark里面最活跃的组件之一，Spark提供了类似Hive的sql和Dataframe这种DSL来查询结构化数据，API很成熟，在流式计算中使用很广，预计在流式计算中也会发展得很快。至于Flink，到目前为止，Flink Table API只支持类似DataFrame这种DSL，并且还是处于beta状态，社区有计划增加SQL 的interface，但是目前还不确定什么时候才能在框架中用上。所以这个部分，Spark胜出。目前Flink已经支持SQL API</p>
<h3 id="7、外部数据源的整合"><a href="#7、外部数据源的整合" class="headerlink" title="7、外部数据源的整合"></a>7、外部数据源的整合</h3><p>　　Spark的数据源 API是整个框架中最好的，支持的数据源包括NoSql db,parquet,ORC等，并且支持一些高级的操作，例如predicate push down。Flink目前还依赖map/reduce InputFormat来做数据源聚合。这一场Spark胜，目前已经提供 </p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">env.readTextFile(path_i)</span><br><span class="line">env.writeTextFile(path_i)</span><br></pre></td></tr></table></figure>


<h3 id="8、Iterative-processing"><a href="#8、Iterative-processing" class="headerlink" title="8、Iterative processing"></a>8、Iterative processing</h3><p>![Flink 迭代处理](_v_images/20190723102241286_1833770582.png =519x)<br>![Spark迭代处理](_v_images/20190723102318593_811318029.png =519x)<br>　　Spark对机器学习的支持较好，因为利用内存cache来加速机器学习算法。然而大部分机器学习算法其实是一个有环的数据流，但是在Spark中，实际是用无环图来表示的，一般的分布式处理引擎都是不鼓励试用有环图的。但是Flink这里又有点不一样，Flink支持在runtime中的有环数据流，这样表示机器学习算法更有效而且更有效率。这一点Flink胜出。</p>
<h3 id="9、Stream-as-platform-vs-Batch-as-Platform"><a href="#9、Stream-as-platform-vs-Batch-as-Platform" class="headerlink" title="9、Stream as platform vs Batch as Platform"></a>9、Stream as platform vs Batch as Platform</h3><ul>
<li><p>Spark诞生在Map/Reduce的时代，数据都是以文件的形式保存在磁盘中，这样非常方便做容错处理。</p>
</li>
<li><p>Flink把纯流式数据计算引入大数据时代，无疑给业界带来了一股清新的空气。这个idea非常类似akka-streams这种。</p>
</li>
</ul>
<p>【参考文献】</p>
<ol>
<li><a href="https://www.iteblog.com/archives/1624.html">Apache Flink vs Apache Spark</a></li>
<li><a href="https://www.jianshu.com/p/da1910535f73">Flink vs Spark</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink:Table API</title>
    <url>/bigdata/Flink/Flink-TableAPI/</url>
    <content><![CDATA[<h1 id="flink-table-api"><a href="#flink-table-api" class="headerlink" title="flink-table-api"></a>flink-table-api</h1><p><a href="https://github.com/crestofwave1/oneFlink/blob/master/doc/table/Concept%20%26%20Common%20API.md">官方文档翻译</a></p>
<h2 id="Concept-amp-Common-API"><a href="#Concept-amp-Common-API" class="headerlink" title="Concept  &amp; Common API"></a>Concept  &amp; Common API</h2><p>Table API和SQL集成在一个联合的API中。这个API核心概念是Table，<br>Table可以作为查询的输入和输出。这篇文章展示了使用Table API和SQL查询的通用结构，<br>如何去进行表的注册，如何去进行表的查询，并且展示如何去进行表的输出。</p>
<h2 id="1-Structure-of-Table-API-and-SQL-Programs"><a href="#1-Structure-of-Table-API-and-SQL-Programs" class="headerlink" title="1. Structure of Table API and SQL Programs"></a>1. Structure of Table API and SQL Programs</h2><p>​    所有使用批量和流式相关的Table API和SQL的程序都有以下相同模式。下面的代码实例展示了Table API和SQL程序的通用结构。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在批处理程序中使用ExecutionEnvironment代替StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册表</span></span><br><span class="line">tableEnv.registerTable(<span class="string">&quot;table1&quot;</span>, ...)           <span class="comment">// or</span></span><br><span class="line">tableEnv.registerTableSource(<span class="string">&quot;table2&quot;</span>, ...)     <span class="comment">// or</span></span><br><span class="line">tableEnv.registerExternalCatalog(<span class="string">&quot;extCat&quot;</span>, ...) </span><br><span class="line"></span><br><span class="line"><span class="comment">// 基于Table API的查询创建表</span></span><br><span class="line"><span class="keyword">val</span> tapiResult = tableEnv.scan(<span class="string">&quot;table1&quot;</span>).select(...)</span><br><span class="line"><span class="comment">// 从SQL查询创建表</span></span><br><span class="line"><span class="keyword">val</span> sqlResult  = tableEnv.sqlQuery(<span class="string">&quot;SELECT ... FROM table2 ...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表操作API查询到的结果表输出到TableSink，SQL查询到的结果一样如此</span></span><br><span class="line">tapiResult.writeToSink(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行</span></span><br><span class="line">env.execute()</span><br></pre></td></tr></table></figure>
<p>注意：Table API和SQL查询很容易集成并被嵌入到DataStream或者DataSet程序中。查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-datastream-and-dataset-api">将DataStream和DataSet API进行整合</a>章节<br>学习DataSteams和DataSets是如何转换成Table以及Table是如何转换为DataStream或DataSet</p>
<h2 id="2-Create-a-TableEnvironment"><a href="#2-Create-a-TableEnvironment" class="headerlink" title="2. Create a TableEnvironment"></a>2. Create a TableEnvironment</h2><p>TableEnvironment是Table API与SQL整合的核心概念之一，它主要有如下功能：</p>
<ul>
<li>在internal catalog注册表</li>
<li>注册external catalog</li>
<li>执行SQL查询</li>
<li>注册UDF函数（user-defined function)，例如 标量, 表或聚合</li>
<li>将DataStream或者DataSet转换为表</li>
<li>保持ExecutionEnvironment或者StreamExecutionEnvironment的引用指向</li>
</ul>
<p>一个表总是与一个特定的TableEnvironment绑定在一块，<br>相同的查询不同的TableEnvironment是无法通过join、union合并在一起。</p>
<p>创建TableEnvironment的方法通常是通过StreamExecutionEnvironment，ExecutionEnvironment对象调用其中的静态方法TableEnvironment.getTableEnvironment()，或者是TableConfig来创建。<br>TableConfig可以用作配置TableEnvironment或是对自定义查询优化器或者是编译过程进行优化(详情查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#query-optimization">查询优化</a>)</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ***************</span></span><br><span class="line"><span class="comment">// 流式查询</span></span><br><span class="line"><span class="comment">// ***************</span></span><br><span class="line"><span class="keyword">val</span> sEnv = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="comment">// 为流式查询创建一个TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> sTableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(sEnv)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ***********</span></span><br><span class="line"><span class="comment">// 批量查询</span></span><br><span class="line"><span class="comment">// ***********</span></span><br><span class="line"><span class="keyword">val</span> bEnv = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="comment">// 为批量查询创建一个TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> bTableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(bEnv)</span><br></pre></td></tr></table></figure>
<h2 id="Register-Tables-in-the-Catalog"><a href="#Register-Tables-in-the-Catalog" class="headerlink" title="Register Tables in the Catalog"></a>Register Tables in the Catalog</h2><p>TableEnvironment包含了通过名称注册表时的表的catalog信息。通常情况下有两种表，一种为输入表，<br>一种为输出表。输入表主要是在使用Table API和SQL查询时提供输入数据，输出表主要是将Table API和<br>SQL查询的结果作为输出结果对接到外部系统。</p>
<p>输入表有多种不同的输入源进行注册：</p>
<ul>
<li>已经存在的Table对象，通常是是作为Table API和SQL查询的结果</li>
<li>TableSource，可以访问外部数据如文件，数据库或者是消息系统</li>
<li>来自DataStream或是DataSet程序中的DataStream或DataSet，讨论DataStream或是DataSet<br>可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-datastream-and-dataset-api">整合DataStream和DataSet API</a>了解到</li>
</ul>
<p>输出表可使用TableSink进行注册</p>
<h2 id="Register-a-Table"><a href="#Register-a-Table" class="headerlink" title="Register a Table"></a>Register a Table</h2><p>Table是如何注册到TableEnvironment中如下所示：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从简单的查询结果中作为表</span></span><br><span class="line"><span class="keyword">val</span> projTable: <span class="type">Table</span> = tableEnv.scan(<span class="string">&quot;X&quot;</span>).select(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的表projTable命名为projectedTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTable(<span class="string">&quot;projectedTable&quot;</span>, projTable)</span><br></pre></td></tr></table></figure>
<p>注意：一张注册过的Table就跟关系型数据库中的视图性质相同，定义表的查询未进行优化，但在另一个查询引用已注册的表时将进行内联。<br>如果多表查询引用了相同的Table，它就会将每一个引用进行内联并且多次执行，已注册的Table的结果之间不会进行共享。</p>
<h2 id="Register-a-TableSource"><a href="#Register-a-TableSource" class="headerlink" title="Register a TableSource"></a>Register a TableSource</h2><p>TableSource可以访问外部系统存储例如数据库（Mysql,HBase），特殊格式编码的文件(CSV, Apache [Parquet, Avro, ORC], …)<br>或者是消息系统 (Apache Kafka, RabbitMQ, …)中的数据。</p>
<p>Flink旨在为通用数据格式和存储系统提供TableSource。请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">此处</a><br>了解支持的TableSource类型与如何去自定义TableSour。</p>
<p>TableSource是如何注册到TableEnvironment中如下所示：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableSource对象</span></span><br><span class="line"><span class="keyword">val</span> csvSource: <span class="type">TableSource</span> = <span class="keyword">new</span> <span class="type">CsvTableSource</span>(<span class="string">&quot;/path/to/file&quot;</span>, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的TableSource作为表并命名为csvTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTableSource(<span class="string">&quot;CsvTable&quot;</span>, csvSource)</span><br></pre></td></tr></table></figure>
<h2 id="Register-a-TableSink"><a href="#Register-a-TableSink" class="headerlink" title="Register a TableSink"></a>Register a TableSink</h2><p>注册过的TableSink可以将SQL查询的结果以表的形式输出到外部的存储系统，例如关系型数据库，<br>Key-Value数据库(Nosql)，消息队列，或者是其他文件系统(使用不同的编码, 例如CSV, Apache [Parquet, Avro, ORC], …)</p>
<p>Flink使用TableSink的目的是为了将常用的数据进行清洗转换然后存储到不同的存储介质中。详情请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">此处</a><br>去深入了解哪些sinks是可用的，并且如何去自定义TableSink。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableSink对象</span></span><br><span class="line"><span class="keyword">val</span> csvSink: <span class="type">TableSink</span> = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">&quot;/path/to/file&quot;</span>, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义字段的名称和类型</span></span><br><span class="line"><span class="keyword">val</span> fieldNames: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> fieldTypes: <span class="type">Array</span>[<span class="type">TypeInformation</span>[_]] = <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">INT</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的TableSink作为表并命名为CsvSinkTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTableSink(<span class="string">&quot;CsvSinkTable&quot;</span>, fieldNames, fieldTypes, csvSink)</span><br></pre></td></tr></table></figure>
<h2 id="Register-an-External-Catalog"><a href="#Register-an-External-Catalog" class="headerlink" title="Register an External Catalog"></a>Register an External Catalog</h2><p>外部目录可以提供有关外部数据库和表的信息，<br>例如其名称，模式，统计以及有关如何访问存储在外部数据库，表或文件中的数据的信息。</p>
<p>外部目录的创建方式可以通过实现ExternalCatalog接口，并且注册到TableEnvironment中，详情如下所示:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个External Catalog目录对象</span></span><br><span class="line"><span class="keyword">val</span> catalog: <span class="type">ExternalCatalog</span> = <span class="keyword">new</span> <span class="type">InMemoryExternalCatalog</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将ExternalCatalog注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerExternalCatalog(<span class="string">&quot;InMemCatalog&quot;</span>, catalog)</span><br></pre></td></tr></table></figure>
<p>一旦将External Catalog注册到TableEnvironment中，所有在ExternalCatalog中<br>定义的表可以通过完整的路径如catalog.database.table进行Table API和SQL的查询操作 </p>
<p>目前，Flink提供InMemoryExternalCatalog对象用来做demo和测试，然而，<br>ExternalCatalog对象还可用作Table API来连接catalogs，例如HCatalog 或 Metastore</p>
<h2 id="Query-a-Table"><a href="#Query-a-Table" class="headerlink" title="Query a Table"></a>Query a Table</h2><h3 id="Table-API"><a href="#Table-API" class="headerlink" title="Table API"></a>Table API</h3><p>Table API是Scala和Java语言集成查询的API，与SQL查询不同之处在于，它的查询不是像<br>SQL一样使用字符串进行查询，而是在语言中使用语法进行逐步组合使用</p>
<p>Table API是基于展示表（流或批处理）的Table类，它提供一些列操作应用相关的操作。<br>这些方法返回一个新的Table对象，该对象表示在输入表上关系运算的结果。一些关系运算是<br>由多个方法组合而成的，例如 table.groupBy(…).select()，其中groupBy()指定<br>表的分组，select()表示在分组的结果上进行查询。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/tableApi.html">Table API</a><br>描述了所有支持表的流式或者批处理相关的操作。</p>
<p>下面给出一个简单的实例去说明如何去使用Table API进行聚合查询：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册Orders表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 扫描注册过的Orders表</span></span><br><span class="line"><span class="keyword">val</span> orders = tableEnv.scan(<span class="string">&quot;Orders&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入</span></span><br><span class="line"><span class="keyword">val</span> revenue = orders</span><br><span class="line">  .filter(<span class="symbol">&#x27;cCountry</span> === <span class="string">&quot;FRANCE&quot;</span>)</span><br><span class="line">  .groupBy(<span class="symbol">&#x27;cID</span>, <span class="symbol">&#x27;cName</span>)</span><br><span class="line">  .select(<span class="symbol">&#x27;cID</span>, <span class="symbol">&#x27;cName</span>, <span class="symbol">&#x27;revenue</span>.sum <span class="type">AS</span> <span class="symbol">&#x27;revSum</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出成一张表或者是转换表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<p>注意：Scala的Table API使用Scala符号，它使用单引号加字段(‘cID)来表示表的属性的引用，<br>如果使用Scala的隐式转换的话，确保引入了org.apache.flink.api.scala._ 和 org.apache.flink.table.api.scala._<br>来确保它们之间的转换。</p>
<h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><p>Flink的SQL操作基于实现了SQL标准的<a href="https://calcite.apache.org/">Apache Calcite</a>，SQL查询通常是使用特殊且有规律的字符串。<br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sql.html">SQL</a><br>描述了所有支持表的流式或者批处理相关的SQL操作。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册Orders表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入</span></span><br><span class="line"><span class="keyword">val</span> revenue = tableEnv.sqlQuery(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  |SELECT cID, cName, SUM(revenue) AS revSum</span></span><br><span class="line"><span class="string">  |FROM Orders</span></span><br><span class="line"><span class="string">  |WHERE cCountry = &#x27;FRANCE&#x27;</span></span><br><span class="line"><span class="string">  |GROUP BY cID, cName</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出成一张表或者是转换表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<p>下面的例子展示了如何去使用更新查询去插入数据到已注册的表中</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册&quot;Orders&quot;表</span></span><br><span class="line"><span class="comment">// 注册&quot;RevenueFrance&quot;输出表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入并且将结果作为结果输出到&quot;RevenueFrance&quot;中</span></span><br><span class="line">tableEnv.sqlUpdate(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  |INSERT INTO RevenueFrance</span></span><br><span class="line"><span class="string">  |SELECT cID, cName, SUM(revenue) AS revSum</span></span><br><span class="line"><span class="string">  |FROM Orders</span></span><br><span class="line"><span class="string">  |WHERE cCountry = &#x27;FRANCE&#x27;</span></span><br><span class="line"><span class="string">  |GROUP BY cID, cName</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<h2 id="Mixing-Table-API-and-SQL"><a href="#Mixing-Table-API-and-SQL" class="headerlink" title="Mixing Table API and SQL"></a>Mixing Table API and SQL</h2><p>Table API和SQL可以很轻松的混合使用因为他们两者返回的结果都为Table对象：</p>
<ul>
<li>可以在SQL查询返回的Table对象上定义Table API查询</li>
<li>通过在TableEnvironment中注册结果表并在SQL查询的FROM子句中引用它，<br>可以在Table API查询的结果上定义SQL查询。</li>
</ul>
<h2 id="Emit-a-Table"><a href="#Emit-a-Table" class="headerlink" title="Emit a Table"></a>Emit a Table</h2><p>通过将Table写入到TableSink来作为一张表的输出，TableSink是做为多种文件类型 (CSV, Apache Parquet, Apache Avro),<br>存储系统(JDBC, Apache HBase, Apache Cassandra, Elasticsearch), 或者是消息系统 (Apache Kafka, RabbitMQ).输出的通用接口，</p>
<p>Batch Table只能通过BatchTableSink来进行数据写入，而Streaming Table可以<br>选择AppendStreamTableSink，RetractStreamTableSink，UpsertStreamTableSink<br>中的任意一个来进行。</p>
<p>请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">Table Source &amp; Sinks</a><br>来更详细的了解支持的Sinks并且如何去实现自定义的TableSink。</p>
<p>可以使用两种方式来输出一张表：</p>
<ul>
<li>Table.writeToSink(TableSink sink)方法使用提供的TableSink自动配置的表的schema来<br>进行表的输出</li>
<li>Table.insertInto（String sinkTable）方法查找在TableEnvironment目录中提供的名称下使用特定模式注册的TableSink。<br>将输出表的模式将根据已注册的TableSink的模式进行验证</li>
</ul>
<p>下面的例子展示了如何去查询结果作为一张表输出</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用Table API或者SQL 查询来查找结果</span></span><br><span class="line"><span class="keyword">val</span> result: <span class="type">Table</span> = ...</span><br><span class="line"><span class="comment">// 创建TableSink对象</span></span><br><span class="line"><span class="keyword">val</span> sink: <span class="type">TableSink</span> = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">&quot;/path/to/file&quot;</span>, fieldDelim = <span class="string">&quot;|&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法1: 使用TableSink的writeToSink()方法来将结果输出为一张表</span></span><br><span class="line">result.writeToSink(sink)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法2: 注册特殊schema的TableSink</span></span><br><span class="line"><span class="keyword">val</span> fieldNames: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> fieldTypes: <span class="type">Array</span>[<span class="type">TypeInformation</span>] = <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">INT</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>)</span><br><span class="line">tableEnv.registerTableSink(<span class="string">&quot;CsvSinkTable&quot;</span>, fieldNames, fieldTypes, sink)</span><br><span class="line"><span class="comment">// 调用注册过的TableSink中insertInto() 方法来将结果输出为一张表</span></span><br><span class="line">result.insertInto(<span class="string">&quot;CsvSinkTable&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行</span></span><br></pre></td></tr></table></figure>
<h2 id="Translate-and-Execute-a-Query"><a href="#Translate-and-Execute-a-Query" class="headerlink" title="Translate and Execute a Query"></a>Translate and Execute a Query</h2><p>Table API和SQL查询的结果转换为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/datastream_api.html">DataStream</a><br>或是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/">DataSet</a><br>取决于它的输入是流式输入还是批处理输入。查询逻辑在内部表示为逻辑执行计划，并分为两个阶段进行转换：</p>
<ul>
<li>优化逻辑执行计划</li>
<li>转换为DataStream或DataSet</li>
</ul>
<p>Table API或SQL查询在下面请看下进行转换：</p>
<ul>
<li>当调用Table.writeToSink() 或 Table.insertInto()进行查询结果表输出的时候</li>
<li>当调用TableEnvironment.sqlUpdate()进行SQL更新查询时</li>
<li>当表转换为DataSteam或DataSet时，详情查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-dataStream-and-dataSet-api">Integration with DataStream and DataSet API</a></li>
</ul>
<p>一旦进行转换后，Table API或SQL查询的结果就会在StreamExecutionEnvironment.execute() 或 ExecutionEnvironment.execute()<br>被调用时被当做DataStream或DataSet一样被进行处理</p>
<h2 id="Integration-with-DataStream-and-DataSet-API"><a href="#Integration-with-DataStream-and-DataSet-API" class="headerlink" title="Integration with DataStream and DataSet API"></a>Integration with DataStream and DataSet API</h2><p>Table API或SQL查询的结果很容易被<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/datastream_api.html">DataStream</a><br>或是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/">DataSet</a>内嵌整合。举个例子，<br>我们会进行外部表的查询(像关系型数据库)，然后做像过滤，映射，聚合或者是元数据关联的一些预处理。<br>然后使用DataStream或是DataSet API(或者是基于这些基础库开发的上层API库, 例如CEP或Gelly)进一步对数据进行处理。<br>同样，Table API或SQL查询也可以应用于DataStream或DataSet程序的结果。</p>
<p>##implicit Conversion for Scala<br>Scala Table API具有DataSet，DataStream和Table Class之间的隐式转换，流式操作API中只要引入org.apache.flink.table.api.scala._<br>和 org.apache.flink.api.scala._ 便可以进行相应的隐式转换</p>
<h2 id="Register-a-DataStream-or-DataSet-as-Table"><a href="#Register-a-DataStream-or-DataSet-as-Table" class="headerlink" title="Register a DataStream or DataSet as Table"></a>Register a DataStream or DataSet as Table</h2><p>DataStream或DataSet也可以作为Table注册到TableEnvironment中。结果表的模式取决于已注册的DataStream或DataSet的数据类型，<br>详情请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#mapping-of-data-types-to-table-schema">mapping of data types to table schema</a></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream作为具有&quot;f0&quot;, &quot;f1&quot;字段的&quot;myTable&quot;表注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerDataStream(<span class="string">&quot;myTable&quot;</span>, stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream作为具有&quot;myLong&quot;, &quot;myString&quot;字段的&quot;myTable2&quot;表注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerDataStream(<span class="string">&quot;myTable2&quot;</span>, stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br></pre></td></tr></table></figure>
<p>注意：DataStream表的名称必须与^ <em>DataStreamTable</em> [0-9] +模式不匹配，<br>并且DataSet表的名称必须与^ <em>DataSetTable</em> [0-9] +模式不匹配。<br>这些模式仅供内部使用。</p>
<h2 id="Convert-a-DataStream-or-DataSet-into-a-Table"><a href="#Convert-a-DataStream-or-DataSet-into-a-Table" class="headerlink" title="Convert a DataStream or DataSet into a Table"></a>Convert a DataStream or DataSet into a Table</h2><p>如果你使用Table API或是SQL查询，你可以直接将DataStream或DataSet直接转换为表而不需要<br>再将它们注册到TableEnvironment中。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1, &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table1: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;myLong, &#x27;myString将DataStram转换为Table</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> table2: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Convert-a-Table-into-a-DataStream-or-DataSet"><a href="#Convert-a-Table-into-a-DataStream-or-DataSet" class="headerlink" title="Convert a Table into a DataStream or DataSet"></a>Convert a Table into a DataStream or DataSet</h2><p>表可以转换为DataStream或DataSet，通过这种方式，自定义DataStream或DataSet<br>同样也可以作为Table API或SQL查询结果的结果。<br>当把表转换为DataStream或DataSet时，你需要指定生成的DataStream或DataSet的数据类型。<br>例如，表格行所需转换的数据类型，通常最方便的转换类型也最常用的是Row。<br>以下列表概述了不同选项的功能：</p>
<ul>
<li>Row：字段按位置，任意数量的字段映射，支持空值，无类型安全访问。</li>
<li>POJO：字段按名称(POJO字段必须与Table字段保持一致)，任意数量的字段映射，支持空值，类型安全访问。</li>
<li>Case Class：字段按位置，任意数量的字段映射，不支持空值，类型安全访问。</li>
<li>Tuple：字段按位置，Scala支持22个字段，Java 25个字段映射，不支持空值，类型安全访问。</li>
<li>Atomic Type：表必须具有单个字段，不支持空值，类型安全访问。<h3 id="Convert-a-Table-into-a-DataStream"><a href="#Convert-a-Table-into-a-DataStream" class="headerlink" title="Convert a Table into a DataStream"></a>Convert a Table into a DataStream</h3>作为流式查询结果的表将动态更新，它随着新记录到达查询的输入流而改变，于是，转换到这样的动态查询DataStream<br>需要对表的更新进行编码。<br>将表转换为DataStream有两种模式：</li>
<li>Append Mode：这种模式仅用于动态表仅仅通过INSERT来进行表的更新，它是仅可追加模式，<br>并且之前输出的表不会进行更改</li>
<li>Retract Mode：这种模式经常用到。它使用布尔值的变量来对INSERT和DELETE对表的更新做标记<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表中有两个字段(String name, Integet age)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为列的 append DataStream</span></span><br><span class="line"><span class="keyword">val</span> dsRow: <span class="type">DataStream</span>[<span class="type">Row</span>] = tableEnv.toAppendStream[<span class="type">Row</span>](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为Tubple2[String,Int]的 append DataStream</span></span><br><span class="line"><span class="comment">// convert the Table into an append DataStream of Tuple2[String, Int]</span></span><br><span class="line"><span class="keyword">val</span> dsTuple: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] dsTuple = </span><br><span class="line">  tableEnv.toAppendStream[(<span class="type">String</span>, <span class="type">Int</span>)](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert the Table into a retract DataStream of Row.</span></span><br><span class="line"><span class="comment">// Retract Mode下将表转换为列的 append DataStream</span></span><br><span class="line"><span class="comment">// 判断A retract stream X是否为DataStream[(Boolean, X)]</span></span><br><span class="line"><span class="comment">//  布尔只表示数据类型的变化,True代表为INSERT，false表示为删除</span></span><br><span class="line"><span class="keyword">val</span> retractStream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, <span class="type">Row</span>)] = tableEnv.toRetractStream[<span class="type">Row</span>](table)</span><br></pre></td></tr></table></figure>
注意：关于动态表和它的属性详情参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/streaming.html">Streaming Queries</a></li>
</ul>
<h3 id="Convert-a-Table-into-a-DataSet"><a href="#Convert-a-Table-into-a-DataSet" class="headerlink" title="Convert a Table into a DataSet"></a>Convert a Table into a DataSet</h3><p>表转换为DataSet如下所示：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表中有两个字段(String name, Integet age)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为列的DataSet</span></span><br><span class="line"><span class="keyword">val</span> dsRow: <span class="type">DataSet</span>[<span class="type">Row</span>] = tableEnv.toDataSet[<span class="type">Row</span>](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为Tubple2[String,Int]的DataSet</span></span><br><span class="line"><span class="keyword">val</span> dsTuple: <span class="type">DataSet</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = tableEnv.toDataSet[(<span class="type">String</span>, <span class="type">Int</span>)](table)</span><br></pre></td></tr></table></figure>
<h3 id="Mapping-of-Data-Types-to-Table-Schema"><a href="#Mapping-of-Data-Types-to-Table-Schema" class="headerlink" title="Mapping of Data Types to Table Schema"></a>Mapping of Data Types to Table Schema</h3><p>Flink的DataStream和DataSet API支持多种类型。组合类型像Tuple(内置Scala元组和Flink Java元组)，<br>POJOs，Scala case classes和Flink中具有可在表表达式中访问的多个字段允许嵌套数据结构的Row类型，<br>其他类型都被视为原子类型。接下来，我们将会描述Table API是如何将这些类型转换为内部的列展现并且<br>举例说明如何将DataStream转换为Table</p>
<h4 id="Position-based-Mapping"><a href="#Position-based-Mapping" class="headerlink" title="Position-based Mapping"></a>Position-based Mapping</h4><p>基于位置的映射通常在保持顺序的情况下给字段一个更有意义的名称，这种映射可用于有固定顺序的组合数据类型，<br>也可用于原子类型。复合数据类型（如元组，行和Case Class）具有此类字段顺序.然而，POJO的字段必须与映射的<br>表的字段名相同。</p>
<p>当定义基于位置的映射，输入的数据类型不得存在指定的名称，不然API会认为这些映射应该按名称来进行映射。<br>如果未指定字段名称，则使用复合类型的默认字段名称和字段顺序，或者使用f0作为原子类型。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1, &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table1: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;myLong, &#x27;myInt将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span> <span class="symbol">&#x27;myInt</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Name-based-Mapping"><a href="#Name-based-Mapping" class="headerlink" title="Name-based Mapping"></a>Name-based Mapping</h4><p>基于名称的映射可用于一切数据类型包括POJOs，它是定义表模式映射最灵活的一种方式。虽然查询结果的字段可能会使用别名，但<br>这种模式下所有的字段都是使用名称进行映射的。使用别名的情况下会进行重排序。<br>如果未指定字段名称，则使用复合类型的默认字段名称和字段顺序，或者使用f0作为原子类型。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1 和 &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只使用&#x27;_2字段将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换字段将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>, <span class="symbol">&#x27;_1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换后的字段给予别名&#x27;myInt, &#x27;myLong将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span> as <span class="symbol">&#x27;myInt</span>, <span class="symbol">&#x27;_1</span> as <span class="symbol">&#x27;myLong</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Atomic-Types"><a href="#Atomic-Types" class="headerlink" title="Atomic Types"></a>Atomic Types</h4><p>Flink将基础类型(Integer, Double, String)和通用类型(不能被分析和拆分的类型)视为原子类型。<br>原子类型的DataStream或DataSet转换为只有单个属性的表。从原子类型推断属性的类型，并且可以指定属性的名称。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Long</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为带默认字段&quot;f0&quot;的表</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为带字段&quot;myLong&quot;的表</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Tuples-Scala-and-Java-and-Case-Classes-Scala-only"><a href="#Tuples-Scala-and-Java-and-Case-Classes-Scala-only" class="headerlink" title="Tuples (Scala and Java) and Case Classes (Scala only)"></a>Tuples (Scala and Java) and Case Classes (Scala only)</h4><p>Flink支持内建的Tuples并且提供了自己的Tuple类给Java进行使用。DataStreams和DataSet这两种<br>Tuple都可以转换为表。提供所有字段的名称(基于位置的映射)字段可以被重命名。如果没有指定字段的名称，<br>就使用默认的字段名称。如果原始字段名(f0, f1, … for Flink Tuples and _1, _2, … for Scala Tuples)被引用了的话，<br>API就会使用基于名称的映射来代替位置的映射。基于名称的映射可以起别名并且会进行重排序。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将默认的字段重命名为&#x27;_1，&#x27;_2的DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字段名为&#x27;myLong，&#x27;myString的DataStream转换为Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将重排序后字段为&#x27;_2，&#x27;_1 的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>, <span class="symbol">&#x27;_1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将映射字段&#x27;_2的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将重排序后字段为&#x27;_2给出别名&#x27;myString，&#x27;_1给出别名&#x27;myLong 的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span> as <span class="symbol">&#x27;myString</span>, <span class="symbol">&#x27;_1</span> as <span class="symbol">&#x27;myLong</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义 case class</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">streamCC</span></span>: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将默认字段&#x27;name, &#x27;age的DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table = tableEnv.fromDataStream(streamCC)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字段名为&#x27;myName，&#x27;myAge的DataStream转换为Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table = tableEnv.fromDataStream(streamCC, <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line">将重排序后字段为<span class="symbol">&#x27;_age</span>给出别名<span class="symbol">&#x27;myAge</span>，<span class="symbol">&#x27;_name</span>给出别名<span class="symbol">&#x27;myName</span> 的<span class="type">DataStream</span>转换为<span class="type">Table</span>(基于名称)</span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="POJO-Java-and-Scala"><a href="#POJO-Java-and-Scala" class="headerlink" title="POJO (Java and Scala)"></a>POJO (Java and Scala)</h4><p>Flink支持POJO作为符合类型。决定POJO规则的文档请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/api_concepts.html#pojos">这里</a></p>
<p>当将一个POJO类型的DataStream或者DataSet转换为Table而不指定字段名称时，Table的字段名称将采用JOPO原生的字段名称作为字段名称。<br>重命名原始的POJO字段需要关键字AS，因为POJO没有固定的顺序，名称映射需要原始名称并且不能通过位置来完成。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Person 是一个有两个字段&quot;name&quot;和&quot;age&quot;的POJO</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为带字段 &quot;age&quot;, &quot;name&quot; 的Table(字段通过名称进行排序)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为重命名为&quot;myAge&quot;, &quot;myName&quot;的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将带映射字段&#x27;name的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将带映射字段&#x27;name并重命名为&#x27;myName的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Row"><a href="#Row" class="headerlink" title="Row"></a>Row</h4><p>Row数据类型可以支持任意数量的字段，并且这些字段支持null值。当进行Row DataStream或Row DataSet<br>转换为Table时可以通过RowTypeInfo来指定字段的名称。Row Type支持基于位置和名称的两种映射方式。<br>通过提供所有字段的名称可以进行字段的重命名(基于位置)，或者是单独选择列来进行映射/重排序/重命名(基于名称)</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在`RowTypeInfo`中指定字段&quot;name&quot; 和 &quot;age&quot;的Row类型DataStream</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Row</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为带默认字段 &quot;age&quot;, &quot;name&quot; 的Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为重命名字段 &#x27;myName, &#x27;myAge 的Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为重命名字段 &#x27;myName, &#x27;myAge 的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为映射字段 &#x27;name的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为映射字段 &#x27;name并重命名为&#x27;myName的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Query-Optimization"><a href="#Query-Optimization" class="headerlink" title="Query Optimization"></a>Query Optimization</h4><p>Apache Flink 基于 Apache Calcite 来做转换和查询优化。当前的查询优化包括投影、过滤下推、<br>相关子查询和各种相关的查询重写。Flink不去做join优化，但是会让他们去顺序执行(FROM子句中表的顺序或者WHERE子句中连接谓词的顺序)</p>
<p>可以通过提供一个CalciteConfig对象来调整在不同阶段应用的优化规则集，<br>这个可以通过调用CalciteConfig.createBuilder())获得的builder来创建，<br>并且可以通过调用tableEnv.getConfig.setCalciteConfig(calciteConfig)来提供给TableEnvironment。</p>
<h4 id="Explaining-a-Table"><a href="#Explaining-a-Table" class="headerlink" title="Explaining a Table"></a>Explaining a Table</h4><p>Table API为计算Table提供了一个机制来解析逻辑和优化查询计划，这个可以通过TableEnvironment.explain(table)<br>来完成。它返回描述三个计划的字符串信息：</p>
<ul>
<li>关联查询抽象语法树，即未优化过的逻辑执行计划</li>
<li>优化过的逻辑执行计划</li>
<li>物理执行计划</li>
</ul>
<p>下面的实例展示了相应的输出：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> tEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> table1 = env.fromElements((<span class="number">1</span>, <span class="string">&quot;hello&quot;</span>)).toTable(tEnv, <span class="symbol">&#x27;count</span>, <span class="symbol">&#x27;word</span>)</span><br><span class="line"><span class="keyword">val</span> table2 = env.fromElements((<span class="number">1</span>, <span class="string">&quot;hello&quot;</span>)).toTable(tEnv, <span class="symbol">&#x27;count</span>, <span class="symbol">&#x27;word</span>)</span><br><span class="line"><span class="keyword">val</span> table = table1</span><br><span class="line">  .where(<span class="symbol">&#x27;word</span>.like(<span class="string">&quot;F%&quot;</span>))</span><br><span class="line">  .unionAll(table2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> explanation: <span class="type">String</span> = tEnv.explain(table)</span><br><span class="line">println(explanation)</span><br></pre></td></tr></table></figure>
<p>对应的输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x3D;&#x3D; 抽象语法树 &#x3D;&#x3D;</span><br><span class="line">LogicalUnion(all&#x3D;[true])</span><br><span class="line">  LogicalFilter(condition&#x3D;[LIKE($1, &#39;F%&#39;)])</span><br><span class="line">    LogicalTableScan(table&#x3D;[[_DataStreamTable_0]])</span><br><span class="line">  LogicalTableScan(table&#x3D;[[_DataStreamTable_1]])</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D; 优化后的逻辑执行计划 &#x3D;&#x3D;</span><br><span class="line">DataStreamUnion(union&#x3D;[count, word])</span><br><span class="line">  DataStreamCalc(select&#x3D;[count, word], where&#x3D;[LIKE(word, &#39;F%&#39;)])</span><br><span class="line">    DataStreamScan(table&#x3D;[[_DataStreamTable_0]])</span><br><span class="line">  DataStreamScan(table&#x3D;[[_DataStreamTable_1]])</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D; 物理执行计划 &#x3D;&#x3D;</span><br><span class="line">Stage 1 : Data Source</span><br><span class="line">  content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">Stage 2 : Data Source</span><br><span class="line">  content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">  Stage 3 : Operator</span><br><span class="line">    content : from: (count, word)</span><br><span class="line">    ship_strategy : REBALANCE</span><br><span class="line"></span><br><span class="line">    Stage 4 : Operator</span><br><span class="line">      content : where: (LIKE(word, &#39;F%&#39;)), select: (count, word)</span><br><span class="line">      ship_strategy : FORWARD</span><br><span class="line"></span><br><span class="line">      Stage 5 : Operator</span><br><span class="line">        content : from: (count, word)</span><br><span class="line">        ship_strategy : REBALANCE</span><br></pre></td></tr></table></figure>

<h1 id="Flink用户自定义函数"><a href="#Flink用户自定义函数" class="headerlink" title="Flink用户自定义函数"></a>Flink用户自定义函数</h1><p>用户自定义函数是非常重要的一个特征，因为他极大地扩展了查询的表达能力。</p>
<p>在大多数场景下，用户自定义函数在使用之前是必须要注册的。对于Scala的Table API，udf是不需要注册的。<br>调用TableEnvironment的registerFunction()方法来实现注册。Udf注册成功之后，会被插入TableEnvironment的function catalog，这样table API和sql就能解析他了。<br>本文会主要讲三种udf：</p>
<ul>
<li>ScalarFunction</li>
<li>TableFunction</li>
<li>AggregateFunction</li>
</ul>
<h2 id="1-Scalar-Functions-标量函数"><a href="#1-Scalar-Functions-标量函数" class="headerlink" title="1. Scalar Functions 标量函数"></a>1. Scalar Functions 标量函数</h2><p>标量函数，是指指返回一个值的函数。标量函数是实现讲0，1，或者多个标量值转化为一个新值。</p>
<p>实现一个标量函数需要继承ScalarFunction，并且实现一个或者多个evaluation方法。标量函数的行为就是通过evaluation方法来实现的。evaluation方法必须定义为public，命名为eval。evaluation方法的输入参数类型和返回值类型决定着标量函数的输入参数类型和返回值类型。evaluation方法也可以被重载实现多个eval。同时evaluation方法支持变参数，例如：eval(String… strs)。</p>
<p>下面给出一个标量函数的例子。例子实现的事一个hashcode方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">12</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">HashCode</span><span class="params">(<span class="keyword">int</span> factor)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.factor = factor;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the function</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> HashCode(<span class="number">10</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in Java Table API</span></span><br><span class="line">myTable.select(<span class="string">&quot;string, string.hashCode(), hashCode(string)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in SQL API</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;</span>);</span><br><span class="line"></span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">默认情况下evaluation方法的返回值类型是由flink类型抽取工具决定。对于基础类型，简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载</span><br><span class="line">ScalarFunction#getResultType()。</span><br><span class="line"></span><br><span class="line">下面给一个例子，通过复写ScalarFunction#getResultType()，将long型的返回值在代码生成的时候翻译成Types.TIMESTAMP。</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TimestampModifier</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">eval</span><span class="params">(<span class="keyword">long</span> t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> t % <span class="number">1000</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> TypeInformation&lt;?&gt; getResultType(signature: Class&lt;?&gt;[]) &#123;</span><br><span class="line">    <span class="keyword">return</span> Types.TIMESTAMP;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-Table-Functions-表函数"><a href="#2-Table-Functions-表函数" class="headerlink" title="2. Table Functions 表函数"></a>2. Table Functions 表函数</h2><p>与标量函数相似之处是输入可以0，1，或者多个参数，但是不同之处可以输出任意数目的行数。返回的行也可以包含一个或者多个列。</p>
<p>为了自定义表函数，需要继承TableFunction，实现一个或者多个evaluation方法。表函数的行为定义在这些evaluation方法内部，函数名为eval并且必须是public。TableFunction可以重载多个eval方法。Evaluation方法的输入参数类型，决定着表函数的输入类型。Evaluation方法也支持变参，例如：eval(String… strs)。返回表的类型取决于TableFunction的基本类型。Evaluation方法使用collect(T)发射输出的rows。</p>
<p>在Table API中，表函数在scala语言中使用方法如下：.join(Expression) 或者 .leftOuterJoin(Expression)，在java语言中使用方法如下：.join(String) 或者.leftOuterJoin(String)。</p>
<p>Join操作算子会使用表值函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行。</p>
<p>leftOuterJoin操作算子会使用表值函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行，并且在表函数返回一个空表的情况下会保留所有的outer rows。</p>
<p>在sql语法中稍微有点区别：<br>cross join用法是LATERAL TABLE(<TableFunction>)。<br>LEFT JOIN用法是在join条件中加入ON TRUE。</p>
<p>下面的理智讲的是如何使用表值函数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// The generic type &quot;Tuple2&lt;String, Integer&gt;&quot; determines the schema of the returned table as (String, Integer).</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Split</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String separator = <span class="string">&quot; &quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Split</span><span class="params">(String separator)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.separator = separator;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String s : str.split(separator)) &#123;</span><br><span class="line">            <span class="comment">// use collect(...) to emit a row</span></span><br><span class="line">            collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(s, s.length()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line">Table myTable = ...         <span class="comment">// table schema: [a: String]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Register the function.</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;split&quot;</span>, <span class="keyword">new</span> Split(<span class="string">&quot;#&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use the table function in the Java Table API. &quot;as&quot; specifies the field names of the table.</span></span><br><span class="line">myTable.join(<span class="string">&quot;split(a) as (word, length)&quot;</span>).select(<span class="string">&quot;a, word, length&quot;</span>);</span><br><span class="line">myTable.leftOuterJoin(<span class="string">&quot;split(a) as (word, length)&quot;</span>).select(<span class="string">&quot;a, word, length&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use the table function in SQL with LATERAL and TABLE keywords.</span></span><br><span class="line">join.md</span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT a, word, length FROM MyTable, LATERAL TABLE(split(a)) as T(word, length)&quot;</span>);</span><br><span class="line"><span class="comment">// LEFT JOIN a table function (equivalent to &quot;leftOuterJoin&quot; in Table API).</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT a, word, length FROM MyTable LEFT JOIN LATERAL TABLE(split(a)) as T(word, length) ON TRUE&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>需要注意的是PROJO类型不需要一个确定的字段顺序。意味着你不能使用as修改表函数返回的pojo的字段的名字。</p>
<p>默认情况下TableFunction返回值类型是由flink类型抽取工具决定。对于基础类型，简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载<br>TableFunction#getResultType()。</p>
<p>下面的例子，我们通过复写TableFunction#getResultType()方法使得表返回类型是RowTypeInfo(String, Integer)。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomTypeSplit</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Row</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String s : str.split(<span class="string">&quot; &quot;</span>)) &#123;</span><br><span class="line">            Row row = <span class="keyword">new</span> Row(<span class="number">2</span>);</span><br><span class="line">            row.setField(<span class="number">0</span>, s);</span><br><span class="line">            row.setField(<span class="number">1</span>, s.length);</span><br><span class="line">            collect(row);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TypeInformation&lt;Row&gt; <span class="title">getResultType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Types.ROW(Types.STRING(), Types.INT());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-Aggregation-Functions-聚合函数"><a href="#3-Aggregation-Functions-聚合函数" class="headerlink" title="3. Aggregation Functions 聚合函数"></a>3. Aggregation Functions 聚合函数</h2><p>用户自定义聚合函数聚合一张表(一行或者多行，一行有一个或者多个属性)为一个标量的值。</p>
<p>上图中是讲的一张饮料的表这个表有是那个字段五行数据，现在要做的事求出所有饮料的最高价。</p>
<p>聚合函数需要继承AggregateFunction。聚合函数工作方式如下：<br>首先，需要一个accumulator，这个是保存聚合中间结果的数据结构。调用AggregateFunction函数的createAccumulator()方法来创建一个空的accumulator.<br>随后，每个输入行都会调用accumulate()方法来更新accumulator。一旦所有的行被处理了，getValue()方法就会被调用，计算和返回最终的结果。</p>
<p>对于每个AggregateFunction，下面三个方法都是比不可少的：<br>createAccumulator()<br>accumulate()<br>getValue()</p>
<p>flink的类型抽取机制不能识别复杂的数据类型，比如，数据类型不是基础类型或者简单的pojos类型。所以，类似于ScalarFunction 和TableFunction，AggregateFunction提供了方法去指定返回结果类型的TypeInformation，用的是AggregateFunction#getResultType()。Accumulator类型用的是AggregateFunction#getAccumulatorType()。</p>
<p>除了上面的方法，这里有一些可选的方法。尽管有些方法是让系统更加高效的执行查询，另外的一些在特定的场景下是必须的。例如，merge()方法在会话组窗口上下文中是必须的。当一行数据是被视为跟两个回话窗口相关的时候，两个会话窗口的accumulators需要被join。</p>
<p>AggregateFunction的下面几个方法，根据使用场景的不同需要被实现：<br>retract()：在bounded OVER窗口的聚合方法中是需要实现的。<br>merge()：在很多batch 聚合和会话窗口聚合是必须的。<br>resetAccumulator(): 在大多数batch聚合是必须的。</p>
<p>AggregateFunction的所有方法都是需要被声明为public，而不是static。定义聚合函数需要实现org.apache.flink.table.functions.AggregateFunction同时需要实现一个或者多个accumulate方法。该方法可以被重载为不同的数据类型，并且支持变参。</p>
<p>在这里就不贴出来AggregateFunction的源码了。</p>
<p>下面举个求加权平均的栗子<br>为了计算加权平均值，累加器需要存储已累积的所有数据的加权和及计数。在栗子中定义一个WeightedAvgAccum类作为accumulator。尽管，retract(), merge(), 和resetAccumulator()方法在很多聚合类型是不需要的，这里也给出了栗子。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Accumulator for WeightedAvg.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvgAccum</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Weighted Average user-defined aggregate function.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvg</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>&lt;<span class="title">Long</span>, <span class="title">WeightedAvgAccum</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> WeightedAvgAccum <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> WeightedAvgAccum();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Long <span class="title">getValue</span><span class="params">(WeightedAvgAccum acc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (acc.count == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> acc.sum / acc.count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accumulate</span><span class="params">(WeightedAvgAccum acc, <span class="keyword">long</span> iValue, <span class="keyword">int</span> iWeight)</span> </span>&#123;</span><br><span class="line">        acc.sum += iValue * iWeight;</span><br><span class="line">        acc.count += iWeight;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">retract</span><span class="params">(WeightedAvgAccum acc, <span class="keyword">long</span> iValue, <span class="keyword">int</span> iWeight)</span> </span>&#123;</span><br><span class="line">        acc.sum -= iValue * iWeight;</span><br><span class="line">        acc.count -= iWeight;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(WeightedAvgAccum acc, Iterable&lt;WeightedAvgAccum&gt; it)</span> </span>&#123;</span><br><span class="line">        Iterator&lt;WeightedAvgAccum&gt; iter = it.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            WeightedAvgAccum a = iter.next();</span><br><span class="line">            acc.count += a.count;</span><br><span class="line">            acc.sum += a.sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resetAccumulator</span><span class="params">(WeightedAvgAccum acc)</span> </span>&#123;</span><br><span class="line">        acc.count = <span class="number">0</span>;</span><br><span class="line">        acc.sum = <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// register function</span></span><br><span class="line">StreamTableEnvironment tEnv = ...</span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;wAvg&quot;</span>, <span class="keyword">new</span> WeightedAvg());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use function</span></span><br><span class="line">tEnv.sqlQuery(<span class="string">&quot;SELECT user, wAvg(points, level) AS avgPoints FROM userScores GROUP BY user&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="4-实现udf的最佳实践经验"><a href="#4-实现udf的最佳实践经验" class="headerlink" title="4. 实现udf的最佳实践经验"></a>4. 实现udf的最佳实践经验</h2><p>Table API和SQL 代码生成器内部会尽可能多的尝试使用原生值。用户定义的函数可能通过对象创建、强制转换(casting)和拆装箱((un)boxing)引入大量开销。因此，强烈推荐参数和返回值的类型定义为原生类型而不是他们包装类型(boxing class)。Types.DATE 和Types.TIME可以用int代替。Types.TIMESTAMP可以用long代替。</p>
<p>我们建议用户自定义函数使用java编写而不是scala编写，因为scala的类型可能会有不被flink类型抽取器兼容。</p>
<p>用Runtime集成UDFs</p>
<p>有时候udf需要获取全局runtime信息或者在进行实际工作之前做一些设置和清除工作。Udf提供了open()和close()方法，可以被复写，功能类似Dataset和DataStream API的RichFunction方法。</p>
<p>Open()方法是在evaluation方法调用前调用一次。Close()是在evaluation方法最后一次调用后调用。</p>
<p>Open()方法提共一个FunctionContext，FunctionContext包含了udf执行环境的上下文，比如，metric group，分布式缓存文件，全局的job参数。</p>
<p>通过调用FunctionContext的相关方法，可以获取到相关的信息：</p>
<p>方法描述</p>
<ul>
<li>getMetricGroup() - 并行子任务的指标组</li>
<li>getCachedFile(name) -分布式缓存文件的本地副本</li>
<li>getJobParameter(name, defaultValue) - 给定key全局job参数。</li>
</ul>
<p>下面，给出的例子就是通过FunctionContext在一个标量函数中获取全局job的参数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(FunctionContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// access &quot;hashcode_factor&quot; parameter</span></span><br><span class="line">        <span class="comment">// &quot;12&quot; would be the default value if parameter does not exist</span></span><br><span class="line">        factor = Integer.valueOf(context.getJobParameter(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;12&quot;</span>)); </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// set job parameter</span></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.setString(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;31&quot;</span>);</span><br><span class="line">env.getConfig().setGlobalJobParameters(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the function</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> HashCode());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in Java Table API</span></span><br><span class="line">myTable.select(<span class="string">&quot;string, string.hashCode(), hashCode(string)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in SQL</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;</span>);</span><br></pre></td></tr></table></figure>
<h1 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h1><h2 id="scala"><a href="#scala" class="headerlink" title="scala"></a>scala</h2><h3 id="三元运算符"><a href="#三元运算符" class="headerlink" title="三元运算符"></a>三元运算符</h3><p>sql或者table API筛选数据，必须保证每个字段不为空，<br>Flink内部，中间结果都是通过case class传递，而case class的字段必须保证不能为空</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">BOOLEAN</span>.?(<span class="type">VALUE1</span>, <span class="type">VALUE2</span>)</span><br><span class="line"><span class="symbol">&#x27;is_active_user</span>.isNull.?(<span class="string">&quot;0&quot;</span>, <span class="string">&quot;1&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="等值判断"><a href="#等值判断" class="headerlink" title="等值判断"></a>等值判断</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="symbol">&#x27;Fuin</span> === <span class="symbol">&#x27;active_user</span></span><br></pre></td></tr></table></figure>
<p>scala中的<code>===</code>是运算符重构</p>
<ol>
<li><a href="https://www.cnblogs.com/Springmoon-venn/p/11826359.html">Flink Table Api &amp; SQL 翻译目录</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>【转发】咱们从头到尾讲一次 Flink 网络流控和反压剖析</title>
    <url>/bigdata/Flink/Flink-backpress-ext/</url>
    <content><![CDATA[<p>本文根据 Apache Flink 系列直播整理而成，由 Apache Flink Contributor、OPPO 大数据平台研发负责人张俊老师分享。主要内容如下：</p>
<ul>
<li><p>网络流控的概念与背景</p>
</li>
<li><p>TCP的流控机制</p>
</li>
<li><p>Flink TCP-based 反压机制（before V1.5）</p>
</li>
<li><p>Flink Credit-based 反压机制 （since V1.5）</p>
</li>
<li><p>总结与思考</p>
</li>
</ul>
<h2 id="网络流控的概念与背景"><a href="#网络流控的概念与背景" class="headerlink" title="网络流控的概念与背景"></a>网络流控的概念与背景</h2><h3 id="为什么需要网络流控"><a href="#为什么需要网络流控" class="headerlink" title="为什么需要网络流控"></a>为什么需要网络流控</h3><p><img src="_v_images/20200714171454820_132283117"></p>
<p>首先我们可以看下这张最精简的网络流控的图，Producer 的吞吐率是 2MB/s，Consumer 是 1MB/s，这个时候我们就会发现在网络通信的时候我们的 Producer 的速度是比 Consumer 要快的，有 1MB/s 的这样的速度差，假定我们两端都有一个 Buffer，Producer 端有一个发送用的 Send Buffer，Consumer 端有一个接收用的 Receive Buffer，在网络端的吞吐率是 2MB/s，过了 5s 后我们的 Receive Buffer 可能就撑不住了，这时候会面临两种情况：</p>
<ul>
<li><p>1.如果 Receive Buffer 是有界的，这时候新到达的数据就只能被丢弃掉了。</p>
</li>
<li><p>2.如果 Receive Buffer 是无界的，Receive Buffer 会持续的扩张，最终会导致 Consumer 的内存耗尽。</p>
</li>
</ul>
<h3 id="网络流控的实现：静态限速"><a href="#网络流控的实现：静态限速" class="headerlink" title="网络流控的实现：静态限速"></a>网络流控的实现：静态限速</h3><p><img src="_v_images/20200714171454414_685240728"></p>
<p>为了解决这个问题，我们就需要网络流控来解决上下游速度差的问题，传统的做法可以在 Producer 端实现一个类似 Rate Limiter 这样的静态限流，Producer 的发送速率是 2MB/s，但是经过限流这一层后，往 Send Buffer 去传数据的时候就会降到 1MB/s 了，这样的话 Producer 端的发送速率跟 Consumer 端的处理速率就可以匹配起来了，就不会导致上述问题。但是这个解决方案有两点限制：</p>
<ul>
<li><p>1、事先无法预估 Consumer 到底能承受多大的速率</p>
</li>
<li><p>2、 Consumer 的承受能力通常会动态地波动</p>
</li>
</ul>
<h3 id="网络流控的实现：动态反馈-自动反压"><a href="#网络流控的实现：动态反馈-自动反压" class="headerlink" title="网络流控的实现：动态反馈/自动反压"></a>网络流控的实现：动态反馈/自动反压</h3><p><img src="_v_images/20200714171454209_1020595047"></p>
<p>针对静态限速的问题我们就演进到了动态反馈（自动反压）的机制，我们需要 Consumer 能够及时的给 Producer 做一个 feedback，即告知 Producer 能够承受的速率是多少。动态反馈分为两种：</p>
<ul>
<li><p>1、负反馈：接受速率小于发送速率时发生，告知 Producer 降低发送速率</p>
</li>
<li><p>2、正反馈：发送速率小于接收速率时发生，告知 Producer 可以把发送速率提上来</p>
</li>
</ul>
<p>让我们来看几个经典案例</p>
<h3 id="案例一：Storm-反压实现"><a href="#案例一：Storm-反压实现" class="headerlink" title="案例一：Storm 反压实现"></a>案例一：Storm 反压实现</h3><p><img src="_v_images/20200714171454004_1684651238"></p>
<p>上图就是 Storm 里实现的反压机制，可以看到 Storm 在每一个 Bolt 都会有一个监测反压的线程（Backpressure Thread），这个线程一但检测到 Bolt 里的接收队列（recv queue）出现了严重阻塞就会把这个情况写到 ZooKeeper 里，ZooKeeper 会一直被 Spout 监听，监听到有反压的情况就会停止发送，通过这样的方式匹配上下游的发送接收速率。</p>
<h3 id="案例二：Spark-Streaming-反压实现"><a href="#案例二：Spark-Streaming-反压实现" class="headerlink" title="案例二：Spark Streaming 反压实现"></a>案例二：Spark Streaming 反压实现</h3><p><img src="_v_images/20200714171453699_1486221085"></p>
<p>Spark Streaming 里也有做类似这样的 feedback 机制，上图 Fecher 会实时的从 Buffer、Processing 这样的节点收集一些指标然后通过 Controller 把速度接收的情况再反馈到 Receiver，实现速率的匹配。</p>
<h3 id="疑问：为什么-Flink（before-V1-5）里没有用类似的方式实现-feedback-机制？"><a href="#疑问：为什么-Flink（before-V1-5）里没有用类似的方式实现-feedback-机制？" class="headerlink" title="疑问：为什么 Flink（before V1.5）里没有用类似的方式实现 feedback 机制？"></a>疑问：为什么 Flink（before V1.5）里没有用类似的方式实现 feedback 机制？</h3><p>首先在解决这个疑问之前我们需要先了解一下 Flink 的网络传输是一个什么样的架构。</p>
<p><img src="_v_images/20200714171453393_758272414"></p>
<p>这张图就体现了 Flink 在做网络传输的时候基本的数据的流向，发送端在发送网络数据前要经历自己内部的一个流程，会有一个自己的 Network Buffer，在底层用 Netty 去做通信，Netty 这一层又有属于自己的 ChannelOutbound Buffer，因为最终是要通过 Socket 做网络请求的发送，所以在 Socket 也有自己的 Send Buffer，同样在接收端也有对应的三级 Buffer。学过计算机网络的时候我们应该了解到，TCP 是自带流量控制的。实际上 Flink （before V1.5）就是通过 TCP 的流控机制来实现 feedback 的。</p>
<h2 id="TCP-流控机制"><a href="#TCP-流控机制" class="headerlink" title="TCP 流控机制"></a>TCP 流控机制</h2><p>根据下图我们来简单的回顾一下 TCP 包的格式结构。首先，他有 Sequence number 这样一个机制给每个数据包做一个编号，还有 ACK number 这样一个机制来确保 TCP 的数据传输是可靠的，除此之外还有一个很重要的部分就是 Window Size，接收端在回复消息的时候会通过 Window Size 告诉发送端还可以发送多少数据。</p>
<p><img src="_v_images/20200714171452987_650184722"></p>
<p>接下来我们来简单看一下这个过程。</p>
<h3 id="TCP-流控：滑动窗口"><a href="#TCP-流控：滑动窗口" class="headerlink" title="TCP 流控：滑动窗口"></a>TCP 流控：滑动窗口</h3><p><img src="_v_images/20200714171452683_1953611527"></p>
<p>TCP 的流控就是基于滑动窗口的机制，现在我们有一个 Socket 的发送端和一个 Socket 的接收端，目前我们的发送端的速率是我们接收端的 3 倍，这样会发生什么样的一个情况呢？假定初始的时候我们发送的 window 大小是 3，然后我们接收端的 window 大小是固定的，就是接收端的 Buffer 大小为 5。</p>
<p><img src="_v_images/20200714171452278_1991948370"></p>
<p>首先，发送端会一次性发 3 个 packets，将 1，2，3 发送给接收端，接收端接收到后会将这 3 个 packets 放到 Buffer 里去。</p>
<p><img src="_v_images/20200714171452072_41416741"></p>
<p>接收端一次消费 1 个 packet，这时候 1 就已经被消费了，然后我们看到接收端的滑动窗口会往前滑动一格，这时候 2，3 还在 Buffer 当中 而 4，5，6 是空出来的，所以接收端会给发送端发送 ACK = 4 ，代表发送端可以从 4 开始发送，同时会将 window 设置为 3 （Buffer 的大小 5 减去已经存下的 2 和 3），发送端接收到回应后也会将他的滑动窗口向前移动到 4，5，6。</p>
<p><img src="_v_images/20200714171451767_719493078"></p>
<p>这时候发送端将 4，5，6 发送，接收端也能成功的接收到 Buffer 中去。</p>
<p><img src="_v_images/20200714171451562_313469730"></p>
<p>到这一阶段后，接收端就消费到 2 了，同样他的窗口也会向前滑动一个，这时候他的 Buffer 就只剩一个了，于是向发送端发送 ACK = 7、window = 1。发送端收到之后滑动窗口也向前移，但是这个时候就不能移动 3 格了，虽然发送端的速度允许发 3 个 packets 但是 window 传值已经告知只能接收一个，所以他的滑动窗口就只能往前移一格到 7 ，这样就达到了限流的效果，发送端的发送速度从 3 降到 1。</p>
<p><img src="_v_images/20200714171451057_482639053"></p>
<p><img src="_v_images/20200714171450752_1192910727"></p>
<p>我们再看一下这种情况，这时候发送端将 7 发送后，接收端接收到，但是由于接收端的消费出现问题，一直没有从 Buffer 中去取，这时候接收端向发送端发送 ACK = 8、window = 0 ，由于这个时候 window = 0，发送端是不能发送任何数据，也就会使发送端的发送速度降为 0。这个时候发送端不发送任何数据了，接收端也不进行任何的反馈了，那么如何知道消费端又开始消费了呢？</p>
<p><img src="_v_images/20200714171450147_1390602232"></p>
<p><img src="_v_images/20200714171449642_832142513"></p>
<p><img src="_v_images/20200714171449037_394744327"></p>
<p>TCP 当中有一个 ZeroWindowProbe 的机制，发送端会定期的发送 1 个字节的探测消息，这时候接收端就会把 window 的大小进行反馈。当接收端的消费恢复了之后，接收到探测消息就可以将 window 反馈给发送端端了从而恢复整个流程。TCP 就是通过这样一个滑动窗口的机制实现 feedback。</p>
<h2 id="Flink-TCP-based-反压机制（before-V1-5）"><a href="#Flink-TCP-based-反压机制（before-V1-5）" class="headerlink" title="Flink TCP-based 反压机制（before V1.5）"></a>Flink TCP-based 反压机制（before V1.5）</h2><h3 id="示例：WindowWordCount"><a href="#示例：WindowWordCount" class="headerlink" title="示例：WindowWordCount"></a>示例：WindowWordCount</h3><p><img src="_v_images/20200714171448732_1736435542"></p>
<p>大体的逻辑就是从 Socket 里去接收数据，每 5s 去进行一次 WordCount，将这个代码提交后就进入到了编译阶段。</p>
<h3 id="编译阶段：生成-JobGraph"><a href="#编译阶段：生成-JobGraph" class="headerlink" title="编译阶段：生成 JobGraph"></a>编译阶段：生成 JobGraph</h3><p><img src="_v_images/20200714171448227_116055159"></p>
<p>这时候还没有向集群去提交任务，在 Client 端会将 StreamGraph 生成 JobGraph，JobGraph 就是做为向集群提交的最基本的单元。在生成 JobGrap 的时候会做一些优化，将一些没有 Shuffle 机制的节点进行合并。有了 JobGraph 后就会向集群进行提交，进入运行阶段。</p>
<h3 id="运行阶段：调度-ExecutionGraph"><a href="#运行阶段：调度-ExecutionGraph" class="headerlink" title="运行阶段：调度 ExecutionGraph"></a>运行阶段：调度 ExecutionGraph</h3><p><img src="_v_images/20200714171447922_1674684296"></p>
<p>JobGraph 提交到集群后会生成 ExecutionGraph ，这时候就已经具备基本的执行任务的雏形了，把每个任务拆解成了不同的 SubTask，上图 ExecutionGraph 中的 Intermediate Result Partition 就是用于发送数据的模块，最终会将 ExecutionGraph 交给 JobManager 的调度器，将整个 ExecutionGraph 调度起来。然后我们概念化这样一张物理执行图，可以看到每个 Task 在接收数据时都会通过这样一个 InputGate 可以认为是负责接收数据的，再往前有这样一个 ResultPartition 负责发送数据，在 ResultPartition 又会去做分区跟下游的 Task 保持一致，就形成了 ResultSubPartition 和 InputChannel 的对应关系。这就是从逻辑层上来看的网络传输的通道，基于这么一个概念我们可以将反压的问题进行拆解。</p>
<h3 id="问题拆解：反压传播两个阶段"><a href="#问题拆解：反压传播两个阶段" class="headerlink" title="问题拆解：反压传播两个阶段"></a>问题拆解：反压传播两个阶段</h3><p><img src="_v_images/20200714171447717_722983245"></p>
<p>反压的传播实际上是分为两个阶段的，对应着上面的执行图，我们一共涉及 3 个 TaskManager，在每个 TaskManager 里面都有相应的 Task 在执行，还有负责接收数据的 InputGate，发送数据的 ResultPartition，这就是一个最基本的数据传输的通道。在这时候假设最下游的 Task （Sink）出现了问题，处理速度降了下来这时候是如何将这个压力反向传播回去呢？这时候就分为两种情况：</p>
<ul>
<li><p>跨 TaskManager ，反压如何从 InputGate 传播到 ResultPartition</p>
</li>
<li><p>TaskManager 内，反压如何从 ResultPartition 传播到 InputGate</p>
</li>
</ul>
<h3 id="跨-TaskManager-数据传输"><a href="#跨-TaskManager-数据传输" class="headerlink" title="跨 TaskManager 数据传输"></a>跨 TaskManager 数据传输</h3><p><img src="_v_images/20200714171447411_1651413338"></p>
<p>前面提到，发送数据需要 ResultPartition，在每个 ResultPartition 里面会有分区 ResultSubPartition，中间还会有一些关于内存管理的 Buffer。 对于一个 TaskManager 来说会有一个统一的 Network BufferPool 被所有的 Task 共享，在初始化时会从 Off-heap Memory 中申请内存，申请到内存的后续内存管理就是同步 Network BufferPool 来进行的，不需要依赖 JVM GC 的机制去释放。有了 Network BufferPool 之后可以为每一个 ResultSubPartition 创建 Local BufferPool 。 如上图左边的 TaskManager 的 Record Writer 写了 &lt;1，2&gt; 这个两个数据进来，因为 ResultSubPartition 初始化的时候为空，没有 Buffer 用来接收，就会向 Local BufferPool 申请内存，这时 Local BufferPool 也没有足够的内存于是将请求转到 Network BufferPool，最终将申请到的 Buffer 按原链路返还给 ResultSubPartition，&lt;1，2&gt; 这个两个数据就可以被写入了。之后会将 ResultSubPartition 的 Buffer 拷贝到 Netty 的 Buffer 当中最终拷贝到 Socket 的 Buffer 将消息发送出去。然后接收端按照类似的机制去处理将消息消费掉。 接下来我们来模拟上下游处理速度不匹配的场景，发送端的速率为 2，接收端的速率为 1，看一下反压的过程是怎样的。</p>
<h3 id="跨-TaskManager-反压过程"><a href="#跨-TaskManager-反压过程" class="headerlink" title="跨 TaskManager 反压过程"></a>跨 TaskManager 反压过程</h3><p><img src="_v_images/20200714171447006_680735181"></p>
<p>因为速度不匹配就会导致一段时间后 InputChannel 的 Buffer 被用尽，于是他会向 Local BufferPool 申请新的 Buffer ，这时候可以看到 Local BufferPool 中的一个 Buffer 就会被标记为 Used。</p>
<p><img src="_v_images/20200714171446799_1194236091"></p>
<p>发送端还在持续以不匹配的速度发送数据，然后就会导致 InputChannel 向 Local BufferPool 申请 Buffer 的时候发现没有可用的 Buffer 了，这时候就只能向 Network BufferPool 去申请，当然每个 Local BufferPool 都有最大的可用的 Buffer，防止一个 Local BufferPool 把 Network BufferPool 耗尽。这时候看到 Network BufferPool 还是有可用的 Buffer 可以向其申请。</p>
<p><img src="_v_images/20200714171445992_941635712"></p>
<p>一段时间后，发现 Network BufferPool 没有可用的 Buffer，或是 Local BufferPool 的最大可用 Buffer 到了上限无法向 Network BufferPool 申请，没有办法去读取新的数据，这时 Netty AutoRead 就会被禁掉，Netty 就不会从 Socket 的 Buffer 中读取数据了。</p>
<p><img src="_v_images/20200714171444186_160162504"></p>
<p>显然，再过不久 Socket 的 Buffer 也被用尽，这时就会将 Window = 0 发送给发送端（前文提到的 TCP 滑动窗口的机制）。这时发送端的 Socket 就会停止发送。</p>
<p><img src="_v_images/20200714171443780_1304730499"></p>
<p>很快发送端的 Socket 的 Buffer 也被用尽，Netty 检测到 Socket 无法写了之后就会停止向 Socket 写数据。</p>
<p><img src="_v_images/20200714171443573_720011262"></p>
<p>Netty 停止写了之后，所有的数据就会阻塞在 Netty 的 Buffer 当中了，但是 Netty 的 Buffer 是无界的，可以通过 Netty 的水位机制中的 high watermark 控制他的上界。当超过了 high watermark，Netty 就会将其 channel 置为不可写，ResultSubPartition 在写之前都会检测 Netty 是否可写，发现不可写就会停止向 Netty 写数据。</p>
<p><img src="_v_images/20200714171443267_566801867"></p>
<p>这时候所有的压力都来到了 ResultSubPartition，和接收端一样他会不断的向 Local BufferPool 和 Network BufferPool 申请内存。</p>
<p><img src="_v_images/20200714171442761_1041985779"></p>
<p>Local BufferPool 和 Network BufferPool 都用尽后整个 Operator 就会停止写数据，达到跨 TaskManager 的反压。</p>
<h3 id="TaskManager-内反压过程"><a href="#TaskManager-内反压过程" class="headerlink" title="TaskManager 内反压过程"></a>TaskManager 内反压过程</h3><p>了解了跨 TaskManager 反压过程后再来看 TaskManager 内反压过程就更好理解了，下游的 TaskManager 反压导致本 TaskManager 的 ResultSubPartition 无法继续写入数据，于是 Record Writer 的写也被阻塞住了，因为 Operator 需要有输入才能有计算后的输出，输入跟输出都是在同一线程执行， Record Writer 阻塞了，Record Reader 也停止从 InputChannel 读数据，这时上游的 TaskManager 还在不断地发送数据，最终将这个 TaskManager 的 Buffer 耗尽。具体流程可以参考下图，这就是 TaskManager 内的反压过程。</p>
<p><img src="_v_images/20200714171442455_926070537"></p>
<p><img src="_v_images/20200714171442149_493428448"></p>
<p><img src="_v_images/20200714171441744_1291490922"></p>
<p><img src="_v_images/20200714171441439_2105575637"></p>
<h2 id="Flink-Credit-based-反压机制（since-V1-5）"><a href="#Flink-Credit-based-反压机制（since-V1-5）" class="headerlink" title="Flink Credit-based 反压机制（since V1.5）"></a>Flink Credit-based 反压机制（since V1.5）</h2><h3 id="TCP-based-反压的弊端"><a href="#TCP-based-反压的弊端" class="headerlink" title="TCP-based 反压的弊端"></a>TCP-based 反压的弊端</h3><p><img src="_v_images/20200714171441134_1354461165"></p>
<p>在介绍 Credit-based 反压机制之前，先分析下 TCP 反压有哪些弊端。</p>
<ul>
<li><p>在一个 TaskManager 中可能要执行多个 Task，如果多个 Task 的数据最终都要传输到下游的同一个 TaskManager 就会复用同一个 Socket 进行传输，这个时候如果单个 Task 产生反压，就会导致复用的 Socket 阻塞，其余的 Task 也无法使用传输，checkpoint barrier 也无法发出导致下游执行 checkpoint 的延迟增大。</p>
</li>
<li><p>依赖最底层的 TCP 去做流控，会导致反压传播路径太长，导致生效的延迟比较大。</p>
</li>
</ul>
<h3 id="引入-Credit-based-反压"><a href="#引入-Credit-based-反压" class="headerlink" title="引入 Credit-based 反压"></a>引入 Credit-based 反压</h3><p>这个机制简单的理解起来就是在 Flink 层面实现类似 TCP 流控的反压机制来解决上述的弊端，Credit 可以类比为 TCP 的 Window 机制。</p>
<h3 id="Credit-based-反压过程"><a href="#Credit-based-反压过程" class="headerlink" title="Credit-based 反压过程"></a>Credit-based 反压过程</h3><p><img src="_v_images/20200714171440828_629774125"></p>
<p>如图所示在 Flink 层面实现反压机制，就是每一次 ResultSubPartition 向 InputChannel 发送消息的时候都会发送一个 backlog size 告诉下游准备发送多少消息，下游就会去计算有多少的 Buffer 去接收消息，算完之后如果有充足的 Buffer 就会返还给上游一个 Credit 告知他可以发送消息（图上两个 ResultSubPartition 和 InputChannel 之间是虚线是因为最终还是要通过 Netty 和 Socket 去通信），下面我们看一个具体示例。</p>
<p><img src="_v_images/20200714171440422_2073806088"></p>
<p>假设我们上下游的速度不匹配，上游发送速率为 2，下游接收速率为 1，可以看到图上在 ResultSubPartition 中累积了两条消息，10 和 11， backlog 就为 2，这时就会将发送的数据 &lt;8,9&gt; 和 backlog = 2 一同发送给下游。下游收到了之后就会去计算是否有 2 个 Buffer 去接收，可以看到 InputChannel 中已经不足了这时就会从 Local BufferPool 和 Network BufferPool 申请，好在这个时候 Buffer 还是可以申请到的。</p>
<p><img src="_v_images/20200714171440216_190878629"></p>
<p>过了一段时间后由于上游的发送速率要大于下游的接受速率，下游的 TaskManager 的 Buffer 已经到达了申请上限，这时候下游就会向上游返回 Credit = 0，ResultSubPartition 接收到之后就不会向 Netty 去传输数据，上游 TaskManager 的 Buffer 也很快耗尽，达到反压的效果，这样在 ResultSubPartition 层就能感知到反压，不用通过 Socket 和 Netty 一层层地向上反馈，降低了反压生效的延迟。同时也不会将 Socket 去阻塞，解决了由于一个 Task 反压导致 TaskManager 和 TaskManager 之间的 Socket 阻塞的问题。</p>
<h2 id="总结与思考"><a href="#总结与思考" class="headerlink" title="总结与思考"></a>总结与思考</h2><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><p>网络流控是为了在上下游速度不匹配的情况下，防止下游出现过载</p>
</li>
<li><p>网络流控有静态限速和动态反压两种手段</p>
</li>
<li><p>Flink 1.5 之前是基于 TCP 流控 + bounded buffer 实现反压</p>
</li>
<li><p>Flink 1.5 之后实现了自己托管的 credit - based 流控机制，在应用层模拟 TCP 的流控机制</p>
</li>
</ul>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>有了动态反压，静态限速是不是完全没有作用了？</p>
<p><img src="_v_images/20200714171439509_423419298"></p>
<p>实际上动态反压不是万能的，我们流计算的结果最终是要输出到一个外部的存储（Storage），外部数据存储到 Sink 端的反压是不一定会触发的，这要取决于外部存储的实现，像 Kafka 这样是实现了限流限速的消息中间件可以通过协议将反压反馈给 Sink 端，但是像 ES 无法将反压进行传播反馈给 Sink 端，这种情况下为了防止外部存储在大的数据量下被打爆，我们就可以通过静态限速的方式在 Source 端去做限流。所以说动态反压并不能完全替代静态限速的，需要根据合适的场景去选择处理方案。</p>
<p>作者：阿里云云栖号<br>链接：<a href="https://juejin.im/post/5dce4b265188254a2b1faddf">https://juejin.im/post/5dce4b265188254a2b1faddf</a><br>来源：掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/Flink-backpress/</url>
    <content><![CDATA[<h1 id="实时流处理系统反压机制（BackPressure）综述-转"><a href="#实时流处理系统反压机制（BackPressure）综述-转" class="headerlink" title="实时流处理系统反压机制（BackPressure）综述[转]"></a>实时流处理系统反压机制（BackPressure）综述[转]</h1><p> 发表于 2018-11-15 |  更新于 2018-12-03 |  分类于 <a href="http://ileaf.tech/category/#/BigData">BigData </a>|  阅读次数 333</p>
<p>本文主要关于实时流处理系统反压机制，最近看到反压问题看到此文章很好，在此分享并mark一下。</p>
<blockquote>
<p>本文主要关于实时流处理系统反压机制，最近看到反压问题看到此文章很好，在此分享并mark一下。<br>(￢_￢)ﾉ最近菜叶子没自己写见谅。<br>本文转自 <a href="https://blog.csdn.net/qq_21125183/article/details/80708142">实时流处理系统反压机制（BackPressure）综述</a><br><a href="https://blog.csdn.net/qq_21125183/article/details/80708142">https://blog.csdn.net/qq_21125183/article/details/80708142</a><br><a href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a></p>
</blockquote>
<p>反压机制（BackPressure）被广泛应用到实时流处理系统中，流处理系统需要能优雅地处理反压（backpressure）问题。<br>反压通常产生于这样的场景：短时负载高峰导致系统接收数据的速率远高于它处理数据的速率。<br>许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或者遇到大促或秒杀活动导致流量陡增。<br>反压如果不能得到正确的处理，可能会导致资源耗尽甚至系统崩溃。反压机制就是指系统能够自己检测到被阻塞的Operator，然后系统自适应地降低源头或者上游的发送速率。</p>
<p>目前主流的流处理系统 Apache Storm、JStorm、Spark Streaming、S4、Apache Flink、Twitter Heron都采用反压机制解决这个问题，不过他们的实现各自不同。</p>
<p><img src="_v_images/20201030212807758_57452691.png" alt="实时流处理系统反压机制01"></p>
<p>不同的组件可以不同的速度执行（并且每个组件中的处理速度随时间改变）。 例如，考虑一个工作流程，或由于数据倾斜或任务调度而导致数据被处理十分缓慢。<br>在这种情况下，如果上游阶段不减速，将导致缓冲区建立长队列(队列占用内存、硬盘空间，节点负载加重)，或导致系统丢弃元组。<br>如果元组在中途丢弃，那么效率可能会有损失，因为已经为这些元组产生的计算被浪费了。<br>并且在一些流处理系统中比如Strom，会将这些丢失的元组重新发送，这样会导致数据的一致性问题(at least once语义)，并且还会导致某些Operator状态叠加。<br>进而整个程序输出结果不准确。第二由于系统接收数据的速率是随着时间改变的，短时负载高峰导致系统接收数据的速率远高于它处理数据的速率的情况，也会导致Tuple在中途丢失。<br>所以实时流处理系统必须能够解决发送速率远大于系统能处理速率这个问题，大多数实时流处理系统采用反压（BackPressure）机制解决这个问题。</p>
<p>下面我们就来介绍一下不同的实时流处理系统采用的反压机制：</p>
<h1 id="Strom-反压机制"><a href="#Strom-反压机制" class="headerlink" title="Strom 反压机制"></a>Strom 反压机制</h1><h2 id="Storm-1-0-以前的反压机制"><a href="#Storm-1-0-以前的反压机制" class="headerlink" title="Storm 1.0 以前的反压机制"></a>Storm 1.0 以前的反压机制</h2><p>对于开启了acker机制的storm程序，可以通过设置conf.setMaxSpoutPending参数来实现反压效果，<strong>如果下游组件(bolt)处理速度跟不上导致spout发送的tuple没有及时确认的数超过了参数设定的值，spout会停止发送数据</strong>，这种方式的缺点是很难调优conf.setMaxSpoutPending参数的设置以达到最好的反压效果，设小了会导致吞吐上不去，设大了会导致worker OOM；有震荡，数据流会处于一个颠簸状态，效果不如逐级反压；另外对于关闭acker机制的程序无效；</p>
<h2 id="Storm-Automatic-Backpressure"><a href="#Storm-Automatic-Backpressure" class="headerlink" title="Storm Automatic Backpressure"></a>Storm Automatic Backpressure</h2><p>新的storm自动反压机制(Automatic Back Pressure)通过监控bolt中的接收队列的情况，当超过高水位值时专门的线程会将反压信息写到 Zookeeper ，Zookeeper上的watch会通知该拓扑的所有Worker都进入反压状态，最后Spout降低tuple发送的速度。</p>
<p><img src="_v_images/20201030212806451_178512803.png" alt="实时流处理系统反压机制02"></p>
<p>每个Executor都有一个接受队列和发送队列用来接收Tuple和发送Spout或者Bolt生成的Tuple元组。每个Worker进程都有一个单的的接收线程监听接收端口。<br>它从每个网络上进来的消息发送到Executor的接收队列中。Executor接收队列存放Worker或者Worker内部其他Executor发过来的消息。<br>Executor工作线程从接收队列中拿出数据，然后调用execute方法，发送Tuple到Executor的发送队列。<br>Executor的发送线程从发送队列中获取消息，按照消息目的地址选择发送到Worker的传输队列中或者其他Executor的接收队列中。<br>最后Worker的发送线程从传输队列中读取消息，然后将Tuple元组发送到网络中。</p>
<ol>
<li>当Worker进程中的Executor线程发现自己的接收队列满了时，也就是接收队列达到<code>high watermark</code>的阈值后，因此它会发送通知消息到背压线程。</li>
<li>背压线程将当前worker进程的信息注册到Zookeeper的Znode节点中。具体路径就是 <code>/Backpressure/topo1/wk1</code>下</li>
<li>Zookeepre的Znode Watcher监视/Backpreesure/topo1下的节点目录变化情况，如果发现目录增加了znode节点说明或者其他变化。这就说明该Topo1需要反压控制，然后它会通知Topo1所有的Worker进入反压状态。</li>
<li>最终Spout降低tuple发送的速度。</li>
</ol>
<h1 id="JStorm-反压机制"><a href="#JStorm-反压机制" class="headerlink" title="JStorm 反压机制"></a>JStorm 反压机制</h1><p>JStorm做了两级的反压，第一级和Jstorm类似，通过执行队列来监测，但是不会通过ZK来协调，而是通过Topology Master来协调。<br>在队列中会标记high water mark和low water mark，当执行队列超过high water mark时，就认为bolt来不及处理，则向TM发一条控制消息，上游开始减慢发送速率，直到下游低于low water mark时解除反压。</p>
<p>此外，在Netty层也做了一级反压，由于每个Worker Task都有自己的发送和接收的缓冲区，可以对缓冲区设定限额、控制大小，如果spout数据量特别大，缓冲区填满会导致下游bolt的接收缓冲区填满，造成了反压。</p>
<p><img src="_v_images/20201030212805000_1695102842.png" alt="实时流处理系统反压机制03"></p>
<p>限流机制：jstorm的限流机制， 当下游bolt发生阻塞时， 并且阻塞task的比例超过某个比例时（现在默认设置为0.1），触发反压</p>
<p>限流方式：计算阻塞Task的地方执行线程执行时间，Spout每发送一个tuple等待相应时间，然后讲这个时间发送给Spout， 于是， spout每发送一个tuple，就会等待这个执行时间。</p>
<p>Task阻塞判断方式：在jstorm 连续4次采样周期中采样，队列情况，当队列超过80%（可以设置）时，即可认为该task处在阻塞状态。</p>
<h1 id="SparkStreaming-反压机制"><a href="#SparkStreaming-反压机制" class="headerlink" title="SparkStreaming 反压机制"></a>SparkStreaming 反压机制</h1><h2 id="为什么引入反压机制Backpressure"><a href="#为什么引入反压机制Backpressure" class="headerlink" title="为什么引入反压机制Backpressure"></a>为什么引入反压机制Backpressure</h2><p>默认情况下，Spark Streaming通过Receiver以生产者生产数据的速率接收数据，计算过程中会出现<code>batch processing time &gt; batch interval</code>的情况，其中<code>batch processing time</code> 为实际计算一个批次花费时间， <code>batch interval</code>为Streaming应用设置的批处理间隔。<br>这意味着Spark Streaming的数据接收速率高于Spark从队列中移除数据的速率，也就是数据处理能力低，在设置间隔内不能完全处理当前接收速率接收的数据。如果这种情况持续过长的时间，会造成数据在内存中堆积，导致Receiver所在Executor内存溢出等问题（如果设置StorageLevel包含disk, 则内存存放不下的数据会溢写至disk, 加大延迟）。<br>Spark 1.5以前版本，用户如果要限制Receiver的数据接收速率，可以通过设置静态配制参数“<code>spark.streaming.receiver.maxRate</code>”的值来实现，此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer数据生产高于maxRate，当前集群处理能力也高于maxRate，这就会造成资源利用率下降等问题。为了更好的协调数据接收速率与资源处理能力，Spark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。</p>
<h2 id="反压机制Backpressure"><a href="#反压机制Backpressure" class="headerlink" title="反压机制Backpressure"></a>反压机制Backpressure</h2><p><code>Spark Streaming Backpressure</code>: 根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。通过属性“spark.streaming.backpressure.enabled”来控制是否启用backpressure机制，默认值false，即不启用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">sparkConf.set(<span class="string">&quot;spark.streaming.backpressure.enabled&quot;</span>,”<span class="keyword">true</span>”)</span><br></pre></td></tr></table></figure>
<p>SparkStreaming 架构图如下所示:</p>
<p><img src="_v_images/20201030212803393_1135733829.png" alt="实时流处理系统反压机制04"></p>
<p>SparkStreaming 反压过程执行如下图所示：</p>
<p>在原架构的基础上加上一个新的组件RateController,这个组件负责监听“OnBatchCompleted”事件，然后从中抽取<code>processingDelay</code> 及<code>schedulingDelay</code>信息. <code>Estimator</code>依据这些信息估算出最大处理速度（rate），最后由基于<code>Receiver</code>的Input Stream将rate通过ReceiverTracker与ReceiverSupervisorImpl转发给BlockGenerator（继承自RateLimiter）.</p>
<p><img src="_v_images/20201030212801986_428923565.png" alt="实时流处理系统反压机制05"></p>
<h2 id="direct模式-BackPressure-此部分详细说明了direct模式接收：转自-开启Back-Pressure使生产环境的Spark-Streaming应用更稳定、有效"><a href="#direct模式-BackPressure-此部分详细说明了direct模式接收：转自-开启Back-Pressure使生产环境的Spark-Streaming应用更稳定、有效" class="headerlink" title="direct模式-BackPressure(此部分详细说明了direct模式接收：转自-开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效)"></a>direct模式-BackPressure(此部分详细说明了direct模式接收：转自-<a href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a>)</h2><p>当Spark Streaming与Kafka使用Direct API集群时，我们可以很方便的去控制最大数据摄入量–通过一个被称作spark.streaming.kafka.maxRatePerPartition的参数。根据文档描述，他的含义是：Direct API读取每一个Kafka partition数据的最大速率（每秒读取的消息量）。<br>配置项spark.streaming.kafka.maxRatePerPartition，对防止流式应用在下边两种情况下出现流量过载时尤其重要：<br>1.Kafka Topic中有大量未处理的消息，并且我们设置是Kafka auto.offset.reset参数值为smallest，他可以防止第一个批次出现数据流量过载情况。<br>2.当Kafka 生产者突然飙升流量的时候，他可以防止批次处理出现数据流量过载情况。</p>
<p>但是，配置Kafka每个partition每批次最大的摄入量是个静态值，也算是个缺点。随着时间的变化，在生产环境运行了一段时间的Spark Streaming应用，每批次每个Kafka partition摄入数据最大量的最优值也是变化的。有时候，是因为消息的大小会变，导致数据处理时间变化。有时候，是因为流计算所使用的多租户集群会变得非常繁忙，比如在白天时候，一些其他的数据应用（例如Impala/Hive/MR作业）竞争共享的系统资源时（CPU/内存/网络/磁盘IO）。<br>背压机制可以解决该问题。背压机制是呼声比较高的功能，他允许根据前一批次数据的处理情况，动态、自动的调整后续数据的摄入量，这样的反馈回路使得我们可以应对流式应用流量波动的问题。<br>Spark Streaming的背压机制是在Spark1.5版本引进的，我们可以添加如下代码启用改功能：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sparkConf.set(&quot;spark.streaming.backpressure.enabled&quot;,”true”)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>那应用启动后的第一个批次流量怎么控制呢？因为他没有前面批次的数据处理时间，所以没有参考的数据去评估这一批次最优的摄入量。在Spark官方文档中有个被称作spark.streaming.backpressure.initialRate的配置，看起来是控制开启背压机制时初始化的摄入量。其实不然，该参数只对receiver模式起作用，并不适用于direct模式。推荐的方法是使用spark.streaming.kafka.maxRatePerPartition控制背压机制起作用前的第一批次数据的最大摄入量。我通常建议设置spark.streaming.kafka.maxRatePerPartition的值为最优估计值的1.5到2倍，让背压机制的算法去调整后续的值。请注意，spark.streaming.kafka.maxRatePerPartition的值会一直控制最大的摄入量，所以背压机制的算法值不会超过他。<br>另一个需要注意的是，在第一个批次处理完成前，紧接着的批次都将使用spark.streaming.kafka.maxRatePerPartition的值作为摄入量。通过Spark UI可以看到，批次间隔为5s，当批次调度延迟31秒时候，前7个批次的摄入量是20条记录。直到第八个批次，背压机制起作用时，摄入量变为5条记录。</p>
<h1 id="Heron-反压机制"><a href="#Heron-反压机制" class="headerlink" title="Heron 反压机制"></a>Heron 反压机制</h1><p><img src="_v_images/20201030212800445_1650579597.png" alt="实时流处理系统反压机制06"></p>
<p>当下游处理速度跟不上上游发送速度时，一旦StreamManager 发现一个或多个Heron Instance 速度变慢，立刻对本地spout进行降级，降低本地Spout发送速度, 停止从这些spout读取数据。并且受影响的StreamManager 会发送一个特殊的start backpressure message 给其他的StreamManager ，要求他们对spout进行本地降级。 当其他StreamManager 接收到这个特殊消息时，他们通过不读取当地Spout中的Tuple来进行降级。一旦出问题的Heron Instance 恢复速度后，本地的SM 会发送stop backpressure message 解除降级。</p>
<p>很多Socket Channel与应用程序级别的Buffer相关联，该缓冲区由high watermark 和low watermark组成。 当缓冲区大小达到high watermark时触发反压，并保持有效，直到缓冲区大小低于low watermark。 此设计的基本原理是防止拓扑在进入和退出背压缓解模式之间快速振荡。</p>
<h1 id="Flink-反压机制"><a href="#Flink-反压机制" class="headerlink" title="Flink 反压机制"></a>Flink 反压机制</h1><p>Flink 没有使用任何复杂的机制来解决反压问题，因为根本不需要那样的方案！它利用自身作为纯数据流引擎的优势来优雅地响应反压问题。下面我们会深入分析 Flink 是如何在 Task 之间传输数据的，以及数据流如何实现自然降速的。 Flink 在运行时主要由 operators 和 streams 两大组件构成。每个 operator 会消费中间态的流，并在流上进行转换，然后生成新的流。对于 Flink 的网络机制一种形象的类比是，Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。还记得经典的线程间通信案例：生产者消费者模型吗？使用 BlockingQueue 的话，一个较慢的接受者会降低发送者的发送速率，因为一旦队列满了（有界队列）发送者会被阻塞。Flink 解决反压的方案就是这种感觉。 在 Flink 中，这些分布式阻塞队列就是这些逻辑流，而队列容量是通过缓冲池来（LocalBufferPool）实现的。每个被生产和被消费的流都会被分配一个缓冲池。缓冲池管理着一组缓冲(Buffer)，缓冲在被消费后可以被回收循环利用。这很好理解：你从池子中拿走一个缓冲，填上数据，在数据消费完之后，又把缓冲还给池子，之后你可以再次使用它。</p>
<h2 id="Flink-网络传输中的内存管理"><a href="#Flink-网络传输中的内存管理" class="headerlink" title="Flink 网络传输中的内存管理"></a>Flink 网络传输中的内存管理</h2><p>如下图所示展示了 Flink 在网络传输场景下的内存管理。网络上传输的数据会写到 Task 的 InputGate（IG） 中，经过 Task 的处理后，再由 Task 写到 ResultPartition（RS） 中。每个 Task 都包括了输入和输入，输入和输出的数据存在 Buffer 中（都是字节数据）。Buffer 是 MemorySegment 的包装类。</p>
<p><img src="_v_images/20201030212758832_1369878662.png" alt="实时流处理系统反压机制07"></p>
<ol>
<li>TaskManager（TM）在启动时，会先初始化NetworkEnvironment对象，TM 中所有与网络相关的东西都由该类来管理（如 Netty 连接），其中就包括NetworkBufferPool。根据配置，Flink 会在 NetworkBufferPool 中生成一定数量（默认2048个）的内存块 MemorySegment（关于 Flink 的内存管理，后续文章会详细谈到），内存块的总数量就代表了网络传输中所有可用的内存。NetworkEnvironment 和 NetworkBufferPool 是 Task 之间共享的，每个 TM 只会实例化一个。</li>
<li>Task 线程启动时，会向 NetworkEnvironment 注册，NetworkEnvironment 会为 Task 的 InputGate（IG）和 ResultPartition（RP） 分别创建一个 LocalBufferPool（缓冲池）并设置可申请的 MemorySegment（内存块）数量。IG 对应的缓冲池初始的内存块数量与 IG 中 InputChannel 数量一致，RP 对应的缓冲池初始的内存块数量与 RP 中的 ResultSubpartition 数量一致。不过，每当创建或销毁缓冲池时，NetworkBufferPool 会计算剩余空闲的内存块数量，并平均分配给已创建的缓冲池。注意，这个过程只是指定了缓冲池所能使用的内存块数量，并没有真正分配内存块，只有当需要时才分配。为什么要动态地为缓冲池扩容呢？因为内存越多，意味着系统可以更轻松地应对瞬时压力（如GC），不会频繁地进入反压状态，所以我们要利用起那部分闲置的内存块。</li>
<li>在 Task 线程执行过程中，当 Netty 接收端收到数据时，为了将 Netty 中的数据拷贝到 Task 中，InputChannel（实际是 RemoteInputChannel）会向其对应的缓冲池申请内存块（上图中的①）。如果缓冲池中也没有可用的内存块且已申请的数量还没到池子上限，则会向 NetworkBufferPool 申请内存块（上图中的②）并交给 InputChannel 填上数据（上图中的③和④）。如果缓冲池已申请的数量达到上限了呢？或者 NetworkBufferPool 也没有可用内存块了呢？这时候，Task 的 Netty Channel 会暂停读取，上游的发送端会立即响应停止发送，拓扑会进入反压状态。当 Task 线程写数据到 ResultPartition 时，也会向缓冲池请求内存块，如果没有可用内存块时，会阻塞在请求内存块的地方，达到暂停写入的目的。</li>
<li>当一个内存块被消费完成之后（在输入端是指内存块中的字节被反序列化成对象了，在输出端是指内存块中的字节写入到 Netty Channel 了），会调用 Buffer.recycle() 方法，会将内存块还给 LocalBufferPool （上图中的⑤）。如果LocalBufferPool中当前申请的数量超过了池子容量（由于上文提到的动态容量，由于新注册的 Task 导致该池子容量变小），则LocalBufferPool会将该内存块回收给 NetworkBufferPool（上图中的⑥）。如果没超过池子容量，则会继续留在池子中，减少反复申请的开销。</li>
</ol>
<h2 id="Flink-反压机制-1"><a href="#Flink-反压机制-1" class="headerlink" title="Flink 反压机制"></a>Flink 反压机制</h2><p>下面这张图简单展示了两个 Task 之间的数据传输以及 Flink 如何感知到反压的：</p>
<p><img src="_v_images/20201030212757424_78076714.png" alt="实时流处理系统反压机制08"></p>
<ol>
<li>记录“A”进入了 Flink 并且被 Task 1 处理。（这里省略了 Netty 接收、反序列化等过程）</li>
<li>记录被序列化到 buffer 中。</li>
<li>该 buffer 被发送到 Task 2，然后 Task 2 从这个 buffer 中读出记录。</li>
</ol>
<p><strong>不要忘了：记录能被 Flink 处理的前提是，必须有空闲可用的 Buffer。</strong></p>
<p>结合上面两张图看：Task 1 在输出端有一个相关联的 LocalBufferPool（称缓冲池1），Task 2 在输入端也有一个相关联的 LocalBufferPool（称缓冲池2）。如果缓冲池1中有空闲可用的 buffer 来序列化记录 “A”，我们就序列化并发送该 buffer。</p>
<p>这里我们需要注意两个场景：</p>
<ul>
<li>本地传输：如果 Task 1 和 Task 2 运行在同一个 worker 节点（TaskManager），该 buffer 可以直接交给下一个 Task。一旦 Task 2 消费了该 buffer，则该 buffer 会被缓冲池1回收。如果 Task 2 的速度比 1 慢，那么 buffer 回收的速度就会赶不上 Task 1 取 buffer 的速度，导致缓冲池1无可用的 buffer，Task 1 等待在可用的 buffer 上。最终形成 Task 1 的降速。</li>
<li>远程传输：如果 Task 1 和 Task 2 运行在不同的 worker 节点上，那么 buffer 会在发送到网络（TCP Channel）后被回收。在接收端，会从 LocalBufferPool 中申请 buffer，然后拷贝网络中的数据到 buffer 中。如果没有可用的 buffer，会停止从 TCP 连接中读取数据。在输出端，通过 Netty 的水位值机制来保证不往网络中写入太多数据（后面会说）。如果网络中的数据（Netty输出缓冲中的字节数）超过了高水位值，我们会等到其降到低水位值以下才继续写入数据。这保证了网络中不会有太多的数据。如果接收端停止消费网络中的数据（由于接收端缓冲池没有可用 buffer），网络中的缓冲数据就会堆积，那么发送端也会暂停发送。另外，这会使得发送端的缓冲池得不到回收，writer 阻塞在向 LocalBufferPool 请求 buffer，阻塞了 writer 往 ResultSubPartition 写数据。</li>
</ul>
<p>这种固定大小缓冲池就像阻塞队列一样，保证了 Flink 有一套健壮的反压机制，使得 Task 生产数据的速度不会快于消费的速度。我们上面描述的这个方案可以从两个 Task 之间的数据传输自然地扩展到更复杂的 pipeline 中，保证反压机制可以扩散到整个 pipeline。</p>
<h2 id="反压实验"><a href="#反压实验" class="headerlink" title="反压实验"></a>反压实验</h2><p>另外，官方博客中为了展示反压的效果，给出了一个简单的实验。下面这张图显示了：随着时间的改变，生产者（黄色线）和消费者（绿色线）每5秒的平均吞吐与最大吞吐（在单一JVM中每秒达到8百万条记录）的百分比。我们通过衡量task每5秒钟处理的记录数来衡量平均吞吐。该实验运行在单 JVM 中，不过使用了完整的 Flink 功能栈。</p>
<p><img src="_v_images/20201030212755917_1236027751.png" alt="实时流处理系统反压机制09"></p>
<p>首先，我们运行生产task到它最大生产速度的60%（我们通过Thread.sleep()来模拟降速）。消费者以同样的速度处理数据。然后，我们将消费task的速度降至其最高速度的30%。你就会看到背压问题产生了，正如我们所见，生产者的速度也自然降至其最高速度的30%。接着，停止消费task的人为降速，之后生产者和消费者task都达到了其最大的吞吐。接下来，我们再次将消费者的速度降至30%，pipeline给出了立即响应：生产者的速度也被自动降至30%。最后，我们再次停止限速，两个task也再次恢复100%的速度。总而言之，我们可以看到：生产者和消费者在 pipeline 中的处理都在跟随彼此的吞吐而进行适当的调整，这就是我们希望看到的反压的效果。</p>
<h2 id="Flink-反压监控"><a href="#Flink-反压监控" class="headerlink" title="Flink 反压监控"></a>Flink 反压监控</h2><p>在 Storm/JStorm 中，只要监控到队列满了，就可以记录下拓扑进入反压了。但是 Flink 的反压太过于天然了，导致我们无法简单地通过监控队列来监控反压状态。Flink 在这里使用了一个 trick 来实现对反压的监控。如果一个 Task 因为反压而降速了，那么它会卡在向 LocalBufferPool 申请内存块上。那么这时候，该 Task 的 stack trace 就会长下面这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.Object.wait(Native Method)</span><br><span class="line">o.a.f.[...].LocalBufferPool.requestBuffer(LocalBufferPool.java:<span class="number">163</span>)</span><br><span class="line">o.a.f.[...].LocalBufferPool.requestBufferBlocking(LocalBufferPool.java:<span class="number">133</span>) &lt;--- BLOCKING request</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure>
<p>那么事情就简单了。通过不断地采样每个 task 的 stack trace 就可以实现反压监控。</p>
<p><img src="_v_images/20201030212753993_1098219801.png" alt="实时流处理系统反压机制10"></p>
<p>Flink 的实现中，只有当 Web 页面切换到某个 Job 的 Backpressure 页面，才会对这个 Job 触发反压检测，因为反压检测还是挺昂贵的。JobManager 会通过 Akka 给每个 TaskManager 发送TriggerStackTraceSample消息。默认情况下，TaskManager 会触发100次 stack trace 采样，每次间隔 50ms（也就是说一次反压检测至少要等待5秒钟）。并将这 100 次采样的结果返回给 JobManager，由 JobManager 来计算反压比率（反压出现的次数/采样的次数），最终展现在 UI 上。UI 刷新的默认周期是一分钟，目的是不对 TaskManager 造成太大的负担。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Flink不需要一种特殊的机制来处理反压，因为Flink 中的数据传输相当于已经提供了应对反压的机制。因此，Flink 所能获得的最大吞吐量由其 pipeline 中最慢的组件决定。相对于 Storm/JStorm 的实现，Flink 的实现更为简洁优雅，源码中也看不见与反压相关的代码，无需 Zookeeper/TopologyMaster 的参与也降低了系统的负载，也利于对反压更迅速的响应。</p>
<blockquote>
<p>本文转自 <a href="https://blog.csdn.net/qq_21125183/article/details/80708142">实时流处理系统反压机制（BackPressure）综述</a><br><a href="https://blog.csdn.net/qq_21125183/article/details/80708142">https://blog.csdn.net/qq_21125183/article/details/80708142</a><br><a href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a></p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>Flink核心知识点梳理</title>
    <url>/bigdata/Flink/Flink-base/</url>
    <content><![CDATA[<h1 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h1><p><img src="_v_images/flink-structure.svg" alt="The processes involved in executing a Flink dataflow"></p>
<h2 id="stateful-stream-processing"><a href="#stateful-stream-processing" class="headerlink" title="stateful stream processing"></a>stateful stream processing</h2><p>processFunction</p>
<p>低阶API<br>构建一些新的组件<br>比如 利用定时做一定情况下的匹配和缓存<br>灵活，开发比较复杂</p>
<p>凌晨更新  注册定时器 </p>
<h2 id="state"><a href="#state" class="headerlink" title="state"></a>state</h2><p>状态托管<br>operator state 算子状态<br>keyed state<br>State Backend (rocksdb + hdfs)</p>
<h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>barrier</p>
<h2 id="DataStream-广播"><a href="#DataStream-广播" class="headerlink" title="DataStream 广播"></a>DataStream 广播</h2><h2 id="CoLocationGroup"><a href="#CoLocationGroup" class="headerlink" title="CoLocationGroup"></a>CoLocationGroup</h2><h2 id="SlotSharingGroup"><a href="#SlotSharingGroup" class="headerlink" title="SlotSharingGroup"></a>SlotSharingGroup</h2><h3 id="如何自定义-Window？"><a href="#如何自定义-Window？" class="headerlink" title="如何自定义 Window？"></a>如何自定义 Window？</h3><p>1、Window Assigner</p>
<p>负责将元素分配到不同的 window。</p>
<p>Window API 提供了自定义的 WindowAssigner 接口，我们可以实现 WindowAssigner 的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public abstract Collection&lt;W&gt; assignWindows(T element, long timestamp)</span><br></pre></td></tr></table></figure>
<p>方法。同时，对于基于 Count 的 window 而言，默认采用了 GlobalWindow 的 window assigner，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">keyBy.window(GlobalWindows.create())</span><br></pre></td></tr></table></figure>
<p>2、Trigger</p>
<p>Trigger 即触发器，定义何时或什么情况下移除 window</p>
<p>我们可以指定触发器来覆盖 WindowAssigner 提供的默认触发器。 请注意，指定的触发器不会添加其他触发条件，但会替换当前触发器。</p>
<p>3、Evictor（可选）</p>
<p>驱逐者，即保留上一 window 留下的某些元素</p>
<p>4、通过 apply WindowFunction 来返回 DataStream 类型数据。</p>
<p>利用 Flink 的内部窗口机制和 DataStream API 可以实现自定义的窗口逻辑，例如 session window。</p>
<h3 id="EventTime-amp-ProcessTime-amp-IngestionTime"><a href="#EventTime-amp-ProcessTime-amp-IngestionTime" class="headerlink" title="EventTime &amp; ProcessTime &amp; IngestionTime"></a>EventTime &amp; ProcessTime &amp; IngestionTime</h3><p> Event time programs must specify how to generate <em>Event Time Watermarks</em>, which is the mechanism that signals progress in event time</p>
<p>Internally, <em>ingestion time</em> is treated much like <em>event time</em>, but with automatic timestamp assignment and automatic watermark generation.</p>
<h2 id="watermark"><a href="#watermark" class="headerlink" title="watermark"></a>watermark</h2><p>kafka的每个分区event-time到来的时间不一致</p>
<p>using Flink’s Kafka-partition-aware watermark generation. watermarks are generated inside the Kafka consumer, per Kafka partition, and the per-partition watermarks are merged in the same way as watermarks are merged on stream shuffles.</p>
<p>watermark在每个kafka分区的kafka消费者中产生，每个分区的watermark合并起来，如在stream shuffle中合并watermark一样</p>
<h2 id="HadoopOutputFormat"><a href="#HadoopOutputFormat" class="headerlink" title="HadoopOutputFormat"></a>HadoopOutputFormat</h2><p>flink hbase connector</p>
<h2 id="算子之间数据传递，是如何序列化的"><a href="#算子之间数据传递，是如何序列化的" class="headerlink" title="算子之间数据传递，是如何序列化的"></a>算子之间数据传递，是如何序列化的</h2>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink-checkpoint与数据一致性</title>
    <url>/bigdata/Flink/Flink-checkpoint-savepoint-2pc/</url>
    <content><![CDATA[<h1 id="1-Flink-checkpoint-与-高可用"><a href="#1-Flink-checkpoint-与-高可用" class="headerlink" title="1. Flink checkpoint 与 高可用"></a>1. Flink checkpoint 与 高可用</h1><p>Flink Checkpoint 受 Chandy-Lamport 分布式快照启发，可以保证数据的高可用。但是有些情况下，不见得一定有效:</p>
<p>Flink On Yarn 模式，某个 Container 发生 OOM 异常，这种情况程序直接变成失败状态，此时 Flink 程序虽然开启 Checkpoint 也无法恢复，因为程序已经变成失败状态，所以此时可以借助外部参与启动程序，比如外部程序检测到实时任务失败时，从新对实时任务进行拉起。</p>
<h2 id="1-1-2PC"><a href="#1-1-2PC" class="headerlink" title="1.1. 2PC"></a>1.1. 2PC</h2><h3 id="1-1-1-Exactly-once-VS-At-least-once"><a href="#1-1-1-Exactly-once-VS-At-least-once" class="headerlink" title="1.1.1. Exactly-once VS At-least-once"></a>1.1.1. Exactly-once VS At-least-once</h3><p>算子做快照时，如果等所有输入端的barrier都到了才开始做快照，可保证算子的exactly-once；如果为了降低延时而跳过对齐，从而继续处理数据，那么等barrier都到齐后做快照就是at-least-once了，因为这次的快照掺杂了下一次快照的数据，当作业失败恢复的时候，这些数据会重复作用系统，就好像这些数据被消费了两遍。</p>
<p>注：对齐只会发生在算子的上端是join操作以及上游存在partition或者shuffle的情况，对于直连操作类似map、flatMap、filter等还是会保证exactly-once的语义。</p>
<h3 id="1-1-2-端到端的Exactly-once实现"><a href="#1-1-2-端到端的Exactly-once实现" class="headerlink" title="1.1.2. 端到端的Exactly once实现"></a>1.1.2. 端到端的Exactly once实现</h3><p>2PC分为几个阶段: 开始事务-&gt;预提交-&gt;提交(或回滚)</p>
<p>为了保证Exactly once, source和sink必须支持flink的2PC</p>
<p>当状态涉及到外部系统时，需要外部系统支持事务操作来配合flink实现2PC协议，从而保证数据的exatly-once。<br>这个时候，sink算子除了将自己的state写到后段，还必须准备好事务提交。</p>
<ul>
<li>一旦所有的算子完成了它们的pre-commit，它们会要求一个commit。</li>
<li>如果存在一个算子pre-commit失败了，本次事务失败，我们回滚到上次的checkpoint。</li>
<li>一旦master做出了commit的决定，那么这个commit必须得到执行，就算宕机恢复也有继续执行。</li>
</ul>
<h4 id="1-1-2-1-pre-commit"><a href="#1-1-2-1-pre-commit" class="headerlink" title="1.1.2.1. pre-commit"></a>1.1.2.1. pre-commit</h4><p>pre-commit阶段起始于一次快照的开始，即master节点将checkpoint的barrier注入source端，barrier随着数据向下流动直到sink端。barrier每到一个算子，都会出发算子做本地快照。</p>
<p><img src="_v_images/20200710154629243_751269158.png" alt="precommit"></p>
<p>当所有的算子都做完了本地快照并且回复到master节点时，pre-commit阶段才算结束。这个时候，checkpoint已经成功，并且包含了外部系统的状态。如果作业失败，可以进行恢复。</p>
<p><img src="_v_images/20200710154750060_1524377793.png" alt="precommit-success"></p>
<h4 id="1-1-2-2-commit"><a href="#1-1-2-2-commit" class="headerlink" title="1.1.2.2. commit"></a>1.1.2.2. commit</h4><p>通知所有的算子这次checkpoint成功了，即2PC的commit阶段。source节点和window节点没有外部状态，所以这时它们不需要做任何操作。<br>而对于sink节点，需要commit这次事务，将数据写到外部系统。</p>
<p><img src="_v_images/20200710154844838_737658241.png" alt="commit"></p>
<h4 id="1-1-2-3-rollback"><a href="#1-1-2-3-rollback" class="headerlink" title="1.1.2.3. rollback"></a>1.1.2.3. rollback</h4><p>一旦任何一个算子的快照保存失败，则触发回滚，同样的sink算子也需要取消写入外部的数据</p>
<h3 id="1-1-3-TwoPhaseCommitSinkFunction"><a href="#1-1-3-TwoPhaseCommitSinkFunction" class="headerlink" title="1.1.3. TwoPhaseCommitSinkFunction"></a>1.1.3. TwoPhaseCommitSinkFunction</h3><p>为了简化2PC的实现成本，flink抽象了TwoPhaseCommitSinkFunction</p>
<ul>
<li>beginTransaction。开始一次事务，在目的文件系统创建一个临时文件。接下来我们就可以将数据写到这个文件。</li>
<li>preCommit。在这个阶段，将文件flush掉，同时重起一个文件写入，作为下一次事务的开始。</li>
<li>commit。这个阶段，将文件写到真正的目的目录。值得注意的是，这会增加数据可视的延时。</li>
<li>abort。如果回滚，那么删除临时文件。</li>
</ul>
<p>如果pre-commit成功了，但是commit没有到达算子旧宕机了，flink会将算子恢复到pre-commit时的状态，然后继续commit。</p>
<p>我们需要做的还有就是保证commit的幂等性，这可以通过检查临时文件是否还在来实现。</p>
<h2 id="1-2-checkpoint"><a href="#1-2-checkpoint" class="headerlink" title="1.2. checkpoint"></a>1.2. checkpoint</h2><p><strong>保留策略</strong>:</p>
<ul>
<li>DELETE_ON_CANCELLATION 表示当程序取消时，删除 Checkpoint 存储文件。</li>
<li>RETAIN_ON_CANCELLATION 表示当程序取消时，保存之前的 Checkpoint 存储文件</li>
</ul>
<p>默认情况下，Flink不会触发一次 Checkpoint 当系统有其他 Checkpoint 在进行时，也就是说 Checkpoint 默认的并发为1。</p>
<p><strong>CheckpointCoordinator</strong> :</p>
<p>针对 Flink DataStream 任务，程序需要经历从 StreamGraph -&gt; JobGraph -&gt; ExecutionGraph -&gt; 物理执行图四个步骤，其中在 ExecutionGraph 构建时，会初始化 CheckpointCoordinator。ExecutionGraph通过ExecutionGraphBuilder.buildGraph方法构建，在构建完时，会调用 ExecutionGraph 的enableCheckpointing方法创建CheckpointCoordinator</p>
<p><strong>Flink Checkpoint 参数配置及建议</strong>:</p>
<ul>
<li>当 Checkpoint 时间比设置的 Checkpoint 间隔时间要长时，可以设置 Checkpoint 间最小时间间隔 。这样在上次 Checkpoint 完成时，不会立马进行下一次 Checkpoint，而是会等待一个最小时间间隔，然后在进行该次 Checkpoint。否则，每次 Checkpoint 完成时，就会立马开始下一次 Checkpoint，系统会有很多资源消耗 Checkpoint。</li>
<li>如果Flink状态很大，在进行恢复时，需要从远程存储读取状态恢复，此时可能导致任务恢复很慢，可以设置 Flink Task 本地状态恢复。任务状态本地恢复默认没有开启，可以设置参数state.backend.local-recovery值为true进行激活。</li>
<li>Checkpoint保存数，Checkpoint 保存数默认是1，也就是保存最新的 Checkpoint 文件，当进行状态恢复时，如果最新的Checkpoint文件不可用时(比如HDFS文件所有副本都损坏或者其他原因)，那么状态恢复就会失败，如果设置 Checkpoint 保存数2，即使最新的Checkpoint恢复失败，那么Flink 会回滚到之前那一次Checkpoint进行恢复。考虑到这种情况，用户可以增加 Checkpoint 保存数。</li>
<li>建议设置的 Checkpoint 的间隔时间最好大于 Checkpoint 的完成时间。</li>
</ul>
<p>下图是不设置 Checkpoint 最小时间间隔示例图，可以看到，系统一致在进行 Checkpoint，可能对运行的任务产生一定影响：<br><img src="_v_images/20200714095846469_121820659.png"></p>
<h2 id="1-3-savepoint"><a href="#1-3-savepoint" class="headerlink" title="1.3. savepoint"></a>1.3. savepoint</h2><blockquote>
<p>注意:<br>使用DataStream进行开发，建议为每个算子定义一个 uid，这样我们在修改作业时，即使导致程序拓扑图改变，由于相关算子 uid 没有变，那么这些算子还能够继续使用之前的状态，如果用户没有定义 uid ， Flink 会为每个算子自动生成 uid，如果用户修改了程序，可能导致之前的状态程序不能再进行复用。</p>
</blockquote>
<p>Flink 在触发Savepoint 或者 Checkpoint时，会根据这次触发的类型计算出在HDFS上面的目录:</p>
<p>如果类型是 Savepoint，那么 其 HDFS 上面的目录为：Savepoint 根目录+savepoint-jobid前六位+随机数字，具体如下格式：</p>
<p><img src="_v_images/20200714100459823_887900222.png"></p>
<p>Checkpoint 目录为 chk-checkpoint ID,具体格式如下：</p>
<p><img src="_v_images/20200714100516223_630729421.png"></p>
<ul>
<li>使用 flink cancel -s 命令取消作业同时触发 Savepoint 时，会有一个问题，可能存在触发 Savepoint 失败。比如实时程序处于异常状态(比如 Checkpoint失败)，而此时你停止作业，同时触发 Savepoint,这次 Savepoint 就会失败，这种情况会导致，在实时平台上面看到任务已经停止，但是实际实时作业在 Yarn 还在运行。针对这种情况，需要捕获触发 Savepoint 失败的异常，当抛出异常时，可以直接在 Yarn 上面 Kill 掉该任务。</li>
<li>使用 DataStream 程序开发时，最好为每个算子分配 uid,这样即使作业拓扑图变了，相关算子还是能够从之前的状态进行恢复，默认情况下，Flink 会为每个算子分配 uid,这种情况下，当你改变了程序的某些逻辑时，可能导致算子的 uid 发生改变，那么之前的状态数据，就不能进行复用，程序在启动的时候，就会报错。</li>
<li>由于 Savepoint 是程序的全局状态，对于某些状态很大的实时任务，当我们触发 Savepoint，可能会对运行着的实时任务产生影响，个人建议如果对于状态过大的实时任务，触发 Savepoint 的时间，不要太过频繁。根据状态的大小，适当的设置触发时间。</li>
<li>当我们从 Savepoint 进行恢复时，需要检查这次 Savepoint 目录文件是否可用。可能存在你上次触发 Savepoint 没有成功，导致 HDFS 目录上面 Savepoint 文件不可用或者缺少数据文件等，这种情况下，如果在指定损坏的 Savepoint 的状态目录进行状态恢复，任务会启动不起来。</li>
</ul>
<h2 id="1-4-snapshot保存到哪里-应该需要汇总到jobManager？"><a href="#1-4-snapshot保存到哪里-应该需要汇总到jobManager？" class="headerlink" title="1.4. snapshot保存到哪里? 应该需要汇总到jobManager？"></a>1.4. snapshot保存到哪里? 应该需要汇总到jobManager？</h2><h2 id="1-5-state-backend"><a href="#1-5-state-backend" class="headerlink" title="1.5. state backend"></a>1.5. state backend</h2><p><img src="_v_images/20200713183839429_2053265091.png"></p>
<h3 id="FsStateBackend"><a href="#FsStateBackend" class="headerlink" title="FsStateBackend"></a>FsStateBackend</h3><p>构造方法:<br><code>FsStateBackend(URI checkpointDataUri,boolean asynchronousSnapshots)</code></p>
<p>1 基于文件系统的状态管理器<br>2 如果使用，默认是异步<br>3 比较稳定，3个副本，比较安全。不会出现任务无法恢复等问题<br>4 状态大小受磁盘容量限制</p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager内存</li>
<li>checkpoint: 外部文件系统(本地或HDFS)</li>
</ul>
<p>容量限制:</p>
<ul>
<li>单TaskManager上State总量不超过它的内存</li>
<li>总大小不超过配置的文件系统容量</li>
</ul>
<p>推荐使用场景:</p>
<ul>
<li>常规使用状态的作业，例如分钟级窗口聚合、join、窗口比较长、kv状态大；需要开启HA的作业</li>
<li>可以用于生产场景</li>
</ul>
<h3 id="RocksDBStateBackend"><a href="#RocksDBStateBackend" class="headerlink" title="RocksDBStateBackend"></a>RocksDBStateBackend</h3><p>状态数据先写入RocksDB，然后异步的将状态数据写入文件系统。正在进行计算的热数据存储在RocksDB，长时间才更新的数据写入磁盘中（文件系统）存储，体量比较小的元数据状态写入JobManager内存中（将工作state保存在RocksDB中，并且默认将checkpoint数据存在文件系统中）</p>
<p>目前唯一支持incremental的checkpoints的策略</p>
<p>构造方法:<br><code>RocksDBStateBackend(URI checkpointDataUri,boolean enableIncrementalCheckpointing)</code></p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager上的KV数据库(实际使用内存+硬盘)</li>
<li>Checkpoint: 外部文件系统(本地或HDFS)</li>
</ul>
<p>容量限制:</p>
<ul>
<li>单TaskManager上的State总量不超过他的内存+磁盘</li>
<li>单key最大2G</li>
<li>总大小不超过配置的文件系统容量</li>
</ul>
<p>推荐使用的场景:</p>
<ul>
<li>超大状态的作业，例如天级别窗口聚合；需要开启HA的作业；对状态读写性能要求不高的作业</li>
<li>可以在生产环境使用</li>
</ul>
<h3 id="MemoryStateBackend"><a href="#MemoryStateBackend" class="headerlink" title="MemoryStateBackend"></a>MemoryStateBackend</h3><p>构造方法:<br><code>MemoryStateBackend(int maxStateSize, boolean asynchronousSnapshots)</code></p>
<p>主机内存中的数据可能会丢失，任务可能无法恢复</p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager内存</li>
<li>Checkpoint: JobManager内存</li>
</ul>
<p>容量限制</p>
<ul>
<li>单个State maxStateSize默认5M</li>
<li>maxStateSize &lt;= akka.frameSize 默认10M</li>
<li>总大小不超过JobManager的内存</li>
</ul>
<p>推荐使用场景：</p>
<ul>
<li>本地测试；几乎无状态的作业，比如ETL；JobManager不容易挂，或挂掉影响不大的情况</li>
<li>不推荐在生产环境使用</li>
</ul>
<h2 id="1-6-checkpoint-与-savepoint"><a href="#1-6-checkpoint-与-savepoint" class="headerlink" title="1.6. checkpoint 与 savepoint"></a>1.6. checkpoint 与 savepoint</h2><p>Checkpoint指定触发生成时间间隔后，每当需要触发Checkpoint时，会向Flink程序运行时的多个分布式的Stream Source中插入一个Barrier标记，这些Barrier会根据Stream中的数据记录一起流向下游的各个Operator。<br>当一个Operator接收到一个Barrier时，它会暂停处理Steam中新接收到的数据记录。<br>因为一个Operator可能存在多个输入的Stream，而每个Stream中都会存在对应的Barrier，该Operator要等到所有的输入Stream中的Barrier都到达。(<strong>对齐</strong>)<br>当所有Stream中的Barrier都已经到达该Operator，这时所有的Barrier在时间上看来是同一个时刻点（表示已经对齐），在等待所有Barrier到达的过程中，<br>Operator的Buffer中可能已经缓存了一些比Barrier早到达Operator的数据记录（Outgoing Records），这时该Operator会将数据记录（Outgoing Records）发射（Emit）出去，作为下游Operator的输入，<br>最后将Barrier对应Snapshot发射（Emit）出去作为此次Checkpoint的结果数据。</p>
<p>Checkpoint 是增量做的，每次的时间较短，数据量较小，只要在程序里面启用后会自动触发，用户无须感知；Checkpoint 是作业 failover 的时候自动使用，不需要用户指定。</p>
<p>Savepoint 是全量做的，每次的时间较长，数据量较大，需要用户主动去触发。Savepoint 一般用于程序的版本更新（详见文档），Bug 修复，A/B Test 等场景，需要用户指定。</p>
<p><strong>保存的内容</strong></p>
<ul>
<li>首先，Savepoint 包含了一个目录，其中包含（通常很大的）二进制文件，这些文件表示了整个流应用在 Checkpoint/Savepoint 时的状态。</li>
<li>以及一个（相对较小的）元数据文件，包含了指向 Savapoint 各个文件的指针，并存储在所选的分布式文件系统或数据存储中。</li>
</ul>
<p><strong>目标</strong></p>
<p>Savepoint 和 Checkpoint 的不同之处很像传统数据库中备份与恢复日志之间的区别。Checkpoint 的主要目标是充当 Flink 中的恢复机制，确保能从潜在的故障中恢复。相反，Savepoint 的主要目标是充当手动备份、恢复暂停作业的方法。</p>
<p><strong>实现</strong></p>
<p>Checkpoint 被设计成轻量和快速的机制。它们可能（但不一定必须）利用底层状态后端的不同功能尽可能快速地恢复数据。例如，基于 RocksDB 状态后端的增量检查点，能够加速 RocksDB 的 checkpoint 过程，这使得 checkpoint 机制变得更加轻量。相反，Savepoint 旨在更多地关注数据的可移植性，并支持对作业做任何更改而状态能保持兼容，这使得生成和恢复的成本更高</p>
<p><strong>状态文件保留策略</strong></p>
<p>Checkpoint默认程序删除，可以设置CheckpointConfig中的参数进行保留 。Savepoint会一直保存，除非用户删除 。</p>
<p><strong>应用</strong></p>
<ul>
<li>部署流应用的一个新版本，包括新功能、BUG 修复、或者一个更好的机器学习模型</li>
<li>引入 A/B 测试，使用相同的源数据测试程序的不同版本，从同一时间点开始测试而不牺牲先前的状态</li>
<li>在需要更多资源时扩容应用程序</li>
<li>迁移流应用程序到 Flink 的新版本上，或者迁移到另一个集群</li>
</ul>
<h1 id="Flink数据一致性"><a href="#Flink数据一致性" class="headerlink" title="Flink数据一致性"></a>Flink数据一致性</h1><h2 id="一、综述"><a href="#一、综述" class="headerlink" title="一、综述"></a>一、综述</h2><p><strong>flink 通过内部依赖checkpoint 并且可以通过设置其参数exactly-once 实现其内部的一致性</strong>。但要实现其端到端的一致性，还必须保证<br>1、source 外部数据源可重设数据的读取位置<br>2、sink端 需要保证数据从故障恢复时，数据不会重复写入外部系统（或者可以逻辑实现写入多次，但只有一次生效的数据sink端）</p>
<h2 id="二、sink-端到端实现方式"><a href="#二、sink-端到端实现方式" class="headerlink" title="二、sink 端到端实现方式"></a>二、sink 端到端实现方式</h2><p><strong>幂等操作：</strong><br>一个操作，可以重复执行多次，但只导致一次结果更改，豁免重复操作执行就不起作用了，他的瑕疵 （在系统恢复的过程中，如果这段时间内多个更新或者插入导致状态不一致，但当数据追上就可以了）<br>（逻辑与、逻辑或等）具体理解参照自己以前写的文章。<br><strong>事务写入：</strong><br>事务应该具有四个属性：原子性、一致性、隔离性、持久性等。其具体的实现方式有两种<br><strong>（1）、预写日志</strong><br>简单易于实现，由于数据提前在状态后端中做了缓存，所以无论什么sink系统，都能用这种方式一批搞定，DataStream API提供了一个模板类：GenericWriteAheadSink，来实现这种事务性sink；<br>缺点：<br>1）、sink系统没说他支持事务。有可能出现一部分写入集群了。一部分没有写进去（如果实表，再写一次就写重复了）<br>2）、checkpoint做完了sink才去真正的写入（但其实得等sink都写完checkpoint才能生效，所以WAL这个机制jobmanager确定它写完还不算真正写完，还得有一个外部系统已经确认 完成的checkpoint）<br>（<strong>2）、两阶段提交。 flink 真正实现exactle-once</strong><br>对于每个checkpoint,sink 任务会启动一个事务，并将接下来所有接收的数据添加到事务中，然后将这些数据写入外部sink系统，但不提交他们（这里是预提交）。当checkpoint完成时的通知，它才正式提交事务，实现结果的真正写入；这种方式真正实现了exactly-once,它需要一个提供事务支持的外部sink系统，Flink提供了其具体实现（TwoPhaseCommitSinkFunction接口）</p>
<h2 id="三、-2pc-对外部-sink的要求"><a href="#三、-2pc-对外部-sink的要求" class="headerlink" title="三、 2pc 对外部 sink的要求"></a>三、 2pc 对外部 sink的要求</h2><p>1、外部sink系统必须事务支持，或者sink任务必须能够模拟外部系统上的事务；<br>2、在checkpoint的间隔期间里，必须能够开启一个事务，并接受数据写入。<br>3、在收到checkpoint完成通知之前，事务必须是“等待提交”的状态，在故障恢复的情况线，这可能需要一些时间。如果个时候sink系统关闭事务（例如超时了），那么未提交的数据就会丢失；<br>4、四年任务必选能够在进程失败后恢复事务<br>5、提交事务必须是幂等操作；</p>
<p>四、综上不同Source和sink的一致性保证：<br><img src="_v_images/20201208154240979_1471214802.png" alt="在这里插入图片描述"></p>
<h2 id="五、应用（flinK-kafka-端到端一致性保证）"><a href="#五、应用（flinK-kafka-端到端一致性保证）" class="headerlink" title="五、应用（flinK+kafka 端到端一致性保证）"></a>五、应用（flinK+kafka 端到端一致性保证）</h2><p>flink 和kafka 端到端一致性(kafka(source+flink+kafka(sink)))<br>1、内部 – 利用checkpoint机制，把状态存盘，发生故障的时候可以恢复，保证内部的状态一致性<br>2、source – kafka consumer作为source，可以将偏移量保存下来，如果后续任务出现了故障，恢复的时候可以由连接器重置偏移量，重新消费数据，保证一致性；</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">kafka</span> 0.8 和<span class="selector-tag">kafka</span> 0.11 之后 通过以下配置将偏移量保存，恢复时候重新消费</span><br><span class="line"> <span class="selector-tag">kafka</span><span class="selector-class">.setStartFromLatest</span>();</span><br><span class="line"> <span class="selector-tag">kafka</span><span class="selector-class">.setCommitOffsetsOnCheckpoints</span>(<span class="selector-tag">false</span>);</span><br><span class="line"> <span class="selector-tag">kafka</span> 0.9 和<span class="selector-tag">kafka0</span>.10 未验证是否支持这两个参数(<span class="selector-tag">todo</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>3、sink FlinkkafkaProducer作为Sink，采用两阶段提交的sink，由下图可以看出flink 0.11 已经默认继承了TwoPhaseCommitSinkFunction<br><img src="_v_images/20201208154240548_914126344.png" alt="在这里插入图片描述"><br>但我们需要在参数种传入指定语义，它默认时还是at-least-once<br>此外我们还需要进行一些producer的容错配置：<br>（1）除了启用Flink的检查点之外，还可以通过将适当的semantic参数传递给FlinkKafkaProducer011（FlinkKafkaProducer对于Kafka&gt; = 1.0.0版本）<br>（2）来选择三种不同的操作模式<br>1）、Semantic.NONE 代表at-mostly-once语义<br>2）、Semantic.AT_LEAST_ONCE（Flink默认设置<br>3）、Semantic.EXACTLY_ONCE 使用Kafka事务提供一次精确的语义，每当您使用事务写入Kafka时<br>（3）、请不要忘记消费kafka记录任何应用程序设置所需的设置isolation.leva（read_committed 或者read_uncommitted-后者是默认）<br>read_committed，只是读取已经提交的数据。</p>
<p>应用；<br>Semantic.EXACTLY_ONCE依赖与下游系统能支持事务操作.以0.11kafka为例.<br>transaction.max.timeout.ms 最大超市时长，默认15分钟，如果需要用exactly语义，需要增加这个值。（因为它小于transaction.timeout.ms ）<br>isolation.level 如果需要用到exactly语义，需要在下级consumerConfig中设置read-commited [read-uncommited(默认值)]<br>transaction.timeout.ms 默认为1hour</p>
<p><strong>其参数对应关系为 和一些报错问题<br>checkpoint间隔&lt;transaction.timeout.ms&lt;transaction.max.timeout.ms</strong></p>
<p><strong>参考：<a href="https://www.cnblogs.com/createweb/p/11971846.html">https://www.cnblogs.com/createweb/p/11971846.html</a></strong></p>
<p>注意：<br>1、Semantic.EXACTLY_ONCE 模式每个FlinkKafkaProducer011实例使用一个固定大小的KafkaProducers池。每个检查点使用这些生产者中的每一个。如果并发检查点的数量超过池大小，FlinkKafkaProducer011 将引发异常，并使整个应用程序失败。请相应地配置最大池大小和最大并发检查点数。</p>
<p>2、Semantic.EXACTLY_ONCE采取所有可能的措施，不要留下任何挥之不去的数据，否则这将有碍于消费者更多地阅读Kafka主题。但是，如果flink应用程序在第一个检查点之前失败，则在重新启动此类应用程序后，系统种将没有有关先前池大小信息，因此，在第一个检查点完成前按比例缩小Flink应用程序的FlinkKafkaProducer011.SAFE_SCALE_DOWN_FACTOR</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">//1。设置最大允许的并行<span class="selector-tag">checkpoint</span>数，防止超过<span class="selector-tag">producer</span>池的个数发生异常</span><br><span class="line"><span class="selector-tag">env</span><span class="selector-class">.getCheckpointConfig</span><span class="selector-class">.setMaxConcurrentCheckpoints</span>(5) </span><br><span class="line">//2。设置<span class="selector-tag">producer</span>的<span class="selector-tag">ack</span>传输配置</span><br><span class="line">// 设置超市时长，默认15分钟，建议1个小时以上</span><br><span class="line"><span class="selector-tag">producerConfig</span><span class="selector-class">.put</span>(<span class="selector-tag">ProducerConfig</span><span class="selector-class">.ACKS_CONFIG</span>, 1) </span><br><span class="line"><span class="selector-tag">producerConfig</span><span class="selector-class">.put</span>(<span class="selector-tag">ProducerConfig</span><span class="selector-class">.TRANSACTION_TIMEOUT_CONFIG</span>, 15000) </span><br><span class="line"></span><br><span class="line">//3。在下一个<span class="selector-tag">kafka</span> <span class="selector-tag">consumer</span>的配置文件，或者代码中设置<span class="selector-tag">ISOLATION_LEVEL_CONFIG-read-commited</span></span><br><span class="line">//<span class="selector-tag">Note</span>:必须在下一个<span class="selector-tag">consumer</span>中指定，当前指定是没用用的</span><br><span class="line"><span class="selector-tag">kafkaonfigs</span><span class="selector-class">.setProperty</span>(<span class="selector-tag">ConsumerConfig</span><span class="selector-class">.ISOLATION_LEVEL_CONFIG</span>,&quot;<span class="selector-tag">read_commited</span>&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>完整应用代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shufang.flink.connectors</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.TimeCharacteristic</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.Semantic</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line"></span><br><span class="line">object KafkaSource01 &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这是checkpoint的超时时间</span></span><br><span class="line">    <span class="comment">//env.getCheckpointConfig.setCheckpointTimeout()</span></span><br><span class="line">    <span class="comment">//设置最大并行的chekpoint</span></span><br><span class="line">    env.getCheckpointConfig.setMaxConcurrentCheckpoints(<span class="number">5</span>)</span><br><span class="line">    env.getCheckpointConfig.setCheckpointInterval(<span class="number">1000</span>) <span class="comment">//增加checkpoint的中间时长，保证可靠性</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 为了保证数据的一致性，我们开启Flink的checkpoint一致性检查点机制，保证容错</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    env.enableCheckpointing(<span class="number">60000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从kafka获取数据，一定要记得添加checkpoint，能保证offset的状态可以重置，从数据源保证数据的一致性</span></span><br><span class="line"><span class="comment">     * 保证kafka代理的offset与checkpoint备份中保持状态一致</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    val kafkaonfigs = <span class="keyword">new</span> Properties()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka的启动集群</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">    <span class="comment">//指定消费者组</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;flinkConsumer&quot;</span>)</span><br><span class="line">    <span class="comment">//指定key的反序列化类型</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer].getName)</span><br><span class="line">    <span class="comment">//指定value的反序列化类型</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer].getName)</span><br><span class="line">    <span class="comment">//指定自动消费offset的起点配置</span></span><br><span class="line">    <span class="comment">//    kafkaonfigs.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义kafkaConsumer，同时可以指定从哪里开始消费</span></span><br><span class="line"><span class="comment">     * 开启了Flink的检查点之后，我们还要开启kafka-offset的检查点，通过kafkaConsumer.setCommitOffsetsOnCheckpoints(true)开启，</span></span><br><span class="line"><span class="comment">     * 一旦这个检查点开启，那么之前配置的 auto-commit-enable = true的配置就会自动失效</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    val kafkaConsumer = <span class="keyword">new</span> FlinkKafkaConsumer[String](</span><br><span class="line">      <span class="string">&quot;console-topic&quot;</span>,</span><br><span class="line">      <span class="keyword">new</span> SimpleStringSchema(), <span class="comment">// 这个schema是将kafka的数据应设成Flink中的String类型</span></span><br><span class="line">      kafkaonfigs</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 开启kafka-offset检查点状态保存机制</span></span><br><span class="line">    kafkaConsumer.setCommitOffsetsOnCheckpoints(<span class="keyword">true</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromEarliest()//</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromTimestamp(1010003794)</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromLatest()</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromSpecificOffsets(Map[KafkaTopicPartition,Long]()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加source数据源</span></span><br><span class="line">    val kafkaStream: DataStream[String] = env.addSource(kafkaConsumer)</span><br><span class="line"></span><br><span class="line">    kafkaStream.print()</span><br><span class="line"></span><br><span class="line">    val sinkStream: DataStream[String] = kafkaStream.assignTimestampsAndWatermarks(<span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor[String](Time.seconds(<span class="number">5</span>)) &#123;</span><br><span class="line">      <span class="function">override def <span class="title">extractTimestamp</span><span class="params">(element: String)</span>: Long </span>= &#123;</span><br><span class="line">        element.split(<span class="string">&quot;,&quot;</span>)(<span class="number">1</span>).toLong</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过FlinkkafkaProduccer API将stream的数据写入到kafka的&#x27;sink-topic&#x27;中</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//    val brokerList = &quot;localhost:9092&quot;</span></span><br><span class="line">    val topic = <span class="string">&quot;sink-topic&quot;</span></span><br><span class="line">    val producerConfig = <span class="keyword">new</span> Properties()</span><br><span class="line">    producerConfig.put(ProducerConfig.ACKS_CONFIG, <span class="keyword">new</span> Integer(<span class="number">1</span>)) <span class="comment">// 设置producer的ack传输配置</span></span><br><span class="line">    producerConfig.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, Time.hours(<span class="number">2</span>)) <span class="comment">//设置超市时长，默认1小时，建议1个小时以上</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义producer，可以通过不同的构造器创建</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    val producer: FlinkKafkaProducer[String] = <span class="keyword">new</span> FlinkKafkaProducer[String](</span><br><span class="line">      topic,</span><br><span class="line">      <span class="keyword">new</span> KeyedSerializationSchemaWrapper[String](SimpleStringSchema),</span><br><span class="line">      producerConfig,</span><br><span class="line">      Semantic.EXACTLY_ONCE</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    FlinkKafkaProducer.SAFE_SCALE_DOWN_FACTOR</span></span><br><span class="line">    <span class="comment">/** *****************************************************************************************************************</span></span><br><span class="line"><span class="comment">     * * 出了要开启flink的checkpoint功能，同时还要设置相关配置功能。</span></span><br><span class="line"><span class="comment">     * * 因在0.9或者0.10，默认的FlinkKafkaProducer只能保证at-least-once语义，假如需要满足at-least-once语义，我们还需要设置</span></span><br><span class="line"><span class="comment">     * * setLogFailuresOnly(boolean)    默认false</span></span><br><span class="line"><span class="comment">     * * setFlushOnCheckpoint(boolean)  默认true</span></span><br><span class="line"><span class="comment">     * * come from 官网 below：</span></span><br><span class="line"><span class="comment">     * * Besides enabling Flink’s checkpointing，you should also configure the setter methods setLogFailuresOnly(boolean)</span></span><br><span class="line"><span class="comment">     * * and setFlushOnCheckpoint(boolean) appropriately.</span></span><br><span class="line"><span class="comment">     * ******************************************************************************************************************/</span></span><br><span class="line"></span><br><span class="line">    producer.setLogFailuresOnly(<span class="keyword">false</span>) <span class="comment">//默认是false</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 除了启用Flink的检查点之外，还可以通过将适当的semantic参数传递给FlinkKafkaProducer011（FlinkKafkaProducer对于Kafka&gt; = 1.0.0版本）</span></span><br><span class="line"><span class="comment">     * 来选择三种不同的操作模式：</span></span><br><span class="line"><span class="comment">     * Semantic.NONE  代表at-mostly-once语义</span></span><br><span class="line"><span class="comment">     * Semantic.AT_LEAST_ONCE（Flink默认设置）</span></span><br><span class="line"><span class="comment">     * Semantic.EXACTLY_ONCE：使用Kafka事务提供一次精确的语义，每当您使用事务写入Kafka时，</span></span><br><span class="line"><span class="comment">     * 请不要忘记为使用Kafka记录的任何应用程序设置所需的设置isolation.level（read_committed 或read_uncommitted-后者是默认值)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    sinkStream.addSink(producer)</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">&quot;kafka source &amp; sink&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a href="http://shiyanjun.cn/archives/1855.html">Flink Checkpoint、Savepoint配置与实践</a></li>
<li><a href="http://wuchong.me/blog/2018/11/04/how-apache-flink-manages-kafka-consumer-offsets/">Flink 小贴士 (2)：Flink 如何管理 Kafka 消费位点</a></li>
<li><a href="https://www.jianshu.com/p/4bcbcda0e2f4">Flink实时计算-深入理解Checkpoint和Savepoint</a></li>
<li><a href="https://arxiv.org/abs/1506.08603">Lightweight Asynchronous Snapshots for Distributed Dataflows: 分布式数据流轻量级异步快照</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink connector hippo</title>
    <url>/bigdata/Flink/Flink-connector-hippo/</url>
    <content><![CDATA[<h1 id="Flink-connector-hippo"><a href="#Flink-connector-hippo" class="headerlink" title="Flink-connector-hippo"></a>Flink-connector-hippo</h1><h2 id="broker分拆"><a href="#broker分拆" class="headerlink" title="broker分拆"></a>broker分拆</h2><p>获取子任务的index</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> taskId = <span class="keyword">this</span>.getRuntimeContext().getIndexOfThisSubtask();</span><br></pre></td></tr></table></figure>
<h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>实现CheckpointedFunction</p>
<p>在ListState中保存每个broker的偏移量 </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ListState&lt;Tuple2&lt;String, String&gt;&gt; offsetState;</span><br></pre></td></tr></table></figure>

<h2 id="watermark生成"><a href="#watermark生成" class="headerlink" title="watermark生成"></a>watermark生成</h2><h2 id="hippo-pullConsumer"><a href="#hippo-pullConsumer" class="headerlink" title="hippo pullConsumer"></a>hippo pullConsumer</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ConsumerConfig config =</span><br><span class="line">                <span class="keyword">new</span> ConsumerConfig(masterAddress, consumerGroup);</span><br><span class="line"><span class="keyword">if</span> (!isRestored &amp;&amp; bootstrapFromMax) &#123;</span><br><span class="line">    config.setConsumeFromMax(<span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">messagePullConsumer = <span class="keyword">new</span> PullMessageConsumer(config);</span><br></pre></td></tr></table></figure>
<h2 id="子任务的checkpointLock"><a href="#子任务的checkpointLock" class="headerlink" title="子任务的checkpointLock"></a>子任务的checkpointLock</h2><p>往下游放入消息必须加锁</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SourceContext&lt;<span class="keyword">byte</span>[]&gt;.getCheckpointLock()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/Flink-checkpoint%E8%AF%8A%E6%96%AD/</url>
    <content><![CDATA[<h1 id="Flink-checkpoint诊断"><a href="#Flink-checkpoint诊断" class="headerlink" title="Flink-checkpoint诊断"></a>Flink-checkpoint诊断</h1>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/Flink-connectors/</url>
    <content><![CDATA[<h1 id="Flink-connectors"><a href="#Flink-connectors" class="headerlink" title="Flink-connectors"></a>Flink-connectors</h1>]]></content>
  </entry>
  <entry>
    <title>Flink数据倾斜</title>
    <url>/bigdata/Flink/Flink-data-skew/</url>
    <content><![CDATA[<h1 id="Flink-data-skew"><a href="#Flink-data-skew" class="headerlink" title="Flink-data-skew"></a>Flink-data-skew</h1><p>【参考文献】</p>
<ol>
<li><a href="https://blog.csdn.net/nazeniwaresakini/article/details/104220120">用两阶段聚合法解决keyBy算子倾斜</a></li>
<li><a href="https://blog.csdn.net/a1240466196/article/details/109012584">Flink调优: 数据倾斜优化</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink: 数据源重放</title>
    <url>/bigdata/Flink/Flink-datasource/</url>
    <content><![CDATA[<h1 id="flink-table-api"><a href="#flink-table-api" class="headerlink" title="flink-table-api"></a>flink-table-api</h1><h2 id="Hippo和Tube如何实现重放"><a href="#Hippo和Tube如何实现重放" class="headerlink" title="Hippo和Tube如何实现重放?"></a>Hippo和Tube如何实现重放?</h2><h3 id="FlinkHippoConsumer"><a href="#FlinkHippoConsumer" class="headerlink" title="FlinkHippoConsumer"></a>FlinkHippoConsumer</h3><h2 id="举一反三"><a href="#举一反三" class="headerlink" title="举一反三"></a>举一反三</h2><h3 id="org-apache-flink-streaming-api-functions-source-RichParallelSourceFunction"><a href="#org-apache-flink-streaming-api-functions-source-RichParallelSourceFunction" class="headerlink" title="org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction"></a>org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction</h3><p>构建并行数据流的基础类，在执行时，运行时将执行与源配置的并行一样多的该函数的并行实例。</p>
<h2 id="org-apache-flink-types-Row"><a href="#org-apache-flink-types-Row" class="headerlink" title="org.apache.flink.types.Row"></a>org.apache.flink.types.Row</h2><p>一行数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Object[]  fields</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/Flink-join/</url>
    <content><![CDATA[<h1 id="Flink-join"><a href="#Flink-join" class="headerlink" title="Flink join"></a>Flink join</h1><p>Flink DataStream API为用户提供了3个算子来实现双流join，分别是：</p>
<ul>
<li>  join():   inner join，on window</li>
<li>  coGroup():   custom join, on window</li>
<li>  intervalJoin():   inner join, on time range, keyed stream</li>
</ul>
<p>另外，还提供了broadcast join来关联较小的</p>
<h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><p>从Kafka分别接入点击流和订单流，并转化为POJO。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;String&gt; clickSourceStream = env</span><br><span class="line">  .addSource(<span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">    <span class="string">&quot;ods_analytics_access_log&quot;</span>,</span><br><span class="line">    <span class="keyword">new</span> SimpleStringSchema(),</span><br><span class="line">    kafkaProps</span><br><span class="line">  ).setStartFromLatest());</span><br><span class="line">DataStream&lt;String&gt; orderSourceStream = env</span><br><span class="line">  .addSource(<span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">    <span class="string">&quot;ods_ms_order_done&quot;</span>,</span><br><span class="line">    <span class="keyword">new</span> SimpleStringSchema(),</span><br><span class="line">    kafkaProps</span><br><span class="line">  ).setStartFromLatest());</span><br><span class="line"></span><br><span class="line">DataStream&lt;AnalyticsAccessLogRecord&gt; clickRecordStream = clickSourceStream</span><br><span class="line">  .map(message -&gt; JSON.parseObject(message, AnalyticsAccessLogRecord.class));</span><br><span class="line">DataStream&lt;OrderDoneLogRecord&gt; orderRecordStream = orderSourceStream</span><br><span class="line">  .map(message -&gt; JSON.parseObject(message, OrderDoneLogRecord.class));</span><br></pre></td></tr></table></figure>
<h2 id="join"><a href="#join" class="headerlink" title="join()"></a>join()</h2><p>join()算子提供的语义为”<strong>Window join</strong>“，即按照指定字段和（滚动/滑动/会话）窗口进行<strong>inner join</strong>，支持处理时间和事件时间两种时间特征。</p>
<p>以下示例以10秒滚动窗口，将两个流通过商品ID关联，取得订单流中的售价相关字段。</p>
<p><img src="//upload-images.jianshu.io/upload_images/195230-05b05dd1da1e6025.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">clickRecordStream</span><br><span class="line">  .join(orderRecordStream)</span><br><span class="line">  .where(record -&gt; record.getMerchandiseId())</span><br><span class="line">  .equalTo(record -&gt; record.getMerchandiseId())</span><br><span class="line">  .window(TumblingProcessingTimeWindows.of(Time.seconds(<span class="number">10</span>)))</span><br><span class="line">  .apply(<span class="keyword">new</span> JoinFunction&lt;AnalyticsAccessLogRecord, OrderDoneLogRecord, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">join</span><span class="params">(AnalyticsAccessLogRecord accessRecord, OrderDoneLogRecord orderRecord)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> StringUtils.join(Arrays.asList(</span><br><span class="line">        accessRecord.getMerchandiseId(),</span><br><span class="line">        orderRecord.getPrice(),</span><br><span class="line">        orderRecord.getCouponMoney(),</span><br><span class="line">        orderRecord.getRebateAmount()</span><br><span class="line">      ), <span class="string">&#x27;\t&#x27;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">  .print().setParallelism(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>简单易用。</p>
<h2 id="coGroup"><a href="#coGroup" class="headerlink" title="coGroup()"></a>coGroup()</h2><p>只有inner join肯定还不够，如何实现left/right outer join呢？答案就是利用coGroup()算子。它的调用方式类似于join()算子，也需要开窗，但是CoGroupFunction比JoinFunction更加灵活，可以按照用户指定的逻辑匹配左流和/或右流的数据并输出。</p>
<p>以下的例子就实现了点击流left join订单流的功能，是很朴素的nested loop join思想（二重循环）。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">clickRecordStream</span><br><span class="line">  .coGroup(orderRecordStream)</span><br><span class="line">  .where(record -&gt; record.getMerchandiseId())</span><br><span class="line">  .equalTo(record -&gt; record.getMerchandiseId())</span><br><span class="line">  .window(TumblingProcessingTimeWindows.of(Time.seconds(<span class="number">10</span>)))</span><br><span class="line">  .apply(<span class="keyword">new</span> CoGroupFunction&lt;AnalyticsAccessLogRecord, OrderDoneLogRecord, Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">coGroup</span><span class="params">(Iterable&lt;AnalyticsAccessLogRecord&gt; accessRecords, Iterable&lt;OrderDoneLogRecord&gt; orderRecords, Collector&lt;Tuple2&lt;String, Long&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">      <span class="keyword">for</span> (AnalyticsAccessLogRecord accessRecord : accessRecords) &#123;</span><br><span class="line">        <span class="keyword">boolean</span> isMatched = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (OrderDoneLogRecord orderRecord : orderRecords) &#123;</span><br><span class="line">          <span class="comment">// 右流中有对应的记录</span></span><br><span class="line">          collector.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(accessRecord.getMerchandiseName(), orderRecord.getPrice()));</span><br><span class="line">          isMatched = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!isMatched) &#123;</span><br><span class="line">          <span class="comment">// 右流中没有对应的记录</span></span><br><span class="line">          collector.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(accessRecord.getMerchandiseName(), <span class="keyword">null</span>));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">  .print().setParallelism(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>CoGroupFunction中会返回所有数据，不管有没有匹配上</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;Tuple3&lt;Long, String, String&gt;&gt; input1 = ...;</span><br><span class="line">input1 = input1.assignTimestampsAndWatermarks(<span class="keyword">new</span> AscendingTimestampExtractor&lt;Tuple3&lt;Long, String, String&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(Tuple3&lt;Long, String, String&gt; arg0)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> arg0.f0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Tuple2&lt;Long, String&gt;&gt; input2 = ...;</span><br><span class="line">input2 = input2.assignTimestampsAndWatermarks(<span class="keyword">new</span> AscendingTimestampExtractor&lt;Tuple2&lt;Long, String&gt;&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(Tuple2&lt;Long, String&gt; stringStringTuple2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> stringStringTuple2.f0;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">input1.coGroup(input2).where(<span class="keyword">new</span> KeySelector&lt;Tuple3&lt;Long, String, String&gt;, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getKey</span><span class="params">(Tuple3&lt;Long, String, String&gt; itemEntity)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> itemEntity.f1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.equalTo(<span class="keyword">new</span> KeySelector&lt;Tuple2&lt;Long, String&gt;, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getKey</span><span class="params">(Tuple2&lt;Long, String&gt; value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value.f1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.window(TumblingEventTimeWindows.of(Time.minutes(<span class="number">1</span>)))</span><br><span class="line">.apply(<span class="keyword">new</span> CoGroupFunction&lt;Tuple3&lt;Long, String, String&gt;, Tuple2&lt;Long, String&gt;, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">coGroup</span><span class="params">(Iterable&lt;Tuple3&lt;Long, String, String&gt;&gt; first,</span></span></span><br><span class="line"><span class="function"><span class="params">            Iterable&lt;Tuple2&lt;Long, String&gt;&gt; second, Collector&lt;String&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        StringBuilder buffer = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        buffer.append(<span class="string">&quot;DataStream first:\n&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (Tuple3&lt;Long, String, String&gt; value : first) &#123;</span><br><span class="line">            buffer.append(value).append(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        buffer.append(<span class="string">&quot;DataStream second:\n&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;Long, String&gt; value : second) &#123;</span><br><span class="line">            buffer.append(value.f0).append(<span class="string">&quot;=&gt;&quot;</span>).append(value.f1).append(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        collector.collect(buffer.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.print();</span><br></pre></td></tr></table></figure>
<p>上面的例子，左流有三个元素 <code>Tuple3&lt;String,String,String&gt;</code>，右流有两个元素<code>Tuple2&lt;String,String&gt;</code><br>两个流第一个元素相互关联。分别指定两个流的事件时间字段。<br>两个流关联后，按照EventTime划分窗口。与单流类似。<br>不管元素是否可以关联上，都会输出</p>
<p>用户可以定义CoGroupFunction函数, 可以实现在窗口内，任意组合，如笛卡尔积</p>
<h2 id="intervalJoin"><a href="#intervalJoin" class="headerlink" title="intervalJoin()"></a>intervalJoin()</h2><p>join()和coGroup()都是基于窗口做关联的。但是在某些情况下，两条流的数据步调未必一致。例如，订单流的数据有可能在点击流的购买动作发生之后很久才被写入，如果用窗口来圈定，很容易join不上。所以Flink又提供了”<strong>Interval join</strong>“的语义，按照指定字段以及<strong>右流相对左流偏移的时间区间</strong>进行关联，即：</p>
<blockquote>
<p>$right.timestamp ∈ [left.timestamp + lowerBound; left.timestamp + upperBound]$</p>
</blockquote>
<p><img src="vx_images/4903841188593.png"></p>
<p>interval join也是inner join，虽然不需要开窗，但是需要用户指定偏移区间的上下界，并且<strong>只支持事件时间</strong>。</p>
<p>示例代码如下。注意在运行之前，需要分别在两个流上应用assignTimestampsAndWatermarks()方法获取事件时间戳和水印。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">clickRecordStream</span><br><span class="line">  .keyBy(record -&gt; record.getMerchandiseId())</span><br><span class="line">  .intervalJoin(orderRecordStream.keyBy(record -&gt; record.getMerchandiseId()))</span><br><span class="line">  .between(Time.seconds(-<span class="number">30</span>), Time.seconds(<span class="number">30</span>))</span><br><span class="line">  .process(<span class="keyword">new</span> ProcessJoinFunction&lt;AnalyticsAccessLogRecord, OrderDoneLogRecord, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(AnalyticsAccessLogRecord accessRecord, OrderDoneLogRecord orderRecord, Context context, Collector&lt;String&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">      collector.collect(StringUtils.join(Arrays.asList(</span><br><span class="line">        accessRecord.getMerchandiseId(),</span><br><span class="line">        orderRecord.getPrice(),</span><br><span class="line">        orderRecord.getCouponMoney(),</span><br><span class="line">        orderRecord.getRebateAmount()</span><br><span class="line">      ), <span class="string">&#x27;\t&#x27;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">  .print().setParallelism(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>由上可见，interval join与window join不同，是两个KeyedStream之上的操作，并且需要调用between()方法指定偏移区间的上下界。如果想令上下界是开区间，可以调用upperBoundExclusive()/lowerBoundExclusive()方法。</p>
<h3 id="interval-join的实现原理"><a href="#interval-join的实现原理" class="headerlink" title="interval join的实现原理"></a>interval join的实现原理</h3><p>以下是KeyedStream.process(ProcessJoinFunction)方法调用的重载方法的逻辑。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;OUT&gt; <span class="function">SingleOutputStreamOperator&lt;OUT&gt; <span class="title">process</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        ProcessJoinFunction&lt;IN1, IN2, OUT&gt; processJoinFunction,</span></span></span><br><span class="line"><span class="function"><span class="params">        TypeInformation&lt;OUT&gt; outputType)</span> </span>&#123;</span><br><span class="line">    Preconditions.checkNotNull(processJoinFunction);</span><br><span class="line">    Preconditions.checkNotNull(outputType);</span><br><span class="line">    <span class="keyword">final</span> ProcessJoinFunction&lt;IN1, IN2, OUT&gt; cleanedUdf = left.getExecutionEnvironment().clean(processJoinFunction);</span><br><span class="line">    <span class="keyword">final</span> IntervalJoinOperator&lt;KEY, IN1, IN2, OUT&gt; operator =</span><br><span class="line">        <span class="keyword">new</span> IntervalJoinOperator&lt;&gt;(</span><br><span class="line">            lowerBound,</span><br><span class="line">            upperBound,</span><br><span class="line">            lowerBoundInclusive,</span><br><span class="line">            upperBoundInclusive,</span><br><span class="line">            left.getType().createSerializer(left.getExecutionConfig()),</span><br><span class="line">            right.getType().createSerializer(right.getExecutionConfig()),</span><br><span class="line">            cleanedUdf</span><br><span class="line">        );</span><br><span class="line">    <span class="keyword">return</span> left</span><br><span class="line">        .connect(right)</span><br><span class="line">        .keyBy(keySelector1, keySelector2)</span><br><span class="line">        .transform(<span class="string">&quot;Interval Join&quot;</span>, outputType, operator);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见是先对两条流执行connect()和keyBy()操作，然后利用IntervalJoinOperator算子进行转换。在IntervalJoinOperator中，会利用两个MapState分别缓存左流和右流的数据。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> MapState&lt;Long, List&lt;BufferEntry&lt;T1&gt;&gt;&gt; leftBuffer;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> MapState&lt;Long, List&lt;BufferEntry&lt;T2&gt;&gt;&gt; rightBuffer;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(StateInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.initializeState(context);</span><br><span class="line">    <span class="keyword">this</span>.leftBuffer = context.getKeyedStateStore().getMapState(<span class="keyword">new</span> MapStateDescriptor&lt;&gt;(</span><br><span class="line">        LEFT_BUFFER,</span><br><span class="line">        LongSerializer.INSTANCE,</span><br><span class="line">        <span class="keyword">new</span> ListSerializer&lt;&gt;(<span class="keyword">new</span> BufferEntrySerializer&lt;&gt;(leftTypeSerializer))</span><br><span class="line">    ));</span><br><span class="line">    <span class="keyword">this</span>.rightBuffer = context.getKeyedStateStore().getMapState(<span class="keyword">new</span> MapStateDescriptor&lt;&gt;(</span><br><span class="line">        RIGHT_BUFFER,</span><br><span class="line">        LongSerializer.INSTANCE,</span><br><span class="line">        <span class="keyword">new</span> ListSerializer&lt;&gt;(<span class="keyword">new</span> BufferEntrySerializer&lt;&gt;(rightTypeSerializer))</span><br><span class="line">    ));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中<code>Long</code>表示事件时间戳，<code>List&lt;BufferEntry&lt;T&gt;&gt;</code>表示该时刻到来的数据记录。</p>
<p>当左流和右流有数据到达时，会分别调用<code>processElement1()</code>和<code>processElement2()</code>方法，它们都调用了<code>processElement()</code>方法，代码如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement1</span><span class="params">(StreamRecord&lt;T1&gt; record)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    processElement(record, leftBuffer, rightBuffer, lowerBound, upperBound, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement2</span><span class="params">(StreamRecord&lt;T2&gt; record)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    processElement(record, rightBuffer, leftBuffer, -upperBound, -lowerBound, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="keyword">private</span> &lt;THIS, OTHER&gt; <span class="function"><span class="keyword">void</span> <span class="title">processElement</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> StreamRecord&lt;THIS&gt; record,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> MapState&lt;Long, List&lt;IntervalJoinOperator.BufferEntry&lt;THIS&gt;&gt;&gt; ourBuffer,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> MapState&lt;Long, List&lt;IntervalJoinOperator.BufferEntry&lt;OTHER&gt;&gt;&gt; otherBuffer,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> <span class="keyword">long</span> relativeLowerBound,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> <span class="keyword">long</span> relativeUpperBound,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> <span class="keyword">boolean</span> isLeft)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> THIS ourValue = record.getValue();</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> ourTimestamp = record.getTimestamp();</span><br><span class="line">    <span class="keyword">if</span> (ourTimestamp == Long.MIN_VALUE) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FlinkException(<span class="string">&quot;Long.MIN_VALUE timestamp: Elements used in &quot;</span> +</span><br><span class="line">                <span class="string">&quot;interval stream joins need to have timestamps meaningful timestamps.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (isLate(ourTimestamp)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    addToBuffer(ourBuffer, ourValue, ourTimestamp);</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Long, List&lt;BufferEntry&lt;OTHER&gt;&gt;&gt; bucket: otherBuffer.entries()) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> timestamp  = bucket.getKey();</span><br><span class="line">        <span class="keyword">if</span> (timestamp &lt; ourTimestamp + relativeLowerBound ||</span><br><span class="line">                timestamp &gt; ourTimestamp + relativeUpperBound) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (BufferEntry&lt;OTHER&gt; entry: bucket.getValue()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (isLeft) &#123;</span><br><span class="line">                collect((T1) ourValue, (T2) entry.element, ourTimestamp, timestamp);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                collect((T1) entry.element, (T2) ourValue, timestamp, ourTimestamp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">long</span> cleanupTime = (relativeUpperBound &gt; <span class="number">0L</span>) ? ourTimestamp + relativeUpperBound : ourTimestamp;</span><br><span class="line">    <span class="keyword">if</span> (isLeft) &#123;</span><br><span class="line">        internalTimerService.registerEventTimeTimer(CLEANUP_NAMESPACE_LEFT, cleanupTime);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        internalTimerService.registerEventTimeTimer(CLEANUP_NAMESPACE_RIGHT, cleanupTime);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码的思路是：</p>
<ol>
<li> 取得当前流<code>StreamRecord</code>的时间戳，调用<code>isLate()</code>方法判断它是否是迟到数据（即时间戳小于当前水印值），如是则丢弃。</li>
<li> 调用<code>addToBuffer()</code>方法，将时间戳和数据一起插入当前流对应的<code>MapState</code>。</li>
<li> 遍历另外一个流的<code>MapState</code>，如果数据满足前述的时间区间条件，则调用<code>collect()</code>方法将该条数据投递给用户定义的<code>ProcessJoinFunction</code>进行处理。<br><code>collect()</code>方法的代码如下，注意结果对应的时间戳是左右流时间戳里较大的那个。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">collect</span><span class="params">(T1 left, T2 right, <span class="keyword">long</span> leftTimestamp, <span class="keyword">long</span> rightTimestamp)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> resultTimestamp = Math.max(leftTimestamp, rightTimestamp);</span><br><span class="line">    collector.setAbsoluteTimestamp(resultTimestamp);</span><br><span class="line">    context.updateTimestamps(leftTimestamp, rightTimestamp, resultTimestamp);</span><br><span class="line">    userFunction.processElement(left, right, context, collector);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="4">
<li> 调用<code>TimerService.registerEventTimeTimer()</code>注册时间戳为<code>timestamp + relativeUpperBound</code>的定时器，该定时器负责在水印超过区间的上界时执行状态的清理逻辑，防止数据堆积。注意左右流的定时器所属的<code>namespace</code>是不同的，具体逻辑则位于<code>onEventTime()</code>方法中。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onEventTime</span><span class="params">(InternalTimer&lt;K, String&gt; timer)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> timerTimestamp = timer.getTimestamp();</span><br><span class="line">    String namespace = timer.getNamespace();</span><br><span class="line">    logger.trace(<span class="string">&quot;onEventTime @ &#123;&#125;&quot;</span>, timerTimestamp);</span><br><span class="line">    <span class="keyword">switch</span> (namespace) &#123;</span><br><span class="line">        <span class="keyword">case</span> CLEANUP_NAMESPACE_LEFT: &#123;</span><br><span class="line">            <span class="keyword">long</span> timestamp = (upperBound &lt;= <span class="number">0L</span>) ? timerTimestamp : timerTimestamp - upperBound;</span><br><span class="line">            logger.trace(<span class="string">&quot;Removing from left buffer @ &#123;&#125;&quot;</span>, timestamp);</span><br><span class="line">            leftBuffer.remove(timestamp);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">case</span> CLEANUP_NAMESPACE_RIGHT: &#123;</span><br><span class="line">            <span class="keyword">long</span> timestamp = (lowerBound &lt;= <span class="number">0L</span>) ? timerTimestamp + lowerBound : timerTimestamp;</span><br><span class="line">            logger.trace(<span class="string">&quot;Removing from right buffer @ &#123;&#125;&quot;</span>, timestamp);</span><br><span class="line">            rightBuffer.remove(timestamp);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Invalid namespace &quot;</span> + namespace);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="broadcast-join"><a href="#broadcast-join" class="headerlink" title="broadcast join"></a>broadcast join</h2>]]></content>
  </entry>
  <entry>
    <title>flink任务提交</title>
    <url>/bigdata/Flink/Flink-job-submit/</url>
    <content><![CDATA[<h1 id="Flink-任务提交"><a href="#Flink-任务提交" class="headerlink" title="Flink-任务提交"></a>Flink-任务提交</h1><h2 id="flink-on-zeppelin"><a href="#flink-on-zeppelin" class="headerlink" title="flink on zeppelin"></a>flink on zeppelin</h2><p><code>org.apache.zeppelin.flink.FlinkScalaInterpreter</code></p>
<h2 id="flink-on-yarn"><a href="#flink-on-yarn" class="headerlink" title="flink on yarn"></a>flink on yarn</h2><p>命令行提交方式</p>
<p><img src="_v_images/20200713162403351_1965495978.png"></p>
<h3 id="yarn-per-job"><a href="#yarn-per-job" class="headerlink" title="yarn per-job"></a>yarn per-job</h3><h4 id="单任务Attach模式"><a href="#单任务Attach模式" class="headerlink" title="单任务Attach模式"></a>单任务Attach模式</h4><p>默认是 Attach 模式，即客户端会一直等待直到程序结束才会退出。</p>
<p>通过 -m yarn-cluster 指定 Yarn 模式</p>
<p>Yarn 上显示名字为 Flink session cluster，这个 Batch 的 Wordcount 任务运行完会 FINISHED。</p>
<h4 id="单任务Detached模式"><a href="#单任务Detached模式" class="headerlink" title="单任务Detached模式"></a>单任务Detached模式</h4><p>由于是 Detached 模式，客户端提交完任务就退出了</p>
<p>Yarn 上显示为 Flink per-job cluster</p>
<h3 id="yarn-session"><a href="#yarn-session" class="headerlink" title="yarn session"></a>yarn session</h3><p>也有attach和detached模式的区分</p>
<p>Flink run 方式提交（推荐模式）</p>
<p>yarn session需要先启动一个集群，然后在提交作业。<br>对于Flink run直接提交作业就相对比较简单，不需要额外的去启动一个集群，直接提交作业，即可完成Flink作业。<br>命令： bin/flink run -m yarn-cluster examples/batch/WordCount.jar，注意使用参数-m yarn-cluster提交到yarn集群。</p>
<h3 id="application-mode"><a href="#application-mode" class="headerlink" title="application mode"></a>application mode</h3><p>应用程序的main方法在jobManager上运行，创建仅仅在特定应用程序的作业之间共享的会话集群，在应用程序完成时终止。</p>
<h2 id="提交任务到yarn并监控任务运行情况"><a href="#提交任务到yarn并监控任务运行情况" class="headerlink" title="提交任务到yarn并监控任务运行情况"></a>提交任务到yarn并监控任务运行情况</h2><p>./flink run -m yarn-cluster -p 4 -yjm 1024m -ytm 1096m -ynm 1  ../examples/batch/WordCount.jar</p>
<p>./flink run-application -t yarn-application ../examples/batch/WordCount.jar</p>
<p>指定application name为1</p>
<p>然后通过yarn-rest-api拿取任务信息</p>
<p>【参考文献】</p>
<ol>
<li><a href="https://www.cnblogs.com/asker009/p/11327533.html">flink on yarn模式下两种提交job方式</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink:指标监控</title>
    <url>/bigdata/Flink/Flink-metrics/</url>
    <content><![CDATA[<h1 id="flink-metrics"><a href="#flink-metrics" class="headerlink" title="flink-metrics"></a>flink-metrics</h1><p>[参考文献]</p>
<ul>
<li><a href="https://blog.csdn.net/qq_21653785/article/details/79625601">Flink源码系列-指标监控</a></li>
<li><a href="https://www.cnblogs.com/0x12345678/p/10561039.html">自定义metric-report</a></li>
<li><a href="http://www.mamicode.com/info-detail-2317943.html">深入理解Flink之metrics</a></li>
<li><a href="https://my.oschina.net/go4it/blog/3023586">聊聊Flink的MertricsQueryServiceGateway</a></li>
<li><a href="https://www.jianshu.com/p/e50586fff515">Flink指标</a></li>
</ul>
<p>Flink Metrics是通过引入<code>com.codahale.metrics</code>包实现的，它将收集的metrics分为四大类：<code>Counter</code>，<code>Gauge</code>，<code>Histogram</code>和<code>Meter</code>下面分别说明：</p>
<ul>
<li><code>Counter计数器</code><br>  用来统计一个metrics的总量。<br>  拿flink中的指标来举例，像Task/Operator中的numRecordsIn（此task或者operator接收到的record总量）和numRecordsOut（此task或者operator发送的record总量）就属于Counter。</li>
<li><code>Gauge指标值</code><br>  用来记录一个metrics的瞬间值。<br>  拿flink中的指标举例，像JobManager或者TaskManager中的<code>JVM.Heap.Used</code>就属于<code>Gauge</code>，记录某个时刻JobManager或者TaskManager所在机器的JVM堆使用量。</li>
<li><code>Histogram直方图</code><br>  有的时候我们不满足于只拿到metrics的总量或者瞬时值，当想得到metrics的最大值，最小值，中位数等信息时，我们就能用到Histogram了。<br>  Flink中属于Histogram的指标很少，但是最重要的一个是属于operator的latency。此项指标会记录数据处理的延迟信息，对任务监控起到很重要的作用。</li>
<li><code>Meter平均值</code><br>   用来记录一个metrics某个时间段内平均值。<br>   flink中类似指标有task/operator中的numRecordsInPerSecond，字面意思就可以理解，指的是此task或者operator每秒接收的记录数。</li>
</ul>
<h3 id="com-tencent-oceanus-metastore-metrics-CustomMetricsRegistry"><a href="#com-tencent-oceanus-metastore-metrics-CustomMetricsRegistry" class="headerlink" title="com.tencent.oceanus.metastore.metrics.CustomMetricsRegistry"></a>com.tencent.oceanus.metastore.metrics.CustomMetricsRegistry</h3><h3 id="org-apache-flink-metrics-MeterView"><a href="#org-apache-flink-metrics-MeterView" class="headerlink" title="org.apache.flink.metrics.MeterView"></a>org.apache.flink.metrics.MeterView</h3>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink runtime</title>
    <url>/bigdata/Flink/Flink-runtime/</url>
    <content><![CDATA[<h1 id="Flink-runtime运行时"><a href="#Flink-runtime运行时" class="headerlink" title="Flink-runtime运行时"></a>Flink-runtime运行时</h1><h2 id="Task-share"><a href="#Task-share" class="headerlink" title="Task share"></a>Task share</h2><h2 id="Chain"><a href="#Chain" class="headerlink" title="Chain"></a>Chain</h2><p>【参考文献】</p>
<ol>
<li><a href="https://www.infoq.cn/article/RWTM9o0SHHV3Xr8o8giT">Apache Flink进阶一: Runtime核心机制剖析</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink asyncIO</title>
    <url>/bigdata/Flink/Flink-syncIO/</url>
    <content><![CDATA[<h1 id="Flink-asyncIO"><a href="#Flink-asyncIO" class="headerlink" title="Flink-asyncIO"></a>Flink-asyncIO</h1><p> <img src="_v_images/20201207210251979_867932479.png"></p>
<p>阿里贡献给flink的，优点就不说了嘛，官网上都有，就是写库不会阻塞性能更好</p>
<p>然后来看一下， Flink 中异步io主要分为两种</p>
<p>　　一种是有序Ordered</p>
<p>　　一种是无序UNordered</p>
<p>主要区别是往下游output的顺序（注意这里顺序不是写库的顺序既然都异步了写库的顺序自然是无法保证的），有序的会按接收的顺序继续往下游output发送，无序就是谁先处理完谁就先往下游发送</p>
<p>两张图了解这两种模式的实现</p>
<p> <img src="_v_images/20201207210251873_2096107056.png"></p>
<p>有序：record数据会通过异步线程写库，Emitter是一个守护进程，会不停的拉取queue头部的数据，如果头部的数据异步写库完成，Emitter将头数据往下游发送，如果头元素还没有异步写库完成，柱塞 <img src="_v_images/20201207210251766_1309898873.png">     </p>
<p>无序：record数据会通过异步线程写库，这里有两个queue,一开始放在uncompleteedQueue，当哪个record异步写库成功后就直接放到completedQueue中，Emitter是一个守护进程，completedQueue只要有数据，会不停的拉取queue数据往下游发送 </p>
<p>可以看到原理还是很简单的，两句话就总结完了，就是利用queue和java的异步线程，现在来看下源码</p>
<p>这里AsyncIO在Flink中被设计成operator中的一种，自然去OneInputStreamOperator的实现类中去找</p>
<p>于是来看一下AsyncWaitOperator.java</p>
<p>　　<img src="_v_images/20201207210251559_1488153726.png"></p>
<p>看到它的open方法（open方法会在taskmanager启动job的时候全部统一调用，可以翻一下以前的文章）</p>
<p>这里启动了一个守护线程Emitter,来看下线程具体做了什么</p>
<p> <img src="_v_images/20201207210251351_312304785.png"></p>
<p> 1处拉取数据，2处就是常规的将拉取到的数据往下游emit，Emitter拉取数据，这里先不讲因为分为有序的和无序的</p>
<p> 这里已经知道了这个Emitter的作用是循环的拉取数据往下游发送</p>
<p> 回到AsyncWaitOperator.java在它的open方法初始化了Emitter,那它是如何处理接收到的数据的呢，看它的ProcessElement（）方法</p>
<p> <img src="_v_images/20201207210251144_1378849400.png"></p>
<pre><code>![](_v_images/20201207210250637_60325951.png)</code></pre>
<p> <img src="_v_images/20201207210250031_255901575.png"></p>
<p> 其实主要就是三个个方法</p>
<p>先是！！！将record封装成了一个包装类StreamRecordQueueEntry，主要是这个包装类的构造方法中,创建了一个CompleteableFuture(这个的complete方法其实会等到用户代码执行的时候用户自己决定什么时候完成）</p>
<p>1处主要就是讲元素加入到了对应的queue,这里也分为两种有序和无序的</p>
<p> <img src="_v_images/20201207210249826_218236941.png"></p>
<p>这里也先不讲这两种模式加入数据的区别</p>
<p>接着2处就是调用用户的代码了，来看看官网的异步io的例子</p>
<p> <img src="_v_images/20201207210249221_1218191589.png"></p>
<p> 给了一个Future作为参数，用户自己起了一个线程（这里思考一下就知道了为什么要新起一个异步线程去执行，因为如果不起线程的话，那processElement方法就柱塞了，无法异步了）去写库读库等，然后调用了这个参数的complete方法（也就是前面那个包装类中的CompleteableFuture）并且传入了一个结果</p>
<p>看下complete方法源码</p>
<p> <img src="_v_images/20201207210248614_1185315462.png"></p>
<p> 这个resultFuture是每个record的包装类StreamRecordQueueEntry的其中一个属性是一个CompletableFuture</p>
<p> 那现在就清楚了，用户代码在自己新起的线程中当自己的逻辑执行完以后会使这个异步线程结束，并输入一个结果</p>
<p> 那这个干嘛用的呢</p>
<p>最开始的图中看到有序和无序实现原理，有序用一个queue,无序用两个queue分别就对应了</p>
<p>OrderedStreamElementQueue类中</p>
<p> <img src="_v_images/20201207210248409_107213650.png"></p>
<p> UnorderedStreamElementQueue类中</p>
<p> <img src="_v_images/20201207210248304_1712699416.png"></p>
<p>回到前面有两个地方没有细讲，一是两种模式的Emitter是如何拉取数据的，二是两种模式下数据是如何加入OrderedStreamElementQueue的</p>
<p>有序模式：</p>
<p>1.先来看一下有序模式的，Emitter的数据拉取，和数据的加入</p>
<p>　　　　其tryPut（）方法</p>
<p>　　　　  <img src="_v_images/20201207210248099_682570540.png"></p>
<p> 　　　  <img src="_v_images/20201207210247594_534665308.png"></p>
<p> 　　　　<em>onComplete**方法</em></p>
<p>　　　　　　　<em><img src="_v_images/20201207210247288_2059500658.png"></em></p>
<pre><code>   onCompleteHandler方法</code></pre>
<p>　　　　  　<img src="_v_images/20201207210247082_286767362.png">　</p>
<p>　　这里比较绕，先将接收的数据加入queue中，然后onComplete()中当上一个异步线程getFuture() 其实就是每个元素包装类里面的那个CompletableFuture,当他结束时（会在用户方法用户调用complete时结束）异步调用传入的对象的 accept方法，accept方法中调用了onCompleteHandler（）方法，onCompleteHandler方法中会判断queue是否为空，以及queue的头元素是否完成了用户的异步方法，当完成的时候，就会将headIsCompleted这个对象signalAll（）唤醒</p>
<p>2.接着看有序模式Emitter的拉取数据</p>
<pre><code>   ![](_v_images/20201207210246482_1132368562.png)</code></pre>
<p>   这里有序方式拉取数据的逻辑很清晰，如果为空或者头元素没有完成用户的异步方法，headIsCompleted这个对象会wait住（上面可以知道，当加入元素的到queue且头元素完成异步方法的时候会signalAll（））然后将头数据返回，往下游发送</p>
<p>这样就实现了有序发送，因为Emitter只拉取头元素且已经完成用户异步方法的头元素</p>
<p>无序模式： </p>
<p>　　这里和有序模式就大同小异了，只是变成了,接收数据后直接加入uncompletedQueue，当数据完成异步方法的时候就，放到completedQueue里面去并signalAll（），只要completedqueue里面有数据，Emitter就拉取往下发</p>
<p>这样就实现了无序模式，也就是异步写入谁先处理完就直接放到完成队列里面去，然后往下发，不用管接收数据的顺序</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink:时间</title>
    <url>/bigdata/Flink/Flink-time/</url>
    <content><![CDATA[<h1 id="Flink-Time"><a href="#Flink-Time" class="headerlink" title="Flink Time"></a>Flink Time</h1><p>![北京时间](_v_images/20190731222505723_213254839.png =968x)</p>
<blockquote>
<p>划定时间窗口和时间戳以毫秒为单位</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">eventStream.assignTimestampsAndWatermarks(assigner = <span class="keyword">new</span> <span class="type">AscendingTimestampExtractor</span>[<span class="type">Event</span>]() &#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractAscendingTimestamp</span></span>(t: <span class="type">Event</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">    t.getTime * <span class="number">1000</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="processFunction中的时间"><a href="#processFunction中的时间" class="headerlink" title="processFunction中的时间"></a>processFunction中的时间</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="type">ProcessFunction</span>[<span class="type">Event</span>, (<span class="type">String</span>, <span class="type">Long</span>)] &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(event: <span class="type">Event</span>, context: <span class="type">ProcessFunction</span>[<span class="type">Event</span>,</span><br><span class="line">          (<span class="type">String</span>, <span class="type">Long</span>)]#<span class="type">Context</span>, collector: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Long</span>)]): <span class="type">Unit</span> = &#123;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">context.timestamp&#x3D;1565064599999</span><br><span class="line">context.timerService().currentWatermark()&#x3D;-9223372036854775808</span><br><span class="line">context.timerService().currentProcessingTime()&#x3D;1565064607343</span><br><span class="line"></span><br><span class="line">Event(time&#x3D;1565064350, count&#x3D;9, url&#x3D;&#x2F;apply&#x2F;main, channelId&#x3D;1057)</span><br></pre></td></tr></table></figure>
<p>以事件事件，窗口大小5min</p>
<p>一条消息，事件的时间是 1565064350(2019-08-06 12:05:50)<br><code>Context.timestamp</code>是1565064599999(2019-08-06 12:09:59), 可以理解为窗口结束的时间<br><code>context.timerService().currentWatermark()</code> 莫名其妙，这么大<br><code>context.timerService().currentProcessingTime()</code>是当前处理事件 2019-08-06 12:10:07</p>
<h3 id="Context-timestamp"><a href="#Context-timestamp" class="headerlink" title="Context.timestamp"></a><code>Context.timestamp</code></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Timestamp of the element currently being processed or timestamp of a firing timer.</span><br><span class="line">This might be &#123;<span class="meta">@code</span> <span class="keyword">null</span>&#125;, <span class="keyword">for</span> example <span class="keyword">if</span> the time characteristic of your program</span><br></pre></td></tr></table></figure>

<h2 id="时间戳timestamp与水印watermark"><a href="#时间戳timestamp与水印watermark" class="headerlink" title="时间戳timestamp与水印watermark"></a>时间戳timestamp与水印watermark</h2><p>提取Timestamp与生成Watermark一般步骤</p>
<ol>
<li>设置时间特性为Event Time。<code>StreamExecutionEnvironment#setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</code>。</li>
<li>在Source后Window前用<code>DataStream#assignTimestampsAndWatermarks</code>方法(<code>AssignerWithPeriodicWatermarks</code>或<code>AssignerWithPunctuatedWatermarks</code>)提取时间戳并生成水印。</li>
<li>重写<code>extractTimestamp</code>方法提取Timestamp，重写<code>getCurrentWatermark</code>方法或<code>checkAndGetNextWatermark</code>方法生成水印。</li>
</ol>
<h3 id="数据源中指定"><a href="#数据源中指定" class="headerlink" title="数据源中指定"></a>数据源中指定</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExampleSourceFunction</span> <span class="keyword">implements</span> <span class="title">SourceFunction</span>&lt;<span class="title">Tuple4</span>&lt;<span class="title">String</span>,<span class="title">Long</span>,<span class="title">String</span>,<span class="title">Integer</span>&gt;&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;Tuple4&lt;String,Long,String,Integer&gt;&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (isRunning)&#123;</span><br><span class="line">                <span class="comment">// 构造测试数据</span></span><br><span class="line">                ....</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 发出一条数据以及数据对应的Timestamp</span></span><br><span class="line">                ctx.collectWithTimestamp(record,eventTime);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 发出一条Watermark</span></span><br><span class="line">                ctx.emitWatermark(<span class="keyword">new</span> Watermark(eventTime - maxOutOfOrderness));</span><br><span class="line"></span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            isRunning = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>时间戳和水位线分别通过两个方法实现的</p>
<h3 id="时间戳的抽取方法"><a href="#时间戳的抽取方法" class="headerlink" title="时间戳的抽取方法"></a>时间戳的抽取方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 传入了两个参数，第二个参数是上一个时间戳，元素的当前内部时间戳，如果尚未分配时间戳，则为负值。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element, <span class="keyword">long</span> recordTimestamp)</span></span>;</span><br></pre></td></tr></table></figure>

<h3 id="周期性水印"><a href="#周期性水印" class="headerlink" title="周期性水印"></a>周期性水印</h3><p>分配器为元素分配事件时间时间戳，并生成表示流中事件时间进度的低水位线。这些时间戳和水印由对事件时间进行操作的函数和运算符使用，例如事件时间窗口。<br>使用此类以周期性间隔生成水印。最多每隔I毫秒(通过<code>ExecutionConfig.getautowerMarkinterval()</code>)配置一次，系统将调用<code>getCurrentWatermark()</code>方法来探测下一个水印值。<br>如果探测到的值为非空，并且时间戳大于前一个水印的时间戳，系统将生成新的水印(以保留升序水印的约定)。 如果自上次调用<code>getCurrentWatermark()</code>方法后没有新元素到达，系统调用该方法的频率可能会低于每I毫秒一次。<br>时间戳和水印被定义为代表自纪元(世界协调时1970年1月1日午夜)以来的毫秒的长度。某个值为t的水印表示不会再出现带有事件时间戳x的元素，其中x小于或等于t。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 返回当前水印。系统定期调用此方法来检索当前水印。该方法可能返回空值，表示没有新的水印可用。</span></span><br><span class="line"><span class="comment">* 只有当返回的水印为非空且其时间戳大于之前发出的水印的时间戳时，才会发出该水印(以保留升序水印的约定)。</span></span><br><span class="line"><span class="comment">* 如果当前水印仍然与前一个相同，则自上一次调用此方法以来，事件时间没有任何进展。如果返回空值，或者返回的水印的时间戳小于上次发出的时间戳，则不会生成新的水印。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">Watermark  AssignerWithPeriodicWatermarks.getCurrentWatermark()</span><br></pre></td></tr></table></figure>
<h3 id="非连续性水印"><a href="#非连续性水印" class="headerlink" title="非连续性水印"></a>非连续性水印</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 询问此实现是否要发出水印。这个方法是在extractTimestamp(对象，长)方法之后调用的。</span></span><br><span class="line"><span class="comment">* 只有当返回的水印为非空且其时间戳大于之前发出的水印的时间戳时，才会发出该水印(以保留升序水印的约定)。</span></span><br><span class="line"><span class="comment">* 如果返回空值，或者返回的水印的时间戳小于上次发出的时间戳，则不会生成新的水印。 有关如何使用此方法的示例，请参见此类的分配器带标点水印的文档。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">Watermark AssignerWithPunctuatedWatermarks.checkAndGetNextWatermark(T lastElement, <span class="keyword">long</span> extractedTimestamp)</span><br></pre></td></tr></table></figure>


<p><img src="_v_images/20201207105022608_1990981860.png"></p>
<h3 id="升序水印-AscendingTimestampExtractor"><a href="#升序水印-AscendingTimestampExtractor" class="headerlink" title="升序水印 AscendingTimestampExtractor"></a>升序水印 AscendingTimestampExtractor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AscendingTimestampExtractor</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">AssignerWithPeriodicWatermarks</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/** The current timestamp. */</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">long</span> currentTimestamp = Long.MIN_VALUE;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/** Handler that is called when timestamp monotony is violated. */</span></span><br><span class="line">	<span class="keyword">private</span> MonotonyViolationHandler violationHandler = <span class="keyword">new</span> LoggingHandler();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Extracts the timestamp from the given element. The timestamp must be monotonically increasing.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> element The element that the timestamp is extracted from.</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> The new timestamp.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(T element)</span></span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Sets the handler for violations to the ascending timestamp order.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> handler The violation handler to use.</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> This extractor.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> AscendingTimestampExtractor&lt;T&gt; <span class="title">withViolationHandler</span><span class="params">(MonotonyViolationHandler handler)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.violationHandler = requireNonNull(handler);</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// ------------------------------------------------------------------------</span></span><br><span class="line">    <span class="comment">// 调用</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element, <span class="keyword">long</span> elementPrevTimestamp)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">final</span> <span class="keyword">long</span> newTimestamp = extractAscendingTimestamp(element);</span><br><span class="line">		<span class="keyword">if</span> (newTimestamp &gt;= <span class="keyword">this</span>.currentTimestamp) &#123;</span><br><span class="line">			<span class="keyword">this</span>.currentTimestamp = newTimestamp;</span><br><span class="line">			<span class="keyword">return</span> newTimestamp;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			violationHandler.handleViolation(newTimestamp, <span class="keyword">this</span>.currentTimestamp);</span><br><span class="line">			<span class="keyword">return</span> newTimestamp;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Watermark <span class="title">getCurrentWatermark</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> Watermark(currentTimestamp == Long.MIN_VALUE ? Long.MIN_VALUE : currentTimestamp - <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AscendingTimestampExtractor抽象类实现了ssignerWithPeriodicWatermarks接口的extractTimestamp及getCurrentWatermark方法，同时声明抽象方法extractAscendingTimestamp供子类实现<br>水印的生产策略为：getCurrentWatermark 方法在currentTimestamp不为Long.MIN_VALUE时返回Watermark(currentTimestamp - 1)</p>
<p>综上：<br>发现AscendingTimestampExtractor适用于elements的时间在每个并行task里面事单调递增的，（timestamp monotony）数据场景。</p>
<h3 id="无序水印-BoundedOutOfOrdernessTimestampExtractor"><a href="#无序水印-BoundedOutOfOrdernessTimestampExtractor" class="headerlink" title="无序水印 BoundedOutOfOrdernessTimestampExtractor"></a>无序水印 BoundedOutOfOrdernessTimestampExtractor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BoundedOutOfOrdernessTimestampExtractor</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">AssignerWithPeriodicWatermarks</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/** The current maximum timestamp seen so far. */</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">long</span> currentMaxTimestamp;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/** The timestamp of the last emitted watermark. */</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">long</span> lastEmittedWatermark = Long.MIN_VALUE;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * The (fixed) interval between the maximum seen timestamp seen in the records</span></span><br><span class="line"><span class="comment">	 * and that of the watermark to be emitted.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> maxOutOfOrderness;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">BoundedOutOfOrdernessTimestampExtractor</span><span class="params">(Time maxOutOfOrderness)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (maxOutOfOrderness.toMilliseconds() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Tried to set the maximum allowed &quot;</span> +</span><br><span class="line">				<span class="string">&quot;lateness to &quot;</span> + maxOutOfOrderness + <span class="string">&quot;. This parameter cannot be negative.&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">this</span>.maxOutOfOrderness = maxOutOfOrderness.toMilliseconds();</span><br><span class="line">		<span class="keyword">this</span>.currentMaxTimestamp = Long.MIN_VALUE + <span class="keyword">this</span>.maxOutOfOrderness;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getMaxOutOfOrdernessInMillis</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> maxOutOfOrderness;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Extracts the timestamp from the given element.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> element The element that the timestamp is extracted from.</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> The new timestamp.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element)</span></span>;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Watermark <span class="title">getCurrentWatermark</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">// this guarantees that the watermark never goes backwards.</span></span><br><span class="line">		<span class="keyword">long</span> potentialWM = currentMaxTimestamp - maxOutOfOrderness;</span><br><span class="line">		<span class="keyword">if</span> (potentialWM &gt;= lastEmittedWatermark) &#123;</span><br><span class="line">			lastEmittedWatermark = potentialWM;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> Watermark(lastEmittedWatermark);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element, <span class="keyword">long</span> previousElementTimestamp)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">long</span> timestamp = extractTimestamp(element);</span><br><span class="line">		<span class="keyword">if</span> (timestamp &gt; currentMaxTimestamp) &#123;</span><br><span class="line">			currentMaxTimestamp = timestamp;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> timestamp;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>BoundedOutOfOrdernessTimestampExtractor</code> 抽象类实现<code>AssignerWithPeriodicWatermarks</code>接口的<code>extractTimestamp及getCurrentWatermark</code>方法，同时声明抽象方法<code>extractAscendingTimestamp</code>供子类实现<br><code>BoundedOutOfOrdernessTimestampExtractor</code> 的构造器接收<code>maxOutOfOrderness</code>参数用于指定element允许滞后（<code>t</code>~`t_w<code>，</code>t<code>为element的eventTime，</code>t_w<code>为前一次watermark的时间）的最大时间，在计算窗口数据时，如果超过该值则会被忽略。 </code>BoundedOutOfOrdernessTimestampExtractor<code>的</code>extractTimestamp<code>方法会调用子类的</code>extractTimestamp<code>方法抽取时间，如果该时间大于</code>currentMaxTimestamp<code>，则更新</code>currentMaxTimestamp<code>； </code>getCurrentWatermark<code>先计算</code>potentialWM<code>，如果</code>potentialWM<code>大于等于</code>lastEmittedWatermark<code>则更新</code>lastEmittedWatemakr<code>(</code>currentMaxTimestamp - lastEmittedWatermark &gt;= maxOutOfOrderness<code>， 这里表示</code>lastEmittedWatermark<code>太小了，所以差值超过了</code>maxOutOfOrderness<code>，因此会调大</code>lastEmittedWatermark<code>)，最后返回</code>watermark` </p>
<p>具体逻辑参考：就是判断如果新的水印时间大于上次最后一次发出水印时间，选择新的水印时间，否则选择上次最后发送水印时间戳</p>
<h3 id="TimeStamp分配器和Watermark生成器-Timestamp-Assigners-Watermark-Generators"><a href="#TimeStamp分配器和Watermark生成器-Timestamp-Assigners-Watermark-Generators" class="headerlink" title="TimeStamp分配器和Watermark生成器(Timestamp Assigners / Watermark Generators)"></a>TimeStamp分配器和Watermark生成器(Timestamp Assigners / Watermark Generators)</h3><h2 id="数据延迟"><a href="#数据延迟" class="headerlink" title="数据延迟"></a>数据延迟</h2><p>主要的办法是给定一个允许延迟的时间，在该时间范围内仍可以接受处理延迟数据</p>
<p>设置允许延迟的时间是通过<code>allowedLateness(lateness: Time)</code>设置</p>
<p>保存延迟数据则是通过<code>sideOutputLateData(outputTag: OutputTag[T])</code>保存</p>
<p>获取延迟数据是通过<code>DataStream.getSideOutput(tag: OutputTag[X])</code>获取</p>
<h3 id="allowedLateness-lateness-Time"><a href="#allowedLateness-lateness-Time" class="headerlink" title="allowedLateness(lateness: Time)"></a>allowedLateness(lateness: Time)</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">allowedLateness</span></span>(lateness: <span class="type">Time</span>): <span class="type">WindowedStream</span>[<span class="type">T</span>, <span class="type">K</span>, <span class="type">W</span>] = &#123;</span><br><span class="line">    javaStream.allowedLateness(lateness)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法传入一个Time值，设置允许数据迟到的时间，这个时间和waterMark中的时间概念不同。再来回顾一下，</p>
<p>waterMark=数据的事件时间-允许乱序时间值</p>
<p>随着新数据的到来，waterMark的值会更新为最新数据事件时间-允许乱序时间值，但是如果这时候来了一条历史数据，waterMark值则不会更新。总的来说，waterMark是为了能接收到尽可能多的乱序数据。</p>
<p>那这里的Time值呢？主要是为了等待迟到的数据，在一定时间范围内，如果属于该窗口的数据到来，仍会进行计算，后面会对计算方式仔细说明</p>
<p><strong>allowedLateness 是等待数据进入窗口的最大时间，未进入的数据，可以通过偏流导出</strong></p>
<p>注意：该方法只针对于基于event-time的窗口，如果是基于processing-time，并且指定了非零的time值则会抛出异常</p>
<h3 id="sideOutputLateData-outputTag-OutputTag-T"><a href="#sideOutputLateData-outputTag-OutputTag-T" class="headerlink" title="sideOutputLateData(outputTag: OutputTag[T])"></a>sideOutputLateData(outputTag: OutputTag[T])</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sideOutputLateData</span></span>(outputTag: <span class="type">OutputTag</span>[<span class="type">T</span>]): <span class="type">WindowedStream</span>[<span class="type">T</span>, <span class="type">K</span>, <span class="type">W</span>] = &#123;</span><br><span class="line">    javaStream.sideOutputLateData(outputTag)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法是将迟来的数据保存至给定的outputTag参数，而OutputTag则是用来标记延迟数据的一个对象。</p>
<h3 id="DataStream-getSideOutput-tag-OutputTag-X"><a href="#DataStream-getSideOutput-tag-OutputTag-X" class="headerlink" title="DataStream.getSideOutput(tag: OutputTag[X])"></a>DataStream.getSideOutput(tag: OutputTag[X])</h3><p>通过window等操作返回的DataStream调用该方法，传入标记延迟数据的对象来获取延迟的数据</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">waterStream.keyBy(<span class="number">0</span>)</span><br><span class="line">      .window(<span class="type">TumblingEventTimeWindows</span>.of(<span class="type">Time</span>.seconds(<span class="number">5</span>L)))</span><br><span class="line">    </span><br><span class="line">      .allowedLateness(<span class="type">Time</span>.seconds(<span class="number">2</span>L))</span><br><span class="line">      .sideOutputLateData(lateData)</span><br><span class="line">      .apply(<span class="keyword">new</span> <span class="type">WindowFunction</span>[(<span class="type">String</span>, <span class="type">Long</span>), <span class="type">String</span>, <span class="type">Tuple</span>, <span class="type">TimeWindow</span>] &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(key: <span class="type">Tuple</span>, window: <span class="type">TimeWindow</span>, input: <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">Long</span>)], out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">          <span class="keyword">val</span> timeArr = <span class="type">ArrayBuffer</span>[<span class="type">String</span>]()</span><br><span class="line">          <span class="keyword">val</span> iterator = input.iterator</span><br><span class="line">          <span class="keyword">while</span> (iterator.hasNext) &#123;</span><br><span class="line">            <span class="keyword">val</span> tup2 = iterator.next()</span><br><span class="line">            timeArr.append(sdf.format(tup2._2))</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">val</span> outData = <span class="type">String</span>.format(<span class="string">&quot;key: %s    data: %s    startTime:  %s    endTime:  %s&quot;</span>,</span><br><span class="line">            key.toString,</span><br><span class="line">            timeArr.mkString(<span class="string">&quot;-&quot;</span>),</span><br><span class="line">            sdf.format(window.getStart),</span><br><span class="line">            sdf.format(window.getEnd))</span><br><span class="line">          out.collect(outData)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">    result.print(<span class="string">&quot;window计算结果:&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> late = result.getSideOutput(lateData)</span><br><span class="line">    late.print(<span class="string">&quot;迟到的数据:&quot;</span>)</span><br></pre></td></tr></table></figure>




<p>【参考文献】</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/103519313">Flink时间系列-EventTime下数据延迟处理</a></li>
<li><a href="https://www.infoq.cn/article/zvc15xotpp5x5brxhwuz">Flink: 时间属性深度解析</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink Timer</title>
    <url>/bigdata/Flink/Flink-timer/</url>
    <content><![CDATA[<h1 id="Timer"><a href="#Timer" class="headerlink" title="Timer"></a>Timer</h1><p>TimerService</p>
<h2 id="SystemProcessingTimeService"><a href="#SystemProcessingTimeService" class="headerlink" title="SystemProcessingTimeService"></a>SystemProcessingTimeService</h2><p>org.apache.flink.streaming.runtime.tasks.SystemProcessingTimeService</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>【草稿】FlinkKuduSink</title>
    <url>/bigdata/Flink/FlinkKuduSink/</url>
    <content><![CDATA[<h1 id="FlinkKuduSink"><a href="#FlinkKuduSink" class="headerlink" title="FlinkKuduSink"></a>FlinkKuduSink</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">org.apache.kudu.client.NonRecoverableException: Couldn<span class="string">&#x27;t find a valid master in (9.7.185.196:7050). Exceptions received: [org.apache.kudu.client.RpcRemoteException: [peer master-] server sent error Service unavailable: service kudu.master.MasterService not registered on TabletServer]</span></span><br><span class="line"><span class="string">	at org.apache.kudu.client.KuduException.transformException(KuduException.java:110)</span></span><br><span class="line"><span class="string">	at org.apache.kudu.client.KuduClient.joinAndHandleException(KuduClient.java:413)</span></span><br><span class="line"><span class="string">	at org.apache.kudu.client.KuduClient.tableExists(KuduClient.java:229)</span></span><br><span class="line"><span class="string">	at org.apache.flink.connectors.kudu.connector.writer.KuduWriter.obtainTable(KuduWriter.java:74)</span></span><br><span class="line"><span class="string">	at org.apache.flink.connectors.kudu.connector.writer.KuduWriter.&lt;init&gt;(KuduWriter.java:59)</span></span><br><span class="line"><span class="string">	at org.apache.flink.connectors.kudu.streaming.KuduSink.open(KuduSink.java:62)</span></span><br><span class="line"><span class="string">	at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:36)</span></span><br><span class="line"><span class="string">	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:102)</span></span><br><span class="line"><span class="string">	at org.apache.flink.streaming.api.operators.StreamSink.open(StreamSink.java:48)</span></span><br><span class="line"><span class="string">	at org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:426)</span></span><br><span class="line"><span class="string">	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:292)</span></span><br><span class="line"><span class="string">	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:726)</span></span><br><span class="line"><span class="string">	at java.lang.Thread.run(Thread.java:748)</span></span><br><span class="line"><span class="string">	Suppressed: org.apache.kudu.client.KuduException$OriginalException: Original asynchronous stack trace</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.ConnectToCluster.incrementCountAndCheckExhausted(ConnectToCluster.java:244)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.ConnectToCluster.access$100(ConnectToCluster.java:49)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.ConnectToCluster$ConnectToMasterErrCB.call(ConnectToCluster.java:363)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.ConnectToCluster$ConnectToMasterErrCB.call(ConnectToCluster.java:352)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.doCall(Deferred.java:1280)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.runCallbacks(Deferred.java:1259)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.handleContinuation(Deferred.java:1315)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.doCall(Deferred.java:1286)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.runCallbacks(Deferred.java:1259)</span></span><br><span class="line"><span class="string">		at com.stumbleupon.async.Deferred.callback(Deferred.java:1002)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.KuduRpc.handleCallback(KuduRpc.java:275)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.KuduRpc.errback(KuduRpc.java:329)</span></span><br><span class="line"><span class="string">		at org.apache.kudu.client.RpcProxy.responseReceived(RpcProxy.java:247)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.kudu.client.NonRecoverableException: must specify at least one key column</span><br><span class="line">	at org.apache.kudu.client.KuduException.transformException(KuduException.java:<span class="number">110</span>)</span><br><span class="line">	at org.apache.kudu.client.KuduClient.joinAndHandleException(KuduClient.java:<span class="number">413</span>)</span><br><span class="line">	at org.apache.kudu.client.KuduClient.createTable(KuduClient.java:<span class="number">118</span>)</span><br><span class="line">	at org.apache.flink.connectors.kudu.connector.writer.KuduWriter.obtainTable(KuduWriter.java:<span class="number">78</span>)</span><br><span class="line">	at org.apache.flink.connectors.kudu.connector.writer.KuduWriter.&lt;init&gt;(KuduWriter.java:<span class="number">59</span>)</span><br><span class="line">	at org.apache.flink.connectors.kudu.streaming.KuduSink.open(KuduSink.java:<span class="number">62</span>)</span><br><span class="line">	at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:<span class="number">36</span>)</span><br><span class="line">	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:<span class="number">102</span>)</span><br><span class="line">	at org.apache.flink.streaming.api.operators.StreamSink.open(StreamSink.java:<span class="number">48</span>)</span><br><span class="line">	at org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:<span class="number">426</span>)</span><br><span class="line">	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:<span class="number">292</span>)</span><br><span class="line">	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:<span class="number">726</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br><span class="line">	Suppressed: org.apache.kudu.client.KuduException$OriginalException: Original asynchronous stack trace</span><br><span class="line">		at org.apache.kudu.client.RpcProxy.dispatchMasterError(RpcProxy.java:<span class="number">386</span>)</span><br><span class="line">		at org.apache.kudu.client.RpcProxy.responseReceived(RpcProxy.java:<span class="number">279</span>)</span><br><span class="line">		at org.apache.kudu.client.RpcProxy.access$<span class="number">000</span>(RpcProxy.java:<span class="number">59</span>)</span><br><span class="line">		at org.apache.kudu.client.RpcProxy$<span class="number">1.</span>call(RpcProxy.java:<span class="number">149</span>)</span><br><span class="line">		at org.apache.kudu.client.RpcProxy$<span class="number">1.</span>call(RpcProxy.java:<span class="number">145</span>)</span><br><span class="line">		at org.apache.kudu.client.Connection.messageReceived(Connection.java:<span class="number">390</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:<span class="number">70</span>)</span><br><span class="line">		at org.apache.kudu.client.Connection.handleUpstream(Connection.java:<span class="number">238</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:<span class="number">791</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">296</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:<span class="number">70</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:<span class="number">791</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">296</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:<span class="number">462</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:<span class="number">443</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:<span class="number">303</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:<span class="number">70</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:<span class="number">791</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">296</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:<span class="number">462</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:<span class="number">443</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:<span class="number">303</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:<span class="number">70</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">564</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:<span class="number">559</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">268</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:<span class="number">255</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:<span class="number">88</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:<span class="number">108</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:<span class="number">337</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:<span class="number">89</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:<span class="number">178</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:<span class="number">108</span>)</span><br><span class="line">		at org.apache.kudu.shaded.org.jboss.netty.util.internal.DeadLockProofWorker$<span class="number">1.</span>run(DeadLockProofWorker.java:<span class="number">42</span>)</span><br><span class="line">		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1149</span>)</span><br><span class="line">		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">624</span>)</span><br><span class="line">		... <span class="number">1</span> more</span><br><span class="line"></span><br><span class="line">Rows per page:</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">1</span> - <span class="number">1</span> of <span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Metric</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink定时输出</title>
    <url>/bigdata/Flink/FlinkOutputTimely/</url>
    <content><![CDATA[<h1 id="FlinkOutputTimely"><a href="#FlinkOutputTimely" class="headerlink" title="FlinkOutputTimely"></a>FlinkOutputTimely</h1><p>定时批量输出</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">CommonSinkOperator</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">Serializable</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractStreamOperator</span>&lt;<span class="title">Object</span>&gt;</span></span><br><span class="line"><span class="class">        <span class="keyword">implements</span> <span class="title">ProcessingTimeCallback</span>,</span></span><br><span class="line"><span class="class">        <span class="title">OneInputStreamOperator</span>&lt;<span class="title">T</span>, <span class="title">Object</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> List&lt;T&gt; list;</span><br><span class="line">    <span class="keyword">private</span> ListState&lt;T&gt; listState;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> bathSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> interval;</span><br><span class="line">    <span class="keyword">private</span> ProcessingTimeService processingTimeService;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CommonSinkOperator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CommonSinkOperator</span><span class="params">(<span class="keyword">int</span> batchSize, <span class="keyword">long</span> interval)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.chainingStrategy = ChainingStrategy.ALWAYS;</span><br><span class="line">        <span class="keyword">this</span>.batchSize = batchSize;</span><br><span class="line">        <span class="keyword">this</span>.interval = interval;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.open();</span><br><span class="line">        <span class="keyword">if</span> (interval &gt; <span class="number">0</span> &amp;&amp; batchSize &gt; <span class="number">1</span>) &#123;</span><br><span class="line">            processingTimeService = getProcessingTimeService();</span><br><span class="line">            <span class="keyword">long</span> now = processingTimeService.getCurrentProcessingTime();</span><br><span class="line">            processingTimeService.registerTimer(now + interval, <span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">            StateInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">super</span>.initializeState(context);</span><br><span class="line">        <span class="keyword">this</span>.list = <span class="keyword">new</span> ArrayList&lt;T&gt;();</span><br><span class="line">        listState = context.getOperatorStateStore()</span><br><span class="line"></span><br><span class="line">                .getSerializableListState(<span class="string">&quot;batch-interval-sink&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">            listState.get().forEach(x -&gt; &#123;</span><br><span class="line">                list.add(x);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">            StreamRecord&lt;T&gt; element)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        list.add(element.getValue());</span><br><span class="line">        <span class="keyword">if</span> (list.size() &gt;= batchSize) &#123;</span><br><span class="line">            saveRecords(list);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">            StateSnapshotContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">super</span>.snapshotState(context);</span><br><span class="line">        <span class="keyword">if</span> (list.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            listState.clear();</span><br><span class="line">            listState.addAll(list);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onProcessingTime</span><span class="params">(<span class="keyword">long</span> timestamp)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (list.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            saveRecords(list);</span><br><span class="line">            list.clear();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> now =processingTimeService.getCurrentProcessingTime();</span><br><span class="line">        processingTimeService.registerTimer(now + interval,<span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">saveRecords</span><span class="params">(List&lt;T&gt; datas)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Oceanus: table meta API</title>
    <url>/bigdata/Flink/Oceanus/</url>
    <content><![CDATA[<h1 id="Oceanus"><a href="#Oceanus" class="headerlink" title="Oceanus"></a>Oceanus</h1><h2 id="拉取库表信息"><a href="#拉取库表信息" class="headerlink" title="拉取库表信息"></a>拉取库表信息</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -o tank_pos_meta.json &#x27;http://&lt;host&gt;:&lt;port&gt;/ec/v1/listTable?pageNum=1&amp;pageSize=999&amp;type=hippo&amp;dbName=bank-pos-info&amp;name=pos_yyyymmdd&#x27;</span><br></pre></td></tr></table></figure>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;result_code&quot;</span>: <span class="string">&quot;0&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;result_msg&quot;</span>: <span class="string">&quot;操作成功&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;result_content&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;tables&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">&quot;id&quot;</span>: <span class="number">2255</span>,</span><br><span class="line">                <span class="attr">&quot;dbName&quot;</span>: <span class="string">&quot;info&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;pos_yyyymmdd&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;hippo&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;principals&quot;</span>: <span class="string">&quot;user_name&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;fields&quot;</span>: <span class="string">&quot;db_name,String,db_name: tb_name,String,tb_name: op_name,String,op_name: exp_time_stample,String,exp_time_stample: exp_time_stample_order,String,exp_time_stample_order: Fbill_no,String,Fbill_no: Fbank_type,Long,Fbank_type: Fbiz_type,Long,Fbiz_type: Fpos_status,Long,Fpos_status: Freverse_status,Long,Freverse_status: Freverse_times,Long,Freverse_times: Ftransaction_id,String,Ftransaction_id: Freal_bill_no,String,Freal_bill_no: Ftrace_no,String,Ftrace_no: Ftx_date,String,Ftx_date: Famount,Long,Famount: Fcur_type,Long,Fcur_type: Fuin,String,Fuin: Fuid,Long,Fuid: Fuser_name,String,Fuser_name: Fuser_id_type,Long,Fuser_id_type: Fuser_id,String,Fuser_id: Fuser_phone,String,Fuser_phone: Fcard_no,String,&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;content&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;银行pos流水&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;attributes&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;table.topic&quot;</span>: <span class="string">&quot;sample_pos&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.bid&quot;</span>: <span class="string">&quot;sample_pos&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;data.encode&quot;</span>: <span class="string">&quot;UTF8&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.hippo.addrlist&quot;</span>: <span class="string">&quot;&lt;hippo_master&gt;&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.package&quot;</span>: <span class="string">&quot;true&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.interfaceId&quot;</span>: <span class="string">&quot;t_sample_pos_yyyymmdd&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;source.data.type&quot;</span>: <span class="string">&quot;data.type.default&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.needwatermark&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.kv&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.field.splitter&quot;</span>: <span class="string">&quot;0x1&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;is.temporal.table&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.field.splitter.other&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.usage&quot;</span>: <span class="string">&quot;table&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.used&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.running.used&quot;</span>: <span class="string">&quot;false&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">&quot;modifier&quot;</span>: <span class="string">&quot;&lt;table_owner&gt;&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modify_time&quot;</span>: <span class="number">1563420065831</span>,</span><br><span class="line">                <span class="attr">&quot;create_time&quot;</span>: <span class="number">1563420065831</span>,</span><br><span class="line">                <span class="attr">&quot;tablesLogs&quot;</span>: <span class="literal">null</span></span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">&quot;total&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;pageNum&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;pageSize&quot;</span>: <span class="number">999</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="flink的优化"><a href="#flink的优化" class="headerlink" title="flink的优化"></a>flink的优化</h2><h3 id="JobManager-failover"><a href="#JobManager-failover" class="headerlink" title="JobManager failover"></a>JobManager failover</h3><p><img src="_v_images/20200601183746039_28243.png"></p>
<p>它的 standby 节点是冷备的，JobManager 的切换会导致它管理的所有 Job 都会被重启恢复，这一行为在我们现网环境中是不可接受的。所以，我们首先定制的第一个大特性就是<br>JobManager 的 failover 优化，让 standby 节点变成热备，这使得 JobManager 的切换对 TaskManager 上已经正在运行的 Job 不产生影响。我们已经对 Standalone 以及 Flink on YARN 这两种部署模式支持了这个特性，Flink on YARN 的支持还处于内部验证阶段。我们以对 Standalone 模式的优化为例来进行分析，它主要包含这么几个步骤：</p>
<ul>
<li>取消 JobManager 跟 TaskManager 因为心跳超时或 Leadership 变动就 cancel task 的行为；</li>
<li>对 ExecutionGraph 核心数据的快照；</li>
<li>通过 ExecutionGraphBuilder 重构空的 ExecutionGraph 加上快照重置来恢复出一个跟原先等价的 ExecutionGraph 对象；</li>
<li>TaskManager 跟新的 JobManager leader 建立连接后以心跳上报自己的状态和必要的信息；<br>新的 JobManager 确认在 reconcile 阶段 Job 的所有 task 是否正常运行。</li>
</ul>
<h3 id="checkpoint失败改进"><a href="#checkpoint失败改进" class="headerlink" title="checkpoint失败改进"></a>checkpoint失败改进</h3><p><img src="_v_images/20200601185553966_3881.png"><br>社区版当前的处理机制。JobMaster 中，每个 Job 会对应一个 Checkpoint Coordinator，它用来管理并协调 Job 检查点的执行。当到达一个检查点的触发周期，Coordinator 会对所有的 Source Task 下发 TriggerCheckpoint 消息，source task 会在自身完成快照后向下游广播 CheckpointBarrier，作为下游 task 触发的通知。其中，如果一个 task 在执行检查点时失败了，这取决于用户是否容忍这个失败（通过一个配置项），如果选择不容忍那么这个失败将变成一个异常导致 task 的失败，与此同时 task 的失败将会通知到 JobMaster，JobMaster 将会通知这个 Job 的其他 task 取消它们的执行。现有的机制存在一些问题：</p>
<ul>
<li>Coordinator 并不能控制 Job 是否容忍检查点失败，因为控制权在 task 端；</li>
<li>Coordinator 当前的失败处理代码逻辑混乱，区分出了触发阶段，却忽略了执行阶段；</li>
<li>无法实现容忍多少个连续的检查点失败则让 Job 失败的逻辑。</li>
</ul>
<p><img src="_v_images/20200601190109255_17290.png"><br>首先，我们对源码中 checkpoint package 下的相关类进行了重构，使得它不再区分触发阶段，引进了更多的检查点失败原因的枚举并重构了相关的代码。然后我们引入了 CheckpointFailureManager 组件，用来统一失败管理，同时为了适配更灵活的容忍失败的能力，我们引入了检查点失败计数器机制。现在，当我们遇到检查点失败后，这个失败信息会直接上报到 Coordinator，而是否要让 Job 失败具体的决策则由 CheckpointFailureManager 作出，这就<strong>使得 Coordinator 具有了完整的检查点控制权，而决策权转让给 CheckpointFailureManager，则充分实现了逻辑解耦</strong>。</p>
<h3 id="AsyncIO超时"><a href="#AsyncIO超时" class="headerlink" title="AsyncIO超时"></a>AsyncIO超时</h3><h3 id="sql-editor"><a href="#sql-editor" class="headerlink" title="sql editor"></a>sql editor</h3><p>ace editor</p>
<h3 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h3><p>[averyzhang@tdw-<ip> /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646]$ ll<br>总用量 32<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 blobStore-b0fe739d-d5e0-4a87-9c34-2a2492fc84a6<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 blobStore-f8cdfc9d-d7d2-4fb6-9836-da65b414b45a<br>drwxr-s—  3 u_teg_tdbank users 4096 6月   5 16:07 container_e03_1542247480019_1646_01_000002<br>drwx–x— 11 u_teg_tdbank users 4096 6月   5 16:07 filecache<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 flink-dist-cache-d55b9eaa-87b9-404e-a015-c4c90c767ac9<br>drwxr-s—  8 u_teg_tdbank users 4096 6月   5 16:07 flink-io-0bd3c6be-79ef-41d6-95ec-f42a949a10f1<br>drwxr-s—  4 u_teg_tdbank users 4096 6月   5 16:07 localState<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 rocksdb-lib-89c57e29c492279dc1e188992c87925e</p>
<p>[averyzhang@tdw-<ip> /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646]$ tree<br>.<br>|– blobStore-b0fe739d-d5e0-4a87-9c34-2a2492fc84a6<br>|– blobStore-f8cdfc9d-d7d2-4fb6-9836-da65b414b45a<br>|– container_e03_1542247480019_1646_01_000002<br>|   |– container_tokens<br>|   |– flink-conf.yaml -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/10/91db3812-bb43-492d-8c32-359b2c21a142-taskmanager-conf.yaml<br>|   |– flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/15/flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar<br>|   |– kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/11/kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar<br>|   |– launch_container.sh<br>|   |– lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/12/lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar<br>|   |– log4j.properties -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/17/log4j.properties<br>|   |– log4j.zip -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/14/log4j.zip<br>|   |– oceanus-common-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/13/oceanus-common-1.1.0-SNAPSHOT.jar<br>|   |– oceanus-core-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/16/oceanus-core-1.1.0-SNAPSHOT.jar<br>|   |– oceanus-ml-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/18/oceanus-ml-1.1.0-SNAPSHOT.jar<br>|   <code>-- tmp |-- filecache [error opening dir] |-- flink-dist-cache-d55b9eaa-87b9-404e-a015-c4c90c767ac9 |-- flink-io-0bd3c6be-79ef-41d6-95ec-f42a949a10f1 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_337adade1e207453ed3502e01d75fd03__1_8__uuid_6d0d5c24-bb66-4793-afa4-7a7e3c3ffd6a |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024751.sst<br>|   |       |– 024753.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_337adade1e207453ed3502e01d75fd03__2_8__uuid_18ea3048-b73d-482d-b6c9-615452280981 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024739.sst<br>|   |       |– 024741.sst<br>|   |       |– 024742.sst<br>|   |       |– 024743.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_be465a1f98956392d0b820196e75d12b__1_8__uuid_efd7a85c-2a15-4d62-9929-60624dd6ea4a |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024741.sst<br>|   |       |– 024743.sst<br>|   |       |– 024744.sst<br>|   |       |– 024745.sst<br>|   |       |– 024746.sst<br>|   |       |– 024747.sst<br>|   |       |– 024748.sst<br>|   |       |– 024749.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_be465a1f98956392d0b820196e75d12b__2_8__uuid_e666a8b1-d26d-4688-b089-0a957e49f947 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024740.sst<br>|   |       |– 024742.sst<br>|   |       |– 024743.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_eaecdab2f3df15db186c08e889659492__1_8__uuid_24efb767-bdf2-4309-a136-302cc4a18399 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024741.sst<br>|   |       |– 024743.sst<br>|   |       |– 024744.sst<br>|   |       |– 024745.sst<br>|   |       |– 024746.sst<br>|   |       |– 024747.sst<br>|   |       |– 024748.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   </code>– job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_eaecdab2f3df15db186c08e889659492__2_8__uuid_776c72fa-68fa-493b-b9ab-03461406816a<br>|       <code>-- db |           |-- 000013.log |           |-- 024740.sst |           |-- 024742.sst |           |-- 024743.sst |           |-- CURRENT |           |-- IDENTITY |           |-- LOCK |           |-- LOG |           |-- MANIFEST-000006 |           |-- OPTIONS-000010 |           </code>– OPTIONS-000012<br>|– localState<br>|   |– aid_AllocationID{e1f41e5a166354d80ad6d6b8d3765fa1}<br>|   <code>-- aid_AllocationID&#123;e6e7f806bb078db66f50eeb3a48f0da9&#125; </code>– rocksdb-lib-89c57e29c492279dc1e188992c87925e<br>    `– librocksdbjni-linux64.so</p>
<p>23 directories, 87 files</p>
<p>[averyzhang@tdw-<ip> /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/container_e03_1542247480019_1646_01_000002]$ ll<br>总用量 52<br>-rw——- 1 u_teg_tdbank users   69 6月   5 16:07 container_tokens<br>lrwxrwxrwx 1 u_teg_tdbank users  154 6月   5 16:07 flink-conf.yaml -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/10/91db3812-bb43-492d-8c32-359b2c21a142-taskmanager-conf.yaml<br>lrwxrwxrwx 1 u_teg_tdbank users  151 6月   5 16:07 flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/15/flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  146 6月   5 16:07 kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/11/kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar<br>-rwx—— 1 u_teg_tdbank users 6328 6月   5 16:07 launch_container.sh<br>lrwxrwxrwx 1 u_teg_tdbank users  164 6月   5 16:07 lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/12/lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  112 6月   5 16:07 log4j.properties -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/17/log4j.properties<br>lrwxrwxrwx 1 u_teg_tdbank users  105 6月   5 16:07 log4j.zip -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/14/log4j.zip<br>lrwxrwxrwx 1 u_teg_tdbank users  129 6月   5 16:07 oceanus-common-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/13/oceanus-common-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  127 6月   5 16:07 oceanus-core-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/16/oceanus-core-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  125 6月   5 16:07 oceanus-ml-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/18/oceanus-ml-1.1.0-SNAPSHOT.jar<br>drwxr-s— 2 u_teg_tdbank users 4096 6月   5 16:07 tmp</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>Flink</tag>
        <tag>Oceanus</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink-window</title>
    <url>/bigdata/Flink/Flink-window/</url>
    <content><![CDATA[<h1 id="Flink-window"><a href="#Flink-window" class="headerlink" title="Flink-window"></a>Flink-window</h1><h2 id="窗口的触发"><a href="#窗口的触发" class="headerlink" title="窗口的触发"></a>窗口的触发</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line">SingleOutputStreamOperator&lt;ItemEntity&gt; streamOperator = env</span><br><span class="line">        .socketTextStream(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">9091</span>)</span><br><span class="line">        .map(<span class="keyword">new</span> MapFunction&lt;String, ItemEntity&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ItemEntity <span class="title">map</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                String[] split = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">if</span> (s.isEmpty() || (split = s.split(<span class="string">&quot;,&quot;</span>)).length != <span class="number">2</span>) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                ItemEntity itemEntity = ItemEntity.builder().timestamp(split[<span class="number">0</span>])</span><br><span class="line">                        .eventId(split[<span class="number">1</span>])</span><br><span class="line">                        .build();</span><br><span class="line">                <span class="keyword">return</span> itemEntity;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        .filter(Objects::nonNull)</span><br><span class="line">        .assignTimestampsAndWatermarks(<span class="keyword">new</span> AscendingTimestampExtractor&lt;ItemEntity&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(ItemEntity itemEntity)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">long</span> timestamp = itemEntity.getTimestamp();</span><br><span class="line">                <span class="keyword">return</span> timestamp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">streamOperator</span><br><span class="line">        .keyBy(<span class="keyword">new</span> KeySelector&lt;ItemEntity, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> String <span class="title">getKey</span><span class="params">(ItemEntity itemEntity)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                String eventId = itemEntity.getEventId();</span><br><span class="line">                <span class="keyword">return</span> eventId;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        .window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">5</span>)))</span><br><span class="line">        .process(</span><br><span class="line">                <span class="keyword">new</span> ProcessWindowFunction&lt;ItemEntity, Tuple2&lt;String, String&gt;, String, TimeWindow&gt;() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(String s, Context context,</span></span></span><br><span class="line"><span class="function"><span class="params">                            Iterable&lt;ItemEntity&gt; iterable,</span></span></span><br><span class="line"><span class="function"><span class="params">                            Collector&lt;Tuple2&lt;String, String&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                        <span class="keyword">for</span> (ItemEntity itemEntity : iterable) &#123;</span><br><span class="line">                            <span class="keyword">long</span> timestamp = itemEntity.getTimestamp();</span><br><span class="line">                            Date date = <span class="keyword">new</span> Date(timestamp);</span><br><span class="line">                            SimpleDateFormat simpleDateFormat = <span class="keyword">new</span> SimpleDateFormat(</span><br><span class="line">                                    <span class="string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>);</span><br><span class="line">                            collector.collect(Tuple2.of(itemEntity.getEventId(),</span><br><span class="line">                                    timestamp + <span class="string">&quot;-&gt;&quot;</span> + simpleDateFormat.format(date)));</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">        .print();</span><br><span class="line">env.execute(<span class="string">&quot;test-window&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>5秒的窗口</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2020-04-01 00:01:00,1</span><br><span class="line">2020-04-01 00:01:00,1</span><br><span class="line">2020-04-01 00:01:06,1 # 触发计算</span><br><span class="line">(1,1585670460000-&gt;2020-04-01 00:01:00)</span><br><span class="line">(1,1585670460000-&gt;2020-04-01 00:01:00)</span><br><span class="line">2020-04-01 00:01:00,1 # 窗口已经关闭，旧数据</span><br><span class="line"><span class="meta">#</span><span class="bash"> WARN  org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor [] - Timestamp monotony violated: 1585670460000 &lt; 1585670466000</span></span><br><span class="line">2020-04-01 00:01:06,1</span><br><span class="line">2020-04-01 00:01:07,1</span><br><span class="line">2020-04-01 00:01:11,1 # 触发计算</span><br><span class="line">(1,1585670466000-&gt;2020-04-01 00:01:06)</span><br><span class="line">(1,1585670466000-&gt;2020-04-01 00:01:06)</span><br><span class="line">(1,1585670467000-&gt;2020-04-01 00:01:07)</span><br></pre></td></tr></table></figure>


<h2 id="window的抽象概念"><a href="#window的抽象概念" class="headerlink" title="window的抽象概念"></a>window的抽象概念</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Keyed Windows</span><br><span class="line"></span><br><span class="line">stream</span><br><span class="line">       .keyBy(...)               &lt;-  keyed versus non-keyed windows</span><br><span class="line">       .window(...)              &lt;-  required: &quot;assigner&quot;</span><br><span class="line">      [.trigger(...)]            &lt;-  optional: &quot;trigger&quot; (else default trigger)</span><br><span class="line">      [.evictor(...)]            &lt;-  optional: &quot;evictor&quot; (else no evictor)</span><br><span class="line">      [.allowedLateness(...)]    &lt;-  optional: &quot;lateness&quot; (else zero)</span><br><span class="line">      [.sideOutputLateData(...)] &lt;-  optional: &quot;output tag&quot; (else no side output for late data)</span><br><span class="line">       .reduce&#x2F;aggregate&#x2F;fold&#x2F;apply()      &lt;-  required: &quot;function&quot;</span><br><span class="line">      [.getSideOutput(...)]      &lt;-  optional: &quot;output tag&quot;</span><br><span class="line">Non-Keyed Windows</span><br><span class="line"></span><br><span class="line">stream</span><br><span class="line">       .windowAll(...)           &lt;-  required: &quot;assigner&quot;</span><br><span class="line">      [.trigger(...)]            &lt;-  optional: &quot;trigger&quot; (else default trigger)</span><br><span class="line">      [.evictor(...)]            &lt;-  optional: &quot;evictor&quot; (else no evictor)</span><br><span class="line">      [.allowedLateness(...)]    &lt;-  optional: &quot;lateness&quot; (else zero)</span><br><span class="line">      [.sideOutputLateData(...)] &lt;-  optional: &quot;output tag&quot; (else no side output for late data)</span><br><span class="line">       .reduce&#x2F;aggregate&#x2F;fold&#x2F;apply()      &lt;-  required: &quot;function&quot;</span><br><span class="line">      [.getSideOutput(...)]      &lt;-  optional: &quot;output tag&quot;</span><br></pre></td></tr></table></figure>
<h3 id="window-assigner"><a href="#window-assigner" class="headerlink" title="window assigner"></a>window assigner</h3><h3 id="window-trigger"><a href="#window-trigger" class="headerlink" title="window trigger"></a>window trigger</h3><h3 id="window-evictor"><a href="#window-evictor" class="headerlink" title="window evictor"></a>window evictor</h3><h2 id="windowOperator工作流程"><a href="#windowOperator工作流程" class="headerlink" title="windowOperator工作流程"></a>windowOperator工作流程</h2><p><img src="_v_images/20201206173044901_44534749.png"></p>
<h3 id="window-state"><a href="#window-state" class="headerlink" title="window state"></a>window state</h3><p><img src="_v_images/20201206173354630_1171217287.png"></p>
<h2 id="Session-window"><a href="#Session-window" class="headerlink" title="Session window"></a>Session window</h2><p><a href="http://wuchong.me/blog/2016/06/06/flink-internals-session-window/">Flink 原理与实现：Session Window</a></p>
<p><code>SESSION(time_attr, interval)</code>定义一个会话时间窗口。<br>会话时间窗口没有一个固定的持续时间，但是它们的边界会根据 <code>interval</code> 所定义的不活跃时间所确定；即一个会话时间窗口在定义的间隔时间内没有时间出现，该窗口会被关闭。例如时间窗口的间隔时间是 30 分钟，当其不活跃的时间达到30分钟后，若观测到新的记录，则会启动一个新的会话时间窗口（否则该行数据会被添加到当前的窗口），且若在 30 分钟内没有观测到新纪录，这个窗口将会被关闭。会话时间窗口可以使用事件时间（批处理、流处理）或处理时间（流处理）。</p>
<p>流式数据处理中，很多操作要依赖于时间属性进行，因此时间属性也是流式引擎能够保证准确处理数据的基石。在这篇文章中，我们将对 Flink 中时间属性和窗口的实现逻辑进行分析。</p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E6%A6%82%E8%A7%88"></a>概览</h2><p>Google 2015 年发表的 <a href="https://ai.google/research/pubs/pub43864">The Dataflow Model</a> 论文是流式处理领域非常具有指导意义的一篇论文，对于大规模/无边界/乱序数据集的数据特征和计算范式进行了总结，并且提出了一个通用的计算模型来指导流式数据处理系统的构建。Flink 参考了很多 Dataflow Model 的思想，尤其是在时间属性和窗口的设计实现方面。</p>
<p>Dataflow 模型将数据处理处理要处理的问题抽象为以下几个基本问题：</p>
<ul>
<li>  What results are being computed?</li>
<li>  Where in event time they are being computed?</li>
<li>  When in processing time they are materialized?</li>
<li>  How earlier results relate to later refinements?</li>
</ul>
<p>要回答上面 Where 和 When 的问题，就需要依赖于时间域（time domain），水位线（watermark），窗口模型（windowing model），触发器（triggering model）等机制。</p>
<h3 id="Event-Time-vs-Processing-Time"><a href="#Event-Time-vs-Processing-Time" class="headerlink" title="Event Time vs Processing Time"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#event-time-vs-processing-time"></a>Event Time vs Processing Time</h3><p>在处理无边界的乱序数据时，需要对涉及到的时间域有一个清晰的认识。在流式处理系统，我们主要关注两种典型的时间属性：</p>
<ul>
<li>  Event Time：事件发生时的确切时间</li>
<li>  Processing Time：事件在系统中被处理的时间</li>
</ul>
<p>事件时间是一个消息的固有属性，消息在流处理系统中流转，事件时间始终保持不变；而处理时间则依赖于流处理系统的本地时钟，随着消息的流转，处理时间也在不断发生变动。在完全理想的情况下，事件事件和处理时间是一致的，也就是事件发生的时候就立即被处理。然而实际情况肯定并非如此，在分布式系统中，由于网络延迟等因素，处理时间必然落后于事件时间。</p>
<p>除了 Event Time 和 Processing Time 之外，Flink 还提供了 Ingestion Time（摄入时间）。摄入时间指的是一个消息进入 Flink 的时间，随着消息的流转，摄入时间不会发生变动。并且，和事件时间可能会出现乱序问题不同，摄入时间是递增的。摄入时间介于事件时间和处理时间之间，</p>
<h3 id="Window"><a href="#Window" class="headerlink" title="Window"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#window"></a>Window</h3><p>对于一个无边界的数据流，窗口（Window）可以沿着时间的边界将其切割成有边界的数据块（chunk）来进行处理。图中给出了三种主要类型的窗口的简单示例。</p>
<p><a href="https://blog.jrwang.me/img/flink/windows.png"><img src="vx_images/4524683776119.png" alt="window"></a></p>
<ul>
<li>  Fixed windows（固定窗口）：在 Flink 中被也称为 Tumbling windows（滚动窗口），将时间切割成具有固定时间长度的段。滚动窗口之间不会重叠。</li>
<li>  Sliding windows（滑动窗口）：滑动窗口是滚动窗口更一般化的表现的形式，由窗口大小和滑动间隔这两个属性来定义。如果滑动间隔小于窗口大小，那么不同的窗口之间就会存在重叠；如果滑动间隔大于窗口大小，不同窗口之间就会存在间隔；如果滑动间隔等于窗口大小，就相当于滚动窗口。</li>
<li>  Session Windows（会话窗口）：和滚动窗口与滑动窗口不同的是，会话窗口并没有固定的窗口大小；它是一种动态窗口，通常由超时间隔（timeout gap）来定义。当超过一段时间没有新的事件到达，则可以认为窗口关闭了。</li>
</ul>
<h3 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#trigger"></a>Trigger</h3><p>触发器（Trigger）提供了一种灵活的机制来决定窗口的计算结果在什么时候对外输出。理论上来说，只有两种类型的触发器，大部分的应用都是选择其一或组合使用：</p>
<ul>
<li>  Repeated update triggers：重复更新窗口的计算结果，更新可以是由新消息到达时触发，也可以是每个一段时间（如1分钟）进行触发</li>
<li>  Completeness triggers：在窗口结束时进行触发，这是更符合直觉的使用方法，也和批处理模式的计算结果相吻合。但是需要一种机制来衡量一个窗口的所有消息都已经被正确地处理了。</li>
</ul>
<h3 id="Watermark"><a href="#Watermark" class="headerlink" title="Watermark"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#watermark"></a>Watermark</h3><p>怎么确定一个窗口是否已经结束，这在流式数据处理系统中并非一个很容易解决的问题。如果窗口是基于处理时间的，那么问题确实容易解决，因为处理时间是完全基于本地时钟的；但是如果窗口基于事件时间，由于分布式系统中消息可能存在延迟、乱序到达的问题，即便系统已经接收到窗口边界以外的数据了，也不能确定前面的所有数据都已经到达了。水位线（Watermark）机制就是用于解决这个问题的。</p>
<p>Watermark 是事件时间域中衡量输入完成进度的一种时间概念。换句话说，在处理使用事件时间属性的数据流时，Watermark 是系统测量数据处理进度的一种方法。假如当前系统的 watermark 为时间 T，那么系统认为所有事件时间小于 T 的消息都已经到达，即系统任务它不会再接收到事件时间小于 T 的消息了。有了 Watermark，系统就可以确定使用事件时间的窗口是否已经完成。但是 Watermark 只是一种度量指标，系统借由它来评估当前的进度，并不能完全保证不会出现小于当前 Watermark 的消息。对于这种消息，即“迟到”的消息，需要进行特殊的处理。这也就是前面所说的流处理系统面临的 <strong>How</strong> 的问题，即如何处理迟到的消息，从而修正已经输出的计算结果。</p>
<h2 id="事件时间和水位线"><a href="#事件时间和水位线" class="headerlink" title="事件时间和水位线"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E4%BA%8B%E4%BB%B6%E6%97%B6%E9%97%B4%E5%92%8C%E6%B0%B4%E4%BD%8D%E7%BA%BF"></a>事件时间和水位线</h2><p>Flink 内部使用 <code>StreamRecord</code> 来表示需要被处理的一条消息，使用 <code>Watermark</code> 来表示一个水位线的标记。<code>Watermark</code> 和 <code>StreamRecord</code> 一样，需要在上下游的算子之间进行流动，它们拥有共同的父类 <code>StreamElement</code>。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 910111213141516</code></td>
<td><code>java//对实际的消息类型做一层封装，timestamp就是这条记录关联的事件时间public final class StreamRecord&lt;T&gt; extends StreamElement &#123;    /** The actual value held by this record. */    private T value;    /** The timestamp of the record. */    private long timestamp;    /** Flag whether the timestamp is actually set. */    private boolean hasTimestamp;&#125;public final class Watermark extends StreamElement &#123;    /** The watermark that signifies end-of-event-time. */    public static final Watermark MAX_WATERMARK = new Watermark(Long.MAX_VALUE);    /** The timestamp of the watermark in milliseconds. */    private final long timestamp;&#125;</code></td>
</tr>
</tbody></table>
<p>有两种方式来生成一个消息流的 event time 和 watermark，一种方式是在数据源中直接生成，另一种方式是通过 Timestamp Assigners / Watermark Generators。</p>
<h3 id="在-SourceFunction-中生成时间信息"><a href="#在-SourceFunction-中生成时间信息" class="headerlink" title="在 SourceFunction 中生成时间信息"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E5%9C%A8-sourcefunction-%E4%B8%AD%E7%94%9F%E6%88%90%E6%97%B6%E9%97%B4%E4%BF%A1%E6%81%AF"></a>在 SourceFunction 中生成时间信息</h3><p>在 <code>SourceFunction</code> 中，可以通过 <code>SourceContext</code> 接口提供的 <code>SourceContext.collectWithTimestamp(T element, long timestamp)</code> 提交带有时间戳的消息，通过 <code>SourceContext.emitWatermark(Watermark mark)</code> 提交 watermark。<code>SourceContext</code> 有几种不同的实现，根据时间属性的设置，会自动选择不同的 <code>SourceContext</code>。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 910111213141516171819202122232425262728293031323334353637383940414243444546474849</code></td>
<td><code>javapublic class StreamSourceContexts &#123;    /**     * Depending on the &#123;@link TimeCharacteristic&#125;, this method will return the adequate     * &#123;@link org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext&#125;. That is:     * &lt;ul&gt;     *     &lt;li&gt;&#123;@link TimeCharacteristic#IngestionTime&#125; = &#123;@code AutomaticWatermarkContext&#125;&lt;/li&gt;     *     &lt;li&gt;&#123;@link TimeCharacteristic#ProcessingTime&#125; = &#123;@code NonTimestampContext&#125;&lt;/li&gt;     *     &lt;li&gt;&#123;@link TimeCharacteristic#EventTime&#125; = &#123;@code ManualWatermarkContext&#125;&lt;/li&gt;     * &lt;/ul&gt;     * */    public static &lt;OUT&gt; SourceFunction.SourceContext&lt;OUT&gt; getSourceContext(            TimeCharacteristic timeCharacteristic,            ProcessingTimeService processingTimeService,            Object checkpointLock,            StreamStatusMaintainer streamStatusMaintainer,            Output&lt;StreamRecord&lt;OUT&gt;&gt; output,            long watermarkInterval,            long idleTimeout) &#123;        final SourceFunction.SourceContext&lt;OUT&gt; ctx;        switch (timeCharacteristic) &#123;            case EventTime:                ctx = new ManualWatermarkContext&lt;&gt;(                    output,                    processingTimeService,                    checkpointLock,                    streamStatusMaintainer,                    idleTimeout);                break;            case IngestionTime:                ctx = new AutomaticWatermarkContext&lt;&gt;(                    output,                    watermarkInterval,                    processingTimeService,                    checkpointLock,                    streamStatusMaintainer,                    idleTimeout);                break;            case ProcessingTime:                ctx = new NonTimestampContext&lt;&gt;(checkpointLock, output);                break;            default:                throw new IllegalArgumentException(String.valueOf(timeCharacteristic));        &#125;        return ctx;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>如果系统时间属性被设置为 <code>TimeCharacteristic#ProcessingTime</code>，那么 <code>NonTimestampContext</code> 会忽略掉时间戳和watermark；如果时间属性被设置为 <code>TimeCharacteristic#EventTime</code>，那么通过 <code>ManualWatermarkContext</code> 提交的 <code>StreamRecord</code> 就会包含时间戳，watermark 也会正常提交。比较特殊的是 <code>TimeCharacteristic#IngestionTime</code>，<code>AutomaticWatermarkContext</code> 会使用系统当前时间作为 <code>StreamRecord</code> 的时间戳，并定期提交 watermark，从而实现 IngestionTime 的效果。</p>
<h3 id="Timestamp-Assigners-Watermark-Generators"><a href="#Timestamp-Assigners-Watermark-Generators" class="headerlink" title="Timestamp Assigners / Watermark Generators"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#timestamp-assigners-watermark-generators"></a>Timestamp Assigners / Watermark Generators</h3><p>也可以通过 Timestamp Assigners / Watermark Generators 来生成事件时间和 watermark，一般是从消息中提取出时间字段。通过 <code>DataStream.assignTimestampsAndWatermarks(AssignerWithPeriodicWatermarks)</code> 和 <code>DataStream.assignTimestampsAndWatermarks(AssignerWithPunctuatedWatermarks)</code> 方法和来自定义提取 timstamp 和生成 watermark 的逻辑。</p>
<p><code>AssignerWithPeriodicWatermarks</code> 和 <code>AssignerWithPunctuatedWatermarks</code> 都继承了 <code>TimestampAssigner</code> 接口：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011</code></td>
<td><code>javapublic interface TimestampAssigner&lt;T&gt; extends Function &#123;    long extractTimestamp(T element, long previousElementTimestamp);&#125;public interface AssignerWithPeriodicWatermarks&lt;T&gt; extends TimestampAssigner&lt;T&gt; &#123;    @Nullable Watermark getCurrentWatermark();&#125;public interface AssignerWithPunctuatedWatermarks&lt;T&gt; extends TimestampAssigner&lt;T&gt; &#123;    @Nullable Watermark checkAndGetNextWatermark(T lastElement, long extractedTimestamp);&#125;</code></td>
</tr>
</tbody></table>
<p><code>AssignerWithPeriodicWatermarks</code> 和 <code>AssignerWithPunctuatedWatermarks</code> 的区别在于 watermark 的生成方式不一样。如果使用 <code>AssignerWithPeriodicWatermarks</code> 那么会定期生成 watermark 信息；而如果使用 <code>AssignerWithPunctuatedWatermarks</code> 则一般依赖于数据流中的特殊元素来生成 watermark。</p>
<p>在使用 <code>AssignerWithPeriodicWatermarks</code> 的情况下会生成一个 <code>TimestampsAndPeriodicWatermarksOperator</code> 算子，<code>TimestampsAndPeriodicWatermarksOperator</code> 会注册定时器，定期提交 watermark 到下游：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233343536373839404142</code></td>
<td><code>javapublic class TimestampsAndPeriodicWatermarksOperator&lt;T&gt;        extends AbstractUdfStreamOperator&lt;T, AssignerWithPeriodicWatermarks&lt;T&gt;&gt;        implements OneInputStreamOperator&lt;T, T&gt;, ProcessingTimeCallback &#123;        @Override    public void open() throws Exception &#123;        super.open();        currentWatermark = Long.MIN_VALUE;        watermarkInterval = getExecutionConfig().getAutoWatermarkInterval();        //注册一个定时器        if (watermarkInterval &gt; 0) &#123;            long now = getProcessingTimeService().getCurrentProcessingTime();            getProcessingTimeService().registerTimer(now + watermarkInterval, this);        &#125;    &#125;    @Override    public void processElement(StreamRecord&lt;T&gt; element) throws Exception &#123;        //从元素中提取时间        final long newTimestamp = userFunction.extractTimestamp(element.getValue(),                element.hasTimestamp() ? element.getTimestamp() : Long.MIN_VALUE);        output.collect(element.replace(element.getValue(), newTimestamp));    &#125;    //定时器触发的回调函数    @Override    public void onProcessingTime(long timestamp) throws Exception &#123;        //watermark 大于当前值，则提交        Watermark newWatermark = userFunction.getCurrentWatermark();        if (newWatermark != null &amp;&amp; newWatermark.getTimestamp() &gt; currentWatermark) &#123;            currentWatermark = newWatermark.getTimestamp();            // emit watermark            output.emitWatermark(newWatermark);        &#125;        // register next timer        long now = getProcessingTimeService().getCurrentProcessingTime();        getProcessingTimeService().registerTimer(now + watermarkInterval, this);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>在使用 <code>AssignerWithPunctuatedWatermarks</code> 的时候，会生成一个 <code>TimestampsAndPunctuatedWatermarksOperator</code> 算子，会针对每个元素判断是否需要提交 watermark：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 910111213141516171819</code></td>
<td><code>javapublic class TimestampsAndPunctuatedWatermarksOperator&lt;T&gt;        extends AbstractUdfStreamOperator&lt;T, AssignerWithPunctuatedWatermarks&lt;T&gt;&gt;        implements OneInputStreamOperator&lt;T, T&gt; &#123;    @Override    public void processElement(StreamRecord&lt;T&gt; element) throws Exception &#123;        final T value = element.getValue();        //生成时间信息        final long newTimestamp = userFunction.extractTimestamp(value,                element.hasTimestamp() ? element.getTimestamp() : Long.MIN_VALUE);        output.collect(element.replace(element.getValue(), newTimestamp));        //判断是否需要提交 watermark        final Watermark nextWatermark = userFunction.checkAndGetNextWatermark(value, newTimestamp);        if (nextWatermark != null &amp;&amp; nextWatermark.getTimestamp() &gt; currentWatermark) &#123;            currentWatermark = nextWatermark.getTimestamp();            output.emitWatermark(nextWatermark);        &#125;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<h2 id="Timer-定时器"><a href="#Timer-定时器" class="headerlink" title="Timer 定时器"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#timer-%E5%AE%9A%E6%97%B6%E5%99%A8"></a>Timer 定时器</h2><p>Timer 提供了一种定时触发器的功能，通过 <code>TimerService</code> 接口注册 timer，触发的回调被封装为 <code>Triggerable</code>：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415</code></td>
<td><code>javapublic interface TimerService &#123;    long currentProcessingTime();    long currentWatermark();    void registerProcessingTimeTimer(long time);    void registerEventTimeTimer(long time);    void deleteProcessingTimeTimer(long time);    void deleteEventTimeTimer(long time);&#125;public interface Triggerable&lt;K, N&gt; &#123;    void onEventTime(InternalTimer&lt;K, N&gt; timer) throws Exception;    void onProcessingTime(InternalTimer&lt;K, N&gt; timer) throws Exception;&#125;</code></td>
</tr>
</tbody></table>
<p><code>TimerService</code> 不仅提供了注册和取消 timer 的功能，还可以通过它来获取当前的系统时间和 watermark 的值。需要注意的一点是，<strong>Timer 只能在 <code>KeyedStream</code> 中使用</strong>。和 <code>TimerService</code> 相对应的是，Flink 内部使用 <code>InternalTimerService</code>，可以设置 timer 关联的 namespace 和 key。Timer 实际上是一种特殊的状态，在 checkpoint 时会写入快照中，这一点在前面分析 checkpoint 过程时也有介绍。</p>
<p>在 <code>InternalTimeService</code> 中注册的 timer 有两种类型，分别为基于系统时间的和基于事件时间的，它使用两个优先级队列分别保存这两种类型的 timer。Timer 则被抽象为接口 <code>InternalTimer</code>，每个 timer 有绑定的 key，namespace 和触发时间 timestamp，<code>TimerHeapInternalTimer</code> 是其具体实现。<code>InternalTimerServiceImpl</code> 内部的两个优先级队列会按照触发时间的大小进行排序。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233</code></td>
<td><code>javapublic interface InternalTimer&lt;K, N&gt; extends PriorityComparable&lt;InternalTimer&lt;?, ?&gt;&gt;, Keyed&lt;K&gt; &#123;    /** Function to extract the key from a &#123;@link InternalTimer&#125;. */    KeyExtractorFunction&lt;InternalTimer&lt;?, ?&gt;&gt; KEY_EXTRACTOR_FUNCTION = InternalTimer::getKey;    /** Function to compare instances of &#123;@link InternalTimer&#125;. */    PriorityComparator&lt;InternalTimer&lt;?, ?&gt;&gt; TIMER_COMPARATOR =        (left, right) -&gt; Long.compare(left.getTimestamp(), right.getTimestamp());    // Returns the timestamp of the timer. This value determines the point in time when the timer will fire.    long getTimestamp();    // Returns the key that is bound to this timer.    @Nonnull @Override K getKey();    // Returns the namespace that is bound to this timer.    @Nonnull N getNamespace();&#125;public class InternalTimerServiceImpl&lt;K, N&gt; implements InternalTimerService&lt;N&gt;, ProcessingTimeCallback &#123;    /**     * Processing time timers that are currently in-flight.     */    private final KeyGroupedInternalPriorityQueue&lt;TimerHeapInternalTimer&lt;K, N&gt;&gt; processingTimeTimersQueue;    /**     * Event time timers that are currently in-flight.     */    private final KeyGroupedInternalPriorityQueue&lt;TimerHeapInternalTimer&lt;K, N&gt;&gt; eventTimeTimersQueue;    /**     * The local event time, as denoted by the last received     * &#123;@link org.apache.flink.streaming.api.watermark.Watermark Watermark&#125;.     */    private long currentWatermark = Long.MIN_VALUE;    private Triggerable&lt;K, N&gt; triggerTarget;&#125;</code></td>
</tr>
</tbody></table>
<p>Processing time timer 的触发依赖于 <code>ProcessingTimeService</code>，它负责所有基于系统时间的触发器的管理，内部使用 <code>ScheduledThreadPoolExecutor</code> 调度定时任务；当定时任务被触发时，<code>ProcessingTimeCallback</code> 的回调会被调用。实际上，<code>InternalTimerServiceImpl</code> 内部依赖了 <code>ProcessingTimeService</code>，并且 <code>InternalTimerServiceImpl</code> 实现了 <code>ProcessingTimeCallback</code> 接口。当注册一个 Processing time timer 的时候，会将 timer 加入优先级队列，并正确设置下一次 <code>ProcessingTimeService</code> 的触发时间；当 <code>ProcessingTimeService</code> 触发 <code>InternalTimerServiceImpl.onProcessingTime()</code> 回调后，会从优先级队列中取出所有符合条件的触发器，并调用 <code>triggerTarget.onProcessingTime(timer)</code>。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233343536</code></td>
<td><code>javapublic class InternalTimerServiceImpl&lt;K, N&gt; implements InternalTimerService&lt;N&gt;, ProcessingTimeCallback &#123;    private final ProcessingTimeService processingTimeService;    @Override    public void registerProcessingTimeTimer(N namespace, long time) &#123;        InternalTimer&lt;K, N&gt; oldHead = processingTimeTimersQueue.peek();        if (processingTimeTimersQueue.add(new TimerHeapInternalTimer&lt;&gt;(time, (K) keyContext.getCurrentKey(), namespace))) &#123;            long nextTriggerTime = oldHead != null ? oldHead.getTimestamp() : Long.MAX_VALUE;            // check if we need to re-schedule our timer to earlier            if (time &lt; nextTriggerTime) &#123; //如果新加入的timer触发时间早于下一次的触发时间，那么应该重新设置下一次触发时间                if (nextTimer != null) &#123;                    nextTimer.cancel(false);                &#125;                nextTimer = processingTimeService.registerTimer(time, this);            &#125;        &#125;    &#125;    @Override    public void onProcessingTime(long time) throws Exception &#123;        // null out the timer in case the Triggerable calls registerProcessingTimeTimer()        // inside the callback.        nextTimer = null;        InternalTimer&lt;K, N&gt; timer;        while ((timer = processingTimeTimersQueue.peek()) != null &amp;&amp; timer.getTimestamp() &lt;= time) &#123;            processingTimeTimersQueue.poll();            keyContext.setCurrentKey(timer.getKey());            triggerTarget.onProcessingTime(timer); // timer 关联的 triggerTarget.onProcessingTime 被调用        &#125;        if (timer != null &amp;&amp; nextTimer == null) &#123;            //注册下一次的触发任务            nextTimer = processingTimeService.registerTimer(timer.getTimestamp(), this);        &#125;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>Event time timer 的触发则依赖于系统当前的 watermark。当注册一个 Processing time timer 的时候，会将对应的 timer 加入优先级队列中；而一旦 watermark 上升，<code>InternalTimerServiceImpl.advanceWatermark()</code> 方法就会被调用，这时会检查优先级队列中所有触发时间早于当前 watermark 值的 timer，并依次调用 <code>triggerTarget.onEventTime(timer)</code> 方法。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 910111213141516</code></td>
<td><code>javapublic class InternalTimerServiceImpl&lt;K, N&gt; implements InternalTimerService&lt;N&gt;, ProcessingTimeCallback &#123;    public void advanceWatermark(long time) throws Exception &#123;        currentWatermark = time;        InternalTimer&lt;K, N&gt; timer;        while ((timer = eventTimeTimersQueue.peek()) != null &amp;&amp; timer.getTimestamp() &lt;= time) &#123;            eventTimeTimersQueue.poll();            keyContext.setCurrentKey(timer.getKey());            triggerTarget.onEventTime(timer);        &#125;    &#125;    @Override    public void registerEventTimeTimer(N namespace, long time) &#123;        eventTimeTimersQueue.add(new TimerHeapInternalTimer&lt;&gt;(time, (K) keyContext.getCurrentKey(), namespace));    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p><code>AbstractStreamOperator</code> 使用 <code>InternalTimeServiceManager</code> 管理所有的 <code>InternalTimerService</code>。在 <code>InternalTimeServiceManager</code> 内部，<code>InternalTimerService</code> 是和名称绑定的，<code>AbstractStreamOperator</code> 在获取 <code>InternalTimerService</code> 时必须指定名称，这样可以方便地将不同的触发对象 <code>Triggerable</code> 绑定到不同的 <code>InternalTimerService</code> 中。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556</code></td>
<td><code>java@Internalpublic class InternalTimeServiceManager&lt;K&gt; &#123;    //所有的 InternalTimerServiceImpl 和名称的映射关系    private final Map&lt;String, InternalTimerServiceImpl&lt;K, ?&gt;&gt; timerServices;        //获取 InternalTimerService， 必须指定名称    public &lt;N&gt; InternalTimerService&lt;N&gt; getInternalTimerService(        String name,        TimerSerializer&lt;K, N&gt; timerSerializer,        Triggerable&lt;K, N&gt; triggerable) &#123;        InternalTimerServiceImpl&lt;K, N&gt; timerService = registerOrGetTimerService(name, timerSerializer);        timerService.startTimerService(            timerSerializer.getKeySerializer(),            timerSerializer.getNamespaceSerializer(),            triggerable);        return timerService;    &#125;    public void advanceWatermark(Watermark watermark) throws Exception &#123;        for (InternalTimerServiceImpl&lt;?, ?&gt; service : timerServices.values()) &#123;            service.advanceWatermark(watermark.getTimestamp());        &#125;    &#125;&#125;public abstract class AbstractStreamOperator&lt;OUT&gt;        implements StreamOperator&lt;OUT&gt;, SetupableStreamOperator&lt;OUT&gt;, Serializable &#123;        protected transient InternalTimeServiceManager&lt;?&gt; timeServiceManager;    public &lt;K, N&gt; InternalTimerService&lt;N&gt; getInternalTimerService(            String name,            TypeSerializer&lt;N&gt; namespaceSerializer,            Triggerable&lt;K, N&gt; triggerable) &#123;        checkTimerServiceInitialization();        // the following casting is to overcome type restrictions.        KeyedStateBackend&lt;K&gt; keyedStateBackend = getKeyedStateBackend();        TypeSerializer&lt;K&gt; keySerializer = keyedStateBackend.getKeySerializer();        InternalTimeServiceManager&lt;K&gt; keyedTimeServiceHandler = (InternalTimeServiceManager&lt;K&gt;) timeServiceManager;        TimerSerializer&lt;K, N&gt; timerSerializer = new TimerSerializer&lt;&gt;(keySerializer, namespaceSerializer);        return keyedTimeServiceHandler.getInternalTimerService(name, timerSerializer, triggerable);    &#125;    //处理 watermark    public void processWatermark(Watermark mark) throws Exception &#123;        if (timeServiceManager != null) &#123;            timeServiceManager.advanceWatermark(mark);        &#125;        output.emitWatermark(mark);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>所有的 operator 的实现都可以通过 <code>InternalTimeServiceManager</code> 来管理 <code>InternalTimerService</code>，那么在用户提供的算子计算逻辑中又如何使用 timer 呢？以 <code>KeyedProcessOperator</code> 和 <code>KeyedProcessFunction</code> 为例，不同类型的 operator 的实现逻辑基本类似，但要注意的一点是，timer 必须在 keyed stream 中才能使用。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273</code></td>
<td><code>javapublic abstract class KeyedProcessFunction&lt;K, I, O&gt; extends AbstractRichFunction &#123;    private static final long serialVersionUID = 1L;    public abstract void processElement(I value, Context ctx, Collector&lt;O&gt; out) throws Exception;    //timer 触发的回调， OnTimerContext 是触发的上下文信息    public void onTimer(long timestamp, OnTimerContext ctx, Collector&lt;O&gt; out) throws Exception &#123;&#125;    /**     * Information available in an invocation of &#123;@link #processElement(Object, Context, Collector)&#125;     * or &#123;@link #onTimer(long, OnTimerContext, Collector)&#125;.     */    public abstract class Context &#123;        public abstract Long timestamp();        public abstract TimerService timerService(); //获取 TimerService，可以用于注册 timer        public abstract &lt;X&gt; void output(OutputTag&lt;X&gt; outputTag, X value);        public abstract K getCurrentKey();    &#125;    /**     * Information available in an invocation of &#123;@link #onTimer(long, OnTimerContext, Collector)&#125;.     */    public abstract class OnTimerContext extends Context &#123;        public abstract TimeDomain timeDomain();        @Override        public abstract K getCurrentKey();    &#125;&#125;public class KeyedProcessOperator&lt;K, IN, OUT&gt;        extends AbstractUdfStreamOperator&lt;OUT, KeyedProcessFunction&lt;K, IN, OUT&gt;&gt;        implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, VoidNamespace&gt; &#123;            @Override    public void open() throws Exception &#123;        super.open();        collector = new TimestampedCollector&lt;&gt;(output);        //注册了一个 TimerService，触发的目标是 KeyedProcessOperator 自身（实现了 Triggerable 接口）        InternalTimerService&lt;VoidNamespace&gt; internalTimerService =                getInternalTimerService(&quot;user-timers&quot;, VoidNamespaceSerializer.INSTANCE, this);        TimerService timerService = new SimpleTimerService(internalTimerService);        context = new ContextImpl(userFunction, timerService); //将 TimerService 封装在 ContextImpl 中        onTimerContext = new OnTimerContextImpl(userFunction, timerService);    &#125;    //event timer 触发    @Override    public void onEventTime(InternalTimer&lt;K, VoidNamespace&gt; timer) throws Exception &#123;        collector.setAbsoluteTimestamp(timer.getTimestamp());        invokeUserFunction(TimeDomain.EVENT_TIME, timer);    &#125;    //processing timer 触发    @Override    public void onProcessingTime(InternalTimer&lt;K, VoidNamespace&gt; timer) throws Exception &#123;        collector.eraseTimestamp();        invokeUserFunction(TimeDomain.PROCESSING_TIME, timer);    &#125;    private void invokeUserFunction(            TimeDomain timeDomain,            InternalTimer&lt;K, VoidNamespace&gt; timer) throws Exception &#123;        onTimerContext.timeDomain = timeDomain;        onTimerContext.timer = timer;        //user function 中的 timer 回调        userFunction.onTimer(timer.getTimestamp(), onTimerContext, collector);        onTimerContext.timeDomain = null;        onTimerContext.timer = null;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E7%AA%97%E5%8F%A3"></a>窗口</h2><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"></a>使用方法</h3><p>窗口的使用有两种基本方式，分别是 Keyed Windows 和 Non-Keyed Windows：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21</td>
<td>// Keyed Windowsstream       .keyBy(…)               &lt;-  keyed versus non-keyed windows       .window(…)              &lt;-  required: “assigner”      [.trigger(…)]            &lt;-  optional: “trigger” (else default trigger)      [.evictor(…)]            &lt;-  optional: “evictor” (else no evictor)      [.allowedLateness(…)]    &lt;-  optional: “lateness” (else zero)      [.sideOutputLateData(…)] &lt;-  optional: “output tag” (else no side output for late data)       .reduce/aggregate/fold/process()      &lt;-  required: “function”      [.getSideOutput(…)]      &lt;-  optional: “output tag”// Non-Keyed Windowsstream       .windowAll(…)           &lt;-  required: “assigner”      [.trigger(…)]            &lt;-  optional: “trigger” (else default trigger)      [.evictor(…)]            &lt;-  optional: “evictor” (else no evictor)      [.allowedLateness(…)]    &lt;-  optional: “lateness” (else zero)      [.sideOutputLateData(…)] &lt;-  optional: “output tag” (else no side output for late data)       .reduce/aggregate/fold/process()      &lt;-  required: “function”      [.getSideOutput(…)]      &lt;-  optional: “output tag”</td>
</tr>
</tbody></table>
<p>接下来，我们将重点关注 Keyed Windows 的实现方式，Non-Keyed Windows 实际上是基于 Keyed Windows 的一种特殊实现，在介绍了 Keyed Windows 的实现方式之后也会进行分析。</p>
<p>从基本的用法来看，首先使用 <code>WindowAssigner</code> 将 <code>KeyedStream</code> 转换为 <code>WindowedStream</code>；然后指定 1）窗口的计算逻辑，如聚合函数或 <code>ProcessWindowFunction</code> 2）触发窗口计算的 <code>Trigger</code> 3）能够修改窗口中元素的 <code>Evictor</code>，这时将会生成一个 <code>WindowOperator</code> （或其子类 <code>EvictingWindowOperator</code>）算子。窗口的主要的实现逻辑就在 <code>WindowOperator</code> 中。</p>
<h3 id="Window-和-WindowAssigner"><a href="#Window-和-WindowAssigner" class="headerlink" title="Window 和 WindowAssigner"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#window-%E5%92%8C-windowassigner"></a>Window 和 WindowAssigner</h3><p>窗口在 Flink 内部就是使用抽象类 <code>Window</code> 来表示，每一个窗口都有一个绑定的最大 timestamp，一旦时间超过这个值表明窗口结束了。<code>Window</code> 有两个具体实现类，分别为 <code>TimeWindow</code> 和 <code>GlobalWindow</code>：<code>TimeWindow</code> 就是时间窗口，每一个时间窗口都有开始时间和结束时间，可以对时间窗口进行合并操作（主要是在 Session Window 中）；<code>GlobalWindow</code> 是一个全局窗口，所有数据都属于该窗口，其最大 timestamp 是 <code>Long.MAX_VALUE</code>，使用单例模式。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 910111213141516171819202122</code></td>
<td><code>javapublic abstract class Window &#123;    public abstract long maxTimestamp();&#125;public class TimeWindow extends Window &#123;    private final long start;    private final long end;    @Override    public long maxTimestamp() &#123;        return end - 1;    &#125;&#125;public class GlobalWindow extends Window &#123;    private static final GlobalWindow INSTANCE = new GlobalWindow();    @Override    public long maxTimestamp() &#123;        return Long.MAX_VALUE;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p><code>WindowAssigner</code> 确定每一条消息属于哪些窗口，一条消息可能属于多个窗口（如在滑动窗口中，窗口之间可能有重叠）；<code>MergingWindowAssigner</code> 是 <code>WindowAssigner</code> 的抽象子类，主要是提供了对时间窗口的合并功能。窗口合并的逻辑在 <code>TimeWindow</code> 提供的工具方法 <code>mergeWindows(Collection&lt;TimeWindow&gt; windows, MergingWindowAssigner.MergeCallback&lt;TimeWindow&gt; c)</code> 中，会对所有窗口按开始时间排序，存在重叠的窗口就可以进行合并。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233</code></td>
<td><code>javapublic abstract class WindowAssigner&lt;T, W extends Window&gt; implements Serializable &#123;    public abstract Collection&lt;W&gt; assignWindows(T element, long timestamp, WindowAssignerContext context);    public abstract boolean isEventTime();    public abstract Trigger&lt;T, W&gt; getDefaultTrigger(StreamExecutionEnvironment env);    public abstract TypeSerializer&lt;W&gt; getWindowSerializer(ExecutionConfig executionConfig);        public abstract static class WindowAssignerContext &#123;        public abstract long getCurrentProcessingTime();    &#125;&#125;public abstract class MergingWindowAssigner&lt;T, W extends Window&gt; extends WindowAssigner&lt;T, W&gt; &#123;    private static final long serialVersionUID = 1L;    public abstract void mergeWindows(Collection&lt;W&gt; windows, MergeCallback&lt;W&gt; callback);    /**     * Callback to be used in &#123;@link #mergeWindows(Collection, MergeCallback)&#125; for specifying which     * windows should be merged.     */    public interface MergeCallback&lt;W&gt; &#123;        /**         * Specifies that the given windows should be merged into the result window.         *         * @param toBeMerged The list of windows that should be merged into one window.         * @param mergeResult The resulting merged window.         */        void merge(Collection&lt;W&gt; toBeMerged, W mergeResult);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>根据窗口类型和时间属性的不同，有不同的 <code>WindowAssigner</code> 的具体实现，如 <code>TumblingEventTimeWindows</code>, <code>TumblingProcessingTimeWindows</code>, <code>SlidingEventTimeWindows</code>, <code>SlidingProcessingTimeWindows</code>, <code>EventTimeSessionWindows</code>, <code>ProcessingTimeSessionWindows</code>, <code>DynamicEventTimeSessionWindows</code>, <code>DynamicProcessingTimeSessionWindows</code>, 以及 <code>GlobalWindows</code>。具体的实现逻辑这里就不赘述了。</p>
<h3 id="Trigger-1"><a href="#Trigger-1" class="headerlink" title="Trigger"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#trigger-1"></a>Trigger</h3><p><code>Trigger</code> 用来确定一个窗口是否应该触发结果的计算，<code>Trigger</code> 提供了一系列的回调函数，根据回调函数返回的结果来决定是否应该触发窗口的计算。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829303132333435363738394041424344454647484950515253</code></td>
<td><code>javapublic abstract class Trigger&lt;T, W extends Window&gt; implements Serializable &#123;    /**     * Called for every element that gets added to a pane. The result of this will determine     * whether the pane is evaluated to emit results.     *     * @param element The element that arrived.     * @param timestamp The timestamp of the element that arrived.     * @param window The window to which the element is being added.     * @param ctx A context object that can be used to register timer callbacks.     */    public abstract TriggerResult onElement(T element, long timestamp, W window, TriggerContext ctx) throws Exception;        /**     * Called when a processing-time timer that was set using the trigger context fires.     *     * @param time The timestamp at which the timer fired.     * @param window The window for which the timer fired.     * @param ctx A context object that can be used to register timer callbacks.     */    public abstract TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception;    /**     * Called when an event-time timer that was set using the trigger context fires.     *     * @param time The timestamp at which the timer fired.     * @param window The window for which the timer fired.     * @param ctx A context object that can be used to register timer callbacks.     */    public abstract TriggerResult onEventTime(long time, W window, TriggerContext ctx) throws Exception;    /**     * Returns true if this trigger supports merging of trigger state and can therefore     * be used with a     * &#123;@link org.apache.flink.streaming.api.windowing.assigners.MergingWindowAssigner&#125;.     *     * &lt;p&gt;If this returns &#123;@code true&#125; you must properly implement     * &#123;@link #onMerge(Window, OnMergeContext)&#125;     */    public boolean canMerge() &#123;        return false;    &#125;    /**     * Called when several windows have been merged into one window by the     * &#123;@link org.apache.flink.streaming.api.windowing.assigners.WindowAssigner&#125;.     *     * @param window The new window that results from the merge.     * @param ctx A context object that can be used to register timer callbacks and access state.     */    public void onMerge(W window, OnMergeContext ctx) throws Exception &#123;        throw new UnsupportedOperationException(&quot;This trigger does not support merging.&quot;);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>Flink 提供了一些内置的 <code>Trigger</code> 实现，这些 <code>Trigger</code> 内部往往配合 timer 定时器进行使用，例如 <code>EventTimeTrigger</code> 是所有事件时间窗口的默认触发器，<code>ProcessingTimeTrigger</code> 是所有处理时间窗口的默认触发器，<code>ContinuousEventTimeTrigger</code> 和 <code>ContinuousProcessingTimeTrigger</code> 定期进行触发，<code>CountTrigger</code> 按照窗口内元素个数进行触发，<code>DeltaTrigger</code> 按照 <code>DeltaFunction</code> 进行触发，<code>NeverTrigger</code> 主要在全局窗口中使用，永远不会触发。</p>
<h3 id="WindowOperator"><a href="#WindowOperator" class="headerlink" title="WindowOperator"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#windowoperator"></a>WindowOperator</h3><p>Window 操作的主要处理逻辑在 <code>WindowOperator</code> 中。由于 window 的使用方式比较比较灵活，下面我们将先介绍最通用的窗口处理逻辑的实现，接着介绍窗口聚合函数的实现，最后介绍对可以合并的窗口的处理逻辑。</p>
<h4 id="窗口处理逻辑"><a href="#窗口处理逻辑" class="headerlink" title="窗口处理逻辑"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E7%AA%97%E5%8F%A3%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91"></a>窗口处理逻辑</h4><p>首先，我们来看一下 <code>WindowOperator</code> 的构造函数，确认它所依赖的比较重要的一些对象：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829</code></td>
<td><code>javapublic class WindowOperator&lt;K, IN, ACC, OUT, W extends Window&gt;    extends AbstractUdfStreamOperator&lt;OUT, InternalWindowFunction&lt;ACC, OUT, K, W&gt;&gt;    implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, W&gt; &#123;    public WindowOperator(            WindowAssigner&lt;? super IN, W&gt; windowAssigner,            TypeSerializer&lt;W&gt; windowSerializer,            KeySelector&lt;IN, K&gt; keySelector,            TypeSerializer&lt;K&gt; keySerializer,            StateDescriptor&lt;? extends AppendingState&lt;IN, ACC&gt;, ?&gt; windowStateDescriptor,            InternalWindowFunction&lt;ACC, OUT, K, W&gt; windowFunction,            Trigger&lt;? super IN, ? super W&gt; trigger,            long allowedLateness,            OutputTag&lt;IN&gt; lateDataOutputTag) &#123;        super(windowFunction);        this.windowAssigner = checkNotNull(windowAssigner);        this.windowSerializer = checkNotNull(windowSerializer);        this.keySelector = checkNotNull(keySelector);        this.keySerializer = checkNotNull(keySerializer);        this.windowStateDescriptor = windowStateDescriptor;        this.trigger = checkNotNull(trigger);        this.allowedLateness = allowedLateness;        this.lateDataOutputTag = lateDataOutputTag;        setChainingStrategy(ChainingStrategy.ALWAYS);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>可以看出，构造 <code>WindowOperator</code> 时需要提供的比较重要的对象包括 <code>WindowAssigner</code>, <code>Trigger</code>, <code>StateDescriptor&lt;? extends AppendingState&lt;IN, ACC&gt;, ?&gt;</code> 以及 <code>InternalWindowFunction&lt;ACC, OUT, K, W&gt;</code>。其中，<code>StateDescriptor&lt;? extends AppendingState&lt;IN, ACC&gt;, ?&gt;</code> 是窗口状态的描述符，窗口的状态必须是 <code>AppendingState</code> 的子类；<code>InternalWindowFunction&lt;ACC, OUT, K, W&gt;</code> 是窗口的计算函数，从名字也可以看出，这是 Flink 内部使用的接口，不对外暴露。</p>
<p>在使用窗口时，最一般化的使用方式是通过 <code>ProcessWindowFunction</code> 或 <code>WindowFunction</code> 指定计算逻辑，<code>ProcessWindowFunction</code> 和 <code>WindowFunction</code> 会被包装成 <code>InternalWindowFunction</code> 的子类。<code>WindowFunction</code> 和 <code>ProcessWindowFunction</code> 的效果在某些场景下是一致的，但 <code>ProcessWindowFunction</code> 能够提供更多的窗口上下文信息，并且在之后的版本中可能会移除 <code>WindowFunction</code> 接口：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233</code></td>
<td><code>javapublic class WindowedStream&lt;T, K, W extends Window&gt; &#123;    @Internal    public &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; process(ProcessWindowFunction&lt;T, R, K, W&gt; function, TypeInformation&lt;R&gt; resultType) &#123;        function = input.getExecutionEnvironment().clean(function);        return apply(new InternalIterableProcessWindowFunction&lt;&gt;(function), resultType, function);    &#125;    private &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; apply(InternalWindowFunction&lt;Iterable&lt;T&gt;, R, K, W&gt; function, TypeInformation&lt;R&gt; resultType, Function originalFunction) &#123;        final String opName = generateOperatorName(windowAssigner, trigger, evictor, originalFunction, null);        KeySelector&lt;T, K&gt; keySel = input.getKeySelector();        WindowOperator&lt;K, T, Iterable&lt;T&gt;, R, W&gt; operator;        if (evictor != null) &#123;            .......        &#125; else &#123;            ListStateDescriptor&lt;T&gt; stateDesc = new ListStateDescriptor&lt;&gt;(&quot;window-contents&quot;,                input.getType().createSerializer(getExecutionEnvironment().getConfig()));            operator =                new WindowOperator&lt;&gt;(windowAssigner,                    windowAssigner.getWindowSerializer(getExecutionEnvironment().getConfig()),                    keySel,                    input.getKeyType().createSerializer(getExecutionEnvironment().getConfig()),                    stateDesc,                    function,                    trigger,                    allowedLateness,                    lateDataOutputTag);        &#125;        return input.transform(opName, resultType, operator);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>可以看出，用户提供的 <code>ProcessWindowFunction</code> 被包装成 <code>InternalIterableProcessWindowFunction</code> 提供给 <code>WindowOperator</code>，并且 window 使用的状态是 <code>ListState</code>。</p>
<p>在 <code>WindowOperator.open()</code> 方法中会进行一些初始化操作，包括创建一个名为 window-timers 的 <code>InternalTimerService</code> 用于注册各种定时器，定时器的触发对象是 <code>WindowOperator</code> 自身。同时，会创建各种上下文对象，并初始化窗口状态。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930</code></td>
<td><code>javapublic class WindowOperator&lt;K, IN, ACC, OUT, W extends Window&gt;    extends AbstractUdfStreamOperator&lt;OUT, InternalWindowFunction&lt;ACC, OUT, K, W&gt;&gt;    implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, W&gt; &#123;    @Override    public void open() throws Exception &#123;        super.open();        this.numLateRecordsDropped = metrics.counter(LATE_ELEMENTS_DROPPED_METRIC_NAME);        timestampedCollector = new TimestampedCollector&lt;&gt;(output);        internalTimerService =                getInternalTimerService(&quot;window-timers&quot;, windowSerializer, this);        triggerContext = new Context(null, null);        processContext = new WindowContext(null);        windowAssignerContext = new WindowAssigner.WindowAssignerContext() &#123;            @Override            public long getCurrentProcessingTime() &#123;                return internalTimerService.currentProcessingTime();            &#125;        &#125;;        // create (or restore) the state that hold the actual window contents        // NOTE - the state may be null in the case of the overriding evicting window operator        if (windowStateDescriptor != null) &#123;            windowState = (InternalAppendingState&lt;K, W, IN, ACC, ACC&gt;) getOrCreateKeyedState(windowSerializer, windowStateDescriptor);        &#125;        .......&#125;</code></td>
</tr>
</tbody></table>
<p>当消息到达时，在窗口算子中的处理流程大致如下：</p>
<ul>
<li>  通过 <code>WindowAssigner</code> 确定消息所在的窗口（可能属于多个窗口）</li>
<li>  将消息加入到对应窗口的状态中</li>
<li>  根据 <code>Trigger.onElement</code> 确定是否应该触发窗口结果的计算，如果使用 <code>InternalWindowFunction</code> 对窗口进行处理</li>
<li>  注册一个定时器，在窗口结束时清理窗口状态</li>
<li>  如果消息太晚到达，提交到 side output 中</li>
</ul>
<p>如下：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576</code></td>
<td><code>javapublic class WindowOperator&lt;K, IN, ACC, OUT, W extends Window&gt;    extends AbstractUdfStreamOperator&lt;OUT, InternalWindowFunction&lt;ACC, OUT, K, W&gt;&gt;    implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, W&gt; &#123;        @Override    public void processElement(StreamRecord&lt;IN&gt; element) throws Exception &#123;        final Collection&lt;W&gt; elementWindows = windowAssigner.assignWindows(            element.getValue(), element.getTimestamp(), windowAssignerContext);        //if element is handled by none of assigned elementWindows        boolean isSkippedElement = true;        final K key = this.&lt;K&gt;getKeyedStateBackend().getCurrentKey();            if (windowAssigner instanceof MergingWindowAssigner) &#123;            ......        &#125; else &#123;            for (W window: elementWindows) &#123;                // drop if the window is already late                if (isWindowLate(window)) &#123;                    continue;                &#125;                isSkippedElement = false;                windowState.setCurrentNamespace(window); //用 window 作为 state 的 namespace                windowState.add(element.getValue()); //消息加入到状态中                triggerContext.key = key;                triggerContext.window = window;                //通过 Trigger.onElement() 判断是否触发窗口结果的计算                TriggerResult triggerResult = triggerContext.onElement(element);                if (triggerResult.isFire()) &#123;                    ACC contents = windowState.get(); //获取窗口状态                    if (contents == null) &#123;                        continue;                    &#125;                    emitWindowContents(window, contents);                &#125;                //是否需要清除窗口状态                if (triggerResult.isPurge()) &#123;                    windowState.clear();                &#125;                //注册一个定时器，窗口结束后清理状态                registerCleanupTimer(window);            &#125;        &#125;        // 迟到的数据        if (isSkippedElement &amp;&amp; isElementLate(element)) &#123;            if (lateDataOutputTag != null)&#123;                sideOutput(element);            &#125; else &#123;                this.numLateRecordsDropped.inc();            &#125;        &#125;    &#125;    protected void registerCleanupTimer(W window) &#123;        long cleanupTime = cleanupTime(window);        if (cleanupTime == Long.MAX_VALUE) &#123;            // don&#39;t set a GC timer for &quot;end of time&quot;            return;        &#125;        if (windowAssigner.isEventTime()) &#123;            triggerContext.registerEventTimeTimer(cleanupTime);        &#125; else &#123;            triggerContext.registerProcessingTimeTimer(cleanupTime);        &#125;    &#125;    //注意，这里窗口的清理时间是 window.maxTimestamp + allowedLateness    private long cleanupTime(W window) &#123;        if (windowAssigner.isEventTime()) &#123;            long cleanupTime = window.maxTimestamp() + allowedLateness;            return cleanupTime &gt;= window.maxTimestamp() ? cleanupTime : Long.MAX_VALUE;        &#125; else &#123;            return window.maxTimestamp();        &#125;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>当定时器到期是，会调用 <code>Trigger.onEventTime</code> 判断是否需要触发窗口结果的计算；并且如果是窗口结束的定时器，会清理掉窗口的状态。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829</code></td>
<td><code>javapublic class WindowOperator&lt;K, IN, ACC, OUT, W extends Window&gt;    extends AbstractUdfStreamOperator&lt;OUT, InternalWindowFunction&lt;ACC, OUT, K, W&gt;&gt;    implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, W&gt; &#123;    @Override    public void onEventTime(InternalTimer&lt;K, W&gt; timer) throws Exception &#123;        triggerContext.key = timer.getKey();        triggerContext.window = timer.getNamespace();        ......        TriggerResult triggerResult = triggerContext.onEventTime(timer.getTimestamp());        if (triggerResult.isFire()) &#123;//触发窗口结果的计算            ACC contents = windowState.get(); //获取状态            if (contents != null) &#123;                emitWindowContents(triggerContext.window, contents);            &#125;        &#125;        if (triggerResult.isPurge()) &#123;            windowState.clear();        &#125;        if (windowAssigner.isEventTime() &amp;&amp; isCleanupTime(triggerContext.window, timer.getTimestamp())) &#123;            clearAllState(triggerContext.window, windowState, mergingWindows);        &#125;        ......    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>当需要进行窗口结果的计算时，会取出当前窗口所保存的状态，调用用户提供的 <code>ProcessWindowFunction</code> 进行处理：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223</code></td>
<td><code>javapublic class WindowOperator&lt;K, IN, ACC, OUT, W extends Window&gt;    extends AbstractUdfStreamOperator&lt;OUT, InternalWindowFunction&lt;ACC, OUT, K, W&gt;&gt;    implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, W&gt; &#123;        private void emitWindowContents(W window, ACC contents) throws Exception &#123;        timestampedCollector.setAbsoluteTimestamp(window.maxTimestamp());        processContext.window = window;        userFunction.process(triggerContext.key, window, processContext, contents, timestampedCollector);    &#125;&#125;public final class InternalIterableProcessWindowFunction&lt;IN, OUT, KEY, W extends Window&gt;        extends WrappingFunction&lt;ProcessWindowFunction&lt;IN, OUT, KEY, W&gt;&gt;        implements InternalWindowFunction&lt;Iterable&lt;IN&gt;, OUT, KEY, W&gt; &#123;        @Override    public void process(KEY key, final W window, final InternalWindowContext context, Iterable&lt;IN&gt; input, Collector&lt;OUT&gt; out) throws Exception &#123;        this.ctx.window = window;        this.ctx.internalContext = context;        ProcessWindowFunction&lt;IN, OUT, KEY, W&gt; wrappedFunction = this.wrappedFunction;        wrappedFunction.process(key, ctx, input, out);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<h4 id="增量窗口聚合"><a href="#增量窗口聚合" class="headerlink" title="增量窗口聚合"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E5%A2%9E%E9%87%8F%E7%AA%97%E5%8F%A3%E8%81%9A%E5%90%88"></a>增量窗口聚合</h4><p>从上面对窗口处理逻辑的介绍我们可以看出，在使用 <code>ProcessWindowFunction</code> 来对窗口进行操作的一个重要缺陷是，需要把整个窗口内的所有消息全部缓存在 <code>ListState</code> 中，这无疑会导致性能问题。如果窗口的计算逻辑支持增量聚合操作，那么可以使用 <code>ReduceFunction</code>, <code>AggregateFunction</code> 或 <code>FoldFunction</code> 进行增量窗口聚合计算，这可以在很大程度上解决 <code>ProcessWindowFunction</code> 的性能问题。</p>
<p>使用 <code>ReduceFunction</code>, <code>AggregateFunction</code> 或 <code>FoldFunction</code> 进行在窗口聚合的底层实现是类似的，区别只在于聚合函数的不同。其中 <code>AggregateFunction</code> 是最通用的函数，我们以 <code>AggregateFunction</code> 为例进行分析。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233343536373839404142434445464748495051</code></td>
<td><code>javapublic class WindowedStream&lt;T, K, W extends Window&gt; &#123;    public &lt;ACC, R&gt; SingleOutputStreamOperator&lt;R&gt; aggregate(            AggregateFunction&lt;T, ACC, R&gt; function,            TypeInformation&lt;ACC&gt; accumulatorType,            TypeInformation&lt;R&gt; resultType) &#123;        checkNotNull(function, &quot;function&quot;);        checkNotNull(accumulatorType, &quot;accumulatorType&quot;);        checkNotNull(resultType, &quot;resultType&quot;);        if (function instanceof RichFunction) &#123;            throw new UnsupportedOperationException(&quot;This aggregation function cannot be a RichFunction.&quot;);        &#125;        return aggregate(function, new PassThroughWindowFunction&lt;K, W, R&gt;(),            accumulatorType, resultType);    &#125;    @PublicEvolving    public &lt;ACC, V, R&gt; SingleOutputStreamOperator&lt;R&gt; aggregate(            AggregateFunction&lt;T, ACC, V&gt; aggregateFunction,            WindowFunction&lt;V, R, K, W&gt; windowFunction,            TypeInformation&lt;ACC&gt; accumulatorType,            TypeInformation&lt;R&gt; resultType) &#123;        ......        final String opName = generateOperatorName(windowAssigner, trigger, evictor, aggregateFunction, windowFunction);        KeySelector&lt;T, K&gt; keySel = input.getKeySelector();        OneInputStreamOperator&lt;T, R&gt; operator;        if (evictor != null) &#123;            .......        &#125; else &#123;            //注意，这里不再是 ListState，而是支持聚合操作的 AggregatingState，其聚合函数就是用户代码提供的            AggregatingStateDescriptor&lt;T, ACC, V&gt; stateDesc = new AggregatingStateDescriptor&lt;&gt;(&quot;window-contents&quot;,                    aggregateFunction, accumulatorType.createSerializer(getExecutionEnvironment().getConfig()));            operator = new WindowOperator&lt;&gt;(windowAssigner,                    windowAssigner.getWindowSerializer(getExecutionEnvironment().getConfig()),                    keySel,                    input.getKeyType().createSerializer(getExecutionEnvironment().getConfig()),                    stateDesc,                    new InternalSingleValueWindowFunction&lt;&gt;(windowFunction),                     trigger,                    allowedLateness,                    lateDataOutputTag);        &#125;        return input.transform(opName, resultType, operator);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>可以看出来，如果使用了增量聚合函数，那么窗口的状态就不再是以 <code>ListState</code> 的形式保存窗口中的所有元素，而是 <code>AggregatingState</code>。这样，每当窗口中新消息到达时，在将消息添加到状态中的同时就会触发聚合函数的计算，这样在状态中就只需要保存聚合后的状态即可。</p>
<p>在上面直接使用 <code>AggregateFunction</code> 的情况下，用户代码中无法访问窗口的上下文信息。为了解决这个问题，可以将增量聚合函数和 <code>ProcessWindowFunction</code> 结合在一起使用，这样在提交窗口计算结果时也可以访问到窗口的上下文信息：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 910111213141516171819202122232425262728293031323334</code></td>
<td><code>javapublic class WindowedStream&lt;T, K, W extends Window&gt; &#123;    public &lt;ACC, V, R&gt; SingleOutputStreamOperator&lt;R&gt; aggregate(            AggregateFunction&lt;T, ACC, V&gt; aggregateFunction,            ProcessWindowFunction&lt;V, R, K, W&gt; windowFunction,            TypeInformation&lt;ACC&gt; accumulatorType,            TypeInformation&lt;V&gt; aggregateResultType,            TypeInformation&lt;R&gt; resultType) &#123;        .......        final String opName = generateOperatorName(windowAssigner, trigger, evictor, aggregateFunction, windowFunction);        KeySelector&lt;T, K&gt; keySel = input.getKeySelector();        OneInputStreamOperator&lt;T, R&gt; operator;        if (evictor != null) &#123;            ........        &#125; else &#123;            AggregatingStateDescriptor&lt;T, ACC, V&gt; stateDesc = new AggregatingStateDescriptor&lt;&gt;(&quot;window-contents&quot;,                    aggregateFunction, accumulatorType.createSerializer(getExecutionEnvironment().getConfig()));            operator = new WindowOperator&lt;&gt;(windowAssigner,                    windowAssigner.getWindowSerializer(getExecutionEnvironment().getConfig()),                    keySel,                    input.getKeyType().createSerializer(getExecutionEnvironment().getConfig()),                    stateDesc,                    new InternalSingleValueProcessWindowFunction&lt;&gt;(windowFunction),                    trigger,                    allowedLateness,                    lateDataOutputTag);        &#125;        return input.transform(opName, resultType, operator);    &#125;&#125;</code></td>
</tr>
</tbody></table>
<h4 id="合并窗口"><a href="#合并窗口" class="headerlink" title="合并窗口"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E5%90%88%E5%B9%B6%E7%AA%97%E5%8F%A3"></a>合并窗口</h4><p>前面在介绍窗口的实现逻辑时都只是考虑了窗口不会发生合并的情况。在一些情况下，窗口的边界不是固定的，可能会随着消息的到达不断进行调整，例如 session window，这就情况下就会发生窗口的合并。</p>
<p>可以合并的窗口相比于不可以合并的窗口，在 <code>WindowOperator.open</code> 方法中除了初始化窗口状态之外，还会初始化一个新的 <code>mergingSetsState</code> 用于保存窗口合并状态：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829303132333435363738394041</code></td>
<td><code>javapublic class WindowOperator&lt;K, IN, ACC, OUT, W extends Window&gt;    extends AbstractUdfStreamOperator&lt;OUT, InternalWindowFunction&lt;ACC, OUT, K, W&gt;&gt;    implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, W&gt; &#123;    @Override    public void open() throws Exception &#123;        ......        // create (or restore) the state that hold the actual window contents        // NOTE - the state may be null in the case of the overriding evicting window operator        if (windowStateDescriptor != null) &#123;            windowState = (InternalAppendingState&lt;K, W, IN, ACC, ACC&gt;) getOrCreateKeyedState(windowSerializer, windowStateDescriptor);        &#125;        // create the typed and helper states for merging windows        if (windowAssigner instanceof MergingWindowAssigner) &#123;            // store a typed reference for the state of merging windows - sanity check            // 窗口状态必须是可以合并的            if (windowState instanceof InternalMergingState) &#123;                windowMergingState = (InternalMergingState&lt;K, W, IN, ACC, ACC&gt;) windowState;            &#125; else if (windowState != null) &#123;                throw new IllegalStateException(                        &quot;The window uses a merging assigner, but the window state is not mergeable.&quot;);            &#125;            @SuppressWarnings(&quot;unchecked&quot;)            final Class&lt;Tuple2&lt;W, W&gt;&gt; typedTuple = (Class&lt;Tuple2&lt;W, W&gt;&gt;) (Class&lt;?&gt;) Tuple2.class;            final TupleSerializer&lt;Tuple2&lt;W, W&gt;&gt; tupleSerializer = new TupleSerializer&lt;&gt;(                    typedTuple,                    new TypeSerializer[] &#123;windowSerializer, windowSerializer&#125;);            final ListStateDescriptor&lt;Tuple2&lt;W, W&gt;&gt; mergingSetsStateDescriptor =                    new ListStateDescriptor&lt;&gt;(&quot;merging-window-set&quot;, tupleSerializer);            // 创建一个 ListState&lt;Tuple2&lt;W,W&gt;&gt; 用于保存合并的窗口集合            // get the state that stores the merging sets            mergingSetsState = (InternalListState&lt;K, VoidNamespace, Tuple2&lt;W, W&gt;&gt;)                    getOrCreateKeyedState(VoidNamespaceSerializer.INSTANCE, mergingSetsStateDescriptor);            mergingSetsState.setCurrentNamespace(VoidNamespace.INSTANCE);        &#125;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>相比于不可合并的窗口，可以合并的窗口实现上的一个难点就在于窗口合并时状态的处理，这需要依赖于 <code>mergingSetsState</code> 和 <code>MergingWindowSet</code>。我们先来梳理下窗口合并时窗口状态的处理，然后再详细地看具体的实现。</p>
<p>首先，可以合并的窗口要求窗口状态必须是可以合并的，只有这样，当两个窗口进行合并时其状态才可以正确地保存，<code>ListState</code>，<code>ReducingState</code>和 <code>AggregatingState</code> 都继承了 <code>MergingState</code> 接口。 <code>InternalMergingState</code> 接口提供了将多个 namespace 关联的状态合并到目标 namespace 的功能，注意方法的签名是将一组作为 source 的 namespace 合并到作为 target 的 namespace ：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112</code></td>
<td><code>javapublic interface InternalMergingState&lt;K, N, IN, SV, OUT&gt; extends InternalAppendingState&lt;K, N, IN, SV, OUT&gt;, MergingState&lt;IN, OUT&gt; &#123;    /**     * Merges the state of the current key for the given source namespaces into the state of     * the target namespace.     *      * @param target The target namespace where the merged state should be stored.     * @param sources The source namespaces whose state should be merged.     *      * @throws Exception The method may forward exception thrown internally (by I/O or functions).     */    void mergeNamespaces(N target, Collection&lt;N&gt; sources) throws Exception;&#125;</code></td>
</tr>
</tbody></table>
<p>现在我们考虑窗口合并的情况。如下图所示，w1 窗口的状态 s1 (w1 也是 s1 的 namespace)，w2 窗口的状态 s2 (w2 也是 s2 的 namespace)，现在新增了一个窗口 w3，则应该对窗口进行合并，将 w1, w2, w3 合并为一个新的窗口 w4。在这种情况下，我们也需要对窗口的状态进行合并。按照常规的思路，我们应该以 w4 作为合并之后窗口状态的 namespace，调用 <code>mergeNamespaces(w4, Collection(w1,w2,w3))</code> 进行状态合并。但是以 w4 作为 namespace 的状态并不存在，因此考虑继续使用 w1 作为窗口 w4 状态的 namespace，即调用 <code>mergeNamespaces(w1, Collection(w2,w3))</code> 进行状态合并，但要将 <code>w4 -&gt; w1</code> 的映射关系保存起来，以便查找窗口的状态。这种 <code>窗口 -&gt; 窗口状态的 namespace</code> 的映射关系就保存在 <code>InternalListState&lt;K, VoidNamespace, Tuple2&lt;W, W&gt;&gt; mergingSetsState</code> 中。</p>
<p><a href="https://blog.jrwang.me/img/flink/mergingwindow-state.svg"><img src="vx_images/4364001218596.svg" alt="mergingwindow-state"></a></p>
<p><code>WindowOperator</code> 内部对窗口合并的处理如下，主要是借助 <code>MergingWindowSet</code> 进行窗口的合并：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889</code></td>
<td><code>javapublic class WindowOperator&lt;K, IN, ACC, OUT, W extends Window&gt;    extends AbstractUdfStreamOperator&lt;OUT, InternalWindowFunction&lt;ACC, OUT, K, W&gt;&gt;    implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, W&gt; &#123;    @Override    public void processElement(StreamRecord&lt;IN&gt; element) throws Exception &#123;        final Collection&lt;W&gt; elementWindows = windowAssigner.assignWindows(                element.getValue(), element.getTimestamp(), windowAssignerContext);        boolean isSkippedElement = true;        final K key = this.&lt;K&gt;getKeyedStateBackend().getCurrentKey();        if (windowAssigner instanceof MergingWindowAssigner) &#123;            MergingWindowSet&lt;W&gt; mergingWindows = getMergingWindowSet(); //获取 MergingWindowSet，这是辅助进行窗口合并的工具            for (W window : elementWindows) &#123;                // adding the new window might result in a merge, in that case the actualWindow                // is the merged window and we work with that. If we don&#39;t merge then                // actualWindow == window                W actualWindow = mergingWindows.addWindow(window,                        new MergingWindowSet.MergeFunction&lt;W&gt;() &#123; //这是合并窗口的回调函数                            @Override                            public void merge(                                    W mergeResult, //这是合并后的窗口                                    Collection&lt;W&gt; mergedWindows, //这是被合并的窗口                                    W stateWindowResult, //这是用作合并后窗口状态的 namespace                                    Collection&lt;W&gt; mergedStateWindows //这是被合并的状态的 namespace                                ) throws Exception &#123;                                .......                                triggerContext.key = key;                                triggerContext.window = mergeResult;                                triggerContext.onMerge(mergedWindows); //调用 Trigger.onMerger 判断是否需要进行触发                                for (W m : mergedWindows) &#123;                                    triggerContext.window = m;                                    triggerContext.clear();                                    deleteCleanupTimer(m);                                &#125;                                // 合并窗口状态                                // merge the merged state windows into the newly resulting state window                                evictingWindowState.mergeNamespaces(stateWindowResult, mergedStateWindows);                            &#125;                        &#125;);                // drop if the window is already late                if (isWindowLate(actualWindow)) &#123;                    mergingWindows.retireWindow(actualWindow);                    continue;                &#125;                isSkippedElement = false;                W stateWindow = mergingWindows.getStateWindow(actualWindow);                if (stateWindow == null) &#123;                    throw new IllegalStateException(&quot;Window &quot; + window + &quot; is not in in-flight window set.&quot;);                &#125;                evictingWindowState.setCurrentNamespace(stateWindow);                evictingWindowState.add(element);                triggerContext.key = key;                triggerContext.window = actualWindow;                evictorContext.key = key;                evictorContext.window = actualWindow;                TriggerResult triggerResult = triggerContext.onElement(element);                if (triggerResult.isFire()) &#123;                    Iterable&lt;StreamRecord&lt;IN&gt;&gt; contents = evictingWindowState.get();                    if (contents == null) &#123;                        // if we have no state, there is nothing to do                        continue;                    &#125;                    emitWindowContents(actualWindow, contents, evictingWindowState);                &#125;                if (triggerResult.isPurge()) &#123;                    evictingWindowState.clear();                &#125;                registerCleanupTimer(actualWindow);            &#125;            // need to make sure to update the merging state in state            mergingWindows.persist();        &#125; else &#123;            ........        &#125;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>窗口合并的主要逻辑被封装在 <code>MergingWindowSet</code> 中，需要重点关注合并时对<code>窗口 -&gt; 窗口状态的 namespace</code> 的映射关系的处理，结合前面的分析应该可以理解：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677</code></td>
<td>```javapublic class MergingWindowSet<W extends Window> {    private final Map&lt;W, W&gt; mapping; //这里保存的就是 <code>窗口 -&gt; 窗口状态的 namespace</code> 的映射关系    public W addWindow(W newWindow, MergeFunction<W> mergeFunction) throws Exception {        List<W> windows = new ArrayList&lt;&gt;();        windows.addAll(this.mapping.keySet());        windows.add(newWindow);        //确定能够合并的窗口，在回调函数中将窗口的合并结果保存在mergeResults        final Map&lt;W, Collection<W>&gt; mergeResults = new HashMap&lt;&gt;();        windowAssigner.mergeWindows(windows,                new MergingWindowAssigner.MergeCallback<W>() {                    @Override                    public void merge(Collection<W> toBeMerged, W mergeResult) {                        mergeResults.put(mergeResult, toBeMerged);                    }                });        W resultWindow = newWindow;        boolean mergedNewWindow = false;        // perform the merge        for (Map.Entry&lt;W, Collection<W>&gt; c: mergeResults.entrySet()) {            W mergeResult = c.getKey(); //合并后产生的窗口            Collection<W> mergedWindows = c.getValue(); //被合并的窗口            // if our new window is in the merged windows make the merge result the            // result window            if (mergedWindows.remove(newWindow)) {                mergedNewWindow = true;                resultWindow = mergeResult;            }            // pick any of the merged windows and choose that window’s state window            // as the state window for the merge result            //从需要被合并的窗口中选择一个作为合并后状态的namespace            W mergedStateWindow = this.mapping.get(mergedWindows.iterator().next());            // figure out the state windows that we are merging            List<W> mergedStateWindows = new ArrayList&lt;&gt;();            for (W mergedWindow: mergedWindows) {                //移除旧的映射关系                W res = this.mapping.remove(mergedWindow);                if (res != null) {                    mergedStateWindows.add(res);                }            }            //新的映射关系            this.mapping.put(mergeResult, mergedStateWindow);            // don’t put the target state window into the merged windows            mergedStateWindows.remove(mergedStateWindow);            // don’t merge the new window itself, it never had any state associated with it            // i.e. if we are only merging one pre-existing window into itself            // without extending the pre-existing window            if (!(mergedWindows.contains(mergeResult) &amp;&amp; mergedWindows.size() == 1)) {                //调用回调函数进行状态的合并                mergeFunction.merge(                        mergeResult, //合并后的窗口                        mergedWindows, //需要被合并的窗口                        this.mapping.get(mergeResult), //用作状态 namespace 的 window                        mergedStateWindows); //需要合并到最终结果的 namespace            }        }        // the new window created a new, self-contained window without merging        if (mergeResults.isEmpty()</td>
</tr>
</tbody></table>
<h4 id="Evictor"><a href="#Evictor" class="headerlink" title="Evictor"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#evictor"></a>Evictor</h4><p>Flink 的窗口操作还提供了一个可选的 evitor，允许在调用 <code>InternalWindowFunction</code> 计算窗口结果之前或之后移除窗口中的元素。在这种情况下，就不能对窗口进行增量聚合操作了，窗口内的所有元素必须保存在 <code>ListState</code> 中，因而对性能会有一定影响。</p>
<p><code>Evictor</code> 提拱了两个方法，分别在 <code>InternalWindowFunction</code> 处理之前和处理之后调用：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java1234</code></td>
<td><code>javapublic interface Evictor&lt;T, W extends Window&gt; extends Serializable &#123;    void evictBefore(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext);    void evictAfter(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext);&#125;</code></td>
</tr>
</tbody></table>
<p>以 <code>CountEvictor</code> 为例，只会保留一定数量的元素在窗口中，超出的部分被移除掉：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415161718192021222324252627282930313233</code></td>
<td><code>javapublic class CountEvictor&lt;W extends Window&gt; implements Evictor&lt;Object, W&gt; &#123;    @Override    public void evictBefore(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, W window, EvictorContext ctx) &#123;        if (!doEvictAfter) &#123;            evict(elements, size, ctx);        &#125;    &#125;    @Override    public void evictAfter(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, W window, EvictorContext ctx) &#123;        if (doEvictAfter) &#123;            evict(elements, size, ctx);        &#125;    &#125;    private void evict(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, int size, EvictorContext ctx) &#123;        if (size &lt;= maxCount) &#123;            return;        &#125; else &#123;            int evictedCount = 0;            for (Iterator&lt;TimestampedValue&lt;Object&gt;&gt; iterator = elements.iterator(); iterator.hasNext();)&#123;                iterator.next();                evictedCount++;                if (evictedCount &gt; size - maxCount) &#123;                    break;                &#125; else &#123;                    //超出的部分都移除                    iterator.remove();                &#125;            &#125;        &#125;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>在使用了 <code>Evictor</code> 的情况下，会生成 <code>EvictingWindowOperator</code> 算子，<code>EvictingWindowOperator</code> 是 <code>WindowOperator</code> 的子类，会在触发窗口计算时调用 <code>Evictor</code>：</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374</code></td>
<td><code>javaclass WindowedStream &#123;    public &lt;ACC, V, R&gt; SingleOutputStreamOperator&lt;R&gt; aggregate(            AggregateFunction&lt;T, ACC, V&gt; aggregateFunction,            ProcessWindowFunction&lt;V, R, K, W&gt; windowFunction,            TypeInformation&lt;ACC&gt; accumulatorType,            TypeInformation&lt;V&gt; aggregateResultType,            TypeInformation&lt;R&gt; resultType) &#123;                if (evictor != null) &#123;            TypeSerializer&lt;StreamRecord&lt;T&gt;&gt; streamRecordSerializer =                    (TypeSerializer&lt;StreamRecord&lt;T&gt;&gt;) new StreamElementSerializer(input.getType().createSerializer(getExecutionEnvironment().getConfig()));            //即便是使用了增量聚合函数，状态仍然是以 `ListState` 形式保存的            ListStateDescriptor&lt;StreamRecord&lt;T&gt;&gt; stateDesc =                    new ListStateDescriptor&lt;&gt;(&quot;window-contents&quot;, streamRecordSerializer);            //生成了 EvictingWindowOperator            operator = new EvictingWindowOperator&lt;&gt;(windowAssigner,                    windowAssigner.getWindowSerializer(getExecutionEnvironment().getConfig()),                    keySel,                    input.getKeyType().createSerializer(getExecutionEnvironment().getConfig()),                    stateDesc,                    new InternalAggregateProcessWindowFunction&lt;&gt;(aggregateFunction, windowFunction),                    trigger,                    evictor,                    allowedLateness,                    lateDataOutputTag);        &#125; else &#123;            .......        &#125;    &#125;&#125;public class WindowOperator&lt;K, IN, ACC, OUT, W extends Window&gt;    extends AbstractUdfStreamOperator&lt;OUT, InternalWindowFunction&lt;ACC, OUT, K, W&gt;&gt;    implements OneInputStreamOperator&lt;IN, OUT&gt;, Triggerable&lt;K, W&gt; &#123;        private void emitWindowContents(W window, Iterable&lt;StreamRecord&lt;IN&gt;&gt; contents, ListState&lt;StreamRecord&lt;IN&gt;&gt; windowState) throws Exception &#123;        timestampedCollector.setAbsoluteTimestamp(window.maxTimestamp());        // Work around type system restrictions...        FluentIterable&lt;TimestampedValue&lt;IN&gt;&gt; recordsWithTimestamp = FluentIterable            .from(contents)            .transform(new Function&lt;StreamRecord&lt;IN&gt;, TimestampedValue&lt;IN&gt;&gt;() &#123;                @Override                public TimestampedValue&lt;IN&gt; apply(StreamRecord&lt;IN&gt; input) &#123;                    return TimestampedValue.from(input);                &#125;            &#125;);        //调用 InternalWindowFunction 之前        evictorContext.evictBefore(recordsWithTimestamp, Iterables.size(recordsWithTimestamp));        FluentIterable&lt;IN&gt; projectedContents = recordsWithTimestamp            .transform(new Function&lt;TimestampedValue&lt;IN&gt;, IN&gt;() &#123;                @Override                public IN apply(TimestampedValue&lt;IN&gt; input) &#123;                    return input.getValue();                &#125;            &#125;);        processContext.window = triggerContext.window;        //调用 InternalWindowFunction 计算结果        userFunction.process(triggerContext.key, triggerContext.window, processContext, projectedContents, timestampedCollector);        //调用 InternalWindowFunction 之前        evictorContext.evictAfter(recordsWithTimestamp, Iterables.size(recordsWithTimestamp));        //work around to fix FLINK-4369, remove the evicted elements from the windowState.        //this is inefficient, but there is no other way to remove elements from ListState, which is an AppendingState.        windowState.clear();        for (TimestampedValue&lt;IN&gt; record : recordsWithTimestamp) &#123;            windowState.add(record.getStreamRecord());        &#125;    &#125;    &#125;</code></td>
</tr>
</tbody></table>
<h4 id="AllWindowedStream"><a href="#AllWindowedStream" class="headerlink" title="AllWindowedStream"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#allwindowedstream"></a>AllWindowedStream</h4><p>前面我们介绍的实际上是 Keyed Windows 的具体实现，它是在 KeyedStream 上进行的窗口操作，所以消息会按照 key 进行分流，这也是窗口最常用的到的的应用场景。但是，针对普通的 Non-Keyed Stream，同样可以进行窗口操作。在这种情况下，<code>DataStream.windowAll(...)</code> 操作得到 <code>AllWindowedStream</code>。</p>
<table>
<thead>
<tr>
<th><br></th>
<th><br></th>
</tr>
</thead>
<tbody><tr>
<td><code>java 1 2 3 4 5 6 7 8 9101112131415</code></td>
<td><code>javapublic class AllWindowedStream&lt;T, W extends Window&gt; &#123;    public AllWindowedStream(DataStream&lt;T&gt; input,            WindowAssigner&lt;? super T, W&gt; windowAssigner) &#123;        this.input = input.keyBy(new NullByteKeySelector&lt;T&gt;());        this.windowAssigner = windowAssigner;        this.trigger = windowAssigner.getDefaultTrigger(input.getExecutionEnvironment());    &#125;&#125;public class NullByteKeySelector&lt;T&gt; implements KeySelector&lt;T, Byte&gt; &#123;    @Override    public Byte getKey(T value) throws Exception &#123;        return 0;    &#125;&#125;</code></td>
</tr>
</tbody></table>
<p>所以很明显，Non-Keyed Windows 实际上就是基于 Keyed Windows 的一种特殊实现，只是使用了一种特殊的 <code>NullByteKeySelector</code>，这样所有的消息得到的 Key 都是一样的。Non-Keyed Windows 的一个问题在于，由于所有消息的 key 都是一样的，那么所有的消息最终都会被同一个 Task 处理，这个 Task 也会成为整个作业的瓶颈。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E5%B0%8F%E7%BB%93"></a>小结</h2><p>时间属性和窗口操作是对流处理系统能力的极大增强。在这篇文章中，我们由 Dataflow Model 引申出时间域（time domain），水位线（watermark），窗口模型（windowing model），触发器（triggering model）等概念，并一一介绍了这些机制在 Flink 内部的实现方式。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/#%E5%8F%82%E8%80%83"></a>参考</h2><ul>
<li>  <a href="https://ai.google/research/pubs/pub43864">The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing</a></li>
<li>  <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101">Streaming 101: The world beyond batch</a></li>
<li>  <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102">Streaming 102: The world beyond batch</a></li>
</ul>
<p>【参考文献】</p>
<ol>
<li><a href="http://wuchong.me/blog/2016/05/25/flink-internals-window-mechanism/">flink原理与实现: window机制</a></li>
<li><a href="https://xie.infoq.cn/article/0d5038bc42862b3db79c571bd">flink窗口应用与实现</a></li>
<li><a href="https://blog.csdn.net/a1240466196/article/details/108334436">Flink原理: 窗口原理详解</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink:HBaseConnectors</title>
    <url>/bigdata/Flink/HBaseConnectors/</url>
    <content><![CDATA[<h1 id="Flink-HBase-connectors"><a href="#Flink-HBase-connectors" class="headerlink" title="Flink HBase connectors"></a>Flink HBase connectors</h1><h2 id="flighting"><a href="#flighting" class="headerlink" title="flighting"></a>flighting</h2><p>奇怪，没有依赖HBase-Client，而是依赖了HBase-server</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-hadoop2-compat<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">type</span>&gt;</span>test-jar<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="添加文件到ClassLoader的classpath"><a href="#添加文件到ClassLoader的classpath" class="headerlink" title="添加文件到ClassLoader的classpath"></a>添加文件到ClassLoader的classpath</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Get the classloader actually used by HBaseConfiguration</span></span><br><span class="line">ClassLoader classLoader = HBaseConfiguration.create().getClassLoader();</span><br><span class="line"><span class="keyword">if</span> (!(classLoader <span class="keyword">instanceof</span> URLClassLoader)) &#123;</span><br><span class="line">	fail(<span class="string">&quot;We should get a URLClassLoader&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Make the addURL method accessible</span></span><br><span class="line">Method method = URLClassLoader.class.getDeclaredMethod(<span class="string">&quot;addURL&quot;</span>, URL.class);</span><br><span class="line">method.setAccessible(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add the directory where we put the hbase-site.xml to the classpath</span></span><br><span class="line">method.invoke(classLoader, directory.toURI().toURL());</span><br></pre></td></tr></table></figure>







]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>【转】实时流处理系统反压机制</title>
    <url>/bigdata/Flink/RealTimeSystem-backpress/</url>
    <content><![CDATA[<h1 id="实时流处理系统反压机制（BackPressure）综述-转"><a href="#实时流处理系统反压机制（BackPressure）综述-转" class="headerlink" title="实时流处理系统反压机制（BackPressure）综述[转]"></a>实时流处理系统反压机制（BackPressure）综述[转]</h1><p> 发表于 2018-11-15 |  更新于 2018-12-03 |  分类于 <a href="http://ileaf.tech/category/#/BigData">BigData </a>|  阅读次数 333</p>
<p>本文主要关于实时流处理系统反压机制，最近看到反压问题看到此文章很好，在此分享并mark一下。</p>
<blockquote>
<p>本文主要关于实时流处理系统反压机制，最近看到反压问题看到此文章很好，在此分享并mark一下。<br>(￢_￢)ﾉ最近菜叶子没自己写见谅。<br>本文转自 <a href="https://blog.csdn.net/qq_21125183/article/details/80708142">实时流处理系统反压机制（BackPressure）综述</a><br><a href="https://blog.csdn.net/qq_21125183/article/details/80708142">https://blog.csdn.net/qq_21125183/article/details/80708142</a><br><a href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a></p>
</blockquote>
<p>反压机制（BackPressure）被广泛应用到实时流处理系统中，流处理系统需要能优雅地处理反压（backpressure）问题。<br>反压通常产生于这样的场景：短时负载高峰导致系统接收数据的速率远高于它处理数据的速率。<br>许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或者遇到大促或秒杀活动导致流量陡增。<br>反压如果不能得到正确的处理，可能会导致资源耗尽甚至系统崩溃。反压机制就是指系统能够自己检测到被阻塞的Operator，然后系统自适应地降低源头或者上游的发送速率。</p>
<p>目前主流的流处理系统 Apache Storm、JStorm、Spark Streaming、S4、Apache Flink、Twitter Heron都采用反压机制解决这个问题，不过他们的实现各自不同。</p>
<p><img src="_v_images/20201030212807758_57452691.png" alt="实时流处理系统反压机制01"></p>
<p>不同的组件可以不同的速度执行（并且每个组件中的处理速度随时间改变）。 例如，考虑一个工作流程，或由于数据倾斜或任务调度而导致数据被处理十分缓慢。<br>在这种情况下，如果上游阶段不减速，将导致缓冲区建立长队列(队列占用内存、硬盘空间，节点负载加重)，或导致系统丢弃元组。<br>如果元组在中途丢弃，那么效率可能会有损失，因为已经为这些元组产生的计算被浪费了。<br>并且在一些流处理系统中比如Strom，会将这些丢失的元组重新发送，这样会导致数据的一致性问题(at least once语义)，并且还会导致某些Operator状态叠加。<br>进而整个程序输出结果不准确。第二由于系统接收数据的速率是随着时间改变的，短时负载高峰导致系统接收数据的速率远高于它处理数据的速率的情况，也会导致Tuple在中途丢失。<br>所以实时流处理系统必须能够解决发送速率远大于系统能处理速率这个问题，大多数实时流处理系统采用反压（BackPressure）机制解决这个问题。</p>
<p>下面我们就来介绍一下不同的实时流处理系统采用的反压机制：</p>
<h1 id="Strom-反压机制"><a href="#Strom-反压机制" class="headerlink" title="Strom 反压机制"></a>Strom 反压机制</h1><h2 id="Storm-1-0-以前的反压机制"><a href="#Storm-1-0-以前的反压机制" class="headerlink" title="Storm 1.0 以前的反压机制"></a>Storm 1.0 以前的反压机制</h2><p>对于开启了acker机制的storm程序，可以通过设置conf.setMaxSpoutPending参数来实现反压效果，<strong>如果下游组件(bolt)处理速度跟不上导致spout发送的tuple没有及时确认的数超过了参数设定的值，spout会停止发送数据</strong>，这种方式的缺点是很难调优conf.setMaxSpoutPending参数的设置以达到最好的反压效果，设小了会导致吞吐上不去，设大了会导致worker OOM；有震荡，数据流会处于一个颠簸状态，效果不如逐级反压；另外对于关闭acker机制的程序无效；</p>
<h2 id="Storm-Automatic-Backpressure"><a href="#Storm-Automatic-Backpressure" class="headerlink" title="Storm Automatic Backpressure"></a>Storm Automatic Backpressure</h2><p>新的storm自动反压机制(Automatic Back Pressure)通过监控bolt中的接收队列的情况，当超过高水位值时专门的线程会将反压信息写到 Zookeeper ，Zookeeper上的watch会通知该拓扑的所有Worker都进入反压状态，最后Spout降低tuple发送的速度。</p>
<p><img src="_v_images/20201030212806451_178512803.png" alt="实时流处理系统反压机制02"></p>
<p>每个Executor都有一个接受队列和发送队列用来接收Tuple和发送Spout或者Bolt生成的Tuple元组。每个Worker进程都有一个单的的接收线程监听接收端口。<br>它从每个网络上进来的消息发送到Executor的接收队列中。Executor接收队列存放Worker或者Worker内部其他Executor发过来的消息。<br>Executor工作线程从接收队列中拿出数据，然后调用execute方法，发送Tuple到Executor的发送队列。<br>Executor的发送线程从发送队列中获取消息，按照消息目的地址选择发送到Worker的传输队列中或者其他Executor的接收队列中。<br>最后Worker的发送线程从传输队列中读取消息，然后将Tuple元组发送到网络中。</p>
<ol>
<li>当Worker进程中的Executor线程发现自己的接收队列满了时，也就是接收队列达到<code>high watermark</code>的阈值后，因此它会发送通知消息到背压线程。</li>
<li>背压线程将当前worker进程的信息注册到Zookeeper的Znode节点中。具体路径就是 <code>/Backpressure/topo1/wk1</code>下</li>
<li>Zookeepre的Znode Watcher监视/Backpreesure/topo1下的节点目录变化情况，如果发现目录增加了znode节点说明或者其他变化。这就说明该Topo1需要反压控制，然后它会通知Topo1所有的Worker进入反压状态。</li>
<li>最终Spout降低tuple发送的速度。</li>
</ol>
<h1 id="JStorm-反压机制"><a href="#JStorm-反压机制" class="headerlink" title="JStorm 反压机制"></a>JStorm 反压机制</h1><p>JStorm做了两级的反压，第一级和Jstorm类似，通过执行队列来监测，但是不会通过ZK来协调，而是通过Topology Master来协调。<br>在队列中会标记high water mark和low water mark，当执行队列超过high water mark时，就认为bolt来不及处理，则向TM发一条控制消息，上游开始减慢发送速率，直到下游低于low water mark时解除反压。</p>
<p>此外，在Netty层也做了一级反压，由于每个Worker Task都有自己的发送和接收的缓冲区，可以对缓冲区设定限额、控制大小，如果spout数据量特别大，缓冲区填满会导致下游bolt的接收缓冲区填满，造成了反压。</p>
<p><img src="_v_images/20201030212805000_1695102842.png" alt="实时流处理系统反压机制03"></p>
<p>限流机制：jstorm的限流机制， 当下游bolt发生阻塞时， 并且阻塞task的比例超过某个比例时（现在默认设置为0.1），触发反压</p>
<p>限流方式：计算阻塞Task的地方执行线程执行时间，Spout每发送一个tuple等待相应时间，然后讲这个时间发送给Spout， 于是， spout每发送一个tuple，就会等待这个执行时间。</p>
<p>Task阻塞判断方式：在jstorm 连续4次采样周期中采样，队列情况，当队列超过80%（可以设置）时，即可认为该task处在阻塞状态。</p>
<h1 id="SparkStreaming-反压机制"><a href="#SparkStreaming-反压机制" class="headerlink" title="SparkStreaming 反压机制"></a>SparkStreaming 反压机制</h1><h2 id="为什么引入反压机制Backpressure"><a href="#为什么引入反压机制Backpressure" class="headerlink" title="为什么引入反压机制Backpressure"></a>为什么引入反压机制Backpressure</h2><p>默认情况下，Spark Streaming通过Receiver以生产者生产数据的速率接收数据，计算过程中会出现<code>batch processing time &gt; batch interval</code>的情况，其中<code>batch processing time</code> 为实际计算一个批次花费时间， <code>batch interval</code>为Streaming应用设置的批处理间隔。<br>这意味着Spark Streaming的数据接收速率高于Spark从队列中移除数据的速率，也就是数据处理能力低，在设置间隔内不能完全处理当前接收速率接收的数据。如果这种情况持续过长的时间，会造成数据在内存中堆积，导致Receiver所在Executor内存溢出等问题（如果设置StorageLevel包含disk, 则内存存放不下的数据会溢写至disk, 加大延迟）。<br>Spark 1.5以前版本，用户如果要限制Receiver的数据接收速率，可以通过设置静态配制参数“<code>spark.streaming.receiver.maxRate</code>”的值来实现，此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer数据生产高于maxRate，当前集群处理能力也高于maxRate，这就会造成资源利用率下降等问题。为了更好的协调数据接收速率与资源处理能力，Spark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。</p>
<h2 id="反压机制Backpressure"><a href="#反压机制Backpressure" class="headerlink" title="反压机制Backpressure"></a>反压机制Backpressure</h2><p><code>Spark Streaming Backpressure</code>: 根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。通过属性“spark.streaming.backpressure.enabled”来控制是否启用backpressure机制，默认值false，即不启用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">sparkConf.set(<span class="string">&quot;spark.streaming.backpressure.enabled&quot;</span>,”<span class="keyword">true</span>”)</span><br></pre></td></tr></table></figure>
<p>SparkStreaming 架构图如下所示:</p>
<p><img src="_v_images/20201030212803393_1135733829.png" alt="实时流处理系统反压机制04"></p>
<p>SparkStreaming 反压过程执行如下图所示：</p>
<p>在原架构的基础上加上一个新的组件RateController,这个组件负责监听“OnBatchCompleted”事件，然后从中抽取<code>processingDelay</code> 及<code>schedulingDelay</code>信息. <code>Estimator</code>依据这些信息估算出最大处理速度（rate），最后由基于<code>Receiver</code>的Input Stream将rate通过ReceiverTracker与ReceiverSupervisorImpl转发给BlockGenerator（继承自RateLimiter）.</p>
<p><img src="_v_images/20201030212801986_428923565.png" alt="实时流处理系统反压机制05"></p>
<h2 id="direct模式-BackPressure-此部分详细说明了direct模式接收：转自-开启Back-Pressure使生产环境的Spark-Streaming应用更稳定、有效"><a href="#direct模式-BackPressure-此部分详细说明了direct模式接收：转自-开启Back-Pressure使生产环境的Spark-Streaming应用更稳定、有效" class="headerlink" title="direct模式-BackPressure(此部分详细说明了direct模式接收：转自-开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效)"></a>direct模式-BackPressure(此部分详细说明了direct模式接收：转自-<a href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a>)</h2><p>当Spark Streaming与Kafka使用Direct API集群时，我们可以很方便的去控制最大数据摄入量–通过一个被称作spark.streaming.kafka.maxRatePerPartition的参数。根据文档描述，他的含义是：Direct API读取每一个Kafka partition数据的最大速率（每秒读取的消息量）。<br>配置项spark.streaming.kafka.maxRatePerPartition，对防止流式应用在下边两种情况下出现流量过载时尤其重要：<br>1.Kafka Topic中有大量未处理的消息，并且我们设置是Kafka auto.offset.reset参数值为smallest，他可以防止第一个批次出现数据流量过载情况。<br>2.当Kafka 生产者突然飙升流量的时候，他可以防止批次处理出现数据流量过载情况。</p>
<p>但是，配置Kafka每个partition每批次最大的摄入量是个静态值，也算是个缺点。随着时间的变化，在生产环境运行了一段时间的Spark Streaming应用，每批次每个Kafka partition摄入数据最大量的最优值也是变化的。有时候，是因为消息的大小会变，导致数据处理时间变化。有时候，是因为流计算所使用的多租户集群会变得非常繁忙，比如在白天时候，一些其他的数据应用（例如Impala/Hive/MR作业）竞争共享的系统资源时（CPU/内存/网络/磁盘IO）。<br>背压机制可以解决该问题。背压机制是呼声比较高的功能，他允许根据前一批次数据的处理情况，动态、自动的调整后续数据的摄入量，这样的反馈回路使得我们可以应对流式应用流量波动的问题。<br>Spark Streaming的背压机制是在Spark1.5版本引进的，我们可以添加如下代码启用改功能：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sparkConf.set(&quot;spark.streaming.backpressure.enabled&quot;,”true”)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>那应用启动后的第一个批次流量怎么控制呢？因为他没有前面批次的数据处理时间，所以没有参考的数据去评估这一批次最优的摄入量。在Spark官方文档中有个被称作spark.streaming.backpressure.initialRate的配置，看起来是控制开启背压机制时初始化的摄入量。其实不然，该参数只对receiver模式起作用，并不适用于direct模式。推荐的方法是使用spark.streaming.kafka.maxRatePerPartition控制背压机制起作用前的第一批次数据的最大摄入量。我通常建议设置spark.streaming.kafka.maxRatePerPartition的值为最优估计值的1.5到2倍，让背压机制的算法去调整后续的值。请注意，spark.streaming.kafka.maxRatePerPartition的值会一直控制最大的摄入量，所以背压机制的算法值不会超过他。<br>另一个需要注意的是，在第一个批次处理完成前，紧接着的批次都将使用spark.streaming.kafka.maxRatePerPartition的值作为摄入量。通过Spark UI可以看到，批次间隔为5s，当批次调度延迟31秒时候，前7个批次的摄入量是20条记录。直到第八个批次，背压机制起作用时，摄入量变为5条记录。</p>
<h1 id="Heron-反压机制"><a href="#Heron-反压机制" class="headerlink" title="Heron 反压机制"></a>Heron 反压机制</h1><p><img src="_v_images/20201030212800445_1650579597.png" alt="实时流处理系统反压机制06"></p>
<p>当下游处理速度跟不上上游发送速度时，一旦StreamManager 发现一个或多个Heron Instance 速度变慢，立刻对本地spout进行降级，降低本地Spout发送速度, 停止从这些spout读取数据。并且受影响的StreamManager 会发送一个特殊的start backpressure message 给其他的StreamManager ，要求他们对spout进行本地降级。 当其他StreamManager 接收到这个特殊消息时，他们通过不读取当地Spout中的Tuple来进行降级。一旦出问题的Heron Instance 恢复速度后，本地的SM 会发送stop backpressure message 解除降级。</p>
<p>很多Socket Channel与应用程序级别的Buffer相关联，该缓冲区由high watermark 和low watermark组成。 当缓冲区大小达到high watermark时触发反压，并保持有效，直到缓冲区大小低于low watermark。 此设计的基本原理是防止拓扑在进入和退出背压缓解模式之间快速振荡。</p>
<h1 id="Flink-反压机制"><a href="#Flink-反压机制" class="headerlink" title="Flink 反压机制"></a>Flink 反压机制</h1><p>Flink 没有使用任何复杂的机制来解决反压问题，因为根本不需要那样的方案！它利用自身作为纯数据流引擎的优势来优雅地响应反压问题。下面我们会深入分析 Flink 是如何在 Task 之间传输数据的，以及数据流如何实现自然降速的。 Flink 在运行时主要由 operators 和 streams 两大组件构成。每个 operator 会消费中间态的流，并在流上进行转换，然后生成新的流。对于 Flink 的网络机制一种形象的类比是，Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。还记得经典的线程间通信案例：生产者消费者模型吗？使用 BlockingQueue 的话，一个较慢的接受者会降低发送者的发送速率，因为一旦队列满了（有界队列）发送者会被阻塞。Flink 解决反压的方案就是这种感觉。 在 Flink 中，这些分布式阻塞队列就是这些逻辑流，而队列容量是通过缓冲池来（LocalBufferPool）实现的。每个被生产和被消费的流都会被分配一个缓冲池。缓冲池管理着一组缓冲(Buffer)，缓冲在被消费后可以被回收循环利用。这很好理解：你从池子中拿走一个缓冲，填上数据，在数据消费完之后，又把缓冲还给池子，之后你可以再次使用它。</p>
<h2 id="Flink-网络传输中的内存管理"><a href="#Flink-网络传输中的内存管理" class="headerlink" title="Flink 网络传输中的内存管理"></a>Flink 网络传输中的内存管理</h2><p>如下图所示展示了 Flink 在网络传输场景下的内存管理。网络上传输的数据会写到 Task 的 InputGate（IG） 中，经过 Task 的处理后，再由 Task 写到 ResultPartition（RS） 中。每个 Task 都包括了输入和输入，输入和输出的数据存在 Buffer 中（都是字节数据）。Buffer 是 MemorySegment 的包装类。</p>
<p><img src="_v_images/20201030212758832_1369878662.png" alt="实时流处理系统反压机制07"></p>
<ol>
<li>TaskManager（TM）在启动时，会先初始化NetworkEnvironment对象，TM 中所有与网络相关的东西都由该类来管理（如 Netty 连接），其中就包括NetworkBufferPool。根据配置，Flink 会在 NetworkBufferPool 中生成一定数量（默认2048个）的内存块 MemorySegment（关于 Flink 的内存管理，后续文章会详细谈到），内存块的总数量就代表了网络传输中所有可用的内存。NetworkEnvironment 和 NetworkBufferPool 是 Task 之间共享的，每个 TM 只会实例化一个。</li>
<li>Task 线程启动时，会向 NetworkEnvironment 注册，NetworkEnvironment 会为 Task 的 InputGate（IG）和 ResultPartition（RP） 分别创建一个 LocalBufferPool（缓冲池）并设置可申请的 MemorySegment（内存块）数量。IG 对应的缓冲池初始的内存块数量与 IG 中 InputChannel 数量一致，RP 对应的缓冲池初始的内存块数量与 RP 中的 ResultSubpartition 数量一致。不过，每当创建或销毁缓冲池时，NetworkBufferPool 会计算剩余空闲的内存块数量，并平均分配给已创建的缓冲池。注意，这个过程只是指定了缓冲池所能使用的内存块数量，并没有真正分配内存块，只有当需要时才分配。为什么要动态地为缓冲池扩容呢？因为内存越多，意味着系统可以更轻松地应对瞬时压力（如GC），不会频繁地进入反压状态，所以我们要利用起那部分闲置的内存块。</li>
<li>在 Task 线程执行过程中，当 Netty 接收端收到数据时，为了将 Netty 中的数据拷贝到 Task 中，InputChannel（实际是 RemoteInputChannel）会向其对应的缓冲池申请内存块（上图中的①）。如果缓冲池中也没有可用的内存块且已申请的数量还没到池子上限，则会向 NetworkBufferPool 申请内存块（上图中的②）并交给 InputChannel 填上数据（上图中的③和④）。如果缓冲池已申请的数量达到上限了呢？或者 NetworkBufferPool 也没有可用内存块了呢？这时候，Task 的 Netty Channel 会暂停读取，上游的发送端会立即响应停止发送，拓扑会进入反压状态。当 Task 线程写数据到 ResultPartition 时，也会向缓冲池请求内存块，如果没有可用内存块时，会阻塞在请求内存块的地方，达到暂停写入的目的。</li>
<li>当一个内存块被消费完成之后（在输入端是指内存块中的字节被反序列化成对象了，在输出端是指内存块中的字节写入到 Netty Channel 了），会调用 Buffer.recycle() 方法，会将内存块还给 LocalBufferPool （上图中的⑤）。如果LocalBufferPool中当前申请的数量超过了池子容量（由于上文提到的动态容量，由于新注册的 Task 导致该池子容量变小），则LocalBufferPool会将该内存块回收给 NetworkBufferPool（上图中的⑥）。如果没超过池子容量，则会继续留在池子中，减少反复申请的开销。</li>
</ol>
<h2 id="Flink-反压机制-1"><a href="#Flink-反压机制-1" class="headerlink" title="Flink 反压机制"></a>Flink 反压机制</h2><p>下面这张图简单展示了两个 Task 之间的数据传输以及 Flink 如何感知到反压的：</p>
<p><img src="_v_images/20201030212757424_78076714.png" alt="实时流处理系统反压机制08"></p>
<ol>
<li>记录“A”进入了 Flink 并且被 Task 1 处理。（这里省略了 Netty 接收、反序列化等过程）</li>
<li>记录被序列化到 buffer 中。</li>
<li>该 buffer 被发送到 Task 2，然后 Task 2 从这个 buffer 中读出记录。</li>
</ol>
<p><strong>不要忘了：记录能被 Flink 处理的前提是，必须有空闲可用的 Buffer。</strong></p>
<p>结合上面两张图看：Task 1 在输出端有一个相关联的 LocalBufferPool（称缓冲池1），Task 2 在输入端也有一个相关联的 LocalBufferPool（称缓冲池2）。如果缓冲池1中有空闲可用的 buffer 来序列化记录 “A”，我们就序列化并发送该 buffer。</p>
<p>这里我们需要注意两个场景：</p>
<ul>
<li>本地传输：如果 Task 1 和 Task 2 运行在同一个 worker 节点（TaskManager），该 buffer 可以直接交给下一个 Task。一旦 Task 2 消费了该 buffer，则该 buffer 会被缓冲池1回收。如果 Task 2 的速度比 1 慢，那么 buffer 回收的速度就会赶不上 Task 1 取 buffer 的速度，导致缓冲池1无可用的 buffer，Task 1 等待在可用的 buffer 上。最终形成 Task 1 的降速。</li>
<li>远程传输：如果 Task 1 和 Task 2 运行在不同的 worker 节点上，那么 buffer 会在发送到网络（TCP Channel）后被回收。在接收端，会从 LocalBufferPool 中申请 buffer，然后拷贝网络中的数据到 buffer 中。如果没有可用的 buffer，会停止从 TCP 连接中读取数据。在输出端，通过 Netty 的水位值机制来保证不往网络中写入太多数据（后面会说）。如果网络中的数据（Netty输出缓冲中的字节数）超过了高水位值，我们会等到其降到低水位值以下才继续写入数据。这保证了网络中不会有太多的数据。如果接收端停止消费网络中的数据（由于接收端缓冲池没有可用 buffer），网络中的缓冲数据就会堆积，那么发送端也会暂停发送。另外，这会使得发送端的缓冲池得不到回收，writer 阻塞在向 LocalBufferPool 请求 buffer，阻塞了 writer 往 ResultSubPartition 写数据。</li>
</ul>
<p>这种固定大小缓冲池就像阻塞队列一样，保证了 Flink 有一套健壮的反压机制，使得 Task 生产数据的速度不会快于消费的速度。我们上面描述的这个方案可以从两个 Task 之间的数据传输自然地扩展到更复杂的 pipeline 中，保证反压机制可以扩散到整个 pipeline。</p>
<h2 id="反压实验"><a href="#反压实验" class="headerlink" title="反压实验"></a>反压实验</h2><p>另外，官方博客中为了展示反压的效果，给出了一个简单的实验。下面这张图显示了：随着时间的改变，生产者（黄色线）和消费者（绿色线）每5秒的平均吞吐与最大吞吐（在单一JVM中每秒达到8百万条记录）的百分比。我们通过衡量task每5秒钟处理的记录数来衡量平均吞吐。该实验运行在单 JVM 中，不过使用了完整的 Flink 功能栈。</p>
<p><img src="_v_images/20201030212755917_1236027751.png" alt="实时流处理系统反压机制09"></p>
<p>首先，我们运行生产task到它最大生产速度的60%（我们通过Thread.sleep()来模拟降速）。消费者以同样的速度处理数据。然后，我们将消费task的速度降至其最高速度的30%。你就会看到背压问题产生了，正如我们所见，生产者的速度也自然降至其最高速度的30%。接着，停止消费task的人为降速，之后生产者和消费者task都达到了其最大的吞吐。接下来，我们再次将消费者的速度降至30%，pipeline给出了立即响应：生产者的速度也被自动降至30%。最后，我们再次停止限速，两个task也再次恢复100%的速度。总而言之，我们可以看到：生产者和消费者在 pipeline 中的处理都在跟随彼此的吞吐而进行适当的调整，这就是我们希望看到的反压的效果。</p>
<h2 id="Flink-反压监控"><a href="#Flink-反压监控" class="headerlink" title="Flink 反压监控"></a>Flink 反压监控</h2><p>在 Storm/JStorm 中，只要监控到队列满了，就可以记录下拓扑进入反压了。但是 Flink 的反压太过于天然了，导致我们无法简单地通过监控队列来监控反压状态。Flink 在这里使用了一个 trick 来实现对反压的监控。如果一个 Task 因为反压而降速了，那么它会卡在向 LocalBufferPool 申请内存块上。那么这时候，该 Task 的 stack trace 就会长下面这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.Object.wait(Native Method)</span><br><span class="line">o.a.f.[...].LocalBufferPool.requestBuffer(LocalBufferPool.java:<span class="number">163</span>)</span><br><span class="line">o.a.f.[...].LocalBufferPool.requestBufferBlocking(LocalBufferPool.java:<span class="number">133</span>) &lt;--- BLOCKING request</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure>
<p>那么事情就简单了。通过不断地采样每个 task 的 stack trace 就可以实现反压监控。</p>
<p><img src="_v_images/20201030212753993_1098219801.png" alt="实时流处理系统反压机制10"></p>
<p>Flink 的实现中，只有当 Web 页面切换到某个 Job 的 Backpressure 页面，才会对这个 Job 触发反压检测，因为反压检测还是挺昂贵的。JobManager 会通过 Akka 给每个 TaskManager 发送TriggerStackTraceSample消息。默认情况下，TaskManager 会触发100次 stack trace 采样，每次间隔 50ms（也就是说一次反压检测至少要等待5秒钟）。并将这 100 次采样的结果返回给 JobManager，由 JobManager 来计算反压比率（反压出现的次数/采样的次数），最终展现在 UI 上。UI 刷新的默认周期是一分钟，目的是不对 TaskManager 造成太大的负担。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Flink不需要一种特殊的机制来处理反压，因为Flink 中的数据传输相当于已经提供了应对反压的机制。因此，Flink 所能获得的最大吞吐量由其 pipeline 中最慢的组件决定。相对于 Storm/JStorm 的实现，Flink 的实现更为简洁优雅，源码中也看不见与反压相关的代码，无需 Zookeeper/TopologyMaster 的参与也降低了系统的负载，也利于对反压更迅速的响应。</p>
<blockquote>
<p>本文转自 <a href="https://blog.csdn.net/qq_21125183/article/details/80708142">实时流处理系统反压机制（BackPressure）综述</a><br><a href="https://blog.csdn.net/qq_21125183/article/details/80708142">https://blog.csdn.net/qq_21125183/article/details/80708142</a><br><a href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a></p>
</blockquote>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink状态管理</title>
    <url>/bigdata/Flink/StateManagement/</url>
    <content><![CDATA[<h1 id="state-management"><a href="#state-management" class="headerlink" title="state-management"></a>state-management</h1><h2 id="org-apache-flink-streaming-api-checkpoint-CheckpointedFunction"><a href="#org-apache-flink-streaming-api-checkpoint-CheckpointedFunction" class="headerlink" title="org.apache.flink.streaming.api.checkpoint.CheckpointedFunction"></a>org.apache.flink.streaming.api.checkpoint.CheckpointedFunction</h2><ul>
<li>CheckpointedFunction是stateful transformation functions的核心接口，用于跨stream维护state<ul>
<li>snapshotState 在checkpoint的时候会被调用，用于snapshot state，通常用于flush、commit、synchronize外部系统</li>
<li>initializeState 在parallel function初始化的时候(<strong>第一次初始化或者从前一次checkpoint recover的时候</strong>)被调用，通常用来初始化state，以及处理state recovery的逻辑</li>
</ul>
</li>
</ul>
<p>从checkpoint中恢复数据时，需要判断snapshot当前的情况，</p>
<p>FunctionSnapshotContext实现了ManagedSnapshotContext, 父类中的方法: <code>getCheckpointId</code>,<code>getCheckpointTimestamp</code><br>FunctionInitializationContext实现了ManagedInitializationContext接口, 实现了<code>isRestored</code>、<code>getOperatorStateStore</code>、<code>getKeyedStateStore</code>方法</p>
<p>在初始化容器之后，我们使用上下文的<code>isrestore()</code>方法检查失败后是否正在恢复。如果是true，即正在恢复，则应用恢复逻辑。</p>
<blockquote>
<p>样例: HBase写入OutPutFormat</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">PortraitOutputFormat</span> <span class="keyword">extends</span> <span class="title">RichOutputFormat</span>&lt;<span class="title">EventItem</span>&gt; <span class="keyword">implements</span> <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 输出阈值，批量写入的条数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> threshold;</span><br><span class="line">    <span class="comment">// 维护在状态中的数据</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> ListState&lt;EventItem&gt; checkpointState;</span><br><span class="line">    <span class="comment">// 内存中的数据</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;EventItem&gt; bufferedEventItem;</span><br><span class="line">    <span class="comment">// HBase客户端</span></span><br><span class="line">    <span class="keyword">private</span> HBaseClient hbaseClient;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PortraitOutputFormat</span><span class="params">(HBaseClient hbaseClient)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.hbaseClient = hbaseClient;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * checkpoint时调用</span></span><br><span class="line"><span class="comment">    * 执行snapshot操作，将内存中的数据写入到内存</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext functionSnapshotContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        checkpointState.clear();</span><br><span class="line">        <span class="keyword">for</span> (EventItem eventItem : bufferedEventItem) &#123;</span><br><span class="line">            checkpointState.add(eventItem);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 创建state，判断是否存在需要恢复的状态，如果有则需要恢复到bufferedEventItem</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ListStateDescriptor&lt;EventItem&gt; descriptor = <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(<span class="string">&quot;buf-p&quot;</span>, EventItem.class);</span><br><span class="line">        checkpointState = context.getOperatorStateStore().getListState(descriptor);</span><br><span class="line">        <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (EventItem eventItem : checkpointState.get()) &#123;</span><br><span class="line">                bufferedEventItem.add(eventItem);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Configuration configuration)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(<span class="keyword">int</span> taskNumber, <span class="keyword">int</span> numTasks)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 将新消息写入到缓存bufferedEventItem，缓存个数大约threshold,则执行sink写入，然后清空bufferedEventItem</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeRecord</span><span class="params">(EventItem value)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (value.getAttachUserId() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        bufferedEventItem.add(value);</span><br><span class="line">        <span class="keyword">int</span> size = bufferedEventItem.size();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (size &gt;= threshold) &#123;</span><br><span class="line">            List&lt;Put&gt; puts = bufferedEventItem</span><br><span class="line">                    .stream()</span><br><span class="line">                    .map(eventItem -&gt; &#123;</span><br><span class="line">                        String rowKey1 = portraitDataGenerator.rowKey(eventItem);</span><br><span class="line">                        Map&lt;String, String&gt; data = portraitDataGenerator.data(eventItem);</span><br><span class="line">                        Put put = <span class="keyword">new</span> Put(rowKey1.getBytes());</span><br><span class="line">                        <span class="keyword">for</span> (String cfc : data.keySet()) &#123;</span><br><span class="line">                            String[] cfcs = cfc.split(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">                            String cf = cfcs[<span class="number">0</span>];</span><br><span class="line">                            String c = cfcs[<span class="number">1</span>];</span><br><span class="line">                            String dataOne = data.get(cfc);</span><br><span class="line">                            put.addColumn(cf.getBytes(), c.getBytes(), dataOne.getBytes());</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> put;</span><br><span class="line">                    &#125;)</span><br><span class="line">                    .collect(Collectors.toList());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                hbaseClient.putAndFlush(puts);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            bufferedEventItem.clear();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hTable != <span class="keyword">null</span>) &#123;</span><br><span class="line">            hTable.flushCommits();</span><br><span class="line">            hTable.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




<h2 id="org-apache-flink-runtime-state-CheckpointListener"><a href="#org-apache-flink-runtime-state-CheckpointListener" class="headerlink" title="org.apache.flink.runtime.state.CheckpointListener"></a>org.apache.flink.runtime.state.CheckpointListener</h2><p>一旦所有checkpoint参与者确认完全，该接口必须由想要接收提交通知的功能/操作来实现。</p>
<h1 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h1><p>1.8 自动清理原理</p>
<p>Apache Flink的1.6.0版本引入了State TTL功能。它使流处理应用程序的开发人员配置过期时间，并在定义时间超时（Time to Live）之后进行清理。在Flink 1.8.0中，该功能得到了扩展，包括对RocksDB和堆状态后端（FSStateBackend和MemoryStateBackend）的历史数据进行持续清理，从而实现旧条目的连续清理过程（根据TTL设置）。</p>
<p>RocksDB后台压缩可以过滤掉过期状态<br>如果你的Flink应用程序使用RocksDB作为状态后端存储，则可以启用另一个基于Flink特定压缩过滤器的清理策略。RocksDB定期运行异步压缩以合并状态更新并减少存储。Flink压缩过滤器使用TTL检查状态条目的到期时间戳，并丢弃所有过期值。</p>
<p>激活此功能的第一步是通过设置以下Flink配置选项来配置RocksDB状态后端：</p>
<p>state.backend.rocksdb.ttl.compaction.filter.enabled</p>
<p>配置RocksDB状态后端后，将为状态启用压缩清理策略，如以下代码示例所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">StateTtlConfig ttlConfig &#x3D; StateTtlConfig</span><br><span class="line">    .newBuilder(Time.days(7))</span><br><span class="line">    .cleanupInRocksdbCompactFilter()</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure>






<p>【参考文献】</p>
<ol>
<li><a href="https://www.jianshu.com/p/6ed0ef5e2b74">Flink Streaming状态处理（Working with State）</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>【草稿】Stream processing with Apache Flink</title>
    <url>/bigdata/Flink/StreamProcessingWithApacheFlink/</url>
    <content><![CDATA[<h1 id="Stream-processing-with-Apache-Flink"><a href="#Stream-processing-with-Apache-Flink" class="headerlink" title="Stream processing with Apache Flink"></a>Stream processing with Apache Flink</h1><h2 id="状态-重放是保证exactly-once的基础"><a href="#状态-重放是保证exactly-once的基础" class="headerlink" title="状态+重放是保证exactly once的基础"></a>状态+重放是保证exactly once的基础</h2><p>Connecting a stateful streaming application running on Flink and an event log is interesting for multiple reasons.<br>In this architecture the event log persists the input events and can replay them in deterministic order.<br>In case of a failure, Flink recovers a stateful streaming application by restoring its state from a previous checkpoint and resetting the read position on the event log.<br>The application will replay (and fast forward) the input events from the event log until it reaches the tail of the stream.<br>This technique is used to recover from failures but can also be leveraged to update an application, fix bugs and repair previously emitted results, migrate an application to a different cluster, or perform A/B tests with different application versions.</p>
<p>将运行在Flink上的有状态流应用程序与事件日志连接起来非常有趣，原因有很多。在这种体系结构中，事件日志保存输入事件，并可以以确定的顺序重播它们。在失败的情况下，Flink通过从以前的检查点恢复有状态流应用程序的状态并重新设置事件日志上的读位置来恢复有状态流应用程序。应用程序将重播(并快进)事件日志中的输入事件，直到它到达流的尾部。此技术用于从故障中恢复，但也可用于更新应用程序、修复bug和修复以前发出的结果、将应用程序迁移到不同的集群或使用不同的应用程序版本执行a/B测试。</p>
<h2 id="事件驱动"><a href="#事件驱动" class="headerlink" title="事件驱动"></a>事件驱动</h2><p>Event-driven applications offer several benefits compared to transactional applications or microservices. Local state access provides very good performance compared to reading and writing queries against remote datastores. Scaling and fault tolerance are handled by the stream processor, and by leveraging an event log as the input source the complete input of an application is reliably stored and can be deterministically replayed. Furthermore, Flink can reset the state of an application to a previous savepoint, making it possible to evolve or rescale an application without losing its state.</p>
<p>与事务性应用程序或微服务相比，事件驱动应用程序有几个优点。与对远程数据存储读写查询相比，本地状态访问提供了非常好的性能。扩展和容错由流处理器处理，通过利用事件日志作为输入源，应用程序的完整输入被可靠地存储并可以确定地重播。此外，Flink可以将应用程序的状态重置为以前的保存点，从而可以在不丢失状态的情况下演化或重新调整应用程序</p>
]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>rtc</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/TTL/</url>
    <content><![CDATA[<h1 id="简析Flink状态生存时间（State-TTL）机制的底层实现"><a href="#简析Flink状态生存时间（State-TTL）机制的底层实现" class="headerlink" title="简析Flink状态生存时间（State TTL）机制的底层实现"></a>简析Flink状态生存时间（State TTL）机制的底层实现</h1><p><a href="https://blog.csdn.net/nazeniwaresakini/article/details/106094778">简析Flink状态生存时间（State TTL）机制的底层实现</a></p>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>从Flink 1.6版本开始，社区为状态引入了TTL（time-to-live，生存时间）机制，支持Keyed State的自动过期，有效解决了状态数据在无干预情况下无限增长导致OOM的问题。State TTL的用法很简单，<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/stream/state/state.html#state-time-to-live-ttll">官方文档</a>中给出的示例代码如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StateTtlConfig ttlConfig =</span><br><span class="line"> StateTtlConfig</span><br><span class="line"> .newBuilder(Time.seconds(<span class="number">1</span>))</span><br><span class="line"> .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)</span><br><span class="line"> .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)</span><br><span class="line"> .build();</span><br><span class="line">ValueStateDescriptor&lt;String&gt; stateDescriptor = <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">&quot;text state&quot;</span>, String.class);</span><br><span class="line">stateDescriptor.enableTimeToLive(ttlConfig);</span><br></pre></td></tr></table></figure>
<p>那么State TTL的背后又隐藏着什么样的思路呢？下面就从设置类StateTtlConfig入手开始研究（Flink代码版本为1.9.3）。</p>
<h3 id="StateTtlConfig"><a href="#StateTtlConfig" class="headerlink" title="StateTtlConfig"></a>StateTtlConfig</h3><p>该类中有5个成员属性，它们就是用户需要指定的全部参数了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> UpdateType updateType</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> StateVisibility stateVisibility</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> TtlTimeCharacteristic ttlTimeCharacteristic</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Time ttl</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> CleanupStrategies cleanupStrategies</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中，ttl参数表示用户设定的状态生存时间。而UpdateType、StateVisibility和TtlTimeCharacteristic都是枚举，分别代表状态时间戳的更新方式、过期状态数据的可见性，以及对应的时间特征。它们的含义在注释中已经解释得很清楚了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * This option value configures when to update last access timestamp which prolongs state TTL. </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">UpdateType</span> </span>&#123;    </span><br><span class="line"><span class="comment">/** TTL is disabled. State does not expire. */</span>    </span><br><span class="line">  Disabled,    </span><br><span class="line"><span class="comment">/** Last access timestamp is initialised when state is created and updated on every write operation. </span></span><br><span class="line"><span class="comment">当每次写操作时，更新时间戳</span></span><br><span class="line"><span class="comment"> */</span>    </span><br><span class="line">  OnCreateAndWrite,    </span><br><span class="line"><span class="comment">/** The same as &lt;code&gt;OnCreateAndWrite&lt;/code&gt; but also updated on read.</span></span><br><span class="line"><span class="comment">当每次读写操作时，更新时间戳</span></span><br><span class="line"><span class="comment"> */</span>    </span><br><span class="line">  OnReadAndWrite</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** * This option configures whether expired user value can be returned or not. */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">StateVisibility</span> </span>&#123;    </span><br><span class="line">  <span class="comment">/** Return expired user value if it is not cleaned up yet. */</span>    </span><br><span class="line">  ReturnExpiredIfNotCleanedUp,    </span><br><span class="line">  <span class="comment">/** Never return expired user value. */</span>    </span><br><span class="line">  NeverReturnExpired</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** * This option configures time scale to use for ttl. */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">TtlTimeCharacteristic</span> </span>&#123;    </span><br><span class="line">  <span class="comment">/** Processing time, see also &lt;code&gt;org.apache.flink.streaming.api.TimeCharacteristic.ProcessingTime&lt;/code&gt;. */</span>    </span><br><span class="line">  ProcessingTime</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Flink目前仅支持基于处理时间的State TTL，事件时间会在不久的将来支持。</p>
<p>CleanupStrategies内部类则用来规定过期状态的特殊清理策略，用户在构造StateTtlConfig时，可以通过调用以下方法之一指定。</p>
<ul>
<li><strong><code>cleanupFullSnapshot()</code></strong><br>  当对状态做全量快照时清理过期数据，对开启了增量检查点（incremental checkpoint）的RocksDB状态后端无效，对应源码中的EmptyCleanupStrategy。<br>  为什么叫做“空的”清理策略呢？因为该选项只能保证状态持久化时不包含过期数据，但TaskManager本地的过期状态则不作任何处理，所以无法从根本上解决OOM的问题，需要定期重启作业。</li>
<li><strong><code>cleanupIncrementally(int cleanupSize, boolean runCleanupForEveryRecord)</code></strong><br>  增量清理过期数据，默认在每次访问状态时进行清理，将runCleanupForEveryRecord设为true可以附加在每次写入/删除时清理。cleanupSize指定每次触发清理时检查的状态条数。<br>  仅对基于堆的状态后端有效，对应源码中的IncrementalCleanupStrategy。</li>
<li><strong><code>cleanupInRocksdbCompactFilter(long queryTimeAfterNumEntries)</code></strong><br>  当RocksDB做compaction操作时，通过Flink定制的过滤器（FlinkCompactionFilter）过滤掉过期状态数据。参数queryTimeAfterNumEntries用于指定在写入多少条状态数据后，通过状态时间戳来判断是否过期。<br>  该策略仅对RocksDB状态后端有效，对应源码中的RocksdbCompactFilterCleanupStrategy。CompactionFilter是RocksDB原生提供的机制，其说明可见<a href="https://links.jianshu.com/go?to=https://github.com/facebook/rocksdb/wiki/Compaction-Filter">这里</a>。</li>
</ul>
<p>如果不调用上述方法，则采用默认的后台清理策略，下文有讲。</p>
<h3 id="TtlStateFactory、TtlStateContext"><a href="#TtlStateFactory、TtlStateContext" class="headerlink" title="TtlStateFactory、TtlStateContext"></a>TtlStateFactory、TtlStateContext</h3><p>在所有Keyed State状态后端的抽象基类AbstractKeyedStateBackend中，创建并记录一个状态实例的方法如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="keyword">public</span> &lt;N, S extends State, V&gt; <span class="function">S <span class="title">getOrCreateKeyedState</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">   <span class="keyword">final</span> TypeSerializer&lt;N&gt; namespaceSerializer, StateDescriptor&lt;S, V&gt; stateDescriptor)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  checkNotNull(namespaceSerializer, <span class="string">&quot;Namespace serializer&quot;</span>);</span><br><span class="line">  checkNotNull(keySerializer, <span class="string">&quot;State key serializer has not been configured in the config. &quot;</span> +</span><br><span class="line">  <span class="string">&quot;This operation cannot use partitioned state.&quot;</span>);</span><br><span class="line">  InternalKvState&lt;K, ?, ?&gt; kvState = keyValueStatesByName.get(stateDescriptor.getName());</span><br><span class="line">  <span class="keyword">if</span> (kvState == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!stateDescriptor.isSerializerInitialized()) &#123;</span><br><span class="line">      stateDescriptor.initializeSerializerUnlessSet(executionConfig);</span><br><span class="line">    &#125;</span><br><span class="line">    kvState = TtlStateFactory.createStateAndWrapWithTtlIfEnabled( namespaceSerializer, stateDescriptor, <span class="keyword">this</span>, ttlTimeProvider);</span><br><span class="line">    keyValueStatesByName.put(stateDescriptor.getName(), kvState);</span><br><span class="line">    publishQueryableStateIfEnabled(stateDescriptor, kvState);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> (S) kvState;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见是调用了TtlStateFactory.createStateAndWrapWithTtlIfEnabled()方法来真正创建。顾名思义，TtlStateFactory是产生TTL状态的工厂类。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;K, N, SV, TTLSV, S extends State, IS extends S&gt; <span class="function">IS <span class="title">createStateAndWrapWithTtlIfEnabled</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">    TypeSerializer&lt;N&gt; namespaceSerializer, </span></span></span><br><span class="line"><span class="function"><span class="params">    StateDescriptor&lt;S, SV&gt; stateDesc, </span></span></span><br><span class="line"><span class="function"><span class="params">    KeyedStateBackend&lt;K&gt; stateBackend, </span></span></span><br><span class="line"><span class="function"><span class="params">    TtlTimeProvider timeProvider</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  Preconditions.checkNotNull(namespaceSerializer);</span><br><span class="line">  Preconditions.checkNotNull(stateDesc);</span><br><span class="line">  Preconditions.checkNotNull(stateBackend);</span><br><span class="line">  Preconditions.checkNotNull(timeProvider);</span><br><span class="line">  <span class="keyword">return</span> stateDesc.getTtlConfig().isEnabled() ? <span class="keyword">new</span> TtlStateFactory&lt;K, N, SV, TTLSV, S, IS&gt;( namespaceSerializer, stateDesc, stateBackend, timeProvider) .createState() : stateBackend.createInternalState(namespaceSerializer, stateDesc);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由上可知，如果我们为状态描述符StateDescriptor加入了TTL，那么就会调用TtlStateFactory.createState()方法创建一个带有TTL的状态实例；否则，就调用StateBackend.createInternalState()创建一个普通的状态实例。TtlStateFactory.createState()的代码如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> IS <span class="title">createState</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  SupplierWithException&lt;IS, Exception&gt; stateFactory = stateFactories.get(stateDesc.getClass());</span><br><span class="line">  <span class="keyword">if</span> (stateFactory == <span class="keyword">null</span>) &#123;</span><br><span class="line">    String message = String.format(<span class="string">&quot;State %s is not supported by %s&quot;</span>, stateDesc.getClass(), TtlStateFactory.class);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> FlinkRuntimeException(message);</span><br><span class="line">  &#125;</span><br><span class="line">  IS state = stateFactory.get();</span><br><span class="line">  <span class="keyword">if</span> (incrementalCleanup != <span class="keyword">null</span>) &#123;</span><br><span class="line">    incrementalCleanup.setTtlState((AbstractTtlState&lt;K, N, ?, TTLSV, ?&gt;) state);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> state;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，stateFactories是一个Map结构，维护了各种状态描述符与对应产生该种状态对象的工厂方法映射。所有的工厂方法都被包装成了Supplier（Java 8提供的函数式接口），所以在上述createState()方法中，可以通过Supplier.get()方法来实际执行createTtl.State()工厂方法，并获得新的状态实例。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">this</span>.stateFactories = createStateFactories();</span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;deprecation&quot;)</span></span><br><span class="line"><span class="keyword">private</span> Map&lt;Class&lt;? extends StateDescriptor&gt;, SupplierWithException&lt;IS, Exception&gt;&gt; createStateFactories() &#123;</span><br><span class="line">  <span class="keyword">return</span> Stream.of(</span><br><span class="line">    Tuple2.of(ValueStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createValueState),</span><br><span class="line">    Tuple2.of(ListStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createListState),</span><br><span class="line">    Tuple2.of(MapStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createMapState),</span><br><span class="line">    Tuple2.of(ReducingStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createReducingState),</span><br><span class="line">    Tuple2.of(AggregatingStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createAggregatingState),</span><br><span class="line">    Tuple2.of(FoldingStateDescriptor.class, (SupplierWithException&lt;IS, Exception&gt;) <span class="keyword">this</span>::createFoldingState)</span><br><span class="line">  ).collect(Collectors.toMap(t -&gt; t.f0, t -&gt; t.f1));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> IS <span class="title">createValueState</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  ValueStateDescriptor&lt;TtlValue&lt;SV&gt;&gt; ttlDescriptor = <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(</span><br><span class="line">      stateDesc.getName(), </span><br><span class="line">      <span class="keyword">new</span> TtlSerializer&lt;&gt;(LongSerializer.INSTANCE, stateDesc.getSerializer())</span><br><span class="line">  );</span><br><span class="line">  <span class="keyword">return</span> (IS) <span class="keyword">new</span> TtlValueState&lt;&gt;(createTtlStateContext(ttlDescriptor));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="function">IS <span class="title">createListState</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  ListStateDescriptor&lt;T&gt; listStateDesc = (ListStateDescriptor&lt;T&gt;) stateDesc;</span><br><span class="line">  ListStateDescriptor&lt;TtlValue&lt;T&gt;&gt; ttlDescriptor = <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(</span><br><span class="line">      stateDesc.getName(), </span><br><span class="line">      <span class="keyword">new</span> TtlSerializer&lt;&gt;(LongSerializer.INSTANCE, listStateDesc.getElementSerializer())</span><br><span class="line">  );</span><br><span class="line">  <span class="keyword">return</span> (IS) <span class="keyword">new</span> TtlListState&lt;&gt;(createTtlStateContext(ttlDescriptor));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 以下略去...</span></span><br></pre></td></tr></table></figure>
<p>可见，带有TTL的状态类名其实就是普通状态类名加上Ttl前缀，只是没有公开给用户而已。并且在生成<code>Ttl$State</code>时，还会通过createTtlStateContext()方法生成TTL状态的上下文。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="keyword">private</span> &lt;OIS extends State, TTLS extends State, V, TTLV&gt; TtlStateContext&lt;OIS, V&gt;</span><br><span class="line">createTtlStateContext(StateDescriptor&lt;TTLS, TTLV&gt; ttlDescriptor) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    ttlDescriptor.enableTimeToLive(stateDesc.getTtlConfig()); </span><br><span class="line">    <span class="comment">// also used by RocksDB backend for TTL compaction filter config</span></span><br><span class="line">    OIS originalState = (OIS) stateBackend.createInternalState(</span><br><span class="line">        namespaceSerializer, </span><br><span class="line">        ttlDescriptor, </span><br><span class="line">        getSnapshotTransformFactory()</span><br><span class="line">    );</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> TtlStateContext&lt;&gt;(</span><br><span class="line">        originalState, </span><br><span class="line">        ttlConfig, </span><br><span class="line">        timeProvider, </span><br><span class="line">        (TypeSerializer&lt;V&gt;) stateDesc.getSerializer(),</span><br><span class="line">        registerTtlIncrementalCleanupCallback((InternalKvState&lt;?, ?, ?&gt;) originalState)</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>TtlStateContext的本质是对以下几个实例做了封装。</p>
<ul>
<li>原始State（通过StateBackend.createInternalState()方法创建）及其序列化器（通过StateDescriptor.getSerializer()方法取得）；</li>
<li>StateTtlConfig，前文已经讲过；</li>
<li>TtlTimeProvider，用来提供判断状态过期标准的时间戳。当前只是简单地代理了System.currentTimeMillis()，没有任何其他代码；</li>
<li>一个Runnable类型的回调方法，通过registerTtlIncrementalCleanupCallback()方法产生，用于状态数据的增量清理，后面会看到它的用途。</li>
</ul>
<p>接下来就具体看看TTL状态是如何实现的。</p>
<h3 id="AbstractTtlState、AbstractTtlDecorator"><a href="#AbstractTtlState、AbstractTtlDecorator" class="headerlink" title="AbstractTtlState、AbstractTtlDecorator"></a>AbstractTtlState、AbstractTtlDecorator</h3><p>在解说之前，先放一幅类图。</p>
<p><img src="_v_images/20200917142252357_1752793097"></p>
<p>所有Ttl.State都是AbstractTtlState的子类，而AbstractTtlState又是装饰器AbstractTtlDecorator的子类。AbstractTtlDecorator提供了最基本的TTL逻辑，代码不长，全部抄录如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractTtlDecorator</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">  <span class="comment">/** Wrapped original state handler. */</span></span><br><span class="line">  <span class="keyword">final</span> T original;</span><br><span class="line">  <span class="keyword">final</span> StateTtlConfig config;</span><br><span class="line">  <span class="keyword">final</span> TtlTimeProvider timeProvider;</span><br><span class="line">  <span class="comment">/** Whether to renew expiration timestamp on state read access. */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> updateTsOnRead;</span><br><span class="line">  <span class="comment">/** Whether to renew expiration timestamp on state read access. */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> returnExpired;</span><br><span class="line">  <span class="comment">/** State value time to live in milliseconds. */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> ttl;</span><br><span class="line">  AbstractTtlDecorator( T original, StateTtlConfig config, TtlTimeProvider timeProvider) &#123;</span><br><span class="line">  <span class="comment">// ......</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 查到已过期数据，返回null</span></span><br><span class="line">  &lt;V&gt; <span class="function">V <span class="title">getUnexpired</span><span class="params">(TtlValue&lt;V&gt; ttlValue)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ttlValue == <span class="keyword">null</span> || (expired(ttlValue) &amp;&amp; !returnExpired) ? <span class="keyword">null</span> : ttlValue.getUserValue();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 过期掉数据</span></span><br><span class="line">  &lt;V&gt; <span class="function"><span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(TtlValue&lt;V&gt; ttlValue)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> TtlUtils.expired(ttlValue, ttl, timeProvider);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 包装数据</span></span><br><span class="line">  &lt;V&gt; <span class="function">TtlValue&lt;V&gt; <span class="title">wrapWithTs</span><span class="params">(V value)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> TtlUtils.wrapWithTs(value, timeProvider.currentTimestamp());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 重新包装数据</span></span><br><span class="line">  &lt;V&gt; <span class="function">TtlValue&lt;V&gt; <span class="title">rewrapWithNewTs</span><span class="params">(TtlValue&lt;V&gt; ttlValue)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> wrapWithTs(ttlValue.getUserValue());</span><br><span class="line">  &#125;</span><br><span class="line">  &lt;SE extends Throwable, CE extends Throwable, CLE extends Throwable, V&gt; <span class="function">V <span class="title">getWithTtlCheckAndUpdate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      SupplierWithException&lt;TtlValue&lt;V&gt;, SE&gt; getter,</span></span></span><br><span class="line"><span class="function"><span class="params">      ThrowingConsumer&lt;TtlValue&lt;V&gt;, CE&gt; updater,</span></span></span><br><span class="line"><span class="function"><span class="params">      ThrowingRunnable&lt;CLE&gt; stateClear</span></span></span><br><span class="line"><span class="function"><span class="params">  )</span> <span class="keyword">throws</span> SE, CE, CLE </span>&#123;</span><br><span class="line">    TtlValue&lt;V&gt; ttlValue = getWrappedWithTtlCheckAndUpdate(getter, updater, stateClear);</span><br><span class="line">    <span class="keyword">return</span> ttlValue == <span class="keyword">null</span> ? <span class="keyword">null</span> : ttlValue.getUserValue();</span><br><span class="line">  &#125;</span><br><span class="line">  &lt;SE extends Throwable, CE extends Throwable, CLE extends Throwable, V&gt; <span class="function">TtlValue&lt;V&gt; <span class="title">getWrappedWithTtlCheckAndUpdate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      SupplierWithException&lt;TtlValue&lt;V&gt;, SE&gt; getter,</span></span></span><br><span class="line"><span class="function"><span class="params">      ThrowingConsumer&lt;TtlValue&lt;V&gt;, CE&gt; updater,</span></span></span><br><span class="line"><span class="function"><span class="params">      ThrowingRunnable&lt;CLE&gt; stateClear</span></span></span><br><span class="line"><span class="function"><span class="params">  )</span> <span class="keyword">throws</span> SE, CE, CLE </span>&#123;</span><br><span class="line">      TtlValue&lt;V&gt; ttlValue = getter.get();</span><br><span class="line">      <span class="keyword">if</span> (ttlValue == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (expired(ttlValue)) &#123;</span><br><span class="line">        stateClear.run();</span><br><span class="line">        <span class="keyword">if</span> (!returnExpired) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (updateTsOnRead) &#123;</span><br><span class="line">          updater.accept(rewrapWithNewTs(ttlValue));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> ttlValue;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它的成员属性比较容易理解，例如，updateTsOnRead表示在读取状态值时也更新时间戳（即UpdateType.OnReadAndWrite），returnExpired表示即使状态过期，在被真正删除之前也返回它的值（即StateVisibility.ReturnExpiredIfNotCleanedUp）。</p>
<p>状态值与TTL的包装（成为TtlValue）以及过期检测都由工具类TtlUtils来负责，思路很简单，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TtlUtils</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> &lt;V&gt; <span class="function"><span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(<span class="meta">@Nullable</span> TtlValue&lt;V&gt; ttlValue, <span class="keyword">long</span> ttl, TtlTimeProvider timeProvider)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> expired(ttlValue, ttl, timeProvider.currentTimestamp());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">static</span> &lt;V&gt; <span class="function"><span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(<span class="meta">@Nullable</span> TtlValue&lt;V&gt; ttlValue, <span class="keyword">long</span> ttl, <span class="keyword">long</span> currentTimestamp)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ttlValue != <span class="keyword">null</span> &amp;&amp; expired(ttlValue.getLastAccessTimestamp(), ttl, currentTimestamp);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(<span class="keyword">long</span> ts, <span class="keyword">long</span> ttl, TtlTimeProvider timeProvider)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> expired(ts, ttl, timeProvider.currentTimestamp());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">expired</span><span class="params">(<span class="keyword">long</span> ts, <span class="keyword">long</span> ttl, <span class="keyword">long</span> currentTimestamp)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> getExpirationTimestamp(ts, ttl) &lt;= currentTimestamp;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getExpirationTimestamp</span><span class="params">(<span class="keyword">long</span> ts, <span class="keyword">long</span> ttl)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> ttlWithoutOverflow = ts &gt; <span class="number">0</span> ? Math.min(Long.MAX_VALUE - ts, ttl) : ttl;</span><br><span class="line">    <span class="keyword">return</span> ts + ttlWithoutOverflow;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">static</span> &lt;V&gt; <span class="function">TtlValue&lt;V&gt; <span class="title">wrapWithTs</span><span class="params">(V value, <span class="keyword">long</span> ts)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> TtlValue&lt;&gt;(value, ts);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>TtlValue的属性只有两个：状态值和时间戳，代码略去。</p>
<p>AbstractTtlDecorator核心方法是获取状态值的getWrappedWithTtlCheckAndUpdate()，它接受三个参数：</p>
<ul>
<li>getter：一个可抛出异常的Supplier，用于获取状态值；</li>
<li>updater：一个可抛出异常的Consumer，用于更新状态的时间戳；</li>
<li>stateClear：一个可抛出异常的Runnable，用于异步删除过期状态。</li>
</ul>
<p>可见，在默认情况下的后台清理策略是：<strong>只有状态值被读取时，才会做过期检测，并异步清除过期的状态</strong>。这种<strong>惰性清理</strong>的机制会导致<strong>那些实际已经过期但从未被再次访问过的状态无法被删除</strong>，需要特别注意。官方文档中也已有提示：</p>
<blockquote>
<p>By default, expired values are explicitly removed on read, such as ValueState#value, and periodically garbage collected in the background if supported by the configured state backend.</p>
</blockquote>
<p>当确认到状态过期时，会调用stateClear的逻辑进行删除；如果需要在读取时顺便更新状态的时间戳，会调用updater的逻辑重新包装一个TtlValue。</p>
<p>AbstractTtlState的代码更加简单，主要的方法列举如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Runnable accessCallback; &lt;SE extends Throwable, CE extends Throwable, T&gt; <span class="function">T <span class="title">getWithTtlCheckAndUpdate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  SupplierWithException&lt;TtlValue&lt;T&gt;, SE&gt; getter,</span></span></span><br><span class="line"><span class="function"><span class="params">  ThrowingConsumer&lt;TtlValue&lt;T&gt;, CE&gt; updater)</span> <span class="keyword">throws</span> SE, CE </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> getWithTtlCheckAndUpdate(getter, updater, original::clear);&#125; <span class="meta">@Overridepublic</span> <span class="function"><span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  original.clear();</span><br><span class="line">  accessCallback.run();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，accessCallback就是TtlStateContext中注册的增量清理回调。</p>
<p>下面以TtlMapState为例，看看具体的TTL状态如何利用上文所述的这些实现。</p>
<h3 id="TtlMapState"><a href="#TtlMapState" class="headerlink" title="TtlMapState"></a>TtlMapState</h3><p>以下是部分代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TtlMapState</span>&lt;<span class="title">K</span>, <span class="title">N</span>, <span class="title">UK</span>, <span class="title">UV</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">extends</span> <span class="title">AbstractTtlState</span>&lt;<span class="title">K</span>, <span class="title">N</span>, <span class="title">Map</span>&lt;<span class="title">UK</span>, <span class="title">UV</span>&gt;, <span class="title">Map</span>&lt;<span class="title">UK</span>, <span class="title">TtlValue</span>&lt;<span class="title">UV</span>&gt;&gt;, <span class="title">InternalMapState</span>&lt;<span class="title">K</span>, <span class="title">N</span>, <span class="title">UK</span>, <span class="title">TtlValue</span>&lt;<span class="title">UV</span>&gt;&gt;&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">implements</span> <span class="title">InternalMapState</span>&lt;<span class="title">K</span>, <span class="title">N</span>, <span class="title">UK</span>, <span class="title">UV</span>&gt; </span>&#123;</span><br><span class="line">    TtlMapState(TtlStateContext&lt;InternalMapState&lt;K, N, UK, TtlValue&lt;UV&gt;&gt;, Map&lt;UK, UV&gt;&gt; ttlStateContext) &#123;</span><br><span class="line">        <span class="keyword">super</span>(ttlStateContext);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> UV <span class="title">get</span><span class="params">(UK key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        TtlValue&lt;UV&gt; ttlValue = getWrapped(key);</span><br><span class="line">        <span class="keyword">return</span> ttlValue == <span class="keyword">null</span> ? <span class="keyword">null</span> : ttlValue.getUserValue();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> TtlValue&lt;UV&gt; <span class="title">getWrapped</span><span class="params">(UK key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        accessCallback.run();</span><br><span class="line">        <span class="keyword">return</span> getWrappedWithTtlCheckAndUpdate(() -&gt; original.get(key), v -&gt; original.put(key, v), () -&gt; original.remove(key));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(UK key, UV value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        accessCallback.run();</span><br><span class="line">        original.put(key, wrapWithTs(value));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putAll</span><span class="params">(Map&lt;UK, UV&gt; map)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        accessCallback.run();</span><br><span class="line">        <span class="keyword">if</span> (map == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        Map&lt;UK, TtlValue&lt;UV&gt;&gt; ttlMap = <span class="keyword">new</span> HashMap&lt;&gt;(map.size());</span><br><span class="line">        <span class="keyword">long</span> currentTimestamp = timeProvider.currentTimestamp();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;UK, UV&gt; entry : map.entrySet()) &#123;</span><br><span class="line">            UK key = entry.getKey();</span><br><span class="line">            ttlMap.put(key, TtlUtils.wrapWithTs(entry.getValue(), currentTimestamp));</span><br><span class="line">        &#125;</span><br><span class="line">        original.putAll(ttlMap);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(UK key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    accessCallback.run();</span><br><span class="line">    original.remove(key);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(UK key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    TtlValue&lt;UV&gt; ttlValue = getWrapped(key);</span><br><span class="line">    <span class="keyword">return</span> ttlValue != <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见，TtlMapState的增删改查操作都是在原MapState上进行，只是加上了TTL相关的逻辑，这也是装饰器模式的特点。例如，TtlMapState.get()方法调用了上述AbstractTtlDecorator.getWrappedWithTtlCheckAndUpdate()方法，传入的获取（getter）、插入（updater）和删除（stateClear）的逻辑就是原MapState的get()、put()和remove()方法。而TtlMapState.put()只是在调用原MapState的put()方法之前，将状态包装为TtlValue而已。</p>
<h2 id="增量清理策略"><a href="#增量清理策略" class="headerlink" title="增量清理策略"></a>增量清理策略</h2><p>另外需要注意，所有增删改查操作之前都需要执行accessCallback.run()方法。如果启用了增量清理策略，该Runnable会通过在状态数据上维护一个全局迭代器向前清理过期数据。如果未启用增量清理策略，accessCallback为空。前文提到过的<code>TtlStateFactory.registerTtlIncrementalCleanupCallback()</code> 方法如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Runnable <span class="title">registerTtlIncrementalCleanupCallback</span><span class="params">(InternalKvState&lt;?, ?, ?&gt; originalState)</span> </span>&#123;</span><br><span class="line">    StateTtlConfig.IncrementalCleanupStrategy config =</span><br><span class="line">        ttlConfig.getCleanupStrategies().getIncrementalCleanupStrategy();</span><br><span class="line">    <span class="keyword">boolean</span> cleanupConfigured = config != <span class="keyword">null</span> &amp;&amp; incrementalCleanup != <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">boolean</span> isCleanupActive = cleanupConfigured &amp;&amp;</span><br><span class="line">        isStateIteratorSupported(originalState, incrementalCleanup.getCleanupSize());</span><br><span class="line">    Runnable callback = isCleanupActive ? incrementalCleanup::stateAccessed : () -&gt; &#123; &#125;;</span><br><span class="line">    <span class="keyword">if</span> (isCleanupActive &amp;&amp; config.runCleanupForEveryRecord()) &#123;</span><br><span class="line">        stateBackend.registerKeySelectionListener(stub -&gt; callback.run());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> callback;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际清理的代码则位于<code>TtlIncrementalCleanup</code>类中，stateIterator就是状态数据的迭代器。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">stateAccessed</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    initIteratorIfNot();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        runCleanup();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FlinkRuntimeException(<span class="string">&quot;Failed to incrementally clean up state with TTL&quot;</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initIteratorIfNot</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (stateIterator == <span class="keyword">null</span> || !stateIterator.hasNext()) &#123;</span><br><span class="line">        stateIterator = ttlState.original.getStateIncrementalVisitor(cleanupSize);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">runCleanup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> entryNum = <span class="number">0</span>;</span><br><span class="line">    Collection&lt;StateEntry&lt;K, N, S&gt;&gt; nextEntries;</span><br><span class="line">    <span class="keyword">while</span> (    entryNum &lt; cleanupSize &amp;&amp;</span><br><span class="line">    stateIterator.hasNext() &amp;&amp;    !(nextEntries = stateIterator.nextEntries()).isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">for</span> (StateEntry&lt;K, N, S&gt; state : nextEntries) &#123;</span><br><span class="line">            S cleanState = ttlState.getUnexpiredOrNull(state.getState());</span><br><span class="line">            <span class="keyword">if</span> (cleanState == <span class="keyword">null</span>) &#123;</span><br><span class="line">                stateIterator.remove(state);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cleanState != state.getState()) &#123;</span><br><span class="line">                stateIterator.update(state, cleanState);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        entryNum += nextEntries.size();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>RocksDB压缩过滤清理策略</p>
<p>如果启用了该策略，Flink会通过维护一个<code>RocksDbTtlCompactFiltersManager</code>实例来管理<code>FlinkCompactionFilter</code>过滤器。<code>FlinkCompactionFilter</code>并不是在Flink工程中维护的，而是位于Data Artisans为Flink专门维护的FRocksDB库内。<a href="https://links.jianshu.com/go?to=https://issues.apache.org/jira/browse/FLINK-10471">FLINK-10471</a>实现了FlinkCompactionFilter及其附属逻辑，主要为C++代码，通过JNI调用。对应的commit详见<a href="https://links.jianshu.com/go?to=https://github.com/dataArtisans/frocksdb/commit/01dca02244522e405c9258000903fee81496f72c">GitHub</a>，这里就不班门弄斧了。关于RocksDB的compaction相关细节，笔者之前也写过<a href="https://www.jianshu.com/p/e89cd503c9ae">一篇长文</a>做了些分析。</p>
]]></content>
  </entry>
  <entry>
    <title>Flink-streaming API</title>
    <url>/bigdata/Flink/StreamingAPI/</url>
    <content><![CDATA[<h1 id="Flink-Streaming-API"><a href="#Flink-Streaming-API" class="headerlink" title="Flink Streaming API"></a>Flink Streaming API</h1><h2 id="org-apache-flink-streaming-api-functions-source-SourceFunction"><a href="#org-apache-flink-streaming-api-functions-source-SourceFunction" class="headerlink" title="org.apache.flink.streaming.api.functions.source.SourceFunction"></a>org.apache.flink.streaming.api.functions.source.SourceFunction</h2>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink:Table API</title>
    <url>/bigdata/Flink/TableAPI/</url>
    <content><![CDATA[<h1 id="flink-table-api"><a href="#flink-table-api" class="headerlink" title="flink-table-api"></a>flink-table-api</h1><p><a href="https://github.com/crestofwave1/oneFlink/blob/master/doc/table/Concept%20%26%20Common%20API.md">官方文档翻译</a></p>
<h2 id="Concept-amp-Common-API"><a href="#Concept-amp-Common-API" class="headerlink" title="Concept  &amp; Common API"></a>Concept  &amp; Common API</h2><p>Table API和SQL集成在一个联合的API中。这个API核心概念是Table，<br>Table可以作为查询的输入和输出。这篇文章展示了使用Table API和SQL查询的通用结构，<br>如何去进行表的注册，如何去进行表的查询，并且展示如何去进行表的输出。</p>
<h2 id="1-Structure-of-Table-API-and-SQL-Programs"><a href="#1-Structure-of-Table-API-and-SQL-Programs" class="headerlink" title="1. Structure of Table API and SQL Programs"></a>1. Structure of Table API and SQL Programs</h2><p>​    所有使用批量和流式相关的Table API和SQL的程序都有以下相同模式。下面的代码实例展示了Table API和SQL程序的通用结构。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在批处理程序中使用ExecutionEnvironment代替StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册表</span></span><br><span class="line">tableEnv.registerTable(<span class="string">&quot;table1&quot;</span>, ...)           <span class="comment">// or</span></span><br><span class="line">tableEnv.registerTableSource(<span class="string">&quot;table2&quot;</span>, ...)     <span class="comment">// or</span></span><br><span class="line">tableEnv.registerExternalCatalog(<span class="string">&quot;extCat&quot;</span>, ...) </span><br><span class="line"></span><br><span class="line"><span class="comment">// 基于Table API的查询创建表</span></span><br><span class="line"><span class="keyword">val</span> tapiResult = tableEnv.scan(<span class="string">&quot;table1&quot;</span>).select(...)</span><br><span class="line"><span class="comment">// 从SQL查询创建表</span></span><br><span class="line"><span class="keyword">val</span> sqlResult  = tableEnv.sqlQuery(<span class="string">&quot;SELECT ... FROM table2 ...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表操作API查询到的结果表输出到TableSink，SQL查询到的结果一样如此</span></span><br><span class="line">tapiResult.writeToSink(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行</span></span><br><span class="line">env.execute()</span><br></pre></td></tr></table></figure>
<p>注意：Table API和SQL查询很容易集成并被嵌入到DataStream或者DataSet程序中。查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-datastream-and-dataset-api">将DataStream和DataSet API进行整合</a>章节<br>学习DataSteams和DataSets是如何转换成Table以及Table是如何转换为DataStream或DataSet</p>
<h2 id="2-Create-a-TableEnvironment"><a href="#2-Create-a-TableEnvironment" class="headerlink" title="2. Create a TableEnvironment"></a>2. Create a TableEnvironment</h2><p>TableEnvironment是Table API与SQL整合的核心概念之一，它主要有如下功能：</p>
<ul>
<li>在internal catalog注册表</li>
<li>注册external catalog</li>
<li>执行SQL查询</li>
<li>注册UDF函数（user-defined function)，例如 标量, 表或聚合</li>
<li>将DataStream或者DataSet转换为表</li>
<li>保持ExecutionEnvironment或者StreamExecutionEnvironment的引用指向</li>
</ul>
<p>一个表总是与一个特定的TableEnvironment绑定在一块，<br>相同的查询不同的TableEnvironment是无法通过join、union合并在一起。</p>
<p>创建TableEnvironment的方法通常是通过StreamExecutionEnvironment，ExecutionEnvironment对象调用其中的静态方法TableEnvironment.getTableEnvironment()，或者是TableConfig来创建。<br>TableConfig可以用作配置TableEnvironment或是对自定义查询优化器或者是编译过程进行优化(详情查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#query-optimization">查询优化</a>)</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ***************</span></span><br><span class="line"><span class="comment">// 流式查询</span></span><br><span class="line"><span class="comment">// ***************</span></span><br><span class="line"><span class="keyword">val</span> sEnv = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="comment">// 为流式查询创建一个TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> sTableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(sEnv)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ***********</span></span><br><span class="line"><span class="comment">// 批量查询</span></span><br><span class="line"><span class="comment">// ***********</span></span><br><span class="line"><span class="keyword">val</span> bEnv = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="comment">// 为批量查询创建一个TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> bTableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(bEnv)</span><br></pre></td></tr></table></figure>
<h2 id="Register-Tables-in-the-Catalog"><a href="#Register-Tables-in-the-Catalog" class="headerlink" title="Register Tables in the Catalog"></a>Register Tables in the Catalog</h2><p>TableEnvironment包含了通过名称注册表时的表的catalog信息。通常情况下有两种表，一种为输入表，<br>一种为输出表。输入表主要是在使用Table API和SQL查询时提供输入数据，输出表主要是将Table API和<br>SQL查询的结果作为输出结果对接到外部系统。</p>
<p>输入表有多种不同的输入源进行注册：</p>
<ul>
<li>已经存在的Table对象，通常是是作为Table API和SQL查询的结果</li>
<li>TableSource，可以访问外部数据如文件，数据库或者是消息系统</li>
<li>来自DataStream或是DataSet程序中的DataStream或DataSet，讨论DataStream或是DataSet<br>可以<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-datastream-and-dataset-api">整合DataStream和DataSet API</a>了解到</li>
</ul>
<p>输出表可使用TableSink进行注册</p>
<h2 id="Register-a-Table"><a href="#Register-a-Table" class="headerlink" title="Register a Table"></a>Register a Table</h2><p>Table是如何注册到TableEnvironment中如下所示：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从简单的查询结果中作为表</span></span><br><span class="line"><span class="keyword">val</span> projTable: <span class="type">Table</span> = tableEnv.scan(<span class="string">&quot;X&quot;</span>).select(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的表projTable命名为projectedTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTable(<span class="string">&quot;projectedTable&quot;</span>, projTable)</span><br></pre></td></tr></table></figure>
<p>注意：一张注册过的Table就跟关系型数据库中的视图性质相同，定义表的查询未进行优化，但在另一个查询引用已注册的表时将进行内联。<br>如果多表查询引用了相同的Table，它就会将每一个引用进行内联并且多次执行，已注册的Table的结果之间不会进行共享。</p>
<h2 id="Register-a-TableSource"><a href="#Register-a-TableSource" class="headerlink" title="Register a TableSource"></a>Register a TableSource</h2><p>TableSource可以访问外部系统存储例如数据库（Mysql,HBase），特殊格式编码的文件(CSV, Apache [Parquet, Avro, ORC], …)<br>或者是消息系统 (Apache Kafka, RabbitMQ, …)中的数据。</p>
<p>Flink旨在为通用数据格式和存储系统提供TableSource。请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">此处</a><br>了解支持的TableSource类型与如何去自定义TableSour。</p>
<p>TableSource是如何注册到TableEnvironment中如下所示：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableSource对象</span></span><br><span class="line"><span class="keyword">val</span> csvSource: <span class="type">TableSource</span> = <span class="keyword">new</span> <span class="type">CsvTableSource</span>(<span class="string">&quot;/path/to/file&quot;</span>, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的TableSource作为表并命名为csvTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTableSource(<span class="string">&quot;CsvTable&quot;</span>, csvSource)</span><br></pre></td></tr></table></figure>
<h2 id="Register-a-TableSink"><a href="#Register-a-TableSink" class="headerlink" title="Register a TableSink"></a>Register a TableSink</h2><p>注册过的TableSink可以将SQL查询的结果以表的形式输出到外部的存储系统，例如关系型数据库，<br>Key-Value数据库(Nosql)，消息队列，或者是其他文件系统(使用不同的编码, 例如CSV, Apache [Parquet, Avro, ORC], …)</p>
<p>Flink使用TableSink的目的是为了将常用的数据进行清洗转换然后存储到不同的存储介质中。详情请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">此处</a><br>去深入了解哪些sinks是可用的，并且如何去自定义TableSink。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableSink对象</span></span><br><span class="line"><span class="keyword">val</span> csvSink: <span class="type">TableSink</span> = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">&quot;/path/to/file&quot;</span>, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义字段的名称和类型</span></span><br><span class="line"><span class="keyword">val</span> fieldNames: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> fieldTypes: <span class="type">Array</span>[<span class="type">TypeInformation</span>[_]] = <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">INT</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的TableSink作为表并命名为CsvSinkTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTableSink(<span class="string">&quot;CsvSinkTable&quot;</span>, fieldNames, fieldTypes, csvSink)</span><br></pre></td></tr></table></figure>
<h2 id="Register-an-External-Catalog"><a href="#Register-an-External-Catalog" class="headerlink" title="Register an External Catalog"></a>Register an External Catalog</h2><p>外部目录可以提供有关外部数据库和表的信息，<br>例如其名称，模式，统计以及有关如何访问存储在外部数据库，表或文件中的数据的信息。</p>
<p>外部目录的创建方式可以通过实现ExternalCatalog接口，并且注册到TableEnvironment中，详情如下所示:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个External Catalog目录对象</span></span><br><span class="line"><span class="keyword">val</span> catalog: <span class="type">ExternalCatalog</span> = <span class="keyword">new</span> <span class="type">InMemoryExternalCatalog</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将ExternalCatalog注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerExternalCatalog(<span class="string">&quot;InMemCatalog&quot;</span>, catalog)</span><br></pre></td></tr></table></figure>
<p>一旦将External Catalog注册到TableEnvironment中，所有在ExternalCatalog中<br>定义的表可以通过完整的路径如catalog.database.table进行Table API和SQL的查询操作 </p>
<p>目前，Flink提供InMemoryExternalCatalog对象用来做demo和测试，然而，<br>ExternalCatalog对象还可用作Table API来连接catalogs，例如HCatalog 或 Metastore</p>
<h2 id="Query-a-Table"><a href="#Query-a-Table" class="headerlink" title="Query a Table"></a>Query a Table</h2><h3 id="Table-API"><a href="#Table-API" class="headerlink" title="Table API"></a>Table API</h3><p>Table API是Scala和Java语言集成查询的API，与SQL查询不同之处在于，它的查询不是像<br>SQL一样使用字符串进行查询，而是在语言中使用语法进行逐步组合使用</p>
<p>Table API是基于展示表（流或批处理）的Table类，它提供一些列操作应用相关的操作。<br>这些方法返回一个新的Table对象，该对象表示在输入表上关系运算的结果。一些关系运算是<br>由多个方法组合而成的，例如 table.groupBy(…).select()，其中groupBy()指定<br>表的分组，select()表示在分组的结果上进行查询。</p>
<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/tableApi.html">Table API</a><br>描述了所有支持表的流式或者批处理相关的操作。</p>
<p>下面给出一个简单的实例去说明如何去使用Table API进行聚合查询：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册Orders表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 扫描注册过的Orders表</span></span><br><span class="line"><span class="keyword">val</span> orders = tableEnv.scan(<span class="string">&quot;Orders&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入</span></span><br><span class="line"><span class="keyword">val</span> revenue = orders</span><br><span class="line">  .filter(<span class="symbol">&#x27;cCountry</span> === <span class="string">&quot;FRANCE&quot;</span>)</span><br><span class="line">  .groupBy(<span class="symbol">&#x27;cID</span>, <span class="symbol">&#x27;cName</span>)</span><br><span class="line">  .select(<span class="symbol">&#x27;cID</span>, <span class="symbol">&#x27;cName</span>, <span class="symbol">&#x27;revenue</span>.sum <span class="type">AS</span> <span class="symbol">&#x27;revSum</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出成一张表或者是转换表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<p>注意：Scala的Table API使用Scala符号，它使用单引号加字段(‘cID)来表示表的属性的引用，<br>如果使用Scala的隐式转换的话，确保引入了org.apache.flink.api.scala._ 和 org.apache.flink.table.api.scala._<br>来确保它们之间的转换。</p>
<h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><p>Flink的SQL操作基于实现了SQL标准的<a href="https://calcite.apache.org/">Apache Calcite</a>，SQL查询通常是使用特殊且有规律的字符串。<br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sql.html">SQL</a><br>描述了所有支持表的流式或者批处理相关的SQL操作。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册Orders表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入</span></span><br><span class="line"><span class="keyword">val</span> revenue = tableEnv.sqlQuery(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  |SELECT cID, cName, SUM(revenue) AS revSum</span></span><br><span class="line"><span class="string">  |FROM Orders</span></span><br><span class="line"><span class="string">  |WHERE cCountry = &#x27;FRANCE&#x27;</span></span><br><span class="line"><span class="string">  |GROUP BY cID, cName</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出成一张表或者是转换表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<p>下面的例子展示了如何去使用更新查询去插入数据到已注册的表中</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册&quot;Orders&quot;表</span></span><br><span class="line"><span class="comment">// 注册&quot;RevenueFrance&quot;输出表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入并且将结果作为结果输出到&quot;RevenueFrance&quot;中</span></span><br><span class="line">tableEnv.sqlUpdate(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  |INSERT INTO RevenueFrance</span></span><br><span class="line"><span class="string">  |SELECT cID, cName, SUM(revenue) AS revSum</span></span><br><span class="line"><span class="string">  |FROM Orders</span></span><br><span class="line"><span class="string">  |WHERE cCountry = &#x27;FRANCE&#x27;</span></span><br><span class="line"><span class="string">  |GROUP BY cID, cName</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<h2 id="Mixing-Table-API-and-SQL"><a href="#Mixing-Table-API-and-SQL" class="headerlink" title="Mixing Table API and SQL"></a>Mixing Table API and SQL</h2><p>Table API和SQL可以很轻松的混合使用因为他们两者返回的结果都为Table对象：</p>
<ul>
<li>可以在SQL查询返回的Table对象上定义Table API查询</li>
<li>通过在TableEnvironment中注册结果表并在SQL查询的FROM子句中引用它，<br>可以在Table API查询的结果上定义SQL查询。</li>
</ul>
<h2 id="Emit-a-Table"><a href="#Emit-a-Table" class="headerlink" title="Emit a Table"></a>Emit a Table</h2><p>通过将Table写入到TableSink来作为一张表的输出，TableSink是做为多种文件类型 (CSV, Apache Parquet, Apache Avro),<br>存储系统(JDBC, Apache HBase, Apache Cassandra, Elasticsearch), 或者是消息系统 (Apache Kafka, RabbitMQ).输出的通用接口，</p>
<p>Batch Table只能通过BatchTableSink来进行数据写入，而Streaming Table可以<br>选择AppendStreamTableSink，RetractStreamTableSink，UpsertStreamTableSink<br>中的任意一个来进行。</p>
<p>请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">Table Source &amp; Sinks</a><br>来更详细的了解支持的Sinks并且如何去实现自定义的TableSink。</p>
<p>可以使用两种方式来输出一张表：</p>
<ul>
<li>Table.writeToSink(TableSink sink)方法使用提供的TableSink自动配置的表的schema来<br>进行表的输出</li>
<li>Table.insertInto（String sinkTable）方法查找在TableEnvironment目录中提供的名称下使用特定模式注册的TableSink。<br>将输出表的模式将根据已注册的TableSink的模式进行验证</li>
</ul>
<p>下面的例子展示了如何去查询结果作为一张表输出</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用Table API或者SQL 查询来查找结果</span></span><br><span class="line"><span class="keyword">val</span> result: <span class="type">Table</span> = ...</span><br><span class="line"><span class="comment">// 创建TableSink对象</span></span><br><span class="line"><span class="keyword">val</span> sink: <span class="type">TableSink</span> = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">&quot;/path/to/file&quot;</span>, fieldDelim = <span class="string">&quot;|&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法1: 使用TableSink的writeToSink()方法来将结果输出为一张表</span></span><br><span class="line">result.writeToSink(sink)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法2: 注册特殊schema的TableSink</span></span><br><span class="line"><span class="keyword">val</span> fieldNames: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> fieldTypes: <span class="type">Array</span>[<span class="type">TypeInformation</span>] = <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">INT</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>)</span><br><span class="line">tableEnv.registerTableSink(<span class="string">&quot;CsvSinkTable&quot;</span>, fieldNames, fieldTypes, sink)</span><br><span class="line"><span class="comment">// 调用注册过的TableSink中insertInto() 方法来将结果输出为一张表</span></span><br><span class="line">result.insertInto(<span class="string">&quot;CsvSinkTable&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行</span></span><br></pre></td></tr></table></figure>
<h2 id="Translate-and-Execute-a-Query"><a href="#Translate-and-Execute-a-Query" class="headerlink" title="Translate and Execute a Query"></a>Translate and Execute a Query</h2><p>Table API和SQL查询的结果转换为<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/datastream_api.html">DataStream</a><br>或是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/">DataSet</a><br>取决于它的输入是流式输入还是批处理输入。查询逻辑在内部表示为逻辑执行计划，并分为两个阶段进行转换：</p>
<ul>
<li>优化逻辑执行计划</li>
<li>转换为DataStream或DataSet</li>
</ul>
<p>Table API或SQL查询在下面请看下进行转换：</p>
<ul>
<li>当调用Table.writeToSink() 或 Table.insertInto()进行查询结果表输出的时候</li>
<li>当调用TableEnvironment.sqlUpdate()进行SQL更新查询时</li>
<li>当表转换为DataSteam或DataSet时，详情查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-dataStream-and-dataSet-api">Integration with DataStream and DataSet API</a></li>
</ul>
<p>一旦进行转换后，Table API或SQL查询的结果就会在StreamExecutionEnvironment.execute() 或 ExecutionEnvironment.execute()<br>被调用时被当做DataStream或DataSet一样被进行处理</p>
<h2 id="Integration-with-DataStream-and-DataSet-API"><a href="#Integration-with-DataStream-and-DataSet-API" class="headerlink" title="Integration with DataStream and DataSet API"></a>Integration with DataStream and DataSet API</h2><p>Table API或SQL查询的结果很容易被<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/datastream_api.html">DataStream</a><br>或是<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/">DataSet</a>内嵌整合。举个例子，<br>我们会进行外部表的查询(像关系型数据库)，然后做像过滤，映射，聚合或者是元数据关联的一些预处理。<br>然后使用DataStream或是DataSet API(或者是基于这些基础库开发的上层API库, 例如CEP或Gelly)进一步对数据进行处理。<br>同样，Table API或SQL查询也可以应用于DataStream或DataSet程序的结果。</p>
<p>##implicit Conversion for Scala<br>Scala Table API具有DataSet，DataStream和Table Class之间的隐式转换，流式操作API中只要引入org.apache.flink.table.api.scala._<br>和 org.apache.flink.api.scala._ 便可以进行相应的隐式转换</p>
<h2 id="Register-a-DataStream-or-DataSet-as-Table"><a href="#Register-a-DataStream-or-DataSet-as-Table" class="headerlink" title="Register a DataStream or DataSet as Table"></a>Register a DataStream or DataSet as Table</h2><p>DataStream或DataSet也可以作为Table注册到TableEnvironment中。结果表的模式取决于已注册的DataStream或DataSet的数据类型，<br>详情请查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#mapping-of-data-types-to-table-schema">mapping of data types to table schema</a></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream作为具有&quot;f0&quot;, &quot;f1&quot;字段的&quot;myTable&quot;表注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerDataStream(<span class="string">&quot;myTable&quot;</span>, stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream作为具有&quot;myLong&quot;, &quot;myString&quot;字段的&quot;myTable2&quot;表注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerDataStream(<span class="string">&quot;myTable2&quot;</span>, stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br></pre></td></tr></table></figure>
<p>注意：DataStream表的名称必须与^ <em>DataStreamTable</em> [0-9] +模式不匹配，<br>并且DataSet表的名称必须与^ <em>DataSetTable</em> [0-9] +模式不匹配。<br>这些模式仅供内部使用。</p>
<h2 id="Convert-a-DataStream-or-DataSet-into-a-Table"><a href="#Convert-a-DataStream-or-DataSet-into-a-Table" class="headerlink" title="Convert a DataStream or DataSet into a Table"></a>Convert a DataStream or DataSet into a Table</h2><p>如果你使用Table API或是SQL查询，你可以直接将DataStream或DataSet直接转换为表而不需要<br>再将它们注册到TableEnvironment中。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1, &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table1: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;myLong, &#x27;myString将DataStram转换为Table</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> table2: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Convert-a-Table-into-a-DataStream-or-DataSet"><a href="#Convert-a-Table-into-a-DataStream-or-DataSet" class="headerlink" title="Convert a Table into a DataStream or DataSet"></a>Convert a Table into a DataStream or DataSet</h2><p>表可以转换为DataStream或DataSet，通过这种方式，自定义DataStream或DataSet<br>同样也可以作为Table API或SQL查询结果的结果。<br>当把表转换为DataStream或DataSet时，你需要指定生成的DataStream或DataSet的数据类型。<br>例如，表格行所需转换的数据类型，通常最方便的转换类型也最常用的是Row。<br>以下列表概述了不同选项的功能：</p>
<ul>
<li>Row：字段按位置，任意数量的字段映射，支持空值，无类型安全访问。</li>
<li>POJO：字段按名称(POJO字段必须与Table字段保持一致)，任意数量的字段映射，支持空值，类型安全访问。</li>
<li>Case Class：字段按位置，任意数量的字段映射，不支持空值，类型安全访问。</li>
<li>Tuple：字段按位置，Scala支持22个字段，Java 25个字段映射，不支持空值，类型安全访问。</li>
<li>Atomic Type：表必须具有单个字段，不支持空值，类型安全访问。<h3 id="Convert-a-Table-into-a-DataStream"><a href="#Convert-a-Table-into-a-DataStream" class="headerlink" title="Convert a Table into a DataStream"></a>Convert a Table into a DataStream</h3>作为流式查询结果的表将动态更新，它随着新记录到达查询的输入流而改变，于是，转换到这样的动态查询DataStream<br>需要对表的更新进行编码。<br>将表转换为DataStream有两种模式：</li>
<li>Append Mode：这种模式仅用于动态表仅仅通过INSERT来进行表的更新，它是仅可追加模式，<br>并且之前输出的表不会进行更改</li>
<li>Retract Mode：这种模式经常用到。它使用布尔值的变量来对INSERT和DELETE对表的更新做标记<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表中有两个字段(String name, Integet age)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为列的 append DataStream</span></span><br><span class="line"><span class="keyword">val</span> dsRow: <span class="type">DataStream</span>[<span class="type">Row</span>] = tableEnv.toAppendStream[<span class="type">Row</span>](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为Tubple2[String,Int]的 append DataStream</span></span><br><span class="line"><span class="comment">// convert the Table into an append DataStream of Tuple2[String, Int]</span></span><br><span class="line"><span class="keyword">val</span> dsTuple: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] dsTuple = </span><br><span class="line">  tableEnv.toAppendStream[(<span class="type">String</span>, <span class="type">Int</span>)](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert the Table into a retract DataStream of Row.</span></span><br><span class="line"><span class="comment">// Retract Mode下将表转换为列的 append DataStream</span></span><br><span class="line"><span class="comment">// 判断A retract stream X是否为DataStream[(Boolean, X)]</span></span><br><span class="line"><span class="comment">//  布尔只表示数据类型的变化,True代表为INSERT，false表示为删除</span></span><br><span class="line"><span class="keyword">val</span> retractStream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, <span class="type">Row</span>)] = tableEnv.toRetractStream[<span class="type">Row</span>](table)</span><br></pre></td></tr></table></figure>
注意：关于动态表和它的属性详情参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/streaming.html">Streaming Queries</a></li>
</ul>
<h3 id="Convert-a-Table-into-a-DataSet"><a href="#Convert-a-Table-into-a-DataSet" class="headerlink" title="Convert a Table into a DataSet"></a>Convert a Table into a DataSet</h3><p>表转换为DataSet如下所示：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表中有两个字段(String name, Integet age)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为列的DataSet</span></span><br><span class="line"><span class="keyword">val</span> dsRow: <span class="type">DataSet</span>[<span class="type">Row</span>] = tableEnv.toDataSet[<span class="type">Row</span>](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为Tubple2[String,Int]的DataSet</span></span><br><span class="line"><span class="keyword">val</span> dsTuple: <span class="type">DataSet</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = tableEnv.toDataSet[(<span class="type">String</span>, <span class="type">Int</span>)](table)</span><br></pre></td></tr></table></figure>
<h3 id="Mapping-of-Data-Types-to-Table-Schema"><a href="#Mapping-of-Data-Types-to-Table-Schema" class="headerlink" title="Mapping of Data Types to Table Schema"></a>Mapping of Data Types to Table Schema</h3><p>Flink的DataStream和DataSet API支持多种类型。组合类型像Tuple(内置Scala元组和Flink Java元组)，<br>POJOs，Scala case classes和Flink中具有可在表表达式中访问的多个字段允许嵌套数据结构的Row类型，<br>其他类型都被视为原子类型。接下来，我们将会描述Table API是如何将这些类型转换为内部的列展现并且<br>举例说明如何将DataStream转换为Table</p>
<h4 id="Position-based-Mapping"><a href="#Position-based-Mapping" class="headerlink" title="Position-based Mapping"></a>Position-based Mapping</h4><p>基于位置的映射通常在保持顺序的情况下给字段一个更有意义的名称，这种映射可用于有固定顺序的组合数据类型，<br>也可用于原子类型。复合数据类型（如元组，行和Case Class）具有此类字段顺序.然而，POJO的字段必须与映射的<br>表的字段名相同。</p>
<p>当定义基于位置的映射，输入的数据类型不得存在指定的名称，不然API会认为这些映射应该按名称来进行映射。<br>如果未指定字段名称，则使用复合类型的默认字段名称和字段顺序，或者使用f0作为原子类型。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1, &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table1: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;myLong, &#x27;myInt将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span> <span class="symbol">&#x27;myInt</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Name-based-Mapping"><a href="#Name-based-Mapping" class="headerlink" title="Name-based Mapping"></a>Name-based Mapping</h4><p>基于名称的映射可用于一切数据类型包括POJOs，它是定义表模式映射最灵活的一种方式。虽然查询结果的字段可能会使用别名，但<br>这种模式下所有的字段都是使用名称进行映射的。使用别名的情况下会进行重排序。<br>如果未指定字段名称，则使用复合类型的默认字段名称和字段顺序，或者使用f0作为原子类型。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1 和 &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只使用&#x27;_2字段将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换字段将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>, <span class="symbol">&#x27;_1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换后的字段给予别名&#x27;myInt, &#x27;myLong将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span> as <span class="symbol">&#x27;myInt</span>, <span class="symbol">&#x27;_1</span> as <span class="symbol">&#x27;myLong</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Atomic-Types"><a href="#Atomic-Types" class="headerlink" title="Atomic Types"></a>Atomic Types</h4><p>Flink将基础类型(Integer, Double, String)和通用类型(不能被分析和拆分的类型)视为原子类型。<br>原子类型的DataStream或DataSet转换为只有单个属性的表。从原子类型推断属性的类型，并且可以指定属性的名称。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Long</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为带默认字段&quot;f0&quot;的表</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为带字段&quot;myLong&quot;的表</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Tuples-Scala-and-Java-and-Case-Classes-Scala-only"><a href="#Tuples-Scala-and-Java-and-Case-Classes-Scala-only" class="headerlink" title="Tuples (Scala and Java) and Case Classes (Scala only)"></a>Tuples (Scala and Java) and Case Classes (Scala only)</h4><p>Flink支持内建的Tuples并且提供了自己的Tuple类给Java进行使用。DataStreams和DataSet这两种<br>Tuple都可以转换为表。提供所有字段的名称(基于位置的映射)字段可以被重命名。如果没有指定字段的名称，<br>就使用默认的字段名称。如果原始字段名(f0, f1, … for Flink Tuples and _1, _2, … for Scala Tuples)被引用了的话，<br>API就会使用基于名称的映射来代替位置的映射。基于名称的映射可以起别名并且会进行重排序。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将默认的字段重命名为&#x27;_1，&#x27;_2的DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字段名为&#x27;myLong，&#x27;myString的DataStream转换为Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将重排序后字段为&#x27;_2，&#x27;_1 的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>, <span class="symbol">&#x27;_1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将映射字段&#x27;_2的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将重排序后字段为&#x27;_2给出别名&#x27;myString，&#x27;_1给出别名&#x27;myLong 的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span> as <span class="symbol">&#x27;myString</span>, <span class="symbol">&#x27;_1</span> as <span class="symbol">&#x27;myLong</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义 case class</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">streamCC</span></span>: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将默认字段&#x27;name, &#x27;age的DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table = tableEnv.fromDataStream(streamCC)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字段名为&#x27;myName，&#x27;myAge的DataStream转换为Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table = tableEnv.fromDataStream(streamCC, <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line">将重排序后字段为<span class="symbol">&#x27;_age</span>给出别名<span class="symbol">&#x27;myAge</span>，<span class="symbol">&#x27;_name</span>给出别名<span class="symbol">&#x27;myName</span> 的<span class="type">DataStream</span>转换为<span class="type">Table</span>(基于名称)</span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="POJO-Java-and-Scala"><a href="#POJO-Java-and-Scala" class="headerlink" title="POJO (Java and Scala)"></a>POJO (Java and Scala)</h4><p>Flink支持POJO作为符合类型。决定POJO规则的文档请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/api_concepts.html#pojos">这里</a></p>
<p>当将一个POJO类型的DataStream或者DataSet转换为Table而不指定字段名称时，Table的字段名称将采用JOPO原生的字段名称作为字段名称。<br>重命名原始的POJO字段需要关键字AS，因为POJO没有固定的顺序，名称映射需要原始名称并且不能通过位置来完成。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Person 是一个有两个字段&quot;name&quot;和&quot;age&quot;的POJO</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为带字段 &quot;age&quot;, &quot;name&quot; 的Table(字段通过名称进行排序)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为重命名为&quot;myAge&quot;, &quot;myName&quot;的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将带映射字段&#x27;name的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将带映射字段&#x27;name并重命名为&#x27;myName的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Row"><a href="#Row" class="headerlink" title="Row"></a>Row</h4><p>Row数据类型可以支持任意数量的字段，并且这些字段支持null值。当进行Row DataStream或Row DataSet<br>转换为Table时可以通过RowTypeInfo来指定字段的名称。Row Type支持基于位置和名称的两种映射方式。<br>通过提供所有字段的名称可以进行字段的重命名(基于位置)，或者是单独选择列来进行映射/重排序/重命名(基于名称)</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在`RowTypeInfo`中指定字段&quot;name&quot; 和 &quot;age&quot;的Row类型DataStream</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Row</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为带默认字段 &quot;age&quot;, &quot;name&quot; 的Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为重命名字段 &#x27;myName, &#x27;myAge 的Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为重命名字段 &#x27;myName, &#x27;myAge 的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为映射字段 &#x27;name的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为映射字段 &#x27;name并重命名为&#x27;myName的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Query-Optimization"><a href="#Query-Optimization" class="headerlink" title="Query Optimization"></a>Query Optimization</h4><p>Apache Flink 基于 Apache Calcite 来做转换和查询优化。当前的查询优化包括投影、过滤下推、<br>相关子查询和各种相关的查询重写。Flink不去做join优化，但是会让他们去顺序执行(FROM子句中表的顺序或者WHERE子句中连接谓词的顺序)</p>
<p>可以通过提供一个CalciteConfig对象来调整在不同阶段应用的优化规则集，<br>这个可以通过调用CalciteConfig.createBuilder())获得的builder来创建，<br>并且可以通过调用tableEnv.getConfig.setCalciteConfig(calciteConfig)来提供给TableEnvironment。</p>
<h4 id="Explaining-a-Table"><a href="#Explaining-a-Table" class="headerlink" title="Explaining a Table"></a>Explaining a Table</h4><p>Table API为计算Table提供了一个机制来解析逻辑和优化查询计划，这个可以通过TableEnvironment.explain(table)<br>来完成。它返回描述三个计划的字符串信息：</p>
<ul>
<li>关联查询抽象语法树，即未优化过的逻辑执行计划</li>
<li>优化过的逻辑执行计划</li>
<li>物理执行计划</li>
</ul>
<p>下面的实例展示了相应的输出：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> tEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> table1 = env.fromElements((<span class="number">1</span>, <span class="string">&quot;hello&quot;</span>)).toTable(tEnv, <span class="symbol">&#x27;count</span>, <span class="symbol">&#x27;word</span>)</span><br><span class="line"><span class="keyword">val</span> table2 = env.fromElements((<span class="number">1</span>, <span class="string">&quot;hello&quot;</span>)).toTable(tEnv, <span class="symbol">&#x27;count</span>, <span class="symbol">&#x27;word</span>)</span><br><span class="line"><span class="keyword">val</span> table = table1</span><br><span class="line">  .where(<span class="symbol">&#x27;word</span>.like(<span class="string">&quot;F%&quot;</span>))</span><br><span class="line">  .unionAll(table2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> explanation: <span class="type">String</span> = tEnv.explain(table)</span><br><span class="line">println(explanation)</span><br></pre></td></tr></table></figure>
<p>对应的输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x3D;&#x3D; 抽象语法树 &#x3D;&#x3D;</span><br><span class="line">LogicalUnion(all&#x3D;[true])</span><br><span class="line">  LogicalFilter(condition&#x3D;[LIKE($1, &#39;F%&#39;)])</span><br><span class="line">    LogicalTableScan(table&#x3D;[[_DataStreamTable_0]])</span><br><span class="line">  LogicalTableScan(table&#x3D;[[_DataStreamTable_1]])</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D; 优化后的逻辑执行计划 &#x3D;&#x3D;</span><br><span class="line">DataStreamUnion(union&#x3D;[count, word])</span><br><span class="line">  DataStreamCalc(select&#x3D;[count, word], where&#x3D;[LIKE(word, &#39;F%&#39;)])</span><br><span class="line">    DataStreamScan(table&#x3D;[[_DataStreamTable_0]])</span><br><span class="line">  DataStreamScan(table&#x3D;[[_DataStreamTable_1]])</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D; 物理执行计划 &#x3D;&#x3D;</span><br><span class="line">Stage 1 : Data Source</span><br><span class="line">  content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">Stage 2 : Data Source</span><br><span class="line">  content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">  Stage 3 : Operator</span><br><span class="line">    content : from: (count, word)</span><br><span class="line">    ship_strategy : REBALANCE</span><br><span class="line"></span><br><span class="line">    Stage 4 : Operator</span><br><span class="line">      content : where: (LIKE(word, &#39;F%&#39;)), select: (count, word)</span><br><span class="line">      ship_strategy : FORWARD</span><br><span class="line"></span><br><span class="line">      Stage 5 : Operator</span><br><span class="line">        content : from: (count, word)</span><br><span class="line">        ship_strategy : REBALANCE</span><br></pre></td></tr></table></figure>

<h1 id="Flink用户自定义函数"><a href="#Flink用户自定义函数" class="headerlink" title="Flink用户自定义函数"></a>Flink用户自定义函数</h1><p>用户自定义函数是非常重要的一个特征，因为他极大地扩展了查询的表达能力。</p>
<p>在大多数场景下，用户自定义函数在使用之前是必须要注册的。对于Scala的Table API，udf是不需要注册的。<br>调用TableEnvironment的registerFunction()方法来实现注册。Udf注册成功之后，会被插入TableEnvironment的function catalog，这样table API和sql就能解析他了。<br>本文会主要讲三种udf：</p>
<ul>
<li>ScalarFunction</li>
<li>TableFunction</li>
<li>AggregateFunction</li>
</ul>
<h2 id="1-Scalar-Functions-标量函数"><a href="#1-Scalar-Functions-标量函数" class="headerlink" title="1. Scalar Functions 标量函数"></a>1. Scalar Functions 标量函数</h2><p>标量函数，是指指返回一个值的函数。标量函数是实现讲0，1，或者多个标量值转化为一个新值。</p>
<p>实现一个标量函数需要继承ScalarFunction，并且实现一个或者多个evaluation方法。标量函数的行为就是通过evaluation方法来实现的。evaluation方法必须定义为public，命名为eval。evaluation方法的输入参数类型和返回值类型决定着标量函数的输入参数类型和返回值类型。evaluation方法也可以被重载实现多个eval。同时evaluation方法支持变参数，例如：eval(String… strs)。</p>
<p>下面给出一个标量函数的例子。例子实现的事一个hashcode方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">12</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">HashCode</span><span class="params">(<span class="keyword">int</span> factor)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.factor = factor;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the function</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> HashCode(<span class="number">10</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in Java Table API</span></span><br><span class="line">myTable.select(<span class="string">&quot;string, string.hashCode(), hashCode(string)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in SQL API</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;</span>);</span><br><span class="line"></span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">默认情况下evaluation方法的返回值类型是由flink类型抽取工具决定。对于基础类型，简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载</span><br><span class="line">ScalarFunction#getResultType()。</span><br><span class="line"></span><br><span class="line">下面给一个例子，通过复写ScalarFunction#getResultType()，将long型的返回值在代码生成的时候翻译成Types.TIMESTAMP。</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TimestampModifier</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">eval</span><span class="params">(<span class="keyword">long</span> t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> t % <span class="number">1000</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> TypeInformation&lt;?&gt; getResultType(signature: Class&lt;?&gt;[]) &#123;</span><br><span class="line">    <span class="keyword">return</span> Types.TIMESTAMP;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-Table-Functions-表函数"><a href="#2-Table-Functions-表函数" class="headerlink" title="2. Table Functions 表函数"></a>2. Table Functions 表函数</h2><p>与标量函数相似之处是输入可以0，1，或者多个参数，但是不同之处可以输出任意数目的行数。返回的行也可以包含一个或者多个列。</p>
<p>为了自定义表函数，需要继承TableFunction，实现一个或者多个evaluation方法。表函数的行为定义在这些evaluation方法内部，函数名为eval并且必须是public。TableFunction可以重载多个eval方法。Evaluation方法的输入参数类型，决定着表函数的输入类型。Evaluation方法也支持变参，例如：eval(String… strs)。返回表的类型取决于TableFunction的基本类型。Evaluation方法使用collect(T)发射输出的rows。</p>
<p>在Table API中，表函数在scala语言中使用方法如下：.join(Expression) 或者 .leftOuterJoin(Expression)，在java语言中使用方法如下：.join(String) 或者.leftOuterJoin(String)。</p>
<p>Join操作算子会使用表值函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行。</p>
<p>leftOuterJoin操作算子会使用表值函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行，并且在表函数返回一个空表的情况下会保留所有的outer rows。</p>
<p>在sql语法中稍微有点区别：<br>cross join用法是LATERAL TABLE(<TableFunction>)。<br>LEFT JOIN用法是在join条件中加入ON TRUE。</p>
<p>下面的理智讲的是如何使用表值函数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// The generic type &quot;Tuple2&lt;String, Integer&gt;&quot; determines the schema of the returned table as (String, Integer).</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Split</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String separator = <span class="string">&quot; &quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Split</span><span class="params">(String separator)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.separator = separator;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String s : str.split(separator)) &#123;</span><br><span class="line">            <span class="comment">// use collect(...) to emit a row</span></span><br><span class="line">            collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(s, s.length()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line">Table myTable = ...         <span class="comment">// table schema: [a: String]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Register the function.</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;split&quot;</span>, <span class="keyword">new</span> Split(<span class="string">&quot;#&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use the table function in the Java Table API. &quot;as&quot; specifies the field names of the table.</span></span><br><span class="line">myTable.join(<span class="string">&quot;split(a) as (word, length)&quot;</span>).select(<span class="string">&quot;a, word, length&quot;</span>);</span><br><span class="line">myTable.leftOuterJoin(<span class="string">&quot;split(a) as (word, length)&quot;</span>).select(<span class="string">&quot;a, word, length&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use the table function in SQL with LATERAL and TABLE keywords.</span></span><br><span class="line">join.md</span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT a, word, length FROM MyTable, LATERAL TABLE(split(a)) as T(word, length)&quot;</span>);</span><br><span class="line"><span class="comment">// LEFT JOIN a table function (equivalent to &quot;leftOuterJoin&quot; in Table API).</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT a, word, length FROM MyTable LEFT JOIN LATERAL TABLE(split(a)) as T(word, length) ON TRUE&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>需要注意的是PROJO类型不需要一个确定的字段顺序。意味着你不能使用as修改表函数返回的pojo的字段的名字。</p>
<p>默认情况下TableFunction返回值类型是由flink类型抽取工具决定。对于基础类型，简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载<br>TableFunction#getResultType()。</p>
<p>下面的例子，我们通过复写TableFunction#getResultType()方法使得表返回类型是RowTypeInfo(String, Integer)。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomTypeSplit</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Row</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String s : str.split(<span class="string">&quot; &quot;</span>)) &#123;</span><br><span class="line">            Row row = <span class="keyword">new</span> Row(<span class="number">2</span>);</span><br><span class="line">            row.setField(<span class="number">0</span>, s);</span><br><span class="line">            row.setField(<span class="number">1</span>, s.length);</span><br><span class="line">            collect(row);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TypeInformation&lt;Row&gt; <span class="title">getResultType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Types.ROW(Types.STRING(), Types.INT());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-Aggregation-Functions-聚合函数"><a href="#3-Aggregation-Functions-聚合函数" class="headerlink" title="3. Aggregation Functions 聚合函数"></a>3. Aggregation Functions 聚合函数</h2><p>用户自定义聚合函数聚合一张表(一行或者多行，一行有一个或者多个属性)为一个标量的值。</p>
<p>上图中是讲的一张饮料的表这个表有是那个字段五行数据，现在要做的事求出所有饮料的最高价。</p>
<p>聚合函数需要继承AggregateFunction。聚合函数工作方式如下：<br>首先，需要一个accumulator，这个是保存聚合中间结果的数据结构。调用AggregateFunction函数的createAccumulator()方法来创建一个空的accumulator.<br>随后，每个输入行都会调用accumulate()方法来更新accumulator。一旦所有的行被处理了，getValue()方法就会被调用，计算和返回最终的结果。</p>
<p>对于每个AggregateFunction，下面三个方法都是比不可少的：<br>createAccumulator()<br>accumulate()<br>getValue()</p>
<p>flink的类型抽取机制不能识别复杂的数据类型，比如，数据类型不是基础类型或者简单的pojos类型。所以，类似于ScalarFunction 和TableFunction，AggregateFunction提供了方法去指定返回结果类型的TypeInformation，用的是AggregateFunction#getResultType()。Accumulator类型用的是AggregateFunction#getAccumulatorType()。</p>
<p>除了上面的方法，这里有一些可选的方法。尽管有些方法是让系统更加高效的执行查询，另外的一些在特定的场景下是必须的。例如，merge()方法在会话组窗口上下文中是必须的。当一行数据是被视为跟两个回话窗口相关的时候，两个会话窗口的accumulators需要被join。</p>
<p>AggregateFunction的下面几个方法，根据使用场景的不同需要被实现：<br>retract()：在bounded OVER窗口的聚合方法中是需要实现的。<br>merge()：在很多batch 聚合和会话窗口聚合是必须的。<br>resetAccumulator(): 在大多数batch聚合是必须的。</p>
<p>AggregateFunction的所有方法都是需要被声明为public，而不是static。定义聚合函数需要实现org.apache.flink.table.functions.AggregateFunction同时需要实现一个或者多个accumulate方法。该方法可以被重载为不同的数据类型，并且支持变参。</p>
<p>在这里就不贴出来AggregateFunction的源码了。</p>
<p>下面举个求加权平均的栗子<br>为了计算加权平均值，累加器需要存储已累积的所有数据的加权和及计数。在栗子中定义一个WeightedAvgAccum类作为accumulator。尽管，retract(), merge(), 和resetAccumulator()方法在很多聚合类型是不需要的，这里也给出了栗子。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Accumulator for WeightedAvg.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvgAccum</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Weighted Average user-defined aggregate function.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvg</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>&lt;<span class="title">Long</span>, <span class="title">WeightedAvgAccum</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> WeightedAvgAccum <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> WeightedAvgAccum();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Long <span class="title">getValue</span><span class="params">(WeightedAvgAccum acc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (acc.count == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> acc.sum / acc.count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accumulate</span><span class="params">(WeightedAvgAccum acc, <span class="keyword">long</span> iValue, <span class="keyword">int</span> iWeight)</span> </span>&#123;</span><br><span class="line">        acc.sum += iValue * iWeight;</span><br><span class="line">        acc.count += iWeight;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">retract</span><span class="params">(WeightedAvgAccum acc, <span class="keyword">long</span> iValue, <span class="keyword">int</span> iWeight)</span> </span>&#123;</span><br><span class="line">        acc.sum -= iValue * iWeight;</span><br><span class="line">        acc.count -= iWeight;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(WeightedAvgAccum acc, Iterable&lt;WeightedAvgAccum&gt; it)</span> </span>&#123;</span><br><span class="line">        Iterator&lt;WeightedAvgAccum&gt; iter = it.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            WeightedAvgAccum a = iter.next();</span><br><span class="line">            acc.count += a.count;</span><br><span class="line">            acc.sum += a.sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resetAccumulator</span><span class="params">(WeightedAvgAccum acc)</span> </span>&#123;</span><br><span class="line">        acc.count = <span class="number">0</span>;</span><br><span class="line">        acc.sum = <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// register function</span></span><br><span class="line">StreamTableEnvironment tEnv = ...</span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;wAvg&quot;</span>, <span class="keyword">new</span> WeightedAvg());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use function</span></span><br><span class="line">tEnv.sqlQuery(<span class="string">&quot;SELECT user, wAvg(points, level) AS avgPoints FROM userScores GROUP BY user&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="4-实现udf的最佳实践经验"><a href="#4-实现udf的最佳实践经验" class="headerlink" title="4. 实现udf的最佳实践经验"></a>4. 实现udf的最佳实践经验</h2><p>Table API和SQL 代码生成器内部会尽可能多的尝试使用原生值。用户定义的函数可能通过对象创建、强制转换(casting)和拆装箱((un)boxing)引入大量开销。因此，强烈推荐参数和返回值的类型定义为原生类型而不是他们包装类型(boxing class)。Types.DATE 和Types.TIME可以用int代替。Types.TIMESTAMP可以用long代替。</p>
<p>我们建议用户自定义函数使用java编写而不是scala编写，因为scala的类型可能会有不被flink类型抽取器兼容。</p>
<p>用Runtime集成UDFs</p>
<p>有时候udf需要获取全局runtime信息或者在进行实际工作之前做一些设置和清除工作。Udf提供了open()和close()方法，可以被复写，功能类似Dataset和DataStream API的RichFunction方法。</p>
<p>Open()方法是在evaluation方法调用前调用一次。Close()是在evaluation方法最后一次调用后调用。</p>
<p>Open()方法提共一个FunctionContext，FunctionContext包含了udf执行环境的上下文，比如，metric group，分布式缓存文件，全局的job参数。</p>
<p>通过调用FunctionContext的相关方法，可以获取到相关的信息：</p>
<p>方法描述</p>
<ul>
<li>getMetricGroup() - 并行子任务的指标组</li>
<li>getCachedFile(name) -分布式缓存文件的本地副本</li>
<li>getJobParameter(name, defaultValue) - 给定key全局job参数。</li>
</ul>
<p>下面，给出的例子就是通过FunctionContext在一个标量函数中获取全局job的参数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(FunctionContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// access &quot;hashcode_factor&quot; parameter</span></span><br><span class="line">        <span class="comment">// &quot;12&quot; would be the default value if parameter does not exist</span></span><br><span class="line">        factor = Integer.valueOf(context.getJobParameter(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;12&quot;</span>)); </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// set job parameter</span></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.setString(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;31&quot;</span>);</span><br><span class="line">env.getConfig().setGlobalJobParameters(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the function</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> HashCode());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in Java Table API</span></span><br><span class="line">myTable.select(<span class="string">&quot;string, string.hashCode(), hashCode(string)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in SQL</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;</span>);</span><br></pre></td></tr></table></figure>
<h1 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h1><h2 id="scala"><a href="#scala" class="headerlink" title="scala"></a>scala</h2><h3 id="三元运算符"><a href="#三元运算符" class="headerlink" title="三元运算符"></a>三元运算符</h3><p>sql或者table API筛选数据，必须保证每个字段不为空，<br>Flink内部，中间结果都是通过case class传递，而case class的字段必须保证不能为空</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">BOOLEAN</span>.?(<span class="type">VALUE1</span>, <span class="type">VALUE2</span>)</span><br><span class="line"><span class="symbol">&#x27;is_active_user</span>.isNull.?(<span class="string">&quot;0&quot;</span>, <span class="string">&quot;1&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="等值判断"><a href="#等值判断" class="headerlink" title="等值判断"></a>等值判断</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="symbol">&#x27;Fuin</span> === <span class="symbol">&#x27;active_user</span></span><br></pre></td></tr></table></figure>
<p>scala中的<code>===</code>是运算符重构</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>Uber-AthenaX</title>
    <url>/bigdata/Flink/Uber-AthenaX/</url>
    <content><![CDATA[<h1 id="Uber-AthenaX"><a href="#Uber-AthenaX" class="headerlink" title="Uber-AthenaX"></a>Uber-AthenaX</h1>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>【转载】flink cep官方文档</title>
    <url>/bigdata/Flink/flink-cep-office/</url>
    <content><![CDATA[<p><a href="https://github.com/crestofwave1/oneFlink/blob/master/doc/CEP/FlinkCEPOfficeWeb.md">转载自 https://github.com/crestofwave1/oneFlink/blob/master/doc/CEP/FlinkCEPOfficeWeb.md</a></p>
<h2 id="0-本文概述简介"><a href="#0-本文概述简介" class="headerlink" title="0. 本文概述简介"></a>0. 本文概述简介</h2><p>FlinkCEP是在Flink之上实现的复杂事件处理（CEP）库。 它允许你在无界的事件流中检测事件模式，让你有机会掌握数据中重要的事项。</p>
<p>本文描述了Flink CEP中可用的API调用。 首先介绍Pattern API，它允许你指定要在流中检测的模式，然后介绍如何检测匹配事件序列并对其进行操作。 然后，我们将介绍CEP库在处理事件时间延迟时所做的假设。</p>
<h2 id="1-入门"><a href="#1-入门" class="headerlink" title="1.入门"></a>1.入门</h2><p>首先是要在你的pom.xml文件中，引入CEP库。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-cep_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>注意要应用模式匹配的DataStream中的事件必须实现正确的equals（）和hashCode（）方法，因为FlinkCEP使用它们来比较和匹配事件。</p>
<p>第一个demo如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(</span><br><span class="line">        <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> event.getId() == <span class="number">42</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ).next(<span class="string">&quot;middle&quot;</span>).subtype(SubEvent.class).where(</span><br><span class="line">        <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent subEvent)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> subEvent.getVolume() &gt;= <span class="number">10.0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ).followedBy(<span class="string">&quot;end&quot;</span>).where(</span><br><span class="line">         <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> event.getName().equals(<span class="string">&quot;end&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(input, pattern);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Alert&gt; result = patternStream.select(</span><br><span class="line">    <span class="keyword">new</span> PatternSelectFunction&lt;Event, Alert&gt; &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Alert <span class="title">select</span><span class="params">(Map&lt;String, List&lt;Event&gt;&gt; pattern)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> createAlertFrom(pattern);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="2-Pattern-API"><a href="#2-Pattern-API" class="headerlink" title="2.Pattern API"></a>2.Pattern API</h2><p>Pattern API允许你定义要从输入流中提取的复杂模式序列。</p>
<p>每个复杂模式序列都是由多个简单模式组成，即寻找具有相同属性的单个事件的模式。我们可以先定义一些简单的模式，然后组合成复杂的模式序列。 可以将模式序列视为此类模式的结构图，基于用户指定的条件从一个模式转换到下一个模式，例如， event.getName().equals(“start”)。 匹配是一系列输入事件，通过一系列有效的模式转换访问复杂模式图中的所有模式。</p>
<p>注意每个模式必须具有唯一的名称，以便后续可以使用该名称来标识匹配的事件。</p>
<p>注意模式名称不能包含字符“：”。</p>
<p>在本节接下来的部分，我们将首先介绍如何定义单个模式，然后如何将各个模式组合到复杂模式中。</p>
<h3 id="2-1-单个模式"><a href="#2-1-单个模式" class="headerlink" title="2.1 单个模式"></a>2.1 单个模式</h3><p>Pattern可以是单单个，也可以是循环模式。单个模式接受单个事件，而循环模式可以接受多个事件。在模式匹配符号中，模式“a b + c？d”（或“a”，后跟一个或多个“b”，可选地后跟“c”，后跟“d”），a，c ？，和d是单例模式，而b +是循环模式。 默认情况下，模式是单个模式，您可以使用Quantifiers将其转换为循环模式。每个模式可以有一个或多个条件，基于它接受事件。</p>
<h4 id="2-1-1-Quantifiers"><a href="#2-1-1-Quantifiers" class="headerlink" title="2.1.1 Quantifiers"></a>2.1.1 Quantifiers</h4><p>在FlinkCEP中，您可以使用以下方法指定循环模式：pattern.oneOrMore（），用于期望一个或多个事件发生的模式（例如之前提到的b +）;和pattern.times（#ofTimes）， 用于期望给定类型事件的特定出现次数的模式，例如4个;和patterntimes（#fromTimes，＃toTimes），用于期望给定类型事件的最小出现次数和最大出现次数的模式，例如， 2-4。</p>
<p>您可以使用pattern.greedy（）方法使循环模式变得贪婪，但是还不能使组模式变得贪婪。您可以使用pattern.optional（）方法使得所有模式，循环与否，变为可选。</p>
<p>对于名为start的模式，以下是有效的Quantifiers：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// expecting 4 occurrences</span></span><br><span class="line">start.times(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">4</span>).optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2, 3 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2, 3 or 4 occurrences and repeating as many as possible</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2, 3 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2, 3 or 4 occurrences and repeating as many as possible</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).optional().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 1 or more occurrences</span></span><br><span class="line">start.oneOrMore();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 1 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.oneOrMore().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or more occurrences</span></span><br><span class="line">start.oneOrMore().optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.oneOrMore().optional().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2 or more occurrences</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>).greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>).optional().greedy();</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="2-1-2-Conditions-条件"><a href="#2-1-2-Conditions-条件" class="headerlink" title="2.1.2 Conditions-条件"></a>2.1.2 Conditions-条件</h4><p>在每个模式中，从一个模式转到下一个模式，可以指定其他条件。您可以将使用下面这些条件：</p>
<ol>
<li>传入事件的属性，例如其值应大于5，或大于先前接受的事件的平均值。</li>
<li>匹配事件的连续性，例如检测模式a，b，c，序列中间不能有任何非匹配事件。</li>
</ol>
<h4 id="2-1-3-Conditions-on-Properties-关于属性的条件"><a href="#2-1-3-Conditions-on-Properties-关于属性的条件" class="headerlink" title="2.1.3 Conditions on Properties-关于属性的条件"></a>2.1.3 Conditions on Properties-关于属性的条件</h4><p>可以通过pattern.where（），pattern.or（）或pattern.until（）方法指定事件属性的条件。 条件可以是IterativeConditions或SimpleConditions。</p>
<ol>
<li>迭代条件：</li>
</ol>
<p>这是最常见的条件类型。 你可以指定一个条件，该条件基于先前接受的事件的属性或其子集的统计信息来接受后续事件。</p>
<p>下面代码说的是：如果名称以“foo”开头同时如果该模式的先前接受的事件的价格总和加上当前事件的价格不超过该值 5.0，则迭代条件接受名为“middle”的模式的下一个事件，。 迭代条件可以很强大的，尤其是与循环模式相结合，例如， oneOrMore()。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">middle.oneOrMore().where(<span class="keyword">new</span> IterativeCondition&lt;SubEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent value, Context&lt;SubEvent&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!value.getName().startsWith(<span class="string">&quot;foo&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">double</span> sum = value.getPrice();</span><br><span class="line">        <span class="keyword">for</span> (Event event : ctx.getEventsForPattern(<span class="string">&quot;middle&quot;</span>)) &#123;</span><br><span class="line">            sum += event.getPrice();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Double.compare(sum, <span class="number">5.0</span>) &lt; <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>注意对context.getEventsForPattern（…）的调用,将为给定潜在匹配项查找所有先前接受的事件。 此操作的代价可能会变化巨大，因此在使用条件时，请尽量减少其使用。</p>
<ol>
<li>简单条件：</li>
</ol>
<p>这种类型的条件扩展了前面提到的IterativeCondition类，并且仅根据事件本身的属性决定是否接受事件。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">start.where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value.getName().startsWith(<span class="string">&quot;foo&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>最后，还可以通过pattern.subtype（subClass）方法将接受事件的类型限制为初始事件类型的子类型。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">start.subtype(SubEvent.class).where(<span class="keyword">new</span> SimpleCondition&lt;SubEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<ol>
<li>组合条件：</li>
</ol>
<p>如上所示，可以将子类型条件与其他条件组合使用。 这适用于所有条件。 您可以通过顺序调用where（）来任意组合条件。 最终结果将是各个条件的结果的逻辑AND。 要使用OR组合条件，可以使用or（）方法，如下所示。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;).or(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// or condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<ol>
<li>停止条件：</li>
</ol>
<p>在循环模式（oneOrMore()和oneOrMore().optional()）的情况下，还可以指定停止条件，例如： 接受值大于5的事件，直到值的总和小于50。</p>
<p>为了更好的理解，可以看看下面的例子：</p>
<p>给定模式：(a+ until b)，b之前，要出现一个或者多个a。</p>
<p>给定输入序列：a1，c，a2，b，a3</p>
<p>输出结果: {a1 a2}{a1}{a2}{a3}</p>
<p>可以看到{a1,a2,a3},{a2,a3}这两个并没有输出，这就是停止条件的作用。</p>
<ol>
<li>连续事件条件</li>
</ol>
<p>FlinkCEP支持事件之间以下形式进行连续：</p>
<ul>
<li>严格连续性：希望所有匹配事件一个接一个地出现，中间没有任何不匹配的事件。</li>
<li>宽松连续性：忽略匹配的事件之间出现的不匹配事件。 不能忽略两个事件之间的匹配事件。</li>
<li>非确定性轻松连续性：进一步放宽连续性，允许忽略某些匹配事件的其他匹配。</li>
</ul>
<p>为了解释上面的内容，我们举个例子。假如有个模式序列”a+ b”，输入序列”a1,c,a2,b”，不同连续条件下有不同的区别：</p>
<ol>
<li>严格连续性：{a2 b} - 由于c的存在导致a1被废弃</li>
<li>宽松连续性：{a1,b}和{a1 a2 b} - c被忽略</li>
<li>非确定性宽松连续性：{a1 b}, {a2 b}, 和 {a1 a2 b}</li>
</ol>
<p>对于循环模式（例如oneOrMore()和times()），默认是宽松的连续性。 如果你想要严格的连续性，你必须使用consecutive()显式指定它， 如果你想要非确定性的松弛连续性，你可以使用allowCombinations()方法。</p>
<p>注意在本节中，我们讨论的是单个循环模式中的连续性，并且需要在该上下文中理解consecutive()和allowCombinations()。 稍后在讲解组合模式时，我们将讨论其他方法，例如next（）和followedBy（），用于指定模式之间的连续条件。</p>
<h4 id="2-1-4-API简介"><a href="#2-1-4-API简介" class="headerlink" title="2.1.4 API简介"></a>2.1.4 API简介</h4><h5 id="1-where-condition"><a href="#1-where-condition" class="headerlink" title="1. where(condition)"></a>1. where(condition)</h5><p>定义当前模式的条件。 为了匹配模式，事件必须满足条件。 多个连续的where()，其条件为AND：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.where(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="2-or-condition"><a href="#2-or-condition" class="headerlink" title="2. or(condition)"></a>2. or(condition)</h5><p>添加与现有条件进行OR运算的新条件。 只有在至少通过其中一个条件时，事件才能匹配该模式：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.where(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;).or(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// alternative condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="3-until-condition"><a href="#3-until-condition" class="headerlink" title="3. until(condition)"></a>3. until(condition)</h5><p>指定循环模式的停止条件。 意味着如果匹配给定条件的事件发生，则不再接受该模式中的事件。</p>
<p>仅适用于oneOrMore（）</p>
<p>注意：它允许在基于事件的条件下清除相应模式的状态。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.oneOrMore().until(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// alternative condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="4-subtype-subClass"><a href="#4-subtype-subClass" class="headerlink" title="4. subtype(subClass)"></a>4. subtype(subClass)</h5><p>定义当前模式的子类型条件。 如果事件属于此子类型，则事件只能匹配该模式：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.subtype(SubEvent.class);</span><br></pre></td></tr></table></figure>
<h5 id="5-oneOrMore"><a href="#5-oneOrMore" class="headerlink" title="5. oneOrMore()"></a>5. oneOrMore()</h5><p>指定此模式至少发生一次匹配事件。</p>
<p>默认情况下，使用宽松的内部连续性。</p>
<p>注意：建议使用until（）或within（）来启用状态清除</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.oneOrMore().until(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// alternative condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="6-timesOrMore-times"><a href="#6-timesOrMore-times" class="headerlink" title="6. timesOrMore(#times)"></a>6. timesOrMore(#times)</h5><p>指定此模式至少需要#times次出现匹配事件。</p>
<p>默认情况下，使用宽松的内部连续性（在后续事件之间）。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.timesOrMore(<span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<h5 id="7-times-ofTimes"><a href="#7-times-ofTimes" class="headerlink" title="7. times(#ofTimes)"></a>7. times(#ofTimes)</h5><p>指定此模式需要匹配事件的确切出现次数。</p>
<p>默认情况下，使用宽松的内部连续性（在后续事件之间）。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.times(<span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<h5 id="8-times-fromTimes-toTimes"><a href="#8-times-fromTimes-toTimes" class="headerlink" title="8. times(#fromTimes, #toTimes)"></a>8. times(#fromTimes, #toTimes)</h5><p>指定此模式期望在匹配事件的#fromTimes次和#toTimes次之间出现。</p>
<p>默认情况下，使用宽松的内部连续性。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.times(<span class="number">2</span>, <span class="number">4</span>);</span><br></pre></td></tr></table></figure>
<h5 id="9-optional"><a href="#9-optional" class="headerlink" title="9. optional()"></a>9. optional()</h5><p>指定此模式是可选的，即有可能根本不会发生。 这适用于所有上述量词。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.oneOrMore().optional();</span><br></pre></td></tr></table></figure>
<h5 id="10-greedy"><a href="#10-greedy" class="headerlink" title="10. greedy()"></a>10. greedy()</h5><p>指定此模式是贪婪的，即它将尽可能多地重复。 这仅适用于quantifiers，目前不支持组模式。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.oneOrMore().greedy();</span><br></pre></td></tr></table></figure>
<h5 id="11-consecutive"><a href="#11-consecutive" class="headerlink" title="11. consecutive()"></a>11. consecutive()</h5><p>与oneOrMore（）和times（）一起使用并在匹配事件之间强加严格的连续性，即任何不匹配的元素都会中断匹配。</p>
<p>如果不使用，则使用宽松的连续性（如followBy（））。</p>
<p>例如，这样的模式：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;c&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.followedBy(<span class="string">&quot;middle&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;).oneOrMore().consecutive()</span><br><span class="line">.followedBy(<span class="string">&quot;end1&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>针对上面的模式，我们假如输入序列如：C D A1 A2 A3 D A4 B</p>
<p>使用consecutive：{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}</p>
<p>不使用:{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}, {C A1 A2 A3 A4 B}</p>
<h5 id="12-allowCombinations"><a href="#12-allowCombinations" class="headerlink" title="12. allowCombinations()"></a>12. allowCombinations()</h5><p>与oneOrMore（）和times（）一起使用，并在匹配事件之间强加非确定性宽松连续性（如 followedByAny()）。</p>
<p>如果不应用，则使用宽松的连续性（如followBy()）。</p>
<p>例如,这样的模式：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;c&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.followedBy(<span class="string">&quot;middle&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;).oneOrMore().allowCombinations()</span><br><span class="line">.followedBy(<span class="string">&quot;end1&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>针对上面的模式，我们假如输入序列如：C D A1 A2 A3 D A4 B</p>
<p>使用allowCombinations：{C A1 B}, {C A1 A2 B}, {C A1 A3 B}, {C A1 A4 B}, {C A1 A2 A3 B}, {C A1 A2 A4 B}, {C A1 A3 A4 B}, {C A1 A2 A3 A4 B}</p>
<p>不使用:{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}, {C A1 A2 A3 A4 B}</p>
<h3 id="2-2-组合模式"><a href="#2-2-组合模式" class="headerlink" title="2.2 组合模式"></a>2.2 组合模式</h3><h4 id="2-2-1-简介"><a href="#2-2-1-简介" class="headerlink" title="2.2.1 简介"></a>2.2.1 简介</h4><p>已经了解了单个模式的样子，现在是时候看看如何将它们组合成一个完整的模式序列。</p>
<p>模式序列必须以初始模式开始，如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>接下来，您可以通过指定它们之间所需的连续条件，为模式序列添加更多模式。 在上一节中，我们描述了Flink支持的不同邻接模式，即严格，宽松和非确定性宽松，以及如何在循环模式中应用它们。 要在连续模式之间应用它们，可以使用：</p>
<blockquote>
<p>next() 对应 严格, followedBy() 对应 宽松连续性 followedByAny() 对应 非确定性宽松连续性</p>
</blockquote>
<p>亦或</p>
<blockquote>
<p>notNext() 如果不希望一个事件类型紧接着另一个类型出现。 notFollowedBy() 不希望两个事件之间任何地方出现该事件。</p>
</blockquote>
<blockquote>
<p>注意 模式序列不能以notFollowedBy（）结束。</p>
</blockquote>
<blockquote>
<p>注意 NOT模式前面不能有可选模式。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// strict contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; strict = start.next(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxed = start.followedBy(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// non-deterministic relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; nonDetermin = start.followedByAny(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// NOT pattern with strict contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; strictNot = start.notNext(<span class="string">&quot;not&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// NOT pattern with relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxedNot = start.notFollowedBy(<span class="string">&quot;not&quot;</span>).where(...);</span><br></pre></td></tr></table></figure>
<p>宽松连续性指的是仅第一个成功匹配的事件会被匹配到，然而非确定性宽松连续性，相同的开始会有多个匹配结果发出。距离，如果一个模式是”a b”，给定输入序列是”a c b1 b2”。对于不同连续性会有不同输出。</p>
<ol>
<li>a和b之间严格连续性，将会返回{},也即是没有匹配。因为c的出现导致a，抛弃了。</li>
<li>a和b之间宽松连续性，返回的是{a，b1},因为宽松连续性将会抛弃为匹配成功的元素，直至匹配到下一个要匹配的事件。</li>
<li>a和b之间非确定性宽松连续性，返回的是{a,b1},{a,b2}。</li>
</ol>
<p>也可以为模式定义时间约束。 例如，可以通过pattern.within（）方法定义模式应在10秒内发生。 时间模式支持处理和事件时间。 注意模式序列只能有一个时间约束。 如果在不同的单独模式上定义了多个这样的约束，则应用最小的约束。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">next.within(Time.seconds(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>
<p>可以为begin，followBy，followByAny和next定义一个模式序列作为条件。模式序列将被逻辑地视为匹配条件，而且将返回GroupPattern并且 可对GroupPattern使用oneOrMore（），times（#ofTimes），times（＃fromTimes，＃toTimes），optional（），consecutive（）， allowCombinations（）等方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PatternPatte &lt;Event, ?&gt; start = Pattern.begin(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;start_middle&quot;</span>).where(...)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// strict contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; strict = start.next(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;next_start&quot;</span>).where(...).followedBy(<span class="string">&quot;next_middle&quot;</span>).where(...)</span><br><span class="line">).times(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxed = start.followedBy(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;followedby_start&quot;</span>).where(...).followedBy(<span class="string">&quot;followedby_middle&quot;</span>).where(...)</span><br><span class="line">).oneOrMore();</span><br><span class="line"></span><br><span class="line"><span class="comment">// non-deterministic relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; nonDetermin = start.followedByAny(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;followedbyany_start&quot;</span>).where(...).followedBy(<span class="string">&quot;followedbyany_middle&quot;</span>).where(...)</span><br><span class="line">).optional();</span><br></pre></td></tr></table></figure>
<h4 id="2-2-2-API"><a href="#2-2-2-API" class="headerlink" title="2.2.2 API"></a>2.2.2 API</h4><ol>
<li>begin(#name)</li>
</ol>
<p>定义一个开始模式</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>begin(#pattern_sequence)</li>
</ol>
<p>定义一个开始模式</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;middle&quot;</span>).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ol>
<li>next(#name)</li>
</ol>
<p>追加一个新的模式。匹配事件必须直接跟着先前的匹配事件（严格连续性）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; next = start.next(<span class="string">&quot;middle&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>next(#pattern_sequence)</li>
</ol>
<p>追加一个新的模式。匹配事件必须直接接着先前的匹配事件（严格连续性）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; next = start.next(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;middle&quot;</span>).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ol>
<li>followedBy(#name)</li>
</ol>
<p>追加加新模式。 匹配事件和先前匹配事件（宽松连续）之间可能发生其他非匹配事件：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedBy = start.followedBy(<span class="string">&quot;middle&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>followedBy(#pattern_sequence)</li>
</ol>
<p>追加新模式。 匹配事件和先前匹配事件（宽松连续）之间可能发生其他非匹配事件：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedBy = start.followedBy(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;middle&quot;</span>).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ol>
<li>followedByAny(#name)</li>
</ol>
<p>添加新模式。 匹配事件和先前匹配事件之间可能发生其他事件，并且将针对每个备选匹配事件（非确定性放松连续性）呈现替代匹配：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedByAny = start.followedByAny(<span class="string">&quot;middle&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>followedByAny(#pattern_sequence)</li>
</ol>
<p>添加新模式。 匹配事件和先前匹配事件之间可能发生其他事件，并且将针对每个备选匹配事件（非确定性放松连续性）呈现替代匹配：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedByAny = start.followedByAny(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;middle&quot;</span>).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ol>
<li>notNext()</li>
</ol>
<p>添加新的否定模式。 匹配（否定）事件必须直接跟着先前的匹配事件（严格连续性）才能丢弃部分匹配：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; notNext = start.notNext(<span class="string">&quot;not&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>notFollowedBy()</li>
</ol>
<p>追加一个新的否定模式匹配。即使在匹配（否定）事件和先前匹配事件（宽松连续性）之间发生其他事件，也将丢弃部分匹配事件序列：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; notFollowedBy = start.notFollowedBy(<span class="string">&quot;not&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>within(time)</li>
</ol>
<p>定义事件序列进行模式匹配的最大时间间隔。 如果未完成的事件序列超过此时间，则将其丢弃：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pattern.within(Time.seconds(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>
<h3 id="2-3-匹配后的跳过策略"><a href="#2-3-匹配后的跳过策略" class="headerlink" title="2.3 匹配后的跳过策略"></a>2.3 匹配后的跳过策略</h3><p>对于给定模式，可以将同一事件分配给多个成功匹配。 要控制将分配事件的匹配数，需要指定名为AfterMatchSkipStrategy的跳过策略。 跳过策略有四种类型，如下所示：</p>
<ul>
<li>NO_SKIP：将发出每个可能的匹配。</li>
<li>SKIP_PAST_LAST_EVENT：丢弃包含匹配事件的每个部分匹配。</li>
<li>SKIP_TO_FIRST：丢弃包含PatternName第一个之前匹配事件的每个部分匹配。</li>
<li>SKIP_TO_LAST：丢弃包含PatternName最后一个匹配事件之前的每个部分匹配。</li>
</ul>
<p>请注意，使用SKIP_TO_FIRST和SKIP_TO_LAST跳过策略时，还应指定有效的PatternName。</p>
<p>例如，对于给定模式a b {2}和数据流ab1，ab2，ab3，ab4，ab5，ab6，这四种跳过策略之间的差异如下：</p>
<p><a href="https://github.com/crestofwave1/oneFlink/blob/master/pic/CEP/%E8%B7%B3%E8%BF%87%E7%AD%96%E7%95%A5.png"><img src="https://github.com/crestofwave1/oneFlink/raw/master/pic/CEP/%E8%B7%B3%E8%BF%87%E7%AD%96%E7%95%A5.png" alt="image"></a></p>
<p>要指定要使用的跳过策略，只需调用以下命令创建AfterMatchSkipStrategy：</p>
<p><a href="https://github.com/crestofwave1/oneFlink/blob/master/pic/CEP/%E5%88%9B%E5%BB%BA%E8%B7%B3%E8%BF%87%E7%AD%96%E7%95%A5.png"><img src="https://github.com/crestofwave1/oneFlink/raw/master/pic/CEP/%E5%88%9B%E5%BB%BA%E8%B7%B3%E8%BF%87%E7%AD%96%E7%95%A5.png" alt="image"></a></p>
<p>使用方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">AfterMatchSkipStrategy skipStrategy = ...</span><br><span class="line">Pattern.begin(<span class="string">&quot;patternName&quot;</span>, skipStrategy);</span><br></pre></td></tr></table></figure>
<h3 id="2-4-检测模式-Detecting-Patterns"><a href="#2-4-检测模式-Detecting-Patterns" class="headerlink" title="2.4 检测模式-Detecting Patterns"></a>2.4 检测模式-Detecting Patterns</h3><p>指定要查找的模式序列后，就可以将其应用于输入流以检测潜在匹配。 要针对模式序列运行事件流，必须创建PatternStream。 给定输入流 input，模式 pattern 和可选的比较器 comparator，用于在EventTime的情况下对具有相同时间戳的事件进行排序或在同一时刻到达，通过调用以下命令创建PatternStream：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = ...</span><br><span class="line">EventComparator&lt;Event&gt; comparator = ... <span class="comment">// optional</span></span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(input, pattern, comparator);</span><br></pre></td></tr></table></figure>
<p>根据实际情况，创建的流可以是有key，也可以是无key的。</p>
<p>请注意，在无key的流上使用模式，将导致job的并行度为1。</p>
<h3 id="2-5-Selecting-from-Patterns"><a href="#2-5-Selecting-from-Patterns" class="headerlink" title="2.5 Selecting from Patterns"></a>2.5 Selecting from Patterns</h3><p>获得PatternStream后，您可以通过select或flatSelect方法从检测到的事件序列中进行查询。</p>
<p>select（）方法需要PatternSelectFunction的实现。 PatternSelectFunction具有为每个匹配事件序列调用的select方法。 它以Map &lt;String，List &gt;的形式接收匹配，其中key是模式序列中每个模式的名称，值是该模式的所有已接受事件的列表（IN是输入元素的类型）。 给定模式的事件按时间戳排序。 返回每个模式的接受事件列表的原因是当使用循环模式（例如oneToMany（）和times（））时，对于给定模式可以接受多个事件。 选择函数只返回一个结果。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPatternSelectFunction</span>&lt;<span class="title">IN</span>, <span class="title">OUT</span>&gt; <span class="keyword">implements</span> <span class="title">PatternSelectFunction</span>&lt;<span class="title">IN</span>, <span class="title">OUT</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> OUT <span class="title">select</span><span class="params">(Map&lt;String, List&lt;IN&gt;&gt; pattern)</span> </span>&#123;</span><br><span class="line">        IN startEvent = pattern.get(<span class="string">&quot;start&quot;</span>).get(<span class="number">0</span>);</span><br><span class="line">        IN endEvent = pattern.get(<span class="string">&quot;end&quot;</span>).get(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> OUT(startEvent, endEvent);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PatternFlatSelectFunction类似于PatternSelectFunction，唯一的区别是它可以返回任意数量的结果。 为此，select方法有一个额外的Collector参数，用于将输出元素向下游转发。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPatternFlatSelectFunction</span>&lt;<span class="title">IN</span>, <span class="title">OUT</span>&gt; <span class="keyword">implements</span> <span class="title">PatternFlatSelectFunction</span>&lt;<span class="title">IN</span>, <span class="title">OUT</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatSelect</span><span class="params">(Map&lt;String, List&lt;IN&gt;&gt; pattern, Collector&lt;OUT&gt; collector)</span> </span>&#123;</span><br><span class="line">        IN startEvent = pattern.get(<span class="string">&quot;start&quot;</span>).get(<span class="number">0</span>);</span><br><span class="line">        IN endEvent = pattern.get(<span class="string">&quot;end&quot;</span>).get(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; startEvent.getValue(); i++ ) &#123;</span><br><span class="line">            collector.collect(<span class="keyword">new</span> OUT(startEvent, endEvent));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-6-处理超时部分模式"><a href="#2-6-处理超时部分模式" class="headerlink" title="2.6 处理超时部分模式"></a>2.6 处理超时部分模式</h3><p>每当模式具有通过within关键字附加的时间窗口长度时，部分事件序列可能因为超出时间窗口长度而被丢弃。 为了对这些超时的部分匹配作出相应的处理，select和flatSelect API调用允许指定超时处理程序。 为每个超时的部分事件序列调用此超时处理程序。 超时处理程序接收到目前为止由模式匹配的所有事件，以及检测到超时时的时间戳。</p>
<p>为了处理部分模式，select和flatSelect API提供了一个带参数的重载版本</p>
<ul>
<li>PatternTimeoutFunction/ PatternFlatTimeoutFunction。</li>
<li>OutputTag 超时的匹配将会在其中返回。</li>
<li>PatternSelectFunction / PatternFlatSelectFunction。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PatternStreamPatte &lt;Event&gt; patternStream = CEP.pattern(input, pattern);</span><br><span class="line"></span><br><span class="line">OutputTag&lt;String&gt; outputTag = <span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">&quot;side-output&quot;</span>)&#123;&#125;;</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;ComplexEvent&gt; result = patternStream.select(</span><br><span class="line">    <span class="keyword">new</span> PatternTimeoutFunction&lt;Event, TimeoutEvent&gt;() &#123;...&#125;,</span><br><span class="line">    outputTag,</span><br><span class="line">    <span class="keyword">new</span> PatternSelectFunction&lt;Event, ComplexEvent&gt;() &#123;...&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">DataStream&lt;TimeoutEvent&gt; timeoutResult = result.getSideOutput(outputTag);</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;ComplexEvent&gt; flatResult = patternStream.flatSelect(</span><br><span class="line">    <span class="keyword">new</span> PatternFlatTimeoutFunction&lt;Event, TimeoutEvent&gt;() &#123;...&#125;,</span><br><span class="line">    outputTag,</span><br><span class="line">    <span class="keyword">new</span> PatternFlatSelectFunction&lt;Event, ComplexEvent&gt;() &#123;...&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">DataStream&lt;TimeoutEvent&gt; timeoutFlatResult = flatResult.getSideOutput(outputTag);</span><br></pre></td></tr></table></figure>
<h3 id="2-7-事件事件模式下处理滞后数据"><a href="#2-7-事件事件模式下处理滞后数据" class="headerlink" title="2.7 事件事件模式下处理滞后数据"></a>2.7 事件事件模式下处理滞后数据</h3><p>在CEP中，元素处理的顺序很重要。为了保证在采用事件事件时以正确的顺序处理事件，最初将传入的事件放入缓冲区，其中事件基于它们的时间戳以升序排序， 并且当watermark到达时，处理该缓冲区中时间戳小于watermark时间的所有元素。这意味着watermark之间的事件按事件时间顺序处理。</p>
<p>请注意，在采用事件时间时，CEP library会假设watermark是正确的。</p>
<p>为了保证跨watermark的记录按照事件事件顺序处理，Flink的CEP库假定watermark是正确的，并将时间戳小于上次可见watermark的时间视为滞后事件。滞后事件不会被进一步处理。</p>
<h3 id="2-8-栗子"><a href="#2-8-栗子" class="headerlink" title="2.8 栗子"></a>2.8 栗子</h3><p>以下示例检测事件的带key数据流上的模式start，middle（name =“error”） - &gt; end（name =“critical”）。 事件的key是其id，并且有效模式必须在10秒内发生。 整个处理是用事件时间完成的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StreamExecutionEnvironment env = ...</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line"></span><br><span class="line">DataStream&lt;Event&gt; partitionedInput = input.keyBy(<span class="keyword">new</span> KeySelector&lt;Event, Integer&gt;() &#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Integer <span class="title">getKey</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> value.getId();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>)</span><br><span class="line">	.next(<span class="string">&quot;middle&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">			<span class="keyword">return</span> value.getName().equals(<span class="string">&quot;error&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;).followedBy(<span class="string">&quot;end&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">			<span class="keyword">return</span> value.getName().equals(<span class="string">&quot;critical&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;).within(Time.seconds(<span class="number">10</span>));</span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(partitionedInput, pattern);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Alert&gt; alerts = patternStream.select(<span class="keyword">new</span> PatternSelectFunction&lt;Event, Alert&gt;() &#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Alert <span class="title">select</span><span class="params">(Map&lt;String, List&lt;Event&gt;&gt; pattern)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> createAlert(pattern);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>mapReducer</tag>
      </tags>
  </entry>
  <entry>
    <title>flink cep</title>
    <url>/bigdata/Flink/flink-cep/</url>
    <content><![CDATA[<p>Flink cep</p>
<p>CEP的处理范例引起了人们的极大兴趣，并在各种用例中得到了应用。 最值得注意的是，CEP现在用于诸如股票市场趋势和信用卡欺诈检测等金融应用</p>
<p>模式，从流中查找符合某个pattern的个体事件。<br>可以将一个pattern sequence视为pattern组成的图, 基于用户定义的条件，从一个pattern传递到下一个pattern<br>一个match是事件必须流过复杂pattern图的所有的pattern。</p>
<p><strong>注意</strong></p>
<ul>
<li>每一个pattern必须具有唯一的名称，用于标示符合条件的事件</li>
<li>pattern名称不能包含:</li>
</ul>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>mapReducer</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink/Storm 动态更新配置实现方案</title>
    <url>/bigdata/Flink/flink-config-dynamic/</url>
    <content><![CDATA[<p>实时计算处理无限数据流，对系统可用性十分敏感，然而业务需求具有必然的更新需求，动态更新实时计算的配置是常见的需求，比如动态增加用户白名单、业务数据在线 debug、新增广告位统计等等。然而，实现并不简单，Apache Strom 和 Apache Storm 具有不同的架构，实现方式也不尽相同。</p>
<p>Apache Strom(这里不包括 Trident)，所有的计算逻辑都是通过实现spout 和 bolt，运行在 task节点上，因此与业务逻辑相关的状态管理、配置管理以及输入输出的控制等均可以定义在 bolt 中，如定时一分钟轮询配置变化、定时 checkpoint 近似数据集等。此外，配置同样可以通过控制流的方式与数据流 uion 到一起，在计算节点检测判断控制流的关键字来实现配置更新的目的。</p>
<p>Apache Flink 的函数式 API 封装要比 Storm 要完善，而灵活性不比 Strom。实现配置动态更新有两种方式，一是在算子中定时轮询拉取配置信息，二是利用广播状态和控制流。</p>
<h1 id="asyncIO"><a href="#asyncIO" class="headerlink" title="asyncIO"></a>asyncIO</h1><h1 id="stateBroadcast"><a href="#stateBroadcast" class="headerlink" title="stateBroadcast"></a>stateBroadcast</h1>]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>mapReducer</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink on yarn</title>
    <url>/bigdata/Flink/flink-on-yarn/</url>
    <content><![CDATA[<h2 id="flink-on-yarn部署"><a href="#flink-on-yarn部署" class="headerlink" title="flink on yarn部署"></a>flink on yarn部署</h2><p>flink on yarn需要的组件与版本如下</p>
<ol>
<li>Zookeeper 3.4.9 用于做Flink的JobManager的HA服务</li>
<li>hadoop 2.7.2 搭建HDFS和Yarn</li>
<li>flink 1.3.2 或者 1.4.1版本（scala 2.11）</li>
</ol>
<p>Zookeeper, HDFS 和 Yarn 的组件的安装可以参照网上的教程。</p>
<p>在zookeeper，HDFS 和Yarn的组件的安装好的前提下，在客户机上提交Flink任务，具体流程如下：</p>
<ul>
<li>在启动Yarn-Session 之前， 设置好HADOOP_HOME,YARN_CONF_DIR ， HADOOP_CONF_DIR环境变量中三者的一个。如下所示， 根据具体的hadoop 路径来设置<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop-current</span></span><br></pre></td></tr></table></figure></li>
<li>配置flink 目录下的flink-conf.yaml, 如下所示<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">localhost</span></span><br><span class="line"><span class="attr">jobmanager.rpc.port:</span> <span class="number">6123</span></span><br><span class="line"><span class="attr">jobmanager.heap.mb:</span> <span class="number">256</span></span><br><span class="line"><span class="attr">taskmanager.heap.mb:</span> <span class="number">512</span></span><br><span class="line"><span class="attr">taskmanager.numberOfTaskSlots:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">taskmanager.memory.preallocate:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">parallelism.default:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">jobmanager.web.port:</span> <span class="number">8081</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># yarn</span></span><br><span class="line"><span class="attr">yarn.maximum-failed-containers:</span> <span class="number">99999</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#akka config</span></span><br><span class="line"><span class="attr">akka.watch.heartbeat.interval:</span> <span class="number">5</span> <span class="string">s</span></span><br><span class="line"><span class="attr">akka.watch.heartbeat.pause:</span> <span class="number">20</span> <span class="string">s</span></span><br><span class="line"><span class="attr">akka.ask.timeout:</span> <span class="number">60</span> <span class="string">s</span></span><br><span class="line"><span class="attr">akka.framesize:</span> <span class="string">20971520b</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#high-avaliability</span></span><br><span class="line"><span class="attr">high-availability:</span> <span class="string">zookeeper</span></span><br><span class="line"><span class="comment">## 根据安装的zookeeper信息填写</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.quorum:</span> <span class="number">10.141</span><span class="number">.61</span><span class="number">.226</span><span class="string">:2181,10.141.53.244:2181,10.141.18.219:2181</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.path.root:</span> <span class="string">/flink</span></span><br><span class="line"><span class="comment">## HA 信息存储到HDFS的目录，根据各自的Hdfs情况修改</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.storageDir:</span> <span class="string">hdfs://hdcluster/flink/recovery/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#checkpoint config</span></span><br><span class="line"><span class="attr">state.backend:</span> <span class="string">rocksdb</span></span><br><span class="line"><span class="comment">## checkpoint到HDFS的目录 根据各自安装的HDFS情况修改</span></span><br><span class="line"><span class="attr">state.backend.fs.checkpointdir:</span> <span class="string">hdfs://hdcluster/flink/checkpoint</span></span><br><span class="line"><span class="comment">## 对外checkpoint到HDFS的目录</span></span><br><span class="line"><span class="attr">state.checkpoints.dir:</span> <span class="string">hdfs://hdcluster/flink/savepoint</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#memory config</span></span><br><span class="line"><span class="attr">env.java.opts:</span> <span class="string">-XX:+UseConcMarkSweepGC</span> <span class="string">-XX:CMSInitiatingOccupancyFraction=75</span> <span class="string">-XX:+UseCMSInitiatingOccupancyOnly</span> <span class="string">-XX:+AlwaysPreTouch</span> <span class="string">-server</span> <span class="string">-XX:+HeapDumpOnOutOfMemoryError</span></span><br><span class="line"><span class="attr">yarn.heap-cutoff-ratio:</span> <span class="number">0.2</span></span><br><span class="line"><span class="attr">taskmanager.memory.off-heap:</span> <span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>提交Yarn-Session，切换到flink的bin 目录下,提交命令如下<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ./yarn-session.sh -n 2 -s 6 -jm 3072 -tm 6144 -nm <span class="built_in">test</span> -d</span></span><br></pre></td></tr></table></figure>
启动yarn-session的参数解释如下</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>参数解释</th>
<th>设置推荐</th>
</tr>
</thead>
<tbody><tr>
<td>-n(–container)</td>
<td>taskmanager的数量</td>
<td></td>
</tr>
<tr>
<td>-s(–slots)</td>
<td>用启动应用所需的slot数量/ -s 的值向上取整，有时可以多一些taskmanager，做冗余 每个taskmanager的slot数量，默认一个slot一个core，默认每个taskmanager的slot的个数为1</td>
<td>6～10</td>
</tr>
<tr>
<td>-jm</td>
<td>jobmanager的内存（单位MB)</td>
<td>3072</td>
</tr>
<tr>
<td>-tm</td>
<td>每个taskmanager的内存（单位MB)</td>
<td>根据core 与内存的比例来设置，-s的值＊ （core与内存的比）来算</td>
</tr>
<tr>
<td>-nm</td>
<td>yarn 的appName(现在yarn的ui上的名字)｜</td>
<td></td>
</tr>
<tr>
<td>-d</td>
<td>后台执行</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>提交yarn－session 后，可以在yarn的ui上看到一个应用（应用有一个appId）, 切换到flink的bin目录下，提交flink 应用。命令如下<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ./flink -run file:///home/yarn/test.jar -a 1 -p 12 -yid appId -nm flink-test -d</span></span><br></pre></td></tr></table></figure>
启动flink 应用的参数解释如下</li>
</ul>
<table>
<thead>
<tr>
<th>参数</th>
<th>参数解释</th>
</tr>
</thead>
<tbody><tr>
<td>-j</td>
<td>运行flink 应用的jar所在的目录</td>
</tr>
<tr>
<td>-a</td>
<td>运行flink 应用的主方法的参数</td>
</tr>
<tr>
<td>-p</td>
<td>运行flink应用的并行度</td>
</tr>
<tr>
<td>-c</td>
<td>运行flink应用的主类, 可以通过在打包设置主类</td>
</tr>
<tr>
<td>-nm</td>
<td>flink 应用名字，在flink-ui 上面展示</td>
</tr>
<tr>
<td>-d</td>
<td>后台执行</td>
</tr>
<tr>
<td>–fromsavepoint</td>
<td>flink 应用启动的状态恢复点</td>
</tr>
</tbody></table>
<ul>
<li>启动flink应用成功，即可在yarn ui 点击对应应用的ApplicationMaster链接,既可以查看flink-ui ，并查看flink 应用运行情况。</li>
</ul>
<p>注：在安装部署遇到任何问题，可以在小象问答，微信群以及私聊提出，我们一般会在晚上作答（由于白天要上班，作答不及时请谅解。）</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink:指标监控</title>
    <url>/bigdata/Flink/metrics/</url>
    <content><![CDATA[<h1 id="flink-metrics"><a href="#flink-metrics" class="headerlink" title="flink-metrics"></a>flink-metrics</h1><p>[参考文献]</p>
<ul>
<li><a href="https://blog.csdn.net/qq_21653785/article/details/79625601">Flink源码系列-指标监控</a></li>
<li><a href="https://www.cnblogs.com/0x12345678/p/10561039.html">自定义metric-report</a></li>
<li><a href="http://www.mamicode.com/info-detail-2317943.html">深入理解Flink之metrics</a></li>
<li><a href="https://my.oschina.net/go4it/blog/3023586">聊聊Flink的MertricsQueryServiceGateway</a></li>
<li><a href="https://www.jianshu.com/p/e50586fff515">Flink指标</a></li>
</ul>
<p>Flink Metrics是通过引入<code>com.codahale.metrics</code>包实现的，它将收集的metrics分为四大类：<code>Counter</code>，<code>Gauge</code>，<code>Histogram</code>和<code>Meter</code>下面分别说明：</p>
<ul>
<li><code>Counter计数器</code><br>  用来统计一个metrics的总量。<br>  拿flink中的指标来举例，像Task/Operator中的numRecordsIn（此task或者operator接收到的record总量）和numRecordsOut（此task或者operator发送的record总量）就属于Counter。</li>
<li><code>Gauge指标值</code><br>  用来记录一个metrics的瞬间值。<br>  拿flink中的指标举例，像JobManager或者TaskManager中的<code>JVM.Heap.Used</code>就属于<code>Gauge</code>，记录某个时刻JobManager或者TaskManager所在机器的JVM堆使用量。</li>
<li><code>Histogram直方图</code><br>  有的时候我们不满足于只拿到metrics的总量或者瞬时值，当想得到metrics的最大值，最小值，中位数等信息时，我们就能用到Histogram了。<br>  Flink中属于Histogram的指标很少，但是最重要的一个是属于operator的latency。此项指标会记录数据处理的延迟信息，对任务监控起到很重要的作用。</li>
<li><code>Meter平均值</code><br>   用来记录一个metrics某个时间段内平均值。<br>   flink中类似指标有task/operator中的numRecordsInPerSecond，字面意思就可以理解，指的是此task或者operator每秒接收的记录数。</li>
</ul>
<h3 id="com-tencent-oceanus-metastore-metrics-CustomMetricsRegistry"><a href="#com-tencent-oceanus-metastore-metrics-CustomMetricsRegistry" class="headerlink" title="com.tencent.oceanus.metastore.metrics.CustomMetricsRegistry"></a>com.tencent.oceanus.metastore.metrics.CustomMetricsRegistry</h3>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/watermark/</url>
    <content><![CDATA[<h1 id="watermark"><a href="#watermark" class="headerlink" title="watermark"></a>watermark</h1><p>a window operator registers a timer for every active window, which cleans up the window’s state when the event time passes the window’s ending time.</p>
]]></content>
  </entry>
  <entry>
    <title>HBase-client</title>
    <url>/bigdata/HBase/HBase-client/</url>
    <content><![CDATA[<h1 id="HBase-client"><a href="#HBase-client" class="headerlink" title="HBase-client"></a>HBase-client</h1><h2 id="读取到旧region的原因"><a href="#读取到旧region的原因" class="headerlink" title="读取到旧region的原因"></a>读取到旧region的原因</h2><p> hbase查询，查询在两张表间切换，查询了三天另一张表，原表已经重建过了，查询切换回原表出现读取到旧region的问题</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase基础与开发实践</title>
    <url>/bigdata/HBase/HBase/</url>
    <content><![CDATA[<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="避免数据热点"><a href="#避免数据热点" class="headerlink" title="避免数据热点"></a>避免数据热点</h3><p>加盐的过程本质上是对原有的主键加上一个字节的前缀，<br>如下面公式所示：<br>new_row_key = (++index % BUCKETS_NUMBER) + original_key</p>
<p>BUCKETS_NUMBER 为桶的个数。主键的分布决定了数据的分布，把主键<br>打散也就意味着数据打散。具体使用时，一般建议桶的数目等于 RegionServer 的<br>数目。</p>
<h3 id="多租户"><a href="#多租户" class="headerlink" title="多租户"></a>多租户</h3><p>我们开发了 DHS 系统（Didi HBase Service）进行项目管理，并且在 HBase 上通过 Namespace、RS Group 等技术来分割用户的资源、数据和权限。通过计算开销并计费的方法来管控资源分配</p>
<p>HBase 自带的 jxm 信息会汇总到 Region 和 RegionServer 级别的数据，管理员会经常用到，但是用户却很少关注这个级别。根据这种情况我们开发了 HBase 表级别的监控，并且会有权限控制，让业务 RD 只能看到和自己相关的表，清楚自己项目表的吞吐及存储占用情况</p>
<p>RegionServer Group，实现细节可以参照 HBase HBASE-6721 这个 Patch。滴滴在这个基础上作了一些分配策略上的优化，以便适合滴滴业务场景的修改。RS Group简单概括是指通过分配一批指定的RegionServer列表，成为一个RS Group，每个 Group 可以按需挂载不同的表，并且当 Group 内的表发生异常后，Region不会迁移到其他的 Group。这样，每个 Group 就相当于一个逻辑上的子集群，通过这种方式达到资源隔离的效果，降低管理成本，不必为每个高 SLA 的业务线单独搭集群。</p>
<h2 id="HDFS中文件的存储"><a href="#HDFS中文件的存储" class="headerlink" title="HDFS中文件的存储"></a>HDFS中文件的存储</h2><p><a href="https://hbase.apache.org/book.html#trouble.namenode.hbase.objects">Browsing HDFS for HBase Objects</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/hbase/data/default/&lt;table_name&gt;/ab0ba9f7e0d2898a0f61aa687d3d4886/&lt;column_family&gt;/&lt;HFile_name&gt;</span><br></pre></td></tr></table></figure>
<p>如</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/hbase/data/default/my_table/d177ff7276d2e46d69dc50f67f92643a/cf/</span><br></pre></td></tr></table></figure>
<p>HFile每bulkload一次，新增加的HFile序列号增加1</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> ./hadoop fs -ls /hbase/data/default/recommend_result/d177ff7276d2e46d69dc50f67f92643a/cf</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-rw-rw-   3 tdw_hectorhe g_cdg_cft_data__cft 2791972087 2019-04-11 07:06 /hbase/data/default/recommend_result/d177ff7276d2e46d69dc50f67f92643a/cf/accd28866e6d40738849b4efb08ea154_SeqId_312_</span><br><span class="line">-rw-r--r--   3 hbaseadmin   users               2941438650 2019-04-11 04:07 /hbase/data/default/recommend_result/d177ff7276d2e46d69dc50f67f92643a/cf/ee29f8ad0fa14f508793108234242de4</span><br></pre></td></tr></table></figure>
<p>如上面的<code>seqId_1</code>，代表序列号为1，在major compact时，将合并成一个文件</p>
<p>如果存在多个HFile，就需要同时查询多个列族。</p>
<ol>
<li>一个region只保存在一个region server中，不会跨越region server，由hdfs保证高可用</li>
</ol>
<h3 id="client写入"><a href="#client写入" class="headerlink" title="client写入"></a>client写入</h3><p>通过client写入数据时，首先会把数据写入到memstore和WAL，数据到达一定的阈值，才会溢写到StoreFile，StoreFile也就是HFile</p>
<h2 id="zk存储"><a href="#zk存储" class="headerlink" title="zk存储"></a>zk存储</h2><h2 id="hbase-meta"><a href="#hbase-meta" class="headerlink" title="hbase meta"></a>hbase meta</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hbase(main):053:0&gt; list_namespace_tables &#x27;hbase&#x27;</span><br><span class="line">TABLE </span><br><span class="line">meta      </span><br><span class="line">namespace </span><br><span class="line">rsgroup  </span><br><span class="line">3 row(s) in 0.0040 seconds</span><br></pre></td></tr></table></figure>





<h2 id="GET的过程"><a href="#GET的过程" class="headerlink" title="GET的过程"></a>GET的过程</h2><h2 id="Coprocessor"><a href="#Coprocessor" class="headerlink" title="Coprocessor"></a>Coprocessor</h2><h2 id="Phoenix"><a href="#Phoenix" class="headerlink" title="Phoenix"></a>Phoenix</h2><p>在没有 Phoenix 之前，用户如果需要分析 HBase 数据，只能从 HBase 拖出去或者绕过 HBase 直接读取 HDFS 上面的HFile 的方式进行，前者浪费了大量的网络IO，后者用不到 HBase 本身做的大量缓存和索引优化。Phoenix 使用 HBase 的协处理器机制，直接在 RegionServer 上执行算子逻辑，然后将算子的结果返回即可，也就是大数据中的“Move Operator to Data”理念。比如，用户执行“ <code>select count(*) from mytable where mytime &gt; timestamp’2018-11-11 0:00:00’</code> ”，在实际执行中，会先找到符合过滤条件的region，然后在RegionServer本地计算count，最后再对各个 Region 上的结果进行汇总。</p>
<p>索引是传统数据库中常见的技术，HBase 表中可以指定主键，对主键使用 LSM 算<br>法构建索引。Phoenix 中，用户在创建表的时候，可以指定索引列，可以是单列，<br>也可以是组合列。很多时候仅有主键索引是不够的，特别是对于列特别多的宽表，<br>为此，Phoenix 提供二级索引功能，用户能够对表中非主键的列添加索引，并可<br>以加入其它相关列到索引表中，如果某个查询涉及到的列全部在索引表中，直接<br>查询索引表即可，无需访问原数据表。索引表跟原表做到实时同步更新，以保证<br>数据一致性。</p>
<p><a href="https://www.imooc.com/video/15575">imooc</a></p>
<p>@Controller<br>    @SessionAttributes({ “credentials”, “user” })</p>
<h2 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h2><h3 id="HFile文件的元数据"><a href="#HFile文件的元数据" class="headerlink" title="HFile文件的元数据"></a>HFile文件的元数据</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs dfs -du -h /hbase/data/default/dal_hx_lct_700_800/999fdd6a2ed426fcb33d202195fdd7d2/i/</span><br><span class="line">16.0 G  /hbase/data/default/dal_hx_lct_700_800/999fdd6a2ed426fcb33d202195fdd7d2/i/0e950ca090d54eb2b98abffc2e285cfa_SeqId_4_</span><br><span class="line">16.0 G  /hbase/data/default/dal_hx_lct_700_800/999fdd6a2ed426fcb33d202195fdd7d2/i/bfc0c2e4fae84ba19ad1eaf78ea04967_SeqId_4_</span><br><span class="line">16.0 G  /hbase/data/default/dal_hx_lct_700_800/999fdd6a2ed426fcb33d202195fdd7d2/i/e5f3675a6b0040faa695ec3b35b2e951_SeqId_4_</span><br><span class="line">6.1 G   /hbase/data/default/dal_hx_lct_700_800/999fdd6a2ed426fcb33d202195fdd7d2/i/f5c2d2461e0f4eb58ed6c75aa1ae9ffa_SeqId_4_</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hbase hfile -m -f /hbase/data/default/dal_hx_lct_700_800/999fdd6a2ed426fcb33d202195fdd7d2/i/0e950ca090d54eb2b98abffc2e285cfa_SeqId_4_</span><br><span class="line"></span><br><span class="line">2020-03-18 14:19:37,389 INFO  [main] hfile.CacheConfig: Created cacheConfig: CacheConfig:disabled</span><br><span class="line">Block index size as per heapsize: 5288</span><br><span class="line">reader=/hbase/data/default/dal_hx_lct_700_800/999fdd6a2ed426fcb33d202195fdd7d2/i/0e950ca090d54eb2b98abffc2e285cfa_SeqId_4_,</span><br><span class="line">    compression=none,</span><br><span class="line">    cacheConf=CacheConfig:disabled,</span><br><span class="line">    firstKey=0632079511/i:v/1584411652893/Put,</span><br><span class="line">    lastKey=0938227441/i:v/1584411652893/Put,</span><br><span class="line">    avgKeyLen=23,</span><br><span class="line">    avgValueLen=1837,</span><br><span class="line">    entries=9189138,</span><br><span class="line">    length=17212333944</span><br><span class="line">Trailer:</span><br><span class="line">    fileinfoOffset=17212333262,</span><br><span class="line">    loadOnOpenDataOffset=17212330707,</span><br><span class="line">    dataIndexCount=73,</span><br><span class="line">    metaIndexCount=0,</span><br><span class="line">    totalUncomressedBytes=17207143638,</span><br><span class="line">    entryCount=9189138,</span><br><span class="line">    compressionCodec=NONE,</span><br><span class="line">    uncompressedDataIndexSize=9529760,</span><br><span class="line">    numDataIndexLevels=2,</span><br><span class="line">    firstDataBlockOffset=0,</span><br><span class="line">    lastDataBlockOffset=17212236283,</span><br><span class="line">    comparatorClassName=org.apache.hadoop.hbase.KeyValue$KeyComparator,</span><br><span class="line">    majorVersion=2,</span><br><span class="line">    minorVersion=3</span><br><span class="line">Fileinfo:</span><br><span class="line">    BULKLOAD_SOURCE_TASK = attempt_20200317094633_0002_r_000001_0</span><br><span class="line">    BULKLOAD_TIMESTAMP = \x00\x00\x01p\xE6\x81\x87\xD0</span><br><span class="line">    DELETE_FAMILY_COUNT = \x00\x00\x00\x00\x00\x00\x00\x00</span><br><span class="line">    EARLIEST_PUT_TS = \x00\x00\x01p\xE6K3\x1D</span><br><span class="line">    EXCLUDE_FROM_MINOR_COMPACTION = \x00</span><br><span class="line">    KEY_VALUE_VERSION = \x00\x00\x00\x01</span><br><span class="line">    MAJOR_COMPACTION_KEY = \xFF</span><br><span class="line">    MAX_MEMSTORE_TS_KEY = \x00\x00\x00\x00\x00\x00\x00\x00</span><br><span class="line">    TIMERANGE = 1584411652893....1584411652893</span><br><span class="line">    hfile.AVG_KEY_LEN = 23</span><br><span class="line">    hfile.AVG_VALUE_LEN = 1837</span><br><span class="line">    hfile.LASTKEY = \x00\x0A0938227441\x01iv\x00\x00\x01p\xE6K3\x1D\x04</span><br><span class="line">Mid-key: \x00\x09078540676\x00\x7F\xFF\xFF\xFF\xFF\xFF\xFF\xFF\xFF</span><br><span class="line">Bloom filter:</span><br><span class="line">    Not present</span><br><span class="line">Delete Family Bloom filter:</span><br><span class="line">    Not present</span><br></pre></td></tr></table></figure>

<h2 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h2><h3 id="写入模型优化"><a href="#写入模型优化" class="headerlink" title="写入模型优化"></a>写入模型优化</h3><p>WAL写入模型</p>
<p>了解了HLog的结构之后，我们就开始研究HLog的写入模型。HLog的写入可以分为三个阶段，首先将数据对&lt;HLogKey,WALEdit&gt;写入本地缓存，然后再将本地缓存写入文件系统，最后执行sync操作同步到磁盘。在以前老的写入模型中，上述三步都由工作线程独自完成，如下图所示：</p>
<p><img src="_v_images/20200815154403071_1496305947.png" alt="103"></p>
<p>上图中，本地缓存写入文件系统那个步骤工作线程需要持有updateLock执行，不同工作线程之间必然会恶性竞争；不仅如此，在Sync HDFS这步中，工作线程之间需要抢占flushLock，因为Sync操作是一个耗时操作，抢占这个锁会导致写入性能大幅降低。</p>
<p>所幸的是，来自中国（准确的来说，是来自小米，鼓掌）的3位工程师意识到了这个问题，进而提出了一种新的写入模型并被官方采纳。根据官方测试，新写入模型的吞吐量比之前提升3倍多，单台RS写入吞吐量介于12150～31520，5台RS组成的集群写入吞吐量介于22000～70000（见HBASE-8755）。下图是小米官方给出来的对比测试结果：</p>
<p><img src="_v_images/20200815154402968_1974951896.png" alt="104"></p>
<p>在新写入模型中，本地缓存写入文件系统以及Sync HDFS都交给了新的独立线程完成，并引入一个Notify线程通知工作线程是否已经Sync成功，采用这种机制消除上述锁竞争，具体如下图所示：</p>
<p><img src="_v_images/20200815154402863_279526558.png" alt="105"></p>
<p>1. 上文中提到工作线程在写入WALEdit之后并没有进行Sync，而是等到释放行锁阻塞在syncedTillHere变量上，等待AsyncNotifier线程唤醒。</p>
<p>2. 工作线程将WALEdit写入本地Buffer之后，会生成一个自增变量txid，携带此txid唤醒AsyncWriter线程</p>
<p>3. AsyncWriter线程会取出本地Buffer中的所有WALEdit，写入HDFS。注意该线程会比较传入的txid和已经写入的最大txid（writtenTxid），如果传入的txid小于writteTxid，表示该txid对应的WALEdit已经写入，直接跳过</p>
<p>4. AsyncWriter线程将所有WALEdit写入HDFS之后携带maxTxid唤醒AsyncFlusher线程</p>
<p>5. AsyncFlusher线程将所有写入文件系统的WALEdit统一Sync刷新到磁盘</p>
<p>6. 数据全部落盘之后调用setFlushedTxid方法唤醒AyncNotifier线程</p>
<p>7. AyncNotifier线程会唤醒所有阻塞在变量syncedTillHere的工作线程，工作线程被唤醒之后表示WAL写入完成，后面再执行MVCC结束写事务，推进全局读取点，本次更新才会对用户可见</p>
<p>通过上述过程的梳理可以知道，新写入模型采取了多线程模式独立完成写文件系统、sync磁盘操作，避免了之前多工作线程恶性抢占锁的问题。同时，工作线程在将WALEdit写入本地Buffer之后并没有马上阻塞，而是释放行锁之后阻塞等待WALEdit落盘，这样可以尽可能地避免行锁竞争，提高写入性能。</p>
<p>wal写入数据写入经历三步:</p>
<ol>
<li>写入本地缓存</li>
<li>写入hdfs</li>
<li>flush hdfs</li>
</ol>
<p>旧的写入模型，工作线程自己写入hdfs和flush，为了避免一致性问题，需要分别竞争updateLock和flushLock, 工作线程在单个线程中完成，写了hdfs，立即直接flush</p>
<p>新的写入模型，将写hdfs和flush hdfs分别由两个单独的线程(AsyncWriter和AsyncFlusher)处理，落盘后回调工作线程；<br>为了避免多个线程同时写入冲突，给每个要写入的文件生成一个自增的txid，写hdfs的线程会把所有的文件全部写入到hdfs，<br>如果工作线程要写的txid小于max txid，代表已经写过了。</p>
<h2 id="memstore"><a href="#memstore" class="headerlink" title="memstore"></a>memstore</h2><h3 id="MSLAB"><a href="#MSLAB" class="headerlink" title="MSLAB"></a>MSLAB</h3><p>LAB 对 GC 的优化</p>
<h3 id="ConcurrentSkipListMap"><a href="#ConcurrentSkipListMap" class="headerlink" title="ConcurrentSkipListMap"></a>ConcurrentSkipListMap</h3><h3 id="CompactingMemStore"><a href="#CompactingMemStore" class="headerlink" title="CompactingMemStore"></a>CompactingMemStore</h3><h2 id="HBase-clonesnapshot-限流实现原理"><a href="#HBase-clonesnapshot-限流实现原理" class="headerlink" title="HBase clonesnapshot 限流实现原理"></a>HBase clonesnapshot 限流实现原理</h2><h2 id="scanner"><a href="#scanner" class="headerlink" title="scanner"></a>scanner</h2>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>HBase</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase线上异常分析</title>
    <url>/bigdata/HBase/online-bug/</url>
    <content><![CDATA[<h1 id="online-bug"><a href="#online-bug" class="headerlink" title="online-bug"></a>online-bug</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">02</span>-<span class="number">02</span> <span class="number">06</span>:<span class="number">47</span>:<span class="number">00</span>,<span class="number">075</span> INFO  [&lt;ip&gt;,<span class="number">60020</span>,1591261891345_ChoreService_3] regionserver.HRegionServer: &lt;ip&gt;,<span class="number">60020</span>,<span class="number">1591261891345</span>-MemstoreFlusherChore requesting flush of hbase:rsgroup,,<span class="number">1591262014513.</span>066ea97b2a302a0e0aec8bc8cf00a680. because m has an old edit so flush to free WALs after random delay 33697ms</span><br><span class="line"><span class="number">2021</span>-<span class="number">02</span>-<span class="number">02</span> <span class="number">06</span>:<span class="number">47</span>:<span class="number">00</span>,<span class="number">175</span> INFO  [&lt;ip&gt;,<span class="number">60020</span>,1591261891345_ChoreService_3] regionserver.HRegionServer: &lt;ip&gt;,<span class="number">60020</span>,<span class="number">1591261891345</span>-MemstoreFlusherChore requesting flush of hbase:rsgroup,,<span class="number">1591262014513.</span>066ea97b2a302a0e0aec8bc8cf00a680. because m has an old edit so flush to free WALs after random delay 114225ms</span><br><span class="line"><span class="number">2021</span>-<span class="number">02</span>-<span class="number">02</span> <span class="number">06</span>:<span class="number">47</span>:<span class="number">00</span>,<span class="number">267</span> INFO  [&lt;ip&gt;,<span class="number">60020</span>,1591261891345_ChoreService_2] regionserver.HRegionServer: &lt;ip&gt;,<span class="number">60020</span>,<span class="number">1591261891345</span>-MemstoreFlusherChore requesting flush of hbase:rsgroup,,<span class="number">1591262014513.</span>066ea97b2a302a0e0aec8bc8cf00a680. because m has an old edit so flush to free WALs after random delay 121313ms</span><br><span class="line"><span class="number">2021</span>-<span class="number">02</span>-<span class="number">02</span> <span class="number">06</span>:<span class="number">47</span>:<span class="number">00</span>,<span class="number">375</span> INFO  [&lt;ip&gt;,<span class="number">60020</span>,1591261891345_ChoreService_3] regionserver.HRegionServer: &lt;ip&gt;,<span class="number">60020</span>,<span class="number">1591261891345</span>-MemstoreFlusherChore requesting flush of hbase:rsgroup,,<span class="number">1591262014513.</span>066ea97b2a302a0e0aec8bc8cf00a680. because m has an old edit so flush to free WALs after random delay 259454ms</span><br><span class="line"><span class="number">2021</span>-<span class="number">02</span>-<span class="number">02</span> <span class="number">06</span>:<span class="number">47</span>:<span class="number">00</span>,<span class="number">467</span> INFO  [&lt;ip&gt;,<span class="number">60020</span>,1591261891345_ChoreService_2] regionserver.HRegionServer: &lt;ip&gt;,<span class="number">60020</span>,<span class="number">1591261891345</span>-MemstoreFlusherChore requesting flush of hbase:rsgroup,,<span class="number">1591262014513.</span>066ea97b2a302a0e0aec8bc8cf00a680. because m has an old edit so flush to free WALs after random delay 191262ms</span><br></pre></td></tr></table></figure>

<p>关于MemStore的刷新方式：<br>1、MemStore达到上限hbase.hregion.memstore.flush.size 默认是128M的时候，会触发MemStore的刷新。这个参数表示单个MemStore的大小的阈值。这个时候是不阻塞写操作的。</p>
<p>2、当一个Region的MemStore总量达到hbase.hregion.memstore.block.multiplier * hbase.hregion.memstore.flush.size（默认2*128M=256M）时，会阻塞这个region的写操作，并强制刷写到HFile。触发这个刷新只会发生在MemStore即将写满128M时put了一个巨大的记录的情况，这时会阻塞写操作，强制刷新成功才能继续写入。</p>
<p>3、一个RegionServer会有很多个Region，很多的MemStore，所以可能单个Region并没有超过阈值，但是整个RegionServer的内存已经占用非常多了，这时候还有另外两个参数控制内存的刷写：hbase.regionserver.global.memstore.upperLimit 默认0.4，当RegionServer上全部的MemStore占用超过heap(heap的大小在hbase-env.sh中设置HBASE_HEAPSIZE，默认1G，我们设置的4G)的40%时，强制阻塞所有的写操作，将所有的MemStore刷写到HFile；hbase.regionserver.global.memstore.lowerLimit 默认0.35，表示所有的MemStore占用超过heap的35%时，会选择一些占用内存比较大的MemStore阻塞写操作并进行flush，这是为了降低阻塞全部写操作flush带来的问题。</p>
<p>4、当HLog达到最大值（hbase.regionserver.maxlogs * hbase.regionserver.hlog.blocksize 默认32*64M = 2G）时，也会触发MemStore的刷新，强制将更新固化到HFile中，避免在RegionServer crash时恢复时间过长。</p>
<p>5、定期会进行MemStore的刷新，hbase.regionserver.optionalcacheflushinterval 默认3600000，一小时，确保MemStore的数据不会长时间没有固化到HFile中。为避免所有的MemStore在同一时间都进行flush导致的问题，定期的flush操作有20000左右的随机延时。</p>
<p>6、手工可以进行flush操作，在hbase shell调用flush，可以针对某个表或者某个region进行flush：<br>hbase(main):010:0&gt; help ‘flush’<br>Flush all regions in passed table or pass a region row to flush an individual region.  For example:</p>
<p>  hbase&gt; flush ‘TABLENAME’<br>  hbase&gt; flush ‘REGIONNAME’</p>
<p>7、手工flush：<br>在API中只看到有setMemStoreFlushSize 指定memstore flush到HDFS上的文件大小，默认是64M，不确定是否可以直接触发flush MemStore。</p>
<p><a href="https://lihuimintu.github.io/2019/06/27/HBase-IO-Case/">HBase Region 过多导致集群问题事件</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>Yarn 2.8 bulkload HBase</title>
    <url>/bigdata/HBase/yarn-2.8/</url>
    <content><![CDATA[<h1 id="yarn-2-8"><a href="#yarn-2-8" class="headerlink" title="yarn-2.8"></a>yarn-2.8</h1><p>yarn 2.8 访问 hbase 时，会带用户，hbase需要修改配置</p>
<p><img src="vx_images/1201339079498.png"></p>
<p><img src="vx_images/2522922637021.png"></p>
<h2 id="Yarn-2-8"><a href="#Yarn-2-8" class="headerlink" title="Yarn 2.8"></a>Yarn 2.8</h2><p>Spark 写入 SSD HBase，配置后可以正常写入</p>
<property>
        <name>yarn.resourcemanager.principal</name>
        <value>gaiaadmin</value>
</property>]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>HBase</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS Java API</title>
    <url>/bigdata/Hadoop/HDFS-Java-API/</url>
    <content><![CDATA[<p>Hadoop是采用Java实现的，所有的命令和操作全部采用Java完成。<br>HDFS: Hadoop Distributed File System 是Hadoop提供的分布式文件系统。</p>
<p>本文介绍HDFS的Java API </p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>首先，看一个例子:</p>
<h1 id="putMerge-本地文件合并并保存到HDFS"><a href="#putMerge-本地文件合并并保存到HDFS" class="headerlink" title="putMerge: 本地文件合并并保存到HDFS"></a>putMerge: 本地文件合并并保存到HDFS</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * copy files in &lt;code&gt;srcDir&lt;/code&gt; </span></span><br><span class="line"><span class="comment"> * and merge to &lt;code&gt;objectFileName&lt;/code&gt; in HDFS</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> srcDir    本地文件夹</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> objectFileName HDFS文件名</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">putMerge</span><span class="params">(String srcDir, String objectFileName)</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;srcDir:&quot;</span> + srcDir+<span class="string">&quot;\t objDir:&quot;</span> + objectFileName);</span><br><span class="line">    <span class="comment">// 读取HDFS的默认配置, 配置文件主要包括: </span></span><br><span class="line">    <span class="comment">// core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml</span></span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    FileSystem hdfs = <span class="keyword">null</span>;</span><br><span class="line">    LocalFileSystem local = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        hdfs = FileSystem.get(conf);<span class="comment">// 获取HDFS配置的FileSystem</span></span><br><span class="line">        local = FileSystem.getLocal(conf);<span class="comment">// 获取本地配置FileSystem</span></span><br><span class="line">        Path inputDir = <span class="keyword">new</span> Path(srcDir); <span class="comment">// 设定输入目录</span></span><br><span class="line">        System.out.println(<span class="string">&quot;inputDir: &quot;</span> + inputDir);</span><br><span class="line">        System.out.println(<span class="string">&quot;local.homeDirectory: &quot;</span> + local.getHomeDirectory());</span><br><span class="line">        System.out.println(<span class="string">&quot;local.workingDirectory: &quot;</span> + local.getWorkingDirectory());</span><br><span class="line">        System.out.println(<span class="string">&quot;local.uri: &quot;</span> + local.getUri());</span><br><span class="line">        System.out.println(<span class="string">&quot;local.conf: &quot;</span> + local.getConf());</span><br><span class="line"></span><br><span class="line">        FileStatus[] inputFiles = local.listStatus(inputDir);</span><br><span class="line">        System.out.println(<span class="string">&quot;inputFiles: &quot;</span> + inputFiles);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus inputFile : inputFiles) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;inputFile: &quot;</span> + inputFile);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (inputFiles.length == <span class="number">0</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;input file path is empty!&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Path hdfsFile = <span class="keyword">new</span> Path(objectFileName); <span class="comment">// 设定输出文件名称</span></span><br><span class="line">        FSDataOutputStream out = hdfs.create(hdfsFile, <span class="keyword">new</span> Progressable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.print(<span class="string">&quot;*&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus inputFile : inputFiles) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;inputFile.path.name: &quot;</span> + inputFile.getPath().getName());</span><br><span class="line">            FSDataInputStream in = local.open(inputFile.getPath());</span><br><span class="line">            <span class="keyword">byte</span> buffer[] = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">256</span>];</span><br><span class="line">            <span class="keyword">int</span> bytesRead = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span> ((bytesRead = in.read(buffer)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                out.write(buffer, <span class="number">0</span>, bytesRead);</span><br><span class="line">            &#125;</span><br><span class="line">            in.close();</span><br><span class="line">            System.out.println();</span><br><span class="line">        &#125;</span><br><span class="line">        out.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行:</p>
<ol>
<li>打包</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mvn package</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>复制到container</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp ~/IdeaProjects/MyTest/out/artifacts/HadoopTest_jar/HadoopTest.jar hadoop0:/root/putMerge.jar</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>执行</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop jar putMerge.jar en002 en002.txt</span><br></pre></td></tr></table></figure>
<p>执行结果</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">version 1</span><br><span class="line">args:en002</span><br><span class="line">args:en002.txt</span><br><span class="line">srcDir:en002</span><br><span class="line">objDir:en002.txt</span><br><span class="line">inputDir: en002</span><br><span class="line">local.homeDirectory: file:/root</span><br><span class="line">local.workingDirectory: file:/root</span><br><span class="line">local.uri: file:///</span><br><span class="line">local.conf: Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml</span><br><span class="line">inputFiles: [Lorg.apache.hadoop.fs.FileStatus;@4073c6c9</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/shengjing.txt; isDirectory=false; length=4467663; replication=1; blocksize=33554432; modification_time=1495535613000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/at.txt; isDirectory=false; length=829203; replication=1; blocksize=33554432; modification_time=1495535613000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/abc.txt; isDirectory=false; length=0; replication=1; blocksize=33554432; modification_time=1495543277000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/a.txt; isDirectory=false; length=18516; replication=1; blocksize=33554432; modification_time=1495535613000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/av.txt; isDirectory=false; length=189407; replication=1; blocksize=33554432; modification_time=1495535613000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/David.txt; isDirectory=false; length=1519616; replication=1; blocksize=33554432; modification_time=1495535613000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/Oliver.txt; isDirectory=false; length=981553; replication=1; blocksize=33554432; modification_time=1495535613000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/Jane.txt; isDirectory=false; length=1114997; replication=1; blocksize=33554432; modification_time=1495535613000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile: DeprecatedRawLocalFileStatus&#123;path=file:/root/en002/Romeo.txt; isDirectory=false; length=145397; replication=1; blocksize=33554432; modification_time=1495535613000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false&#125;</span><br><span class="line">inputFile.path.name: shengjing.txt</span><br><span class="line"></span><br><span class="line">inputFile.path.name: at.txt</span><br><span class="line">*******</span><br><span class="line">inputFile.path.name: abc.txt</span><br><span class="line"></span><br><span class="line">inputFile.path.name: a.txt</span><br><span class="line"></span><br><span class="line">inputFile.path.name: av.txt</span><br><span class="line">*******</span><br><span class="line">inputFile.path.name: David.txt</span><br><span class="line">******************************************************************</span><br><span class="line">inputFile.path.name: Oliver.txt</span><br><span class="line">***************************</span><br><span class="line">inputFile.path.name: Jane.txt</span><br><span class="line">**********************************</span><br><span class="line">inputFile.path.name: Romeo.txt</span><br><span class="line">**</span><br><span class="line">**</span><br></pre></td></tr></table></figure>
<p>可能出现的问题:</p>
<ol>
<li><code>LocalFileSystem.listStatus</code>返回为 <code>empty</code>, 可能的原因有:<ul>
<li>Hadoop没有权限读取目录或目录中的文件</li>
<li>本地目录中的文件是中文的，而系统不支持显示中文</li>
</ul>
</li>
</ol>
<h1 id="FileSystem"><a href="#FileSystem" class="headerlink" title="FileSystem"></a>FileSystem</h1><p><a href="http://hadoop.apache.org/docs/stable/api/org/apache/hadoop/fs/FileSystem.html">DOCS-FileSystem</a><br>FileSystem 是Hadoop提供的操作本地文件和HDFS中文件的API，可以实现CRUD等操作</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Append to an existing file.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">append</span><span class="params">(Path f)</span> <span class="keyword">throws</span> IOException</span></span><br><span class="line"><span class="function"><span class="comment">/**</span></span></span><br><span class="line"><span class="function"><span class="comment">* Concat existing files together.</span></span></span><br><span class="line"><span class="function"><span class="comment">*/</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">concat</span><span class="params">(Path trg,Path[] psrcs)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">/** </span></span></span><br><span class="line"><span class="function"><span class="comment">* Renames Path src to Path dst. </span></span></span><br><span class="line"><span class="function"><span class="comment">* Can take place on local fs or remote DFS.</span></span></span><br><span class="line"><span class="function"><span class="comment">*/</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">boolean</span> <span class="title">rename</span><span class="params">(Path src, Path dst)</span> <span class="keyword">throws</span> IOException</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br></pre></td></tr></table></figure>








<h2 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">FileSystem fs = FileSystem.get(conf);  </span><br><span class="line">Path path = <span class="keyword">new</span> Path(<span class="string">&quot;/user/hadoop/data/20130709&quot;</span>);  </span><br><span class="line">fs.create(path);  </span><br><span class="line">fs.close();  </span><br></pre></td></tr></table></figure>


<h2 id="删除目录"><a href="#删除目录" class="headerlink" title="删除目录"></a>删除目录</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">FileSystem fs = FileSystem.get(conf);  </span><br><span class="line">Path path = <span class="keyword">new</span> Path(<span class="string">&quot;/user/hadoop/data/20130710&quot;</span>);  </span><br><span class="line">fs.delete(path);  </span><br><span class="line">fs.close(); </span><br></pre></td></tr></table></figure>
<h2 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">FileSystem fs = FileSystem.get(conf);  </span><br><span class="line">Path path = <span class="keyword">new</span> Path(<span class="string">&quot;/user/hadoop/data/write.txt&quot;</span>);  </span><br><span class="line">FSDataOutputStream out = fs.create(path);  </span><br><span class="line">out.writeUTF(<span class="string">&quot;da jia hao,cai shi zhen de hao!&quot;</span>);  </span><br><span class="line">fs.close();</span><br></pre></td></tr></table></figure>
<h2 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">FileSystem fs = FileSystem.get(conf);  </span><br><span class="line">Path path = <span class="keyword">new</span> Path(<span class="string">&quot;/user/hadoop/data/write.txt&quot;</span>);  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span>(fs.exists(path))&#123;  </span><br><span class="line">    FSDataInputStream is = fs.open(path);  </span><br><span class="line">    FileStatus status = fs.getFileStatus(path);  </span><br><span class="line">    <span class="comment">// status.getLen() 返回文件的长度 字节长度</span></span><br><span class="line">    <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[Integer.parseInt(String.valueOf(status.getLen()))];  </span><br><span class="line">    is.readFully(<span class="number">0</span>, buffer);  </span><br><span class="line">    is.close();  </span><br><span class="line">    fs.close();  </span><br><span class="line">    System.out.println(buffer.toString());  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>



<h2 id="上传本地文件到HDFS"><a href="#上传本地文件到HDFS" class="headerlink" title="上传本地文件到HDFS"></a>上传本地文件到HDFS</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">FileSystem fs = FileSystem.get(conf);  </span><br><span class="line">Path src = <span class="keyword">new</span> Path(<span class="string">&quot;/home/hadoop/word.txt&quot;</span>);  </span><br><span class="line">Path dst = <span class="keyword">new</span> Path(<span class="string">&quot;/user/hadoop/data/&quot;</span>);  </span><br><span class="line"><span class="comment">// FileSystem可以直接将本地文件复制到HDFS的制定目录</span></span><br><span class="line">fs.copyFromLocalFile(src, dst);  </span><br><span class="line">fs.close(); </span><br></pre></td></tr></table></figure>
<h2 id="删除文件"><a href="#删除文件" class="headerlink" title="删除文件"></a>删除文件</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">FileSystem fs = FileSystem.get(conf);  </span><br><span class="line"><span class="comment">// 删除文件和目录均是通过FileSystem.delete(Path path)</span></span><br><span class="line">Path path = <span class="keyword">new</span> Path(<span class="string">&quot;/user/hadoop/data/word.txt&quot;</span>);  </span><br><span class="line">fs.delete(path);  </span><br><span class="line">fs.close();</span><br></pre></td></tr></table></figure>

<h2 id="获取给定目录下的所有子目录以及子文件"><a href="#获取给定目录下的所有子目录以及子文件" class="headerlink" title="获取给定目录下的所有子目录以及子文件"></a>获取给定目录下的所有子目录以及子文件</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Configuration conf = <span class="keyword">new</span> Configuration(); </span><br><span class="line">FileSystem fs = FileSystem.get(conf);  </span><br><span class="line">Path path = <span class="keyword">new</span> Path(<span class="string">&quot;/user/hadoop&quot;</span>);  </span><br><span class="line">getFile(path,fs);  </span><br><span class="line"><span class="comment">//fs.close();   </span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getFile</span><span class="params">(Path path,FileSystem fs)</span> <span class="keyword">throws</span> IOException </span>&#123;  </span><br><span class="line">    FileStatus[] fileStatus = fs.listStatus(path);  </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;fileStatus.length;i++)&#123;  </span><br><span class="line">        <span class="keyword">if</span>(fileStatus[i].isDir())&#123;  </span><br><span class="line">            Path p = <span class="keyword">new</span> Path(fileStatus[i].getPath().toString());  </span><br><span class="line">            getFile(p,fs);  </span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;  </span><br><span class="line">            System.out.println(fileStatus[i].getPath().toString());  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="查找某个文件在HDFS集群的位置"><a href="#查找某个文件在HDFS集群的位置" class="headerlink" title="查找某个文件在HDFS集群的位置"></a>查找某个文件在HDFS集群的位置</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 查找某个文件在HDFS集群的位置 </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getFileLocal</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>&#123;  </span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">    FileSystem fs = FileSystem.get(conf);  </span><br><span class="line">    Path path = <span class="keyword">new</span> Path(<span class="string">&quot;/user/hadoop/data/write.txt&quot;</span>);  </span><br><span class="line">      </span><br><span class="line">    FileStatus status = fs.getFileStatus(path);  </span><br><span class="line">    BlockLocation[] locations = fs.getFileBlockLocations(status, <span class="number">0</span>, status.getLen());  </span><br><span class="line">      </span><br><span class="line">    <span class="keyword">int</span> length = locations.length;  </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;length;i++)&#123;  </span><br><span class="line">        String[] hosts = locations[i].getHosts();  </span><br><span class="line">        System.out.println(<span class="string">&quot;block_&quot;</span> + i + <span class="string">&quot;_location:&quot;</span> + hosts[i]);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<h2 id="HDFS集群上所有节点名称信息"><a href="#HDFS集群上所有节点名称信息" class="headerlink" title="HDFS集群上所有节点名称信息"></a>HDFS集群上所有节点名称信息</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * HDFS集群上所有节点名称信息 </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getHDFSNode</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>&#123;  </span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">    FileSystem fs = FileSystem.get(conf);  </span><br><span class="line"></span><br><span class="line">    DistributedFileSystem  dfs = (DistributedFileSystem)fs;  </span><br><span class="line">    DatanodeInfo[] dataNodeStats = dfs.getDataNodeStats();  </span><br><span class="line">      </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;dataNodeStats.length;i++)&#123;  </span><br><span class="line">        System.out.println(<span class="string">&quot;DataNode_&quot;</span> + i + <span class="string">&quot;_Node:&quot;</span> + dataNodeStats[i].getHostName());  </span><br><span class="line">    &#125;  </span><br><span class="line">      </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<h1 id="读写"><a href="#读写" class="headerlink" title="读写"></a>读写</h1><p><code>FSDataInputStream</code> 与 <code>FSDataOutputStream</code></p>
<p><code>FSDataInputStream</code> 扩展了 <code>DataInputStream</code> 以支持随机读</p>
<h2 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h2><ul>
<li><p>TextInputFormat 是 InputFormat 的默认实现, TextInputFormat<br>返回的键是每行的字节偏移量，返回的值是该行的数据。<br>key: LongWritable<br>value: Text</p>
</li>
<li><p><code>KeyValueTextInputFormat</code> 使用分隔符分割每行，分隔符之前的是键，之后的是值。默认的分隔符是制表符(\T)，分离器的属性通过<br><code>key.value.separator.in.input.line</code>中指定</p>
</li>
</ul>
<p>key: Text<br>value: Text</p>
<ul>
<li><code>SequenceFileInputFormat&lt;K,V&gt;</code> 用户自定义的序列化格式, 序列化文件为Hadoop专用的压缩二进制文件格式</li>
</ul>
<p>key: K 用户定义<br>value: V 用户定义</p>
<ul>
<li><code>NLineInputFormat</code> key为分片的偏移量，value为包含N行数据的片段，N通过属性 <code>mapred.line.inout.format.linespermap</code>中指定，默认为1<br>key: LongWritable<br>value: Text</li>
</ul>
<hr>
<p>【参考文献】</p>
<ol>
<li><a href="ref-url" title="ref-alt-title"></a></li>
</ol>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title>【转载】Flink追源索骥</title>
    <url>/bigdata/Flink/%E8%BF%BD%E6%BA%90%E7%B4%A2%E9%AA%A5/</url>
    <content><![CDATA[<h1 id="追源索骥：透过源码看懂Flink核心框架的执行流程"><a href="#追源索骥：透过源码看懂Flink核心框架的执行流程" class="headerlink" title="追源索骥：透过源码看懂Flink核心框架的执行流程"></a>追源索骥：透过源码看懂Flink核心框架的执行流程</h1><p>标签（空格分隔）： flink</p>
<hr>
<p>[TOC]</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Flink是大数据处理领域最近很火的一个开源的分布式、高性能的流式处理框架，其对数据的处理可以达到毫秒级别。本文以一个来自官网的WordCount例子为引，全面阐述flink的核心架构及执行流程，希望读者可以借此更加深入的理解Flink逻辑。</p>
<blockquote>
<p>本文跳过了一些基本概念，如果对相关概念感到迷惑，请参考官网文档。另外在本文写作过程中，Flink正式发布了其1.5 RELEASE版本，在其发布之后完成的内容将按照1.5的实现来组织。</p>
</blockquote>
<h2 id="1-从-Hello-World-WordCount开始"><a href="#1-从-Hello-World-WordCount开始" class="headerlink" title="1.从 Hello,World WordCount开始"></a>1.从 <del>Hello,World</del> WordCount开始</h2><p>首先，我们把WordCount的例子再放一遍：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SocketTextStreamWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (args.length != <span class="number">2</span>)&#123;</span><br><span class="line">		System.err.println(<span class="string">&quot;USAGE:\nSocketTextStreamWordCount &lt;hostname&gt; &lt;port&gt;&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	String hostName = args[<span class="number">0</span>];</span><br><span class="line">	Integer port = Integer.parseInt(args[<span class="number">1</span>]);</span><br><span class="line">	<span class="comment">// set up the execution environment</span></span><br><span class="line">	<span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment</span><br><span class="line">			.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// get input data</span></span><br><span class="line">	DataStream&lt;String&gt; text = env.socketTextStream(hostName, port);</span><br><span class="line">	</span><br><span class="line">	text.flatMap(<span class="keyword">new</span> LineSplitter()).setParallelism(<span class="number">1</span>)</span><br><span class="line">	<span class="comment">// group by the tuple field &quot;0&quot; and sum up tuple field &quot;1&quot;</span></span><br><span class="line">			.keyBy(<span class="number">0</span>)</span><br><span class="line">			.sum(<span class="number">1</span>).setParallelism(<span class="number">1</span>)</span><br><span class="line">			.print();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// execute program</span></span><br><span class="line">	env.execute(<span class="string">&quot;Java WordCount from SocketTextStream Example&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Implements the string tokenizer that splits sentences into words as a user-defined</span></span><br><span class="line"><span class="comment">	 * FlatMapFunction. The function takes a line (String) and splits it into</span></span><br><span class="line"><span class="comment">	 * multiple pairs in the form of &quot;(word,1)&quot; (Tuple2&amp;lt;String, Integer&amp;gt;).</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">LineSplitter</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">			<span class="comment">// normalize and split the line</span></span><br><span class="line">			String[] tokens = value.toLowerCase().split(<span class="string">&quot;\\W+&quot;</span>);</span><br><span class="line">			<span class="comment">// emit the pairs</span></span><br><span class="line">			<span class="keyword">for</span> (String token : tokens) &#123;</span><br><span class="line">				<span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">					out.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(token, <span class="number">1</span>));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>首先从命令行中获取socket对端的ip和端口，然后启动一个执行环境，从socket中读取数据，split成单个单词的流，并按单词进行总和的计数，最后打印出来。这个例子相信接触过大数据计算或者函数式编程的人都能看懂，就不过多解释了。</p>
<h3 id="1-1-flink执行环境"><a href="#1-1-flink执行环境" class="headerlink" title="1.1 flink执行环境"></a>1.1 flink执行环境</h3><p>程序的启动，从这句开始：<code> final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()</code>。<br>这行代码会返回一个可用的执行环境。执行环境是整个flink程序执行的上下文，记录了相关配置（如并行度等），并提供了一系列方法，如读取输入流的方法，以及真正开始运行整个代码的execute方法等。对于分布式流处理程序来说，我们在代码中定义的flatMap,keyBy等等操作，事实上可以理解为一种声明，告诉整个程序我们采用了什么样的算子，而真正开启计算的代码不在此处。由于我们是在本地运行flink程序，因此这行代码会返回一个LocalStreamEnvironment，最后我们要调用它的execute方法来开启真正的任务。我们先接着往下看。</p>
<h3 id="1-2-算子（Operator）的注册（声明）"><a href="#1-2-算子（Operator）的注册（声明）" class="headerlink" title="1.2 算子（Operator）的注册（声明）"></a>1.2 算子（Operator）的注册（声明）</h3><p>我们以flatMap为例,<code>text.flatMap(new LineSplitter())</code>这一句话跟踪进去是这样的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">flatMap</span><span class="params">(FlatMapFunction&lt;T, R&gt; flatMapper)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">		TypeInformation&lt;R&gt; outType = TypeExtractor.getFlatMapReturnTypes(clean(flatMapper),</span><br><span class="line">				getType(), Utils.getCallLocationName(), <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> transform(<span class="string">&quot;Flat Map&quot;</span>, outType, <span class="keyword">new</span> StreamFlatMap&lt;&gt;(clean(flatMapper)));</span><br><span class="line"></span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>里面完成了两件事，一是用反射拿到了flatMap算子的输出类型，二是生成了一个Operator。flink流式计算的核心概念，就是将数据从输入流一个个传递给Operator进行链式处理，最后交给输出流的过程。对数据的每一次处理在逻辑上成为一个operator，并且为了本地化处理的效率起见，operator之间也可以串成一个chain一起处理（可以参考责任链模式帮助理解）。下面这张图表明了flink是如何看待用户的处理流程的：抽象化为一系列operator，以source开始，以sink结尾，中间的operator做的操作叫做transform，并且可以把几个操作串在一起执行。<br><img src="http://static.zybuluo.com/bethunebtj/jal2x1y6zqs4jug4ryqnvu3l/image_1cae39t06eoo3ml1be8o0412c69.png" alt="image_1cae39t06eoo3ml1be8o0412c69.png-43.5kB"><br>我们也可以更改flink的设置，要求它不要对某个操作进行chain处理，或者从某个操作开启一个新chain等。<br>上面代码中的最后一行transform方法的作用是返回一个SingleOutputStreamOperator，它继承了Datastream类并且定义了一些辅助方法，方便对流的操作。在返回之前，transform方法还把它注册到了执行环境中（后面生成执行图的时候还会用到它）。其他的操作，包括keyBy，sum和print，都只是不同的算子，在这里出现都是一样的效果，即生成一个operator并注册给执行环境用于生成DAG。</p>
<h3 id="1-3-程序的执行"><a href="#1-3-程序的执行" class="headerlink" title="1.3 程序的执行"></a>1.3 程序的执行</h3><p>程序执行即<code>env.execute(&quot;Java WordCount from SocketTextStream Example&quot;)</code>这行代码。</p>
<h4 id="1-3-1-本地模式下的execute方法"><a href="#1-3-1-本地模式下的execute方法" class="headerlink" title="1.3.1 本地模式下的execute方法"></a>1.3.1 本地模式下的execute方法</h4><p>这行代码主要做了以下事情：</p>
<ul>
<li>生成StreamGraph。代表程序的拓扑结构，是从用户代码直接生成的图。</li>
<li>生成JobGraph。这个图是要交给flink去生成task的图。</li>
<li>生成一系列配置</li>
<li>将JobGraph和配置交给flink集群去运行。如果不是本地运行的话，还会把jar文件通过网络发给其他节点。</li>
<li>以本地模式运行的话，可以看到启动过程，如启动性能度量、web模块、JobManager、ResourceManager、taskManager等等</li>
<li>启动任务。值得一提的是在启动任务之前，先启动了一个用户类加载器，这个类加载器可以用来做一些在运行时动态加载类的工作。</li>
</ul>
<h4 id="1-3-2-远程模式（RemoteEnvironment）的execute方法"><a href="#1-3-2-远程模式（RemoteEnvironment）的execute方法" class="headerlink" title="1.3.2 远程模式（RemoteEnvironment）的execute方法"></a>1.3.2 远程模式（RemoteEnvironment）的execute方法</h4><p>远程模式的程序执行更加有趣一点。第一步仍然是获取StreamGraph，然后调用executeRemotely方法进行远程执行。<br>该方法首先创建一个用户代码加载器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ClassLoader usercodeClassLoader = JobWithJars.buildUserCodeClassLoader(jarFiles, globalClasspaths,   getClass().getClassLoader());</span><br></pre></td></tr></table></figure>
<p>然后创建一系列配置，交给Client对象。Client这个词有意思，看见它就知道这里绝对是跟远程集群打交道的客户端。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ClusterClient client;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	client = <span class="keyword">new</span> StandaloneClusterClient(configuration);</span><br><span class="line">	client.setPrintStatusDuringExecution(getConfig().isSysoutLoggingEnabled());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> client.run(streamGraph, jarFiles, globalClasspaths, usercodeClassLoader).getJobExecutionResult();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>client的run方法首先生成一个JobGraph，然后将其传递给JobClient。关于Client、JobClient、JobManager到底谁管谁，可以看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/6hhl3e1fumlr0aq78d2m35nt/image_1cae7g15p6k94no1ves121c5pd9.png" alt="image_1cae7g15p6k94no1ves121c5pd9.png-19.7kB"><br>确切的说，JobClient负责以异步的方式和JobManager通信（Actor是scala的异步模块），具体的通信任务由JobClientActor完成。相对应的，JobManager的通信任务也由一个Actor完成。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JobListeningContext jobListeningContext = submitJob(actorSystem, config, highAvailabilityServices, jobGraph, timeout, sysoutLogUpdates,	classLoader);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> awaitJobResult(jobListeningContext);</span><br></pre></td></tr></table></figure>
<p>可以看到，该方法阻塞在awaitJobResult方法上，并最终返回了一个JobListeningContext，透过这个Context可以得到程序运行的状态和结果。</p>
<h4 id="1-3-3-程序启动过程"><a href="#1-3-3-程序启动过程" class="headerlink" title="1.3.3 程序启动过程"></a>1.3.3 程序启动过程</h4><p>上面提到，整个程序真正意义上开始执行，是这里：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.execute(<span class="string">&quot;Java WordCount from SocketTextStream Example&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>远程模式和本地模式有一点不同，我们先按本地模式来调试。<br>我们跟进源码，（在本地调试模式下）会启动一个miniCluster，然后开始执行代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// LocalStreamEnvironment.java</span></span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">execute</span><span class="params">(String jobName)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//生成各种图结构</span></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">		    <span class="comment">//启动集群，包括启动JobMaster，进行leader选举等等</span></span><br><span class="line">			miniCluster.start();</span><br><span class="line">			configuration.setInteger(RestOptions.PORT, miniCluster.getRestAddress().getPort());</span><br><span class="line">            </span><br><span class="line">            <span class="comment">//提交任务到JobMaster</span></span><br><span class="line">			<span class="keyword">return</span> miniCluster.executeJobBlocking(jobGraph);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">finally</span> &#123;</span><br><span class="line">			transformations.clear();</span><br><span class="line">			miniCluster.close();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>这个方法里有一部分逻辑是与生成图结构相关的，我们放在第二章里讲；现在我们先接着往里跟：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//MiniCluster.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">executeJobBlocking</span><span class="params">(JobGraph job)</span> <span class="keyword">throws</span> JobExecutionException, InterruptedException </span>&#123;</span><br><span class="line">		checkNotNull(job, <span class="string">&quot;job is null&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//在这里，最终把job提交给了jobMaster</span></span><br><span class="line">		<span class="keyword">final</span> CompletableFuture&lt;JobSubmissionResult&gt; submissionFuture = submitJob(job);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">final</span> CompletableFuture&lt;JobResult&gt; jobResultFuture = submissionFuture.thenCompose(</span><br><span class="line">			(JobSubmissionResult ignored) -&gt; requestJobResult(job.getJobID()));</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>正如我在注释里写的，这一段代码核心逻辑就是调用那个<code>submitJob</code>方法。那么我们再接着看这个方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;JobSubmissionResult&gt; <span class="title">submitJob</span><span class="params">(JobGraph jobGraph)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">final</span> DispatcherGateway dispatcherGateway;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		dispatcherGateway = getDispatcherGateway();</span><br><span class="line">	&#125; <span class="keyword">catch</span> (LeaderRetrievalException | InterruptedException e) &#123;</span><br><span class="line">		ExceptionUtils.checkInterrupted(e);</span><br><span class="line">		<span class="keyword">return</span> FutureUtils.completedExceptionally(e);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// we have to allow queued scheduling in Flip-6 mode because we need to request slots</span></span><br><span class="line">	<span class="comment">// from the ResourceManager</span></span><br><span class="line">	jobGraph.setAllowQueuedScheduling(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Void&gt; jarUploadFuture = uploadAndSetJarFiles(dispatcherGateway, jobGraph);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; acknowledgeCompletableFuture = jarUploadFuture.thenCompose(</span><br><span class="line">	</span><br><span class="line">	<span class="comment">//在这里执行了真正的submit操作</span></span><br><span class="line">		(Void ack) -&gt; dispatcherGateway.submitJob(jobGraph, rpcTimeout));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> acknowledgeCompletableFuture.thenApply(</span><br><span class="line">		(Acknowledge ignored) -&gt; <span class="keyword">new</span> JobSubmissionResult(jobGraph.getJobID()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的<code>Dispatcher</code>是一个接收job，然后指派JobMaster去启动任务的类,我们可以看看它的类结构，有两个实现。在本地环境下启动的是<code>MiniDispatcher</code>，在集群上提交任务时，集群上启动的是<code>StandaloneDispatcher</code>。</p>
<p><img src="http://static.zybuluo.com/bethunebtj/y9hjeinc58dqc7wiepv2iim4/image_1cenfj3p9fp110p0a8unn1mrh9.png" alt="image_1cenfj3p9fp110p0a8unn1mrh9.png-27.4kB"></p>
<p>那么这个Dispatcher又做了什么呢？它启动了一个<code>JobManagerRunner</code>（这里我要吐槽Flink的命名，这个东西应该叫做JobMasterRunner才对，flink里的JobMaster和JobManager不是一个东西），委托JobManagerRunner去启动该Job的<code>JobMaster</code>。我们看一下对应的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//jobManagerRunner.java</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">verifyJobSchedulingStatusAndStartJobManager</span><span class="params">(UUID leaderSessionId)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">	    <span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; startFuture = jobMaster.start(<span class="keyword">new</span> JobMasterId(leaderSessionId), rpcTimeout);</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>然后，JobMaster经过了一堆方法嵌套之后，执行到了这里：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">scheduleExecutionGraph</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	checkState(jobStatusListener == <span class="keyword">null</span>);</span><br><span class="line">	<span class="comment">// register self as job status change listener</span></span><br><span class="line">	jobStatusListener = <span class="keyword">new</span> JobManagerJobStatusListener();</span><br><span class="line">	executionGraph.registerJobStatusListener(jobStatusListener);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">	    <span class="comment">//这里调用了ExecutionGraph的启动方法</span></span><br><span class="line">		executionGraph.scheduleForExecution();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">		executionGraph.failGlobal(t);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们知道，flink的框架里有三层图结构，其中ExecutionGraph就是真正被执行的那一层，所以到这里为止，一个任务从提交到真正执行的流程就走完了，我们再回顾一下（顺便提一下远程提交时的流程区别）：</p>
<ul>
<li>客户端代码的execute方法执行；</li>
<li>本地环境下，MiniCluster完成了大部分任务，直接把任务委派给了MiniDispatcher；</li>
<li>远程环境下，启动了一个<code>RestClusterClient</code>，这个类会以HTTP Rest的方式把用户代码提交到集群上；</li>
<li>远程环境下，请求发到集群上之后，必然有个handler去处理，在这里是<code>JobSubmitHandler</code>。这个类接手了请求后，委派StandaloneDispatcher启动job，到这里之后，本地提交和远程提交的逻辑往后又统一了；</li>
<li>Dispatcher接手job之后，会实例化一个<code>JobManagerRunner</code>，然后用这个runner启动job；</li>
<li>JobManagerRunner接下来把job交给了<code>JobMaster</code>去处理；</li>
<li>JobMaster使用<code>ExecutionGraph</code>的方法启动了整个执行图；整个任务就启动起来了。</li>
</ul>
<p>至此，第一部分就讲完了。</p>
<h2 id="2-理解flink的图结构"><a href="#2-理解flink的图结构" class="headerlink" title="2.理解flink的图结构"></a>2.理解flink的图结构</h2><p>第一部分讲到，我们的主函数最后一项任务就是生成StreamGraph，然后生成JobGraph，然后以此开始调度任务运行，所以接下来我们从这里入手，继续探索flink。</p>
<h3 id="2-1-flink的三层图结构"><a href="#2-1-flink的三层图结构" class="headerlink" title="2.1 flink的三层图结构"></a>2.1 flink的三层图结构</h3><p>事实上，flink总共提供了三种图的抽象，我们前面已经提到了StreamGraph和JobGraph，还有一种是ExecutionGraph，是用于调度的基本数据结构。<br><img src="http://static.zybuluo.com/bethunebtj/nseitc0kyuq0n44s7qcp6ij9/image_1caf1oll019fp1odv1bh9idosr79.png" alt="image_1caf1oll019fp1odv1bh9idosr79.png-486.3kB"><br>上面这张图清晰的给出了flink各个图的工作原理和转换过程。其中最后一个物理执行图并非flink的数据结构，而是程序开始执行后，各个task分布在不同的节点上，所形成的物理上的关系表示。</p>
<ul>
<li>从JobGraph的图里可以看到，数据从上一个operator流到下一个operator的过程中，上游作为生产者提供了IntermediateDataSet，而下游作为消费者需要JobEdge。事实上，JobEdge是一个通信管道，连接了上游生产的dataset和下游的JobVertex节点。</li>
<li>在JobGraph转换到ExecutionGraph的过程中，主要发生了以下转变：</li>
<li> 加入了并行度的概念，成为真正可调度的图结构</li>
<li> 生成了与JobVertex对应的ExecutionJobVertex，ExecutionVertex，与IntermediateDataSet对应的IntermediateResult和IntermediateResultPartition等，并行将通过这些类实现</li>
<li>ExecutionGraph已经可以用于调度任务。我们可以看到，flink根据该图生成了一一对应的Task，每个task对应一个ExecutionGraph的一个Execution。Task用InputGate、InputChannel和ResultPartition对应了上面图中的IntermediateResult和ExecutionEdge。</li>
</ul>
<p>那么，flink抽象出这三层图结构，四层执行逻辑的意义是什么呢？<br>StreamGraph是对用户逻辑的映射。JobGraph在此基础上进行了一些优化，比如把一部分操作串成chain以提高效率。ExecutionGraph是为了调度存在的，加入了并行处理的概念。而在此基础上真正执行的是Task及其相关结构。</p>
<h3 id="2-2-StreamGraph的生成"><a href="#2-2-StreamGraph的生成" class="headerlink" title="2.2 StreamGraph的生成"></a>2.2 StreamGraph的生成</h3><p>在第一节的算子注册部分，我们可以看到，flink把每一个算子transform成一个对流的转换（比如上文中返回的SingleOutputStreamOperator是一个DataStream的子类），并且注册到执行环境中，用于生成StreamGraph。实际生成StreamGraph的入口是<code>StreamGraphGenerator.generate(env, transformations)</code> 其中的transformations是一个list，里面记录的就是我们在transform方法中放进来的算子。</p>
<h4 id="2-2-1-StreamTransformation类代表了流的转换"><a href="#2-2-1-StreamTransformation类代表了流的转换" class="headerlink" title="2.2.1 StreamTransformation类代表了流的转换"></a>2.2.1 StreamTransformation类代表了流的转换</h4><p>StreamTransformation代表了从一个或多个DataStream生成新DataStream的操作。顺便，DataStream类在内部组合了一个StreamTransformation类，实际的转换操作均通过该类完成。<br><img src="http://static.zybuluo.com/bethunebtj/69v9syr2p5k5om3c4jox9wh0/image_1caf64b7c1gjnv2eebi1v9e1cvum.png" alt="image_1caf64b7c1gjnv2eebi1v9e1cvum.png-129.4kB"><br>我们可以看到，从source到各种map,union再到sink操作全部被映射成了StreamTransformation。<br>其映射过程如下所示：<br><img src="http://static.zybuluo.com/bethunebtj/a8sjspg8agzl3utnncntds9q/image_1caf6ak4rkqsc1u1hci93fe0d13.png" alt="image_1caf6ak4rkqsc1u1hci93fe0d13.png-36.6kB"></p>
<p>以MapFunction为例：</p>
<ul>
<li><p>首先，用户代码里定义的UDF会被当作其基类对待，然后交给StreamMap这个operator做进一步包装。事实上，每一个Transformation都对应了一个StreamOperator。</p>
</li>
<li><p>由于map这个操作只接受一个输入，所以再被进一步包装为OneInputTransformation。</p>
</li>
<li><p>最后，将该transformation注册到执行环境中，当执行上文提到的generate方法时，生成StreamGraph图结构。</p>
<blockquote>
<p>另外，并不是每一个 StreamTransformation 都会转换成runtime层中的物理操作。有一些只是逻辑概念，比如union、split/select、partition等。如下图所示的转换树，在运行时会优化成下方的操作图。<br><img src="http://static.zybuluo.com/bethunebtj/6zmlsivd9cjdm5nhsacuk3o1/image_1caf71h79s0s3fodem1aeb1j3m1g.png" alt="image_1caf71h79s0s3fodem1aeb1j3m1g.png-83.8kB"></p>
</blockquote>
</li>
</ul>
<h4 id="2-2-2-StreamGraph生成函数分析"><a href="#2-2-2-StreamGraph生成函数分析" class="headerlink" title="2.2.2 StreamGraph生成函数分析"></a>2.2.2 StreamGraph生成函数分析</h4><p>我们从StreamGraphGenerator.generate()方法往下看：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static StreamGraph generate(StreamExecutionEnvironment env, List&lt;StreamTransformation&lt;?&gt;&gt; transformations) &#123;</span><br><span class="line">	return new StreamGraphGenerator(env).generateInternal(transformations);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">   &#x2F;&#x2F;注意，StreamGraph的生成是从sink开始的</span><br><span class="line">private StreamGraph generateInternal(List&lt;StreamTransformation&lt;?&gt;&gt; transformations) &#123;</span><br><span class="line">	for (StreamTransformation&lt;?&gt; transformation: transformations) &#123;</span><br><span class="line">		transform(transformation);</span><br><span class="line">	&#125;</span><br><span class="line">	return streamGraph;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;这个方法的核心逻辑就是判断传入的steamOperator是哪种类型，并执行相应的操作，详情见下面那一大堆if-else</span><br><span class="line">private Collection&lt;Integer&gt; transform(StreamTransformation&lt;?&gt; transform) &#123;</span><br><span class="line"></span><br><span class="line">	if (alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">		return alreadyTransformed.get(transform);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	LOG.debug(&quot;Transforming &quot; + transform);</span><br><span class="line"></span><br><span class="line">	if (transform.getMaxParallelism() &lt;&#x3D; 0) &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; if the max parallelism hasn&#39;t been set, then first use the job wide max parallelism</span><br><span class="line">		&#x2F;&#x2F; from theExecutionConfig.</span><br><span class="line">		int globalMaxParallelismFromConfig &#x3D; env.getConfig().getMaxParallelism();</span><br><span class="line">		if (globalMaxParallelismFromConfig &gt; 0) &#123;</span><br><span class="line">			transform.setMaxParallelism(globalMaxParallelismFromConfig);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; call at least once to trigger exceptions about MissingTypeInfo</span><br><span class="line">	transform.getOutputType();</span><br><span class="line"></span><br><span class="line">	Collection&lt;Integer&gt; transformedIds;</span><br><span class="line">	&#x2F;&#x2F;这里对操作符的类型进行判断，并以此调用相应的处理逻辑.简而言之，处理的核心无非是递归的将该节点和节点的上游节点加入图</span><br><span class="line">	if (transform instanceof OneInputTransformation&lt;?, ?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformOneInputTransform((OneInputTransformation&lt;?, ?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof TwoInputTransformation&lt;?, ?, ?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformTwoInputTransform((TwoInputTransformation&lt;?, ?, ?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SourceTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSource((SourceTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SinkTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSink((SinkTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof UnionTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformUnion((UnionTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SplitTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSplit((SplitTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SelectTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSelect((SelectTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof FeedbackTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformFeedback((FeedbackTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof CoFeedbackTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformCoFeedback((CoFeedbackTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof PartitionTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformPartition((PartitionTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SideOutputTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSideOutput((SideOutputTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		throw new IllegalStateException(&quot;Unknown transformation: &quot; + transform);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F;注意这里和函数开始时的方法相对应，在有向图中要注意避免循环的产生</span><br><span class="line">	&#x2F;&#x2F; need this check because the iterate transformation adds itself before</span><br><span class="line">	&#x2F;&#x2F; transforming the feedback edges</span><br><span class="line">	if (!alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">		alreadyTransformed.put(transform, transformedIds);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (transform.getBufferTimeout() &gt; 0) &#123;</span><br><span class="line">		streamGraph.setBufferTimeout(transform.getId(), transform.getBufferTimeout());</span><br><span class="line">	&#125;</span><br><span class="line">	if (transform.getUid() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setTransformationUID(transform.getId(), transform.getUid());</span><br><span class="line">	&#125;</span><br><span class="line">	if (transform.getUserProvidedNodeHash() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setTransformationUserHash(transform.getId(), transform.getUserProvidedNodeHash());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (transform.getMinResources() !&#x3D; null &amp;&amp; transform.getPreferredResources() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setResources(transform.getId(), transform.getMinResources(), transform.getPreferredResources());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return transformedIds;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为map，filter等常用操作都是OneInputStreamOperator,我们就来看看<code>transformOneInputTransform((OneInputTransformation&lt;?, ?&gt;) transform)</code>方法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private &lt;IN, OUT&gt; Collection&lt;Integer&gt; transformOneInputTransform(OneInputTransformation&lt;IN, OUT&gt; transform) &#123;</span><br><span class="line"></span><br><span class="line">		Collection&lt;Integer&gt; inputIds &#x3D; transform(transform.getInput());</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 在递归处理节点过程中，某个节点可能已经被其他子节点先处理过了，需要跳过</span><br><span class="line">		if (alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">			return alreadyTransformed.get(transform);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;这里是获取slotSharingGroup。这个group用来定义当前我们在处理的这个操作符可以跟什么操作符chain到一个slot里进行操作</span><br><span class="line">        &#x2F;&#x2F;因为有时候我们可能不满意flink替我们做的chain聚合</span><br><span class="line">        &#x2F;&#x2F;一个slot就是一个执行task的基本容器</span><br><span class="line">		String slotSharingGroup &#x3D; determineSlotSharingGroup(transform.getSlotSharingGroup(), inputIds);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;把该operator加入图</span><br><span class="line">		streamGraph.addOperator(transform.getId(),</span><br><span class="line">				slotSharingGroup,</span><br><span class="line">				transform.getOperator(),</span><br><span class="line">				transform.getInputType(),</span><br><span class="line">				transform.getOutputType(),</span><br><span class="line">				transform.getName());</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F;对于keyedStream，我们还要记录它的keySelector方法</span><br><span class="line">        &#x2F;&#x2F;flink并不真正为每个keyedStream保存一个key，而是每次需要用到key的时候都使用keySelector方法进行计算</span><br><span class="line">        &#x2F;&#x2F;因此，我们自定义的keySelector方法需要保证幂等性</span><br><span class="line">        &#x2F;&#x2F;到后面介绍keyGroup的时候我们还会再次提到这一点</span><br><span class="line">		if (transform.getStateKeySelector() !&#x3D; null) &#123;</span><br><span class="line">			TypeSerializer&lt;?&gt; keySerializer &#x3D; transform.getStateKeyType().createSerializer(env.getConfig());</span><br><span class="line">			streamGraph.setOneInputStateKey(transform.getId(), transform.getStateKeySelector(), keySerializer);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		streamGraph.setParallelism(transform.getId(), transform.getParallelism());</span><br><span class="line">		streamGraph.setMaxParallelism(transform.getId(), transform.getMaxParallelism());</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F;为当前节点和它的依赖节点建立边</span><br><span class="line">        &#x2F;&#x2F;这里可以看到之前提到的select union partition等逻辑节点被合并入edge的过程</span><br><span class="line">		for (Integer inputId: inputIds) &#123;</span><br><span class="line">			streamGraph.addEdge(inputId, transform.getId(), 0);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return Collections.singleton(transform.getId());</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	public void addEdge(Integer upStreamVertexID, Integer downStreamVertexID, int typeNumber) &#123;</span><br><span class="line">		addEdgeInternal(upStreamVertexID,</span><br><span class="line">				downStreamVertexID,</span><br><span class="line">				typeNumber,</span><br><span class="line">				null,</span><br><span class="line">				new ArrayList&lt;String&gt;(),</span><br><span class="line">				null);</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">    &#x2F;&#x2F;addEdge的实现，会合并一些逻辑节点</span><br><span class="line">	private void addEdgeInternal(Integer upStreamVertexID,</span><br><span class="line">			Integer downStreamVertexID,</span><br><span class="line">			int typeNumber,</span><br><span class="line">			StreamPartitioner&lt;?&gt; partitioner,</span><br><span class="line">			List&lt;String&gt; outputNames,</span><br><span class="line">			OutputTag outputTag) &#123;</span><br><span class="line">        &#x2F;&#x2F;如果输入边是侧输出节点，则把side的输入边作为本节点的输入边，并递归调用</span><br><span class="line">		if (virtualSideOutputNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualSideOutputNodes.get(virtualId).f0;</span><br><span class="line">			if (outputTag &#x3D;&#x3D; null) &#123;</span><br><span class="line">				outputTag &#x3D; virtualSideOutputNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, null, outputTag);</span><br><span class="line">			&#x2F;&#x2F;如果输入边是select，则把select的输入边作为本节点的输入边</span><br><span class="line">		&#125; else if (virtualSelectNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualSelectNodes.get(virtualId).f0;</span><br><span class="line">			if (outputNames.isEmpty()) &#123;</span><br><span class="line">				&#x2F;&#x2F; selections that happen downstream override earlier selections</span><br><span class="line">				outputNames &#x3D; virtualSelectNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, outputNames, outputTag);</span><br><span class="line">			&#x2F;&#x2F;如果是partition节点</span><br><span class="line">		&#125; else if (virtualPartitionNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualPartitionNodes.get(virtualId).f0;</span><br><span class="line">			if (partitioner &#x3D;&#x3D; null) &#123;</span><br><span class="line">				partitioner &#x3D; virtualPartitionNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, outputNames, outputTag);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">		&#x2F;&#x2F;正常的edge处理逻辑</span><br><span class="line">			StreamNode upstreamNode &#x3D; getStreamNode(upStreamVertexID);</span><br><span class="line">			StreamNode downstreamNode &#x3D; getStreamNode(downStreamVertexID);</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; If no partitioner was specified and the parallelism of upstream and downstream</span><br><span class="line">			&#x2F;&#x2F; operator matches use forward partitioning, use rebalance otherwise.</span><br><span class="line">			if (partitioner &#x3D;&#x3D; null &amp;&amp; upstreamNode.getParallelism() &#x3D;&#x3D; downstreamNode.getParallelism()) &#123;</span><br><span class="line">				partitioner &#x3D; new ForwardPartitioner&lt;Object&gt;();</span><br><span class="line">			&#125; else if (partitioner &#x3D;&#x3D; null) &#123;</span><br><span class="line">				partitioner &#x3D; new RebalancePartitioner&lt;Object&gt;();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (partitioner instanceof ForwardPartitioner) &#123;</span><br><span class="line">				if (upstreamNode.getParallelism() !&#x3D; downstreamNode.getParallelism()) &#123;</span><br><span class="line">					throw new UnsupportedOperationException(&quot;Forward partitioning does not allow &quot; +</span><br><span class="line">							&quot;change of parallelism. Upstream operation: &quot; + upstreamNode + &quot; parallelism: &quot; + upstreamNode.getParallelism() +</span><br><span class="line">							&quot;, downstream operation: &quot; + downstreamNode + &quot; parallelism: &quot; + downstreamNode.getParallelism() +</span><br><span class="line">							&quot; You must use another partitioning strategy, such as broadcast, rebalance, shuffle or global.&quot;);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			StreamEdge edge &#x3D; new StreamEdge(upstreamNode, downstreamNode, typeNumber, outputNames, partitioner, outputTag);</span><br><span class="line"></span><br><span class="line">			getStreamNode(edge.getSourceId()).addOutEdge(edge);</span><br><span class="line">			getStreamNode(edge.getTargetId()).addInEdge(edge);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-2-3-WordCount函数的StreamGraph"><a href="#2-2-3-WordCount函数的StreamGraph" class="headerlink" title="2.2.3 WordCount函数的StreamGraph"></a>2.2.3 WordCount函数的StreamGraph</h4><p>flink提供了一个StreamGraph可视化显示工具，<a href="http://flink.apache.org/visualizer/">在这里</a><br>我们可以把我们的程序的执行计划打印出来<code>System.out.println(env.getExecutionPlan());</code> 复制到这个网站上，点击生成，如图所示：<br><img src="http://static.zybuluo.com/bethunebtj/sfckex3xgu33m3srk2bc5hgk/image_1cafgsliu1n2n1uj21p971b0h6m71t.png" alt="image_1cafgsliu1n2n1uj21p971b0h6m71t.png-25.7kB"><br>可以看到，我们源程序被转化成了4个operator。<br>另外，在operator之间的连线上也显示出了flink添加的一些逻辑流程。由于我设定了每个操作符的并行度都是1，所以在每个操作符之间都是直接FORWARD，不存在shuffle的过程。</p>
<h3 id="2-3-JobGraph的生成"><a href="#2-3-JobGraph的生成" class="headerlink" title="2.3 JobGraph的生成"></a>2.3 JobGraph的生成</h3><p>flink会根据上一步生成的StreamGraph生成JobGraph，然后将JobGraph发送到server端进行ExecutionGraph的解析。</p>
<h4 id="2-3-1-JobGraph生成源码"><a href="#2-3-1-JobGraph生成源码" class="headerlink" title="2.3.1 JobGraph生成源码"></a>2.3.1 JobGraph生成源码</h4><p>与StreamGraph类似，JobGraph的入口方法是<code>StreamingJobGraphGenerator.createJobGraph()</code>。我们直接来看源码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private JobGraph createJobGraph() &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 设置启动模式为所有节点均在一开始就启动</span><br><span class="line">		jobGraph.setScheduleMode(ScheduleMode.EAGER);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 为每个节点生成hash id</span><br><span class="line">		Map&lt;Integer, byte[]&gt; hashes &#x3D; defaultStreamGraphHasher.traverseStreamGraphAndGenerateHashes(streamGraph);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 为了保持兼容性创建的hash</span><br><span class="line">		List&lt;Map&lt;Integer, byte[]&gt;&gt; legacyHashes &#x3D; new ArrayList&lt;&gt;(legacyStreamGraphHashers.size());</span><br><span class="line">		for (StreamGraphHasher hasher : legacyStreamGraphHashers) &#123;</span><br><span class="line">			legacyHashes.add(hasher.traverseStreamGraphAndGenerateHashes(streamGraph));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		Map&lt;Integer, List&lt;Tuple2&lt;byte[], byte[]&gt;&gt;&gt; chainedOperatorHashes &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        &#x2F;&#x2F;生成jobvertex，串成chain等</span><br><span class="line">        &#x2F;&#x2F;这里的逻辑大致可以理解为，挨个遍历节点，如果该节点是一个chain的头节点，就生成一个JobVertex，如果不是头节点，就要把自身配置并入头节点，然后把头节点和自己的出边相连；对于不能chain的节点，当作只有头节点处理即可</span><br><span class="line">		setChaining(hashes, legacyHashes, chainedOperatorHashes);</span><br><span class="line">        &#x2F;&#x2F;设置输入边edge</span><br><span class="line">		setPhysicalEdges();</span><br><span class="line">        &#x2F;&#x2F;设置slot共享group</span><br><span class="line">		setSlotSharing();</span><br><span class="line">        &#x2F;&#x2F;配置检查点</span><br><span class="line">		configureCheckpointing();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 如果有之前的缓存文件的配置的话，重新读入</span><br><span class="line">		for (Tuple2&lt;String, DistributedCache.DistributedCacheEntry&gt; e : streamGraph.getEnvironment().getCachedFiles()) &#123;</span><br><span class="line">			DistributedCache.writeFileInfoToConfig(e.f0, e.f1, jobGraph.getJobConfiguration());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 传递执行环境配置</span><br><span class="line">		try &#123;</span><br><span class="line">			jobGraph.setExecutionConfig(streamGraph.getExecutionConfig());</span><br><span class="line">		&#125;</span><br><span class="line">		catch (IOException e) &#123;</span><br><span class="line">			throw new IllegalConfigurationException(&quot;Could not serialize the ExecutionConfig.&quot; +</span><br><span class="line">					&quot;This indicates that non-serializable types (like custom serializers) were registered&quot;);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return jobGraph;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-3-2-operator-chain的逻辑"><a href="#2-3-2-operator-chain的逻辑" class="headerlink" title="2.3.2 operator chain的逻辑"></a>2.3.2 operator chain的逻辑</h4><blockquote>
<p>为了更高效地分布式执行，Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。将operators链接成task是非常有效的优化：它能减少线程之间的切换，减少消息的序列化/反序列化，减少数据在缓冲区的交换，减少了延迟的同时提高整体的吞吐量。</p>
</blockquote>
<p><img src="http://static.zybuluo.com/bethunebtj/jcjalvv130ex52vkglkt56r2/image_1cafj7s6bittk5tt0bequlig2a.png" alt="image_1cafj7s6bittk5tt0bequlig2a.png-158.7kB"><br>上图中将KeyAggregation和Sink两个operator进行了合并，因为这两个合并后并不会改变整体的拓扑结构。但是，并不是任意两个 operator 就能 chain 一起的,其条件还是很苛刻的：</p>
<blockquote>
<ul>
<li>上下游的并行度一致</li>
<li>下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）</li>
<li>上下游节点都在同一个 slot group 中（下面会解释 slot group）</li>
<li>下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）</li>
<li>上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）</li>
<li>两个节点间数据分区方式是 forward（参考理解数据流的分区）</li>
<li>用户没有禁用 chain</li>
</ul>
</blockquote>
<p>flink的chain逻辑是一种很常见的设计，比如spring的interceptor也是类似的实现方式。通过把操作符串成一个大操作符，flink避免了把数据序列化后通过网络发送给其他节点的开销，能够大大增强效率。</p>
<h4 id="2-3-3-JobGraph的提交"><a href="#2-3-3-JobGraph的提交" class="headerlink" title="2.3.3 JobGraph的提交"></a>2.3.3 JobGraph的提交</h4><p>前面已经提到，JobGraph的提交依赖于JobClient和JobManager之间的异步通信，如图所示：<br><img src="http://static.zybuluo.com/bethunebtj/dj015uuqpnb4ct7810qfilhe/image_1cafn516r1p68kt31g7r196rcsv2n.png" alt="image_1cafn516r1p68kt31g7r196rcsv2n.png-40.1kB"><br>在submitJobAndWait方法中，其首先会创建一个JobClientActor的ActorRef,然后向其发起一个SubmitJobAndWait消息，该消息将JobGraph的实例提交给JobClientActor。发起模式是ask，它表示需要一个应答消息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Future&lt;Object&gt; future &#x3D; Patterns.ask(jobClientActor, new JobClientMessages.SubmitJobAndWait(jobGraph), new Timeout(AkkaUtils.INF_TIMEOUT()));</span><br><span class="line">answer &#x3D; Await.result(future, AkkaUtils.INF_TIMEOUT());</span><br></pre></td></tr></table></figure>
<p>该SubmitJobAndWait消息被JobClientActor接收后，最终通过调用tryToSubmitJob方法触发真正的提交动作。当JobManager的actor接收到来自client端的请求后，会执行一个submitJob方法，主要做以下事情：</p>
<blockquote>
<ul>
<li>向BlobLibraryCacheManager注册该Job；</li>
<li>构建ExecutionGraph对象；</li>
<li>对JobGraph中的每个顶点进行初始化；</li>
<li>将DAG拓扑中从source开始排序，排序后的顶点集合附加到Exec&gt; - utionGraph对象；</li>
<li>获取检查点相关的配置，并将其设置到ExecutionGraph对象；</li>
<li>向ExecutionGraph注册相关的listener；</li>
<li>执行恢复操作或者将JobGraph信息写入SubmittedJobGraphStore以在后续用于恢复目的；</li>
<li>响应给客户端JobSubmitSuccess消息；</li>
<li>对ExecutionGraph对象进行调度执行；</li>
</ul>
</blockquote>
<p>最后，JobManger会返回消息给JobClient，通知该任务是否提交成功。</p>
<h3 id="2-4-ExecutionGraph的生成"><a href="#2-4-ExecutionGraph的生成" class="headerlink" title="2.4 ExecutionGraph的生成"></a>2.4 ExecutionGraph的生成</h3><p>与StreamGraph和JobGraph不同，ExecutionGraph并不是在我们的客户端程序生成，而是在服务端（JobManager处）生成的，顺便flink只维护一个JobManager。其入口代码是<code>ExecutionGraphBuilder.buildGraph（...）</code><br>该方法长200多行，其中一大半是checkpoiont的相关逻辑，我们暂且略过，直接看核心方法<code>executionGraph.attachJobGraph(sortedTopology)</code><br>因为ExecutionGraph事实上只是改动了JobGraph的每个节点，而没有对整个拓扑结构进行变动，所以代码里只是挨个遍历jobVertex并进行处理：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for (JobVertex jobVertex : topologiallySorted) &#123;</span><br><span class="line"></span><br><span class="line">			if (jobVertex.isInputVertex() &amp;&amp; !jobVertex.isStoppable()) &#123;</span><br><span class="line">				this.isStoppable &#x3D; false;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F;在这里生成ExecutionGraph的每个节点</span><br><span class="line">			&#x2F;&#x2F;首先是进行了一堆赋值，将任务信息交给要生成的图节点，以及设定并行度等等</span><br><span class="line">			&#x2F;&#x2F;然后是创建本节点的IntermediateResult，根据本节点的下游节点的个数确定创建几份</span><br><span class="line">			&#x2F;&#x2F;最后是根据设定好的并行度创建用于执行task的ExecutionVertex</span><br><span class="line">			&#x2F;&#x2F;如果job有设定inputsplit的话，这里还要指定inputsplits</span><br><span class="line">			ExecutionJobVertex ejv &#x3D; new ExecutionJobVertex(</span><br><span class="line">				this,</span><br><span class="line">				jobVertex,</span><br><span class="line">				1,</span><br><span class="line">				rpcCallTimeout,</span><br><span class="line">				globalModVersion,</span><br><span class="line">				createTimestamp);</span><br><span class="line">            </span><br><span class="line">            &#x2F;&#x2F;这里要处理所有的JobEdge</span><br><span class="line">            &#x2F;&#x2F;对每个edge，获取对应的intermediateResult，并记录到本节点的输入上</span><br><span class="line">            &#x2F;&#x2F;最后，把每个ExecutorVertex和对应的IntermediateResult关联起来</span><br><span class="line">			ejv.connectToPredecessors(this.intermediateResults);</span><br><span class="line"></span><br><span class="line">			ExecutionJobVertex previousTask &#x3D; this.tasks.putIfAbsent(jobVertex.getID(), ejv);</span><br><span class="line">			if (previousTask !&#x3D; null) &#123;</span><br><span class="line">				throw new JobException(String.format(&quot;Encountered two job vertices with ID %s : previous&#x3D;[%s] &#x2F; new&#x3D;[%s]&quot;,</span><br><span class="line">						jobVertex.getID(), ejv, previousTask));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			for (IntermediateResult res : ejv.getProducedDataSets()) &#123;</span><br><span class="line">				IntermediateResult previousDataSet &#x3D; this.intermediateResults.putIfAbsent(res.getId(), res);</span><br><span class="line">				if (previousDataSet !&#x3D; null) &#123;</span><br><span class="line">					throw new JobException(String.format(&quot;Encountered two intermediate data set with ID %s : previous&#x3D;[%s] &#x2F; new&#x3D;[%s]&quot;,</span><br><span class="line">							res.getId(), res, previousDataSet));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			this.verticesInCreationOrder.add(ejv);</span><br><span class="line">			this.numVerticesTotal +&#x3D; ejv.getParallelism();</span><br><span class="line">			newExecJobVertices.add(ejv);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>
<p>至此，ExecutorGraph就创建完成了。</p>
<h2 id="3-任务的调度与执行"><a href="#3-任务的调度与执行" class="headerlink" title="3. 任务的调度与执行"></a>3. 任务的调度与执行</h2><p>关于flink的任务执行架构，官网的这两张图就是最好的说明：<br><img src="http://static.zybuluo.com/bethunebtj/qiv2wip1rok62ljo0tef3qf0/image_1cafnu1pl1d8c15m219b8vkb2334.png" alt="image_1cafnu1pl1d8c15m219b8vkb2334.png-112.9kB"><br>Flink 集群启动后，首先会启动一个 JobManger 和多个的 TaskManager。用户的代码会由JobClient 提交给 JobManager，JobManager 再把来自不同用户的任务发给 不同的TaskManager 去执行，每个TaskManager管理着多个task，task是执行计算的最小结构， TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述除了task外的三者均为独立的 JVM 进程。<br>要注意的是，TaskManager和job并非一一对应的关系。flink调度的最小单元是task而非TaskManager，也就是说，来自不同job的不同task可能运行于同一个TaskManager的不同线程上。<br><img src="http://static.zybuluo.com/bethunebtj/b7cmjn41b1zp5sco34kgvusn/image_1cclle7ui2j41nf611gs1is18m19.png" alt="image_1cclle7ui2j41nf611gs1is18m19.png-127.5kB"><br>一个flink任务所有可能的状态如上图所示。图上画的很明白，就不再赘述了。</p>
<h3 id="3-1-计算资源的调度"><a href="#3-1-计算资源的调度" class="headerlink" title="3.1 计算资源的调度"></a>3.1 计算资源的调度</h3><p>Task slot是一个TaskManager内资源分配的最小载体，代表了一个固定大小的资源子集，每个TaskManager会将其所占有的资源平分给它的slot。<br>通过调整 task slot 的数量，用户可以定义task之间是如何相互隔离的。每个 TaskManager 有一个slot，也就意味着每个task运行在独立的 JVM 中。每个 TaskManager 有多个slot的话，也就是说多个task运行在同一个JVM中。<br>而在同一个JVM进程中的task，可以共享TCP连接（基于多路复用）和心跳消息，可以减少数据的网络传输，也能共享一些数据结构，一定程度上减少了每个task的消耗。<br>每个slot可以接受单个task，也可以接受多个连续task组成的pipeline，如下图所示，FlatMap函数占用一个taskslot，而key Agg函数和sink函数共用一个taskslot：<br><img src="http://static.zybuluo.com/bethunebtj/6ypu9v09z0mit936uk0mcddi/image_1cafpf21c1jh3s5ap1fisu4v23h.png" alt="image_1cafpf21c1jh3s5ap1fisu4v23h.png-44.7kB"><br>为了达到共用slot的目的，除了可以以chain的方式pipeline算子，我们还可以允许SlotSharingGroup，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/tgamd7vw9qcdttvihlmvhie9/image_1cafpko68b3r1lk0dpsnmbj3c3u.png" alt="image_1cafpko68b3r1lk0dpsnmbj3c3u.png-61.2kB"><br>我们可以把不能被chain成一条的两个操作如flatmap和key&amp;sink放在一个TaskSlot里执行，这样做可以获得以下好处：</p>
<ul>
<li>共用slot使得我们不再需要计算每个任务需要的总task数目，直接取最高算子的并行度即可</li>
<li>对计算资源的利用率更高。例如，通常的轻量级操作map和重量级操作Aggregate不再分别需要一个线程，而是可以在同一个线程内执行，而且对于slot有限的场景，我们可以增大每个task的并行度了。<br>接下来我们还是用官网的图来说明flink是如何重用slot的：<br><img src="http://static.zybuluo.com/bethunebtj/l0n9ny2y198x0daucmyo0zb4/image_1cafqroarkjkuje1hfi18gor654b.png" alt="image_1cafqroarkjkuje1hfi18gor654b.png-137kB"></li>
</ul>
<ol>
<li>TaskManager1分配一个SharedSlot0</li>
<li>把source task放入一个SimpleSlot0，再把该slot放入SharedSlot0</li>
<li>把flatmap task放入一个SimpleSlot1，再把该slot放入SharedSlot0</li>
<li>因为我们的flatmap task并行度是2，因此不能再放入SharedSlot0，所以向TaskMange21申请了一个新的SharedSlot0</li>
<li>把第二个flatmap task放进一个新的SimpleSlot，并放进TaskManager2的SharedSlot0</li>
<li>开始处理key&amp;sink task，因为其并行度也是2，所以先把第一个task放进TaskManager1的SharedSlot</li>
<li>把第二个key&amp;sink放进TaskManager2的SharedSlot</li>
</ol>
<h3 id="3-2-JobManager执行job"><a href="#3-2-JobManager执行job" class="headerlink" title="3.2 JobManager执行job"></a>3.2 JobManager执行job</h3><p>JobManager负责接收 flink 的作业，调度 task，收集 job 的状态、管理 TaskManagers。被实现为一个 akka actor。</p>
<h4 id="3-2-1-JobManager的组件"><a href="#3-2-1-JobManager的组件" class="headerlink" title="3.2.1 JobManager的组件"></a>3.2.1 JobManager的组件</h4><ul>
<li>BlobServer 是一个用来管理二进制大文件的服务，比如保存用户上传的jar文件，该服务会将其写到磁盘上。还有一些相关的类，如BlobCache，用于TaskManager向JobManager下载用户的jar文件</li>
<li>InstanceManager 用来管理当前存活的TaskManager的组件，记录了TaskManager的心跳信息等</li>
<li>CompletedCheckpointStore 用于保存已完成的checkpoint相关信息，持久化到内存中或者zookeeper上</li>
<li>MemoryArchivist 保存了已经提交到flink的作业的相关信息，如JobGraph等</li>
</ul>
<h4 id="3-2-2-JobManager的启动过程"><a href="#3-2-2-JobManager的启动过程" class="headerlink" title="3.2.2 JobManager的启动过程"></a>3.2.2 JobManager的启动过程</h4><p>先列出JobManager启动的核心代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def runJobManager(</span><br><span class="line">      configuration: Configuration,</span><br><span class="line">      executionMode: JobManagerMode,</span><br><span class="line">      listeningAddress: String,</span><br><span class="line">      listeningPort: Int)</span><br><span class="line">    : Unit &#x3D; &#123;</span><br><span class="line"></span><br><span class="line">    val numberProcessors &#x3D; Hardware.getNumberCPUCores()</span><br><span class="line"></span><br><span class="line">    val futureExecutor &#x3D; Executors.newScheduledThreadPool(</span><br><span class="line">      numberProcessors,</span><br><span class="line">      new ExecutorThreadFactory(&quot;jobmanager-future&quot;))</span><br><span class="line"></span><br><span class="line">    val ioExecutor &#x3D; Executors.newFixedThreadPool(</span><br><span class="line">      numberProcessors,</span><br><span class="line">      new ExecutorThreadFactory(&quot;jobmanager-io&quot;))</span><br><span class="line"></span><br><span class="line">    val timeout &#x3D; AkkaUtils.getTimeout(configuration)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; we have to first start the JobManager ActorSystem because this determines the port if 0</span><br><span class="line">    &#x2F;&#x2F; was chosen before. The method startActorSystem will update the configuration correspondingly.</span><br><span class="line">    val jobManagerSystem &#x3D; startActorSystem(</span><br><span class="line">      configuration,</span><br><span class="line">      listeningAddress,</span><br><span class="line">      listeningPort)</span><br><span class="line"></span><br><span class="line">    val highAvailabilityServices &#x3D; HighAvailabilityServicesUtils.createHighAvailabilityServices(</span><br><span class="line">      configuration,</span><br><span class="line">      ioExecutor,</span><br><span class="line">      AddressResolution.NO_ADDRESS_RESOLUTION)</span><br><span class="line"></span><br><span class="line">    val metricRegistry &#x3D; new MetricRegistryImpl(</span><br><span class="line">      MetricRegistryConfiguration.fromConfiguration(configuration))</span><br><span class="line"></span><br><span class="line">    metricRegistry.startQueryService(jobManagerSystem, null)</span><br><span class="line"></span><br><span class="line">    val (_, _, webMonitorOption, _) &#x3D; try &#123;</span><br><span class="line">      startJobManagerActors(</span><br><span class="line">        jobManagerSystem,</span><br><span class="line">        configuration,</span><br><span class="line">        executionMode,</span><br><span class="line">        listeningAddress,</span><br><span class="line">        futureExecutor,</span><br><span class="line">        ioExecutor,</span><br><span class="line">        highAvailabilityServices,</span><br><span class="line">        metricRegistry,</span><br><span class="line">        classOf[JobManager],</span><br><span class="line">        classOf[MemoryArchivist],</span><br><span class="line">        Option(classOf[StandaloneResourceManager])</span><br><span class="line">      )</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case t: Throwable &#x3D;&gt;</span><br><span class="line">        futureExecutor.shutdownNow()</span><br><span class="line">        ioExecutor.shutdownNow()</span><br><span class="line"></span><br><span class="line">        throw t</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; block until everything is shut down</span><br><span class="line">    jobManagerSystem.awaitTermination()</span><br><span class="line">    </span><br><span class="line">    .......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>配置Akka并生成ActorSystem，启动JobManager</li>
<li>启动HA和metric相关服务</li>
<li>在<code>startJobManagerActors()</code>方法中启动JobManagerActors，以及webserver，TaskManagerActor，ResourceManager等等</li>
<li>阻塞等待终止</li>
<li>集群通过LeaderService等选出JobManager的leader</li>
</ul>
<h4 id="3-2-3-JobManager启动Task"><a href="#3-2-3-JobManager启动Task" class="headerlink" title="3.2.3 JobManager启动Task"></a>3.2.3 JobManager启动Task</h4><p>JobManager 是一个Actor，通过各种消息来完成核心逻辑：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">override def handleMessage: Receive &#x3D; &#123;</span><br><span class="line">  case GrantLeadership(newLeaderSessionID) &#x3D;&gt;</span><br><span class="line">    log.info(s&quot;JobManager $getAddress was granted leadership with leader session ID &quot; +</span><br><span class="line">      s&quot;$newLeaderSessionID.&quot;)</span><br><span class="line">    leaderSessionID &#x3D; newLeaderSessionID</span><br><span class="line">    </span><br><span class="line">    .......</span><br></pre></td></tr></table></figure>
<p>有几个比较重要的消息：</p>
<ul>
<li>GrantLeadership 获得leader授权，将自身被分发到的 session id 写到 zookeeper，并恢复所有的 jobs</li>
<li>RevokeLeadership 剥夺leader授权，打断清空所有的 job 信息，但是保留作业缓存，注销所有的 TaskManagers</li>
<li>RegisterTaskManagers 注册 TaskManager，如果之前已经注册过，则只给对应的 Instance 发送消息，否则启动注册逻辑：在 InstanceManager 中注册该 Instance 的信息，并停止 Instance BlobLibraryCacheManager 的端口【供下载 lib 包用】，同时使用 watch 监听 task manager 的存活</li>
<li>SubmitJob 提交 jobGraph<br>最后一项SubmintJob就是我们要关注的，从客户端收到JobGraph，转换为ExecutionGraph并执行的过程。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private def submitJob(jobGraph: JobGraph, jobInfo: JobInfo, isRecovery: Boolean &#x3D; false): Unit &#x3D; &#123;</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">    executionGraph &#x3D; ExecutionGraphBuilder.buildGraph(</span><br><span class="line">          executionGraph,</span><br><span class="line">          jobGraph,</span><br><span class="line">          flinkConfiguration,</span><br><span class="line">          futureExecutor,</span><br><span class="line">          ioExecutor,</span><br><span class="line">          scheduler,</span><br><span class="line">          userCodeLoader,</span><br><span class="line">          checkpointRecoveryFactory,</span><br><span class="line">          Time.of(timeout.length, timeout.unit),</span><br><span class="line">          restartStrategy,</span><br><span class="line">          jobMetrics,</span><br><span class="line">          numSlots,</span><br><span class="line">          blobServer,</span><br><span class="line">          log.logger)</span><br><span class="line">          </span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">    if (leaderElectionService.hasLeadership) &#123;</span><br><span class="line">            log.info(s&quot;Scheduling job $jobId ($jobName).&quot;)</span><br><span class="line">            </span><br><span class="line">            executionGraph.scheduleForExecution()</span><br><span class="line">            </span><br><span class="line">          &#125; else &#123;</span><br><span class="line">            self ! decorateMessage(RemoveJob(jobId, removeJobFromStateBackend &#x3D; false))</span><br><span class="line"></span><br><span class="line">            log.warn(s&quot;Submitted job $jobId, but not leader. The other leader needs to recover &quot; +</span><br><span class="line">              &quot;this. I am not scheduling the job for execution.&quot;)</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
首先做一些准备工作，然后获取一个ExecutionGraph，判断是否是恢复的job，然后将job保存下来，并且通知客户端本地已经提交成功了，最后如果确认本JobManager是leader，则执行<code>executionGraph.scheduleForExecution()</code>方法，这个方法经过一系列调用，把每个ExecutionVertex传递给了Excution类的deploy方法：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void deploy() throws JobException &#123;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			&#x2F;&#x2F; good, we are allowed to deploy</span><br><span class="line">			if (!slot.setExecutedVertex(this)) &#123;</span><br><span class="line">				throw new JobException(&quot;Could not assign the ExecutionVertex to the slot &quot; + slot);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; race double check, did we fail&#x2F;cancel and do we need to release the slot?</span><br><span class="line">			if (this.state !&#x3D; DEPLOYING) &#123;</span><br><span class="line">				slot.releaseSlot();</span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (LOG.isInfoEnabled()) &#123;</span><br><span class="line">				LOG.info(String.format(&quot;Deploying %s (attempt #%d) to %s&quot;, vertex.getTaskNameWithSubtaskIndex(),</span><br><span class="line">						attemptNumber, getAssignedResourceLocation().getHostname()));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			final TaskDeploymentDescriptor deployment &#x3D; vertex.createDeploymentDescriptor(</span><br><span class="line">				attemptId,</span><br><span class="line">				slot,</span><br><span class="line">				taskState,</span><br><span class="line">				attemptNumber);</span><br><span class="line"></span><br><span class="line">			final TaskManagerGateway taskManagerGateway &#x3D; slot.getTaskManagerGateway();</span><br><span class="line"></span><br><span class="line">			final CompletableFuture&lt;Acknowledge&gt; submitResultFuture &#x3D; taskManagerGateway.submitTask(deployment, timeout);</span><br><span class="line"></span><br><span class="line">            ......</span><br><span class="line">		&#125;</span><br><span class="line">		catch (Throwable t) &#123;</span><br><span class="line">			markFailed(t);</span><br><span class="line">			ExceptionUtils.rethrow(t);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
我们首先生成了一个TaskDeploymentDescriptor，然后交给了<code>taskManagerGateway.submitTask()</code>方法执行。接下来的部分，就属于TaskManager的范畴了。<h3 id="3-3-TaskManager执行task"><a href="#3-3-TaskManager执行task" class="headerlink" title="3.3 TaskManager执行task"></a>3.3 TaskManager执行task</h3><h4 id="3-3-1-TaskManager的基本组件"><a href="#3-3-1-TaskManager的基本组件" class="headerlink" title="3.3.1 TaskManager的基本组件"></a>3.3.1 TaskManager的基本组件</h4>TaskManager是flink中资源管理的基本组件，是所有执行任务的基本容器，提供了内存管理、IO管理、通信管理等一系列功能，本节对各个模块进行简要介绍。</li>
</ul>
<ol>
<li>MemoryManager flink并没有把所有内存的管理都委托给JVM，因为JVM普遍存在着存储对象密度低、大内存时GC对系统影响大等问题。所以flink自己抽象了一套内存管理机制，将所有对象序列化后放在自己的MemorySegment上进行管理。MemoryManger涉及内容较多，将在后续章节进行继续剖析。</li>
<li>IOManager flink通过IOManager管理磁盘IO的过程，提供了同步和异步两种写模式，又进一步区分了block、buffer和bulk三种读写方式。<br>IOManager提供了两种方式枚举磁盘文件，一种是直接遍历文件夹下所有文件，另一种是计数器方式，对每个文件名以递增顺序访问。<br>在底层，flink将文件IO抽象为FileIOChannle，封装了底层实现。<br><img src="http://static.zybuluo.com/bethunebtj/d3j6qnbjywjzknu6pb3pou6i/image_1cag7idg4vfj1l871n0l1k0e1f7u4o.png" alt="image_1cag7idg4vfj1l871n0l1k0e1f7u4o.png-194.1kB"><br>可以看到，flink在底层实际上都是以异步的方式进行读写。</li>
<li>NetworkEnvironment 是TaskManager的网络 IO 组件，包含了追踪中间结果和数据交换的数据结构。它的构造器会统一将配置的内存先分配出来，抽象成 NetworkBufferPool 统一管理内存的申请和释放。意思是说，在输入和输出数据时，不管是保留在本地内存，等待chain在一起的下个操作符进行处理，还是通过网络把本操作符的计算结果发送出去，都被抽象成了NetworkBufferPool。后续我们还将对这个组件进行详细分析。</li>
</ol>
<h4 id="3-3-2-TaskManager执行Task"><a href="#3-3-2-TaskManager执行Task" class="headerlink" title="3.3.2 TaskManager执行Task"></a>3.3.2 TaskManager执行Task</h4><p>对于TM来说，执行task就是把收到的<code>TaskDeploymentDescriptor</code>对象转换成一个task并执行的过程。TaskDeploymentDescriptor这个类保存了task执行所必须的所有内容，例如序列化的算子，输入的InputGate和输出的ResultPartition的定义，该task要作为几个subtask执行等等。<br>按照正常逻辑思维，很容易想到TM的submitTask方法的行为：首先是确认资源，如寻找JobManager和Blob，而后建立连接，解序列化算子，收集task相关信息，接下来就是创建一个新的<code>Task</code>对象，这个task对象就是真正执行任务的关键所在。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val task &#x3D; new Task(</span><br><span class="line">        jobInformation,</span><br><span class="line">        taskInformation,</span><br><span class="line">        tdd.getExecutionAttemptId,</span><br><span class="line">        tdd.getAllocationId,</span><br><span class="line">        tdd.getSubtaskIndex,</span><br><span class="line">        tdd.getAttemptNumber,</span><br><span class="line">        tdd.getProducedPartitions,</span><br><span class="line">        tdd.getInputGates,</span><br><span class="line">        tdd.getTargetSlotNumber,</span><br><span class="line">        tdd.getTaskStateHandles,</span><br><span class="line">        memoryManager,</span><br><span class="line">        ioManager,</span><br><span class="line">        network,</span><br><span class="line">        bcVarManager,</span><br><span class="line">        taskManagerConnection,</span><br><span class="line">        inputSplitProvider,</span><br><span class="line">        checkpointResponder,</span><br><span class="line">        blobCache,</span><br><span class="line">        libCache,</span><br><span class="line">        fileCache,</span><br><span class="line">        config,</span><br><span class="line">        taskMetricGroup,</span><br><span class="line">        resultPartitionConsumableNotifier,</span><br><span class="line">        partitionStateChecker,</span><br><span class="line">        context.dispatcher)</span><br></pre></td></tr></table></figure>
<p>如果读者是从头开始看这篇blog，里面有很多对象应该已经比较明确其作用了（除了那个brVarManager，这个是管理广播变量的，广播变量是一类会被分发到每个任务中的共享变量）。接下来的主要任务，就是把这个task启动起来,然后报告说已经启动task了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; all good, we kick off the task, which performs its own initialization</span><br><span class="line">task.startTaskThread()</span><br><span class="line"></span><br><span class="line">sender ! decorateMessage(Acknowledge.get())</span><br></pre></td></tr></table></figure>
<h4 id="3-3-2-1-生成Task对象"><a href="#3-3-2-1-生成Task对象" class="headerlink" title="3.3.2.1 生成Task对象"></a>3.3.2.1 生成Task对象</h4><p>在执行new Task()方法时，第一步是把构造函数里的这些变量赋值给当前task的fields。<br>接下来是初始化ResultPartition和InputGate。这两个类描述了task的输出数据和输入数据。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for (ResultPartitionDeploymentDescriptor desc: resultPartitionDeploymentDescriptors) &#123;</span><br><span class="line">	ResultPartitionID partitionId &#x3D; new ResultPartitionID(desc.getPartitionId(), executionId);</span><br><span class="line"></span><br><span class="line">	this.producedPartitions[counter] &#x3D; new ResultPartition(</span><br><span class="line">	    taskNameWithSubtaskAndId,</span><br><span class="line">		this,</span><br><span class="line">		jobId,</span><br><span class="line">		partitionId,</span><br><span class="line">		desc.getPartitionType(),</span><br><span class="line">		desc.getNumberOfSubpartitions(),</span><br><span class="line">		desc.getMaxParallelism(),</span><br><span class="line">		networkEnvironment.getResultPartitionManager(),</span><br><span class="line">		resultPartitionConsumableNotifier,</span><br><span class="line">		ioManager,</span><br><span class="line">		desc.sendScheduleOrUpdateConsumersMessage());		</span><br><span class="line">	&#x2F;&#x2F;为每个partition初始化对应的writer </span><br><span class="line">	writers[counter] &#x3D; new ResultPartitionWriter(producedPartitions[counter]);</span><br><span class="line"></span><br><span class="line">	++counter;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Consumed intermediate result partitions</span><br><span class="line">this.inputGates &#x3D; new SingleInputGate[inputGateDeploymentDescriptors.size()];</span><br><span class="line">this.inputGatesById &#x3D; new HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">counter &#x3D; 0;</span><br><span class="line"></span><br><span class="line">for (InputGateDeploymentDescriptor inputGateDeploymentDescriptor: inputGateDeploymentDescriptors) &#123;</span><br><span class="line">	SingleInputGate gate &#x3D; SingleInputGate.create(</span><br><span class="line">		taskNameWithSubtaskAndId,</span><br><span class="line">		jobId,</span><br><span class="line">		executionId,</span><br><span class="line">		inputGateDeploymentDescriptor,</span><br><span class="line">		networkEnvironment,</span><br><span class="line">		this,</span><br><span class="line">		metricGroup.getIOMetricGroup());</span><br><span class="line"></span><br><span class="line">	inputGates[counter] &#x3D; gate;</span><br><span class="line">	inputGatesById.put(gate.getConsumedResultId(), gate);</span><br><span class="line"></span><br><span class="line">	++counter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后，创建一个Thread对象，并把自己放进该对象，这样在执行时，自己就有了自身的线程的引用。</p>
<h4 id="3-3-2-2-运行Task对象"><a href="#3-3-2-2-运行Task对象" class="headerlink" title="3.3.2.2 运行Task对象"></a>3.3.2.2 运行Task对象</h4><p> Task对象本身就是一个Runable，因此在其run方法里定义了运行逻辑。<br> 第一步是切换Task的状态：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">      while (true) &#123;</span><br><span class="line">	ExecutionState current &#x3D; this.executionState;</span><br><span class="line">	&#x2F;&#x2F;&#x2F;&#x2F;如果当前的执行状态为CREATED，则将其设置为DEPLOYING状态</span><br><span class="line">	if (current &#x3D;&#x3D; ExecutionState.CREATED) &#123;</span><br><span class="line">		if (transitionState(ExecutionState.CREATED, ExecutionState.DEPLOYING)) &#123;</span><br><span class="line">			&#x2F;&#x2F; success, we can start our work</span><br><span class="line">			break;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;如果当前执行状态为FAILED，则发出通知并退出run方法</span><br><span class="line">	else if (current &#x3D;&#x3D; ExecutionState.FAILED) &#123;</span><br><span class="line">		&#x2F;&#x2F; we were immediately failed. tell the TaskManager that we reached our final state</span><br><span class="line">		notifyFinalState();</span><br><span class="line">		if (metrics !&#x3D; null) &#123;</span><br><span class="line">			metrics.close();</span><br><span class="line">		&#125;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;如果当前执行状态为CANCELING，则将其修改为CANCELED状态，并退出run</span><br><span class="line">	else if (current &#x3D;&#x3D; ExecutionState.CANCELING) &#123;</span><br><span class="line">		if (transitionState(ExecutionState.CANCELING, ExecutionState.CANCELED)) &#123;</span><br><span class="line">			&#x2F;&#x2F; we were immediately canceled. tell the TaskManager that we reached our final state</span><br><span class="line">			notifyFinalState();</span><br><span class="line">			if (metrics !&#x3D; null) &#123;</span><br><span class="line">				metrics.close();</span><br><span class="line">			&#125;</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;否则说明发生了异常</span><br><span class="line">	else &#123;</span><br><span class="line">		if (metrics !&#x3D; null) &#123;</span><br><span class="line">			metrics.close();</span><br><span class="line">		&#125;</span><br><span class="line">		throw new IllegalStateException(&quot;Invalid state for beginning of operation of task &quot; + this + &#39;.&#39;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实这里有个值得关注的点，就是flink里大量使用了这种while(true)的写法来修改和检测状态，emmm…<br>接下来，就是导入用户类加载器并加载用户代码。<br>然后，是向网络管理器注册当前任务（flink的各个算子在运行时进行数据交换需要依赖网络管理器），分配一些缓存以保存数据<br>然后，读入指定的缓存文件。<br>然后，再把task创建时传入的那一大堆变量用于创建一个执行环境Envrionment。<br>再然后，对于那些并不是第一次执行的task（比如失败后重启的）要恢复其状态。<br>接下来最重要的是</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">invokable.invoke();</span><br></pre></td></tr></table></figure>
<p>方法。为什么这么说呢，因为这个方法就是用户代码所真正被执行的入口。比如我们写的什么new MapFunction()的逻辑，最终就是在这里被执行的。这里说一下这个invokable，这是一个抽象类，提供了可以被TaskManager执行的对象的基本抽象。<br>这个invokable是在解析JobGraph的时候生成相关信息的，并在此处形成真正可执行的对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; now load the task&#39;s invokable code</span><br><span class="line">&#x2F;&#x2F;通过反射生成对象</span><br><span class="line">invokable &#x3D; loadAndInstantiateInvokable(userCodeClassLoader, nameOfInvokableClass);</span><br></pre></td></tr></table></figure>
<p><img src="http://static.zybuluo.com/bethunebtj/9bemw0us5cocnej8lq4x64rk/image_1cbkaa8r9182i18ct1kfu8g829m9.png" alt="image_1cbkaa8r9182i18ct1kfu8g829m9.png-29.9kB"><br>上图显示了flink提供的可被执行的Task类型。从名字上就可以看出各个task的作用，在此不再赘述。<br>接下来就是invoke方法了，因为我们的wordcount例子用了流式api，在此我们以StreamTask的invoke方法为例进行说明。</p>
<h4 id="3-3-2-3-StreamTask的执行逻辑"><a href="#3-3-2-3-StreamTask的执行逻辑" class="headerlink" title="3.3.2.3 StreamTask的执行逻辑"></a>3.3.2.3 StreamTask的执行逻辑</h4><p>先上部分核心代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final void invoke() throws Exception &#123;</span><br><span class="line"></span><br><span class="line">	boolean disposed &#x3D; false;</span><br><span class="line">    try &#123;</span><br><span class="line">			&#x2F;&#x2F; -------- Initialize ---------</span><br><span class="line">			&#x2F;&#x2F;先做一些赋值操作</span><br><span class="line">            ......</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; if the clock is not already set, then assign a default TimeServiceProvider</span><br><span class="line">	&#x2F;&#x2F;处理timer</span><br><span class="line">	if (timerService &#x3D;&#x3D; null) &#123;</span><br><span class="line">		ThreadFactory timerThreadFactory &#x3D;</span><br><span class="line">			new DispatcherThreadFactory(TRIGGER_THREAD_GROUP, &quot;Time Trigger for &quot; + getName());</span><br><span class="line"></span><br><span class="line">		timerService &#x3D; new SystemProcessingTimeService(this, getCheckpointLock(), timerThreadFactory);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;把之前JobGraph串起来的chain的信息形成实现</span><br><span class="line">	operatorChain &#x3D; new OperatorChain&lt;&gt;(this);</span><br><span class="line">	headOperator &#x3D; operatorChain.getHeadOperator();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; task specific initialization</span><br><span class="line">	&#x2F;&#x2F;这个init操作的起名非常诡异，因为这里主要是处理算子采用了自定义的checkpoint检查机制的情况，但是起了一个非常大众脸的名字</span><br><span class="line">	init();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; save the work of reloading state, etc, if the task is already canceled</span><br><span class="line">	if (canceled) &#123;</span><br><span class="line">		throw new CancelTaskException();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; -------- Invoke --------</span><br><span class="line">	LOG.debug(&quot;Invoking &#123;&#125;&quot;, getName());</span><br><span class="line">			</span><br><span class="line">	&#x2F;&#x2F; we need to make sure that any triggers scheduled in open() cannot be</span><br><span class="line">	&#x2F;&#x2F; executed before all operators are opened</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; both the following operations are protected by the lock</span><br><span class="line">		&#x2F;&#x2F; so that we avoid race conditions in the case that initializeState()</span><br><span class="line">		&#x2F;&#x2F; registers a timer, that fires before the open() is called.</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;初始化操作符状态，主要是一些state啥的</span><br><span class="line">		initializeState();</span><br><span class="line">		&#x2F;&#x2F;对于富操作符，执行其open操作</span><br><span class="line">		openAllOperators();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; final check to exit early before starting to run</span><br><span class="line">	f (canceled) &#123;</span><br><span class="line">	    throw new CancelTaskException();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; let the task do its work</span><br><span class="line">	&#x2F;&#x2F;真正开始执行的代码</span><br><span class="line">	isRunning &#x3D; true;</span><br><span class="line">	run();</span><br></pre></td></tr></table></figure>
<p>StreamTask.invoke()方法里，第一个值得一说的是<code>TimerService</code>。Flink在2015年决定向StreamTask类加入timer service的时候解释到：</p>
<blockquote>
<p>This integrates the timer as a service in StreamTask that StreamOperators can use by calling a method on the StreamingRuntimeContext. This also ensures that the timer callbacks can not be called concurrently with other methods on the StreamOperator. This behaviour is ensured by an ITCase.</p>
</blockquote>
<p>第二个要注意的是chain操作。前面提到了，flink会出于优化的角度，把一些算子chain成一个整体的算子作为一个task来执行。比如wordcount例子中，Source和FlatMap算子就被chain在了一起。在进行chain操作的时候，会设定头节点，并且指定输出的RecordWriter。</p>
<p>接下来不出所料仍然是初始化，只不过初始化的对象变成了各个operator。如果是有checkpoint的，那就从state信息里恢复，不然就作为全新的算子处理。从源码中可以看到，flink针对keyed算子和普通算子做了不同的处理。keyed算子在初始化时需要计算出一个group区间，这个区间的值在整个生命周期里都不会再变化，后面key就会根据hash的不同结果，分配到特定的group中去计算。顺便提一句，flink的keyed算子保存的是对每个数据的key的计算方法，而非真实的key，用户需要自己保证对每一行数据提供的keySelector的幂等性。至于为什么要用KeyGroup的设计，这就牵扯到扩容的范畴了，将在后面的章节进行讲述。<br>对于<code>openAllOperators()</code>方法，就是对各种RichOperator执行其open方法，通常可用于在执行计算之前加载资源。<br>最后，run方法千呼万唤始出来，该方法经过一系列跳转，最终调用chain上的第一个算子的run方法。在wordcount的例子中，它最终调用了SocketTextStreamFunction的run，建立socket连接并读入文本。</p>
<h3 id="3-4-StreamTask与StreamOperator"><a href="#3-4-StreamTask与StreamOperator" class="headerlink" title="3.4 StreamTask与StreamOperator"></a>3.4 StreamTask与StreamOperator</h3><p>前面提到，Task对象在执行过程中，把执行的任务交给了StreamTask这个类去执行。在我们的wordcount例子中，实际初始化的是OneInputStreamTask的对象（参考上面的类图）。那么这个对象是如何执行用户的代码的呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">protected void run() throws Exception &#123;</span><br><span class="line">	&#x2F;&#x2F; cache processor reference on the stack, to make the code more JIT friendly</span><br><span class="line">	final StreamInputProcessor&lt;IN&gt; inputProcessor &#x3D; this.inputProcessor;</span><br><span class="line"></span><br><span class="line">	while (running &amp;&amp; inputProcessor.processInput()) &#123;</span><br><span class="line">		&#x2F;&#x2F; all the work happens in the &quot;processInput&quot; method</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它做的，就是把任务直接交给了InputProcessor去执行processInput方法。这是一个<code>StreamInputProcessor</code>的实例，该processor的任务就是处理输入的数据，包括用户数据、watermark和checkpoint数据等。我们先来看看这个processor是如何产生的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void init() throws Exception &#123;</span><br><span class="line">	StreamConfig configuration &#x3D; getConfiguration();</span><br><span class="line"></span><br><span class="line">	TypeSerializer&lt;IN&gt; inSerializer &#x3D; configuration.getTypeSerializerIn1(getUserCodeClassLoader());</span><br><span class="line">	int numberOfInputs &#x3D; configuration.getNumberOfInputs();</span><br><span class="line"></span><br><span class="line">	if (numberOfInputs &gt; 0) &#123;</span><br><span class="line">		InputGate[] inputGates &#x3D; getEnvironment().getAllInputGates();</span><br><span class="line"></span><br><span class="line">		inputProcessor &#x3D; new StreamInputProcessor&lt;&gt;(</span><br><span class="line">				inputGates,</span><br><span class="line">				inSerializer,</span><br><span class="line">				this,</span><br><span class="line">				configuration.getCheckpointMode(),</span><br><span class="line">				getCheckpointLock(),</span><br><span class="line">				getEnvironment().getIOManager(),</span><br><span class="line">				getEnvironment().getTaskManagerInfo().getConfiguration(),</span><br><span class="line">				getStreamStatusMaintainer(),</span><br><span class="line">				this.headOperator);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; make sure that stream tasks report their I&#x2F;O statistics</span><br><span class="line">		inputProcessor.setMetricGroup(getEnvironment().getMetricGroup().getIOMetricGroup());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是OneInputStreamTask的init方法，从configs里面获取StreamOperator信息，生成自己的inputProcessor。那么inputProcessor是如何处理数据的呢？我们接着跟进源码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public boolean processInput() throws Exception &#123;</span><br><span class="line">		if (isFinished) &#123;</span><br><span class="line">			return false;</span><br><span class="line">		&#125;</span><br><span class="line">		if (numRecordsIn &#x3D;&#x3D; null) &#123;</span><br><span class="line">			numRecordsIn &#x3D; ((OperatorMetricGroup) streamOperator.getMetricGroup()).getIOMetricGroup().getNumRecordsInCounter();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;这个while是用来处理单个元素的（不要想当然以为是循环处理元素的）</span><br><span class="line">		while (true) &#123;</span><br><span class="line">		    &#x2F;&#x2F;注意 1在下面</span><br><span class="line">		    &#x2F;&#x2F;2.接下来，会利用这个反序列化器得到下一个数据记录，并进行解析（是用户数据还是watermark等等），然后进行对应的操作</span><br><span class="line">			if (currentRecordDeserializer !&#x3D; null) &#123;</span><br><span class="line">				DeserializationResult result &#x3D; currentRecordDeserializer.getNextRecord(deserializationDelegate);</span><br><span class="line"></span><br><span class="line">				if (result.isBufferConsumed()) &#123;</span><br><span class="line">					currentRecordDeserializer.getCurrentBuffer().recycle();</span><br><span class="line">					currentRecordDeserializer &#x3D; null;</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				if (result.isFullRecord()) &#123;</span><br><span class="line">					StreamElement recordOrMark &#x3D; deserializationDelegate.getInstance();</span><br><span class="line"></span><br><span class="line">                    &#x2F;&#x2F;如果元素是watermark，就准备更新当前channel的watermark值（并不是简单赋值，因为有乱序存在），</span><br><span class="line">					if (recordOrMark.isWatermark()) &#123;</span><br><span class="line">						&#x2F;&#x2F; handle watermark</span><br><span class="line">						statusWatermarkValve.inputWatermark(recordOrMark.asWatermark(), currentChannel);</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else if (recordOrMark.isStreamStatus()) &#123;</span><br><span class="line">					&#x2F;&#x2F;如果元素是status，就进行相应处理。可以看作是一个flag，标志着当前stream接下来即将没有元素输入（idle），或者当前即将由空闲状态转为有元素状态（active）。同时，StreamStatus还对如何处理watermark有影响。通过发送status，上游的operator可以很方便的通知下游当前的数据流的状态。</span><br><span class="line">						&#x2F;&#x2F; handle stream status</span><br><span class="line">						statusWatermarkValve.inputStreamStatus(recordOrMark.asStreamStatus(), currentChannel);</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else if (recordOrMark.isLatencyMarker()) &#123;</span><br><span class="line">					&#x2F;&#x2F;LatencyMarker是用来衡量代码执行时间的。在Source处创建，携带创建时的时间戳，流到Sink时就可以知道经过了多长时间</span><br><span class="line">						&#x2F;&#x2F; handle latency marker</span><br><span class="line">						synchronized (lock) &#123;</span><br><span class="line">							streamOperator.processLatencyMarker(recordOrMark.asLatencyMarker());</span><br><span class="line">						&#125;</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else &#123;</span><br><span class="line">					&#x2F;&#x2F;这里就是真正的，用户的代码即将被执行的地方。从章节1到这里足足用了三万字，有点万里长征的感觉</span><br><span class="line">						&#x2F;&#x2F; now we can do the actual processing</span><br><span class="line">						StreamRecord&lt;IN&gt; record &#x3D; recordOrMark.asRecord();</span><br><span class="line">						synchronized (lock) &#123;</span><br><span class="line">							numRecordsIn.inc();</span><br><span class="line">							streamOperator.setKeyContextElement1(record);</span><br><span class="line">							streamOperator.processElement(record);</span><br><span class="line">						&#125;</span><br><span class="line">						return true;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;1.程序首先获取下一个buffer</span><br><span class="line">            &#x2F;&#x2F;这一段代码是服务于flink的FaultTorrent机制的，后面我会讲到，这里只需理解到它会尝试获取buffer，然后赋值给当前的反序列化器</span><br><span class="line">			final BufferOrEvent bufferOrEvent &#x3D; barrierHandler.getNextNonBlocked();</span><br><span class="line">			if (bufferOrEvent !&#x3D; null) &#123;</span><br><span class="line">				if (bufferOrEvent.isBuffer()) &#123;</span><br><span class="line">					currentChannel &#x3D; bufferOrEvent.getChannelIndex();</span><br><span class="line">					currentRecordDeserializer &#x3D; recordDeserializers[currentChannel];</span><br><span class="line">					currentRecordDeserializer.setNextBuffer(bufferOrEvent.getBuffer());</span><br><span class="line">				&#125;</span><br><span class="line">				else &#123;</span><br><span class="line">					&#x2F;&#x2F; Event received</span><br><span class="line">					final AbstractEvent event &#x3D; bufferOrEvent.getEvent();</span><br><span class="line">					if (event.getClass() !&#x3D; EndOfPartitionEvent.class) &#123;</span><br><span class="line">						throw new IOException(&quot;Unexpected event: &quot; + event);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			else &#123;</span><br><span class="line">				isFinished &#x3D; true;</span><br><span class="line">				if (!barrierHandler.isEmpty()) &#123;</span><br><span class="line">					throw new IllegalStateException(&quot;Trailing data in checkpoint barrier handler.&quot;);</span><br><span class="line">				&#125;</span><br><span class="line">				return false;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>到此为止，以上部分就是一个flink程序启动后，到执行用户代码之前，flink框架所做的准备工作。回顾一下：</p>
<ul>
<li>启动一个环境</li>
<li>生成StreamGraph</li>
<li>注册和选举JobManager</li>
<li>在各节点生成TaskManager，并根据JobGraph生成对应的Task</li>
<li>启动各个task，准备执行代码</li>
</ul>
<p>接下来，我们挑几个Operator看看flink是如何抽象这些算子的。</p>
<h2 id="4-StreamOperator的抽象与实现"><a href="#4-StreamOperator的抽象与实现" class="headerlink" title="4. StreamOperator的抽象与实现"></a>4. StreamOperator的抽象与实现</h2><h3 id="4-1-数据源的逻辑——StreamSource与时间模型"><a href="#4-1-数据源的逻辑——StreamSource与时间模型" class="headerlink" title="4.1 数据源的逻辑——StreamSource与时间模型"></a>4.1 数据源的逻辑——StreamSource与时间模型</h3><p>StreamSource抽象了一个数据源，并且指定了一些如何处理数据的模式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class StreamSource&lt;OUT, SRC extends SourceFunction&lt;OUT&gt;&gt;</span><br><span class="line">		extends AbstractUdfStreamOperator&lt;OUT, SRC&gt; implements StreamOperator&lt;OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">	public void run(final Object lockingObject, final StreamStatusMaintainer streamStatusMaintainer) throws Exception &#123;</span><br><span class="line">		run(lockingObject, streamStatusMaintainer, output);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void run(final Object lockingObject,</span><br><span class="line">			final StreamStatusMaintainer streamStatusMaintainer,</span><br><span class="line">			final Output&lt;StreamRecord&lt;OUT&gt;&gt; collector) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">		final TimeCharacteristic timeCharacteristic &#x3D; getOperatorConfig().getTimeCharacteristic();</span><br><span class="line"></span><br><span class="line">		LatencyMarksEmitter latencyEmitter &#x3D; null;</span><br><span class="line">		if (getExecutionConfig().isLatencyTrackingEnabled()) &#123;</span><br><span class="line">			latencyEmitter &#x3D; new LatencyMarksEmitter&lt;&gt;(</span><br><span class="line">				getProcessingTimeService(),</span><br><span class="line">				collector,</span><br><span class="line">				getExecutionConfig().getLatencyTrackingInterval(),</span><br><span class="line">				getOperatorConfig().getVertexID(),</span><br><span class="line">				getRuntimeContext().getIndexOfThisSubtask());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		final long watermarkInterval &#x3D; getRuntimeContext().getExecutionConfig().getAutoWatermarkInterval();</span><br><span class="line"></span><br><span class="line">		this.ctx &#x3D; StreamSourceContexts.getSourceContext(</span><br><span class="line">			timeCharacteristic,</span><br><span class="line">			getProcessingTimeService(),</span><br><span class="line">			lockingObject,</span><br><span class="line">			streamStatusMaintainer,</span><br><span class="line">			collector,</span><br><span class="line">			watermarkInterval,</span><br><span class="line">			-1);</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			userFunction.run(ctx);</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; if we get here, then the user function either exited after being done (finite source)</span><br><span class="line">			&#x2F;&#x2F; or the function was canceled or stopped. For the finite source case, we should emit</span><br><span class="line">			&#x2F;&#x2F; a final watermark that indicates that we reached the end of event-time</span><br><span class="line">			if (!isCanceledOrStopped()) &#123;</span><br><span class="line">				ctx.emitWatermark(Watermark.MAX_WATERMARK);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			&#x2F;&#x2F; make sure that the context is closed in any case</span><br><span class="line">			ctx.close();</span><br><span class="line">			if (latencyEmitter !&#x3D; null) &#123;</span><br><span class="line">				latencyEmitter.close();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">	private static class LatencyMarksEmitter&lt;OUT&gt; &#123;</span><br><span class="line">		private final ScheduledFuture&lt;?&gt; latencyMarkTimer;</span><br><span class="line"></span><br><span class="line">		public LatencyMarksEmitter(</span><br><span class="line">				final ProcessingTimeService processingTimeService,</span><br><span class="line">				final Output&lt;StreamRecord&lt;OUT&gt;&gt; output,</span><br><span class="line">				long latencyTrackingInterval,</span><br><span class="line">				final int vertexID,</span><br><span class="line">				final int subtaskIndex) &#123;</span><br><span class="line"></span><br><span class="line">			latencyMarkTimer &#x3D; processingTimeService.scheduleAtFixedRate(</span><br><span class="line">				new ProcessingTimeCallback() &#123;</span><br><span class="line">					@Override</span><br><span class="line">					public void onProcessingTime(long timestamp) throws Exception &#123;</span><br><span class="line">						try &#123;</span><br><span class="line">							&#x2F;&#x2F; ProcessingTimeService callbacks are executed under the checkpointing lock</span><br><span class="line">							output.emitLatencyMarker(new LatencyMarker(timestamp, vertexID, subtaskIndex));</span><br><span class="line">						&#125; catch (Throwable t) &#123;</span><br><span class="line">							&#x2F;&#x2F; we catch the Throwables here so that we don&#39;t trigger the processing</span><br><span class="line">							&#x2F;&#x2F; timer services async exception handler</span><br><span class="line">							LOG.warn(&quot;Error while emitting latency marker.&quot;, t);</span><br><span class="line">						&#125;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;,</span><br><span class="line">				0L,</span><br><span class="line">				latencyTrackingInterval);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		public void close() &#123;</span><br><span class="line">			latencyMarkTimer.cancel(true);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在StreamSource生成上下文之后，接下来就是把上下文交给SourceFunction去执行:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">userFunction.run(ctx);</span><br></pre></td></tr></table></figure>
<p>SourceFunction是对Function的一个抽象，就好像MapFunction，KeyByFunction一样，用户选择实现这些函数，然后flink框架就能利用这些函数进行计算，完成用户逻辑。<br>我们的wordcount程序使用了flink提供的一个<code>SocketTextStreamFunction</code>。我们可以看一下它的实现逻辑，对source如何运行有一个基本的认识：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void run(SourceContext&lt;String&gt; ctx) throws Exception &#123;</span><br><span class="line">		final StringBuilder buffer &#x3D; new StringBuilder();</span><br><span class="line">		long attempt &#x3D; 0;</span><br><span class="line"></span><br><span class="line">		while (isRunning) &#123;</span><br><span class="line"></span><br><span class="line">			try (Socket socket &#x3D; new Socket()) &#123;</span><br><span class="line">				currentSocket &#x3D; socket;</span><br><span class="line"></span><br><span class="line">				LOG.info(&quot;Connecting to server socket &quot; + hostname + &#39;:&#39; + port);</span><br><span class="line">				socket.connect(new InetSocketAddress(hostname, port), CONNECTION_TIMEOUT_TIME);</span><br><span class="line">				BufferedReader reader &#x3D; new BufferedReader(new InputStreamReader(socket.getInputStream()));</span><br><span class="line"></span><br><span class="line">				char[] cbuf &#x3D; new char[8192];</span><br><span class="line">				int bytesRead;</span><br><span class="line">				&#x2F;&#x2F;核心逻辑就是一直读inputSocket,然后交给collect方法</span><br><span class="line">				while (isRunning &amp;&amp; (bytesRead &#x3D; reader.read(cbuf)) !&#x3D; -1) &#123;</span><br><span class="line">					buffer.append(cbuf, 0, bytesRead);</span><br><span class="line">					int delimPos;</span><br><span class="line">					while (buffer.length() &gt;&#x3D; delimiter.length() &amp;&amp; (delimPos &#x3D; buffer.indexOf(delimiter)) !&#x3D; -1) &#123;</span><br><span class="line">						String record &#x3D; buffer.substring(0, delimPos);</span><br><span class="line">						&#x2F;&#x2F; truncate trailing carriage return</span><br><span class="line">						if (delimiter.equals(&quot;\n&quot;) &amp;&amp; record.endsWith(&quot;\r&quot;)) &#123;</span><br><span class="line">							record &#x3D; record.substring(0, record.length() - 1);</span><br><span class="line">						&#125;</span><br><span class="line">						&#x2F;&#x2F;读到数据后，把数据交给collect方法，collect方法负责把数据交到合适的位置（如发布为br变量，或者交给下个operator，或者通过网络发出去）</span><br><span class="line">						ctx.collect(record);</span><br><span class="line">						buffer.delete(0, delimPos + delimiter.length());</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; if we dropped out of this loop due to an EOF, sleep and retry</span><br><span class="line">			if (isRunning) &#123;</span><br><span class="line">				attempt++;</span><br><span class="line">				if (maxNumRetries &#x3D;&#x3D; -1 || attempt &lt; maxNumRetries) &#123;</span><br><span class="line">					LOG.warn(&quot;Lost connection to server socket. Retrying in &quot; + delayBetweenRetries + &quot; msecs...&quot;);</span><br><span class="line">					Thread.sleep(delayBetweenRetries);</span><br><span class="line">				&#125;</span><br><span class="line">				else &#123;</span><br><span class="line">					&#x2F;&#x2F; this should probably be here, but some examples expect simple exists of the stream source</span><br><span class="line">					&#x2F;&#x2F; throw new EOFException(&quot;Reached end of stream and reconnects are not enabled.&quot;);</span><br><span class="line">					break;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; collect trailing data</span><br><span class="line">		if (buffer.length() &gt; 0) &#123;</span><br><span class="line">			ctx.collect(buffer.toString());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>整段代码里，只有collect方法有些复杂度，后面我们在讲到flink的对象机制时会结合来讲，此处知道collect方法会收集结果，然后发送给接收者即可。在我们的wordcount里，这个算子的接收者就是被chain在一起的flatmap算子，不记得这个示例程序的话，可以返回第一章去看一下。</p>
<h3 id="4-2-从数据输入到数据处理——OneInputStreamOperator-amp-AbstractUdfStreamOperator"><a href="#4-2-从数据输入到数据处理——OneInputStreamOperator-amp-AbstractUdfStreamOperator" class="headerlink" title="4.2 从数据输入到数据处理——OneInputStreamOperator &amp; AbstractUdfStreamOperator"></a>4.2 从数据输入到数据处理——OneInputStreamOperator &amp; AbstractUdfStreamOperator</h3><p>StreamSource是用来开启整个流的算子，而承接输入数据并进行处理的算子就是OneInputStreamOperator、TwoInputStreamOperator等。<br><img src="http://static.zybuluo.com/bethunebtj/9itne7dj58lkkb4mtrt9c8q5/image_1cdc1tbgs136k1ppf17at14fumjf2d.png" alt="image_1cdc1tbgs136k1ppf17at14fumjf2d.png-126.7kB"><br>整个StreamOperator的继承关系如上图所示（图很大，建议点开放大看）。<br>OneInputStreamOperator这个接口的逻辑很简单：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public interface OneInputStreamOperator&lt;IN, OUT&gt; extends StreamOperator&lt;OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * Processes one element that arrived at this operator.</span><br><span class="line">	 * This method is guaranteed to not be called concurrently with other methods of the operator.</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	void processElement(StreamRecord&lt;IN&gt; element) throws Exception;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * Processes a &#123;@link Watermark&#125;.</span><br><span class="line">	 * This method is guaranteed to not be called concurrently with other methods of the operator.</span><br><span class="line">	 *</span><br><span class="line">	 * @see org.apache.flink.streaming.api.watermark.Watermark</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	void processWatermark(Watermark mark) throws Exception;</span><br><span class="line"></span><br><span class="line">	void processLatencyMarker(LatencyMarker latencyMarker) throws Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而实现了这个接口的StreamFlatMap算子也很简单，没什么可说的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class StreamFlatMap&lt;IN, OUT&gt;</span><br><span class="line">		extends AbstractUdfStreamOperator&lt;OUT, FlatMapFunction&lt;IN, OUT&gt;&gt;</span><br><span class="line">		implements OneInputStreamOperator&lt;IN, OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">	private static final long serialVersionUID &#x3D; 1L;</span><br><span class="line"></span><br><span class="line">	private transient TimestampedCollector&lt;OUT&gt; collector;</span><br><span class="line"></span><br><span class="line">	public StreamFlatMap(FlatMapFunction&lt;IN, OUT&gt; flatMapper) &#123;</span><br><span class="line">		super(flatMapper);</span><br><span class="line">		chainingStrategy &#x3D; ChainingStrategy.ALWAYS;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void open() throws Exception &#123;</span><br><span class="line">		super.open();</span><br><span class="line">		collector &#x3D; new TimestampedCollector&lt;&gt;(output);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void processElement(StreamRecord&lt;IN&gt; element) throws Exception &#123;</span><br><span class="line">		collector.setTimestamp(element);</span><br><span class="line">		userFunction.flatMap(element.getValue(), collector);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从类图里可以看到，flink为我们封装了一个算子的基类<code>AbstractUdfStreamOperator</code>，提供了一些通用功能，比如把context赋给算子，保存快照等等，其中最为大家了解的应该是这两个：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void open() throws Exception &#123;</span><br><span class="line">	super.open();</span><br><span class="line">	FunctionUtils.openFunction(userFunction, new Configuration());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void close() throws Exception &#123;</span><br><span class="line">	super.close();</span><br><span class="line">	functionsClosed &#x3D; true;</span><br><span class="line">	FunctionUtils.closeFunction(userFunction);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这两个就是flink提供的<code>Rich***Function</code>系列算子的open和close方法被执行的地方。</p>
<h3 id="4-3-StreamSink"><a href="#4-3-StreamSink" class="headerlink" title="4.3 StreamSink"></a>4.3 StreamSink</h3><p>StreamSink着实没什么可说的，逻辑很简单，值得一提的只有两个方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void processElement(StreamRecord&lt;IN&gt; element) throws Exception &#123;</span><br><span class="line">	sinkContext.element &#x3D; element;</span><br><span class="line">	userFunction.invoke(element.getValue(), sinkContext);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">protected void reportOrForwardLatencyMarker(LatencyMarker maker) &#123;</span><br><span class="line">	&#x2F;&#x2F; all operators are tracking latencies</span><br><span class="line">	this.latencyGauge.reportLatency(maker, true);</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; sinks don&#39;t forward latency markers</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>processElement</code> 是继承自StreamOperator的方法。<code>reportOrForwardLatencyMarker</code>是用来计算延迟的，前面提到StreamSource会产生LateMarker，用于记录数据计算时间，就是在这里完成了计算。</p>
<p>算子这部分逻辑相对简单清晰，就讲这么多吧。</p>
<h2 id="5-为执行保驾护航——Fault-Tolerant与保证Exactly-Once语义"><a href="#5-为执行保驾护航——Fault-Tolerant与保证Exactly-Once语义" class="headerlink" title="5. 为执行保驾护航——Fault Tolerant与保证Exactly-Once语义"></a>5. 为执行保驾护航——Fault Tolerant与保证Exactly-Once语义</h2><h3 id="5-1-Fault-Tolerant演进之路"><a href="#5-1-Fault-Tolerant演进之路" class="headerlink" title="5.1 Fault Tolerant演进之路"></a>5.1 Fault Tolerant演进之路</h3><p>对于7×24小时不间断运行的流程序来说，要保证fault tolerant是很难的，这不像是离线任务，如果失败了只需要清空已有结果，重新跑一次就可以了。对于流任务，如果要保证能够重新处理已处理过的数据，就要把数据保存下来；而这就面临着几个问题：比如一是保存多久的数据？二是重复计算的数据应该怎么处理，怎么保证幂等性？<br>对于一个流系统，我们有以下希望：</p>
<ol>
<li>最好能做到exactly-once</li>
<li>处理延迟越低越好</li>
<li>吞吐量越高越好</li>
<li>计算模型应当足够简单易用，又具有足够的表达力</li>
<li>从错误恢复的开销越低越好</li>
<li>足够的流控制能力（背压能力）</li>
</ol>
<h4 id="5-1-1-Storm的Record-acknowledgement模式"><a href="#5-1-1-Storm的Record-acknowledgement模式" class="headerlink" title="5.1.1 Storm的Record acknowledgement模式"></a>5.1.1 Storm的Record acknowledgement模式</h4><p>storm的fault tolerant是这样工作的：每一个被storm的operator处理的数据都会向其上一个operator发送一份应答消息，通知其已被下游处理。storm的源operator保存了所有已发送的消息的每一个下游算子的应答消息，当它收到来自sink的应答时，它就知道该消息已经被完整处理，可以移除了。<br>如果没有收到应答，storm就会重发该消息。显而易见，这是一种at least once的逻辑。另外，这种方式面临着严重的幂等性问题，例如对一个count算子，如果count的下游算子出错，source重发该消息，那么防止该消息被count两遍的逻辑需要程序员自己去实现。最后，这样一种处理方式非常低效，吞吐量很低。</p>
<h4 id="5-1-2-Spark-streaming的micro-batch模式"><a href="#5-1-2-Spark-streaming的micro-batch模式" class="headerlink" title="5.1.2 Spark streaming的micro batch模式"></a>5.1.2 Spark streaming的micro batch模式</h4><p>前面提到，storm的实现方式就注定了与高吞吐量无缘。那么，为了提高吞吐量，把一批数据聚集在一起处理就是很自然的选择。Spark Streaming的实现就是基于这样的思路：<br>我们可以在完全的连续计算与完全的分批计算中间取折中，通过控制每批计算数据的大小来控制延迟与吞吐量的制约，如果想要低延迟，就用小一点的batch，如果想要大吞吐量，就不得不忍受更高的延迟（更久的等待数据到来的时间和更多的计算），如下图所示。<br><img src="http://static.zybuluo.com/bethunebtj/1uwp211uaxpb6nqbztfkh3u1/image_1ceop58ha180p1h3ren58jk15gb9.png" alt="image_1ceop58ha180p1h3ren58jk15gb9.png-105.7kB"><br>以这样的方式，可以在每个batch中做到exactly-once，但是这种方式也有其弊端：<br>首先，batch的方式使得一些需要跨batch的操作变得非常困难，例如session window；用户不得不自己想办法去实现相关逻辑。<br>其次，batch模式很难做好背压。当一个batch因为种种原因处理慢了，那么下一个batch要么不得不容纳更多的新来数据，要么不得不堆积更多的batch，整个任务可能会被拖垮，这是一个非常致命的问题。<br>最后，batch的方式基本意味着其延迟是有比较高的下限的，实时性上不好。</p>
<h4 id="5-1-3-Google-Cloud-Dataflow的事务式模型"><a href="#5-1-3-Google-Cloud-Dataflow的事务式模型" class="headerlink" title="5.1.3 Google Cloud Dataflow的事务式模型"></a>5.1.3 Google Cloud Dataflow的事务式模型</h4><p>我们在传统数据库，如mysql中使用binlog来完成事务，这样的思路也可以被用在实现exactly-once模型中。例如，我们可以log下每个数据元素每一次被处理时的结果和当时所处的操作符的状态。这样，当我们需要fault tolerant时，我们只需要读一下log就可以了。这种模式规避了storm和spark所面临的问题，并且能够很好的实现exactly-once，唯一的弊端是：如何尽可能的减少log的成本？Flink给了我们答案。</p>
<h4 id="5-1-4-Flink的分布式快照机制"><a href="#5-1-4-Flink的分布式快照机制" class="headerlink" title="5.1.4 Flink的分布式快照机制"></a>5.1.4 Flink的分布式快照机制</h4><p> 实现exactly-once的关键是什么？是能够准确的知道和快速记录下来当前的operator的状态、当前正在处理的元素（以及正处在不同算子之间传递的元素）。如果上面这些可以做到，那么fault tolerant无非就是从持久化存储中读取上次记录的这些元信息，并且恢复到程序中。那么Flink是如何实现的呢？</p>
<p>Flink的分布式快照的核心是其轻量级异步分布式快照机制。为了实现这一机制，flink引入了一个概念，叫做Barrier。Barrier是一种标记，它被source产生并且插入到流数据中，被发送到下游节点。当下游节点处理到该barrier标志时，这就意味着在该barrier插入到流数据时，已经进入系统的数据在当前节点已经被处理完毕。<br><img src="http://static.zybuluo.com/bethunebtj/r0h3z9im5o9ijqlvvl7vjgrt/image_1ceos05badva20hb5glen1voqm.png" alt="image_1ceos05badva20hb5glen1voqm.png-15.3kB"></p>
<p>如图所示，每当一个barrier流过一个算子节点时，就说明了在该算子上，可以触发一次检查点，用以保存当前节点的状态和已经处理过的数据，这就是一份快照。（在这里可以联想一下micro-batch，把barrier想象成分割每个batch的逻辑，会好理解一点）这样的方式下，记录快照就像和前面提到的micro-batch一样容易。</p>
<p>与此同时，该算子会向下游发送该barrier。因为数据在算子之间是按顺序发送的，所以当下游节点收到该barrier时，也就意味着同样的一批数据在下游节点上也处理完毕，可以进行一次checkpoint，保存基于该节点的一份快照，快照完成后，会通知JobMananger自己完成了这个快照。这就是分布式快照的基本含义。</p>
<p>再看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/fp1rtm1pjv12lo6nld7bns5j/image_1ceot7q13apu1a04170af7j1jao34.png" alt="image_1ceot7q13apu1a04170af7j1jao34.png-66.6kB"><br>有时，有的算子的上游节点和下游节点都不止一个，应该怎么处理呢？如果有不止一个下游节点，就向每个下游发送barrier。同理，如果有不止一个上游节点，那么就要等到所有上游节点的同一批次的barrier到达之后，才能触发checkpoint。因为每个节点运算速度不同，所以有的上游节点可能已经在发下个barrier周期的数据了，有的上游节点还没发送本次的barrier，这时候，当前算子就要缓存一下提前到来的数据，等比较慢的上游节点发送barrier之后，才能处理下一批数据。</p>
<p>当整个程序的最后一个算子sink都收到了这个barrier，也就意味着这个barrier和上个barrier之间所夹杂的这批元素已经全部落袋为安。这时，最后一个算子通知JobManager整个流程已经完成，而JobManager随后发出通知，要求所有算子删除本次快照内容，以完成清理。这整个部分，就是Flink的<strong>两阶段提交的checkpoint过程</strong>，如下面四幅图所示：<br><img src="http://static.zybuluo.com/bethunebtj/achr7r6gcstodi7m9gc270r5/image_1ceot517e14g31u2u1mnt12o91dkb1g.png" alt="image_1ceot517e14g31u2u1mnt12o91dkb1g.png-175.5kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/sibwkuskxs20xjcqkn872xg5/image_1ceot5kqbnik1f2i1dss1q5c1a1t.png" alt="image_1ceot5kqbnik1f2i1dss1q5c1a1t.png-221.3kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/0ly9zl3w3twknw7ftalv722a/image_1ceot64dppjtojkq3n1jl5j0h2a.png" alt="image_1ceot64dppjtojkq3n1jl5j0h2a.png-297.8kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/b5wrovrsrghkxuumgf6rgabc/image_1ceot6kes56sidn1f2u1voo19kf2n.png" alt="image_1ceot6kes56sidn1f2u1voo19kf2n.png-255.5kB"></p>
<p>总之，通过这种方式，flink实现了我们前面提到的六项对流处理框架的要求：exactly-once、低延迟、高吞吐、易用的模型、方便的恢复机制。</p>
<p>最后，贴一个美团做的flink与storm的性能对比：<a href="https://tech.meituan.com/Flink_Benchmark.html">flink与storm的性能对比</a></p>
<h3 id="5-2-checkpoint的生命周期"><a href="#5-2-checkpoint的生命周期" class="headerlink" title="5.2 checkpoint的生命周期"></a>5.2 checkpoint的生命周期</h3><p>接下来，我们结合源码来看看flink的checkpoint到底是如何实现其生命周期的：</p>
<blockquote>
<p>由于flink提供的SocketSource并不支持checkpoint，所以这里我以<code>FlinkKafkaConsumer010</code>作为sourceFunction。</p>
</blockquote>
<h4 id="5-2-1-触发checkpoint"><a href="#5-2-1-触发checkpoint" class="headerlink" title="5.2.1 触发checkpoint"></a>5.2.1 触发checkpoint</h4><p>要完成一次checkpoint，第一步必然是发起checkpoint请求。那么，这个请求是哪里发出的，怎么发出的，又由谁控制呢？<br>还记得如果我们要设置checkpoint的话，需要指定checkpoint间隔吧？既然是一个指定间隔触发的功能，那应该会有类似于Scheduler的东西存在，flink里，这个负责触发checkpoint的类是<code>CheckpointCoordinator</code>。</p>
<p>flink在提交job时，会启动这个类的<code>startCheckpointScheduler</code>方法，如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void startCheckpointScheduler() &#123;</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (shutdown) &#123;</span><br><span class="line">			throw new IllegalArgumentException(&quot;Checkpoint coordinator is shut down&quot;);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; make sure all prior timers are cancelled</span><br><span class="line">		stopCheckpointScheduler();</span><br><span class="line"></span><br><span class="line">		periodicScheduling &#x3D; true;</span><br><span class="line">		currentPeriodicTrigger &#x3D; timer.scheduleAtFixedRate(</span><br><span class="line">				new ScheduledTrigger(), </span><br><span class="line">				baseInterval, baseInterval, TimeUnit.MILLISECONDS);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private final class ScheduledTrigger implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void run() &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			triggerCheckpoint(System.currentTimeMillis(), true);</span><br><span class="line">		&#125;</span><br><span class="line">		catch (Exception e) &#123;</span><br><span class="line">			LOG.error(&quot;Exception while triggering checkpoint.&quot;, e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>启动之后，就会以设定好的频率调用<code>triggerCheckPoint()</code>方法。这个方法太长，我大概说一下都做了什么：</p>
<ul>
<li>检查符合触发checkpoint的条件，例如如果禁止了周期性的checkpoint，尚未达到触发checkpoint的最小间隔等等，就直接return</li>
<li>检查是否所有需要checkpoint和需要响应checkpoint的ACK（ack涉及到checkpoint的两阶段提交，后面会讲）的task都处于running状态，否则return</li>
<li>如果都符合，那么执行<code>checkpointID = checkpointIdCounter.getAndIncrement();</code>以生成一个新的id，然后生成一个<code>PendingCheckpoint</code>。PendingCheckpoint是一个启动了的checkpoint，但是还没有被确认。等到所有的task都确认了本次checkpoint，那么这个checkpoint对象将转化为一个<code>CompletedCheckpoint</code>。</li>
<li>定义一个超时callback，如果checkpoint执行了很久还没完成，就把它取消</li>
<li>触发MasterHooks，用户可以定义一些额外的操作，用以增强checkpoint的功能（如准备和清理外部资源）</li>
<li>接下来是核心逻辑：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  &#x2F;&#x2F; send the messages to the tasks that trigger their checkpoint</span><br><span class="line">for (Execution execution: executions) &#123;</span><br><span class="line">	execution.triggerCheckpoint(checkpointID, timestamp, checkpointOptions);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里是调用了Execution的triggerCheckpoint方法，一个execution就是一个executionVertex的实际执行者。我们看一下这个方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void triggerCheckpoint(long checkpointId, long timestamp, CheckpointOptions checkpointOptions) &#123;</span><br><span class="line">	final LogicalSlot slot &#x3D; assignedResource;</span><br><span class="line"></span><br><span class="line">	if (slot !&#x3D; null) &#123;</span><br><span class="line">	&#x2F;&#x2F;TaskManagerGateway是用来跟taskManager进行通信的组件</span><br><span class="line">		final TaskManagerGateway taskManagerGateway &#x3D; slot.getTaskManagerGateway();</span><br><span class="line"></span><br><span class="line">		taskManagerGateway.triggerCheckpoint(attemptId, getVertex().getJobId(), checkpointId, timestamp, checkpointOptions);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		LOG.debug(&quot;The execution has no slot assigned. This indicates that the execution is &quot; +</span><br><span class="line">			&quot;no longer running.&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再往下跟就进入了<code>Task</code>类的范畴，我们将在下一小节进行解读。本小节主要讲了<code>CheckpointCoordinator</code>类是如何触发一次checkpoint，从其名字也可以看出来其功能：检查点协调器。</p>
<h4 id="5-2-2-Task层面checkpoint的准备工作"><a href="#5-2-2-Task层面checkpoint的准备工作" class="headerlink" title="5.2.2 Task层面checkpoint的准备工作"></a>5.2.2 Task层面checkpoint的准备工作</h4><p>先说Task类中的部分，该类创建了一个<code>CheckpointMetaData</code>的对象，并且生成了一个Runable匿名类用于执行checkpoint，然后以异步的方式触发了该Runable：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void triggerCheckpointBarrier(</span><br><span class="line">		final long checkpointID,</span><br><span class="line">		long checkpointTimestamp,</span><br><span class="line">		final CheckpointOptions checkpointOptions) &#123;</span><br><span class="line"></span><br><span class="line">           ......</span><br><span class="line"></span><br><span class="line">		Runnable runnable &#x3D; new Runnable() &#123;</span><br><span class="line">			@Override</span><br><span class="line">			public void run() &#123;</span><br><span class="line">				&#x2F;&#x2F; set safety net from the task&#39;s context for checkpointing thread</span><br><span class="line">				LOG.debug(&quot;Creating FileSystem stream leak safety net for &#123;&#125;&quot;, Thread.currentThread().getName());</span><br><span class="line">				FileSystemSafetyNet.setSafetyNetCloseableRegistryForThread(safetyNetCloseableRegistry);</span><br><span class="line"></span><br><span class="line">				try &#123;</span><br><span class="line">					boolean success &#x3D; invokable.triggerCheckpoint(checkpointMetaData, checkpointOptions);</span><br><span class="line">					if (!success) &#123;</span><br><span class="line">						checkpointResponder.declineCheckpoint(</span><br><span class="line">								getJobID(), getExecutionId(), checkpointID,</span><br><span class="line">								new CheckpointDeclineTaskNotReadyException(taskName));</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">				</span><br><span class="line">                   ......</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;;</span><br><span class="line">		executeAsyncCallRunnable(runnable, String.format(&quot;Checkpoint Trigger for %s (%s).&quot;, taskNameWithSubtask, executionId));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上面代码里的invokable事实上就是我们的StreamTask了。Task类实际上是将checkpoint委托给了更具体的类去执行，而StreamTask也将委托给更具体的类，直到业务代码。<br>StreamTask是这样实现的：</p>
<ul>
<li>如果task还在运行，那就可以进行checkpoint。方法是先向下游所有出口广播一个Barrier，然后触发本task的State保存。</li>
<li>如果task结束了，那我们就要通知下游取消本次checkpoint，方法是发送一个CancelCheckpointMarker，这是类似于Barrier的另一种消息。</li>
<li>注意，从这里开始，整个执行链路上开始出现Barrier，可以和前面讲Fault Tolerant原理的地方结合看一下。 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private boolean performCheckpoint(</span><br><span class="line">		CheckpointMetaData checkpointMetaData,</span><br><span class="line">		CheckpointOptions checkpointOptions,</span><br><span class="line">		CheckpointMetrics checkpointMetrics) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (isRunning) &#123;</span><br><span class="line">		</span><br><span class="line">			operatorChain.broadcastCheckpointBarrier(</span><br><span class="line">					checkpointMetaData.getCheckpointId(),</span><br><span class="line">					checkpointMetaData.getTimestamp(),</span><br><span class="line">					checkpointOptions);</span><br><span class="line"></span><br><span class="line">			checkpointState(checkpointMetaData, checkpointOptions, checkpointMetrics);</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line"></span><br><span class="line">               ......</span><br><span class="line">               </span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
完成<code>broadcastCheckpointBarrier</code>方法后，在<code>checkpointState()</code>方法中，StreamTask还做了很多别的工作：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void executeCheckpointing() throws Exception &#123;</span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line"></span><br><span class="line">	try &#123;</span><br><span class="line">	    &#x2F;&#x2F;这里，就是调用StreamOperator进行snapshotState的入口方法</span><br><span class="line">		for (StreamOperator&lt;?&gt; op : allOperators) &#123;</span><br><span class="line">			checkpointStreamOperator(op);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit</span><br><span class="line">		AsyncCheckpointRunnable asyncCheckpointRunnable &#x3D; new AsyncCheckpointRunnable(</span><br><span class="line">			owner,</span><br><span class="line">			operatorSnapshotsInProgress,</span><br><span class="line">			checkpointMetaData,</span><br><span class="line">			checkpointMetrics,</span><br><span class="line">			startAsyncPartNano);</span><br><span class="line"></span><br><span class="line">		owner.cancelables.registerCloseable(asyncCheckpointRunnable);</span><br><span class="line">		&#x2F;&#x2F;这里注册了一个Runnable，在执行完checkpoint之后向JobManager发出CompletedCheckPoint消息，这也是fault tolerant两阶段提交的一部分</span><br><span class="line">		owner.asyncOperationsThreadPool.submit(asyncCheckpointRunnable);</span><br><span class="line">		</span><br><span class="line">		......</span><br><span class="line">	</span><br><span class="line">	&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
说到checkpoint，我们印象里最直观的感受肯定是我们的一些做聚合的操作符的状态保存，比如sum的和以及count的值等等。这些内容就是StreamOperator部分将要触发保存的内容。可以看到，除了我们直观的这些操作符的状态保存外，flink的checkpoint做了大量的其他工作。</li>
</ul>
<p>接下来，我们就把目光转向操作符的checkpoint机制。</p>
<h4 id="5-2-3-操作符的状态保存及barrier传递"><a href="#5-2-3-操作符的状态保存及barrier传递" class="headerlink" title="5.2.3 操作符的状态保存及barrier传递"></a>5.2.3 操作符的状态保存及barrier传递</h4><p>第四章时，我们已经了解了StreamOperator的类关系，这里，我们就直接接着上一节的<code>checkpointStreamOperator(op)</code>方法往下讲。<br>顺便，前面也提到了，在进行checkpoint之前，operator初始化时，会执行一个<code>initializeState</code>方法，在该方法中，如果task是从失败中恢复的话，其保存的state也会被restore进来。</p>
<p>传递barrier是在进行本operator的statesnapshot之前完成的，我们先来看看其逻辑，其实和传递一条数据是类似的，就是生成一个<code>CheckpointBarrier</code>对象，然后向每个streamOutput写进去：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   public void broadcastCheckpointBarrier(long id, long timestamp, CheckpointOptions checkpointOptions) throws IOException &#123;</span><br><span class="line">	try &#123;</span><br><span class="line">		CheckpointBarrier barrier &#x3D; new CheckpointBarrier(id, timestamp, checkpointOptions);</span><br><span class="line">		for (RecordWriterOutput&lt;?&gt; streamOutput : streamOutputs) &#123;</span><br><span class="line">			streamOutput.broadcastEvent(barrier);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	catch (InterruptedException e) &#123;</span><br><span class="line">		throw new IOException(&quot;Interrupted while broadcasting checkpoint barrier&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下游的operator接收到本barrier，就会触发其自身的checkpoint。</p>
<p>StreamTask在执行完broadcastCheckpointBarrier之后，<br>我们当前的wordcount程序里有两个operator chain，分别是：</p>
<ul>
<li>kafka source -&gt; flatmap</li>
<li>keyed aggregation -&gt; sink</li>
</ul>
<p>我们就按这个顺序来捋一下checkpoint的过程。</p>
<p>1.kafka source的checkpoint过程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final void snapshotState(FunctionSnapshotContext context) throws Exception &#123;</span><br><span class="line">	if (!running) &#123;</span><br><span class="line">		LOG.debug(&quot;snapshotState() called on closed source&quot;);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		unionOffsetStates.clear();</span><br><span class="line"></span><br><span class="line">		final AbstractFetcher&lt;?, ?&gt; fetcher &#x3D; this.kafkaFetcher;</span><br><span class="line">		if (fetcher &#x3D;&#x3D; null) &#123;</span><br><span class="line">			&#x2F;&#x2F; the fetcher has not yet been initialized, which means we need to return the</span><br><span class="line">			&#x2F;&#x2F; originally restored offsets or the assigned partitions</span><br><span class="line">			for (Map.Entry&lt;KafkaTopicPartition, Long&gt; subscribedPartition : subscribedPartitionsToStartOffsets.entrySet()) &#123;</span><br><span class="line">				unionOffsetStates.add(Tuple2.of(subscribedPartition.getKey(), subscribedPartition.getValue()));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">				&#x2F;&#x2F; the map cannot be asynchronously updated, because only one checkpoint call can happen</span><br><span class="line">				&#x2F;&#x2F; on this function at a time: either snapshotState() or notifyCheckpointComplete()</span><br><span class="line">				pendingOffsetsToCommit.put(context.getCheckpointId(), restoredState);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			HashMap&lt;KafkaTopicPartition, Long&gt; currentOffsets &#x3D; fetcher.snapshotCurrentState();</span><br><span class="line"></span><br><span class="line">			if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">				&#x2F;&#x2F; the map cannot be asynchronously updated, because only one checkpoint call can happen</span><br><span class="line">				&#x2F;&#x2F; on this function at a time: either snapshotState() or notifyCheckpointComplete()</span><br><span class="line">				pendingOffsetsToCommit.put(context.getCheckpointId(), currentOffsets);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			for (Map.Entry&lt;KafkaTopicPartition, Long&gt; kafkaTopicPartitionLongEntry : currentOffsets.entrySet()) &#123;</span><br><span class="line">				unionOffsetStates.add(</span><br><span class="line">						Tuple2.of(kafkaTopicPartitionLongEntry.getKey(), kafkaTopicPartitionLongEntry.getValue()));</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">			&#x2F;&#x2F; truncate the map of pending offsets to commit, to prevent infinite growth</span><br><span class="line">			while (pendingOffsetsToCommit.size() &gt; MAX_NUM_PENDING_CHECKPOINTS) &#123;</span><br><span class="line">				pendingOffsetsToCommit.remove(0);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>kafka的snapshot逻辑就是记录一下当前消费的offsets，然后做成tuple（partitiion，offset）放进一个<code>StateBackend</code>里。StateBackend是flink抽象出来的一个用于保存状态的接口。</p>
<p>2.<strong>FlatMap算子的checkpoint过程</strong><br>没什么可说的，就是调用了snapshotState()方法而已。</p>
<p>3.<strong>本operator chain的state保存过程</strong><br>细心的同学应该注意到了，各个算子的snapshot方法只把自己的状态保存到了StateBackend里，没有写入的持久化操作。这部分操作被放到了<code>AbstractStreamOperator</code>中，由flink统一负责持久化。其实不需要看源码我们也能想出来，持久化无非就是把这些数据用一个流写到磁盘或者别的地方，接下来我们来看看是不是这样：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">         &#x2F;&#x2F;还是AbstractStreamOperator.java的snapshotState方法</span><br><span class="line">if (null !&#x3D; operatorStateBackend) &#123;</span><br><span class="line">	snapshotInProgress.setOperatorStateManagedFuture(</span><br><span class="line">		operatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么这个operatorStateBackend是怎么保存状态的呢？</p>
<ul>
<li>首先把各个算子的state做了一份深拷贝；</li>
<li>然后以异步的方式执行了一个内部类的runnable，该内部类的run方法实现了一个模版方法，首先打开stream，然后写入数据，然后再关闭stream。</li>
</ul>
<p>我们来看看这个写入数据的方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">            public SnapshotResult&lt;OperatorStateHandle&gt; performOperation() throws Exception &#123;</span><br><span class="line">	long asyncStartTime &#x3D; System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line">	CheckpointStreamFactory.CheckpointStateOutputStream localOut &#x3D; this.out;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; get the registered operator state infos ...</span><br><span class="line">	List&lt;RegisteredOperatorBackendStateMetaInfo.Snapshot&lt;?&gt;&gt; operatorMetaInfoSnapshots &#x3D;</span><br><span class="line">		new ArrayList&lt;&gt;(registeredOperatorStatesDeepCopies.size());</span><br><span class="line"></span><br><span class="line">	for (Map.Entry&lt;String, PartitionableListState&lt;?&gt;&gt; entry : registeredOperatorStatesDeepCopies.entrySet()) &#123;</span><br><span class="line">		operatorMetaInfoSnapshots.add(entry.getValue().getStateMetaInfo().snapshot());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; ... write them all in the checkpoint stream ...</span><br><span class="line">	DataOutputView dov &#x3D; new DataOutputViewStreamWrapper(localOut);</span><br><span class="line"></span><br><span class="line">	OperatorBackendSerializationProxy backendSerializationProxy &#x3D;</span><br><span class="line">		new OperatorBackendSerializationProxy(operatorMetaInfoSnapshots, broadcastMetaInfoSnapshots);</span><br><span class="line"></span><br><span class="line">	backendSerializationProxy.write(dov);</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注释写的很清楚，我就不多说了。</p>
<p>4.<strong>后继operatorChain的checkpoint过程</strong><br>前面说到，在flink的流中，barrier流过时会触发checkpoint。在上面第1步中，上游节点已经发出了Barrier，所以在我们的keyed aggregation -&gt; sink 这个operatorchain中，我们将首先捕获这个barrier。</p>
<p>捕获barrier的过程其实就是处理input数据的过程，对应着<code>StreamInputProcessor.processInput()</code>方法，该方法我们在第四章已经讲过，这里我们简单回顾一下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">         &#x2F;&#x2F;每个元素都会触发这一段逻辑，如果下一个数据是buffer，则从外围的while循环里进入处理用户数据的逻辑；这个方法里默默的处理了barrier的逻辑</span><br><span class="line">         final BufferOrEvent bufferOrEvent &#x3D; barrierHandler.getNextNonBlocked();</span><br><span class="line">if (bufferOrEvent !&#x3D; null) &#123;</span><br><span class="line">	if (bufferOrEvent.isBuffer()) &#123;</span><br><span class="line">		currentChannel &#x3D; bufferOrEvent.getChannelIndex();</span><br><span class="line">		currentRecordDeserializer &#x3D; recordDeserializers[currentChannel];</span><br><span class="line">		currentRecordDeserializer.setNextBuffer(bufferOrEvent.getBuffer());</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		&#x2F;&#x2F; Event received</span><br><span class="line">		final AbstractEvent event &#x3D; bufferOrEvent.getEvent();</span><br><span class="line">		if (event.getClass() !&#x3D; EndOfPartitionEvent.class) &#123;</span><br><span class="line">			throw new IOException(&quot;Unexpected event: &quot; + event);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>处理barrier的过程在这段代码里没有体现，因为被包含在了<code>getNextNonBlocked()</code>方法中，我们看下这个方法的核心逻辑：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">         &#x2F;&#x2F;BarrierBuffer.getNextNonBlocked方法</span><br><span class="line">else if (bufferOrEvent.getEvent().getClass() &#x3D;&#x3D; CheckpointBarrier.class) &#123;</span><br><span class="line">	if (!endOfStream) &#123;</span><br><span class="line">		&#x2F;&#x2F; process barriers only if there is a chance of the checkpoint completing</span><br><span class="line">		processBarrier((CheckpointBarrier) bufferOrEvent.getEvent(), bufferOrEvent.getChannelIndex());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">else if (bufferOrEvent.getEvent().getClass() &#x3D;&#x3D; CancelCheckpointMarker.class) &#123;</span><br><span class="line">	processCancellationBarrier((CancelCheckpointMarker) bufferOrEvent.getEvent());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先提一嘴，大家还记得之前的部分也提到过CheckpointMarker吧，这里正好也对上了。</p>
<p>处理barrier也是个麻烦事，大家回想一下5.1节提到的屏障的原理图，一个opertor必须收到从每个inputchannel发过来的同一序号的barrier之后才能发起本节点的checkpoint，如果有的channel的数据处理的快了，那该barrier后的数据还需要缓存起来，如果有的inputchannel被关闭了，那它就不会再发送barrier过来了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void processBarrier(CheckpointBarrier receivedBarrier, int channelIndex) throws Exception &#123;</span><br><span class="line">		final long barrierId &#x3D; receivedBarrier.getId();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; fast path for single channel cases</span><br><span class="line">		if (totalNumberOfInputChannels &#x3D;&#x3D; 1) &#123;</span><br><span class="line">			if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; new checkpoint</span><br><span class="line">				currentCheckpointId &#x3D; barrierId;</span><br><span class="line">				notifyCheckpoint(receivedBarrier);</span><br><span class="line">			&#125;</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; -- general code path for multiple input channels --</span><br><span class="line"></span><br><span class="line">		if (numBarriersReceived &gt; 0) &#123;</span><br><span class="line">			&#x2F;&#x2F; this is only true if some alignment is already progress and was not canceled</span><br><span class="line"></span><br><span class="line">			if (barrierId &#x3D;&#x3D; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; regular case</span><br><span class="line">				onBarrier(channelIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			else if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; we did not complete the current checkpoint, another started before</span><br><span class="line">				LOG.warn(&quot;Received checkpoint barrier for checkpoint &#123;&#125; before completing current checkpoint &#123;&#125;. &quot; +</span><br><span class="line">						&quot;Skipping current checkpoint.&quot;, barrierId, currentCheckpointId);</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; let the task know we are not completing this</span><br><span class="line">				notifyAbort(currentCheckpointId, new CheckpointDeclineSubsumedException(barrierId));</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; abort the current checkpoint</span><br><span class="line">				releaseBlocksAndResetBarriers();</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; begin a the new checkpoint</span><br><span class="line">				beginNewAlignment(barrierId, channelIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			else &#123;</span><br><span class="line">				&#x2F;&#x2F; ignore trailing barrier from an earlier checkpoint (obsolete now)</span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		else if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">			&#x2F;&#x2F; first barrier of a new checkpoint</span><br><span class="line">			beginNewAlignment(barrierId, channelIndex);</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line">			&#x2F;&#x2F; either the current checkpoint was canceled (numBarriers &#x3D;&#x3D; 0) or</span><br><span class="line">			&#x2F;&#x2F; this barrier is from an old subsumed checkpoint</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; check if we have all barriers - since canceled checkpoints always have zero barriers</span><br><span class="line">		&#x2F;&#x2F; this can only happen on a non canceled checkpoint</span><br><span class="line">		if (numBarriersReceived + numClosedChannels &#x3D;&#x3D; totalNumberOfInputChannels) &#123;</span><br><span class="line">			&#x2F;&#x2F; actually trigger checkpoint</span><br><span class="line">			if (LOG.isDebugEnabled()) &#123;</span><br><span class="line">				LOG.debug(&quot;Received all barriers, triggering checkpoint &#123;&#125; at &#123;&#125;&quot;,</span><br><span class="line">						receivedBarrier.getId(), receivedBarrier.getTimestamp());</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			releaseBlocksAndResetBarriers();</span><br><span class="line">			notifyCheckpoint(receivedBarrier);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>总之，当收到全部的barrier之后，就会触发<code>notifyCheckpoint()</code>，该方法又会调用StreamTask的<code>triggerCheckpoint</code>，和之前的operator是一样的。</p>
<p>如果还有后续的operator的话，就是完全相同的循环，不再赘述。</p>
<p>5.<strong>报告完成checkpoint事件</strong><br>当一个operator保存完checkpoint数据后，就会启动一个异步对象<code>AsyncCheckpointRunnable</code>，用以报告该检查点已完成，其具体逻辑在reportCompletedSnapshotStates中。这个方法把任务又最终委托给了<code>RpcCheckpointResponder</code>这个类：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">checkpointResponder.acknowledgeCheckpoint(</span><br><span class="line">			jobId,</span><br><span class="line">			executionAttemptID,</span><br><span class="line">			checkpointId,</span><br><span class="line">			checkpointMetrics,</span><br><span class="line">			acknowledgedState);</span><br></pre></td></tr></table></figure>
<p>从这个类也可以看出来，它的逻辑是通过rpc的方式远程调JobManager的相关方法完成报告事件，底层也是通过akka实现的。<br>那么，谁响应了这个rpc调用呢？是该任务的JobMaster。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   &#x2F;&#x2F;JobMaster.java</span><br><span class="line">public void acknowledgeCheckpoint(</span><br><span class="line">		final JobID jobID,</span><br><span class="line">		final ExecutionAttemptID executionAttemptID,</span><br><span class="line">		final long checkpointId,</span><br><span class="line">		final CheckpointMetrics checkpointMetrics,</span><br><span class="line">		final TaskStateSnapshot checkpointState) &#123;</span><br><span class="line"></span><br><span class="line">	final CheckpointCoordinator checkpointCoordinator &#x3D; executionGraph.getCheckpointCoordinator();</span><br><span class="line">	final AcknowledgeCheckpoint ackMessage &#x3D; new AcknowledgeCheckpoint(</span><br><span class="line">		jobID,</span><br><span class="line">		executionAttemptID,</span><br><span class="line">		checkpointId,</span><br><span class="line">		checkpointMetrics,</span><br><span class="line">		checkpointState);</span><br><span class="line"></span><br><span class="line">	if (checkpointCoordinator !&#x3D; null) &#123;</span><br><span class="line">		getRpcService().execute(() -&gt; &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				checkpointCoordinator.receiveAcknowledgeMessage(ackMessage);</span><br><span class="line">			&#125; catch (Throwable t) &#123;</span><br><span class="line">				log.warn(&quot;Error while processing checkpoint acknowledgement message&quot;);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		log.error(&quot;Received AcknowledgeCheckpoint message for job &#123;&#125; with no CheckpointCoordinator&quot;,</span><br><span class="line">				jobGraph.getJobID());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>JobMaster反手<del>就是一巴掌</del>就把任务又rpc给了<code>CheckpointCoordinator.receiveAcknowledgeMessage()</code>方法。</p>
<p>之前提到，coordinator在触发checkpoint时，生成了一个<code>PendingCheckpoint</code>，保存了所有operator的id。</p>
<p>当PendingCheckpoint收到一个operator的完成checkpoint的消息时，它就把这个operator从未完成checkpoint的节点集合移动到已完成的集合。当所有的operator都报告完成了checkpoint时，CheckpointCoordinator会触发<code>completePendingCheckpoint()</code>方法，该方法做了以下事情：</p>
<ul>
<li>把pendinCgCheckpoint转换为CompletedCheckpoint</li>
<li>把CompletedCheckpoint加入已完成的检查点集合，并从未完成检查点集合删除该检查点</li>
<li>再度向各个operator发出rpc，通知该检查点已完成</li>
</ul>
<p>本文里，收到这个远程调用的就是那两个operator chain，我们来看看其逻辑:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void notifyCheckpointComplete(long checkpointId) throws Exception &#123;</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (isRunning) &#123;</span><br><span class="line">			LOG.debug(&quot;Notification of complete checkpoint for task &#123;&#125;&quot;, getName());</span><br><span class="line"></span><br><span class="line">			for (StreamOperator&lt;?&gt; operator : operatorChain.getAllOperators()) &#123;</span><br><span class="line">				if (operator !&#x3D; null) &#123;</span><br><span class="line">					operator.notifyCheckpointComplete(checkpointId);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line">			LOG.debug(&quot;Ignoring notification of complete checkpoint for not-running task &#123;&#125;&quot;, getName());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再接下来无非就是层层通知对应的算子做出响应罢了。</p>
<p>至此，flink的两阶段提交的checkpoint逻辑全部完成。</p>
<h3 id="5-3-承载checkpoint数据的抽象：State-amp-StateBackend"><a href="#5-3-承载checkpoint数据的抽象：State-amp-StateBackend" class="headerlink" title="5.3 承载checkpoint数据的抽象：State &amp; StateBackend"></a>5.3 承载checkpoint数据的抽象：State &amp; StateBackend</h3><p>State是快照数据的载体，StateBackend是快照如何被保存的抽象。</p>
<p>State分为 KeyedState和OperatorState，从名字就可以看出来分别对应着keyedStream和其他的oeprator。从State由谁管理上，也可以区分为raw state和Managed state。Flink管理的就是Managed state，用户自己管理的就是raw state。Managed State又分为ValueState、ListState、ReducingState、AggregatingState、FoldingState、MapState这么几种，看名字知用途。</p>
<p>StateBackend目前提供了三个backend，MemoryStateBackend，FsStateBackend，RocksDBStateBackend，都是看名字知用途系列。</p>
<p>State接口、StateBackend接口及其实现都比较简单，代码就不贴了， 尤其State本质上就是一层容器封装。</p>
<p>贴个别人写的状态管理的文章吧：<a href="https://yq.aliyun.com/articles/225623?spm=a2c4e.11153940.blogcont225624.12.7c797f6bZo3tiM">详解Flink中的状态管理</a></p>
<h2 id="6-数据流转——Flink的数据抽象及数据交换过程"><a href="#6-数据流转——Flink的数据抽象及数据交换过程" class="headerlink" title="6.数据流转——Flink的数据抽象及数据交换过程"></a>6.数据流转——Flink的数据抽象及数据交换过程</h2><p>本章打算讲一下flink底层是如何定义和在操作符之间传递数据的。</p>
<h3 id="6-1-flink的数据抽象"><a href="#6-1-flink的数据抽象" class="headerlink" title="6.1 flink的数据抽象"></a>6.1 flink的数据抽象</h3><h4 id="6-1-1-MemorySegment"><a href="#6-1-1-MemorySegment" class="headerlink" title="6.1.1 MemorySegment"></a>6.1.1 MemorySegment</h4><p>Flink作为一个高效的流框架，为了避免JVM的固有缺陷（java对象存储密度低，FGC影响吞吐和响应等），必然走上自主管理内存的道路。</p>
<p>这个<code>MemorySegment</code>就是Flink的内存抽象。默认情况下，一个MemorySegment可以被看做是一个32kb大的内存块的抽象。这块内存既可以是JVM里的一个byte[]，也可以是堆外内存（DirectByteBuffer）。</p>
<p>如果说byte[]数组和direct memory是最底层的存储，那么memorysegment就是在其上覆盖的一层统一抽象。它定义了一系列抽象方法，用于控制和底层内存的交互，如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public abstract class MemorySegment &#123;</span><br><span class="line"></span><br><span class="line">    public abstract byte get(int index);</span><br><span class="line">    </span><br><span class="line">    public abstract void put(int index, byte b);</span><br><span class="line">    </span><br><span class="line">    public int size() ;</span><br><span class="line">    </span><br><span class="line">    public abstract ByteBuffer wrap(int offset, int length);</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以看到，它在提供了诸多直接操作内存的方法外，还提供了一个<code>wrap()</code>方法，将自己包装成一个ByteBuffer，我们待会儿讲这个ByteBuffer。</p>
<p>Flink为MemorySegment提供了两个实现类：<code>HeapMemorySegment</code>和<code>HybridMemorySegment</code>。他们的区别在于前者只能分配堆内存，而后者能用来分配堆内和堆外内存。事实上，Flink框架里，只使用了后者。这是为什么呢？</p>
<p>如果HybridMemorySegment只能用于分配堆外内存的话，似乎更合常理。但是在JVM的世界中，如果一个方法是一个虚方法，那么每次调用时，JVM都要花时间去确定调用的到底是哪个子类实现的该虚方法（方法重写机制，不明白的去看JVM的invokeVirtual指令），也就意味着每次都要去翻方法表；而如果该方法虽然是个虚方法，但实际上整个JVM里只有一个实现（就是说只加载了一个子类进来），那么JVM会很聪明的把它去虚化处理，这样就不用每次调用方法时去找方法表了，能够大大提升性能。但是只分配堆内或者堆外内存不能满足我们的需要，所以就出现了HybridMemorySegment同时可以分配两种内存的设计。</p>
<p>我们可以看看HybridMemorySegment的构造代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HybridMemorySegment(ByteBuffer buffer, Object owner) &#123;</span><br><span class="line">	super(checkBufferAndGetAddress(buffer), buffer.capacity(), owner);</span><br><span class="line">	this.offHeapBuffer &#x3D; buffer;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	HybridMemorySegment(byte[] buffer, Object owner) &#123;</span><br><span class="line">	super(buffer, owner);</span><br><span class="line">	this.offHeapBuffer &#x3D; null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，第一个构造函数的<code>checkBufferAndGetAddress()</code>方法能够得到direct buffer的内存地址，因此可以操作堆外内存。</p>
<h4 id="6-1-2-ByteBuffer与NetworkBufferPool"><a href="#6-1-2-ByteBuffer与NetworkBufferPool" class="headerlink" title="6.1.2 ByteBuffer与NetworkBufferPool"></a>6.1.2 ByteBuffer与NetworkBufferPool</h4><p>在<code>MemorySegment</code>这个抽象之上，Flink在数据从operator内的数据对象在向TaskManager上转移，预备被发给下个节点的过程中，使用的抽象或者说内存对象是<code>Buffer</code>。</p>
<p><strong>注意</strong>，这个Buffer是个flink接口，不是java.nio提供的那个Buffer抽象类。Flink在这一层面同时使用了这两个同名概念，用来存储对象，直接看代码时到处都是各种xxxBuffer很容易混淆：</p>
<ul>
<li>java提供的那个Buffer抽象类在这一层主要用于构建<code>HeapByteBuffer</code>，这个主要是当数据从jvm里的一个对象被序列化成字节数组时用的；</li>
<li>Flink的这个Buffer接口主要是一种flink层面用于传输数据和事件的统一抽象，其实现类是<code>NetworkBuffer</code>，是对<code>MemorySegment</code>的包装。Flink在各个TaskManager之间传递数据时，使用的是这一层的抽象。</li>
</ul>
<p>因为Buffer的底层是MemorySegment，这可能不是JVM所管理的，所以为了知道什么时候一个Buffer用完了可以回收，Flink引入了引用计数的概念，当确认这个buffer没有人引用，就可以回收这一片MemorySegment用于别的地方了（JVM的垃圾回收为啥不用引用计数？读者思考一下）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public abstract class AbstractReferenceCountedByteBuf extends AbstractByteBuf &#123;</span><br><span class="line"></span><br><span class="line">    private volatile int refCnt &#x3D; 1;</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了方便管理<code>NetworkBuffer</code>，Flink提供了<code>BufferPoolFactory</code>，并且提供了唯一实现<code>NetworkBufferPool</code>，这是个工厂模式的应用。</p>
<p>NetworkBufferPool在每个TaskManager上只有一个，负责所有子task的内存管理。其实例化时就会尝试获取所有可由它管理的内存（对于堆内存来说，直接获取所有内存并放入老年代，并令用户对象只在新生代存活，可以极大程度的减少Full GC），我们看看其构造方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public NetworkBufferPool(int numberOfSegmentsToAllocate, int segmentSize) &#123;</span><br><span class="line"></span><br><span class="line">		......</span><br><span class="line">		</span><br><span class="line">		try &#123;</span><br><span class="line">			this.availableMemorySegments &#x3D; new ArrayBlockingQueue&lt;&gt;(numberOfSegmentsToAllocate);</span><br><span class="line">		&#125;</span><br><span class="line">		catch (OutOfMemoryError err) &#123;</span><br><span class="line">			throw new OutOfMemoryError(&quot;Could not allocate buffer queue of length &quot;</span><br><span class="line">					+ numberOfSegmentsToAllocate + &quot; - &quot; + err.getMessage());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			for (int i &#x3D; 0; i &lt; numberOfSegmentsToAllocate; i++) &#123;</span><br><span class="line">				ByteBuffer memory &#x3D; ByteBuffer.allocateDirect(segmentSize);</span><br><span class="line">				availableMemorySegments.add(MemorySegmentFactory.wrapPooledOffHeapMemory(memory, null));</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">        </span><br><span class="line">		long allocatedMb &#x3D; (sizeInLong * availableMemorySegments.size()) &gt;&gt; 20;</span><br><span class="line"></span><br><span class="line">		LOG.info(&quot;Allocated &#123;&#125; MB for network buffer pool (number of memory segments: &#123;&#125;, bytes per segment: &#123;&#125;).&quot;,</span><br><span class="line">				allocatedMb, availableMemorySegments.size(), segmentSize);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>由于NetworkBufferPool只是个工厂，实际的内存池是<code>LocalBufferPool</code>。每个TaskManager都只有一个NetworkBufferPool工厂，但是上面运行的每个task都要有一个和其他task隔离的LocalBufferPool池，这从逻辑上很好理解。另外，NetworkBufferPool会计算自己所拥有的所有内存分片数，在分配新的内存池时对每个内存池应该占有的内存分片数重分配，步骤是：</p>
<ul>
<li>首先，从整个工厂管理的内存片中拿出所有的内存池所需要的最少Buffer数目总和</li>
<li>如果正好分配完，就结束</li>
<li>其次，把所有的剩下的没分配的内存片，按照每个LocalBufferPool内存池的剩余想要容量大小进行按比例分配</li>
<li>剩余想要容量大小是这么个东西：如果该内存池至少需要3个buffer，最大需要10个buffer，那么它的剩余想要容量就是7</li>
</ul>
<p>实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   private void redistributeBuffers() throws IOException &#123;</span><br><span class="line">	assert Thread.holdsLock(factoryLock);</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; All buffers, which are not among the required ones</span><br><span class="line">	final int numAvailableMemorySegment &#x3D; totalNumberOfMemorySegments - numTotalRequiredBuffers;</span><br><span class="line"></span><br><span class="line">	if (numAvailableMemorySegment &#x3D;&#x3D; 0) &#123;</span><br><span class="line">		&#x2F;&#x2F; in this case, we need to redistribute buffers so that every pool gets its minimum</span><br><span class="line">		for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">			bufferPool.setNumBuffers(bufferPool.getNumberOfRequiredMemorySegments());</span><br><span class="line">		&#125;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	long totalCapacity &#x3D; 0; &#x2F;&#x2F; long to avoid int overflow</span><br><span class="line"></span><br><span class="line">	for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">		int excessMax &#x3D; bufferPool.getMaxNumberOfMemorySegments() -</span><br><span class="line">			bufferPool.getNumberOfRequiredMemorySegments();</span><br><span class="line">		totalCapacity +&#x3D; Math.min(numAvailableMemorySegment, excessMax);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; no capacity to receive additional buffers?</span><br><span class="line">	if (totalCapacity &#x3D;&#x3D; 0) &#123;</span><br><span class="line">		return; &#x2F;&#x2F; necessary to avoid div by zero when nothing to re-distribute</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	final int memorySegmentsToDistribute &#x3D; MathUtils.checkedDownCast(</span><br><span class="line">			Math.min(numAvailableMemorySegment, totalCapacity));</span><br><span class="line"></span><br><span class="line">	long totalPartsUsed &#x3D; 0; &#x2F;&#x2F; of totalCapacity</span><br><span class="line">	int numDistributedMemorySegment &#x3D; 0;</span><br><span class="line">	for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">		int excessMax &#x3D; bufferPool.getMaxNumberOfMemorySegments() -</span><br><span class="line">			bufferPool.getNumberOfRequiredMemorySegments();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; shortcut</span><br><span class="line">		if (excessMax &#x3D;&#x3D; 0) &#123;</span><br><span class="line">			continue;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		totalPartsUsed +&#x3D; Math.min(numAvailableMemorySegment, excessMax);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		final int mySize &#x3D; MathUtils.checkedDownCast(</span><br><span class="line">				memorySegmentsToDistribute * totalPartsUsed &#x2F; totalCapacity - numDistributedMemorySegment);</span><br><span class="line"></span><br><span class="line">		numDistributedMemorySegment +&#x3D; mySize;</span><br><span class="line">		bufferPool.setNumBuffers(bufferPool.getNumberOfRequiredMemorySegments() + mySize);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	assert (totalPartsUsed &#x3D;&#x3D; totalCapacity);</span><br><span class="line">	assert (numDistributedMemorySegment &#x3D;&#x3D; memorySegmentsToDistribute);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来说说这个<code>LocalBufferPool</code>内存池。<br>LocalBufferPool的逻辑想想无非是<del>增删改查</del>，值得说的是其fields：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;** 该内存池需要的最少内存片数目*&#x2F;</span><br><span class="line">private final int numberOfRequiredMemorySegments;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 当前已经获得的内存片中，还没有写入数据的空白内存片</span><br><span class="line"> *&#x2F;</span><br><span class="line">private final ArrayDeque&lt;MemorySegment&gt; availableMemorySegments &#x3D; new ArrayDeque&lt;MemorySegment&gt;();</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 注册的所有监控buffer可用性的监听器</span><br><span class="line"> *&#x2F;</span><br><span class="line">private final ArrayDeque&lt;BufferListener&gt; registeredListeners &#x3D; new ArrayDeque&lt;&gt;();</span><br><span class="line"></span><br><span class="line">&#x2F;** 能给内存池分配的最大分片数*&#x2F;</span><br><span class="line">private final int maxNumberOfMemorySegments;</span><br><span class="line"></span><br><span class="line">&#x2F;** 当前内存池大小 *&#x2F;</span><br><span class="line">private int currentPoolSize;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 所有经由NetworkBufferPool分配的，被本内存池引用到的（非直接获得的）分片数</span><br><span class="line"> *&#x2F;</span><br><span class="line">private int numberOfRequestedMemorySegments;</span><br></pre></td></tr></table></figure>
<p>承接NetworkBufferPool的重分配方法，我们来看看LocalBufferPool的<code>setNumBuffers()</code>方法，代码很短，逻辑也相当简单，就不展开说了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void setNumBuffers(int numBuffers) throws IOException &#123;</span><br><span class="line">	synchronized (availableMemorySegments) &#123;</span><br><span class="line">		checkArgument(numBuffers &gt;&#x3D; numberOfRequiredMemorySegments,</span><br><span class="line">				&quot;Buffer pool needs at least %s buffers, but tried to set to %s&quot;,</span><br><span class="line">				numberOfRequiredMemorySegments, numBuffers);</span><br><span class="line"></span><br><span class="line">		if (numBuffers &gt; maxNumberOfMemorySegments) &#123;</span><br><span class="line">			currentPoolSize &#x3D; maxNumberOfMemorySegments;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			currentPoolSize &#x3D; numBuffers;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		returnExcessMemorySegments();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; If there is a registered owner and we have still requested more buffers than our</span><br><span class="line">		&#x2F;&#x2F; size, trigger a recycle via the owner.</span><br><span class="line">		if (owner !&#x3D; null &amp;&amp; numberOfRequestedMemorySegments &gt; currentPoolSize) &#123;</span><br><span class="line">			owner.releaseMemory(numberOfRequestedMemorySegments - numBuffers);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="6-1-3-RecordWriter与Record"><a href="#6-1-3-RecordWriter与Record" class="headerlink" title="6.1.3 RecordWriter与Record"></a>6.1.3 RecordWriter与Record</h4><p>我们接着往高层抽象走，刚刚提到了最底层内存抽象是MemorySegment，用于数据传输的是Buffer，那么，承上启下对接从Java对象转为Buffer的中间对象是什么呢？是<code>StreamRecord</code>。</p>
<p>从<code>StreamRecord&lt;T&gt;</code>这个类名字就可以看出来，这个类就是个wrap，里面保存了原始的Java对象。另外，StreamRecord还保存了一个timestamp。</p>
<p>那么这个对象是怎么变成LocalBufferPool内存池里的一个大号字节数组的呢？借助了<code>StreamWriter</code>这个类。</p>
<p>我们直接来看把数据序列化交出去的方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void sendToTarget(T record, int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	RecordSerializer&lt;T&gt; serializer &#x3D; serializers[targetChannel];</span><br><span class="line"></span><br><span class="line">	SerializationResult result &#x3D; serializer.addRecord(record);</span><br><span class="line"></span><br><span class="line">	while (result.isFullBuffer()) &#123;</span><br><span class="line">		if (tryFinishCurrentBufferBuilder(targetChannel, serializer)) &#123;</span><br><span class="line">			&#x2F;&#x2F; If this was a full record, we are done. Not breaking</span><br><span class="line">			&#x2F;&#x2F; out of the loop at this point will lead to another</span><br><span class="line">			&#x2F;&#x2F; buffer request before breaking out (that would not be</span><br><span class="line">			&#x2F;&#x2F; a problem per se, but it can lead to stalls in the</span><br><span class="line">			&#x2F;&#x2F; pipeline).</span><br><span class="line">			if (result.isFullRecord()) &#123;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		BufferBuilder bufferBuilder &#x3D; requestNewBufferBuilder(targetChannel);</span><br><span class="line"></span><br><span class="line">		result &#x3D; serializer.continueWritingWithNextBufferBuilder(bufferBuilder);</span><br><span class="line">	&#125;</span><br><span class="line">	checkState(!serializer.hasSerializedData(), &quot;All data should be written at once&quot;);</span><br><span class="line">       </span><br><span class="line">       </span><br><span class="line">       </span><br><span class="line">	if (flushAlways) &#123;</span><br><span class="line">		targetPartition.flush(targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先说最后一行，如果配置为flushAlways，那么会立刻把元素发送出去，但是这样吞吐量会下降；Flink的默认设置其实也不是一个元素一个元素的发送，是单独起了一个线程，每隔固定时间flush一次所有channel，较真起来也算是mini batch了。</p>
<p>再说序列化那一句:<code>SerializationResult result = serializer.addRecord(record);</code>。在这行代码中，Flink把对象调用该对象所属的序列化器序列化为字节数组。</p>
<h3 id="6-2-数据流转过程"><a href="#6-2-数据流转过程" class="headerlink" title="6.2 数据流转过程"></a>6.2 数据流转过程</h3><p>上一节讲了各层数据的抽象，这一节讲讲数据在各个task之间exchange的过程。</p>
<h4 id="6-2-1-整体过程"><a href="#6-2-1-整体过程" class="headerlink" title="6.2.1 整体过程"></a>6.2.1 整体过程</h4><p>看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/e5m0ggy1t6z8tjgfn52cr31r/image_1cetavukjja42ce1261v5k57i9.png" alt="image_1cetavukjja42ce1261v5k57i9.png-821.8kB"></p>
<ol>
<li>第一步必然是准备一个ResultPartition；</li>
<li>通知JobMaster；</li>
<li>JobMaster通知下游节点；如果下游节点尚未部署，则部署之；</li>
<li>下游节点向上游请求数据</li>
<li>开始传输数据</li>
</ol>
<h4 id="6-2-2-数据跨task传递"><a href="#6-2-2-数据跨task传递" class="headerlink" title="6.2.2 数据跨task传递"></a>6.2.2 数据跨task传递</h4><p>本节讲一下算子之间具体的数据传输过程。也先上一张图：<br><img src="http://static.zybuluo.com/bethunebtj/d9pmni04fg8i11xotv4xqxh7/image_1cfmpba9v15anggtvsba2o1277m.png" alt="image_1cfmpba9v15anggtvsba2o1277m.png-357.5kB"><br>数据在task之间传递有如下几步：</p>
<ol>
<li>数据在本operator处理完后，交给<code>RecordWriter</code>。每条记录都要选择一个下游节点，所以要经过<code>ChannelSelector</code>。</li>
<li>每个channel都有一个serializer（我认为这应该是为了避免多线程写的麻烦），把这条Record序列化为ByteBuffer</li>
<li>接下来数据被写入ResultPartition下的各个subPartition里，此时该数据已经存入DirectBuffer（MemorySegment）</li>
<li>单独的线程控制数据的flush速度，一旦触发flush，则通过Netty的nio通道向对端写入</li>
<li>对端的netty client接收到数据，decode出来，把数据拷贝到buffer里，然后通知<code>InputChannel</code></li>
<li>有可用的数据时，下游算子从阻塞醒来，从InputChannel取出buffer，再解序列化成record，交给算子执行用户代码</li>
</ol>
<p>数据在不同机器的算子之间传递的步骤就是以上这些。</p>
<p>了解了步骤之后，再来看一下部分关键代码：<br>首先是把数据交给recordwriter。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   &#x2F;&#x2F;RecordWriterOutput.java</span><br><span class="line">@Override</span><br><span class="line">public void collect(StreamRecord&lt;OUT&gt; record) &#123;</span><br><span class="line">	if (this.outputTag !&#x3D; null) &#123;</span><br><span class="line">		&#x2F;&#x2F; we are only responsible for emitting to the main input</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">       &#x2F;&#x2F;这里可以看到把记录交给了recordwriter</span><br><span class="line">	pushToRecordWriter(record);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后recordwriter把数据发送到对应的通道。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   &#x2F;&#x2F;RecordWriter.java</span><br><span class="line">public void emit(T record) throws IOException, InterruptedException &#123;</span><br><span class="line">    &#x2F;&#x2F;channelselector登场了</span><br><span class="line">	for (int targetChannel : channelSelector.selectChannels(record, numChannels)) &#123;</span><br><span class="line">		sendToTarget(record, targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	private void sendToTarget(T record, int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	</span><br><span class="line">	&#x2F;&#x2F;选择序列化器并序列化数据</span><br><span class="line">	RecordSerializer&lt;T&gt; serializer &#x3D; serializers[targetChannel];</span><br><span class="line"></span><br><span class="line">	SerializationResult result &#x3D; serializer.addRecord(record);</span><br><span class="line"></span><br><span class="line">	while (result.isFullBuffer()) &#123;</span><br><span class="line">		if (tryFinishCurrentBufferBuilder(targetChannel, serializer)) &#123;</span><br><span class="line">			&#x2F;&#x2F; If this was a full record, we are done. Not breaking</span><br><span class="line">			&#x2F;&#x2F; out of the loop at this point will lead to another</span><br><span class="line">			&#x2F;&#x2F; buffer request before breaking out (that would not be</span><br><span class="line">			&#x2F;&#x2F; a problem per se, but it can lead to stalls in the</span><br><span class="line">			&#x2F;&#x2F; pipeline).</span><br><span class="line">			if (result.isFullRecord()) &#123;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		BufferBuilder bufferBuilder &#x3D; requestNewBufferBuilder(targetChannel);</span><br><span class="line"></span><br><span class="line">           &#x2F;&#x2F;写入channel</span><br><span class="line">		result &#x3D; serializer.continueWritingWithNextBufferBuilder(bufferBuilder);</span><br><span class="line">	&#125;</span><br><span class="line">	checkState(!serializer.hasSerializedData(), &quot;All data should be written at once&quot;);</span><br><span class="line"></span><br><span class="line">	if (flushAlways) &#123;</span><br><span class="line">		targetPartition.flush(targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来是把数据推给底层设施（netty）的过程：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   &#x2F;&#x2F;ResultPartition.java</span><br><span class="line">@Override</span><br><span class="line">public void flushAll() &#123;</span><br><span class="line">	for (ResultSubpartition subpartition : subpartitions) &#123;</span><br><span class="line">		subpartition.flush();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;PartitionRequestQueue.java</span><br><span class="line">	void notifyReaderNonEmpty(final NetworkSequenceViewReader reader) &#123;</span><br><span class="line">	&#x2F;&#x2F;这里交给了netty server线程去推</span><br><span class="line">	ctx.executor().execute(new Runnable() &#123;</span><br><span class="line">		@Override</span><br><span class="line">		public void run() &#123;</span><br><span class="line">			ctx.pipeline().fireUserEventTriggered(reader);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>netty相关的部分：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;AbstractChannelHandlerContext.java</span><br><span class="line">public ChannelHandlerContext fireUserEventTriggered(final Object event) &#123;</span><br><span class="line">    if (event &#x3D;&#x3D; null) &#123;</span><br><span class="line">        throw new NullPointerException(&quot;event&quot;);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        final AbstractChannelHandlerContext next &#x3D; this.findContextInbound();</span><br><span class="line">        EventExecutor executor &#x3D; next.executor();</span><br><span class="line">        if (executor.inEventLoop()) &#123;</span><br><span class="line">            next.invokeUserEventTriggered(event);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            executor.execute(new OneTimeTask() &#123;</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    next.invokeUserEventTriggered(event);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return this;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后真实的写入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   &#x2F;&#x2F;PartittionRequesetQueue.java</span><br><span class="line">private void enqueueAvailableReader(final NetworkSequenceViewReader reader) throws Exception &#123;</span><br><span class="line">	if (reader.isRegisteredAsAvailable() || !reader.isAvailable()) &#123;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F; Queue an available reader for consumption. If the queue is empty,</span><br><span class="line">	&#x2F;&#x2F; we try trigger the actual write. Otherwise this will be handled by</span><br><span class="line">	&#x2F;&#x2F; the writeAndFlushNextMessageIfPossible calls.</span><br><span class="line">	boolean triggerWrite &#x3D; availableReaders.isEmpty();</span><br><span class="line">	registerAvailableReader(reader);</span><br><span class="line"></span><br><span class="line">	if (triggerWrite) &#123;</span><br><span class="line">		writeAndFlushNextMessageIfPossible(ctx.channel());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void writeAndFlushNextMessageIfPossible(final Channel channel) throws IOException &#123;</span><br><span class="line">	</span><br><span class="line">       ......</span><br><span class="line"></span><br><span class="line">			next &#x3D; reader.getNextBuffer();</span><br><span class="line">			if (next &#x3D;&#x3D; null) &#123;</span><br><span class="line">				if (!reader.isReleased()) &#123;</span><br><span class="line">					continue;</span><br><span class="line">				&#125;</span><br><span class="line">				markAsReleased(reader.getReceiverId());</span><br><span class="line"></span><br><span class="line">				Throwable cause &#x3D; reader.getFailureCause();</span><br><span class="line">				if (cause !&#x3D; null) &#123;</span><br><span class="line">					ErrorResponse msg &#x3D; new ErrorResponse(</span><br><span class="line">						new ProducerFailedException(cause),</span><br><span class="line">						reader.getReceiverId());</span><br><span class="line"></span><br><span class="line">					ctx.writeAndFlush(msg);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				&#x2F;&#x2F; This channel was now removed from the available reader queue.</span><br><span class="line">				&#x2F;&#x2F; We re-add it into the queue if it is still available</span><br><span class="line">				if (next.moreAvailable()) &#123;</span><br><span class="line">					registerAvailableReader(reader);</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				BufferResponse msg &#x3D; new BufferResponse(</span><br><span class="line">					next.buffer(),</span><br><span class="line">					reader.getSequenceNumber(),</span><br><span class="line">					reader.getReceiverId(),</span><br><span class="line">					next.buffersInBacklog());</span><br><span class="line"></span><br><span class="line">				if (isEndOfPartitionEvent(next.buffer())) &#123;</span><br><span class="line">					reader.notifySubpartitionConsumed();</span><br><span class="line">					reader.releaseAllResources();</span><br><span class="line"></span><br><span class="line">					markAsReleased(reader.getReceiverId());</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; Write and flush and wait until this is done before</span><br><span class="line">				&#x2F;&#x2F; trying to continue with the next buffer.</span><br><span class="line">				channel.writeAndFlush(msg).addListener(writeListener);</span><br><span class="line"></span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面这段代码里第二个方法中调用的<code>writeAndFlush(msg)</code>就是真正往netty的nio通道里写入的地方了。在这里，写入的是一个RemoteInputChannel，对应的就是下游节点的InputGate的channels。</p>
<p>有写就有读，nio通道的另一端需要读入buffer，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   &#x2F;&#x2F;CreditBasedPartitionRequestClientHandler.java</span><br><span class="line">private void decodeMsg(Object msg) throws Throwable &#123;</span><br><span class="line">	final Class&lt;?&gt; msgClazz &#x3D; msg.getClass();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; ---- Buffer --------------------------------------------------------</span><br><span class="line">	if (msgClazz &#x3D;&#x3D; NettyMessage.BufferResponse.class) &#123;</span><br><span class="line">		NettyMessage.BufferResponse bufferOrEvent &#x3D; (NettyMessage.BufferResponse) msg;</span><br><span class="line"></span><br><span class="line">		RemoteInputChannel inputChannel &#x3D; inputChannels.get(bufferOrEvent.receiverId);</span><br><span class="line">		if (inputChannel &#x3D;&#x3D; null) &#123;</span><br><span class="line">			bufferOrEvent.releaseBuffer();</span><br><span class="line"></span><br><span class="line">			cancelRequestFor(bufferOrEvent.receiverId);</span><br><span class="line"></span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		decodeBufferOrEvent(inputChannel, bufferOrEvent);</span><br><span class="line"></span><br><span class="line">	&#125; </span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>插一句，Flink其实做阻塞和获取数据的方式非常自然，利用了生产者和消费者模型，当获取不到数据时，消费者自然阻塞；当数据被加入队列，消费者被notify。Flink的背压机制也是借此实现。</p>
<p>然后在这里又反序列化成<code>StreamRecord</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   &#x2F;&#x2F;StreamElementSerializer.java</span><br><span class="line">public StreamElement deserialize(DataInputView source) throws IOException &#123;</span><br><span class="line">	int tag &#x3D; source.readByte();</span><br><span class="line">	if (tag &#x3D;&#x3D; TAG_REC_WITH_TIMESTAMP) &#123;</span><br><span class="line">		long timestamp &#x3D; source.readLong();</span><br><span class="line">		return new StreamRecord&lt;T&gt;(typeSerializer.deserialize(source), timestamp);</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_REC_WITHOUT_TIMESTAMP) &#123;</span><br><span class="line">		return new StreamRecord&lt;T&gt;(typeSerializer.deserialize(source));</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_WATERMARK) &#123;</span><br><span class="line">		return new Watermark(source.readLong());</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_STREAM_STATUS) &#123;</span><br><span class="line">		return new StreamStatus(source.readInt());</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_LATENCY_MARKER) &#123;</span><br><span class="line">		return new LatencyMarker(source.readLong(), new OperatorID(source.readLong(), source.readLong()), source.readInt());</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		throw new IOException(&quot;Corrupt stream, found tag: &quot; + tag);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后再次在<code>StreamInputProcessor.processInput()</code>循环中得到处理。</p>
<p>至此，数据在跨jvm的节点之间的流转过程就讲完了。</p>
<h3 id="6-3-Credit漫谈"><a href="#6-3-Credit漫谈" class="headerlink" title="6.3 Credit漫谈"></a>6.3 Credit漫谈</h3><p>在看上一部分的代码时，有一个小细节不知道读者有没有注意到，我们的数据发送端的代码叫做<code>PartittionRequesetQueue.java</code>，而我们的接收端却起了一个完全不相干的名字：<code>CreditBasedPartitionRequestClientHandler.java</code>。为什么前面加了CreditBased的前缀呢？</p>
<h4 id="6-3-1-背压问题"><a href="#6-3-1-背压问题" class="headerlink" title="6.3.1 背压问题"></a>6.3.1 背压问题</h4><p>在流模型中，我们期待数据是像水流一样平滑的流过我们的引擎，但现实生活不会这么美好。数据的上游可能因为各种原因数据量暴增，远远超出了下游的瞬时处理能力（回忆一下98年大洪水），导致系统崩溃。<br>那么框架应该怎么应对呢？和人类处理自然灾害的方式类似，我们修建了三峡大坝，当洪水来临时把大量的水囤积在大坝里；对于Flink来说，就是在数据的接收端和发送端放置了缓存池，用以缓冲数据，并且设置闸门阻止数据向下流。</p>
<p>那么Flink又是如何处理背压的呢？答案也是靠这些缓冲池。<br><img src="http://static.zybuluo.com/bethunebtj/1r40q9nbeuxh4j0omiic5tob/image_1cfksrl5cd4m1lbqqqgvc811349.png" alt="image_1cfksrl5cd4m1lbqqqgvc811349.png-43.1kB"><br>这张图说明了Flink在生产和消费数据时的大致情况。<code>ResultPartition</code>和<code>InputGate</code>在输出和输入数据时，都要向<code>NetworkBufferPool</code>申请一块<code>MemorySegment</code>作为缓存池。<br>接下来的情况和生产者消费者很类似。当数据发送太多，下游处理不过来了，那么首先InputChannel会被填满，然后是InputChannel能申请到的内存达到最大，于是下游停止读取数据，上游负责发送数据的nettyServer会得到响应，停止从ResultSubPartition读取缓存，那么ResultPartition很快也将存满数据不能被消费，从而生产数据的逻辑被阻塞在获取新buffer上，非常自然地形成背压的效果。</p>
<p>Flink自己做了个试验用以说明这个机制的效果：<br><img src="http://static.zybuluo.com/bethunebtj/xxqpmehf1w4un8leyc9itr9y/image_1cfkta54rkdd1od4aau1e3n7nhm.png" alt="image_1cfkta54rkdd1od4aau1e3n7nhm.png-240.6kB"><br>我们首先设置生产者的发送速度为60%，然后下游的算子以同样的速度处理数据。然后我们将下游算子的处理速度降低到30%，可以看到上游的生产者的数据产生曲线几乎与消费者同步下滑。而后当我们解除限速，整个流的速度立刻提高到了100%。</p>
<h4 id="6-3-2-使用Credit实现ATM网络流控"><a href="#6-3-2-使用Credit实现ATM网络流控" class="headerlink" title="6.3.2 使用Credit实现ATM网络流控"></a>6.3.2 使用Credit实现ATM网络流控</h4><p>上文已经提到，对于流量控制，一个朴素的思路就是在<del>长江上建三峡</del>链路上建立一个拦截的dam，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/1wc3o2qo6ozsyxqebnn2xw0j/image_1cfku114lf7hpqf3lmcl0116c13.png" alt="image_1cfku114lf7hpqf3lmcl0116c13.png-22.7kB"><br>基于Credit的流控就是这样一种建立在信用（消费数据的能力)上的，面向每个虚链路（而非端到端的）流模型，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/on4kd4bzvoozbo6yk6n2but6/image_1cfku4g4g174d7gb5ecbfcib71g.png" alt="image_1cfku4g4g174d7gb5ecbfcib71g.png-22.5kB"><br>首先，下游会向上游发送一条credit message，用以通知其目前的信用（可联想信用卡的可用额度），然后上游会根据这个信用消息来决定向下游发送多少数据。当上游把数据发送给下游时，它就从下游的信用卡上划走相应的额度（credit balance）：<br><img src="http://static.zybuluo.com/bethunebtj/i8t1qvlib162x1i6lm0qruju/image_1cfkug5sm1v4l15pbgj4jntc7q1t.png" alt="image_1cfkug5sm1v4l15pbgj4jntc7q1t.png-12.9kB"><br>下游总共获得的credit数目是Buf_Alloc，已经消费的数据是Fwd_Cnt，上游发送出来的数据是Tx_Cnt，那么剩下的那部分就是Crd_Bal:<br>Crd_Bal = Buf_Alloc - ( Tx_Cnt - Fwd_Cnt )<br>上面这个式子应该很好理解。</p>
<p>可以看到，Credit Based Flow Control的关键是buffer分配。这种分配可以在数据的发送端完成，也可以在接收端完成。对于下游可能有多个上游节点的情况（比如Flink），使用接收端的credit分配更加合理：<br><img src="http://static.zybuluo.com/bethunebtj/o09mav0lfnk7iqar98iphr7o/image_1cfkvpmlh1gl31ef41cvh1c903a19.png" alt="image_1cfkvpmlh1gl31ef41cvh1c903a19.png-13.1kB"><br>上图中，接收者可以观察到每个上游连接的带宽情况，而上游的节点Snd1却不可能轻易知道发往同一个下游节点的其他Snd2的带宽情况，从而如果在上游控制流量将会很困难，而在下游控制流量将会很方便。</p>
<p>因此，这就是为何Flink在接收端有一个基于Credit的Client，而不是在发送端有一个CreditServer的原因。</p>
<p>最后，再讲一下Credit的面向虚链路的流设计和端到端的流设计的区别：<br><img src="http://static.zybuluo.com/bethunebtj/1mm2eqnuop9rcccap915qrzx/image_1cfl05d2f1ub879c1lc5qsq14n9m.png" alt="image_1cfl05d2f1ub879c1lc5qsq14n9m.png-13.4kB"><br>如上图所示，a是面向连接的流设计，b是端到端的流设计。其中，a的设计使得当下游节点3因某些情况必须缓存数据暂缓处理时，每个上游节点（1和2）都可以利用其缓存保存数据；而端到端的设计b里，只有节点3的缓存才可以用于保存数据（读者可以从如何实现上想想为什么）。</p>
<p>对流控制感兴趣的读者，可以看这篇文章：<a href="https://www.nap.edu/read/5769/chapter/1">Traffic Management For High-Speed Networks</a>。</p>
<h2 id="7-其他核心概念"><a href="#7-其他核心概念" class="headerlink" title="7.其他核心概念"></a>7.其他核心概念</h2><p>截至第六章，和执行过程相关的部分就全部讲完，告一段落了。第七章主要讲一点杂七杂八的内容，有时间就不定期更新。</p>
<h3 id="7-1-EventTime时间模型"><a href="#7-1-EventTime时间模型" class="headerlink" title="7.1 EventTime时间模型"></a>7.1 EventTime时间模型</h3><p>flink有三种时间模型：ProcessingTime，EventTime和IngestionTime。<br>关于时间模型看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/kcp52h1se5xzocfqcigcv9oh/image_1cdbotdcmoe11q961st5lbn1j4n9.png" alt="image_1cdbotdcmoe11q961st5lbn1j4n9.png-38.4kB"><br>从这张图里可以很清楚的看到三种Time模型的区别。</p>
<ul>
<li>EventTime是数据被生产出来的时间，可以是比如传感器发出信号的时间等（此时数据还没有被传输给flink）。</li>
<li>IngestionTime是数据进入flink的时间，也就是从Source进入flink流的时间（此时数据刚刚被传给flink）</li>
<li>ProcessingTime是针对当前算子的系统时间，是指该数据已经进入某个operator时，operator所在系统的当前时间</li>
</ul>
<p>例如，我在写这段话的时间是2018年5月13日03点47分，但是我引用的这张EventTime的图片，是2015年画出来的，那么这张图的EventTime是2015年，而ProcessingTime是现在。<br>Flink官网对于时间戳的解释非常详细：<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/event_time.html">点我</a><br>Flink对于EventTime模型的实现，依赖的是一种叫做<code>watermark</code>的对象。watermark是携带有时间戳的一个对象，会按照程序的要求被插入到数据流中，用以标志某个事件在该时间发生了。<br>我再做一点简短的说明，还是以官网的图为例：<br><img src="http://static.zybuluo.com/bethunebtj/f4k8110qo8arjey5zbp75xz3/image_1cdbt8v5jl2ujn91uu1joh1p4gm.png" alt="image_1cdbt8v5jl2ujn91uu1joh1p4gm.png-11.3kB"><br>对于有序到来的数据，假设我们在timestamp为11的元素后加入一个watermark，时间记录为11，则下个元素收到该watermark时，认为所有早于11的元素均已到达。这是非常理想的情况。<br><img src="http://static.zybuluo.com/bethunebtj/3aqwmrc5hg054b09z47lwsvp/image_1cdbtcc5c1a6i1tuaadb1rd5136913.png" alt="image_1cdbtcc5c1a6i1tuaadb1rd5136913.png-11.6kB"><br>而在现实生活中，经常会遇到乱序的数据。这时，我们虽然在timestamp为7的元素后就收到了11，但是我们一直等到了收到元素12之后，才插入了watermark为11的元素。与上面的图相比，如果我们仍然在11后就插入11的watermark，那么元素9就会被丢弃，造成数据丢失。而我们在12之后插入watermark11，就保证了9仍然会被下一个operator处理。当然，我们不可能无限制的永远等待迟到元素，所以要在哪个元素后插入11需要根据实际场景权衡。</p>
<p>对于来自多个数据源的watermark，可以看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/pu1cr48mq9340g5embaig9b5/image_1cdbufp4a1opmsit5n61mial4520.png" alt="image_1cdbufp4a1opmsit5n61mial4520.png-72kB"><br>可以看到，当一个operator收到多个watermark时，它遵循最小原则（或者说最早），即算子的当前watermark是流经该算子的最小watermark，以容许来自不同的source的乱序数据到来。<br>关于事件时间模型，更多内容可以参考<a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101">Stream 101</a> 和谷歌的这篇论文：<a href="https://research.google.com/pubs/archive/43864.pdf">Dataflow Model paper</a></p>
<h3 id="7-2-FLIP-6-部署及处理模型演进"><a href="#7-2-FLIP-6-部署及处理模型演进" class="headerlink" title="7.2 FLIP-6 部署及处理模型演进"></a>7.2 FLIP-6 部署及处理模型演进</h3><p>就在老白写这篇blog的时候，Flink发布了其1.5 RELEASE版本，号称实现了其部署及处理模型（也就是FLIP-6)，所以打算简略地说一下FLIP-6的主要内容。</p>
<h4 id="7-2-1-现有模型不足"><a href="#7-2-1-现有模型不足" class="headerlink" title="7.2.1 现有模型不足"></a>7.2.1 现有模型不足</h4><p>1.5之前的Flink模型有很多不足，包括：</p>
<ul>
<li>只能静态分配计算资源</li>
<li>在YARN上所有的资源分配都是一碗水端平的</li>
<li>与Docker/k8s的集成非常之蠢，颇有脱裤子放屁的神韵</li>
<li>JobManager没有任务调度逻辑</li>
<li>任务在YARN上执行结束后web dashboard就不可用</li>
<li>集群的session模式和per job模式混淆难以理解</li>
</ul>
<p>就我个人而言，我觉得Flink有一个这里完全没提到的不足才是最应该修改的：针对任务的完全的资源隔离。尤其是如果用Standalone集群，一个用户的task跑挂了TaskManager，然后拖垮了整个集群的情况简直不要太多。</p>
<h4 id="7-2-2-核心变更"><a href="#7-2-2-核心变更" class="headerlink" title="7.2.2 核心变更"></a>7.2.2 核心变更</h4><p><strong>Single Job JobManager</strong><br>最重要的变更是一个JobManager只处理一个job。当我们生成JobGraph时就顺便起一个JobManager，这显然更加自然。</p>
<p><strong>ResourceManager</strong><br>其职责包括获取新的TM和slot，通知失败，释放资源以及缓存TM以用于重用等。重要的是，这个组件要能做到挂掉时不要搞垮正在运行的好好的任务。其职责和与JobManager、TaskManager的交互图如下：<br><img src="http://static.zybuluo.com/bethunebtj/pzuvevivascmk2xky450ll87/image_1cfl9453k1gld4acr1m13j3195sg.png" alt="image_1cfl9453k1gld4acr1m13j3195sg.png-23.9kB"></p>
<p><strong>TaskManager</strong><br>TM要与上面的两个组件交互。与JobManager交互时，要能提供slot，要能与所有给出slot的JM交互。丢失与JM的连接时要能试图把本TM上的slot的情况通告给新JM，如果这一步失败，就要能重新分配slot。<br>与ResourceManager交互时，要通知RM自己的资源和当前的Job分配情况，能按照RM的要求分配资源或者关闭自身。</p>
<p><strong>JobManager Slot Pool</strong><br>这个pool要持有所有分配给当前job的slot资源，并且能在RM挂掉的情况下管理当前已经持有的slot。</p>
<p><strong>Dispatcher</strong><br>需要一个Job的分发器的主要原因是在有的集群环境下我们可能需要一个统一的提交和监控点，以及替代之前的Standalone模式下的JobManager。将来对分发器的期望可能包括权限控制等。<br><img src="http://static.zybuluo.com/bethunebtj/on7x5expzpyvtyqvkjm1si9e/image_1cfl9ju2617bh1s191mar1jsp12vot.png" alt="image_1cfl9ju2617bh1s191mar1jsp12vot.png-31.4kB"></p>
<h4 id="7-2-3-Cluster-Manager的架构"><a href="#7-2-3-Cluster-Manager的架构" class="headerlink" title="7.2.3 Cluster Manager的架构"></a>7.2.3 Cluster Manager的架构</h4><p><strong>YARN</strong><br>新的基于YARN的架构主要包括不再需要先在容器里启动集群，然后提交任务；用户代码不再使用动态ClassLoader加载；不用的资源可以释放；可以按需分配不同大小的容器等。其执行过程如下：<br>无Dispatcher时<br><img src="http://static.zybuluo.com/bethunebtj/w3z5qz98tq5q4jtndka8kdhp/image_1cfla0n7u1lg21n3o36uu0c1o5h1a.png" alt="image_1cfla0n7u1lg21n3o36uu0c1o5h1a.png-46.2kB"><br>有Dispatcher时<br><img src="http://static.zybuluo.com/bethunebtj/ukhd6f3480du2nsx2wnl56g3/image_1cfla15os15i3qcsu6c4p4clk1n.png" alt="image_1cfla15os15i3qcsu6c4p4clk1n.png-50.7kB"></p>
<p><strong>Mesos</strong><br>与基于YARN的模式很像，但是只有带Dispatcher模式，因为只有这样才能在Mesos集群里跑其RM。<br><img src="http://static.zybuluo.com/bethunebtj/k0b95bqzs9crsj2jwk8oy33n/image_1cfla4tka101n18bf1mno4npu9s24.png" alt="image_1cfla4tka101n18bf1mno4npu9s24.png-49.2kB"><br>Mesos的Fault Tolerance是类似这样的：<br><img src="http://static.zybuluo.com/bethunebtj/app8m86al53shk2a83w14x0r/image_1cfla6eka1ph71mu1pll1q0mgqq2h.png" alt="image_1cfla6eka1ph71mu1pll1q0mgqq2h.png-12.1kB"><br>必须用类似Marathon之类的技术保证Dispatcher的HA。</p>
<p><strong>Standalone</strong><br>其实没啥可说的，把以前的JobManager的职责换成现在的Dispatcher就行了。<br><img src="http://static.zybuluo.com/bethunebtj/nn4vbn25yojf3vq80yffr20v/image_1cflaaim2ih2v54umsmq01lqc2u.png" alt="image_1cflaaim2ih2v54umsmq01lqc2u.png-36.8kB"><br>将来可能会实现一个类似于轻量级Yarn的模式。</p>
<p><strong>Docker/k8s</strong><br>用户定义好容器，至少有一个是job specific的（不然怎么启动任务）；还有用于启动TM的，可以不是job specific的。启动过程如下<br><img src="http://static.zybuluo.com/bethunebtj/vcow51koxy17wd3qxj60y4lj/image_1cflafs2o1trgicjmdbndn1bdq3b.png" alt="image_1cflafs2o1trgicjmdbndn1bdq3b.png-24.2kB"></p>
<h4 id="7-2-4-组件设计及细节"><a href="#7-2-4-组件设计及细节" class="headerlink" title="7.2.4 组件设计及细节"></a>7.2.4 组件设计及细节</h4><p><strong>分配slot相关细节</strong><br>从新的TM取slot过程：<br><img src="http://static.zybuluo.com/bethunebtj/r1anoecf2er16nuh3h9r9jb8/image_1cflakoadvjm8pf6nt1k331qj33o.png" alt="image_1cflakoadvjm8pf6nt1k331qj33o.png-77.2kB"></p>
<p>从Cached TM取slot过程：<br><img src="http://static.zybuluo.com/bethunebtj/2uyr1ynvj8ieqi8rth8h8bub/image_1cflambu91ufi5fl1cg9gimdff45.png" alt="image_1cflambu91ufi5fl1cg9gimdff45.png-63.4kB"></p>
<p><strong>失败处理</strong></p>
<ol>
<li><p>TM失败<br>TM失败时，RM要能检测到失败，更新自己的状态，发送消息给JM，重启一份TM；JM要能检测到失败，从状态移除失效slot，标记该TM的task为失败，并在没有足够slot继续任务时调整规模；TM自身则要能从Checkpoint恢复</p>
</li>
<li><p>RM失败<br>此时TM要能检测到失败，并准备向新的RM注册自身，并且向新的RM传递自身的资源情况；JM要能检测到失败并且等待新的RM可用，重新请求需要的资源；丢失的数据要能从Container、TM等处恢复。</p>
</li>
<li><p>JM失败<br>TM释放所有task，向新JM注册资源，并且如果不成功，就向RM报告这些资源可用于重分配；RM坐等；JM丢失的数据从持久化存储中获得，已完成的checkpoints从HA恢复，从最近的checkpoint重启task，并申请资源。</p>
</li>
<li><p>JM &amp; RM 失败<br>TM将在一段时间内试图把资源交给新上任的JM，如果失败，则把资源交给新的RM</p>
</li>
<li><p>TM &amp; RM失败<br>JM如果正在申请资源，则要等到新的RM启动后才能获得；JM可能需要调整其规模，因为损失了TM的slot。</p>
</li>
</ol>
<h2 id="8-后记"><a href="#8-后记" class="headerlink" title="8.后记"></a>8.后记</h2><p>Flink是当前流处理领域的优秀框架，其设计思想和代码实现都蕴含着许多人的智慧结晶。这篇解读花了很多时间，篇幅也写了很长，也仍然不能能覆盖Flink的方方面面，也肯定有很多错误之处，欢迎大家批评指正！Flink生态里中文资料确实不多，对Flink源码有兴趣的读者，可以参考<a href="https://blog.csdn.net/yanghua_kobe/article/category/6170573/4">VinoYang的专栏</a>，继续学习之旅。</p>
<p>本文至此结束。</p>
<p>最后，欢迎关注我的微信公众号，一起交流技术，或者职业生涯？<br><img src="http://static.zybuluo.com/bethunebtj/daydmugl837tmw92klc6rqxz/image_1cfhqfqgt17r89b4156i1bni1hqq9.png" alt="老白讲互联网"></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS基础</title>
    <url>/bigdata/Hadoop/HDFS/</url>
    <content><![CDATA[<ul>
<li>NameNode 保存这个文件的数据块信息</li>
<li>DataNode 存储实际的文件</li>
<li>当MR启动的时候，首先获取所要处理的文件的块信息和节点信息，然后在这些节点上同时启动任务，在数据所在节点上同时处理</li>
</ul>
<p>MapReduce是底层编程语言，您需要专业知识才能在此级别工作。工程师在Map Reduce上开发了一个名为Hive的层，以便用户可以使用SQL来处理HDFS中存储的数据。Hive将这些SQL查询转换为一系列Map Reduce，然后调度执行。因此，Hive极大地简化了数据处理任务。但是Hive使用底层Map Reduce体系结构，这是用于处理数据的另一层</p>
<p>Impala 一旦部署在Hadoop集群中，它将在每个数据节点上运行自己的进程，并完全跳过MapReduce阶段。一旦收到一个SQL，Impala master节点调度数据所在的节点上直接执行任务。因为它跳过MapReduce转换阶段并直接在节点上执行，所以它可以完成每秒钟的SQL查询</p>
<p>当您在Hive中启动查询时，在背景地图中，Reduce会出现在启动查询需要花费大量时间的画面中，就像您在Impala中启动查询一样，它使用自己的体系结构，即MPP(大规模并行处理)而不是Map Reduce来从HDFS获取结果。它在内存中执行查询，总是比磁盘快。</p>
<p>It’s an HDFS quirk. A file that’s currently being written to will appear to have a size of 0 but once it’s closed it will show its true size</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title>mapReducer</title>
    <url>/bigdata/Hadoop/MapReducer/</url>
    <content><![CDATA[<h1 id="mapReducer-处理数据的流程"><a href="#mapReducer-处理数据的流程" class="headerlink" title="mapReducer 处理数据的流程"></a>mapReducer 处理数据的流程</h1><p>Map Reducer shuffle </p>
<p>partition sorting combiner</p>
<p>shuffle过程</p>
<p>MapReducer过程</p>
<p>参考文献: <a href="http://www.cnblogs.com/ljy2013/articles/4435657.html">http://www.cnblogs.com/ljy2013/articles/4435657.html</a></p>
<h1 id="MapReducer-实践"><a href="#MapReducer-实践" class="headerlink" title="MapReducer 实践"></a>MapReducer 实践</h1><ol>
<li>wordCount解析</li>
<li>Mapper class, CombinerClass,ReducerClass </li>
<li>分析 TokenCountMapper  与 LongSumReducer</li>
<li>常用的系列化类: 实现 WriteComparable 的类</li>
</ol>
<h1 id="文件的读写"><a href="#文件的读写" class="headerlink" title="文件的读写"></a>文件的读写</h1><h2 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h2><ul>
<li><p>TextInputFormat 是 InputFormat 的默认实现, TextInputFormat<br>返回的键是每行的字节偏移量，返回的值是该行的数据。<br>key: LongWritable<br>value: Text</p>
</li>
<li><p><code>KeyValueTextInputFormat</code> 使用分隔符分割每行，分隔符之前的是键，之后的是值。默认的分隔符是制表符(\T)，分离器的属性通过<br><code>key.value.separator.in.input.line</code>中指定</p>
</li>
</ul>
<p>key: Text<br>value: Text</p>
<ul>
<li><code>SequenceFileInputFormat&lt;K,V&gt;</code> 用户自定义的序列化格式, 序列化文件为Hadoop专用的压缩二进制文件格式</li>
</ul>
<p>key: K 用户定义<br>value: V 用户定义</p>
<ul>
<li><code>NLineInputFormat</code> key为分片的偏移量，value为包含N行数据的片段，N通过属性 <code>mapred.line.inout.format.linespermap</code>中指定，默认为1<br>key: LongWritable<br>value: Text</li>
</ul>
<p>通过 <code>JobConf.setInputFormat(KeyValueTextInputFormat.class)</code>指定</p>
<h2 id="自定义-InputFormat"><a href="#自定义-InputFormat" class="headerlink" title="自定义 InputFormat"></a>自定义 InputFormat</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">InputFormat</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	* 将输入的文件分割成 numSplits 个片段</span></span><br><span class="line"><span class="comment">	*/</span></span><br><span class="line">	InputSplit[] getSplits(JobConf job, <span class="keyword">int</span> numSplits) <span class="keyword">throws</span> IOException;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	* </span></span><br><span class="line"><span class="comment">	*/</span></span><br><span class="line">	<span class="function">RecordReader&lt;K,V&gt; <span class="title">getRecordReader</span><span class="params">( InputSplit split, </span></span></span><br><span class="line"><span class="function"><span class="params">		JobConf job,</span></span></span><br><span class="line"><span class="function"><span class="params">		Reporter reporter)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述所有的 <code>InputFormat</code> 都是 <code>FileInputFormat</code> 类的一个子类，<code>FileInputFormat</code>默认实现了 <code>InputFormat</code> 接口，且实现了 <code>getSplits</code> 方法,把输入的数据粗略的划分为一组分片, 每个分片的大小必须大于<code>mapred.min.split.size</code>个字节,且小于文件系统的块, 在实际情况下,一个分片的大小总是一个块的大小,在HDFS中默认为64MB; 而 <code>getRecordReader</code>为抽象方法,  在自定义实现<code>InputFormat</code>时, 可以通过继承 <code>FileInputFormat</code> , 自定义 <code>getRecordReader</code> 方法.</p>
<ul>
<li><p><code>isSplitable</code> 方法</p>
</li>
<li><p><code>RecordReader</code></p>
</li>
<li><p>编写 InputFormat 实例</p>
</li>
</ul>
<h1 id="OutputFormat"><a href="#OutputFormat" class="headerlink" title="OutputFormat"></a>OutputFormat</h1><hr>
<p>【参考文献】</p>
<ol>
<li><a href="ref-url" title="ref-alt-title">ref-title</a></li>
</ol>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>mapReducer</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop NameNode 高可用 (High Availability) 实现解析</title>
    <url>/bigdata/Hadoop/HDFS-NameNode-2.x-HA/</url>
    <content><![CDATA[<h2 id="NameNode-高可用整体架构概述"><a href="#NameNode-高可用整体架构概述" class="headerlink" title="NameNode 高可用整体架构概述"></a>NameNode 高可用整体架构概述</h2><p>在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，包括 MapReduce、Hive、Pig 以及 HBase 等也都无法正常工作，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。</p>
<p>所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger(JobTracker 在 2.0 中已经被整合到 YARN ResourceManger 之中) 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。HDFS NameNode 和 YARN ResourceManger 的高可用 (High Availability，HA) 方案基本类似，两者也复用了部分代码，但是由于 HDFS NameNode 对于数据存储和数据一致性的要求比 YARN ResourceManger 高得多，所以 HDFS NameNode 的高可用实现更为复杂一些，本文从内部实现的角度对 HDFS NameNode 的高可用机制进行详细的分析。</p>
<p>HDFS NameNode 的高可用整体架构如图 1 所示 (图片来源于参考文献 [1])：</p>
<p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img001.png" alt="img"></p>
<p>从上图中，我们可以看出 NameNode 的高可用架构主要分为下面几个部分：</p>
<p>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。</p>
<p>主备切换控制器 ZKFailoverController：</p>
<p>ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。<strong>检测NameNode和主从切换  healthMonitor和ActiveStandbyElector</strong></p>
<p>Zookeeper 集群：为主备切换控制器提供主备选举支持。</p>
<p>共享存储系统：</p>
<p>共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。(会不会没有同步完，新的选举就开始了)</p>
<p>DataNode 节点：</p>
<p>除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 <strong>HDFS 的数据块和 DataNode 之间的映射关系</strong>。<strong>DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。</strong> name node包含的元数据信息</p>
<p>下面开始分别介绍 NameNode 的主备切换实现和共享存储系统的实现，在文章的最后会结合笔者的实践介绍一下在 NameNode 的高可用运维中的一些注意事项。</p>
<h2 id="NameNode-的主备切换实现"><a href="#NameNode-的主备切换实现" class="headerlink" title="NameNode 的主备切换实现"></a>NameNode 的主备切换实现</h2><p>NameNode 主备切换主要由 <strong>ZKFailoverController</strong>、<strong>HealthMonitor</strong> 和 <strong>ActiveStandbyElector</strong> 这 3 个组件来协同实现：</p>
<p><strong>HealthMonitor负责监听NameNode的状态，而ActiveStandbyElector负责主备切换</strong></p>
<p>ZKFailoverController 作为 NameNode 机器上一个独立的进程启动 (在 hdfs 启动脚本之中的进程名为 zkfc)，启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 <strong>HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。</strong> 回调方法分别用于几个场景：</p>
<ul>
<li>强制fench NameNode</li>
<li></li>
</ul>
<p>HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调ZKFailoverController 的相应方法进行自动的主备选举。</p>
<p>ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</p>
<p>NameNode 实现主备切换的流程如图 2 所示，有以下几步：</p>
<p><strong>HAServiceProtocol RPC与Hadoop RPC的异同</strong></p>
<ol>
<li>HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。</li>
<li>HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会<strong>回调 ZKFailoverController 注册的相应方法进行处理</strong>。</li>
<li>如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。</li>
<li>ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。</li>
<li>ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。</li>
<li>ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。</li>
</ol>
<h5 id="图-2-NameNode-的主备切换流程"><a href="#图-2-NameNode-的主备切换流程" class="headerlink" title="图 2.NameNode 的主备切换流程"></a>图 2.NameNode 的主备切换流程</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img002.png" alt="img"></p>
<p>下面分别对 HealthMonitor、ActiveStandbyElector 和 ZKFailoverController 的实现细节进行分析：</p>
<h3 id="HealthMonitor-实现分析"><a href="#HealthMonitor-实现分析" class="headerlink" title="HealthMonitor 实现分析"></a>HealthMonitor 实现分析</h3><p>ZKFailoverController 在初始化的时候会创建 HealthMonitor，HealthMonitor 在内部会启动一个线程来循环调用 NameNode 的 HAServiceProtocol RPC 接口的方法来检测 NameNode 的状态，并将状态的变化通过回调的方式来通知 ZKFailoverController。</p>
<p>HealthMonitor 主要检测 NameNode 的两类状态，分别是 HealthMonitor.State 和 HAServiceStatus。HealthMonitor.State 是通过 HAServiceProtocol RPC 接口的 monitorHealth 方法来获取的，反映了 NameNode 节点的健康状况，主要是磁盘存储资源是否充足。HealthMonitor.State 包括下面几种状态：</p>
<ul>
<li>•INITIALIZING：HealthMonitor 在初始化过程中，还没有开始进行健康状况检测；</li>
<li>•SERVICE_HEALTHY：NameNode 状态正常；</li>
<li>•SERVICE_NOT_RESPONDING：调用 NameNode 的 monitorHealth 方法调用无响应或响应超时；</li>
<li>•SERVICE_UNHEALTHY：NameNode 还在运行，但是 monitorHealth 方法返回状态不正常，磁盘存储资源不足；</li>
<li>•HEALTH_MONITOR_FAILED：HealthMonitor 自己在运行过程中发生了异常，不能继续检测 NameNode 的健康状况，会导致 ZKFailoverController 进程退出；</li>
</ul>
<p>HealthMonitor.State 在状态检测之中起主要的作用，在 HealthMonitor.State 发生变化的时候，HealthMonitor 会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。</p>
<p>而 HAServiceStatus 则是通过 HAServiceProtocol RPC 接口的 getServiceStatus 方法来获取的，主要反映的是 NameNode 的 HA 状态，包括：</p>
<ul>
<li>•INITIALIZING：NameNode 在初始化过程中；</li>
<li>•ACTIVE：当前 NameNode 为主 NameNode；</li>
<li>•STANDBY：当前 NameNode 为备 NameNode；</li>
<li>•STOPPING：当前 NameNode 已停止；</li>
</ul>
<p>HAServiceStatus 在状态检测之中只是起辅助的作用，在 HAServiceStatus 发生变化时，HealthMonitor 也会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。</p>
<h3 id="ActiveStandbyElector-实现分析"><a href="#ActiveStandbyElector-实现分析" class="headerlink" title="ActiveStandbyElector 实现分析"></a>ActiveStandbyElector 实现分析</h3><p>Namenode(包括 YARN ResourceManager) 的主备选举是通过 ActiveStandbyElector 来完成的，ActiveStandbyElector 主要是利用了 Zookeeper 的写一致性和临时节点机制，具体的主备选举实现如下：</p>
<p><strong>创建锁节点</strong></p>
<p>如果 HealthMonitor 检测到对应的 NameNode 的状态正常，那么表示这个 NameNode 有资格参加 Zookeeper 的主备选举。如果目前还没有进行过主备选举的话，那么相应的 ActiveStandbyElector 就会发起一次主备选举，尝试在 Zookeeper 上创建一个路径为/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 的临时节点 (${dfs.nameservices} 为 Hadoop 的配置参数 dfs.nameservices 的值，下同)，Zookeeper 的写一致性会保证最终只会有一个 ActiveStandbyElector 创建成功，那么创建成功的 ActiveStandbyElector 对应的 NameNode 就会成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Active 状态。而创建失败的 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Standby 状态。</p>
<p><strong>注册 Watcher 监听</strong></p>
<p>不管创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点是否成功，ActiveStandbyElector 随后都会向 Zookeeper 注册一个 Watcher 来监听这个节点的状态变化事件，ActiveStandbyElector 主要关注这个节点的 NodeDeleted 事件。</p>
<p><strong>自动触发主备选举</strong></p>
<p>如果 Active NameNode 对应的 HealthMonitor 检测到 NameNode 的状态异常时， ZKFailoverController 会主动删除当前在 Zookeeper 上建立的临时节点<code>/hadoop-ha/$&#123;dfs.nameservices&#125;/ActiveStandbyElectorLock</code>， 这样处于 Standby 状态的 NameNode 的 ActiveStandbyElector 注册的监听器就会收到这个节点的 NodeDeleted 事件。收到这个事件之后，会马上再次进入到创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点的流程，如果创建成功，这个本来处于 Standby 状态的 NameNode 就选举为主 NameNode 并随后开始切换为 Active 状态。</p>
<p>当然，如果是 Active 状态的 NameNode 所在的机器整个宕掉的话，那么根据 Zookeeper 的临时节点特性，/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点会自动被删除，从而也会自动进行一次主备切换。</p>
<p><strong>防止脑裂</strong></p>
<p>Zookeeper 在工程实践的过程中经常会发生的一个现象就是 Zookeeper 客户端“假死”，所谓的“假死”是指如果 Zookeeper 客户端机器负载过高或者正在进行 JVM Full GC，那么可能会导致 Zookeeper 客户端到 Zookeeper 服务端的心跳不能正常发出，一旦这个时间持续较长，超过了配置的 Zookeeper Session Timeout 参数的话，Zookeeper 服务端就会认为客户端的 session 已经过期从而将客户端的 Session 关闭。“假死”有可能引起分布式系统常说的双主或脑裂 (brain-split) 现象。具体到本文所述的 NameNode，假设 NameNode1 当前为 Active 状态，NameNode2 当前为 Standby 状态。如果某一时刻 NameNode1 对应的 ZKFailoverController 进程发生了“假死”现象，那么 Zookeeper 服务端会认为 NameNode1 挂掉了，根据前面的主备切换逻辑，NameNode2 会替代 NameNode1 进入 Active 状态。但是此时 NameNode1 可能仍然处于 Active 状态正常运行，即使随后 NameNode1 对应的 ZKFailoverController 因为负载下降或者 Full GC 结束而恢复了正常，感知到自己和 Zookeeper 的 Session 已经关闭，但是由于网络的延迟以及 CPU 线程调度的不确定性，仍然有可能会在接下来的一段时间窗口内 NameNode1 认为自己还是处于 Active 状态。这样 NameNode1 和 NameNode2 都处于 Active 状态，都可以对外提供服务。这种情况对于 NameNode 这类对数据一致性要求非常高的系统来说是灾难性的，数据会发生错乱且无法恢复。Zookeeper 社区对这种问题的解决方法叫做 fencing，中文翻译为隔离，也就是想办法把旧的 Active NameNode 隔离起来，使它不能正常对外提供服务。</p>
<p>ActiveStandbyElector 为了实现 fencing，会在成功创建 Zookeeper 节点 hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 从而成为 Active NameNode 之后，创建另外一个路径为/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 的持久节点，这个节点里面保存了这个 Active NameNode 的地址信息。Active NameNode 的 ActiveStandbyElector 在正常的状态下关闭 Zookeeper Session 的时候 (注意由于/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 是临时节点，也会随之删除)，会一起删除节点/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb。但是如果 ActiveStandbyElector 在异常的状态下 Zookeeper Session 关闭 (比如前述的 Zookeeper 假死)，那么由于/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 是持久节点，会一直保留下来。后面当另一个 NameNode 选主成功之后，会注意到上一个 Active NameNode 遗留下来的这个节点，从而会回调 ZKFailoverController 的方法对旧的 Active NameNode 进行 fencing，具体处理见后文 ZKFailoverController 部分所述。</p>
<h3 id="ZKFailoverController-实现分析"><a href="#ZKFailoverController-实现分析" class="headerlink" title="ZKFailoverController 实现分析"></a>ZKFailoverController 实现分析</h3><p>ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调函数，ZKFailoverController 的处理逻辑主要靠 HealthMonitor 和 ActiveStandbyElector 的回调函数来驱动。</p>
<p><strong>对 HealthMonitor 状态变化的处理</strong></p>
<p>如前所述，HealthMonitor 会检测 NameNode 的两类状态，HealthMonitor.State 在状态检测之中起主要的作用，ZKFailoverController 注册到 HealthMonitor 上的处理 HealthMonitor.State 状态变化的回调函数主要关注 SERVICE_HEALTHY、SERVICE_NOT_RESPONDING 和 SERVICE_UNHEALTHY 这 3 种状态：</p>
<ul>
<li>•如果检测到状态为 SERVICE_HEALTHY，表示当前的 NameNode 有资格参加 Zookeeper 的主备选举，如果目前还没有进行过主备选举的话，ZKFailoverController 会调用 ActiveStandbyElector 的 joinElection 方法发起一次主备选举。</li>
<li>•如果检测到状态为 SERVICE_NOT_RESPONDING 或者是 SERVICE_UNHEALTHY，就表示当前的 NameNode 出现问题了，ZKFailoverController 会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举，这样其它的 NameNode 就有机会成为主 NameNode。</li>
</ul>
<p>而 HAServiceStatus 在状态检测之中仅起辅助的作用，在 HAServiceStatus 发生变化时，ZKFailoverController 注册到 HealthMonitor 上的处理 HAServiceStatus 状态变化的回调函数会判断 NameNode 返回的 HAServiceStatus 和 ZKFailoverController 所期望的是否一致，如果不一致的话，ZKFailoverController 也会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举。</p>
<p><strong>对 ActiveStandbyElector 主备选举状态变化的处理</strong></p>
<p>在 ActiveStandbyElector 的主备选举状态发生变化时，会回调 ZKFailoverController 注册的回调函数来进行相应的处理：</p>
<ul>
<li>•如果 ActiveStandbyElector 选主成功，那么 ActiveStandbyElector 对应的 NameNode 成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeActive 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToActive 方法，将 NameNode 转换为 Active 状态。</li>
<li>•如果 ActiveStandbyElector 选主失败，那么 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeStandby 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，将 NameNode 转换为 Standby 状态。</li>
<li>•如果 ActiveStandbyElector 选主成功之后，发现了上一个 Active NameNode 遗留下来的/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 节点 (见“ActiveStandbyElector 实现分析”一节“防止脑裂”部分所述)，那么 ActiveStandbyElector 会首先回调 ZKFailoverController 注册的 fenceOldActive 方法，尝试对旧的 Active NameNode 进行 fencing，在进行 fencing 的时候，会执行以下的操作：</li>
</ul>
<ol>
<li>1.首先尝试调用这个旧 Active NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，看能不能把它转换为 Standby 状态。</li>
<li>2.如果 transitionToStandby 方法调用失败，那么就执行 Hadoop 配置文件之中预定义的隔离措施，Hadoop 目前主要提供两种隔离措施，通常会选择 sshfence：</li>
</ol>
<ul>
<li>•sshfence：通过 SSH 登录到目标机器上，执行命令 fuser 将对应的进程杀死；</li>
<li>•shellfence：执行一个用户自定义的 shell 脚本来将对应的进程隔离；</li>
</ul>
<p>只有在成功地执行完成 fencing 之后，选主成功的 ActiveStandbyElector 才会回调 ZKFailoverController 的 becomeActive 方法将对应的 NameNode 转换为 Active 状态，开始对外提供服务。</p>
<h2 id="NameNode-的共享存储实现"><a href="#NameNode-的共享存储实现" class="headerlink" title="NameNode 的共享存储实现"></a>NameNode 的共享存储实现</h2><p>过去几年中 Hadoop 社区涌现过很多的 NameNode 共享存储方案，比如 shared NAS+NFS、BookKeeper、BackupNode 和 QJM(Quorum Journal Manager) 等等。目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案合并到 HDFS 的 trunk 之中并且作为默认的共享存储实现，本部分只针对基于 QJM 的共享存储方案的内部实现原理进行分析。为了理解 QJM 的设计和实现，首先要对 NameNode 的元数据存储结构有所了解。</p>
<h3 id="NameNode-的元数据存储概述"><a href="#NameNode-的元数据存储概述" class="headerlink" title="NameNode 的元数据存储概述"></a>NameNode 的元数据存储概述</h3><p>一个典型的 NameNode 的元数据存储目录结构如图 3 所示 (图片来源于参考文献 [4])，这里主要关注其中的 EditLog 文件和 FSImage 文件：</p>
<h5 id="图-3-NameNode-的元数据存储目录结构"><a href="#图-3-NameNode-的元数据存储目录结构" class="headerlink" title="图 3 .NameNode 的元数据存储目录结构"></a>图 3 .NameNode 的元数据存储目录结构</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img003.png" alt="img"></p>
<p>NameNode 在执行 HDFS 客户端提交的创建文件或者移动文件这样的写操作的时候，会首先把这些操作记录在 EditLog 文件之中，然后再更新内存中的文件系统镜像。内存中的文件系统镜像用于 NameNode 向客户端提供读服务，而 EditLog 仅仅只是在数据恢复的时候起作用。记录在 EditLog 之中的每一个操作又称为一个事务，每个事务有一个整数形式的事务 id 作为编号。EditLog 会被切割为很多段，每一段称为一个 Segment。正在写入的 EditLog Segment 处于 in-progress 状态，其文件名形如 edits_inprogress_${start_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，例如上图中的 edits_inprogress_0000000000000000020。而已经写入完成的 EditLog Segment 处于 finalized 状态，其文件名形如 edits_${start_txid}-${end_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，${end_txid} 表示这个 segment 的结束事务 id，例如上图中的 edits_0000000000000000001-0000000000000000019。</p>
<p>NameNode 会定期对内存中的文件系统镜像进行 checkpoint 操作，在磁盘上生成 FSImage 文件，FSImage 文件的文件名形如 fsimage_${end_txid}，其中${end_txid} 表示这个 fsimage 文件的结束事务 id，例如上图中的 fsimage_0000000000000000020。在 NameNode 启动的时候会进行数据恢复，首先把 FSImage 文件加载到内存中形成文件系统镜像，然后再把 EditLog 之中 FsImage 的结束事务 id 之后的 EditLog 回放到这个文件系统镜像上。</p>
<h3 id="基于-QJM-的共享存储系统的总体架构"><a href="#基于-QJM-的共享存储系统的总体架构" class="headerlink" title="基于 QJM 的共享存储系统的总体架构"></a>基于 QJM 的共享存储系统的总体架构</h3><p><strong>基于 QJM 的共享存储系统主要用于保存 EditLog，并不保存 FSImage 文件</strong>。FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法 (参见参考文献 [3])，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉。</p>
<p>基于 QJM 的共享存储系统的内部实现架构图如图 4 所示，主要包含下面几个主要的组件：</p>
<h5 id="图-4-基于-QJM-的共享存储系统的内部实现架构图"><a href="#图-4-基于-QJM-的共享存储系统的内部实现架构图" class="headerlink" title="图 4 . 基于 QJM 的共享存储系统的内部实现架构图"></a>图 4 . 基于 QJM 的共享存储系统的内部实现架构图</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img004.png" alt="img"></p>
<p>FSEditLog：这个类封装了对 EditLog 的所有操作，是 NameNode 对 EditLog 的所有操作的入口。</p>
<p>JournalSet： 这个类封装了对本地磁盘和 JournalNode 集群上的 EditLog 的操作，内部包含了两类 JournalManager，一类为 FileJournalManager，用于实现对本地磁盘上 EditLog 的操作。一类为 QuorumJournalManager，用于实现对 JournalNode 集群上共享目录的 EditLog 的操作。FSEditLog 只会调用 JournalSet 的相关方法，而不会直接使用 FileJournalManager 和 QuorumJournalManager。</p>
<p>FileJournalManager：封装了对本地磁盘上的 EditLog 文件的操作，不仅 NameNode 在向本地磁盘上写入 EditLog 的时候使用 FileJournalManager，JournalNode 在向本地磁盘写入 EditLog 的时候也复用了 FileJournalManager 的代码和逻辑。</p>
<p>QuorumJournalManager：封装了对 JournalNode 集群上的 EditLog 的操作，它会根据 JournalNode 集群的 URI 创建负责与 JournalNode 集群通信的类 AsyncLoggerSet， QuorumJournalManager 通过 AsyncLoggerSet 来实现对 JournalNode 集群上的 EditLog 的写操作，对于读操作，QuorumJournalManager 则是通过 Http 接口从 JournalNode 上的 JournalNodeHttpServer 读取 EditLog 的数据。</p>
<p>AsyncLoggerSet：内部包含了与 JournalNode 集群进行通信的 AsyncLogger 列表，每一个 AsyncLogger 对应于一个 JournalNode 节点，另外 AsyncLoggerSet 也包含了用于等待大多数 JournalNode 返回结果的工具类方法给 QuorumJournalManager 使用。</p>
<p>AsyncLogger：具体的实现类是 IPCLoggerChannel，IPCLoggerChannel 在执行方法调用的时候，会把调用提交到一个单线程的线程池之中，由线程池线程来负责向对应的 JournalNode 的 JournalNodeRpcServer 发送 RPC 请求。</p>
<p>JournalNodeRpcServer：运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求。</p>
<p>JournalNodeHttpServer：运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby 状态的 NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求。</p>
<p>下面对基于 QJM 的共享存储系统的两个关键性问题同步数据和恢复数据进行详细分析。</p>
<h3 id="基于-QJM-的共享存储系统的数据同步机制分析"><a href="#基于-QJM-的共享存储系统的数据同步机制分析" class="headerlink" title="基于 QJM 的共享存储系统的数据同步机制分析"></a>基于 QJM 的共享存储系统的数据同步机制分析</h3><p>Active NameNode 和 StandbyNameNode 使用 JouranlNode 集群来进行数据同步的过程如图 5 所示，Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog：</p>
<h5 id="图-5-基于-QJM-的共享存储的数据同步机制"><a href="#图-5-基于-QJM-的共享存储的数据同步机制" class="headerlink" title="图 5 . 基于 QJM 的共享存储的数据同步机制"></a>图 5 . 基于 QJM 的共享存储的数据同步机制</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img005.png" alt="img"></p>
<p><strong>Active NameNode 提交 EditLog 到 JournalNode 集群</strong></p>
<p>当处于 Active 状态的 NameNode 调用 FSEditLog 类的 logSync 方法来提交 EditLog 的时候，会通过 JournalSet 同时向本地磁盘目录和 JournalNode 集群上的共享存储目录写入 EditLog。写入 JournalNode 集群是通过并行调用每一个 JournalNode 的 QJournalProtocol RPC 接口的 journal 方法实现的，如果对大多数 JournalNode 的 journal 方法调用成功，那么就认为提交 EditLog 成功，否则 NameNode 就会认为这次提交 EditLog 失败。提交 EditLog 失败会导致 Active NameNode 关闭 JournalSet 之后退出进程，留待处于 Standby 状态的 NameNode 接管之后进行数据恢复。</p>
<p>从上面的叙述可以看出，Active NameNode 提交 EditLog 到 JournalNode 集群的过程实际上是同步阻塞的，但是并不需要所有的 JournalNode 都调用成功，只要大多数 JournalNode 调用成功就可以了。如果无法形成大多数，那么就认为提交 EditLog 失败，NameNode 停止服务退出进程。如果对应到分布式系统的 CAP 理论的话，虽然采用了 Paxos 的“大多数”思想对 C(consistency，一致性) 和 A(availability，可用性) 进行了折衷，但还是可以认为 NameNode 选择了 C 而放弃了 A，这也符合 NameNode 对数据一致性的要求。</p>
<p><strong>Standby NameNode 从 JournalNode 集群同步 EditLog</strong></p>
<p>当 NameNode 进入 Standby 状态之后，会启动一个 EditLogTailer 线程。这个线程会定期调用 EditLogTailer 类的 doTailEdits 方法从 JournalNode 集群上同步 EditLog，然后把同步的 EditLog 回放到内存之中的文件系统镜像上 (并不会同时把 EditLog 写入到本地磁盘上)。</p>
<p>这里需要关注的是：从 JournalNode 集群上同步的 EditLog 都是处于 finalized 状态的 EditLog Segment。“NameNode 的元数据存储概述”一节说过 EditLog Segment 实际上有两种状态，处于 in-progress 状态的 Edit Log 当前正在被写入，被认为是处于不稳定的中间态，有可能会在后续的过程之中发生修改，比如被截断。Active NameNode 在完成一个 EditLog Segment 的写入之后，就会向 JournalNode 集群发送 finalizeLogSegment RPC 请求，将完成写入的 EditLog Segment finalized，然后开始下一个新的 EditLog Segment。一旦 finalizeLogSegment 方法在大多数的 JournalNode 上调用成功，表明这个 EditLog Segment 已经在大多数的 JournalNode 上达成一致。一个 EditLog Segment 处于 finalized 状态之后，可以保证它再也不会变化。</p>
<p>从上面描述的过程可以看出，虽然 Active NameNode 向 JournalNode 集群提交 EditLog 是同步的，但 Standby NameNode 采用的是定时从 JournalNode 集群上同步 EditLog 的方式，那么 Standby NameNode 内存中文件系统镜像有很大的可能是落后于 Active NameNode 的，所以 Standby NameNode 在转换为 Active NameNode 的时候需要把落后的 EditLog 补上来。</p>
<h3 id="基于-QJM-的共享存储系统的数据恢复机制分析"><a href="#基于-QJM-的共享存储系统的数据恢复机制分析" class="headerlink" title="基于 QJM 的共享存储系统的数据恢复机制分析"></a>基于 QJM 的共享存储系统的数据恢复机制分析</h3><p>处于 Standby 状态的 NameNode 转换为 Active 状态的时候，有可能上一个 Active NameNode 发生了异常退出，那么 JournalNode 集群中各个 JournalNode 上的 EditLog 就可能会处于不一致的状态，所以首先要做的事情就是让 JournalNode 集群中各个节点上的 EditLog 恢复为一致。另外如前所述，当前处于 Standby 状态的 NameNode 的内存中的文件系统镜像有很大的可能是落后于旧的 Active NameNode 的，所以在 JournalNode 集群中各个节点上的 EditLog 达成一致之后，接下来要做的事情就是从 JournalNode 集群上补齐落后的 EditLog。只有在这两步完成之后，当前新的 Active NameNode 才能安全地对外提供服务。</p>
<p>补齐落后的 EditLog 的过程复用了前面描述的 Standby NameNode 从 JournalNode 集群同步 EditLog 的逻辑和代码，最终调用 EditLogTailer 类的 doTailEdits 方法来完成 EditLog 的补齐。使 JournalNode 集群上的 EditLog 达成一致的过程是一致性算法 Paxos 的典型应用场景，QJM 对这部分的处理可以看做是 Single Instance Paxos(参见参考文献 [3]) 算法的一个实现，在达成一致的过程中，Active NameNode 和 JournalNode 集群之间的交互流程如图 6 所示，具体描述如下：</p>
<h5 id="图-6-Active-NameNode-和-JournalNode-集群的交互流程图"><a href="#图-6-Active-NameNode-和-JournalNode-集群的交互流程图" class="headerlink" title="图 6.Active NameNode 和 JournalNode 集群的交互流程图"></a>图 6.Active NameNode 和 JournalNode 集群的交互流程图</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img006.png" alt="img"></p>
<p><strong>生成一个新的 Epoch</strong></p>
<p>Epoch 是一个单调递增的整数，用来标识每一次 Active NameNode 的生命周期，每发生一次 NameNode 的主备切换，Epoch 就会加 1。这实际上是一种 fencing 机制，为什么需要 fencing 已经在前面“ActiveStandbyElector 实现分析”一节的“防止脑裂”部分进行了说明。产生新 Epoch 的流程与 Zookeeper 的 ZAB(Zookeeper Atomic Broadcast) 协议在进行数据恢复之前产生新 Epoch 的过程完全类似：</p>
<ol>
<li><p>1.</p>
<p>Active NameNode 首先向 JournalNode 集群发送 getJournalState RPC 请求，每个 JournalNode 会返回自己保存的最近的那个 Epoch(代码中叫 lastPromisedEpoch)。</p>
</li>
<li><p>2.</p>
<p>NameNode 收到大多数的 JournalNode 返回的 Epoch 之后，在其中选择最大的一个加 1 作为当前的新 Epoch，然后向各个 JournalNode 发送 newEpoch RPC 请求，把这个新的 Epoch 发给各个 JournalNode。</p>
</li>
<li><p>3.</p>
<p>每一个 JournalNode 在收到新的 Epoch 之后，首先检查这个新的 Epoch 是否比它本地保存的 lastPromisedEpoch 大，如果大的话就把 lastPromisedEpoch 更新为这个新的 Epoch，并且向 NameNode 返回它自己的本地磁盘上最新的一个 EditLogSegment 的起始事务 id，为后面的数据恢复过程做好准备。如果小于或等于的话就向 NameNode 返回错误。</p>
</li>
<li><p>4.</p>
<p>NameNode 收到大多数 JournalNode 对 newEpoch 的成功响应之后，就会认为生成新的 Epoch 成功。</p>
</li>
</ol>
<p>在生成新的 Epoch 之后，每次 NameNode 在向 JournalNode 集群提交 EditLog 的时候，都会把这个 Epoch 作为参数传递过去。每个 JournalNode 会比较传过来的 Epoch 和它自己保存的 lastPromisedEpoch 的大小，如果传过来的 epoch 的值比它自己保存的 lastPromisedEpoch 小的话，那么这次写相关操作会被拒绝。一旦大多数 JournalNode 都拒绝了这次写操作，那么这次写操作就失败了。如果原来的 Active NameNode 恢复正常之后再向 JournalNode 写 EditLog，那么因为它的 Epoch 肯定比新生成的 Epoch 小，并且大多数的 JournalNode 都接受了这个新生成的 Epoch，所以拒绝写入的 JournalNode 数目至少是大多数，这样原来的 Active NameNode 写 EditLog 就肯定会失败，失败之后这个 NameNode 进程会直接退出，这样就实现了对原来的 Active NameNode 的隔离了。</p>
<p><strong>选择需要数据恢复的 EditLog Segment 的 id</strong></p>
<p>需要恢复的 Edit Log 只可能是各个 JournalNode 上的最后一个 Edit Log Segment，如前所述，JournalNode 在处理完 newEpoch RPC 请求之后，会向 NameNode 返回它自己的本地磁盘上最新的一个 EditLog Segment 的起始事务 id，这个起始事务 id 实际上也作为这个 EditLog Segment 的 id。NameNode 会在所有这些 id 之中选择一个最大的 id 作为要进行数据恢复的 EditLog Segment 的 id。</p>
<p><strong>向 JournalNode 集群发送 prepareRecovery RPC 请求</strong></p>
<p>NameNode 接下来向 JournalNode 集群发送 prepareRecovery RPC 请求，请求的参数就是选出的 EditLog Segment 的 id。JournalNode 收到请求后返回本地磁盘上这个 Segment 的起始事务 id、结束事务 id 和状态 (in-progress 或 finalized)。</p>
<p>这一步对应于 Paxos 算法的 Phase 1a 和 Phase 1b(参见参考文献 [3]) 两步。Paxos 算法的 Phase1 是 prepare 阶段，这也与方法名 prepareRecovery 相对应。并且这里以前面产生的新的 Epoch 作为 Paxos 算法中的提案编号 (proposal number)。只要大多数的 JournalNode 的 prepareRecovery RPC 调用成功返回，NameNode 就认为成功。</p>
<p>选择进行同步的基准数据源，向 JournalNode 集群发送 acceptRecovery RPC 请求 NameNode 根据 prepareRecovery 的返回结果，选择一个 JournalNode 上的 EditLog Segment 作为同步的基准数据源。选择基准数据源的原则大致是：在 in-progress 状态和 finalized 状态的 Segment 之间优先选择 finalized 状态的 Segment。如果都是 in-progress 状态的话，那么优先选择 Epoch 比较高的 Segment(也就是优先选择更新的)，如果 Epoch 也一样，那么优先选择包含的事务数更多的 Segment。</p>
<p>在选定了同步的基准数据源之后，NameNode 向 JournalNode 集群发送 acceptRecovery RPC 请求，将选定的基准数据源作为参数。JournalNode 接收到 acceptRecovery RPC 请求之后，从基准数据源 JournalNode 的 JournalNodeHttpServer 上下载 EditLog Segment，将本地的 EditLog Segment 替换为下载的 EditLog Segment。</p>
<p>这一步对应于 Paxos 算法的 Phase 2a 和 Phase 2b(参见参考文献 [3]) 两步。Paxos 算法的 Phase2 是 accept 阶段，这也与方法名 acceptRecovery 相对应。只要大多数 JournalNode 的 acceptRecovery RPC 调用成功返回，NameNode 就认为成功。</p>
<p><strong>向 JournalNode 集群发送 finalizeLogSegment RPC 请求，数据恢复完成</strong></p>
<p>上一步执行完成之后，NameNode 确认大多数 JournalNode 上的 EditLog Segment 已经从基准数据源进行了同步。接下来，NameNode 向 JournalNode 集群发送 finalizeLogSegment RPC 请求，JournalNode 接收到请求之后，将对应的 EditLog Segment 从 in-progress 状态转换为 finalized 状态，实际上就是将文件名从 edits_inprogress_${startTxid} 重命名为 edits_${startTxid}-${endTxid}，见“NameNode 的元数据存储概述”一节的描述。</p>
<p>只要大多数 JournalNode 的 finalizeLogSegment RPC 调用成功返回，NameNode 就认为成功。此时可以保证 JournalNode 集群的大多数节点上的 EditLog 已经处于一致的状态，这样 NameNode 才能安全地从 JournalNode 集群上补齐落后的 EditLog 数据。</p>
<p>需要注意的是，尽管基于 QJM 的共享存储方案看起来理论完备，设计精巧，但是仍然无法保证数据的绝对强一致，下面选取参考文献 [2] 中的一个例子来说明：</p>
<p>假设有 3 个 JournalNode：JN1、JN2 和 JN3，Active NameNode 发送了事务 id 为 151、152 和 153 的 3 个事务到 JournalNode 集群，这 3 个事务成功地写入了 JN2，但是在还没能写入 JN1 和 JN3 之前，Active NameNode 就宕机了。同时，JN3 在整个写入的过程中延迟较大，落后于 JN1 和 JN2。最终成功写入 JN1 的事务 id 为 150，成功写入 JN2 的事务 id 为 153，而写入到 JN3 的事务 id 仅为 125，如图 7 所示 (图片来源于参考文献 [2])。按照前面描述的只有成功地写入了大多数的 JournalNode 才认为写入成功的原则，显然事务 id 为 151、152 和 153 的这 3 个事务只能算作写入失败。在进行数据恢复的过程中，会发生下面两种情况：</p>
<h5 id="图-7-JournalNode-集群写入的事务-id-情况"><a href="#图-7-JournalNode-集群写入的事务-id-情况" class="headerlink" title="图 7.JournalNode 集群写入的事务 id 情况"></a>图 7.JournalNode 集群写入的事务 id 情况</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img007.png" alt="img"></p>
<ul>
<li>•如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段收到了 JN2 的回复，那么肯定会以 JN2 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 153。从恢复的结果来看，实际上可以认为前面宕机的 Active NameNode 对事务 id 为 151、152 和 153 的这 3 个事务的写入成功了。但是如果从 NameNode 自身的角度来看，这显然就发生了数据不一致的情况。</li>
<li>•如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段没有收到 JN2 的回复，那么肯定会以 JN1 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 150。在这种情况下，如果从 NameNode 自身的角度来看的话，数据就是一致的了。</li>
</ul>
<p>事实上不光本文描述的基于 QJM 的共享存储方案无法保证数据的绝对一致，大家通常认为的一致性程度非常高的 Zookeeper 也会发生类似的情况，这也从侧面说明了要实现一个数据绝对一致的分布式存储系统的确非常困难。</p>
<h3 id="NameNode-在进行状态转换时对共享存储的处理"><a href="#NameNode-在进行状态转换时对共享存储的处理" class="headerlink" title="NameNode 在进行状态转换时对共享存储的处理"></a>NameNode 在进行状态转换时对共享存储的处理</h3><p>下面对 NameNode 在进行状态转换的过程中对共享存储的处理进行描述，使得大家对基于 QJM 的共享存储方案有一个完整的了解，同时也作为本部分的总结。</p>
<p><strong>NameNode 初始化启动，进入 Standby 状态</strong></p>
<p>在 NameNode 以 HA 模式启动的时候，NameNode 会认为自己处于 Standby 模式，在 NameNode 的构造函数中会加载 FSImage 文件和 EditLog Segment 文件来恢复自己的内存文件系统镜像。在加载 EditLog Segment 的时候，调用 FSEditLog 类的 initSharedJournalsForRead 方法来创建只包含了在 JournalNode 集群上的共享目录的 JournalSet，也就是说，这个时候只会从 JournalNode 集群之中加载 EditLog，而不会加载本地磁盘上的 EditLog。另外值得注意的是，加载的 EditLog Segment 只是处于 finalized 状态的 EditLog Segment，而处于 in-progress 状态的 Segment 需要后续在切换为 Active 状态的时候，进行一次数据恢复过程，将 in-progress 状态的 Segment 转换为 finalized 状态的 Segment 之后再进行读取。</p>
<p>加载完 FSImage 文件和共享目录上的 EditLog Segment 文件之后，NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式。如前所述，EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog。而 StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点。</p>
<p><strong>NameNode 从 Standby 状态切换为 Active 状态</strong></p>
<p>当 NameNode 从 Standby 状态切换为 Active 状态的时候，首先需要做的就是停止它在 Standby 状态的时候启动的线程和相关的服务，包括上面提到的 EditLogTailer 线程和 StandbyCheckpointer 线程，然后关闭用于读取 JournalNode 集群的共享目录上的 EditLog 的 JournalSet，接下来会调用 FSEditLog 的 initJournalSetForWrite 方法重新打开 JournalSet。不同的是，这个 JournalSet 内部同时包含了本地磁盘目录和 JournalNode 集群上的共享目录。这些工作完成之后，就开始执行“基于 QJM 的共享存储系统的数据恢复机制分析”一节所描述的流程，调用 FSEditLog 类的 recoverUnclosedStreams 方法让 JournalNode 集群中各个节点上的 EditLog 达成一致。然后调用 EditLogTailer 类的 catchupDuringFailover 方法从 JournalNode 集群上补齐落后的 EditLog。最后打开一个新的 EditLog Segment 用于新写入数据，同时启动 Active NameNode 所需要的线程和服务。</p>
<p><strong>NameNode 从 Active 状态切换为 Standby 状态</strong></p>
<p>当 NameNode 从 Active 状态切换为 Standby 状态的时候，首先需要做的就是停止它在 Active 状态的时候启动的线程和服务，然后关闭用于读取本地磁盘目录和 JournalNode 集群上的共享目录的 EditLog 的 JournalSet。接下来会调用 FSEditLog 的 initSharedJournalsForRead 方法重新打开用于读取 JournalNode 集群上的共享目录的 JournalSet。这些工作完成之后，就会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，EditLogTailer 线程会定时从 JournalNode 集群上同步 Edit Log。</p>
<h2 id="NameNode-高可用运维中的注意事项"><a href="#NameNode-高可用运维中的注意事项" class="headerlink" title="NameNode 高可用运维中的注意事项"></a>NameNode 高可用运维中的注意事项</h2><p>本节结合笔者的实践，从初始化部署和日常运维两个方面介绍一些在 NameNode 高可用运维中的注意事项。</p>
<h3 id="初始化部署"><a href="#初始化部署" class="headerlink" title="初始化部署"></a>初始化部署</h3><p>如果在开始部署 Hadoop 集群的时候就启用 NameNode 的高可用的话，那么相对会比较容易。但是如果在采用传统的单 NameNode 的架构运行了一段时间之后，升级为 NameNode 的高可用架构的话，就要特别注意在升级的时候需要按照以下的步骤进行操作：</p>
<ol>
<li>1.对 Zookeeper 进行初始化，创建 Zookeeper 上的/hadoop-ha/${dfs.nameservices} 节点。创建节点是为随后通过 Zookeeper 进行主备选举做好准备，在进行主备选举的时候会在这个节点下面创建子节点 (具体可参照“ActiveStandbyElector 实现分析”一节的叙述)。这一步通过在原有的 NameNode 上执行命令 hdfs zkfc -formatZK 来完成。</li>
<li>2.启动所有的 JournalNode，这通过脚本命令 hadoop-daemon.sh start journalnode 来完成。</li>
<li>3.对 JouranlNode 集群的共享存储目录进行格式化，并且将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件 (具体可参照“NameNode 的元数据存储概述”一节的叙述) 之后的 EditLog 拷贝到 JournalNode 集群上的共享目录之中，这通过在原有的 NameNode 上执行命令 hdfs namenode -initializeSharedEdits 来完成。</li>
<li>4.启动原有的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。</li>
<li>5.对新增的 NameNode 节点进行初始化，将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件拷贝到这个新增的 NameNode 的本地磁盘上，同时需要验证 JournalNode 集群的共享存储目录上已经具有了这个 FSImage 文件之后的 EditLog(已经在第 3 步完成了)。这一步通过在新增的 NameNode 上执行命令 hdfs namenode -bootstrapStandby 来完成。</li>
<li>6.启动新增的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。</li>
<li>7.在这两个 NameNode 上启动 zkfc(ZKFailoverController) 进程，谁通过 Zookeeper 选主成功，谁就是主 NameNode，另一个为备 NameNode。这通过脚本命令 hadoop-daemon.sh start zkfc 完成。</li>
</ol>
<h3 id="日常维护"><a href="#日常维护" class="headerlink" title="日常维护"></a>日常维护</h3><p>笔者在日常的维护之中主要遇到过下面两种问题：</p>
<p>Zookeeper 过于敏感：Hadoop 的配置项中 Zookeeper 的 session timeout 的配置参数 ha.zookeeper.session-timeout.ms 的默认值为 5000，也就是 5s，这个值比较小，会导致 Zookeeper 比较敏感，可以把这个值尽量设置得大一些，避免因为网络抖动等原因引起 NameNode 进行无谓的主备切换。</p>
<p>单台 JouranlNode 故障时会导致主备无法切换：在理论上，如果有 3 台或者更多的 JournalNode，那么挂掉一台 JouranlNode 应该仍然可以进行正常的主备切换。但是笔者在某次 NameNode 重启的时候，正好赶上一台 JournalNode 挂掉宕机了，这个时候虽然某一台 NameNode 通过 Zookeeper 选主成功，但是这台被选为主的 NameNode 无法成功地从 Standby 状态切换为 Active 状态。事后追查原因发现，被选为主的 NameNode 卡在退出 Standby 状态的最后一步，这个时候它需要等待到 JournalNode 的请求全部完成之后才能退出。但是由于有一台 JouranlNode 宕机，到这台 JournalNode 的请求都积压在一起并且在不断地进行重试，同时在 Hadoop 的配置项中重试次数的默认值非常大，所以就会导致被选为主的 NameNode 无法及时退出 Standby 状态。这个问题主要是 Hadoop 内部的 RPC 通信框架的设计缺陷引起的，Hadoop HA 的源代码 IPCLoggerChannel 类中有关于这个问题的 TODO，但是截止到社区发布的 2.7.1 版本这个问题仍然存在。</p>
<h4 id="相关主题"><a href="#相关主题" class="headerlink" title="相关主题"></a>相关主题</h4><ul>
<li>•[<a href="https://issues.apache.org/jira/browse/HDFS-1623">1]Sanjay Radia, Suresh Srinivas. High Availability for the HDFS Namenode.</a></li>
<li>•[<a href="https://issues.apache.org/jira/browse/HDFS-3077">2]Todd Lipcon . Quorum-Journal Design.</a></li>
<li>•[<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">3]L Lamport. Paxos Made Simple. ACM SIGACT News,2001</a></li>
<li>•[<a href="http://shop.oreilly.com/product/0636920033448.do">4]Tom White.Hadoop: The Definitive Guide 4th Edition. O’Reilly Media, Inc., 2015</a></li>
<li>•<a href="http://www.ibm.com/developerworks/cn/opensource/">developerWorks 开源技术主题</a>：查找丰富的操作信息、工具和项目更新，帮助您掌握开源技术并将其用于 IBM 产品。</li>
</ul>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>mapReducer</tag>
      </tags>
  </entry>
  <entry>
    <title>orcfile</title>
    <url>/bigdata/Hadoop/ORC-file/</url>
    <content><![CDATA[<h1 id="ORC-file"><a href="#ORC-file" class="headerlink" title="ORC file"></a>ORC file</h1><p>源码主要有core和mapreduce两个module，其中MapReduce module就是Hadoop的InputFormat和OutFormat，这个module下有两个包，mapred和MapReduce分别符合MapReduce的V1和V2的Input/Output Format.</p>
<p>四个类：OrcInputFormat、OrcOutputFormat、OrcMapreduceRecordReader和OrcMapreduceRecordWriter</p>
<h2 id="OrcInputFormat与OrcOutputFormat"><a href="#OrcInputFormat与OrcOutputFormat" class="headerlink" title="OrcInputFormat与OrcOutputFormat"></a>OrcInputFormat与OrcOutputFormat</h2><p>OrcInputFormat继承了FileInputFormat，getSplits用的就是FileInputFormat的实现，只是重写了createRecordReader方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> RecordReader&lt;NullWritable, V&gt;</span><br><span class="line">    createRecordReader(InputSplit inputSplit,</span><br><span class="line">                       TaskAttemptContext taskAttemptContext</span><br><span class="line">                       ) <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">  FileSplit split = (FileSplit) inputSplit;</span><br><span class="line">  Configuration conf = taskAttemptContext.getConfiguration();</span><br><span class="line">  Reader file = OrcFile.createReader(split.getPath(),</span><br><span class="line">      OrcFile.readerOptions(conf)</span><br><span class="line">          .maxLength(OrcConf.MAX_FILE_LENGTH.getLong(conf)));</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> OrcMapreduceRecordReader&lt;&gt;(file,</span><br><span class="line">      org.apache.orc.mapred.OrcInputFormat.buildOptions(conf,</span><br><span class="line">          file, split.getStart(), split.getLength()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里面用到了org.apache.orc.Reader和org.apache.orc.OrcFile. 模板里面的V通常会是OrcStruct，Orc中一个表的schema可以表示为一个OrcStruct。<br>同样滴，OrcOutputFormat当中也是重写了craeteRecordWriter方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> RecordWriter&lt;NullWritable, V&gt;</span><br><span class="line">     getRecordWriter(TaskAttemptContext taskAttemptContext</span><br><span class="line">                     ) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  Configuration conf = taskAttemptContext.getConfiguration();</span><br><span class="line">  Path filename = getDefaultWorkFile(taskAttemptContext, EXTENSION);</span><br><span class="line">  Writer writer = OrcFile.createWriter(filename,</span><br><span class="line">      org.apache.orc.mapred.OrcOutputFormat.buildOptions(conf));</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">new</span> OrcMapreduceRecordWriter&lt;V&gt;(writer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里面用到了org.apache.orc.Writer和org.apache.orc.OrcFile.<br>以上用到的这三个类都是core module里的，之后再去读。</p>
<h2 id="OrcMapreduceRecordReader"><a href="#OrcMapreduceRecordReader" class="headerlink" title="OrcMapreduceRecordReader"></a>OrcMapreduceRecordReader</h2><p>这个类里面其实复用了org.apache.orc.mapred包下面的一些Writable类，这些Writable类用来在MapReduce中支持Orc中的一些特殊数据类型，比如Map、List、Struct等等，可以将这些数据类型从DataInput中反序列化出来，也可以将数据序列化到DataOutput中去。</p>
<p>从构造方法可以看到：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">OrcMapreduceRecordReader</span><span class="params">(Reader fileReader,</span></span></span><br><span class="line"><span class="function"><span class="params">                                Reader.Options options)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.batchReader = fileReader.rows(options);</span><br><span class="line">  <span class="keyword">if</span> (options.getSchema() == <span class="keyword">null</span>) &#123;</span><br><span class="line">    schema = fileReader.getSchema();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    schema = options.getSchema();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">this</span>.batch = schema.createRowBatch();</span><br><span class="line">  rowInBatch = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">this</span>.row = (V) OrcStruct.createValue(schema);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中batchReader是org.apache.orc.RecordReader类型的，这个RecordReader在core中。batch是真正有数据的地方。batch的类型是org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch，从java doc可以看出来它是干嘛用的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A VectorizedRowBatch is a set of rows, organized with each column</span></span><br><span class="line"><span class="comment"> * as a vector. It is the unit of query execution, organized to minimize</span></span><br><span class="line"><span class="comment"> * the cost per row and achieve high cycles-per-instruction.</span></span><br><span class="line"><span class="comment"> * The major fields are public by design to allow fast and convenient</span></span><br><span class="line"><span class="comment"> * access by the vectorized query execution code.</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>
<p>而schema是org.apache.orc.TypeDescription类型的，而TypeDescription其实是一个数据类型的描述，它有一个category，可以是INT、FLOAT等等，也可以是STRUCT。这里schema的category通常会是STRUCT。STRUCT和OrcStruct是对应的，是一个复合类型，其中可以包含其他类型的属性，用来表示一个表的schema。</p>
<p>row就是batchReader从batch中读出来的一行记录。</p>
<p>OrcMapreduceRecordReader中另外一个重要的方法是nextKeyValue：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!ensureBatch()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (schema.getCategory() == TypeDescription.Category.STRUCT) &#123;</span><br><span class="line">    OrcStruct result = (OrcStruct) row;</span><br><span class="line">    List&lt;TypeDescription&gt; children = schema.getChildren();</span><br><span class="line">    <span class="keyword">int</span> numberOfChildren = children.size();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; numberOfChildren; ++i) &#123;</span><br><span class="line">      result.setFieldValue(i, OrcMapredRecordReader.nextValue(batch.cols[i], rowInBatch,</span><br><span class="line">          children.get(i), result.getFieldValue(i)));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    OrcMapredRecordReader.nextValue(batch.cols[<span class="number">0</span>], rowInBatch, schema, row);</span><br><span class="line">  &#125;</span><br><span class="line">  rowInBatch += <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看出来，这个方法中，判断当schema是STRUCT的category时，将它看做一个表的schema，取出里面包含的children，即各个字段的TypeDescription，然后读取各个字段的值，存入row中。这其中复用了OrcMapredRecordReader.nextValue()方法.</p>
<h2 id="OrcMapreduceRecordWriter"><a href="#OrcMapreduceRecordWriter" class="headerlink" title="OrcMapreduceRecordWriter"></a>OrcMapreduceRecordWriter</h2><p>OrcMapreduceRecordWriter和OrcMapreduceRecordReader类似，只不过其中的batchReader换成了org.apache.orc<br>.Writer类型的writer。构造方法如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">OrcMapreduceRecordWriter</span><span class="params">(Writer writer)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.writer = writer;</span><br><span class="line">  schema = writer.getSchema();</span><br><span class="line">  <span class="keyword">this</span>.batch = schema.createRowBatch();</span><br><span class="line">  isTopStruct = schema.getCategory() == TypeDescription.Category.STRUCT;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个类的主要方法就是write方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(NullWritable nullWritable, V v)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// if the batch is full, write it out.</span></span><br><span class="line">  <span class="keyword">if</span> (batch.size == batch.getMaxSize()) &#123;</span><br><span class="line">    writer.addRowBatch(batch);</span><br><span class="line">    batch.reset();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// add the new row</span></span><br><span class="line">  <span class="keyword">int</span> row = batch.size++;</span><br><span class="line">  <span class="comment">// skip over the OrcKey or OrcValue</span></span><br><span class="line">  <span class="keyword">if</span> (v <span class="keyword">instanceof</span> OrcKey) &#123;</span><br><span class="line">    v = (V)((OrcKey) v).key;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v <span class="keyword">instanceof</span> OrcValue) &#123;</span><br><span class="line">    v = (V)((OrcValue) v).value;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (isTopStruct) &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> f=<span class="number">0</span>; f &lt; schema.getChildren().size(); ++f) &#123;</span><br><span class="line">      OrcMapredRecordWriter.setColumn(schema.getChildren().get(f),</span><br><span class="line">          batch.cols[f], row, ((OrcStruct) v).getFieldValue(f));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    OrcMapredRecordWriter.setColumn(schema, batch.cols[<span class="number">0</span>], row, v);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看出来，write先把V类型（通常是OrcStruct）的记录写入batch，如果batch写满了，就批量写入writer。</p>
<p>【参考文献】</p>
<ol>
<li><a href="https://blog.csdn.net/bhq2010/article/details/76213895">ORC源码阅读(1) - mapreduce module</a></li>
</ol>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>mapReducer</tag>
        <tag>hive</tag>
        <tag>orc</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Hadoop/Yarn/</url>
    <content><![CDATA[<h1 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h1><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">grep -A2 -B1 cg yarn-site.xml </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.memory-control.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.oom.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.hierarchy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop-yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/cgroup<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>Hadoop专题</title>
    <url>/bigdata/Hadoop/base/</url>
    <content><![CDATA[<p>从本篇开始，陆续对常用大数据平台的原理和部分核心源码进行解读和整理。</p>
<p>这里的常用大数据平台包括Hadoop(HDFS、MR)、Spark、Kylin、Flink、HBase、Flume、Elastic Search等</p>
<h1 id="Hadoop专题"><a href="#Hadoop专题" class="headerlink" title="Hadoop专题"></a>Hadoop专题</h1><ol>
<li><a href="/distributed/docker/hadoop-cluser-in-docker/">在Docker上搭建Hadoop集群container</a></li>
<li><a href="/distributed/hadoop/hadoop-cluser-configuration/">Hadoop集群节点配置及搭建</a></li>
<li><a href="/distributed/hadoop/HDFS-Java-API/">HDFS Java API</a></li>
</ol>
<h2 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h2><ul>
<li>HDFS的架构</li>
<li>数据存储与交互</li>
</ul>
<h2 id="MR架构"><a href="#MR架构" class="headerlink" title="MR架构"></a>MR架构</h2><p>对于MapReduce作业，完整的作业运行流程，这里借用刘军老师的<a href="http://item.jd.com/11315351.html">Hadoop大数据处理</a>中的一张图：</p>
<p><img src="_v_images/20191210133913040_1367150948.png" alt="hadoop"></p>
<p>完整过程应该是分为7部分，分别是：</p>
<ol>
<li>作业启动：开发者通过控制台启动作业；</li>
<li>作业初始化：这里主要是切分数据、创建作业和提交作业，与第三步紧密相联；</li>
<li>作业/任务调度：对于1.0版的Hadoop来说就是JobTracker来负责任务调度，对于2.0版的Hadoop来说就是Yarn中的Resource Manager负责整个系统的资源管理与分配，<br>Yarn可以参考IBM的一篇博客<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/">Hadoop新MapReduce框架Yarn详解</a>；</li>
<li>Map任务；</li>
<li>Shuffle；</li>
<li>Reduce任务；</li>
<li>作业完成：通知开发者任务完成。</li>
</ol>
<p>而这其中最主要的MapReduce过程，主要是第4、5、6步三部分，这也是本篇博客重点讨论的地方，详细作用如下：</p>
<ol>
<li><strong>Map</strong>: 数据输入,做初步的处理,输出形式的中间结果；</li>
<li><strong>Shuffle</strong>: 按照partition、key对中间结果进行排序合并,输出给reduce线程；</li>
<li><strong>Reduce</strong>: 对相同key的输入进行最终的处理,并将结果写入到文件中。</li>
</ol>
<p>这里先给出官网上关于这个过程的经典流程图：</p>
<p><img src="_v_images/20191210133912634_295276182.png" alt="mapreduce"><br>mapreduce</p>
<p>上图是把MapReduce过程分为两个部分，而实际上从两边的Map和Reduce到中间的那一大块都属于Shuffle过程，也就是说，Shuffle过程有一部分是在Map端，有一部分是在Reduce端，下文也将会分两部分来介绍Shuffle过程。</p>
<p>大部分的情况下，map task与reduce task的执行是分布在不同的节点上的，因此，很多情况下，reduce执行时需要跨节点去拉取其他节点上的map task结果，这样造成了集群内部的网络资源消耗很严重，而且在节点的内部，相比于内存，磁盘IO对性能的影响是非常严重的。如果集群中运行的作业有很多，那么task的执行对于集群内部网络的资源消费非常大。因此，我们对于MapRedue作业Shuffle过程的期望是：</p>
<ul>
<li>完整地从map task端拉取数据到Reduce端；</li>
<li>在跨节点拉取数据时，尽可能地减少对带宽的不必要消耗；</li>
<li>减少磁盘IO对task执行的影响。</li>
</ul>
<p><a href="https://matt33.com/2016/03/02/hadoop-shuffle/">MapReduce之Shuffle过程详述</a></p>
<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>在进行海量数据处理时，外存文件数据<strong>I/O访问</strong>会成为一个制约系统性能的瓶颈，因此，Hadoop的Map过程实现的一个重要原则就是：<strong>近数据计算</strong>，这里主要指两个方面：</p>
<ol>
<li>代码靠近数据：<ul>
<li>原则：本地化数据处理（locality），即一个计算节点尽可能处理本地磁盘上所存储的数据；</li>
<li>尽量选择数据所在<code>DataNode</code>启动<code>Map</code>任务；</li>
<li>这样可以减少数据通信，提高计算效率；</li>
</ul>
</li>
<li>数据靠近代码：<ul>
<li>当本地没有数据处理时，尽可能从同一机架或最近其他节点传输数据进行处理（host选择算法）。</li>
</ul>
</li>
</ol>
<p>下面，我们分块去介绍Hadoop的Map过程，map的经典流程图如下：</p>
<p><img src="_v_images/20191210133912228_1057323278.png" alt="map-shuffle"></p>
<h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><ol>
<li>map task只读取split分片，split与block（hdfs的最小存储单位，默认为64MB）可能是一对一也能是一对多，但是对于一个split只会对应一个文件的一个block或多个block，不允许一个split对应多个文件的多个block；</li>
<li>这里切分和输入数据时会涉及到InputFormat的文件切分算法和host选择算法。</li>
</ol>
<h4 id="文件切分算法"><a href="#文件切分算法" class="headerlink" title="文件切分算法"></a>文件切分算法</h4><p><strong>文件切分算法</strong>，主要用于确定<code>InputSplit</code>的个数以及每个<code>InputSplit</code>对应的数据段。<code>FileInputFormat</code>以文件为单位切分生成<code>InputSplit</code>，对于每个文件，由以下三个属性值决定其对应的<code>InputSplit</code>的个数：、、、🤣、、、、、😍😱😱😮</p>
<ul>
<li><code>goalSize</code>： 它是根据用户期望的InputSplit数目计算出来的，即<code>totalSize/numSplits</code>。其中，<code>totalSize</code>为文件的总大小；<code>numSplits</code>为用户设定的Map Task个数，默认情况下是1；</li>
<li><code>minSize</code>：InputSplit的最小值，由配置参数<code>mapred.min.split.size</code>确定，默认是1；</li>
<li><code>blockSize</code>：文件在hdfs中存储的block大小，不同文件可能不同，默认是64MB。</li>
</ul>
<p>这三个参数共同决定InputSplit的最终大小，计算方法如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">splitSize&#x3D;max&#123;minSize, min&#123;gogalSize,blockSize&#125;&#125;</span><br></pre></td></tr></table></figure>
<h4 id="host选择算法"><a href="#host选择算法" class="headerlink" title="host选择算法"></a>host选择算法</h4><p>FileInputFormat的host选择算法参考《Hadoop技术内幕-深入解析MapReduce架构设计与实现原理》的p50.</p>
<h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><ul>
<li>作用：将map的结果发送到相应的reduce端，总的partition的数目等于reducer的数量。</li>
<li>实现功能：<ol>
<li>map输出的是<code>key/value</code>对，决定于当前的mapper的part交给哪个reduce的方法是：<br>mapreduce提供的Partitioner接口，对key进行hash后，再以reducetask数量取模，然后到指定的job上（<strong>HashPartitioner</strong>，可以通过<code>job.setPartitionerClass(MyPartition.class)</code>自定义）。</li>
<li>然后将数据写入到内存缓冲区，缓冲区的作用是批量收集map结果，减少磁盘IO的影响。key/value对以及Partition的结果都会被写入缓冲区。在写入之前，key与value值都会被序列化成字节数组。</li>
</ol>
</li>
<li>要求：负载均衡，效率；</li>
</ul>
<h3 id="spill（溢写）：sort-amp-combiner"><a href="#spill（溢写）：sort-amp-combiner" class="headerlink" title="spill（溢写）：sort &amp; combiner"></a>spill（溢写）：sort &amp; combiner</h3><ul>
<li>作用：把内存缓冲区中的数据写入到本地磁盘，在写入本地磁盘时先按照partition、再按照key进行排序（<code>quick sort</code>）；</li>
<li>注意：<ol>
<li>这个spill是由<strong>另外单独的线程</strong>来完成，不影响往缓冲区写map结果的线程；</li>
<li>内存缓冲区默认大小限制为100MB，它有个溢写比例（<code>spill.percent</code>），默认为0.8，当缓冲区的数据达到阈值时，溢写线程就会启动，先锁定这80MB的内存，执行溢写过程，<code>map task</code>的输出结果还可以往剩下的20MB内存中写，互不影响。然后再重新利用这块缓冲区，因此Map的内存缓冲区又叫做<strong>环形缓冲区</strong>（两个指针的方向不会变，下面会详述）；</li>
<li>在将数据写入磁盘之前，先要对要写入磁盘的数据进行一次<strong>排序</strong>操作，先按<code>&lt;key,value,partition&gt;</code>中的partition分区号排序，然后再按key排序，这个就是<strong>sort操作</strong>，最后溢出的小文件是分区的，且同一个分区内是保证key有序的；</li>
</ol>
</li>
</ul>
<p><strong>combine</strong>：执行combine操作要求开发者必须在程序中设置了combine（程序中通过<code>job.setCombinerClass(myCombine.class)</code>自定义combine操作）。</p>
<ul>
<li>程序中有两个阶段可能会执行combine操作：<ol>
<li>map输出数据根据分区排序完成后，在写入文件之前会执行一次combine操作（前提是作业中设置了这个操作）；</li>
<li>如果map输出比较大，溢出文件个数大于3（此值可以通过属性<code>min.num.spills.for.combine</code>配置）时，在merge的过程（多个spill文件合并为一个大文件）中还会执行combine操作；</li>
</ol>
</li>
<li>combine主要是把形如<code>&lt;aa,1&gt;,&lt;aa,2&gt;</code>这样的key值相同的数据进行计算，计算规则与reduce一致，比如：当前计算是求key对应的值求和，则combine操作后得到<code>&lt;aa,3&gt;</code>这样的结果。</li>
<li>注意事项：不是每种作业都可以做combine操作的，只有满足以下条件才可以：<ol>
<li>reduce的输入输出类型都一样，因为combine本质上就是reduce操作；</li>
<li>计算逻辑上，combine操作后不会影响计算结果，像求和就不会影响；</li>
</ol>
</li>
</ul>
<h3 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h3><ul>
<li>merge过程：当map很大时，每次溢写会产生一个spill_file，这样会有多个spill_file，而最终的一个map task输出只有一个文件，因此，最终的结果输出之前会对多个中间过程进行多次溢写文件（spill_file）的合并，此过程就是merge过程。也即是，待Map Task任务的所有数据都处理完后，会对任务产生的所有中间数据文件做一次合并操作，以确保一个Map Task最终只生成一个中间数据文件。</li>
<li>注意：<ol>
<li>如果生成的文件太多，可能会执行多次合并，每次最多能合并的文件数默认为10，可以通过属性<code>min.num.spills.for.combine</code>配置；</li>
<li>多个溢出文件合并时，会进行一次排序，排序算法是<strong>多路归并排序</strong>；</li>
<li>是否还需要做combine操作，一是看是否设置了combine，二是看溢出的文件数是否大于等于3；</li>
<li>最终生成的文件格式与单个溢出文件一致，也是按分区顺序存储，并且输出文件会有一个对应的索引文件，记录每个分区数据的起始位置，长度以及压缩长度，这个索引文件名叫做<code>file.out.index</code>。</li>
</ol>
</li>
</ul>
<h3 id="内存缓冲区"><a href="#内存缓冲区" class="headerlink" title="内存缓冲区"></a>内存缓冲区</h3><ol>
<li>在Map Task任务的业务处理方法map()中，最后一步通过<code>OutputCollector.collect(key,value)</code>或<code>context.write(key,value)</code>输出Map Task的中间处理结果，在相关的<code>collect(key,value)</code>方法中，会调用<code>Partitioner.getPartition(K2 key, V2 value, int numPartitions)</code>方法获得输出的key/value对应的分区号(分区号可以认为对应着一个要执行Reduce Task的节点)，然后将<code>&lt;key,value,partition&gt;</code>暂时保存在内存中的MapOutputBuffe内部的环形数据缓冲区，该缓冲区的默认大小是100MB，可以通过参数<code>io.sort.mb</code>来调整其大小。</li>
<li>当缓冲区中的数据使用率达到一定阀值后，触发一次Spill操作，将环形缓冲区中的部分数据写到磁盘上，生成一个临时的Linux本地数据的spill文件；然后在缓冲区的使用率再次达到阀值后，再次生成一个spill文件。直到数据处理完毕，在磁盘上会生成很多的临时文件。</li>
<li>缓存有一个阀值比例配置，当达到整个缓存的这个比例时，会触发spill操作；触发时，map输出还会接着往剩下的空间写入，但是写满的空间会被锁定，数据溢出写入磁盘。当这部分溢出的数据写完后，空出的内存空间可以接着被使用，形成像环一样的被循环使用的效果，所以又叫做<strong>环形内存缓冲区</strong>；</li>
<li>MapOutputBuffe内部存数的数据采用了两个索引结构，涉及三个环形内存缓冲区。下来看一下两级索引结构：</li>
</ol>
<p><img src="_v_images/20191210133911922_22828392.jpg" alt="buffer"></p>
<p><a href="http://www.cnblogs.com/edisonchou/p/4298423.html">写入到缓冲区的数据采取了压缩算法</a><br>这三个环形缓冲区的含义分别如下：</p>
<ol>
<li><strong>kvoffsets</strong>缓冲区：也叫偏移量索引数组，用于保存<code>key/value</code>信息在位置索引 <code>kvindices</code> 中的偏移量。当 <code>kvoffsets</code> 的使用率超过 <code>io.sort.spill.percent</code> (默认为80%)后，便会触发一次 SpillThread 线程的“溢写”操作，也就是开始一次 Spill 阶段的操作。</li>
<li><strong>kvindices</strong>缓冲区：也叫位置索引数组，用于保存 <code>key/value</code> 在数据缓冲区 <code>kvbuffer</code> 中的起始位置。</li>
<li><strong>kvbuffer</strong>即数据缓冲区：用于保存实际的 <code>key/value</code> 的值。默认情况下该缓冲区最多可以使用 <code>io.sort.mb</code> 的95%，当 <code>kvbuffer</code> 使用率超过 <code>io.sort.spill.percent</code> (默认为80%)后，便会出发一次 SpillThread 线程的“溢写”操作，也就是开始一次 Spill 阶段的操作。</li>
</ol>
<p>写入到本地磁盘时，对数据进行排序，实际上是对<strong>kvoffsets</strong>这个偏移量索引数组进行排序。</p>
<h2 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h2><p>Reduce过程的经典流程图如下：</p>
<p><img src="_v_images/20191210133911614_1936741169.png" alt="reduce-shuffle"></p>
<h3 id="copy过程"><a href="#copy过程" class="headerlink" title="copy过程"></a>copy过程</h3><ul>
<li>作用：拉取数据；</li>
<li>过程：Reduce进程启动一些数据copy线程(<code>Fetcher</code>)，通过HTTP方式请求map task所在的TaskTracker获取map task的输出文件。因为这时map task早已结束，这些文件就归TaskTracker管理在本地磁盘中。</li>
<li>默认情况下，当整个MapReduce作业的所有已执行完成的Map Task任务数超过Map Task总数的5%后，JobTracker便会开始调度执行Reduce Task任务。然后Reduce Task任务默认启动<code>mapred.reduce.parallel.copies</code>(默认为5）个MapOutputCopier线程到已完成的Map Task任务节点上分别copy一份属于自己的数据。 这些copy的数据会首先保存的内存缓冲区中，当内冲缓冲区的使用率达到一定阀值后，则写到磁盘上。</li>
</ul>
<p><strong>内存缓冲区</strong></p>
<ul>
<li>这个内存缓冲区大小的控制就不像map那样可以通过<code>io.sort.mb</code>来设定了，而是通过另外一个参数来设置：<code>mapred.job.shuffle.input.buffer.percent（default 0.7）</code>， 这个参数其实是一个百分比，意思是说，shuffile在reduce内存中的数据最多使用内存量为：0.7 × <code>maxHeap of reduce task</code>。</li>
<li>如果该reduce task的最大heap使用量（通常通过<code>mapred.child.java.opts</code>来设置，比如设置为-Xmx1024m）的一定比例用来缓存数据。默认情况下，reduce会使用其heapsize的70%来在内存中缓存数据。如果reduce的heap由于业务原因调整的比较大，相应的缓存大小也会变大，这也是为什么reduce用来做缓存的参数是一个百分比，而不是一个固定的值了。</li>
</ul>
<h3 id="merge过程"><a href="#merge过程" class="headerlink" title="merge过程"></a>merge过程</h3><ul>
<li>Copy过来的数据会先放入内存缓冲区中，这里的缓冲区大小要比 map 端的更为灵活，它基于 JVM 的<code>heap size</code>设置，因为 Shuffle 阶段 Reducer 不运行，所以应该把绝大部分的内存都给 Shuffle 用。</li>
<li>这里需要强调的是，merge 有三种形式：1)内存到内存 2)内存到磁盘 3)磁盘到磁盘。默认情况下第一种形式是不启用的。当内存中的数据量到达一定阈值，就启动内存到磁盘的 merge（图中的第一个merge，之所以进行merge是因为reduce端在从多个map端copy数据的时候，并没有进行sort，只是把它们加载到内存，当达到阈值写入磁盘时，需要进行merge） 。这和map端的很类似，这实际上就是溢写的过程，在这个过程中如果你设置有Combiner，它也是会启用的，然后在磁盘中生成了众多的溢写文件，这种merge方式一直在运行，直到没有 map 端的数据时才结束，然后才会启动第三种磁盘到磁盘的 merge （图中的第二个merge）方式生成最终的那个文件。</li>
<li>在远程copy数据的同时，Reduce Task在后台启动了两个后台线程对内存和磁盘上的数据文件做合并操作，以防止内存使用过多或磁盘生的文件过多。</li>
</ul>
<h3 id="reducer的输入文件"><a href="#reducer的输入文件" class="headerlink" title="reducer的输入文件"></a>reducer的输入文件</h3><ul>
<li>merge的最后会生成一个文件，大多数情况下存在于磁盘中，但是需要将其放入内存中。当reducer 输入文件已定，整个 Shuffle 阶段才算结束。然后就是 Reducer 执行，把结果放到 HDFS 上。</li>
</ul>
<h3 id="shuffle"><a href="#shuffle" class="headerlink" title="shuffle"></a>shuffle</h3><h3 id="maptask并行度决定机制"><a href="#maptask并行度决定机制" class="headerlink" title="maptask并行度决定机制"></a>maptask并行度决定机制</h3><p>maptask 的并行度决定 map 阶段的任务处理并发度，进而影响到整个 job 的处理速度 那么， mapTask 并行实例是否越多越好呢？其并行度又是如何决定呢？  </p>
<p>一个 job 的 map 阶段并行度由客户端在提交 job 时决定， 客户端对 map 阶段并行度的规划<br>的基本逻辑为：<br>将待处理数据执行逻辑切片（即按照一个特定切片大小，将待处理数据划分成逻辑上的多 个 split），然后每一个 split 分配一个 mapTask 并行实例处理<br>这段逻辑及形成的切片规划描述文件，是由 FileInputFormat实现类的 getSplits()方法完成的。<br>该方法返回的是 List<InputSplit>， InputSplit 封装了每一个逻辑切片的信息，包括长度和位置  信息，而 getSplits()方法返回一组 InputSplit</p>
<p> 4、切片机制</p>
<p><img src="_v_images/20191210125844932_1553710655.png"></p>
<p>5、maptask并行度经验之谈</p>
<p>如果硬件配置为 2*12core + 64G，恰当的 map 并行度是大约每个节点 20-100 个 map，最好 每个 map 的执行时间至少一分钟。<br>     （1）如果 job 的每个 map 或者 reduce task 的运行时间都只有 30-40 秒钟，那么就减少该 job 的 map 或者 reduce 数，每一个 task(map|reduce)的 setup 和加入到调度器中进行调度，这个 中间的过程可能都要花费几秒钟，所以如果每个 task 都非常快就跑完了，就会在 task 的开<br>始和结束的时候浪费太多的时间。<br>配置 task 的 JVM 重用可以改善该问题：<br>mapred.job.reuse.jvm.num.tasks，默认是 1，表示一个 JVM 上最多可以顺序执行的 task 数目（属于同一个 Job）是 1。也就是说一个 task 启一个 JVM。这个值可以在 mapred-site.xml 中进行更改， 当设置成多个，就意味着这多个 task 运行在同一个 JVM 上，但不是同时执行，<br>是排队顺序执行<br>   （2）如果 input 的文件非常的大，比如 1TB，可以考虑将 hdfs 上的每个 blocksize 设大，比如 设成 256MB 或者 512MB<br>     6、reducetask并行度决定机制</p>
<p><img src="_v_images/20191210130405036_148457935.png"></p>
<p>文件切分算法，主要用于确定InputSplit的个数以及每个InputSplit对应的数据段。FileInputFormat以文件为单位切分生成InputSplit，对于每个文件，由以下三个属性值决定其对应的InputSplit的个数：</p>
<p>goalSize： 它是根据用户期望的InputSplit数目计算出来的，即totalSize/numSplits。其中，totalSize为文件的总大小；numSplits为用户设定的Map Task个数，默认情况下是1；<br>minSize：InputSplit的最小值，由配置参数mapred.min.split.size确定，默认是1；<br>blockSize：文件在hdfs中存储的block大小，不同文件可能不同，默认是64MB。<br>这三个参数共同决定InputSplit的最终大小，计算方法如下：</p>
<p>splitSize=max{minSize, min{gogalSize,blockSize}}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 用户设置了numSplit，那么goalSize&#x3D;totalSize&#x2F;numSplit</span><br><span class="line">2. minSize&#x3D;max(1,minSplitSize)</span><br><span class="line">3. splitSize&#x3D;max(minSplitSize, min(goalSize,blockSize))</span><br><span class="line">4. task个数&#x3D;totalSize除以splitSize</span><br></pre></td></tr></table></figure>
<p>FileInputFormat的host选择算法参考《Hadoop技术内幕-深入解析MapReduce架构设计与实现原理》的p50.</p>
<h2 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h2><p><a href="http://smartsi.club/hadoop-mapReduce2.x-working-principle.html">Hadoop MapReduce 2.x 工作原理</a><br><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/">Hadoop新MapReduce框架Yarn详解</a></p>
<h2 id="hadoop-优缺点"><a href="#hadoop-优缺点" class="headerlink" title="hadoop 优缺点"></a>hadoop 优缺点</h2><p>与许多伟大的系统一样，Hadoop开启了我们对一个新的空间的问题。具体来说，Hadoop在存储和提供对大量数据的访问方面表现优异，然而，它并没有提供关于数据访问速度的性能保证。此外，尽管Hadoop是高可用性系统，但在高并发负载下性能下降。最后，虽然Hadoop在存储数据方面表现良好，但它并未针对提取数据和使数据立即可读而进行优化。</p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop集群节点配置及搭建</title>
    <url>/bigdata/Hadoop/hadoop-cluser-configuration/</url>
    <content><![CDATA[<p>[&lt;&lt;] Hadoop专题</p>
<p>在<a href="hadoop-01">上一篇</a>中介绍了在Docker搭建三个节点的Hadoop集群，本文主要介绍hadoop集群节点的配置</p>
<p>NameNode<br>SecondNameNode<br>DataNode</p>
<p>JobTracker<br>JobTask</p>
<p>移动计算 而非 移动数据</p>
<h2 id="查看classpath"><a href="#查看classpath" class="headerlink" title="查看classpath"></a>查看classpath</h2><p>hadoop命令行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop classpath</span><br><span class="line">/opt/module/hadoop/etc/hadoop:/opt/module/hadoop/share/hadoop/common/lib/*:/opt/module/hadoop/share/hadoop/common/*:/opt/module/hadoop/share/hadoop/hdfs:/opt/module/hadoop/share/hadoop/hdfs/lib/*:/opt/module/hadoop/share/hadoop/hdfs/*:/opt/module/hadoop/share/hadoop/mapreduce/lib/*:/opt/module/hadoop/share/hadoop/mapreduce/*:/opt/module/hadoop/share/hadoop/yarn:/opt/module/hadoop/share/hadoop/yarn/lib/*:/opt/module/hadoop/share/hadoop/yarn/*</span><br></pre></td></tr></table></figure>
<p>配置文件</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop/etc/hadoop:/opt/module/hadoop/share/hadoop/common/lib/*:/opt/module/hadoop/share/hadoop/common/*:/opt/module/hadoop/share/hadoop/hdfs:/opt/module/hadoop/share/hadoop/hdfs/lib/*:/opt/module/hadoop/share/hadoop/hdfs/*:/opt/module/hadoop/share/hadoop/mapreduce/lib/*:/opt/module/hadoop/share/hadoop/mapreduce/*:/opt/module/hadoop/share/hadoop/yarn:/opt/module/hadoop/share/hadoop/yarn/lib/*:/opt/module/hadoop/share/hadoop/yarn/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<hr>
<p>[参考文献]</p>
<ol>
<li></li>
</ol>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Impala基础与痛点</title>
    <url>/bigdata/Impala/01.Impala/</url>
    <content><![CDATA[<h1 id="01-Impala"><a href="#01-Impala" class="headerlink" title="01.Impala"></a>01.Impala</h1><h2 id="components"><a href="#components" class="headerlink" title="components"></a>components</h2><p><a href="https://impala.apache.org/docs/build/html/topics/impala_components.html">impala components</a></p>
<h3 id="impalad的部署"><a href="#impalad的部署" class="headerlink" title="impalad的部署"></a>impalad的部署</h3><p>Impala daemons can be deployed in one of the following ways:</p>
<ul>
<li>HDFS and Impala are co-located, and each Impala daemon runs on the same host as a DataNode.</li>
<li>Impala is deployed separately in a compute cluster and reads remotely from HDFS, S3, ADLS, etc.</li>
</ul>
<h3 id="hive连接表需要刷新impalad"><a href="#hive连接表需要刷新impalad" class="headerlink" title="hive连接表需要刷新impalad"></a>hive连接表需要刷新impalad</h3><p>The catalog service avoids the need to issue REFRESH and INVALIDATE METADATA statements when the metadata changes are performed by statements issued through Impala. When you create a table, load data, and so on through Hive, you do need to issue REFRESH or INVALIDATE METADATA on an Impala daemon before executing a query there.</p>
<p>impala 自己执行修改元数据的请求时，不需要刷新和重载元数据，当通过hive创建表和加载数据时，在执行查询之前，需要在Impala守护进程上发出REFRESH或INVALIDATE元数据。</p>
<p>The REFRESH and INVALIDATE METADATA statements are not needed when the CREATE TABLE, INSERT, or other table-changing or data-changing operation is performed through Impala. These statements are still needed if such operations are done through Hive or by manipulating data files directly in HDFS, but in those cases the statements only need to be issued on one Impala daemon rather than on all daemons. </p>
<p>当通过Impala执行创建表、插入或其他表更改或数据更改操作时，不需要刷新和无效元数据语句。<br>如果通过Hive或直接在HDFS中操作数据文件，仍然需要，但是在这种情况下，只需要在一个Impala守护进程上发出这些语句，而不是在所有守护进程上。</p>
<h3 id="元数据加载与对查询的影响"><a href="#元数据加载与对查询的影响" class="headerlink" title="元数据加载与对查询的影响"></a>元数据加载与对查询的影响</h3><p><code>‑‑load_catalog_in_background</code> option to control when the metadata of a table is loaded.<br>If set to false, the metadata of a table is loaded when it is referenced for the first time. This means that the first run of a particular query can be slower than subsequent runs. Starting in Impala 2.2, the default for ‑‑load_catalog_in_background is false.</p>
<p>表的元数据在第一次引用时加载。这意味着特定查询的第一次运行可能比后续运行慢</p>
<p>If set to true, the catalog service attempts to load metadata for a table even if no query needed that metadata. So metadata will possibly be already loaded when the first query that would need it is run. However, for the following reasons, we recommend not to set the option to true.</p>
<p>catalogd尝试加载表的元数据，即使没有查询需要该元数据。因此，在运行第一个需要元数据的查询时，元数据可能已经被加载</p>
<p>Background load can interfere with query-specific metadata loading. This can happen on startup or after invalidating metadata, with a duration depending on the amount of metadata, and can lead to a seemingly random long running queries that are difficult to diagnose.</p>
<p>后台加载可能会干扰特定查询的元数据加载。这种情况可能在启动时发生，也可能在元数据失效后发生，持续时间取决于元数据的数量，并可能导致看似随机的长时间运行查询，而这些查询很难诊断。</p>
<p>Impala may load metadata for tables that are possibly never used, potentially increasing catalog size and consequently memory usage for both catalog service and Impala Daemon.</p>
<p>Impala可以为可能从未使用过的表加载元数据，这可能会增加目录大小，从而增加目录服务和Impala守护进程的内存使用量。</p>
<h3 id="元数据刷新耗时"><a href="#元数据刷新耗时" class="headerlink" title="元数据刷新耗时"></a>元数据刷新耗时</h3><p>For tables with a large volume of data and/or many partitions, retrieving all the metadata for a table can be time-consuming, taking minutes in some cases. Thus, each Impala node caches all of this metadata to reuse for future queries against the same table.<br>对于具有大量数据和/或许多分区的表，检索表的所有元数据可能很耗时，在某些情况下会花费几分钟。<br>因此，每个Impala节点都会缓存所有这些元数据，以供将来针对同一表的查询重用。</p>
<p>If the table definition or the data in the table is updated, all other Impala daemons in the cluster must receive the latest metadata, replacing the obsolete cached metadata, before issuing a query against that table</p>
<p>For DDL and DML issued through Hive, or changes made manually to files in HDFS, you still use the REFRESH statement (when new data files are added to existing tables) or the INVALIDATE METADATA statement (for entirely new tables, or after dropping a table, performing an HDFS rebalance operation, or deleting data files). Issuing INVALIDATE METADATA by itself retrieves metadata for all the tables tracked by the metastore. If you know that only specific tables have been changed outside of Impala, you can issue REFRESH table_name for each affected table to only retrieve the latest metadata for those tables.</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Impala</tag>
      </tags>
  </entry>
  <entry>
    <title>Impala: why faster than hive</title>
    <url>/bigdata/Impala/Impala-why-faster-than-hive/</url>
    <content><![CDATA[<p>[TOC]</p>
<h1 id="Impala"><a href="#Impala" class="headerlink" title="Impala"></a>Impala</h1><blockquote>
<p><a href="https://stackoverflow.com/questions/16755599/how-does-impala-provide-faster-query-response-compared-to-hive">How does impala provide faster query response compared to hive</a></p>
</blockquote>
<p>Impala = SQL on HDFS<br>Hive = SQL on Hadoop</p>
<p>impala darmon running on datanode<br>cache some of the data that is in HDFS</p>
<h2 id="why-fast"><a href="#why-fast" class="headerlink" title="why fast"></a>why fast</h2><blockquote>
<p>why Impala is faster than Hive in Query processing? Below are the some key points.</p>
</blockquote>
<ul>
<li>While processing SQL-like queries, Impala does not write intermediate results on disk(like in Hive MapReduce); instead full SQL processing is done in memory, which makes it faster.</li>
<li>With Impala, the query starts its execution instantly compared to MapReduce, which may take significant time to start processing larger SQL queries and this adds more time in processing.</li>
<li>Impala Query Planner uses smart algorithms to execute queries in multiple stages in parallel nodes to provide results faster, avoiding sorting and shuffle steps, which may be unnecessary in most of the cases.</li>
<li>Impala has information about each data block in HDFS, so when processing the query, it takes advantage of this knowledge to distribute queries more evenly in all DataNodes.</li>
<li>There exists Impala daemon, which runs on each DataNode. These are responsible for processing queries.When query submitted, impalad(Impala daemon) reads and writes to data file and parallelizes the query by distributing the work to all other Impala nodes in the Impala cluster.</li>
<li>Another key reason for fast performance is that Impala first generates assembly-level code for each query. The assembly code executes faster than any other code framework because while Impala queries are running natively in memory, having a framework will add additional delay in the execution due to the framework overhead.</li>
</ul>
<ol>
<li>在处理类似sql的查询时，Impala不会在磁盘上写入中间结果(如Hive MapReduce);相反，SQL处理完全是在内存中完成的，这使它更快。</li>
<li>不使用map/reduce, 将数据fork到jvm和流量穿透是非常昂贵的。Impala将查询任务分割成子任务，在数据所在的节点上，各个节点独立并行运行，最后再单个节点上汇总结果。</li>
<li>与MapReduce相比，Impala查询立即开始执行，MapReduce可能会花费大量时间来开始处理较大的SQL查询，这会增加处理时间。</li>
<li>Impala Query Planner使用智能算法在并行节点中的多个stage执行查询，以更快地提供结果，避免sortinh和shuffle步骤，这在大多数情况下可能是不必要的。</li>
<li>Impala拥有关于HDFS每个数据块的信息，因此在处理查询时，它利用这些知识在所有数据节点中更均匀地分布查询。</li>
<li>存在在每个DataNode上运行的Impala守护进程。它们负责处理查询。当提交查询时，impalad(Impala守护进程)对数据文件进行读写操作，并通过将工作分配给Impala集群中的所有其他Impala节点来并行化查询。</li>
<li>快速性能的另一个关键原因是Impala首先为每个查询生成汇编级别的代码。汇编代码的执行速度比任何其他代码框架都快，因为Impala查询在本机的内存中运行时，拥有一个框架会由于框架开销而增加额外的执行延迟。</li>
<li>它使用hdfs存储，对于大文件来说速度很快。它尽可能多地缓存查询、结果和数据。</li>
<li>它支持新的文件格式，如parquet，即列式存储格式。使用这种格式，数据扫描量更少</li>
</ol>
<p>Impala在内存中的处理所有查询，因此节点上的内存限制肯定是一个因素。必须有足够的内存来支持生成的数据集，在复杂的连接操作期间，数据集可能会成倍增长。如果查询开始处理数据，结果数据集无法装入可用内存，则查询将失败。</p>
<h3 id="disadvantage"><a href="#disadvantage" class="headerlink" title="disadvantage"></a>disadvantage</h3><ol>
<li>不支持UDF和自定义序列化</li>
<li>impala查询是HiveSQL的子集</li>
<li>hive支持存储和查询，而impala只能查询</li>
</ol>
<h2 id="Impala-doesn’t-provide-fault-tolerance-compared-to-Hive"><a href="#Impala-doesn’t-provide-fault-tolerance-compared-to-Hive" class="headerlink" title="Impala doesn’t provide fault-tolerance compared to Hive"></a>Impala doesn’t provide fault-tolerance compared to Hive</h2><p>so if there is a problem during your query then it’s gone. </p>
<blockquote>
<p>Definitely for ETL type of jobs where failure of one job would be costly I would recommend Hive, but Impala can be awesome for small ad-hoc queries, for example for data scientists or business analysts who just want to take a look and analyze some data without building robust jobs. Also from my personal experience, Impala is still not very mature, and I’ve seen some crashes sometimes when the amount of data is larger than available memory.</p>
</blockquote>
<p>对于ETL类型的工作，如果一个工作的失败代价很高，我会推荐Hive，但是Impala对于小的特别查询来说可能是很棒的，例如对于那些只想查看和分析一些数据而不想构建健壮工作的数据科学家或业务分析师来说。从我个人的经验来看，Impala还不太成熟，有时当数据量超过可用内存时，我会看到一些崩溃。</p>
<blockquote>
<p>This means if your join, sort, or group by didn’t fit in memory, Impala would just kill the query. No warning. Just dead. Hive would never do that because it’s underlying processing architecture has no problem doing that.</p>
</blockquote>
<p>这就意味着，内存不能承载join sort或group运算，Impala会无告警的立即kill掉查询，直接失败。而hive离线处理架构可以轻松处理，不会死掉</p>
<h2 id="MPP"><a href="#MPP" class="headerlink" title="MPP"></a>MPP</h2><blockquote>
<p>Impala uses MPP(massively parallel processing) unlike Hive which uses MapReduce under the hood, which involves some initial overheads (as Charles sir has specified). Massively parallel processing is a type of computing that uses many separate CPUs running in parallel to execute a single program where each CPU has it’s own dedicated memory. The very fact that Impala, being MPP based, doesn’t involve the overheads of a MapReduce jobs viz. job setup and creation, slot assignment, split creation, map generation etc., makes it blazingly fast.</p>
</blockquote>
<p>Impala提供了更快的响应，因为它使用了MPP(大规模并行处理)，而Hive在底层使用了MapReduce，这涉及到一些初始开销(正如Charles sir所指定的)。大规模并行处理是一种计算类型，它使用许多单独的并行运行的CPU来执行单个程序，其中每个CPU都有自己的专用内存。Impala是基于MPP的，它不涉及MapReduce作业的开销，即作业设置和创建、插槽分配、分割创建、地图生成等，这使得它的运行速度非常快。</p>
<blockquote>
<p>But that doesn’t mean that Impala is the solution to all your problems. Being highly memory intensive (MPP), it is not a good fit for tasks that require heavy data operations like joins etc., as you just can’t fit everything into the memory. This is where Hive is a better fit.</p>
</blockquote>
<p>MPP 作为高度内存密集型的运算，因为无法将所有的数据放入内存，并不适合需要大数据量的操作(如join)；反而Hive更适合</p>
<p>实时的对部分数据即时查询适合Impala，对大数据的批处理请求，适合Hive</p>
<h2 id="Impala-not-always-faster-than-hive"><a href="#Impala-not-always-faster-than-hive" class="headerlink" title="Impala not always faster than hive"></a>Impala not always faster than hive</h2><blockquote>
<p>In my current job we used to make all the querys with Impala, the biggest query (like 800 million rows after 8 joins) was taking from 2 to 20 mins (depending if the tables where already on memory or not) I migrate that Query to Hive, partitioned the tables and create buckets on them, now it takes 3–4 mins, It may be a few more seconds than the best 2 mins with Impala but it’s much more fast if we consider that most of the time Impala takes 12–18 mins.</p>
</blockquote>
<p>在我目前的工作中，使用Impala进行所有的查询，最大的查询(比如8个连接后的8亿行)需要2到20分钟(取决于表是否已经在内存中);我将该查询迁移到Hive，对表进行分区并在其上创建桶，现在需要3到4分钟，这可能比Impala最好的2分钟多几秒钟，但如果我们考虑Impala大部分时间需要12到18分钟，速度会快得多。 </p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Impala</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka</title>
    <url>/bigdata/Kafka/kafka-base/</url>
    <content><![CDATA[<h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h1><h2 id="ACK机制"><a href="#ACK机制" class="headerlink" title="ACK机制"></a>ACK机制</h2><p>Kafka producer有三种ack机制  初始化producer时在config中进行配置</p>
<table>
<thead>
<tr>
<th>ACK</th>
<th>同步</th>
<th>延迟</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>producer不等待broker同步完成就发送下一条(批)信息</td>
<td>低的延迟最弱的持久性，当服务器发生故障时，就很可能发生数据丢失。例如leader已经死亡，producer不知情，还会继续发送消息broker接收不到数据就会数据丢失</td>
</tr>
<tr>
<td>1</td>
<td>producer要等待leader成功收到数据并得到确认，才发送下一条message</td>
<td>较好的持久性较低的延迟性：Partition的Leader死亡，follwer尚未复制，数据就会丢失</td>
</tr>
<tr>
<td>-1</td>
<td>producer得到follwer确认，才发送下一条数据</td>
<td>持久性最好，延时性最差</td>
</tr>
</tbody></table>
<p>三种机制性能递减，可靠性递增。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Kylin权威指南</title>
    <url>/bigdata/Kylin/01.kylin/</url>
    <content><![CDATA[<p>apache Kylin 权威指南</p>
<p>各式各样的”SQL on Hadoop”技术应运而生，其中以Hive为代表，Impala、Presto、Phoenix、Drill、SparkSQL等紧随其后。它们的主要技术是”大规模并行处理”（Massive Parallel Processing，MPP）和”列式存储”（Columnar Storage）。大规模并行处理可以调动多台机器一起进行并行计算，用线性增加的资源来换取计算时间的线性下降。列式存储则将记录按列存放，这样做不仅可以在访问时只读取需要的列，还可以利用存储设备擅长连续读取的特点，大大提高读取的速率。这两项关键技术使得Hadoop上的SQL查询速度从小时提高到了分钟。</p>
<p>对于分析师来说，完备的、经过验证的数据模型比分析性能更加重要，直接访问纷繁复杂的原始数据并进行相关分析其实并不是很友好的体验，特别是在超大规模的数据集上，分析师将更多的精力花在了等待查询结果上，而不是在更加重要的建立领域模型上。</p>
<p>“预计算”就是Kylin在”大规模并行处理”和”列式存储”之外，提供给大数据分析的第三个关键技术。</p>
<p>Apache Kylin的工作原理本质上是MOLAP（Multidimensional Online Analytical Processing）Cube，也就是多维立方体分析。这是数据分析中相当经典的理论</p>
<p>Cube理论</p>
<p>星形模型（Star Schema）</p>
<p>MDX（MultiDimensional eXpressions）作为接口。虽然MDX作为OLAP查询语言</p>
<p>·大规模并行处理：可以通过增加机器的方式来扩容处理速度，在相同的时间里处理更多的数据。 ·列式存储：通过按列存储提高单位时间里数据的I/O吞吐率，还能跳过不需要访问的列。 ·索引：利用索引配合查询条件，可以迅速跳过不符合条件的数据块，仅扫描需要扫描的数据内容。 ·压缩：压缩数据然后存储，使得存储的密度更高，在有限的I/O速率下，在单位时间里读取更多的记录。</p>
<p>所有这些方法都只是提高了单位时间内处理数据的能力，当大家都一致采用这些技术时，它们之间的区别将只停留在实现层面的代码细节上。最重要的是，这些技术都不会改变一个事实，那就是处理时间与数据量之间的正比例关系。当数据量翻倍时，MPP（在不扩容的前提下）需要翻倍的时间来完成计算；列式存储需要翻倍的存储空间；索引下符合条件的记录数也会翻倍；压缩后的数据大小也还是之前的两倍。因此查询速度也会随之变成之前的两倍。当数据量成十倍百倍地增长时，这些技术的查询速度就会成十倍百倍地下降，最终变得不能接受。</p>
<p>Kylin对基数的计算方法采用的是HyperLogLog的近似算法</p>
<p>衍生维度 ??</p>
<h2 id="增量构建"><a href="#增量构建" class="headerlink" title="增量构建"></a>增量构建</h2><p>ETL</p>
<p>-</p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>Kylin</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark SQL</title>
    <url>/bigdata/Spark/Spark-SQL/</url>
    <content><![CDATA[<h1 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark-SQL"></a>Spark-SQL</h1><h2 id="join"><a href="#join" class="headerlink" title="join"></a>join</h2><p>Spark 中支持多种连接类型：</p>
<ul>
<li>Inner Join : 内连接；</li>
<li>Full Outer Join : 全外连接；</li>
<li>Left Outer Join : 左外连接；</li>
<li>Right Outer Join : 右外连接；</li>
<li>Left Semi Join : 左半连接；</li>
<li>Left Anti Join : 左反连接；</li>
<li>Natural Join : 自然连接；</li>
<li>Cross (or Cartesian) Join : 交叉 (或笛卡尔) 连接</li>
</ul>
<p><img src="vx_images/289801248595.png" alt="SQL JOINS"></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">emp 员工表</span><br><span class="line"> <span class="operator">|</span><span class="comment">-- ENAME: 员工姓名</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- DEPTNO: 部门编号</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- EMPNO: 员工编号</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- HIREDATE: 入职时间</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- JOB: 职务</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- MGR: 上级编号</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- SAL: 薪资</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- COMM: 奖金  </span></span><br><span class="line"></span><br><span class="line">dept 部门表</span><br><span class="line"> <span class="operator">|</span><span class="comment">-- DEPTNO: 部门编号</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- DNAME:  部门名称</span></span><br><span class="line"> <span class="operator">|</span><span class="comment">-- LOC:    部门所在城市</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- LEFT SEMI JOIN</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">LEFT</span> SEMI <span class="keyword">JOIN</span> dept <span class="keyword">ON</span> emp.deptno <span class="operator">=</span> dept.deptno</span><br><span class="line"><span class="comment">-- 等价于如下的 IN 语句</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">WHERE</span> deptno <span class="keyword">IN</span> (<span class="keyword">SELECT</span> deptno <span class="keyword">FROM</span> dept)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- LEFT ANTI JOIN</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">LEFT</span> ANTI <span class="keyword">JOIN</span> dept <span class="keyword">ON</span> emp.deptno <span class="operator">=</span> dept.deptno</span><br><span class="line"><span class="comment">-- 等价于如下的 IN 语句</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">WHERE</span> deptno <span class="keyword">NOT</span> <span class="keyword">IN</span> (<span class="keyword">SELECT</span> deptno <span class="keyword">FROM</span> dept)</span><br><span class="line"></span><br><span class="line"><span class="comment">--CROSS JOIN</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">CROSS</span> <span class="keyword">JOIN</span> dept <span class="keyword">ON</span> emp.deptno <span class="operator">=</span> dept.deptno</span><br><span class="line"></span><br><span class="line"><span class="comment">--自然连接是在两张表中寻找那些数据类型和列名都相同的字段，然后自动地将他们连接起来，并返回所有符合条件的结果。</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">NATURAL</span> <span class="keyword">JOIN</span> dept</span><br><span class="line"></span><br><span class="line"><span class="comment">--程序自动推断出使用两张表都存在的 dept 列进行连接</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp <span class="keyword">JOIN</span> dept <span class="keyword">ON</span> emp.deptno <span class="operator">=</span> dept.deptno</span><br></pre></td></tr></table></figure>
<h3 id="内部实现"><a href="#内部实现" class="headerlink" title="内部实现"></a>内部实现</h3><p>broadcast join –&gt; hash join  –&gt; sort-merge join</p>
<p>在对大表与大表之间进行连接操作时，通常都会触发 <code>Shuffle Join</code>，两表的所有分区节点会进行 <code>All-to-All</code> 的通讯，这种查询通常比较昂贵，会对网络 IO 会造成比较大的负担。</p>
<p><img src="vx_images/4246497595210.png" alt="https://github.com/heibaiying"></p>
<p>而对于大表和小表的连接操作，Spark 会在一定程度上进行优化，如果小表的数据量小于 Worker Node 的内存空间，Spark 会考虑将小表的数据广播到每一个 Worker Node，在每个工作节点内部执行连接计算，这可以降低网络的 IO，但会加大每个 Worker Node 的 CPU 负担。</p>
<p><img src="vx_images/4195188806118"></p>
<p>是否采用广播方式进行 <code>Join</code> 取决于程序内部对小表的判断，如果想明确使用广播方式进行 <code>Join</code>，则可以在 DataFrame API 中使用 <code>broadcast</code> 方法指定需要广播的小表：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">empDF.join(broadcast(deptDF), joinExpression).show()</span><br></pre></td></tr></table></figure>

<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><table>
<thead>
<tr>
<th align="left"><strong>优化规则</strong></th>
<th align="left"><strong>规则名称</strong></th>
<th align="left"><strong>简介</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">列裁剪</td>
<td align="left">column_prune</td>
<td align="left">对于上层算子不需要的列，不在下层算子输出该列，减少计算</td>
</tr>
<tr>
<td align="left">子查询去关联</td>
<td align="left">decorrelate</td>
<td align="left">尝试对相关子查询进行改写，将其转换为普通 join 或 aggregation 计算</td>
</tr>
<tr>
<td align="left">聚合消除</td>
<td align="left">aggregation_eliminate</td>
<td align="left">尝试消除执行计划中的某些不必要的聚合算子</td>
</tr>
<tr>
<td align="left">投影消除</td>
<td align="left">projection_eliminate</td>
<td align="left">消除执行计划中不必要的投影算子</td>
</tr>
<tr>
<td align="left">最大最小消除</td>
<td align="left">max_min_eliminate</td>
<td align="left">改写聚合中的 max/min 计算，转化为 <code>order by</code> + <code>limit 1</code></td>
</tr>
<tr>
<td align="left">谓词下推</td>
<td align="left">predicate_push_down</td>
<td align="left">尝试将执行计划中过滤条件下推到离数据源更近的算子上</td>
</tr>
<tr>
<td align="left">外连接消除</td>
<td align="left">outer_join_eliminate</td>
<td align="left">尝试消除执行计划中不必要的 left join 或者 right join</td>
</tr>
<tr>
<td align="left">分区裁剪</td>
<td align="left">partition_processor</td>
<td align="left">将分区表查询改成为用 union all，并裁剪掉不满足过滤条件的分区</td>
</tr>
<tr>
<td align="left">聚合下推</td>
<td align="left">aggregation_push_down</td>
<td align="left">尝试将执行计划中的聚合算子下推到更底层的计算节点</td>
</tr>
<tr>
<td align="left">TopN 下推</td>
<td align="left">topn_push_down</td>
<td align="left">尝试将执行计划中的 TopN 算子下推到离数据源更近的算子上</td>
</tr>
<tr>
<td align="left">Join 重排序</td>
<td align="left">join_reorder</td>
<td align="left">对多表 join 确定连接顺序</td>
</tr>
</tbody></table>
<h2 id="逻辑优化"><a href="#逻辑优化" class="headerlink" title="逻辑优化"></a>逻辑优化</h2><h3 id="子查询相关的优化"><a href="#子查询相关的优化" class="headerlink" title="子查询相关的优化"></a>子查询相关的优化</h3><p>关联子查询去关联</p>
<h3 id="列裁剪"><a href="#列裁剪" class="headerlink" title="列裁剪"></a>列裁剪</h3><h3 id="关联子查询去关联"><a href="#关联子查询去关联" class="headerlink" title="关联子查询去关联"></a>关联子查询去关联</h3><h3 id="Max-Min-消除"><a href="#Max-Min-消除" class="headerlink" title="Max/Min 消除"></a>Max/Min 消除</h3><h3 id="谓词下推"><a href="#谓词下推" class="headerlink" title="谓词下推"></a>谓词下推</h3><h3 id="分区裁剪"><a href="#分区裁剪" class="headerlink" title="分区裁剪"></a>分区裁剪</h3><h3 id="TopN-和-Limit-下推"><a href="#TopN-和-Limit-下推" class="headerlink" title="TopN 和 Limit 下推"></a>TopN 和 Limit 下推</h3><h3 id="Join-Reorder"><a href="#Join-Reorder" class="headerlink" title="Join Reorder"></a>Join Reorder</h3><h2 id="物理优化"><a href="#物理优化" class="headerlink" title="物理优化"></a>物理优化</h2><h3 id="选择最优的索引进行表的访问"><a href="#选择最优的索引进行表的访问" class="headerlink" title="选择最优的索引进行表的访问"></a>选择最优的索引进行表的访问</h3><h3 id="收集统计信息来获得表的数据分布情况"><a href="#收集统计信息来获得表的数据分布情况" class="headerlink" title="收集统计信息来获得表的数据分布情况"></a>收集统计信息来获得表的数据分布情况</h3><h3 id="在错误索引的解决方案中会介绍当发现-TiDB-索引选错时，你应该使用那些手段来让它使用正确的索引"><a href="#在错误索引的解决方案中会介绍当发现-TiDB-索引选错时，你应该使用那些手段来让它使用正确的索引" class="headerlink" title="在错误索引的解决方案中会介绍当发现 TiDB 索引选错时，你应该使用那些手段来让它使用正确的索引"></a>在错误索引的解决方案中会介绍当发现 TiDB 索引选错时，你应该使用那些手段来让它使用正确的索引</h3><h3 id="在-Distinct-优化中会介绍在物理优化中会做的一个有关-DISTINCT-关键字的优化，在这一小节中会介绍它的优缺点以及如何使用它。"><a href="#在-Distinct-优化中会介绍在物理优化中会做的一个有关-DISTINCT-关键字的优化，在这一小节中会介绍它的优缺点以及如何使用它。" class="headerlink" title="在 Distinct 优化中会介绍在物理优化中会做的一个有关 DISTINCT 关键字的优化，在这一小节中会介绍它的优缺点以及如何使用它。"></a>在 Distinct 优化中会介绍在物理优化中会做的一个有关 DISTINCT 关键字的优化，在这一小节中会介绍它的优缺点以及如何使用它。</h3><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a href="https://www.infoq.cn/article/an-article-mastering-sql-on-hadoop-core-technology">The Business Intelligence for Hadoop Benchmark</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark data skew</title>
    <url>/bigdata/Spark/Spark-data-skew/</url>
    <content><![CDATA[<h1 id="Spark-data-skew"><a href="#Spark-data-skew" class="headerlink" title="Spark-data-skew"></a>Spark-data-skew</h1><h2 id="触发shuffle的算子"><a href="#触发shuffle的算子" class="headerlink" title="触发shuffle的算子"></a>触发shuffle的算子</h2><p>数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等</p>
<p>[Spark性能优化指南——高级篇](<a href="https://tech.meituan.com/2016/05/12/spark-tuning-pro.html">https://tech.meituan.com/2016/05/12/spark-tuning-pro.html</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark join</title>
    <url>/bigdata/Spark/Spark-join/</url>
    <content><![CDATA[<h1 id="Spark-Join"><a href="#Spark-Join" class="headerlink" title="Spark-Join"></a>Spark-Join</h1><table>
<thead>
<tr>
<th>参数</th>
<th>默认值</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>spark.sql.shuffle.partitions</td>
<td>200</td>
<td>Configures the number of partitions to use when shuffling data for joins or aggregations.</td>
</tr>
<tr>
<td>spark.default.parallelism</td>
<td>For distributed shuffle operations like reduceByKey and join, the largest number of partitions in a parent RDD. For operations like parallelize with no parent RDDs, it depends on the cluster manager:Local mode: number of cores on the local machineMesos fine grained mode: 8 Others: total number of cores on all executor nodes or 2, whichever is larger</td>
<td>Default number of partitions in RDDs returned by transformations like join, reduceByKey, and parallelize when not set by user.</td>
</tr>
</tbody></table>
<p>上面两个参数都是设置默认的并行度，但是适用的场景不同：</p>
<p>spark.sql.shuffle.partitions是对sparkSQL进行shuffle操作的时候生效，比如 join或者aggregation等操作的时候，之前有个同学设置了spark.default.parallelism 这个并行度为2000，结果还是产生200的stage，排查了很久才发现，是这个原因。<br>spark.default.parallelism这个参数只是针对rdd的shuffle操作才生效，比如join，reduceByKey。</p>
<p>作者：pcqlegend<br>链接：<a href="https://www.jianshu.com/p/c5914126ef98">https://www.jianshu.com/p/c5914126ef98</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h2 id="shuffle-join-VS-map-join"><a href="#shuffle-join-VS-map-join" class="headerlink" title="shuffle join VS map join"></a>shuffle join VS map join</h2><p>在对大表与大表之间进行连接操作时，通常都会触发 <code>Shuffle Join</code>，两表的所有分区节点会进行 <code>All-to-All</code> 的通讯，这种查询通常比较昂贵，会对网络 IO 会造成比较大的负担。</p>
<p><img src="_v_images/20201009194634406_1569670303.png"></p>
<p>而对于大表和小表的连接操作，Spark 会在一定程度上进行优化，如果小表的数据量小于 Worker Node 的内存空间，Spark 会考虑将小表的数据广播到每一个 Worker Node，在每个工作节点内部执行连接计算，这可以降低网络的 IO，但会加大每个 Worker Node 的 CPU 负担。</p>
<p><img src="_v_images/20201009194633499_170639920"></p>
<p>是否采用广播方式进行 <code>Join</code> 取决于程序内部对小表的判断，如果想明确使用广播方式进行 <code>Join</code>，则可以在 DataFrame API 中使用 <code>broadcast</code> 方法指定需要广播的小表：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">empDF.join(broadcast(deptDF), joinExpression).show()</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>

<p>作者：heibaiying<br>链接：<a href="https://juejin.im/post/6844903950349500430">https://juejin.im/post/6844903950349500430</a><br>来源：掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h2 id="map-join小表误判"><a href="#map-join小表误判" class="headerlink" title="map-join小表误判"></a>map-join小表误判</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> a是一个几亿行的大表，b是一个只有几十行的小表。a和b都是由hive创建的表</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">where</span> id <span class="keyword">not</span> <span class="keyword">in</span> (<span class="keyword">select</span> id <span class="keyword">from</span> b)</span><br></pre></td></tr></table></figure>
<p>在spark ui中看到了该sql的执行计划，该sql语句执行了Map-side Join操作，但是spark把a表当成了小表，准备把a表broadcast到其他的节点，然后就是一直卡在这步broadcast操作上。 造成上述问题的原因就是spark认为a表是一个小表，但是在spark ui上明显可以看到a表读了很多的行。但是为什么spark还会认为a表是一个小表呢？原因是spark判断一个hive表的大小会用hive的metastore数据来判断，因为我们的a表没有执行过ANALYZE TABLE，自然a表的metastore里面的数据就不准确了。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><ol>
<li><p>设置<code>spark.sql.statistics.fallBackToHdfs=True</code><br>该参数能让spark直接读取hdfs的文件大小来判断一个表达大小，从而代替从metastore里面的获取的关于表的信息。这样spark自然能正确的判断出表的大小，从而使用b表来进行broadcast。</p>
</li>
<li><p>使用hint<br>在使用sql语句执行的时候在sql语句里面加上mapjoin的注释，也能够达到相应的效果，比如把上述的sql语句改成:</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+ BROADCAST (b) */</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">where</span> id <span class="keyword">not</span> <span class="keyword">in</span> (<span class="keyword">select</span> id <span class="keyword">from</span> b)</span><br></pre></td></tr></table></figure>
<p>这样spark也会使用b表来进行broadcast。</p>
<ol start="3">
<li>使用spark代码的方式<br>使用broadcast函数就能达到此效果：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions import broadcast</span><br><span class="line">broadcast(spark.table(&quot;b&quot;)).<span class="keyword">join</span>(spark.table(&quot;a&quot;), &quot;id&quot;).<span class="keyword">show</span>()</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>备注</li>
</ol>
<ul>
<li><p>只有当要进行join的表的大小小于spark.sql.autoBroadcastJoinThreshold（默认是10M）的时候，才会进行mapjoin。</p>
</li>
<li><p>Impala通过hint和执行表的位置调整也能够优化join操作，通过explain也可以查看sql的执行计划，然后再进行优化。</p>
</li>
</ul>
<p>Join背景  </p>
<p>当前SparkSQL支持三种join算法：Shuffle Hash Join、Broadcast Hash Join以及Sort Merge Join。其中前两者归根到底都属于Hash Join，只不过载Hash Join之前需要先Shuffle还是先Broadcast。其实，Hash Join算法来自于传统数据库，而Shuffle和Broadcast是大数据在分布式情况下的概念，两者结合的产物。因此可以说，大数据的根就是传统数据库。Hash Join是内核。</p>
<h4 id="Spark-Join的分类和实现机制"><a href="#Spark-Join的分类和实现机制" class="headerlink" title="Spark Join的分类和实现机制"></a>Spark Join的分类和实现机制</h4><p><img src="vx_images/4410808926830" alt="图片"></p>
<p>上图是Spark Join的分类和使用。</p>
<h5 id="Hash-Join"><a href="#Hash-Join" class="headerlink" title="Hash Join"></a>Hash Join</h5><p>先来看看这样一条SQL语句：select * from order,item where item.id = order.i_id，参与join的两张表是order和item，join key分别是item.id以及order.i_id。现在假设Join采用的是hash join算法，整个过程会经历三步：</p>
<ul>
<li><p>  确定Build Table以及Probe Table：这个概念比较重要，Build Table会被构建成以join key为key的hash table，而Probe Table使用join key在这张hash table表中寻找符合条件的行，然后进行join链接。Build表和Probe表是Spark决定的。通常情况下，小表会被作为Build Table，较大的表会被作为Probe Table。</p>
</li>
<li><p>  构建Hash Table：依次读取Build Table(item)的数据，对于每一条数据根据Join Key(item.id)进行hash，hash到对应的bucket中(类似于HashMap的原理)，最后会生成一张HashTable，HashTable会缓存在内存中，如果内存放不下会dump到磁盘中。</p>
</li>
<li><p>  匹配：生成Hash Table后，在依次扫描Probe Table(order)的数据，使用相同的hash函数(在spark中，实际上就是要使用相同的partitioner)在Hash Table中寻找hash(join key)相同的值，如果匹配成功就将两者join在一起。</p>
</li>
</ul>
<h5 id="Broadcast-Hash-Join"><a href="#Broadcast-Hash-Join" class="headerlink" title="Broadcast Hash Join"></a>Broadcast Hash Join</h5><p>当Join的一张表很小的时候，使用broadcast hash join。</p>
<p>Broadcast Hash Join的条件有以下几个：</p>
<ul>
<li><p>  被广播的表需要小于spark.sql.autoBroadcastJoinThreshold所配置的信息，默认是10M；</p>
</li>
<li><p>  基表不能被广播，比如left outer join时，只能广播右表。</p>
</li>
</ul>
<p><img src="vx_images/4390860112486" alt="图片"></p>
<p>broadcast hash join可以分为两步：</p>
<ul>
<li><p>  broadcast阶段：将小表广播到所有的executor上，广播的算法有很多，最简单的是先发给driver，driver再统一分发给所有的executor，要不就是基于bittorrete的p2p思路；</p>
</li>
<li><p>  hash join阶段：在每个executor上执行 hash join，小表构建为hash table，大表的分区数据匹配hash table中的数据。</p>
</li>
</ul>
<h5 id="Sort-Merge-Join"><a href="#Sort-Merge-Join" class="headerlink" title="Sort Merge Join"></a>Sort Merge Join</h5><p><img src="vx_images/4199861566008" alt="图片"></p>
<p>当两个表都非常大时，SparkSQL采用了一种全新的方案来对表进行Join，即Sort Merge Join。这种方式不用将一侧数据全部加载后再进行hash join，但需要在join前将数据进行排序。</p>
<p>首先将两张表按照join key进行重新shuffle，保证join key值相同的记录会被分在相应的分区，分区后对每个分区内的数据进行排序，排序后再对相应的分区内的记录进行连接。可以看出，无论分区有多大，Sort Merge Join都不用把一侧的数据全部加载到内存中，而是即用即丢；因为两个序列都有有序的，从头遍历，碰到key相同的就输出，如果不同，左边小就继续取左边，反之取右边。从而大大提高了大数据量下sql join的稳定性。</p>
<p>整个过程分为三个步骤：</p>
<ul>
<li><p>  shuffle阶段：将两张大表根据join key进行重新分区，两张表数据会分布到整个集群，以便分布式并行处理</p>
</li>
<li><p>  sort阶段：对单个分区节点的两表数据，分别进行排序</p>
</li>
<li><p>  merge阶段：对排好序的两张分区表数据执行join操作。join操作很简单，分别遍历两个有序序列，碰到相同join key就merge输出，否则继续取更小一边的key。</p>
</li>
</ul>
<p><img src="vx_images/4141432879366" alt="图片"></p>
<p>经过上文的分析，很明显可以得出这几种join的代价关系：cost(Broadcast Hash Join)&lt; cost(Shuffle Hash Join) &lt; cost(Sort Merge Join)，数据仓库设计时最好避免大表与大表的join查询，SparkSQL也可以根据内存资源、带宽资源适量将参数spark.sql. autoBroadcastJoinThreshold调大，让更多join实际执行为Broadcast Hash Join。</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark streaming runtime</title>
    <url>/bigdata/Spark/Spark-streaming-runtime/</url>
    <content><![CDATA[<h1 id="Spark-streaming-runtime"><a href="#Spark-streaming-runtime" class="headerlink" title="Spark-streaming-runtime"></a>Spark-streaming-runtime</h1><p><img src="_v_images/20210113163649916_346932316.jpg"></p>
<p> <a href="https://zhuanlan.zhihu.com/p/159041276">https://zhuanlan.zhihu.com/p/159041276</a></p>
<p><strong>spark vs storm</strong></p>
<p><img src="_v_images/20210113163812387_1035142961.png"></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark task split block</title>
    <url>/bigdata/Spark/Spark-task_split_block/</url>
    <content><![CDATA[<h1 id="Spark-task-split-block"><a href="#Spark-task-split-block" class="headerlink" title="Spark-task_split_block"></a>Spark-task_split_block</h1><p>梳理一下Spark中关于并发度涉及的几个概念File，Block，Split，Task，Partition，RDD以及节点数、Executor数、core数目的关系。</p>
<p><img src="_v_images/20201015163856847_762442646.jpg"></p>
<ol>
<li>用户设置了numSplit，那么goalSize=totalSize/numSplit</li>
<li>minSize=max(1,minSplitSize)</li>
<li>splitSize=max(minSplitSize, min(goalSize,blockSize))</li>
<li>task个数=totalSize除以splitSize</li>
</ol>
<p>输入可能以多个文件的形式存储在HDFS上，每个File都包含了很多块，称为<strong>Block</strong>。<br>当Spark读取这些文件作为输入时，会根据具体数据格式对应的InputFormat进行解析，一般是将若干个Block合并成一个输入分片，称为<strong>InputSplit</strong>，注意InputSplit不能跨越文件。<br>随后将为这些输入分片生成具体的<strong>Task</strong>。InputSplit与Task是<strong>一一对应</strong>的关系。<br>随后这些具体的Task每个都会被分配到集群上的某个节点的某个<strong>Executor</strong>去执行。</p>
<ul>
<li>每个节点可以起一个或多个Executor。</li>
<li>每个Executor由若干<strong>core</strong>组成，每个Executor的每个core<strong>一次只能执行一个</strong>Task。</li>
<li>每个Task执行的结果就是生成了目标<strong>RDD</strong>的一个<strong>partiton</strong>。</li>
</ul>
<p><strong>注意:</strong> 这里的core是虚拟的core而不是机器的物理CPU核，可以理解为就是Executor的一个工作线程。</p>
<p>而 Task被执行的并发度 = Executor数目 * 每个Executor核数。</p>
<p>至于partition的数目：</p>
<ul>
<li>对于数据读入阶段，例如sc.textFile，输入文件被划分为多少InputSplit就会需要多少初始Task。</li>
<li>在Map阶段partition数目保持不变。</li>
<li>在Reduce阶段，RDD的聚合会触发shuffle操作，聚合后的RDD的partition数目跟具体操作有关，例如repartition操作会聚合成指定分区数，还有一些算子是可配置的。</li>
</ul>
<h3 id="1，Application"><a href="#1，Application" class="headerlink" title="1，Application"></a>1，Application</h3><p>application（应用）其实就是用spark-submit提交的程序。比方说spark examples中的计算pi的SparkPi。一个application通常包含三部分：从数据源（比方说HDFS）取数据形成RDD，通过RDD的transformation和action进行计算，将结果输出到console或者外部存储（比方说collect收集输出到console）。</p>
<h3 id="2，Driver"><a href="#2，Driver" class="headerlink" title="2，Driver"></a>2，Driver</h3><p> Spark中的driver感觉其实和yarn中Application Master的功能相类似。主要完成任务的调度以及和executor和cluster manager进行协调。有client和cluster联众模式。client模式driver在任务提交的机器上运行，而cluster模式会随机选择机器中的一台机器启动driver。从spark官网截图的一张图可以大致了解driver的功能。</p>
<p><img src="_v_images/20201015163856640_926148743.png"></p>
<h3 id="3，Job"><a href="#3，Job" class="headerlink" title="3，Job"></a>3，Job</h3><p> Spark中的Job和MR中Job不一样不一样。MR中Job主要是Map或者Reduce Job。而Spark的Job其实很好区别，一个action算子就算一个Job，比方说count，first等。</p>
<h3 id="4-Task"><a href="#4-Task" class="headerlink" title="4, Task"></a>4, Task</h3><p>Task是Spark中最新的执行单元。RDD一般是带有partitions的，每个partition的在一个executor上的执行可以任务是一个Task。 </p>
<h3 id="5-Stage"><a href="#5-Stage" class="headerlink" title="5, Stage"></a>5, Stage</h3><p>Stage概念是spark中独有的。一般而言一个Job会切换成一定数量的stage。各个stage之间按照顺序执行。至于stage是怎么切分的，首选得知道spark论文中提到的narrow dependency(窄依赖)和wide dependency（ 宽依赖）的概念。其实很好区分，看一下父RDD中的数据是否进入不同的子RDD，如果只进入到一个子RDD则是窄依赖，否则就是宽依赖。宽依赖和窄依赖的边界就是stage的划分点</p>
<p><img src="_v_images/20201015163856436_1360238478.png"></p>
<p><img src="_v_images/20201015163856129_654594465.png"></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 使用</title>
    <url>/bigdata/Spark/Spark-usage/</url>
    <content><![CDATA[<h1 id="Spark-使用"><a href="#Spark-使用" class="headerlink" title="Spark 使用"></a>Spark 使用</h1><h2 id="copy-file"><a href="#copy-file" class="headerlink" title="copy file"></a>copy file</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.&#123;<span class="type">FileAlreadyExistsException</span>, <span class="type">FileSystem</span>, <span class="type">FileUtil</span>, <span class="type">Path</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> srcFileSystem: <span class="type">FileSystem</span> = <span class="type">FileSystemUtil</span></span><br><span class="line">      .apply(spark.sparkContext.hadoopConfiguration)</span><br><span class="line">      .getFileSystem(sourceFile)</span><br><span class="line">    <span class="keyword">val</span> dstFileSystem: <span class="type">FileSystem</span> = <span class="type">FileSystemUtil</span></span><br><span class="line">      .apply(spark.sparkContext.hadoopConfiguration)</span><br><span class="line">      .getFileSystem(sourceFile)</span><br><span class="line"></span><br><span class="line">    <span class="type">FileUtil</span>.copy(</span><br><span class="line">      srcFileSystem,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">Path</span>(<span class="keyword">new</span> <span class="type">URI</span>(sourceFile)),</span><br><span class="line">      dstFileSystem,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">Path</span>(<span class="keyword">new</span> <span class="type">URI</span>(targetFile)),</span><br><span class="line">      <span class="literal">true</span>,</span><br><span class="line">      spark.sparkContext.hadoopConfiguration)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark开发集锦</title>
    <url>/bigdata/Spark/Spark-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><p><a href="https://spark-reference-doc-cn.readthedocs.io/zh_CN/latest/programming-guide/rdd-guide.html">Spark 2.2.x中文文档</a><br>spark两个重要概念</p>
<ul>
<li>RDD</li>
<li>共享变量</li>
</ul>
<h2 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h2><h3 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h3><h3 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h3><h2 id="dev"><a href="#dev" class="headerlink" title="dev"></a>dev</h2><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><p>spark core依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>hdfs client</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>导包</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br></pre></td></tr></table></figure>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>每个JVM进程中，只能有一个活跃（active）的 SparkContext 对象。如果你非要再新建一个，那首先必须将之前那个活跃的 SparkContext 对象stop()掉。</p>
<blockquote>
<p>如何保证SparkContext是单例</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(appName).setMaster(master)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-shell –help 可以查看完整的选项列表</span><br></pre></td></tr></table></figure>
<h2 id="RDD-弹性分布式数据集"><a href="#RDD-弹性分布式数据集" class="headerlink" title="RDD: 弹性分布式数据集"></a>RDD: 弹性分布式数据集</h2><p>可容错、可并行操作的分布式元素集合</p>
<p>有两种方法可以创建 RDD 对象：由驱动程序中的集合对象通过并行化操作创建，或者从外部存储系统中数据集加载（如：共享文件系统、HDFS、HBase或者其他Hadoop支持的数据源）。</p>
<h3 id="并行集合"><a href="#并行集合" class="headerlink" title="并行集合"></a>并行集合</h3><h2 id="Spark-SQL-partition个数与宽窄依赖"><a href="#Spark-SQL-partition个数与宽窄依赖" class="headerlink" title="Spark SQL partition个数与宽窄依赖"></a>Spark SQL partition个数与宽窄依赖</h2><h3 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey"></a>groupByKey</h3><h4 id="默认值"><a href="#默认值" class="headerlink" title="默认值"></a>默认值</h4><ol>
<li>不指定partition大小</li>
</ol>
<p>默认的 Spark SQL 会使用 <code>spark.sql.shuffle.partitions</code> 的数量来进行 <code>aggregation</code> 和 <code>join</code>，默认值为 200。这会导致 partition 膨胀的问题，200个 partition 都需要执行，无论大小，尽管有些 partition 是没有数据的。</p>
<ol start="2">
<li>通过repartition设定大小后，再groupByKey</li>
</ol>
<p>仍然是200</p>
<ol start="3">
<li><p>Using repartition Operator With Explicit Number of Partitions</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">repartition(numPartitions: <span class="type">Int</span>, partitionExprs: <span class="type">Column</span>*): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure>
<p>指定partitionExprs，则可以实现指定的分区数</p>
</li>
</ol>
<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>rdd的几个基本方法:</p>
<p>getPartitions()</p>
<p>compute()</p>
<h2 id="Hadoop-split-Hadoop分片"><a href="#Hadoop-split-Hadoop分片" class="headerlink" title="Hadoop split: Hadoop分片"></a>Hadoop split: Hadoop分片</h2><p>hdfs dfs blockSize</p>
<p>hdfs-site.xml中修改dfs.blockSize, spark 2.7.x 默认值为128M</p>
<p><img src="_v_images/20200728185752151_2000769439.png"></p>
<h2 id="spark-3-0-读取-orcfile"><a href="#spark-3-0-读取-orcfile" class="headerlink" title="spark 3.0 读取 orcfile"></a>spark 3.0 读取 orcfile</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> path=<span class="string">&quot;/data/sample.orc&quot;</span></span><br><span class="line"><span class="keyword">val</span> orcRdd: <span class="type">RDD</span>[(<span class="type">NullWritable</span>, <span class="type">OrcStruct</span>)] =</span><br><span class="line">  sc.hadoopFile(</span><br><span class="line">    path,</span><br><span class="line">    classOf[<span class="type">OrcInputFormat</span>],</span><br><span class="line">    classOf[<span class="type">NullWritable</span>],</span><br><span class="line">    classOf[<span class="type">OrcStruct</span>],</span><br><span class="line">    <span class="number">10</span>)</span><br><span class="line"><span class="keyword">val</span> result= orcRdd.map((line: (<span class="type">NullWritable</span>, <span class="type">OrcStruct</span>)) =&gt; &#123;</span><br><span class="line">  line._2.getNumFields</span><br><span class="line">&#125;).collect()</span><br></pre></td></tr></table></figure>



<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>toDebugString</p>
<p>参考文献:</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/52328286">Number of Partitions for groupBy Aggregation</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark资源评估</title>
    <url>/bigdata/Spark/Spark%E8%B5%84%E6%BA%90%E8%AF%84%E4%BC%B0/</url>
    <content><![CDATA[<h1 id="Spark资源评估"><a href="#Spark资源评估" class="headerlink" title="Spark资源评估"></a>Spark资源评估</h1><table>
<thead>
<tr>
<th>机器机型</th>
<th>内存</th>
<th>硬盘</th>
<th>核数</th>
</tr>
</thead>
<tbody><tr>
<td>M10</td>
<td>128G</td>
<td>3.6T</td>
<td>48</td>
</tr>
<tr>
<td>BX1</td>
<td>16G×16 256G</td>
<td>4T×12=48T</td>
<td>80</td>
</tr>
<tr>
<td>CG3</td>
<td>256G</td>
<td>3.6T</td>
<td>96</td>
</tr>
</tbody></table>
<h2 id="Spark-On-Yarn-内存计算"><a href="#Spark-On-Yarn-内存计算" class="headerlink" title="Spark On Yarn 内存计算"></a>Spark On Yarn 内存计算</h2><p>在介绍了，spark任务在yarn运行时需要的Continer数量，以及内存大小之后，我们再来看spark on yarn的时候整体任务在yarn中占用资源大小。</p>
<p>Core： yarn中Core指的是Continer数量，所以Core = ContinerNum</p>
<p>而内存的计算则较为复杂了，设单个Continer向集群申请的资源经我们上面公式算出来的需要申请的内存大小为：excutorTotalMemory ，则该Continer在yarn集群上占用的最终资源为continerMemory。<br>minContiner = yarn.scheduler.minimum-allocation-mb（continer分配资源的最小值，目前是128）<br>Increment = yarn.scheduler.increment-allocation-mb（yarn分配资源的增量，也叫规整化参数，默认值为1024 mb）<br>resultMemory的计算方式如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">If（totalMemory&lt;=minContiner）&#123;</span><br><span class="line">	continerMemory = minContiner</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">	continerMemory = minContiner + Math.ceil（(excutorTotalMemory - minContiner)/increment） * increment</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>总结</strong></p>
<p>例如某个spark任务的提交参数为，driverMemory=2G，executorMemory=2G，executorNum = 1<br>minContiner=512m<br>Increment =1024m<br>则该任务<br>executorContinerMemory计算过程如下</p>
<pre><code>申请资源数：executor = Max(executorMemory*0.1，384M)+executorMemory=2432M
ContinerMymory = 512+Math.ceil（(2432-512)/1024.0）*1024 = 2.5G</code></pre>
<p>driverContinerMemory计算过程同上：2.5G<br>最终该任务在yarn消耗资源为5G<br>可以看出来，spark任务最终消耗资源并非为初始化资源数。</p>
<p>需要join 75张表，每张表的主键分布不同：</p>
<ul>
<li>直接join会造成数据倾斜，某个节点撑爆</li>
<li>所有的表都shuffle，会造成shuffle数据量太多，撑爆硬盘</li>
</ul>
<p>申请的资源:</p>
<p><img src="_v_images/20201012172033562_1858655038.png"></p>
<p>策略一:</p>
<ul>
<li>join后的表，每隔join20次则repartition一次</li>
<li>待join的子表，partition个数超过30，或行数超过1.5亿，则repartition一次</li>
</ul>
<p><img src="_v_images/20201012170200410_989497495.png"></p>
<p>宽表数据量:<br><img src="_v_images/20201012190000429_1118094404.png"></p>
<p><img src="_v_images/20201012204407377_1330736778.png"></p>
<h2 id="问题点"><a href="#问题点" class="headerlink" title="问题点"></a>问题点</h2><ol>
<li>dag排布的规则是什么？</li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse： one of the fastest olap engine</title>
    <url>/bigdata/clickhouse/ClickHouse/</url>
    <content><![CDATA[<h1 id="ClickHouse"><a href="#ClickHouse" class="headerlink" title="ClickHouse"></a>ClickHouse</h1><p><a href="https://clickhouse.yandex/docs/zh/">官方文档</a></p>
<h1 id="Clickhouse"><a href="#Clickhouse" class="headerlink" title="Clickhouse"></a>Clickhouse</h1><p><a href="https://clickhouse.yandex/">offical website</a> <a href="https://github.com/ClickHouse/ClickHouse/">github</a><br><a href="https://github.com/ClickHouse-China/ClickhouseMeetup">meetup backup</a></p>
<h2 id="why-do-we-need-ClickHouse"><a href="#why-do-we-need-ClickHouse" class="headerlink" title="why do we need ClickHouse"></a>why do we need ClickHouse</h2><ul>
<li>交互式查询</li>
<li>持续追加数据</li>
</ul>
<blockquote>
<p>Hypothesis<br>If we have good enough column-oriented DBMS,<br>we could store all our data in non-aggregated form<br>(raw pageviews and sessions) and generate all the reports on the fly,<br>to allow infinite customization.</p>
</blockquote>
<p>愿景：<br>足够好的列式DBMS，可以存储所有非聚合数据(原始的浏览数据和会话)，可以在线生成所有的报告，拥有足够的个性化</p>
<h3 id="yandex数据量"><a href="#yandex数据量" class="headerlink" title="yandex数据量"></a>yandex数据量</h3><ul>
<li><blockquote>
<p>30 trillions of rows (as of 2019)</p>
</blockquote>
</li>
<li><blockquote>
<p>600 servers</p>
</blockquote>
</li>
<li>  total throughput of query processing is up to two terabytes per second</li>
</ul>
<h2 id="feature"><a href="#feature" class="headerlink" title="feature"></a>feature</h2><ul>
<li>  column-oriented 列数存储</li>
<li>  distributed 分布式</li>
<li>  linearly scalable 线性扩展</li>
<li>  fault-tolerant 容错</li>
<li>  data ingestion in realtime 实时数据摄取</li>
<li>  realtime (sub-second) queries 实时亚秒级查询</li>
<li>  support of SQL dialect + extensions 支持SQL方言和扩展</li>
</ul>
<h2 id="why-fast"><a href="#why-fast" class="headerlink" title="why fast"></a>why fast</h2><h3 id="High-level-architecture-架构"><a href="#High-level-architecture-架构" class="headerlink" title="High level architecture 架构"></a>High level architecture 架构</h3><p>— Scale-out shared nothing; 横向伸缩无共享</p>
<p>— Massive Parallel Processing; MPP</p>
<h3 id="Data-storage-optimizations-存储优化"><a href="#Data-storage-optimizations-存储优化" class="headerlink" title="Data storage optimizations 存储优化"></a>Data storage optimizations 存储优化</h3><p>— Column-oriented storage; 列式存储</p>
<p>— Merge Tree;</p>
<p>— Sparse index; 稀疏index</p>
<p>— Data compression; 数据压缩</p>
<h3 id="Algorithmic-optimizations-算法优化"><a href="#Algorithmic-optimizations-算法优化" class="headerlink" title="Algorithmic optimizations 算法优化"></a>Algorithmic optimizations 算法优化</h3><p>Best algorithms in the world…<br>… are happy to be used in ClickHouse.</p>
<p>— Volnitsky substring search</p>
<p>— Hyperscan and RE2</p>
<p>— SIMD JSON</p>
<p>— HDR Histograms</p>
<p>— Roaring Bitmaps</p>
<p>…</p>
<h3 id="Low-level-optimizations-底层优化"><a href="#Low-level-optimizations-底层优化" class="headerlink" title="Low-level optimizations 底层优化"></a>Low-level optimizations 底层优化</h3><p>Optimizations for CPU instruction sets<br>using SIMD processing. 使用SIMD优化CPU指令集</p>
<p>— SIMD text parsing</p>
<p>— SIMD data filtering</p>
<p>— SIMD decompression</p>
<p>— SIMD string operations</p>
<p>…</p>
<h3 id="Specializations-of-algorithms…"><a href="#Specializations-of-algorithms…" class="headerlink" title="Specializations of algorithms…"></a>Specializations of algorithms…</h3><p>… and attention to detail:</p>
<p>— uniq, uniqExact, uniqCombined, uniqUpTo;</p>
<p>— quantile, quantileTiming, quantileExact, quantileTDigest, quantileWeighted;</p>
<p>— 40+ specializations of GROUP BY;</p>
<p>— algorithms optimize itself for data distribution:<br>LZ4 decompression with Bayesian Bandits.</p>
<h3 id="Interfaces"><a href="#Interfaces" class="headerlink" title="Interfaces"></a>Interfaces</h3><p>HTTP REST</p>
<p>clickhouse-client</p>
<p>JDBC, ODBC</p>
<p>(new) MySQL protocol compatibility</p>
<p>Python, PHP, Perl, Go,<br>Node.js, Ruby, C++, .NET, Scala, R, Julia, Rust</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/clickhouse/%E5%90%91%E9%87%8F%E5%8C%96%E4%B8%8E%E7%81%AB%E5%B1%B1%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="向量化执行引擎"><a href="#向量化执行引擎" class="headerlink" title="向量化执行引擎"></a>向量化执行引擎</h1><p><a href="http://mysql.taobao.org/monthly/2017/01/06/">向量化执行引擎</a></p>
<h2 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h2><ol>
<li>传统的一次一个tuple的pipeline模式，CPU的大部分处理时在遍历操作数，而不是在处理数据，CPU利用率低，还导致缓存性能低和频繁跳转。</li>
<li>寻址性能是存储的瓶颈，顺序读写性能比随机读取效率更高，但大部分查询都是随机读取，此外磁盘读写速度远远落后于CPU数据执行速度。列存储可以最大化利用磁盘读写能力</li>
</ol>
<p>列存储的优势:</p>
<ul>
<li>压缩能力提升: 列类型统一，存放一起，易于压缩</li>
<li>减少IO读写总量：仅仅需要读取需要的列</li>
<li>减少查询过程中的节点函数的调用次数：计算过程中，列存以数据块的形式返回上层节点，减少函数调用次数</li>
<li>向量化执行：计算的过程中，相同的列执行相同的操作，可以使用SIMD提升计算效率；不支持SIMD，也可以通过循环提升效率</li>
<li>延迟物化：减少查询计划树之间传递数据总量</li>
</ul>
<h2 id="向量化引擎的适用条件"><a href="#向量化引擎的适用条件" class="headerlink" title="向量化引擎的适用条件"></a>向量化引擎的适用条件</h2><ul>
<li>列存储</li>
<li>OLAP</li>
</ul>
<p>OLAP适合列存储<br>OLTP点查询适合行存储</p>
<h2 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h2><ul>
<li>火山模型: 修改成一次返回一组列</li>
<li>层次型执行模式: 将优化好的执行计划数转换为编译执行：一次调用下来后，每一层都完成后才向上返回数据，减少各层次节点间的调用次数</li>
</ul>
<p>在数据量比较大的情况下，内存可能放不下这些数据，需要写盘，这样会造成额外的开销。</p>
<h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><ul>
<li>向量化执行引擎可以减少节点间的调度，提高CPU的利用率。</li>
<li>因为列存数据，同一列的数据放在一起，导致向量化执行引擎在执行的时候拥有了更多的机会能够利用的当前硬件与编译的新优化特征。</li>
<li>因为列存数据存储将同类型的类似数据放在一起使得压缩比能够达到更高，这样可以拉近一些磁盘IO能力与计算能力的差距。</li>
</ul>
<h2 id="注意的问题"><a href="#注意的问题" class="headerlink" title="注意的问题"></a>注意的问题</h2><ul>
<li>通信库的效率: MPP架构上是share nothing架构的，所以它的集群各执行节点是有通信需要的，通信效率的高低也是决定了查询执行效率。另外就是大集群情况下，如果使用tcp方式连接，连接数会受限。</li>
<li>数据读写争抢问题 这个问题本身不是向量化执行引擎的，而是列存带来的，因为列存储表每一列单独存储为一个文件，这样在写盘的时候有优化与没有优化的差距还是非常明显的。</li>
<li>列存数据过滤效率问题 列存数据中的一个处理单元是由连续的N个值放在一起组成的一个Col（数组），然后再由多个Col的数组组成了一个处理单元。在进行过率的时候如何能够更加紧凑的放置数据是需要我们考虑列存在过滤掉效率和存放之间如何优化的问题。</li>
<li>表达式计算问题（LLVM） LLVM优化可以将表达式计算由遍历树多层调用模式变为，只调用一个函数的扁平式执行方式。这样可以极大的提高表达式的执行性能。值得一提的是LLVM技术的优势也可以应用在执行计划编译执行模型的构建上面。</li>
</ul>
<h1 id="火山模型"><a href="#火山模型" class="headerlink" title="火山模型"></a>火山模型</h1><p>例如 SQL：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Id, Name, Age, (Age <span class="operator">-</span> <span class="number">30</span>) <span class="operator">*</span> <span class="number">50</span> <span class="keyword">AS</span> Bonus</span><br><span class="line"><span class="keyword">FROM</span> People</span><br><span class="line"><span class="keyword">WHERE</span> Age <span class="operator">&gt;</span> <span class="number">30</span></span><br></pre></td></tr></table></figure>
<p>对应火山模型如下：</p>
<p><img src="vx_images/3461008149501.jpg"></p>
<p>其中——</p>
<p>User：客户端；</p>
<p>Project：垂直分割（投影），选择字段；</p>
<p>Select（或 Filter）：水平分割（选择)，用于过滤行，也称为谓词；</p>
<p>Scan：扫描数据。</p>
<p>这里包含了 3 个 Operator，首先 User 调用最上方的 Operator（Project）希望得到 next tuple，Project 调用子节点（Select），而 Select 又调用子节点（Scan），Scan 获得表中的 tuple 返回给 Select，Select 会检查是否满足过滤条件，如果满足则返回给 Project，如果不满足则请求 Scan 获取 next tuple。Project 会对每一个 tuple 选择需要的字段或者计算新字段并返回新的 tuple 给 User。当 Scan 发现没有数据可以获取时，则返回一个结束标记告诉上游已结束。</p>
<p>为了更好地理解一个 Operator 中发生了什么，下面通过伪代码来理解 Select Operator：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">Tuple <span class="title">Select::next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        Tuple candidate = child-&gt;next(); <span class="comment">// 从子节点中获取 next tuple</span></span><br><span class="line">        <span class="keyword">if</span> (candidate == EndOfStream) <span class="comment">// 是否得到结束标记</span></span><br><span class="line">            <span class="keyword">return</span> EndOfStream;</span><br><span class="line">        <span class="keyword">if</span> (condition-&gt;check(candidate)) <span class="comment">// 是否满足过滤条件</span></span><br><span class="line">            <span class="keyword">return</span> candidate; <span class="comment">// 返回 tuple</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="火山模型的优缺点"><a href="#火山模型的优缺点" class="headerlink" title="火山模型的优缺点"></a>火山模型的优缺点</h2><p>可以看出火山模型的<strong>优点</strong>在于：简单，每个 Operator 可以单独抽象实现、不需要关心其他 Operator 的逻辑。</p>
<p>那么<strong>缺点</strong>呢？也够明显吧？每次都是计算一个 tuple（Tuple-at-a-time），这样会造成多次调用 next ，也就是造成大量的虚函数调用，这样会造成 CPU 的利用率不高。</p>
<blockquote>
<p>知识点补习——虚函数<br>C++ 中用 virtual 标记的函数，而在 Java 中没有 final 修饰的普通方法（没有标记为 static、native）都是虚函数。<br>虚函数的重要特性是支持在子类中进行 override（重写），从而实现面向对象的重要特性之一：多态。</p>
</blockquote>
<p>但是为什么之前的数据库设计者没有去优化这方面呢？是他们没想到吗？怎么可能？这个时候我们可能要考虑到 30 年前的硬件水平了，当时的 IO 速度是远远小于 CPU 的计算速度的，那么 SQL 查询引擎的优化则会被 IO 开销所遮蔽（毕竟花费很多精力只带来 1% 场景下的速度提升意义并不大）。</p>
<p>可是随着近些年来存储越来越快，这个时候我们再思考如何让计算更快可能就有点意思了。</p>
<h2 id="虚函数造成cpu利用率不高"><a href="#虚函数造成cpu利用率不高" class="headerlink" title="虚函数造成cpu利用率不高"></a>虚函数造成cpu利用率不高</h2><ul>
<li>空间开销<br>  首先，由于需要为每一个包含虚函数的类生成一个虚函数表，所以程序的二进制文件大小会相应的增大；其次，对于包含虚函数的类的实例来说，每个实例都包含一个虚函数表指针用于指向对应的虚函数表，所以每个实例的空间占用都增加一个指针大小（32位系统4字节，64位系统8字节）。这些空间开销可能会造成缓存的不友好，在一定程度上影响程序性能。</li>
<li>时间开销<br>  虚函数的时间开销主要是增加了一次内存寻址，通过虚函数表指针找到虚函数表，虽对程序性能有一些影响，但是影响并不大。</li>
</ul>
<p>影响到虚函数调用性能的背后原因是流水线和分支预测，由于虚函数调用需要间接跳转，所以会导致虚函数调用比普通函数调用多了分支预测的过程，产生性能差距的原因主要是分支预测失败导致的流水线冲刷性能开销。</p>
<h2 id="优化方向"><a href="#优化方向" class="headerlink" title="优化方向"></a>优化方向</h2><h2 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h2><p><img src="vx_images/5443594707024.png"></p>
<h2 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h2><p>按照行加载到CPU Cache，如果只访问个别列就丢弃了，CPU Cache利用率不高。<br>按列存储，因为输入是同列的一组数据，面对的是相同的操作，并且如果每次只取一列的部分数据，返回一个可以放到 CPU Cache 的向量，那么又可以利用到 CPU Cache。</p>
<p>知识点补习：向量化<br>向量化计算就是将一个循环处理一个数组的时候每次处理 1 个数据共处理 N 次，转化为向量化——每次同时处理 8 个数据共处理 N/8 次，其中依赖的技术就是 SIMD（Single Instruction Multiple Data，单指令流多数据流），SIMD 可以在一条 CPU 指令上处理 2、4、8 或者更多份的数据。</p>
<h2 id="代码生成是否因为SQL复杂过慢"><a href="#代码生成是否因为SQL复杂过慢" class="headerlink" title="代码生成是否因为SQL复杂过慢"></a>代码生成是否因为SQL复杂过慢</h2><h2 id="循环优化"><a href="#循环优化" class="headerlink" title="循环优化"></a>循环优化</h2><h2 id="share-nothing架构"><a href="#share-nothing架构" class="headerlink" title="share nothing架构"></a>share nothing架构</h2><h2 id="表达式计算问题（LLVM）"><a href="#表达式计算问题（LLVM）" class="headerlink" title="表达式计算问题（LLVM）"></a>表达式计算问题（LLVM）</h2><p>列式存储</p>
<p>SIMD</p>
<p>火山模型</p>
<p>延迟物化</p>
<p>谓词</p>
<p>Greenplum</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/distributed/02.%E9%99%90%E6%B5%81/</url>
    <content><![CDATA[<h1 id="02-限流"><a href="#02-限流" class="headerlink" title="02.限流"></a>02.限流</h1>]]></content>
  </entry>
  <entry>
    <title>分布式理论：隔离机制【转载】</title>
    <url>/bigdata/distributed/03.%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>转载自 <a href="https://segmentfault.com/a/1190000020791119">微服务容错 - 隔离熔断限流</a></p>
<p>在高并发访问下，系统所依赖的服务的稳定性对系统的影响非常大，依赖有很多不可控的因素，比如网络连接变慢，资源突然繁忙，暂时不可用，服务脱机等。我们要构建稳定、可靠的分布式系统，就必须要有这样一套容错机制。常用的的容错技术如：隔离，降级，熔断，限流等策略，本文将详细的介绍微服务中的容错机制。</p>
<h2 id="隔离机制"><a href="#隔离机制" class="headerlink" title="隔离机制"></a>隔离机制</h2><p>为什么要隔离? 比如我们现在某个接口所在的服务A需要调用服务B，而服务B同时需要调用C服务，此时服务C突然宕机同时此时流量暴涨，调用全部打到服务B上，此时B服务调用C超时大量的线程资源被该接口所占全部hang住，慢慢服务B中的线程数量则会持续增加直致CPU资源耗尽到100%，整个服务对外不可用渐渐蔓延到B服务集群中的其他节点，导致服务级联故障。</p>
<p><img src="_v_images/20191130225057895_2045824433" alt="1570592685522.png" title="1570592685522.png"></p>
<p>此时我们就需要对服务出现异常的情况进行隔离，防止级联故障效应，常用的隔离策略有线程池隔离和信号量隔离</p>
<h3 id="线程池隔离"><a href="#线程池隔离" class="headerlink" title="线程池隔离"></a>线程池隔离</h3><p>线程池隔离顾名思义就是通过Java的线程池进行隔离，B服务调用C服务给予固定的线程数量比如10个线程，如果此时C服务宕机了就算大量的请求过来，调用C服务的接口只会占用10个线程不会占用其他工作线程资源，因此B服务就不会出现级联故障</p>
<p><img src="_v_images/20191130225057490_1596748749" alt="1570593867373.png" title="1570593867373.png"></p>
<h3 id="信号量隔离"><a href="#信号量隔离" class="headerlink" title="信号量隔离"></a>信号量隔离</h3><p>另一种隔离信号量隔离是使用<code>JUC</code>下的Semaphore来实现的，当拿不到信号量的时候直接拒接因此不会出现超时占用其他工作线程的情况。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Semaphore semaphore &#x3D; new Semaphore(10,true);</span><br><span class="line">&#x2F;&#x2F;获取信号量</span><br><span class="line">semaphore.acquire();</span><br><span class="line">&#x2F;&#x2F;do something here</span><br><span class="line">&#x2F;&#x2F;释放信号量</span><br><span class="line">semaphore.release();</span><br></pre></td></tr></table></figure>
<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>​线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。而信号量隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。</p>
<table>
<thead>
<tr>
<th>比较项</th>
<th>线程池隔离</th>
<th>信号量隔离</th>
</tr>
</thead>
<tbody><tr>
<td>线程</td>
<td>与调用线程不同，使用的是线程池创建的线程</td>
<td>与调用线程相同</td>
</tr>
<tr>
<td>开销</td>
<td>排队，切换，调度等开销</td>
<td>无线程切换性能更高</td>
</tr>
<tr>
<td>是否支持异步</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>是否支持超时</td>
<td>支持超时</td>
<td><strong>支持超时(<a href="https://www.codercto.com/a/77154.html">新版本支持</a>)</strong></td>
</tr>
<tr>
<td>并发支持</td>
<td>支持通过线程池大小控制</td>
<td>支持通过最大信号量控制</td>
</tr>
</tbody></table>
<h2 id="降级熔断机制"><a href="#降级熔断机制" class="headerlink" title="降级熔断机制"></a>降级熔断机制</h2><p>​ 什么是降级和熔断？降级和熔断有什么区别？虽然很多人把降级熔断当着一个词来说的，但是降级和熔断是完全不同的概念的，看看下面几种场景：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">场景一：比如我们每天上班坐公交，1路和2路公交都能到公司，但是2路公交需要下车走点路，所以平时都是坐1路公交，</span><br><span class="line">突然有一天等了1路公交好久都没来，于是就坐了2路公交作为替代方案总不能迟到吧！下次再等1路车。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">场景二：第二天，第三天 ... 已经一个星期了都没看到1路公交，心里觉得可能是1路公交改路线了，</span><br><span class="line">于是直接坐2路公交了，在接下来的日子里都是直接忽略1路车直接坐2路车</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">场景三：突然有一天在等2路车的时候看到了1路车，是不是1路车现在恢复了，于是天天开心的坐着1路车上班去了，领导再也不担心我迟到了</span><br></pre></td></tr></table></figure>
<p>场景一 在1路车没等到的情况下采取降级方案坐2路车，这就是降级策略，<br>场景二 如果多次都没有等到1路车就直接不等了下次直接坐2路车，这就是熔断策略，<br>场景三 如果过段时间1路车恢复了就使用2路车，这就是熔断恢复！</p>
<h3 id="降级机制"><a href="#降级机制" class="headerlink" title="降级机制"></a>降级机制</h3><p>常用的降级策略如：熔断器降级，限流降级，超时降级，异常降级，平均响应时间降级等</p>
<p><img src="_v_images/20191130225057086_638012610" alt="1570591437265.png" title="1570591437265.png"></p>
<ul>
<li><strong>熔断器降级：</strong>即熔断器开启的时间直接熔断走降级的策略</li>
<li><strong>限流降级：</strong>对流量进行限制达到降级的效果，如：<code>Hystrix</code>中的线程池，信号量都能达到限流的效果</li>
<li><strong>超时降级：</strong>课时设置对应的超时时间如果服务调用超时了就执行降级策略，如：<code>Hystrix</code>中默认为1s</li>
<li><strong>异常降级：</strong>异常降级很简单就是服务出现异常了执行降级策略</li>
<li><strong>平均响应时间降级：</strong>服务响应时间持续飙高的时候实现降级策略，如Sentinel中默认的RT 上限是 4900 ms</li>
</ul>
<h3 id="熔断机制"><a href="#熔断机制" class="headerlink" title="熔断机制"></a>熔断机制</h3><p>​ 熔断其实是一个框架级的处理，那么这套熔断机制的设计，基本上业内用的是<code>Martin Fowler</code>提出的断路器模式，断路器的基本原理非常简单。<br>您将受保护的函数调用包装在断路器对象中，该对象将监视故障。一旦故障达到某个阈值，断路器将跳闸，并且所有进一步的断路器调用都会返回错误，而根本不会进行受保护的调用。常见的断路器模式有基本模式和扩展模式。</p>
<p><strong>基本模式：</strong></p>
<ul>
<li>如果断路器状态为close，则调用断路器将调用supplier服务模块；</li>
<li>如果断路器状态为open则直接返回错误；</li>
<li>如果超时，我们将增加失败计数器，成功的调用会将其重置为零；</li>
<li>通过比较故障计数和阈值来确定断路器的状态；</li>
</ul>
<p><img src="_v_images/20191130225056679_1480988248" alt="20191024163112.png" title="20191024163112.png"></p>
<p><strong>扩展模式：</strong></p>
<p>基础模式的断路器避免了在电路断开时发出受保护的呼叫，但是当情况恢复正常时，将需要外部干预才能将其重置。对于建筑物中的电路断路器，这是一种合理的方法，但是对于软件断路器，我们可以让断路器本身检测基础调用是否再次正常工作。我们可以通过在适当的时间间隔后再次尝试受保护的调用来实现这种自我重置行为，并在成功后重置断路器。于是就出现了扩展模式：</p>
<p><img src="_v_images/20191130225056272_406198049" alt="20191024163133.png" title="20191024163133.png"></p>
<ul>
<li>最开始处于<code>closed</code>状态，一旦检测到错误到达一定阈值，便转为<code>open</code>状态；</li>
<li>这时候会有个 reset timeout，到了这个时间了，会转移到<code>half open</code>状态；</li>
<li>尝试放行一部分请求到后端，一旦检测成功便回归到<code>closed</code>状态，即恢复服务；</li>
</ul>
<h3 id="熔断策略"><a href="#熔断策略" class="headerlink" title="熔断策略"></a>熔断策略</h3><p>我们通常用以下几种方式来衡量资源是否处于稳定的状态：</p>
<ul>
<li>平均响应时间：如<code>Sentinel</code>中的熔断就使用了平均响应时间，当 1s 内持续进入 5 个请求，对应时刻的平均响应时间（秒级）均超过阈值（<code>count</code>，以 ms 为单位），那么在接下的时间窗口之内，对这个方法的调用都会自动地熔断。</li>
<li>异常比例 ：主流的容错框架<code>Hystrix</code>和<code>sentinel</code>中都使用了异常比例熔断策略，比如当资源的每秒请求量 &gt;= 5，并且每秒异常总数占通过量的比值超过阈值之后，资源进入熔断状态，即在接下的时间窗口之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 <code>[0.0, 1.0]</code>，代表 0% - 100%。</li>
<li>异常数：如<code>Sentinel</code>中的熔断就使用了异常数熔断策略，当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 <code>timeWindow</code> 小于 60s，则结束熔断状态后仍可能再进入熔断状态。</li>
</ul>
<h2 id="限流机制"><a href="#限流机制" class="headerlink" title="限流机制"></a>限流机制</h2><p>​ 限流也是提高系统的容错性的一种方案，不同的场景对“流”的定义也是不同的，可以是网络流量，带宽，每秒处理的事务数 (<code>TPS</code>)，每秒请求数 (<code>hits per second</code>)，并发请求数，甚至还可能是业务上的某个指标，比如用户在某段时间内允许的最多请求短信验证码次数。我们常说的限流都是限制每秒请求数，从分布式角度来看，限流可分为 <code>分布式限流</code> （比如基于<code>Sentinel</code>或者<code>Redis</code>的集群限流）和 <code>单机限流</code> 。从算法实现角度来看，限流算法可分为 <code>漏桶算法</code>、 <code>令牌桶算法</code> 和 <code>滑动时间窗口算法</code> 。</p>
<h3 id="单机限流"><a href="#单机限流" class="headerlink" title="单机限流"></a>单机限流</h3><p><strong>漏桶算法</strong></p>
<p><img src="_v_images/20191130225055766_1808623677" alt="1570701032430.png" title="1570701032430.png"></p>
<ul>
<li>一个固定容量的漏桶，按照常量固定速率流出水滴；</li>
<li>如果桶是空的，则不需流出水滴；</li>
<li>可以以任意速率流入水滴到漏桶；</li>
<li>如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。</li>
</ul>
<p><strong>令牌桶算法</strong></p>
<p><img src="_v_images/20191130225055360_839601664" alt="1570700342271.png" title="1570700342271.png"></p>
<ul>
<li>假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌；</li>
<li>桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝；</li>
<li>当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上；</li>
<li>如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。</li>
</ul>
<p><strong>固定时间窗口算法</strong><br><img src="_v_images/20191130225054755_1892726461" alt="20191024163948.png" title="20191024163948.png"></p>
<p>这种实现计数器限流方式由于是在一个时间间隔内进行限制，如果用户在上个时间间隔结束前请求（但没有超过限制），同时在当前时间间隔刚开始请求（同样没超过限制），在各自的时间间隔内，这些请求都是正常的，但是将间隔临界的一段时间内的请求就会超过系统限制，可能导致系统被压垮。</p>
<p><strong>滑动时间窗口算法</strong></p>
<p><img src="_v_images/20191130225054050_1038055339" alt="1571219763433.png" title="1571219763433.png"></p>
<ul>
<li>0、初始化，设置时间窗口，设置时间窗口时间点间隔长度；</li>
<li>1、判断请求时间点是否在时间窗口中，在进入步骤2，否则进入步骤3；</li>
<li>2、判断是否超过时间窗口限流值，是-&gt;进行限流，否-&gt;对应时间窗口计数器+1；</li>
<li>3、移动当时时间窗口，移动方式是：起始时间点变为时间列表中的第二时间点，结束时间增加一个时间点。重新步骤一的判断 。</li>
</ul>
<h3 id="分布式限流"><a href="#分布式限流" class="headerlink" title="分布式限流"></a>分布式限流</h3><p>当应用为单点应用时，只要应用进行了限流，那么应用所依赖的各种服务也都得到了保护。 但线上业务出于各种原因考虑，多是分布式系统，单节点的限流仅能保护自身节点，但无法保护应用依赖的各种服务，并且在进行节点扩容、缩容时也无法准确控制整个服务的请求限制。</p>
<p><img src="_v_images/20191130225053543_420645799" alt="1571903140149.png" title="1571903140149.png"></p>
<p>如果实现了分布式限流，那么就可以方便地控制整个服务集群的请求限制，且由于整个集群的请求数量得到了限制，因此服务依赖的各种资源也得到了限流的保护。</p>
<p><img src="_v_images/20191130225052943_1592738452" alt="1571904304647.png" title="1571904304647.png"></p>
<p><strong>分布式限流方案</strong></p>
<p>分布式限流的思想我列举下面三个方案：</p>
<p><strong>1，<code>Redis</code>令牌桶</strong></p>
<p>这种方案是最简单的一种集群限流思想。在本地限流中，我们使用Long的原子类作令牌桶，当实例数量超过1，我们就考虑将<code>Redis</code>用作公共内存区域，进行读写。涉及到的并发控制，也可以使用<code>Redis</code>实现分布式锁。</p>
<p><strong>缺点：</strong>每取一次令牌都会进行一次网络开销，而网络开销起码是毫秒级，所以这种方案支持的并发量是非常有限的。</p>
<p><strong>2，<code>QPS</code>统一分配</strong></p>
<p>这种方案的思想是将集群限流最大程度的本地化。</p>
<p>举个例子，我们有两台服务器实例，对应的是同一个应用程序（<code>Application.name</code>相同），程序中设置的<code>QPS</code>为100，将应用程序与同一个控制台程序进行连接，控制台端依据应用的实例数量将<code>QPS</code>进行均分，动态设置每个实例的<code>QPS</code>为50，若是遇到两个服务器的配置并不相同，在负载均衡层的就已经根据服务器的优劣对流量进行分配，例如一台分配70%流量，另一台分配30%的流量。面对这种情况，控制台也可以对其实行加权分配<code>QPS</code>的策略。</p>
<p><strong>缺点：</strong></p>
<p>这也算一种集群限流的实现方案，但依旧存在不小的问题。该模式的分配比例是建立在大数据流量下的趋势进行分配，实际情况中可能并不是严格的五五分或三七分，误差不可控，极容易出现用户连续访问某一台服务器遇到请求驳回而另一台服务器此刻空闲流量充足的尴尬情况。</p>
<p><strong>3，发票服务器</strong></p>
<p>这种方案的思想是建立在<code>Redis</code>令牌桶方案的基础之上的。如何解决每次取令牌都伴随一次网络开销，该方案的解决方法是建立一层控制端，利用该控制端与<code>Redis</code>令牌桶进行交互，只有当客户端的剩余令牌数不足时，客户端才向该控制层取令牌并且每次取一批。</p>
<p><strong>缺点：</strong><br>这种思想类似于Java集合框架的数组扩容，设置一个阈值，只有当超过该临界值时，才会触发异步调用。其余存取令牌的操作与本地限流无二。虽然该方案依旧存在误差，但误差最大也就一批次令牌数而已。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1，<a href="https://www.cnblogs.com/rjzheng/p/10340176.html">https://www.cnblogs.com/rjzhe…</a><br>2，<a href="https://www.martinfowler.com/bliki/CircuitBreaker.html">https://www.martinfowler.com/…</a><br>3，<a href="https://www.cnblogs.com/babycomeon/p/11216538.html">https://www.cnblogs.com/babyc…</a><br>4，<a href="https://github.com/alibaba/Sentinel/wiki/Sentinel-%E4%B8%8E-Hystrix-%E7%9A%84%E5%AF%B9%E6%AF%94">https://github.com/alibaba/Se…</a><br>5，<a href="https://www.jishuwen.com/d/2TX1">https://www.jishuwen.com/d/2TX1</a><br>6，<a href="https://juejin.im/post/5c74a2e2f265da2dea053355">https://juejin.im/post/5c74a2…</a><br>7，<a href="https://www.jianshu.com/p/2596e559db5c">https://www.jianshu.com/p/259…</a><br>8，<a href="https://zhuanlan.zhihu.com/p/48965194">https://zhuanlan.zhihu.com/p/…</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Image</tag>
        <tag>熔断</tag>
        <tag>限流</tag>
        <tag>异步</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>在Docker上搭建Jenkins环境</title>
    <url>/bigdata/docker/Jenkins_Docker/</url>
    <content><![CDATA[<ol>
<li>从网易镜像仓库下载Jenkins</li>
</ol>
<p><a href="https://c.163yun.com/hub#/m/search/?keyword=jenkins">网易镜像仓库</a></p>
<p>拉取到本地</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull hub.c.163.com/library/jenkins:latest</span><br></pre></td></tr></table></figure>
<p>查看镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hub.c.163.com&#x2F;library&#x2F;jenkins   latest              88d9d8a30b47        8 months ago        810MB</span><br></pre></td></tr></table></figure>
<p>从官网下载最新的Jenkins</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://updates.jenkins-ci.org/download/war/2.107.2/jenkins.war</span><br></pre></td></tr></table></figure>
<p>DockerFile</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">FROM hub.c.163.com/library/jenkins</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将最新的Jenkins拷贝到`/usr/share/jenkins/`目录</span></span><br><span class="line">ADD jenkins.war /usr/share/jenkins/</span><br></pre></td></tr></table></figure>
<p>常见镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker build -t avery/jenkins .</span><br></pre></td></tr></table></figure>
<p>启动一个Container</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name prod_jenkins2 -d -p 9005:8080 -p 9006:50000 -v  /Users/avery/docker/jenkins/backup/jenkins_home:/var/jenkins_home avery/jenkins</span><br></pre></td></tr></table></figure>
<ol>
<li>创建本地Jenkins数据目录，将该目录映射到docker中的Jenkins目录，方便备份数据</li>
<li>8080端口是Jenkins web service的默认端口，将宿主机的端口映射到8080端口，可以直接访问</li>
<li>–name 命名为prod_jenkins2</li>
<li>-d 后台运行</li>
<li>-p 端口映射</li>
<li>-v 文件目录映射</li>
</ol>
<p>查看</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container ls -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS                   NAMES</span><br><span class="line">cb8cdf3be078        avery/jenkins       &quot;/bin/tini -- /usr/l…&quot;   3 hours ago         Exited (143) 3 hours ago                           prod_jenkins2</span><br></pre></td></tr></table></figure>
<p>启动后，可以直接通过url ‘<a href="http://localhost:9001&#39;">http://localhost:9001&#39;</a> 访问，Jenkins首次打开，需要获取随机密码</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 获取jenkins密码</span></span><br><span class="line">docker container exec cb8cdf3be078 cat /var/jenkins_home/secrets/initialAdminPassword</span><br><span class="line">a7cefff7d2634cc6a9542491f465eb52</span><br><span class="line"><span class="meta">#</span><span class="bash"> 或者直接进入shell查看</span></span><br><span class="line">docker exec -it cb8cdf3be078 bash</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker</title>
    <url>/bigdata/docker/base/</url>
    <content><![CDATA[<p>网易镜像 <a href="https://c.163yun.com/hub#/m/home/">https://c.163yun.com/hub#/m/home/</a></p>
<h1 id="修改数据源"><a href="#修改数据源" class="headerlink" title="修改数据源"></a>修改数据源</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod a+w /etc/sysconfig/docker</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 增加 ADD_REGISTRY=&#x27;--add-registry hub.c.163.com&#x27;</span></span></span><br></pre></td></tr></table></figure>
<h1 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h1><h2 id="image"><a href="#image" class="headerlink" title="image"></a>image</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker image ls</span><br></pre></td></tr></table></figure>



<h2 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container ls -a</span><br><span class="line">CONTAINER ID        IMAGE                         COMMAND               CREATED             STATUS              PORTS                   NAMES</span><br><span class="line">f7c2d84561dd        hub.c.163.com/public/centos   &quot;/usr/sbin/sshd -D&quot;   7 minutes ago       Up 7 minutes        0.0.0.0:32768-&gt;22/tcp   centos</span><br><span class="line"></span><br><span class="line">docker exec -it centos /bin/bash</span><br></pre></td></tr></table></figure>


<h2 id="文件拷贝"><a href="#文件拷贝" class="headerlink" title="文件拷贝"></a>文件拷贝</h2><ol>
<li>本地copy文件到container</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp ~/putMerge.jar hadoop0:~/</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>container文件copy到本地</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp hadoop0:~/putMerge.jar ~/</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>images 重命名</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker tag IMAGEID(镜像id) REPOSITORY:TAG（仓库：标签）</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">例子</span></span><br><span class="line">docker tag ca1b6b825289 reffs/xxxxxxx:v1.0</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum list installed | grep docker</span><br><span class="line">卸载：</span><br><span class="line"></span><br><span class="line">yum -y remove docker.x86_64</span><br><span class="line">重装：</span><br><span class="line"></span><br><span class="line">yum install docker-io</span><br><span class="line">启动：</span><br><span class="line"></span><br><span class="line">service docker start</span><br></pre></td></tr></table></figure>
<p>Docker 核心基础技术</p>
<ul>
<li>Namespace</li>
<li>cgroup</li>
</ul>
<p>linux Namespace</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">setns(fd,..)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -l /proc/1/ns</span><br><span class="line"></span><br><span class="line">ll /proc/1/ns/</span><br><span class="line">total 0</span><br><span class="line">lrwxrwxrwx 1 root root 0 Jun  5 15:20 cgroup -&gt; cgroup:[4026531835]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Jun  5 15:20 ipc -&gt; ipc:[4026531839]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Apr 15 19:28 mnt -&gt; mnt:[4026531840]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Apr 15 19:28 net -&gt; net:[4026531957]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Jun  5 15:20 pid -&gt; pid:[4026531836]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Apr 15 16:20 uts -&gt; uts:[4026531838]</span><br></pre></td></tr></table></figure>


<h2 id="cgroup-子系统"><a href="#cgroup-子系统" class="headerlink" title="cgroup 子系统"></a>cgroup 子系统</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lssubsys -m</span><br><span class="line"></span><br><span class="line">lssubsys -m</span><br><span class="line">cpuset /sys/fs/cgroup/cpuset</span><br><span class="line">cpu,cpuacct /sys/fs/cgroup/cpu,cpuacct</span><br><span class="line">memory /sys/fs/cgroup/memory</span><br><span class="line">devices /sys/fs/cgroup/devices</span><br><span class="line">freezer /sys/fs/cgroup/freezer</span><br><span class="line">net_cls /sys/fs/cgroup/net_cls</span><br><span class="line">blkio /sys/fs/cgroup/blkio</span><br><span class="line">perf_event /sys/fs/cgroup/perf_event</span><br><span class="line">hugetlb /sys/fs/cgroup/hugetlb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls /sys/fs/cgroup/cpu/mytest</span><br><span class="line"></span><br><span class="line">cgcreate -g cpu:mytest</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>在Docker上搭建Hadoop集群container</title>
    <url>/bigdata/docker/hadoop-cluser-in-docker/</url>
    <content><![CDATA[<blockquote>
<p>为了学习Hadoop，尝试使用Vbox搭建环境，不是很方便。后面转向Docker。本文将使用Docker搭建Hadoop集群记录下来，以备后用</p>
</blockquote>
<p>基础环境</p>
<ul>
<li>MacOS 10.12</li>
<li>Docker 17.03.1-ce</li>
</ul>
<p>网易镜像 <a href="https://c.163yun.com/hub#/m/home/">https://c.163yun.com/hub#/m/home/</a></p>
<h1 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h1><p>在MacOS 上安装Docker即为简单，从官网上下载dmg包，拖到应用目录启动即可。</p>
<p>安装完成后 查看docker 版本:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> docker version</span></span><br><span class="line"></span><br><span class="line">Client:</span><br><span class="line"> Version:      17.03.1-ce</span><br><span class="line"> API version:  1.27</span><br><span class="line"> Go version:   go1.7.5</span><br><span class="line"> Git commit:   c6d412e</span><br><span class="line"> Built:        Tue Mar 28 00:40:02 2017</span><br><span class="line"> OS/Arch:      darwin/amd64</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Version:      17.03.1-ce</span><br><span class="line"> API version:  1.27 (minimum version 1.12)</span><br><span class="line"> Go version:   go1.7.5</span><br><span class="line"> Git commit:   c6d412e</span><br><span class="line"> Built:        Fri Mar 24 00:00:50 2017</span><br><span class="line"> OS/Arch:      linux/amd64</span><br><span class="line"> Experimental: true</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="docker-建立镜像"><a href="#docker-建立镜像" class="headerlink" title="docker 建立镜像"></a>docker 建立镜像</h1><p>建立三个镜像，存储目录如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> tree</span></span><br><span class="line">.</span><br><span class="line">├── centos-ssh-root</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── centos-ssh-root-jdk</span><br><span class="line">│   ├── Dockerfile</span><br><span class="line">│   └── jdk-7u79.tar.gz</span><br><span class="line">└── centos-ssh-root-jdk-hadoop</span><br><span class="line">    ├── Dockerfile</span><br><span class="line">    └── hadoop-2.7.3.tar.gz</span><br></pre></td></tr></table></figure>
<h2 id="建立CentOS-SSH-root基础镜像"><a href="#建立CentOS-SSH-root基础镜像" class="headerlink" title="建立CentOS-SSH-root基础镜像"></a>建立CentOS-SSH-root基础镜像</h2><p>建立一个带有ssh和root账户的CentOS镜像</p>
<ol>
<li>新建Dockerfile文件<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> mkdir  centos-ssh-root</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> <span class="built_in">cd</span> centos-ssh-root</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 新建 Dockerfile 文件</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> vi  Dockerfile</span></span><br></pre></td></tr></table></figure>
Dockerfile的内容为:</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 选择一个已有的os镜像作为基础  国内首选仓库 c.163.com</span></span><br><span class="line">FROM hub.c.163.com/public/centos:7.2.1511 </span><br><span class="line">RUN yum clean all</span><br><span class="line">RUN yum install -y yum-plugin-ovl || true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装基础的工具包</span></span><br><span class="line">RUN yum install -y vim tar wget curl rsync bzip2 iptables tcpdump less telnet net-tools lsof sysstat cronie python-setuptools</span><br><span class="line">RUN yum clean all</span><br><span class="line">RUN easy_install supervisor</span><br><span class="line">RUN cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">EXPOSE 22</span><br><span class="line">RUN mkdir -p /etc/supervisor/conf.d/</span><br><span class="line">RUN /usr/bin/echo_supervisord_conf &gt; /etc/supervisord.conf</span><br><span class="line">RUN echo [include] &gt;&gt; /etc/supervisord.conf</span><br><span class="line">RUN echo &#x27;files = /etc/supervisor/conf.d/*.conf&#x27; &gt;&gt; /etc/supervisord.conf</span><br><span class="line"><span class="meta">#</span><span class="bash">COPY sshd.conf /etc/supervisor/conf.d/sshd.conf</span></span><br><span class="line">CMD [&quot;/usr/bin/supervisord&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 镜像的作者</span>  </span><br><span class="line">MAINTAINER avery </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装openssh-server和sudo软件包，并且将sshd的UsePAM参数设置成no</span>  </span><br><span class="line">RUN yum install -y openssh-server sudo  </span><br><span class="line">RUN sed -i &#x27;s/UsePAM yes/UsePAM no/g&#x27; /etc/ssh/sshd_config  </span><br><span class="line"><span class="meta">#</span><span class="bash">安装openssh-clients</span></span><br><span class="line">RUN yum  install -y openssh-clients</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加测试用户root，密码abc.123，并且将此用户添加到sudoers里</span>  </span><br><span class="line">RUN echo &quot;root:abc.123&quot; | chpasswd  </span><br><span class="line">RUN echo &quot;root   ALL=(ALL)       ALL&quot; &gt;&gt; /etc/sudoers  </span><br><span class="line"><span class="meta">#</span><span class="bash"> 下面这两句比较特殊，</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在centos6上必须要有，否则创建出来的容器sshd不能登录</span>  </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为了避免文件已存在报错，首先删掉私钥文件</span></span><br><span class="line">RUN rm -rf /etc/ssh/ssh_host_rsa_key</span><br><span class="line">RUN rm -rf /etc/ssh/ssh_host_dsa_key</span><br><span class="line"></span><br><span class="line">RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key  </span><br><span class="line">RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key  </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动sshd服务并且暴露22端口</span>  </span><br><span class="line"><span class="meta">#</span><span class="bash"> RUN mkdir /var/run/sshd</span>  </span><br><span class="line">EXPOSE 22  </span><br><span class="line">CMD [&quot;/usr/sbin/sshd&quot;, &quot;-D&quot;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>创建镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在Dockerfile同级目录下执行下面的命令，最后的.必须有</span></span><br><span class="line">docker build -t=&quot;avery/centos-ssh-root&quot; .</span><br></pre></td></tr></table></figure>
<p>查看刚刚创建成功的镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> docker images</span></span><br><span class="line">REPOSITORY                         TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">avery/centos-ssh-root              latest              ba72ccadf508        35 hours ago        776 MB</span><br></pre></td></tr></table></figure>
<h1 id="创建带有JDK的镜像"><a href="#创建带有JDK的镜像" class="headerlink" title="创建带有JDK的镜像"></a>创建带有JDK的镜像</h1><ol>
<li>准备 下载JDK<br>此处使用JDK7u79<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> mkdir centos-ssh-root-jdk</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> <span class="built_in">cd</span> centos-ssh-root-jdk</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> cp ~/Download/jdk-7u79.tar.gz .</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> vi Dockerfile</span></span><br></pre></td></tr></table></figure></li>
<li>Dockerfile文件</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">FROM avery/centos-ssh-root</span><br><span class="line">ADD jdk-7u79.tar.gz /usr/local/</span><br><span class="line">RUN mv /usr/local/jdk1.7.0_79 /usr/local/jdk1.7</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加环境变量</span></span><br><span class="line">ENV JAVA_HOME /usr/local/jdk1.7</span><br><span class="line">ENV PATH $JAVA_HOME/bin:$PATH</span><br><span class="line"><span class="meta">#</span><span class="bash"> 可能上面的设置不会生效</span></span><br><span class="line">RUN echo &#x27;JAVA_HOME=/usr/local/jdk1.7/&#x27; &gt;&gt; .bash_profile </span><br><span class="line">RUN echo &#x27;PATH=$JAVA_HOME/bin:$PATH&#x27; &gt;&gt; .bash_profile </span><br><span class="line">RUN echo &#x27;export JAVA_HOME&#x27; &gt;&gt; .bash_profile </span><br><span class="line">RUN echo &#x27;export PATH&#x27; &gt;&gt; .bash_profile</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>创建镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker build -t=&quot;avery/centos-ssh-root&quot; .</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>查看镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> docker images</span></span><br><span class="line">REPOSITORY                         TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">avery/centos-ssh-root-jdk          latest              e773519d0452        34 hours ago        1.39 GB</span><br><span class="line">avery/centos-ssh-root              latest              ba72ccadf508        35 hours ago        776 MB</span><br></pre></td></tr></table></figure>
<h2 id="构建hadoop镜像"><a href="#构建hadoop镜像" class="headerlink" title="构建hadoop镜像"></a>构建hadoop镜像</h2><ol>
<li>准备</li>
</ol>
<p>官网下载 hadoop-2.7.3.tar.gz</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> mkdir centos-ssh-root-jdk-hadoop</span> </span><br><span class="line"><span class="meta">%</span><span class="bash"> <span class="built_in">cd</span> centos-ssh-root-jdk-hadoop</span> </span><br><span class="line"><span class="meta">%</span><span class="bash"> cp ../hadoop-2.7.3.tar.gz .</span> </span><br><span class="line"><span class="meta">%</span><span class="bash"> vi Dockerfile</span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>Dockerfile</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">FROM avery/centos-ssh-root-jdk</span><br><span class="line">ADD hadoop-2.7.3.tar.gz /usr/local</span><br><span class="line">RUN mv /usr/local/hadoop-2.7.3 usr/local/hadoop</span><br><span class="line">ENV HADOOP_HOME /usr/local/hadoop</span><br><span class="line">ENV PATH $HADOOP_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为了防止环境变量失效</span></span><br><span class="line">RUN  echo &#x27;HADOOP_HOME=/usr/local/hadoop/&#x27; &gt;&gt;.bash_profile</span><br><span class="line">RUN  echo &#x27;PATH=$HADOOP_HOME/bin:$PATH&#x27; &gt;&gt; .bash_profile </span><br><span class="line">RUN  echo &#x27;export HADOOP_HOME&#x27; &gt;&gt; .bash_profile</span><br><span class="line">RUN  echo &#x27;export PATH&#x27; &gt;&gt; .bash_profile</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>创建镜像<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker build -t=&quot;avery/centos-ssh-root-jdk-hadoop&quot; .</span><br></pre></td></tr></table></figure></li>
<li>查看</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> docker images</span></span><br><span class="line">REPOSITORY                         TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">avery/centos-ssh-root-jdk-hadoop   latest              c93aadf2b6c5        1 hours ago        2.05 GB</span><br><span class="line">avery/centos-ssh-root-jdk          latest              e773519d0452        1 hours ago        1.39 GB</span><br><span class="line">avery/centos-ssh-root              latest              ba72ccadf508        1 hours ago        776 MB</span><br></pre></td></tr></table></figure>
<h1 id="docker-搭建-Hadoop集群"><a href="#docker-搭建-Hadoop集群" class="headerlink" title="docker 搭建 Hadoop集群"></a>docker 搭建 Hadoop集群</h1><p>此处搭建的集群只在本机使用，各个Docker container没有独立的ip，如需要通过IP访问可以参考<a href="http://blog.csdn.net/xu470438000/article/details/50512442">使用docker搭建hadoop分布式集群</a></p>
<p>在MacOS上修改系统文件，需要关闭Rootless:</p>
<p>重启按住 Command+R，进入恢复模式，打开Terminal。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">csrutil disable</span><br></pre></td></tr></table></figure>
<p>重启即可。如果要恢复默认，那么</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">csrutil enable</span><br></pre></td></tr></table></figure>

<h2 id="创建3台container"><a href="#创建3台container" class="headerlink" title="创建3台container"></a>创建3台container</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name hadoop0 --hostname hadoop0 -d -P -p 50070:50070 -p 8088:8088 avery/centos-ssh-root-jdk-hadoop</span><br><span class="line"></span><br><span class="line">docker run --name hadoop1 --hostname hadoop1 -d -P avery/centos-ssh-root-jdk-hadoop</span><br><span class="line"></span><br><span class="line">docker run --name hadoop2 --hostname hadoop2 -d -P avery/centos-ssh-root-jdk-hadoop</span><br></pre></td></tr></table></figure>
<p>查看三个container的信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container ls</span><br><span class="line">CONTAINER ID        IMAGE                              COMMAND               CREATED             STATUS              PORTS                                                                     NAMES</span><br><span class="line">78e5e35adfa4        avery/centos-ssh-root-jdk-hadoop   &quot;/usr/sbin/sshd -D&quot;   3 minutes ago       Up 3 minutes        0.0.0.0:32776-&gt;22/tcp                                                     hadoop2</span><br><span class="line">5f27fd91c7ba        avery/centos-ssh-root-jdk-hadoop   &quot;/usr/sbin/sshd -D&quot;   3 minutes ago       Up 3 minutes        0.0.0.0:32775-&gt;22/tcp                                                     hadoop1</span><br><span class="line">1d7fd37371cc        avery/centos-ssh-root-jdk-hadoop   &quot;/usr/sbin/sshd -D&quot;   3 minutes ago       Up 3 minutes        0.0.0.0:8088-&gt;8088/tcp, 0.0.0.0:50070-&gt;50070/tcp, 0.0.0.0:32774-&gt;22/tcp   hadoop0</span><br></pre></td></tr></table></figure>
<p>查看三个container的ip:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> hadoop0</span></span><br><span class="line">172.17.0.2</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> hadoop1</span></span><br><span class="line">172.17.0.3</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> hadoop2</span></span><br><span class="line">172.17.0.4</span><br></pre></td></tr></table></figure>

<h2 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h2><p>准备搭建一个具有三个节点的集群，一主两从 </p>
<ul>
<li>主节点：hadoop0 ip：172.17.0.2</li>
<li>从节点1：hadoop1 ip：172.17.0.3</li>
<li>从节点2：hadoop2 ip：172.17.0.4</li>
</ul>
<h2 id="连接container"><a href="#连接container" class="headerlink" title="连接container"></a>连接container</h2><p>验证ssh连接</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> ssh root@localhost -p 32774</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入密码 abc.123</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> ssh root@localhost -p 32775</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入密码 abc.123</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> ssh root@localhost -p 32776</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入密码 abc.123</span></span><br></pre></td></tr></table></figure>
<p>使用exec</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it hadoop0 /bin/bash</span><br></pre></td></tr></table></figure>

<h2 id="修改container的主机名"><a href="#修改container的主机名" class="headerlink" title="修改container的主机名"></a>修改container的主机名</h2><p>分别修改三个container的hosts</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/hosts </span><br></pre></td></tr></table></figure>
<p>添加下面配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">172.17.0.2    hadoop0</span><br><span class="line">172.17.0.3    hadoop1</span><br><span class="line">172.17.0.4    hadoop2</span><br></pre></td></tr></table></figure>
<h2 id="ssh-免密"><a href="#ssh-免密" class="headerlink" title="ssh 免密"></a>ssh 免密</h2><p>设置ssh免密码登录<br>在hadoop0上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">mkdir .ssh</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i hadoop0</span><br><span class="line">ssh-copy-id -i hadoop1</span><br><span class="line">ssh-copy-id -i hadoop2</span><br></pre></td></tr></table></figure>
<p>在hadoop1上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i hadoop1</span><br></pre></td></tr></table></figure>
<p>在hadoop2上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i hadoop2</span><br></pre></td></tr></table></figure>
<p>至此，Docker搭建Hadoop集群的准备工作</p>
<hr>
<p>【参考文献】</p>
<ol>
<li><a href="http://blog.csdn.net/xu470438000/article/details/50512442">使用docker搭建hadoop分布式集群</a></li>
</ol>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>在Docker上搭建Yarn集群和HDFS集群</title>
    <url>/bigdata/docker/yarn-docker/</url>
    <content><![CDATA[<p>yarn作为目前最流行的分布式计算资源管理平台，为Hadoop MR、spark、Flink等提供了资源容器</p>
<h2 id="Docker-File"><a href="#Docker-File" class="headerlink" title="Docker File"></a>Docker File</h2><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 基础镜像</span></span><br><span class="line"><span class="keyword">FROM</span> hub.c.<span class="number">163</span>.com/public/centos</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum clean all</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y yum-plugin-ovl || <span class="literal">true</span></span></span><br><span class="line"><span class="comment"># 安装基础的工具包</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y vim tar wget curl rsync bzip2 iptables tcpdump less telnet net-tools lsof sysstat cronie python-setuptools</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum clean all</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">22</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /etc/supervisor/conf.d/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> [include] &gt;&gt; /etc/supervisord.conf</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&#x27;files = /etc/supervisor/conf.d/*.conf&#x27;</span> &gt;&gt; /etc/supervisord.conf</span></span><br><span class="line"><span class="comment">#COPY sshd.conf /etc/supervisor/conf.d/sshd.conf</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/usr/bin/supervisord&quot;</span>]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像的作者  </span></span><br><span class="line"><span class="keyword">MAINTAINER</span> averyzhang</span><br><span class="line"><span class="comment"># 安装openssh-server和sudo软件包，并且将sshd的UsePAM参数设置成no  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y openssh-server sudo  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">&#x27;s/UsePAM yes/UsePAM no/g&#x27;</span> /etc/ssh/sshd_config  </span></span><br><span class="line"><span class="comment">#安装openssh-clients</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum  install -y openssh-clients</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加测试用户root，密码abc.123，并且将此用户添加到sudoers里  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;root:abc.123&quot;</span> | chpasswd  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;root   ALL=(ALL)       ALL&quot;</span> &gt;&gt; /etc/sudoers  </span></span><br><span class="line"><span class="comment"># 下面这两句比较特殊，</span></span><br><span class="line"><span class="comment"># 在centos6上必须要有，否则创建出来的容器sshd不能登录  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了避免文件已存在报错，首先删掉私钥文件</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /etc/ssh/ssh_host_rsa_key</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /etc/ssh/ssh_host_dsa_key</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动sshd服务并且暴露22端口  </span></span><br><span class="line"><span class="comment"># RUN mkdir /var/run/sshd  </span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">22</span>  </span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/usr/sbin/sshd&quot;</span>, <span class="string">&quot;-D&quot;</span>]</span></span><br><span class="line"><span class="comment">###### 以上建立centos-ssh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装java</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel.x86_64</span></span><br><span class="line"><span class="comment">## 添加环境变量</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME /usr/lib/jvm/jre-openjdk/</span><br><span class="line"><span class="keyword">ENV</span> JRE_HOME $&#123;JAVA_HOME&#125;</span><br><span class="line"><span class="keyword">ENV</span> PATH $JAVA_HOME/bin:$PATH</span><br><span class="line"><span class="keyword">ENV</span> CLASSPATH $CLASSPATH:.:$JAVA_HOME/lib</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export JAVA_HOME=/usr/lib/jvm/jre-openjdk/&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export JRE_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span>&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span>&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export CLASSPATH=<span class="variable">$CLASSPATH</span>:.:<span class="variable">$JAVA_HOME</span>/lib&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装scala</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /data/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://downloads.lightbend.com/scala/2.10.7/scala-2.10.7.rpm</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y scala-2.10.7.rpm</span></span><br><span class="line"><span class="keyword">ENV</span> SCALA_HOME /usr/share/java</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export SCALA_HOME=/usr/share/java&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装Hadoop</span></span><br><span class="line"><span class="comment">## RUN wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> hadoop-2.7.7.tar /data/hadoop</span></span><br><span class="line"><span class="comment"># RUN tar zxvf /data/hadoop-2.7.7.tar -C /data/hadoop</span></span><br><span class="line"><span class="comment"># RUN ln -s /data/hadoop-2.7.7 /data/hadoop</span></span><br><span class="line"><span class="keyword">ENV</span> HADOOP_HOME /data/hadoop</span><br><span class="line"><span class="keyword">ENV</span> HADOOP_CONF_DIR $&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line"><span class="keyword">ENV</span> YARN_HOME $&#123;HADOOP_HOME&#125;</span><br><span class="line"><span class="keyword">ENV</span> YARN_CONF_DIR $&#123;YARN_HOME&#125;/etc/hadoop</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export HADOOP_HOME=/data/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export YARN_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export YARN_CONF_DIR=<span class="variable">$&#123;YARN_HOME&#125;</span>/etc/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br></pre></td></tr></table></figure>
<h2 id="制作image"><a href="#制作image" class="headerlink" title="制作image"></a>制作image</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker build -t=&quot;avery/centos-yarn&quot; .</span><br></pre></td></tr></table></figure>
<h2 id="创建yarn节点"><a href="#创建yarn节点" class="headerlink" title="创建yarn节点"></a>创建yarn节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name yarn0 --hostname yarn0 -d -P -p 50070:50070 -p 8088:8088 avery/centos-yarn</span><br><span class="line">docker run --name yarn1 --hostname yarn1 -d -P avery/centos-yarn</span><br><span class="line">docker run --name yarn2 --hostname yarn2 -d -P avery/centos-yarn</span><br><span class="line">docker run --name yarn3 --hostname yarn3 -d -P avery/centos-yarn</span><br></pre></td></tr></table></figure>
<p>查看三个container的ip:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn0</span></span><br><span class="line">172.17.0.2</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn1</span></span><br><span class="line">172.17.0.3</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn2</span></span><br><span class="line">172.17.0.4</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn3</span></span><br><span class="line">172.17.0.5</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>节点</th>
<th>备注</th>
<th>ip</th>
</tr>
</thead>
<tbody><tr>
<td>yarn0</td>
<td>master</td>
<td>172.17.0.2</td>
</tr>
<tr>
<td>yarn1</td>
<td>slaver</td>
<td>172.17.0.3</td>
</tr>
<tr>
<td>yarn2</td>
<td>slaver</td>
<td>172.17.0.4</td>
</tr>
<tr>
<td>yarn3</td>
<td>slaver</td>
<td>172.17.0.5</td>
</tr>
</tbody></table>
<p>查看端口</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container ls -a                                        </span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS                                                                     NAMES</span><br><span class="line">e150f9141cbd        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32771-&gt;22/tcp                                                     yarn3</span><br><span class="line">9fe0eb86b3e9        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32770-&gt;22/tcp                                                     yarn2</span><br><span class="line">1d5c0ea3d3b3        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32769-&gt;22/tcp                                                     yarn1</span><br><span class="line">60a9cb47ff0c        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:8088-&gt;8088/tcp, 0.0.0.0:50070-&gt;50070/tcp, 0.0.0.0:32768-&gt;22/tcp   yarn0</span><br></pre></td></tr></table></figure>


<h2 id="连接container"><a href="#连接container" class="headerlink" title="连接container"></a>连接container</h2><p>验证ssh连接</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> ssh root@localhost -p 32774</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入密码 abc.123</span></span><br></pre></td></tr></table></figure>
<p>使用exec</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it yarn0 /bin/bash</span><br></pre></td></tr></table></figure>

<h2 id="修改container的主机名"><a href="#修改container的主机名" class="headerlink" title="修改container的主机名"></a>修改container的主机名</h2><p>分别修改三个container的hosts</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/hosts </span><br></pre></td></tr></table></figure>
<p>添加下面配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">172.17.0.2      yarn0</span><br><span class="line">172.17.0.3      yarn1</span><br><span class="line">172.17.0.4      yarn2</span><br><span class="line">172.17.0.5      yarn3</span><br></pre></td></tr></table></figure>
<h2 id="ssh-免密"><a href="#ssh-免密" class="headerlink" title="ssh 免密"></a>ssh 免密</h2><p>设置ssh免密码登录<br>在yarn0上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">mkdir .ssh</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn0</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>在yarn1上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>在yarn2上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn0</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>至此，Docker搭建Hadoop集群的准备工作</p>
<h2 id="Hadoop-安装"><a href="#Hadoop-安装" class="headerlink" title="Hadoop 安装"></a>Hadoop 安装</h2><p>登录yarn0，修改Hadoop配置</p>
<p>配置 Hadoop，cd  ~/hadoop-2.7.2/etc/hadoop进入hadoop配置目录，需要配置有以下7个文件：hadoop-env.sh，yarn-env.sh，slaves，core-site.xml，hdfs-site.xml，maprd-site.xml，yarn-site.xml。</p>
<p>在hadoop-env.sh中配置JAVA_HOME</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The java implementation to use.</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_77</span><br></pre></td></tr></table></figure>
<p>在yarn-env.sh中配置JAVA_HOME</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> some Java parameters</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_77</span><br></pre></td></tr></table></figure>
<p>在slaves中配置slave节点的ip或者host，</p>
<p>yarn1<br>yarn2<br>yarn3</p>
<p>修改core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://yarn0:9000/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang//hadoop-2.7.2/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn0:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang/hadoop-2.7.2/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang/hadoop-2.7.2/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改yarn-site.xml</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8032&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8030&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8035&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8033&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8088&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>将配置好的hadoop-2.7.2文件夹分发给所有slaves节点</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r hadoop/* root@yarn1:/data/hadoop</span><br><span class="line">scp -r hadoop/* root@yarn2:/data/hadoop</span><br><span class="line">scp -r hadoop/* root@yarn3:/data/hadoop</span><br></pre></td></tr></table></figure>
<h2 id="启动HDFS和yarn"><a href="#启动HDFS和yarn" class="headerlink" title="启动HDFS和yarn"></a>启动HDFS和yarn</h2><p>格式化HDFS</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/hadoop namenode -format    #格式化namenode</span><br><span class="line">注：若格式化之后重新修改了配置文件，重新格式化之前需要删除tmp，dfs，logs文件夹。</span><br><span class="line">sbin/start-dfs.sh              #启动dfs </span><br><span class="line">sbin/start-yarn.sh              #启动yarn</span><br></pre></td></tr></table></figure>
<p>检查</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">[root@yarn0 hadoop]# jps</span><br><span class="line">709 ResourceManager</span><br><span class="line">984 Jps</span><br><span class="line">346 NameNode</span><br><span class="line">543 SecondaryNameNode</span><br><span class="line">[root@yarn0 hadoop]# ssh yarn1</span><br><span class="line">Last login: Sun Jun  2 23:21:51 2019 from yarn0</span><br><span class="line">[root@yarn1 ~]# jps</span><br><span class="line">305 NodeManager</span><br><span class="line">449 Jps</span><br><span class="line">200 DataNode</span><br><span class="line">[root@yarn1 ~]# ssh yarn2</span><br><span class="line">Last login: Sun Jun  2 23:22:18 2019 from yarn0</span><br><span class="line">[root@yarn2 ~]# jps</span><br><span class="line">193 DataNode</span><br><span class="line">442 Jps</span><br><span class="line">298 NodeManager</span><br><span class="line">[root@yarn2 ~]# ssh yarn3</span><br><span class="line">Last login: Sun Jun  2 23:22:25 2019 from yarn0</span><br><span class="line">[root@yarn3 ~]# jps</span><br><span class="line">178 DataNode</span><br><span class="line">283 NodeManager</span><br><span class="line">427 Jps</span><br></pre></td></tr></table></figure>
<p>yarn web</p>
<p>浏览器打开 <a href="http://localhost:8088/">http://localhost:8088</a></p>
<p><img src="/images/distributed/docker/docker-yarn-web.png"></p>
<p>搞定收工</p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
        <tag>Docker</tag>
        <tag>yarn</tag>
      </tags>
  </entry>
  <entry>
    <title>Doris</title>
    <url>/bigdata/doris/Doris(AVERYZHANG-MB1%E7%9A%84%E5%86%B2%E7%AA%81%E7%89%88%E6%9C%AC)/</url>
    <content><![CDATA[<h1 id="Doris"><a href="#Doris" class="headerlink" title="Doris"></a>Doris</h1><p>参考文献:</p>
<p><a href="https://blog.bcmeng.com/post/doris-bitmap.html">Apache Doris 基于 Bitmap的精确去重和用户行为分析</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Doris</tag>
      </tags>
  </entry>
  <entry>
    <title>Doris</title>
    <url>/bigdata/doris/Doris/</url>
    <content><![CDATA[<h1 id="Doris"><a href="#Doris" class="headerlink" title="Doris"></a>Doris</h1><p>参考文献:</p>
<p><a href="https://blog.bcmeng.com/post/doris-bitmap.html">Apache Doris 基于 Bitmap的精确去重和用户行为分析</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Doris</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo基础</title>
    <url>/bigdata/dubbo/base/</url>
    <content><![CDATA[<h1 id="Dubbo-分布式服务治理框架"><a href="#Dubbo-分布式服务治理框架" class="headerlink" title="Dubbo-分布式服务治理框架"></a>Dubbo-分布式服务治理框架</h1><blockquote>
<p>学习dubbo教程 笔记整理</p>
<p><a href="http://dubbo.io/Developer+Guide-zh.htm">Dubbo官方文档</a></p>
</blockquote>
<p>关键词：分布式治理</p>
<p>Dubbo是阿里巴巴推出的一款分布式服务治理框架（虽然现在阿里内部一些部门已经不再使用）。</p>
<p>Dubbo将分布式服务分为四个角色：服务提供者、服务消费者、注册中心和监控中心。</p>
<h1 id="Dubbo角色"><a href="#Dubbo角色" class="headerlink" title="Dubbo角色"></a>Dubbo角色</h1><p>![][dubbo-roles]</p>
<ol>
<li>服务提供者注册到服务注册中心</li>
<li>服务消费者从服务提供者订阅服务</li>
<li>当服务提供者发生变化（出现新服务提供者、旧的服务提供者死掉等），注册中心通知服务消费者</li>
<li>当服务消费者调用服务时，首先从注册中心查找服务，注册中心直接将选定的服务提供者的ip和端口等信息返回给服务消费者，服务消费者直接调用服务提供者</li>
<li>服务提供者和服务消费者每个一分钟将收集的运行信息上报到监控中心</li>
</ol>
<p>只有服务消费者调用服务生成者是同步调用，其他都是异步的。</p>
<p>Provider与Registry、Consumer与Register之间都保持着长连接，用于保持信息同步</p>
<h1 id="简洁的项目结构"><a href="#简洁的项目结构" class="headerlink" title="简洁的项目结构"></a>简洁的项目结构</h1><h1 id="Dubbo支持的RPC协议"><a href="#Dubbo支持的RPC协议" class="headerlink" title="Dubbo支持的RPC协议"></a>Dubbo支持的RPC协议</h1><ol>
<li>支持常见的传输协议：RMI、Dubbo、Hessain、WebService、Http等，<br> 其中Dubbo和RMI协议基于TCP实现，Hessian和WebService基于HTTP实现。</li>
<li>传输框架：Netty、Mina、以及基于servlet等方式。</li>
<li>序列化方式：Hessian2、dubbo、JSON（ fastjson 实现）、JAVA、SOAP 等。</li>
<li>注册中心可以选择 zooKeeper Redis Dubbo Multicast</li>
</ol>
<h1 id="Dubbo-服务降级"><a href="#Dubbo-服务降级" class="headerlink" title="Dubbo 服务降级"></a>Dubbo 服务降级</h1><p><a href="http://blog.csdn.net/zuoanyinxiang/article/details/51027576">Dubbo学习(七)：服务的升级和降级</a></p>
<p>服务降级方式：</p>
<ul>
<li>服务接口拒绝服务：无用户特定信息，页面能访问，但是添加删除提示服务器繁忙。页面内容也可在Varnish或CDN内获取。</li>
<li>页面拒绝服务：页面提示由于服务繁忙此服务暂停。跳转到varnish或nginx的一个静态页面。</li>
<li>延迟持久化：页面访问照常，但是涉及记录变更，会提示稍晚能看到结果，将数据记录到异步队列或log，服务恢复后执行。</li>
<li>随机拒绝服务：服务接口随机拒绝服务，让用户重试，目前较少有人采用。因为用户体验不佳。</li>
</ul>
<p>服务降级埋点的地方：</p>
<ul>
<li>消息中间件：所有API调用可以使用消息中间件进行控制</li>
<li>前端页面：指定网址不可访问（NGINX+LUA）</li>
<li>底层数据驱动：拒绝所有增删改动作，只允许查询</li>
</ul>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive base</title>
    <url>/bigdata/hive/base/</url>
    <content><![CDATA[<h1 id="base"><a href="#base" class="headerlink" title="base"></a>base</h1>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive SQL优化样例</title>
    <url>/bigdata/hive/hive-sample/</url>
    <content><![CDATA[<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+ MAPJOIN(hj3,hj1,hj0)*/</span> <span class="number">20210324</span> <span class="keyword">as</span> fdate, TO_CHAR(SYSTIMESTAMP(), <span class="string">&#x27;yyyymmddhh24miss&#x27;</span>) <span class="keyword">as</span> fetl_time,hj2.fuin <span class="keyword">as</span> fuin,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span>(SUBSTR(<span class="built_in">CAST</span>(if (((hj2.fevent_time <span class="keyword">between</span> <span class="number">20210318000000</span> <span class="keyword">and</span> <span class="number">20210324235959</span>) <span class="keyword">and</span> (hj2.fscn <span class="keyword">in</span> (<span class="string">&#x27;1&#x27;</span>))) , hj2.fevent_time, <span class="keyword">null</span>) <span class="keyword">AS</span> STRING),<span class="number">1</span>,<span class="number">8</span>))) <span class="keyword">as</span> flabel_25942,   <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span>(SUBSTR(<span class="built_in">CAST</span>(if (((hj2.fevent_time <span class="keyword">between</span> <span class="number">20210318000000</span> <span class="keyword">and</span> <span class="number">20210324235959</span>)  <span class="keyword">and</span> (hj2.fscn <span class="keyword">in</span> (<span class="string">&#x27;1&#x27;</span>))) , hj2.fevent_time, <span class="keyword">null</span>) <span class="keyword">AS</span> STRING),<span class="number">1</span>,<span class="number">8</span>))) <span class="keyword">as</span> flabel_25970, <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span>(SUBSTR(<span class="built_in">CAST</span>(if (((hj2.furl_orig <span class="operator">=</span> <span class="string">&#x27;/mb/v5/fund/list/steady.shtml&#x27;</span>)  <span class="keyword">or</span> (hj2.furl_orig <span class="operator">=</span> <span class="string">&#x27;/mb/v4/fundlist/fund_all.shtml&#x27;</span>)    <span class="keyword">or</span> (hj2.furl_orig <span class="operator">=</span> <span class="string">&#x27;/mb/v4/fundlist/fund_all_v5.shtml&#x27;</span>))  <span class="keyword">and</span> ((hj2.fevent_time <span class="keyword">between</span> <span class="number">20210318000000</span> <span class="keyword">and</span> <span class="number">20210324235959</span>)) , hj2.fevent_time, <span class="keyword">null</span>) <span class="keyword">AS</span> STRING),<span class="number">1</span>,<span class="number">8</span>))) <span class="keyword">as</span> flabel_25972</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> dml_base::dml_evt_lct_cft_label_factory_mta_access_dd hj2</span><br><span class="line"></span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> dim_base::dim_lct_hq_beacon_report_manage hj1 <span class="keyword">on</span> if(hj2.furl_orig <span class="keyword">is</span> <span class="keyword">null</span></span><br><span class="line">                                                              <span class="keyword">or</span> <span class="built_in">trim</span>(hj2.furl_orig) <span class="operator">=</span> <span class="string">&#x27;&#x27;</span>, concat(<span class="string">&#x27;null_&#x27;</span>, <span class="built_in">floor</span>(rand() <span class="operator">*</span> <span class="number">10000</span>)), hj2.furl_orig) <span class="operator">=</span> hj1.fevent_code</span><br><span class="line"></span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> dim_base::dim_lct_hq_virtual_event_info hj3 <span class="keyword">on</span> if(hj2.furl_orig <span class="keyword">is</span> <span class="keyword">null</span></span><br><span class="line">                                                      <span class="keyword">or</span> <span class="built_in">trim</span>(hj2.furl_orig) <span class="operator">=</span> <span class="string">&#x27;&#x27;</span>, concat(<span class="string">&#x27;null_&#x27;</span>, <span class="built_in">floor</span>(rand() <span class="operator">*</span> <span class="number">10000</span>)), hj2.furl_orig) <span class="operator">=</span> hj3.fevent_code</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> dim_base::dim_prd_lct_cft_fund_type_conf hj0 <span class="keyword">on</span> if(hj2.fspid_fundcode <span class="keyword">is</span> <span class="keyword">null</span></span><br><span class="line">                                                             <span class="keyword">or</span> <span class="built_in">trim</span>(hj2.fspid_fundcode) <span class="operator">=</span> <span class="string">&#x27;&#x27;</span>, concat(<span class="string">&#x27;null_&#x27;</span>, <span class="built_in">floor</span>(rand() <span class="operator">*</span> <span class="number">10000</span>)), hj2.fspid_fundcode) <span class="operator">=</span> hj0.fspid_fundcode</span><br><span class="line"></span><br><span class="line"><span class="keyword">where</span> hj2.fuin <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">and</span> <span class="built_in">trim</span>(hj2.fuin) <span class="operator">&lt;&gt;</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">and</span> hj2.fdate <span class="operator">&gt;=</span> <span class="number">20210318</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">and</span> hj2.fdate <span class="operator">&lt;=</span> <span class="number">20210324</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> hj2.fuin</span><br></pre></td></tr></table></figure>




<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ABSTRACT SYNTAX TREE:</span><br><span class="line">  (TOK_QUERY (TOK_FROM (TOK_LEFTOUTERJOIN (TOK_LEFTOUTERJOIN (TOK_LEFTOUTERJOIN (TOK_TABREF (TOK_TAB dml_evt_lct_cft_label_factory_mta_access_dd dml_base) hj2) (TOK_TABREF (TOK_TAB dim_lct_hq_beacon_report_manage dim_base) hj1) (= (<span class="function">TOK_FUNCTION <span class="title">if</span> <span class="params">(or (TOK_FUNCTION TOK_ISNULL (. (TOK_TABLE_OR_COL hj2)</span> furl_orig)) <span class="params">(= (TOK_FUNCTION trim (. (TOK_TABLE_OR_COL hj2)</span> furl_orig)) &#x27;&#x27;)) <span class="params">(TOK_FUNCTION concat <span class="string">&#x27;null_&#x27;</span> (TOK_FUNCTION floor (* (TOK_FUNCTION rand)</span> 10000))) <span class="params">(. (TOK_TABLE_OR_COL hj2)</span> furl_orig)) <span class="params">(. (TOK_TABLE_OR_COL hj1)</span> fevent_code))) <span class="params">(TOK_TABREF (TOK_TAB dim_lct_hq_virtual_event_info dim_base)</span> hj3) <span class="params">(= (TOK_FUNCTION <span class="keyword">if</span> (or (TOK_FUNCTION TOK_ISNULL (. (TOK_TABLE_OR_COL hj2)</span> furl_orig)) <span class="params">(= (TOK_FUNCTION trim (. (TOK_TABLE_OR_COL hj2)</span> furl_orig)) &#x27;&#x27;)) <span class="params">(TOK_FUNCTION concat <span class="string">&#x27;null_&#x27;</span> (TOK_FUNCTION floor (* (TOK_FUNCTION rand)</span> 10000))) <span class="params">(. (TOK_TABLE_OR_COL hj2)</span> furl_orig)) <span class="params">(. (TOK_TABLE_OR_COL hj3)</span> fevent_code))) <span class="params">(TOK_TABREF (TOK_TAB dim_prd_lct_cft_fund_type_conf dim_base)</span> hj0) <span class="params">(= (TOK_FUNCTION <span class="keyword">if</span> (or (TOK_FUNCTION TOK_ISNULL (. (TOK_TABLE_OR_COL hj2)</span> fspid_fundcode)) <span class="params">(= (TOK_FUNCTION trim (. (TOK_TABLE_OR_COL hj2)</span> fspid_fundcode)) &#x27;&#x27;)) <span class="params">(TOK_FUNCTION concat <span class="string">&#x27;null_&#x27;</span> (TOK_FUNCTION floor (* (TOK_FUNCTION rand)</span> 10000))) <span class="params">(. (TOK_TABLE_OR_COL hj2)</span> fspid_fundcode)) <span class="params">(. (TOK_TABLE_OR_COL hj0)</span> fspid_fundcode)))) <span class="params">(TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)</span>) <span class="params">(TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST (TOK_TABLE_OR_COL hj3)</span> <span class="params">(TOK_TABLE_OR_COL hj1)</span> <span class="params">(TOK_TABLE_OR_COL hj0)</span>))) <span class="params">(TOK_SELEXPR <span class="number">20210324</span> fdate)</span> <span class="params">(TOK_SELEXPR (TOK_FUNCTION TO_CHAR (TOK_FUNCTION SYSTIMESTAMP)</span> &#x27;yyyymmddhh24miss&#x27;) fetl_time) <span class="params">(TOK_SELEXPR (. (TOK_TABLE_OR_COL hj2)</span> fuin) fuin) <span class="params">(TOK_SELEXPR (TOK_FUNCTIONDI COUNT (TOK_FUNCTION SUBSTR (TOK_FUNCTION TOK_STRING (TOK_FUNCTION <span class="keyword">if</span> (and (and (&gt;= (. (TOK_TABLE_OR_COL hj2)</span> fevent_time) 20210318000000) <span class="params">(&lt;= (. (TOK_TABLE_OR_COL hj2)</span> fevent_time) 20210324235959)) <span class="params">(in (. (TOK_TABLE_OR_COL hj2)</span> fscn) &#x27;1&#x27;)) <span class="params">(. (TOK_TABLE_OR_COL hj2)</span> fevent_time) TOK_NULL)) 1 8)) flabel_25942) <span class="params">(TOK_SELEXPR (TOK_FUNCTIONDI COUNT (TOK_FUNCTION SUBSTR (TOK_FUNCTION TOK_STRING (TOK_FUNCTION <span class="keyword">if</span> (and (and (&gt;= (. (TOK_TABLE_OR_COL hj2)</span> fevent_time) 20210318000000) <span class="params">(&lt;= (. (TOK_TABLE_OR_COL hj2)</span> fevent_time) 20210324235959)) <span class="params">(in (. (TOK_TABLE_OR_COL hj2)</span> fscn) &#x27;1&#x27;)) <span class="params">(. (TOK_TABLE_OR_COL hj2)</span> fevent_time) TOK_NULL)) 1 8)) flabel_25970) <span class="params">(TOK_SELEXPR (TOK_FUNCTIONDI COUNT (TOK_FUNCTION SUBSTR (TOK_FUNCTION TOK_STRING (TOK_FUNCTION <span class="keyword">if</span> (and (or (or (= (. (TOK_TABLE_OR_COL hj2)</span> furl_orig) &#x27;/mb/v5/fund/list/steady.shtml&#x27;) <span class="params">(= (. (TOK_TABLE_OR_COL hj2)</span> furl_orig) &#x27;/mb/v4/fundlist/fund_all.shtml&#x27;)) <span class="params">(= (. (TOK_TABLE_OR_COL hj2)</span> furl_orig) &#x27;/mb/v4/fundlist/fund_all_v5.shtml&#x27;)) <span class="params">(and (&gt;= (. (TOK_TABLE_OR_COL hj2)</span> fevent_time) 20210318000000) <span class="params">(&lt;= (. (TOK_TABLE_OR_COL hj2)</span> fevent_time) 20210324235959))) <span class="params">(. (TOK_TABLE_OR_COL hj2)</span> fevent_time) TOK_NULL)) 1 8)) flabel_25972)) <span class="params">(TOK_WHERE (and (and (and (TOK_FUNCTION TOK_ISNOTNULL (. (TOK_TABLE_OR_COL hj2)</span> fuin)) <span class="params">(&lt;&gt; (TOK_FUNCTION trim (. (TOK_TABLE_OR_COL hj2)</span> fuin)) &#x27;&#x27;)) <span class="params">(&gt;= (. (TOK_TABLE_OR_COL hj2)</span> fdate) 20210318)) <span class="params">(&lt;= (. (TOK_TABLE_OR_COL hj2)</span> fdate) 20210324))) <span class="params">(TOK_GROUPBY (. (TOK_TABLE_OR_COL hj2)</span> fuin))))</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">STAGE DEPENDENCIES:</span></span><br><span class="line"><span class="function">  Stage-1</span></span><br><span class="line"><span class="function">    type:root stage</span>;</span><br><span class="line">  Stage-<span class="number">2</span></span><br><span class="line">    type:;depends on:Stage-<span class="number">1</span>;</span><br><span class="line">  Stage-<span class="number">3</span></span><br><span class="line">    type:;depends on:Stage-<span class="number">2</span>;</span><br><span class="line">  Stage-<span class="number">0</span></span><br><span class="line">    type:root stage;</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-<span class="number">1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Alias -&gt; Map Operator Tree:</span><br><span class="line">        dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2 </span><br><span class="line">          Operator:          TableScan</span><br><span class="line">            alias: dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2</span><br><span class="line">            Operator:            Filter Operator</span><br><span class="line">              predicate:</span><br><span class="line">                  expr: (((<span class="function">fuin is not <span class="keyword">null</span> <span class="title">and</span> <span class="params">(trim(fuin)</span> &lt;&gt; &#x27;&#x27;)) <span class="title">and</span> <span class="params">(fdate &gt;= <span class="number">20210318</span>)</span>) <span class="title">and</span> <span class="params">(fdate &lt;= <span class="number">20210324</span>)</span>)</span></span><br><span class="line"><span class="function">                  type: <span class="keyword">boolean</span></span></span><br><span class="line"><span class="function">              Operator:              Common Join Operator</span></span><br><span class="line"><span class="function">                condition map:</span></span><br><span class="line"><span class="function">                     Left Outer Join0 to 1</span></span><br><span class="line"><span class="function">                     Left Outer Join0 to 2</span></span><br><span class="line"><span class="function">                condition expressions:</span></span><br><span class="line"><span class="function">                  0 </span>&#123;fdate&#125; &#123;fuin&#125; &#123;furl_orig&#125; &#123;fevent_time&#125; &#123;fspid_fundcode&#125; &#123;fscn&#125;</span><br><span class="line">                  <span class="number">1</span> </span><br><span class="line">                  <span class="number">2</span> </span><br><span class="line">                handleSkewJoin: <span class="keyword">false</span></span><br><span class="line">                keys:</span><br><span class="line">                  0 [class com.tencent.tdw_udf_cloud.hive.udf.generic.GenericUDFIf(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNull(Column[furl_orig](), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Column[furl_orig](), Const string ()(), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Const string null_, class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge((), Const int 10000()()(), Column[furl_orig]()]</span><br><span class="line">                  <span class="number">1</span> [Column[fevent_code]]</span><br><span class="line">                  <span class="number">2</span> [Column[fevent_code]]</span><br><span class="line">                outputColumnNames: _col0, _col42, _col85, _col88, _col103, _col104</span><br><span class="line">                Position of Big Table: <span class="number">0</span></span><br><span class="line">                Operator:                File Output Operator</span><br><span class="line">                  compressed: <span class="keyword">false</span></span><br><span class="line">                  GlobalTableId: <span class="number">0</span></span><br><span class="line">                  table:</span><br><span class="line">                    table descs</span><br><span class="line">                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">      Local Work:</span><br><span class="line">        Map Reduce Local Work</span><br><span class="line">          Alias -&gt; Map Local Tables:</span><br><span class="line">            dim_base/dim_lct_hq_beacon_report_manage#hj1 </span><br><span class="line">              Fetch Operator</span><br><span class="line">                limit: -<span class="number">1</span></span><br><span class="line">            dim_base/dim_lct_hq_virtual_event_info#hj3 </span><br><span class="line">              Fetch Operator</span><br><span class="line">                limit: -<span class="number">1</span></span><br><span class="line">          Alias -&gt; Map Local Operator Tree:</span><br><span class="line">            dim_base/dim_lct_hq_beacon_report_manage#hj1 </span><br><span class="line">              Operator:              TableScan</span><br><span class="line">                alias: dim_base/dim_lct_hq_beacon_report_manage#hj1</span><br><span class="line">                Operator:                Common Join Operator</span><br><span class="line">                  condition map:</span><br><span class="line">                       Left Outer Join0 to <span class="number">1</span></span><br><span class="line">                       Left Outer Join0 to <span class="number">2</span></span><br><span class="line">                  condition expressions:</span><br><span class="line">                    <span class="number">0</span> &#123;fdate&#125; &#123;fuin&#125; &#123;furl_orig&#125; &#123;fevent_time&#125; &#123;fspid_fundcode&#125; &#123;fscn&#125;</span><br><span class="line">                    <span class="number">1</span> </span><br><span class="line">                    <span class="number">2</span> </span><br><span class="line">                  handleSkewJoin: <span class="keyword">false</span></span><br><span class="line">                  keys:</span><br><span class="line">                    0 [class com.tencent.tdw_udf_cloud.hive.udf.generic.GenericUDFIf(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNull(Column[furl_orig](), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Column[furl_orig](), Const string ()(), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Const string null_, class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge((), Const int 10000()()(), Column[furl_orig]()]</span><br><span class="line">                    <span class="number">1</span> [Column[fevent_code]]</span><br><span class="line">                    <span class="number">2</span> [Column[fevent_code]]</span><br><span class="line">                  outputColumnNames: _col0, _col42, _col85, _col88, _col103, _col104</span><br><span class="line">                  Position of Big Table: <span class="number">0</span></span><br><span class="line">                  Operator:                  File Output Operator</span><br><span class="line">                    compressed: <span class="keyword">false</span></span><br><span class="line">                    GlobalTableId: <span class="number">0</span></span><br><span class="line">                    table:</span><br><span class="line">                      table descs</span><br><span class="line">                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">            dim_base/dim_lct_hq_virtual_event_info#hj3 </span><br><span class="line">              Operator:              TableScan</span><br><span class="line">                alias: dim_base/dim_lct_hq_virtual_event_info#hj3</span><br><span class="line">                Operator:                Common Join Operator</span><br><span class="line">                  condition map:</span><br><span class="line">                       Left Outer Join0 to <span class="number">1</span></span><br><span class="line">                       Left Outer Join0 to <span class="number">2</span></span><br><span class="line">                  condition expressions:</span><br><span class="line">                    <span class="number">0</span> &#123;fdate&#125; &#123;fuin&#125; &#123;furl_orig&#125; &#123;fevent_time&#125; &#123;fspid_fundcode&#125; &#123;fscn&#125;</span><br><span class="line">                    <span class="number">1</span> </span><br><span class="line">                    <span class="number">2</span> </span><br><span class="line">                  handleSkewJoin: <span class="keyword">false</span></span><br><span class="line">                  keys:</span><br><span class="line">                    0 [class com.tencent.tdw_udf_cloud.hive.udf.generic.GenericUDFIf(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNull(Column[furl_orig](), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Column[furl_orig](), Const string ()(), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Const string null_, class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge((), Const int 10000()()(), Column[furl_orig]()]</span><br><span class="line">                    <span class="number">1</span> [Column[fevent_code]]</span><br><span class="line">                    <span class="number">2</span> [Column[fevent_code]]</span><br><span class="line">                  outputColumnNames: _col0, _col42, _col85, _col88, _col103, _col104</span><br><span class="line">                  Position of Big Table: <span class="number">0</span></span><br><span class="line">                  Operator:                  File Output Operator</span><br><span class="line">                    compressed: <span class="keyword">false</span></span><br><span class="line">                    GlobalTableId: <span class="number">0</span></span><br><span class="line">                    table:</span><br><span class="line">                      table descs</span><br><span class="line">                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">      Path -&gt; Alias:</span><br><span class="line">        hdfs:<span class="comment">//&lt;hive_hdfs_base_path&gt;/warehouse/dml_base.db/dml_evt_lct_cft_label_factory_mta_access_dd/par_20210318 [dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2]</span></span><br><span class="line">        hdfs:<span class="comment">//&lt;hive_hdfs_base_path&gt;/warehouse/dml_base.db/dml_evt_lct_cft_label_factory_mta_access_dd/par_20210319 [dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2]</span></span><br><span class="line">        hdfs:<span class="comment">//&lt;hive_hdfs_base_path&gt;/warehouse/dml_base.db/dml_evt_lct_cft_label_factory_mta_access_dd/par_20210320 [dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2]</span></span><br><span class="line">        hdfs:<span class="comment">//&lt;hive_hdfs_base_path&gt;/warehouse/dml_base.db/dml_evt_lct_cft_label_factory_mta_access_dd/par_20210321 [dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2]</span></span><br><span class="line">        hdfs:<span class="comment">//&lt;hive_hdfs_base_path&gt;/warehouse/dml_base.db/dml_evt_lct_cft_label_factory_mta_access_dd/par_20210322 [dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2]</span></span><br><span class="line">        hdfs:<span class="comment">//&lt;hive_hdfs_base_path&gt;/warehouse/dml_base.db/dml_evt_lct_cft_label_factory_mta_access_dd/par_20210323 [dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2]</span></span><br><span class="line">        hdfs:<span class="comment">//&lt;hive_hdfs_base_path&gt;/warehouse/dml_base.db/dml_evt_lct_cft_label_factory_mta_access_dd/par_20210324 [dml_base/dml_evt_lct_cft_label_factory_mta_access_dd#hj2]</span></span><br><span class="line"></span><br><span class="line">  Stage: Stage-<span class="number">2</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Alias -&gt; Map Operator Tree:</span><br><span class="line">        hdfs:<span class="comment">//&lt;tmp_hive_hdfs_base_path&gt;/20210325/&lt;hdfs_user&gt;_tdwadmin_20210325195415346_29895878_7_699597773/10002 </span></span><br><span class="line">          Operator:          Select Operator</span><br><span class="line">            expressions:</span><br><span class="line">                  expr: _col0</span><br><span class="line">                  type: bigint</span><br><span class="line">                  expr: _col42</span><br><span class="line">                  type: string</span><br><span class="line">                  expr: _col85</span><br><span class="line">                  type: string</span><br><span class="line">                  expr: _col88</span><br><span class="line">                  type: bigint</span><br><span class="line">                  expr: _col103</span><br><span class="line">                  type: string</span><br><span class="line">                  expr: _col104</span><br><span class="line">                  type: string</span><br><span class="line">            outputColumnNames: _col0, _col42, _col85, _col88, _col103, _col104</span><br><span class="line">            Operator:            Common Join Operator</span><br><span class="line">              condition map:</span><br><span class="line">                   Left Outer Join0 to <span class="number">1</span></span><br><span class="line">              condition expressions:</span><br><span class="line">                <span class="number">0</span> &#123;_col0&#125; &#123;_col42&#125; &#123;_col85&#125; &#123;_col88&#125; &#123;_col104&#125;</span><br><span class="line">                <span class="number">1</span> </span><br><span class="line">              handleSkewJoin: <span class="keyword">false</span></span><br><span class="line">              keys:</span><br><span class="line">                0 [class com.tencent.tdw_udf_cloud.hive.udf.generic.GenericUDFIf(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNull(Column[_col103](), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Column[_col103](), Const string ()(), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Const string null_, class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge((), Const int 10000()()(), Column[_col103]()]</span><br><span class="line">                <span class="number">1</span> [Column[fspid_fundcode]]</span><br><span class="line">              outputColumnNames: _col0, _col42, _col85, _col88, _col104</span><br><span class="line">              Position of Big Table: <span class="number">0</span></span><br><span class="line">              Operator:              File Output Operator</span><br><span class="line">                compressed: <span class="keyword">false</span></span><br><span class="line">                GlobalTableId: <span class="number">0</span></span><br><span class="line">                table:</span><br><span class="line">                  table descs</span><br><span class="line">                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">      Local Work:</span><br><span class="line">        Map Reduce Local Work</span><br><span class="line">          Alias -&gt; Map Local Tables:</span><br><span class="line">            dim_base/dim_prd_lct_cft_fund_type_conf#hj0 </span><br><span class="line">              Fetch Operator</span><br><span class="line">                limit: -<span class="number">1</span></span><br><span class="line">          Alias -&gt; Map Local Operator Tree:</span><br><span class="line">            dim_base/dim_prd_lct_cft_fund_type_conf#hj0 </span><br><span class="line">              Operator:              TableScan</span><br><span class="line">                alias: dim_base/dim_prd_lct_cft_fund_type_conf#hj0</span><br><span class="line">                Operator:                Common Join Operator</span><br><span class="line">                  condition map:</span><br><span class="line">                       Left Outer Join0 to <span class="number">1</span></span><br><span class="line">                  condition expressions:</span><br><span class="line">                    <span class="number">0</span> &#123;_col0&#125; &#123;_col42&#125; &#123;_col85&#125; &#123;_col88&#125; &#123;_col104&#125;</span><br><span class="line">                    <span class="number">1</span> </span><br><span class="line">                  handleSkewJoin: <span class="keyword">false</span></span><br><span class="line">                  keys:</span><br><span class="line">                    0 [class com.tencent.tdw_udf_cloud.hive.udf.generic.GenericUDFIf(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNull(Column[_col103](), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Column[_col103](), Const string ()(), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Const string null_, class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge((), Const int 10000()()(), Column[_col103]()]</span><br><span class="line">                    <span class="number">1</span> [Column[fspid_fundcode]]</span><br><span class="line">                  outputColumnNames: _col0, _col42, _col85, _col88, _col104</span><br><span class="line">                  Position of Big Table: <span class="number">0</span></span><br><span class="line">                  Operator:                  File Output Operator</span><br><span class="line">                    compressed: <span class="keyword">false</span></span><br><span class="line">                    GlobalTableId: <span class="number">0</span></span><br><span class="line">                    table:</span><br><span class="line">                      table descs</span><br><span class="line">                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">      Path -&gt; Alias:</span><br><span class="line">        hdfs:<span class="comment">//&lt;tmp_hive_hdfs_base_path&gt;/20210325/&lt;hdfs_user&gt;_tdwadmin_20210325195415346_29895878_7_699597773/10002 [hdfs://&lt;tmp_hive_hdfs_base_path&gt;/20210325/&lt;hdfs_user&gt;_tdwadmin_20210325195415346_29895878_7_699597773/10002]</span></span><br><span class="line"></span><br><span class="line">  Stage: Stage-<span class="number">3</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Alias -&gt; Map Operator Tree:</span><br><span class="line">        hdfs:<span class="comment">//&lt;tmp_hive_hdfs_base_path&gt;/20210325/&lt;hdfs_user&gt;_tdwadmin_20210325195415346_29895878_7_699597773/10002 </span></span><br><span class="line">          Operator:          Select Operator</span><br><span class="line">            expressions:</span><br><span class="line">                  expr: _col0</span><br><span class="line">                  type: bigint</span><br><span class="line">                  expr: _col42</span><br><span class="line">                  type: string</span><br><span class="line">                  expr: _col85</span><br><span class="line">                  type: string</span><br><span class="line">                  expr: _col88</span><br><span class="line">                  type: bigint</span><br><span class="line">                  expr: _col103</span><br><span class="line">                  type: string</span><br><span class="line">                  expr: _col104</span><br><span class="line">                  type: string</span><br><span class="line">            outputColumnNames: _col0, _col42, _col85, _col88, _col103, _col104</span><br><span class="line">            Operator:            Common Join Operator</span><br><span class="line">              condition map:</span><br><span class="line">                   Left Outer Join0 to <span class="number">1</span></span><br><span class="line">              condition expressions:</span><br><span class="line">                <span class="number">0</span> &#123;_col0&#125; &#123;_col42&#125; &#123;_col85&#125; &#123;_col88&#125; &#123;_col104&#125;</span><br><span class="line">                <span class="number">1</span> </span><br><span class="line">              handleSkewJoin: <span class="keyword">false</span></span><br><span class="line">              keys:</span><br><span class="line">                0 [class com.tencent.tdw_udf_cloud.hive.udf.generic.GenericUDFIf(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNull(Column[_col103](), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Column[_col103](), Const string ()(), class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(Const string null_, class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge(class org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge((), Const int 10000()()(), Column[_col103]()]</span><br><span class="line">                <span class="number">1</span> [Column[fspid_fundcode]]</span><br><span class="line">              outputColumnNames: _col0, _col42, _col85, _col88, _col104</span><br><span class="line">              Position of Big Table: <span class="number">0</span></span><br><span class="line">              Operator:              File Output Operator</span><br><span class="line">                compressed: <span class="keyword">false</span></span><br><span class="line">                GlobalTableId: <span class="number">0</span></span><br><span class="line">                table:</span><br><span class="line">                  table descs</span><br><span class="line">                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">      Path -&gt; Alias:</span><br><span class="line">        hdfs:<span class="comment">//&lt;tmp_hive_hdfs_base_path&gt;/20210325/&lt;hdfs_user&gt;_tdwadmin_20210325195415346_29895878_7_699597773/10002 [hdfs://&lt;tmp_hive_hdfs_base_path&gt;/20210325/&lt;hdfs_user&gt;_tdwadmin_20210325195415346_29895878_7_699597773/10002]</span></span><br><span class="line">      Reduce Operator Tree:</span><br><span class="line">        Operator:        Group By Operator</span><br><span class="line">          aggregations:</span><br><span class="line">                expr: count(DISTINCT KEY._col1:<span class="number">1.</span>_col0)</span><br><span class="line">                expr: count(DISTINCT KEY._col1:<span class="number">2.</span>_col0)</span><br><span class="line">          keys:</span><br><span class="line">                expr: KEY._col0</span><br><span class="line">                type: string</span><br><span class="line">          mode: mergepartial</span><br><span class="line">          outputColumnNames: _col0, _col1, _col2</span><br><span class="line">          UseNewGroupBy: <span class="keyword">true</span></span><br><span class="line">          Operator:          Select Operator</span><br><span class="line">            expressions:</span><br><span class="line">                  expr: <span class="number">20210324</span></span><br><span class="line">                  type: <span class="keyword">int</span></span><br><span class="line">                  expr: (systimestamp to_char <span class="string">&#x27;yyyymmddhh24miss&#x27;</span>)</span><br><span class="line">                  type: string</span><br><span class="line">                  expr: _col0</span><br><span class="line">                  type: string</span><br><span class="line">                  expr: _col1</span><br><span class="line">                  type: bigint</span><br><span class="line">                  expr: _col1</span><br><span class="line">                  type: bigint</span><br><span class="line">                  expr: _col2</span><br><span class="line">                  type: bigint</span><br><span class="line">            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5</span><br><span class="line">            Operator:            File Output Operator</span><br><span class="line">              compressed: <span class="keyword">false</span></span><br><span class="line">              GlobalTableId: <span class="number">0</span></span><br><span class="line">              table:</span><br><span class="line">                table descs</span><br><span class="line">                  input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line"></span><br><span class="line">  Stage: Stage-<span class="number">0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit: <span class="number">100000000</span></span><br></pre></td></tr></table></figure>




<p>error</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">submitSql has error: </span><br><span class="line">org.apache.spark.sql.AnalysisException: nondeterministic expressions are only allowed in</span><br><span class="line">Project, Filter, Aggregate or Window, found:</span><br><span class="line"> ((IF(((hj2.`furl_orig` IS NULL) OR (com.tencent.tdw_udf_cloud.hive.udf.UDFTrim(hj2.`furl_orig`) = <span class="string">&#x27;&#x27;</span>)), com.tencent.tdw_udf_cloud.hive.udf.UDFConcat(<span class="string">&#x27;null_&#x27;</span>, com.tencent.tdw_udf_cloud.hive.udf.UDFFloor((org.apache.hadoop.hive.ql.udf.UDFRand() * CAST(<span class="number">10000</span> AS DOUBLE)))), hj2.`furl_orig`)) = hj1.`fevent_code`)</span><br><span class="line">in operator Join LeftOuter, (if ((isnull(furl_orig#92) || (HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFTrim(furl_orig#92) = ))) HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFConcat(null_,HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFFloor((HiveSimpleUDF#org.apache.hadoop.hive.ql.udf.UDFRand() * cast(10000 as double)))) else furl_orig#92 = fevent_code#132)</span><br><span class="line">               ;;</span><br><span class="line">Aggregate [fuin#49], [20210324 AS fdate#0, HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFToChar(HiveSimpleUDF#org.apache.hadoop.hive.ql.udf.UDFSysTimestamp(),yyyymmddhh24miss) AS fetl_time#1, fuin#49 AS fuin#2, count(distinct HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFSubstr(cast(if ((((fevent_time#95L &gt;= 20210318000000) &amp;&amp; (fevent_time#95L &lt;= 20210324235959)) &amp;&amp; fscn#111 IN (1))) fevent_time#95L else cast(null as bigint) as string),1,8)) AS flabel_25942#3L, count(distinct HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFSubstr(cast(if ((((fevent_time#95L &gt;= 20210318000000) &amp;&amp; (fevent_time#95L &lt;= 20210324235959)) &amp;&amp; fscn#111 IN (1))) fevent_time#95L else cast(null as bigint) as string),1,8)) AS flabel_25970#4L, count(distinct HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFSubstr(cast(if (((((furl_orig#92 = /mb/v5/fund/list/steady.shtml) || (furl_orig#92 = /mb/v4/fundlist/fund_all.shtml)) || (furl_orig#92 = /mb/v4/fundlist/fund_all_v5.shtml)) &amp;&amp; ((fevent_time#95L &gt;= 20210318000000) &amp;&amp; (fevent_time#95L &lt;= 20210324235959)))) fevent_time#95L else cast(null as bigint) as string),1,8)) AS flabel_25972#5L]</span><br><span class="line">+- Filter ((isnotnull(fuin#49) &amp;&amp; NOT (HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFTrim(fuin#49) = )) &amp;&amp; ((fdate#7L &gt;= cast(20210318 as bigint)) &amp;&amp; (fdate#7L &lt;= cast(20210324 as bigint))))</span><br><span class="line">   +- Join LeftOuter, (if ((isnull(fspid_fundcode#110) || (HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFTrim(fspid_fundcode#110) = ))) HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFConcat(null_,HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFFloor((HiveSimpleUDF#org.apache.hadoop.hive.ql.udf.UDFRand() * cast(10000 as double)))) else fspid_fundcode#110 = fspid_fundcode#209)</span><br><span class="line">      :- Join LeftOuter, (if ((isnull(furl_orig#92) || (HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFTrim(furl_orig#92) = ))) HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFConcat(null_,HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFFloor((HiveSimpleUDF#org.apache.hadoop.hive.ql.udf.UDFRand() * cast(10000 as double)))) else furl_orig#92 = fevent_code#201)</span><br><span class="line">      :  :- Join LeftOuter, (if ((isnull(furl_orig#92) || (HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFTrim(furl_orig#92) = ))) HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFConcat(null_,HiveSimpleUDF#com.tencent.tdw_udf_cloud.hive.udf.UDFFloor((HiveSimpleUDF#org.apache.hadoop.hive.ql.udf.UDFRand() * cast(10000 as double)))) else furl_orig#92 = fevent_code#132)</span><br><span class="line">      :  :  :- SubqueryAlias hj2</span><br><span class="line">      :  :  :  +- MetastoreRelation dml_base, dml_evt_lct_cft_label_factory_mta_access_dd</span><br><span class="line">      :  :  +- BroadcastHint</span><br><span class="line">      :  :     +- SubqueryAlias hj1</span><br><span class="line">      :  :        +- MetastoreRelation dim_base, dim_lct_hq_beacon_report_manage</span><br><span class="line">      :  +- BroadcastHint</span><br><span class="line">      :     +- SubqueryAlias hj3</span><br><span class="line">      :        +- MetastoreRelation dim_base, dim_lct_hq_virtual_event_info</span><br><span class="line">      +- BroadcastHint</span><br><span class="line">         +- SubqueryAlias hj0</span><br><span class="line">            +- MetastoreRelation dim_base, dim_prd_lct_cft_fund_type_conf</span><br></pre></td></tr></table></figure>




<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.RuntimeException: Map local work failed at org.apache.hadoop.hive.ql.exec.ExecMapper.processOldMapLocalWork(ExecMapper.java:<span class="number">317</span>) at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:<span class="number">151</span>) at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:<span class="number">54</span>) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:<span class="number">453</span>) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:<span class="number">343</span>) at org.apache.hadoop.mapred.YarnChild$<span class="number">2.</span>run(YarnChild.java:<span class="number">175</span>) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:<span class="number">422</span>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">2286</span>) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<span class="number">169</span>) Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: 没有那个文件或目录 at org.apache.hadoop.hive.ql.exec.persistence.HashMapWrapper.getPersistentHash(HashMapWrapper.java:<span class="number">189</span>) at org.apache.hadoop.hive.ql.exec.persistence.HashMapWrapper.put(HashMapWrapper.java:<span class="number">155</span>) at org.apache.hadoop.hive.ql.exec.MapJoinOperator.process(MapJoinOperator.java:<span class="number">474</span>) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:<span class="number">471</span>) at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:<span class="number">37</span>) at org.apache.hadoop.hive.ql.exec.ExecMapper.processOldMapLocalWork(ExecMapper.java:<span class="number">302</span>) ... <span class="number">9</span> more Caused by: java.io.IOException: 没有那个文件或目录 at java.io.UnixFileSystem.createFileExclusively(Native Method) at java.io.File.createTempFile(File.java:<span class="number">2024</span>) at org.apache.hadoop.hive.ql.exec.persistence.HashMapWrapper.getPersistentHash(HashMapWrapper.java:<span class="number">176</span>) ... <span class="number">14</span> more	N/A</span><br></pre></td></tr></table></figure>


<p>定位出错误原因是：强制指定了mapjoin，内存溢出了</p>
<p>Hive的自动join策略选择：</p>
<p>由于开启了hive.auto.convert.join，但是实际小表大小是hive.mapjoin.smalltable.filesize（默认25M，小表不会超过25M）。由于使用的是orc压缩，解压缩后可能大小到了250M，存放到内存大小可能就会超过1G。mapjoin的时候，hive orcfile 放到内存中会放大40倍<br> 可以看到JVM Max Heap Size大小为：1013645312 （大约1G）</p>
<h2 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h2><p>由于使用了hive.auto.convert.join,对小表进行广播，但是原表是orc的，存放到内存可能膨胀到大于localtask的堆内存大小，导致sql执行失败。</p>
<h2 id="解决措施"><a href="#解决措施" class="headerlink" title="解决措施"></a>解决措施</h2><h6 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h6><p>调大localtask的内存，set hive.mapred.local.mem=XX ，默认1G，调大到4G</p>
<h6 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h6><p>直接关表autojoin，将hive.auto.convert.join设置成false</p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>HiveSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive MapJoin优化实践</title>
    <url>/bigdata/hive/mapjoin-optimization/</url>
    <content><![CDATA[<h1 id="MapJoin-Optimization"><a href="#MapJoin-Optimization" class="headerlink" title="MapJoin Optimization"></a>MapJoin Optimization</h1><p>主要的几个优化参数：</p>
<ol>
<li>smalltable的大小，超过这个值才会使用map join</li>
<li>map join的合并</li>
<li>local task内存: mapjoin的小表转换为hashtable后的大小阈值，超过了会报错</li>
<li>本地任务可以使用的最大内存比例</li>
<li>join条件字段类型需要一致</li>
<li>map节点的内存大小</li>
</ol>
<p>在Hive中，common join是很慢的，如果我们是一张大表关联多张小表，可以使用mapjoin加快速度。</p>
<p>mapjoin主要有以下参数：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--是否自动转换为mapjoin</span></span><br><span class="line">hive.auto.convert.join</span><br><span class="line"><span class="comment">--小表的最大文件大小，默认为25000000，即25M</span></span><br><span class="line">hive.mapjoin.smalltable.filesize</span><br><span class="line"><span class="comment">--是否将多个mapjoin合并为一个</span></span><br><span class="line">hive.auto.convert.join.noconditionaltask</span><br><span class="line"><span class="comment">--多个mapjoin转换为1个时，所有小表的文件大小总和的最大值</span></span><br><span class="line">hive.auto.convert.join.noconditionaltask.size</span><br></pre></td></tr></table></figure>
<p>例如，一个大表顺序关联3个小表a(10M), b(8M),c(12M)，<br>如果<code>hive.auto.convert.join.noconditionaltask.size</code>的值：</p>
<ol>
<li>&lt;=18M，则无法合并mapjoin，必须执行3个mapjoin；</li>
<li><blockquote>
<p>18M &lt;30M，则可以合并a和b表的mapjoin，所以只需要执行2个mapjoin；</p>
</blockquote>
</li>
<li><blockquote>
<p>30M，则可以将3个mapjoin都合并为1个。</p>
</blockquote>
</li>
</ol>
<h2 id="合并mapjoin"><a href="#合并mapjoin" class="headerlink" title="合并mapjoin"></a>合并mapjoin</h2><p><strong>合并<code>mapjoin</code>有啥好处呢？</strong><br>因为每个<code>mapjoin</code>都要执行一次map，需要读写一次数据，所以多个<code>mapjoin</code>就要做多次的数据读写，合并mapjoin后只用读写一次，自然能大大加快速度。<br>但是执行map是内存大小是有限制的，在一次map里对多个小表做mapjoin就必须把多个小表都加入内存，为了防止内存溢出，所以加了<code>hive.auto.convert.join.noconditionaltask.size</code>参数来做限制。不过，这个值只是限制输入的表文件的大小，并不代表实际<code>mapjoin</code>时<code>hashtable</code>的大小。</p>
<p>我们可以通过explain查看执行计划，来看看<code>mapjoin</code>是否生效。</p>
<p>具体示例</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.auto.convert.join<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.mapjoin.smalltable.filesize<span class="operator">=</span><span class="number">300000000</span>;</span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join.noconditionaltask<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join.noconditionaltask.size<span class="operator">=</span><span class="number">300000000</span>;</span><br></pre></td></tr></table></figure>
<p>使用<code>mapjoin</code>时，会先执行一个本地任务(<code>mapreduce local task</code>)将小表转成hashtable并序列化为文件再压缩，随后这些hashtable文件会被上传到hadoop缓存，提供给各个<code>mapjoin</code>使用。这里有三个参数我们需要注意：</p>
<h2 id="local-task-memory-小表转换成hashtable的内存阈值"><a href="#local-task-memory-小表转换成hashtable的内存阈值" class="headerlink" title="local task memory: 小表转换成hashtable的内存阈值"></a>local task memory: 小表转换成hashtable的内存阈值</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--将小表转成hashtable的本地任务的最大内存使用率,默认0.9</span></span><br><span class="line">hive.mapjoin.localtask.max.memory.usage</span><br><span class="line"><span class="comment">--如果mapjoin后面紧跟着一个group by任务，这种情况下 本地任务的最大内存使用率，默认是0.55</span></span><br><span class="line">hive.mapjoin.followby.gby.localtask.max.memory.usage</span><br><span class="line"><span class="comment">--localtask每处理完多少行，就执行内存检查。默认为100000</span></span><br><span class="line">hive.mapjoin.check.memory.rows</span><br></pre></td></tr></table></figure>
<p>如果我们的<code>localtask</code>的内存使用超过阀值，任务会直接失败。</p>
<h2 id="字段类型要一致"><a href="#字段类型要一致" class="headerlink" title="字段类型要一致"></a>字段类型要一致</h2><p>此外，使用mapjoin时还要注意，用作join的关联字段的字段类型最好要一致。</p>
<p>我就碰到一个诡异的问题，执行mapjoin 的local task时一直卡住，40万行的小表处理了好几个小时，正常情况下应该几秒钟就完成了。查了好久原因，结果原来是做join的关联字段的类型不一致，一边是int， 一边是string，hive解释计划里显示它们都会被转成double再来join。我把字段类型改为一致的，瞬间就快了。照理说就算转成double也不该这么慢，不知道是不是hive的bug。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--是否自动转换为mapjoin</span></span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">--小表的最大文件大小，默认为25000000，即25M</span></span><br><span class="line"><span class="keyword">set</span> hive.mapjoin.smalltable.filesize <span class="operator">=</span> <span class="number">25000000</span>;</span><br><span class="line"><span class="comment">--是否将多个mapjoin合并为一个</span></span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join.noconditionaltask <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">--多个mapjoin转换为1个时，所有小表的文件大小总和的最大值。</span></span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join.noconditionaltask.size <span class="operator">=</span> <span class="number">10000000</span>;</span><br></pre></td></tr></table></figure>
<p>hive的join 有一种优化的方式：map join</p>
<p>但是，使用这种优化的时候要小心一点，先说一下优化配置的参数：</p>
<h2 id="localtask-max-memory-usage-本地任务内存百分比"><a href="#localtask-max-memory-usage-本地任务内存百分比" class="headerlink" title="localtask max memory usage: 本地任务内存百分比"></a>localtask max memory usage: 本地任务内存百分比</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.optimize.correlation<span class="operator">=</span><span class="literal">true</span></span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join<span class="operator">=</span><span class="literal">true</span></span><br><span class="line"><span class="keyword">set</span> hive.mapjoin.localtask.max.memory.usage<span class="operator">=</span><span class="number">0.99</span></span><br><span class="line">hive.mapjoin.localtask.max.memory.usage</span><br></pre></td></tr></table></figure>
<blockquote>
<p>说明：本地任务可以使用内存的百分比 默认值： 0.90，如果你的localtask mapjoin 表很小可以试试，但彻底解决需要</p>
</blockquote>
<p><code>set hive.auto.convert.join=false;</code>关闭自动mapjoin 但这个参数用的时候一定要注意，</p>
<p>如果你的sql 很长join会常多，关闭mapjoin任务数会成10倍激增，contener满了任务同样会非常之慢，<br><code>set hive.auto.convert.join=false;</code>一定要用在localtask级别这种超轻量及的job上。</p>
<h2 id="local-mem-map节点的内存大小"><a href="#local-mem-map节点的内存大小" class="headerlink" title="local mem: map节点的内存大小"></a>local mem: map节点的内存大小</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--设置本地memory的大小值，单位为M</span></span><br><span class="line">hive.mapred.local.mem</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>MapJoin</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache iceberg：Netflix 数据仓库的基石</title>
    <url>/bigdata/iceberg/Apache%20iceberg%EF%BC%9ANetflix%20%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E5%9F%BA%E7%9F%B3/</url>
    <content><![CDATA[<h1 id="Apache-iceberg：Netflix-数据仓库的基石"><a href="#Apache-iceberg：Netflix-数据仓库的基石" class="headerlink" title="Apache iceberg：Netflix 数据仓库的基石"></a>Apache iceberg：Netflix 数据仓库的基石</h1><p><a href="https://mp.weixin.qq.com/s/acWcoZ25zDXetA3ewypG2g?spm=a2c6h.12873639.0.0.7e4b13839s5rpH">Apache iceberg：Netflix 数据仓库的基石</a></p>
<h2 id="5-year-challenges"><a href="#5-year-challenges" class="headerlink" title="5-year challenges"></a>5-year challenges</h2><p>智能处理引擎</p>
<ul>
<li>CBO，更好的join实现</li>
<li>缓存结果集，物化视图</li>
</ul>
<p>减少人工维护数据</p>
<ul>
<li>data librarian services 数据图书馆服务</li>
<li>declarative instead of imperative 陈述式而不是命令式</li>
</ul>
<h2 id="Problem-Whack-a-mole"><a href="#Problem-Whack-a-mole" class="headerlink" title="Problem Whack-a-mole"></a>Problem Whack-a-mole</h2><p>1、不安全的操作随处可见: 同时写多个分区，列重命名<br>2、和对象存储交互有时候会出现很大的问题: eventual consistency to performance problems(最终一致性的性能问题)、output committees can’t fix it<br>3、无休止的可扩展性挑战。</p>
<h2 id="iceberg"><a href="#iceberg" class="headerlink" title="iceberg"></a>iceberg</h2><ol>
<li>在单个文件中修改或跳过数据</li>
<li>当然多个文件也支持这些操作</li>
</ol>
<p><img src="_v_images/20201014205326408_1460756353.png"></p>
<p><img src="_v_images/20201014205344160_898972367.png"></p>
<p>Hive 表的核心思想是把数据组织成目录树，如上所述。</p>
<p>如果我们需要过滤数据，可以在 where 里面添加分区相关的信息。</p>
<p>带来的问题是如果一张表有很多分区，我们需要使用 HMS（Hive MetaStore）来记录这些分区，同时底层的文件系统（比如 HDFS）仍然需要在每个分区里面记录这些分区数据。</p>
<p>这就导致我们需要在 HMS 和 文件系统里面同时保存一些状态信息；因为缺乏锁机制，所以对上面两个系统进行修改也不能保证原子性。</p>
<p>当然 Hive 这样维护表也不是没有好处。这种设计使得很多引擎（Hive、Spark、Presto、Flink、Pig）都支持读写 Hive 表，同时支持很多第三方工具。简单和透明使得 Hive 表变得不可或缺的。</p>
<p>Iceberg 的目标包括：</p>
<p>1、成为静态数据交换的开放规范，维护一个清晰的格式规范，支持多语言，支持跨项目的需求等。<br>2、提升扩展性和可靠性。能够在一个节点上运行，也能在集群上运行。所有的修改都是原子性的，串行化隔离。原生支持云对象存储，支持多并发写。<br>3、修复持续的可用性问题，比如模式演进，分区隐藏，支持时间旅行、回滚等。</p>
<p>Iceberg 主要设计思想：</p>
<p>记录表在所有时间的所有文件，和 Delta Lake 或 Apache Hudi 一样，支持 snapshot，其是表在某个时刻的完整文件列表。每一次写操作都会生成一个新的快照。</p>
<p>读取数据的时候使用当前的快照，Iceberg 使用乐观锁机制来创建新的快照，然后提交。</p>
<p>Iceberg 这么设计的好处是：</p>
<ul>
<li>所有的修改都是原子性的；</li>
<li>没有耗时的文件系统操作；</li>
<li>快照是索引好的，以便加速读取；</li>
<li>CBO metrics 信息是可靠的；</li>
<li>更新支持版本，支持物化视图。</li>
</ul>
<p>Iceberg 在 Netflix 生产环境维护着数十 PB 的数据，数百万个分区。对大表进行查询能够提供低延迟的响应。</p>
<p>未来工作：1、支持 Spark 向量化以便实现快速的 bulk read，Presto 向量化已经支持。2、行级别的删除，支持 MERGE INTO 等</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Iceberg</tag>
      </tags>
  </entry>
  <entry>
    <title>DataLake三剑客</title>
    <url>/bigdata/iceberg/DataLake%E4%B8%89%E5%89%91%E5%AE%A2(AVERYZHANG-MB1%E7%9A%84%E5%86%B2%E7%AA%81%E7%89%88%E6%9C%AC)/</url>
    <content><![CDATA[<h1 id="DataLake三剑客"><a href="#DataLake三剑客" class="headerlink" title="DataLake三剑客"></a>DataLake三剑客</h1><p><strong>作者</strong>：辛庸，阿里巴巴计算平台事业部 EMR 技术专家。Apache Hadoop，Apache Spark contributor。对 Hadoop、Spark、Hive、Druid 等大数据组件有深入研究。目前从事大数据云化相关工作，专注于计算引擎、存储结构、数据库事务等内容。</p>
<h3 id="共同点"><a href="#共同点" class="headerlink" title="共同点"></a>共同点</h3><p>定性上讲，三者均为 Data Lake 的数据存储中间层，其数据管理的功能均是基于一系列的 meta 文件。meta 文件的角色类似于数据库的 catalog/wal，起到 schema 管理、事务管理和数据管理的功能。与数据库不同的是，这些 meta 文件是与数据文件一起存放在存储引擎中的，用户可以直接看到。这种做法直接继承了大数据分析中数据对用户可见的传统，但是无形中也增加了数据被不小心破坏的风险。一旦某个用户不小心删了 meta 目录，表就被破坏了，想要恢复难度非常大。</p>
<p>Meta 文件包含有表的 schema 信息。因此系统可以自己掌握 Schema 的变动，提供 Schema 演化的支持。Meta 文件也有 transaction log 的功能（需要文件系统有原子性和一致性的支持）。所有对表的变更都会生成一份新的 meta 文件，于是系统就有了 ACID 和多版本的支持，同时可以提供访问历史的功能。在这些方面，三者是相同的。</p>
<p>下面来谈一下三者的不同。</p>
<h3 id="Hudi"><a href="#Hudi" class="headerlink" title="Hudi"></a>Hudi</h3><p>先说 Hudi。Hudi 的设计目标正如其名，Hadoop Upserts Deletes and Incrementals（原为 Hadoop Upserts anD Incrementals），强调了其主要支持 Upserts、Deletes 和 Incremental 数据处理，其主要提供的写入工具是 Spark HudiDataSource API 和自身提供的 DeltaStreamer，均支持三种数据写入方式：UPSERT，INSERT 和 BULK_INSERT。其对 Delete 的支持也是通过写入时指定一定的选项支持的，并不支持纯粹的 delete 接口。</p>
<p>其典型用法是将上游数据通过 Kafka 或者 Sqoop，经由 DeltaStreamer 写入 Hudi。DeltaStreamer 是一个常驻服务，不断地从上游拉取数据，并写入 hudi。写入是分批次的，并且可以设置批次之间的调度间隔。默认间隔为 0，类似于 Spark Streaming 的 As-soon-as-possible 策略。随着数据不断写入，会有小文件产生。对于这些小文件，DeltaStreamer 可以自动地触发小文件合并的任务。</p>
<p>在查询方面，Hudi 支持 Hive、Spark、Presto。</p>
<p>在性能方面，Hudi 设计了 <code>`</code><br>HoodieKey<br><code>，一个类似于主键的东西。</code><br>HoodieKey<br><code>有 Min/Max 统计，BloomFilter，用于快速定位 Record 所在的文件。在具体做 Upserts 时，如果 </code>HoodieKey<br><code>不存在于 BloomFilter，则执行插入，否则，确认 </code>HoodieKey<br>是否真正存在，如果真正存在，则执行 update。这种基于 HoodieKey + BloomFilter 的 upserts 方法是比较高效的，否则，需要做全表的 Join 才能实现 upserts。对于查询性能，一般需求是根据查询谓词生成过滤条件下推至 datasource。Hudi 这方面没怎么做工作，其性能完全基于引擎自带的谓词下推和 partition prune 功能。</p>
<p>Hudi 的另一大特色是支持 Copy On Write 和 Merge On Read。前者在写入时做数据的 merge，写入性能略差，但是读性能更高一些。后者读的时候做 merge，读性能查，但是写入数据会比较及时，因而后者可以提供近实时的数据分析能力。</p>
<p>最后，Hudi 提供了一个名为 run_sync_tool 的脚本同步数据的 schema 到 Hive 表。Hudi 还提供了一个命令行工具用于管理 Hudi 表。</p>
<p><strong>hudi</strong><br><img src="_v_images/20201014213247817_752642290.png" alt="image.png" title="image.png"></p>
<hr>
<h3 id="Iceberg"><a href="#Iceberg" class="headerlink" title="Iceberg"></a>Iceberg</h3><p>Iceberg 没有类似的 HoodieKey 设计，其不强调主键。上文已经说到，没有主键，做 update/delete/merge 等操作就要通过 Join 来实现，而 Join 需要有一个 类似 SQL 的执行引擎。Iceberg 并不绑定某个引擎，也没有自己的引擎，所以 Iceberg 并不支持 update/delete/merge。如果用户需要 update 数据，最好的方法就是找出哪些 partition 需要更新，然后通过 overwrite 的方式重写数据。Iceberg 官网提供的 quickstart 以及 Spark 的接口均只是提到了使用 Spark dataframe API 向 Iceberg 写数据的方式，没有提及别的数据摄入方法。至于使用 Spark Streaming 写入，代码中是实现了相应的 StreamWriteSupport，应该是支持流式写入，但是貌似官网并未明确提及这一点。支持流式写入意味着有小文件问题，对于怎么合并小文件，官网也未提及。我怀疑对于流式写入和小文件合并，可能 Iceberg 还没有很好的生产 ready，因而没有提及（纯属个人猜测）。</p>
<p>在查询方面，Iceberg 支持 Spark、Presto。</p>
<p>Iceberg 在查询性能方面做了大量的工作。值得一提的是它的 hidden partition 功能。Hidden partition 意思是说，对于用户输入的数据，用户可以选取其中某些列做适当的变换（Transform）形成一个新的列作为 partition 列。这个 partition 列仅仅为了将数据进行分区，并不直接体现在表的 schema 中。例如，用户有 timestamp 列，那么可以通过 hour(timestamp) 生成一个 timestamp_hour 的新分区列。timestamp_hour 对用户不可见，仅仅用于组织数据。Partition 列有 partition 列的统计，如该 partition 包含的数据范围。当用户查询时，可以根据 partition 的统计信息做 partition prune。</p>
<p>除了 hidden partition，Iceberg 也对普通的 column 列做了信息收集。这些统计信息非常全，包括列的 size，列的 value count，null value count，以及列的最大最小值等等。这些信息都可以用来在查询时过滤数据。</p>
<p>Iceberg 提供了建表的 API，用户可以使用该 API 指定表明、schema、partition 信息等，然后在 Hive catalog 中完成建表。</p>
<hr>
<h3 id="Delta"><a href="#Delta" class="headerlink" title="Delta"></a>Delta</h3><p>我们最后来说 Delta。Delta 的定位是流批一体的 Data Lake 存储层，支持 update/delete/merge。由于出自 Databricks，spark 的所有数据写入方式，包括基于 dataframe 的批式、流式，以及 SQL 的 Insert、Insert Overwrite 等都是支持的（开源的 SQL 写暂不支持，EMR 做了支持）。与 Iceberg 类似，Delta 不强调主键，因此其 update/delete/merge 的实现均是基于 spark 的 join 功能。在数据写入方面，Delta 与 Spark 是强绑定的，这一点 Hudi 是不同的：Hudi 的数据写入不绑定 Spark（可以用 Spark，也可以使用 Hudi 自己的写入工具写入）。</p>
<p>在查询方面，开源 Delta 目前支持 Spark 与 Presto，但是，Spark 是不可或缺的，因为 delta log 的处理需要用到 Spark。这意味着如果要用 Presto 查询 Delta，查询时还要跑一个 Spark 作业。更为蛋疼的是，Presto 查询是基于 SymlinkTextInputFormat。在查询之前，要运行 Spark 作业生成这么个 Symlink 文件。如果表数据是实时更新的，意味着每次在查询之前先要跑一个 SparkSQL，再跑 Presto。这样的话为何不都在 SparkSQL 里搞定呢？这是一个非常蛋疼的设计。为此，EMR 在这方面做了改进，支持了 DeltaInputFormat，用户可以直接使用 Presto 查询 Delta 数据，而不必事先启动一个 Spark 任务。</p>
<p>在查询性能方面，开源的 Delta 几乎没有任何优化。Iceberg 的 hidden partition 且不说，普通的 column 的统计信息也没有。Databricks 对他们引以为傲的 Data Skipping 技术做了保留。不得不说这对于推广 Delta 来说不是件好事。EMR 团队在这方面正在做一些工作，希望能弥补这方面能力的缺失。</p>
<p>Delta 在数据 merge 方面性能不如 Hudi，在查询方面性能不如 Iceberg，是不是意味着 Delta 一无是处了呢？其实不然。Delta 的一大优点就是与 Spark 的整合能力（虽然目前仍不是很完善，但 Spark-3.0 之后会好很多），尤其是其流批一体的设计，配合 multi-hop 的 data pipeline，可以支持分析、Machine learning、CDC 等多种场景。使用灵活、场景支持完善是它相比 Hudi 和 Iceberg 的最大优点。另外，Delta 号称是 Lambda 架构、Kappa 架构的改进版，无需关心流批，无需关心架构。这一点上 Hudi 和 Iceberg 是力所不及的。</p>
<p><strong>delta</strong><br><img src="_v_images/20201014213246690_850183439.png" alt="image.png" title="image.png"></p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过上面的分析能够看到，三个引擎的初衷场景并不完全相同，Hudi 为了 incremental 的 upserts，Iceberg 定位于高性能的分析与可靠的数据管理，Delta 定位于流批一体的数据处理。这种场景的不同也造成了三者在设计上的差别。尤其是 Hudi，其设计与另外两个相比差别更为明显。随着时间的发展，三者都在不断补齐自己缺失的能力，可能在将来会彼此趋同，互相侵入对方的领地。当然也有可能各自关注自己专长的场景，筑起自己的优势壁垒，因此最终谁赢谁输还是未知之数。</p>
<p>下表从多个维度对三者进行了总结，需要注意的是此表所列的能力仅代表至 2019 年底。</p>
<table>
<thead>
<tr>
<th>·</th>
<th>Delta</th>
<th>Hudi</th>
<th>Iceberg</th>
</tr>
</thead>
<tbody><tr>
<td>Incremental Ingestion</td>
<td>Spark</td>
<td>Spark</td>
<td>Spark</td>
</tr>
<tr>
<td>ACID updates</td>
<td>HDFS, S3 (Databricks), OSS</td>
<td>HDFS</td>
<td>HDFS, S3</td>
</tr>
<tr>
<td>Upserts/Delete/Merge/Update</td>
<td>Delete/Merge/Update</td>
<td>Upserts/Delete</td>
<td>No</td>
</tr>
<tr>
<td>Streaming sink</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes(not ready?)</td>
</tr>
<tr>
<td>Streaming source</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>FileFormats</td>
<td>Parquet</td>
<td>Avro,Parquet</td>
<td>Parquet, ORC</td>
</tr>
<tr>
<td>Data Skipping</td>
<td>File-Level Max-Min stats + Z-Ordering (Databricks)</td>
<td>File-Level Max-Min stats + Bloom Filter</td>
<td>File-Level Max-Min Filtering</td>
</tr>
<tr>
<td>Concurrency control</td>
<td>Optimistic</td>
<td>Optimistic</td>
<td>Optimistic</td>
</tr>
<tr>
<td>Data Validation</td>
<td>Yes (Databricks)</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Merge on read</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Schema Evolution</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>File I/O Cache</td>
<td>Yes (Databricks)</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Cleanup</td>
<td>Manual</td>
<td>Automatic</td>
<td>No</td>
</tr>
<tr>
<td>Compaction</td>
<td>Manual</td>
<td>Automatic</td>
<td>No</td>
</tr>
</tbody></table>
<p>注：限于本人水平，文中内容可能有误，也欢迎读者批评指正！</p>
<hr>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Iceberg</tag>
      </tags>
  </entry>
  <entry>
    <title>DataLake三剑客</title>
    <url>/bigdata/iceberg/DataLake%E4%B8%89%E5%89%91%E5%AE%A2/</url>
    <content><![CDATA[<h1 id="DataLake三剑客"><a href="#DataLake三剑客" class="headerlink" title="DataLake三剑客"></a>DataLake三剑客</h1><p><strong>作者</strong>：辛庸，阿里巴巴计算平台事业部 EMR 技术专家。Apache Hadoop，Apache Spark contributor。对 Hadoop、Spark、Hive、Druid 等大数据组件有深入研究。目前从事大数据云化相关工作，专注于计算引擎、存储结构、数据库事务等内容。</p>
<h3 id="共同点"><a href="#共同点" class="headerlink" title="共同点"></a>共同点</h3><p>定性上讲，三者均为 Data Lake 的数据存储中间层，其数据管理的功能均是基于一系列的 meta 文件。meta 文件的角色类似于数据库的 catalog/wal，起到 schema 管理、事务管理和数据管理的功能。与数据库不同的是，这些 meta 文件是与数据文件一起存放在存储引擎中的，用户可以直接看到。这种做法直接继承了大数据分析中数据对用户可见的传统，但是无形中也增加了数据被不小心破坏的风险。一旦某个用户不小心删了 meta 目录，表就被破坏了，想要恢复难度非常大。</p>
<p>Meta 文件包含有表的 schema 信息。因此系统可以自己掌握 Schema 的变动，提供 Schema 演化的支持。Meta 文件也有 transaction log 的功能（需要文件系统有原子性和一致性的支持）。所有对表的变更都会生成一份新的 meta 文件，于是系统就有了 ACID 和多版本的支持，同时可以提供访问历史的功能。在这些方面，三者是相同的。</p>
<p>下面来谈一下三者的不同。</p>
<h3 id="Hudi"><a href="#Hudi" class="headerlink" title="Hudi"></a>Hudi</h3><p>先说 Hudi。Hudi 的设计目标正如其名，Hadoop Upserts Deletes and Incrementals（原为 Hadoop Upserts anD Incrementals），强调了其主要支持 Upserts、Deletes 和 Incremental 数据处理，其主要提供的写入工具是 Spark HudiDataSource API 和自身提供的 DeltaStreamer，均支持三种数据写入方式：UPSERT，INSERT 和 BULK_INSERT。其对 Delete 的支持也是通过写入时指定一定的选项支持的，并不支持纯粹的 delete 接口。</p>
<p>其典型用法是将上游数据通过 Kafka 或者 Sqoop，经由 DeltaStreamer 写入 Hudi。DeltaStreamer 是一个常驻服务，不断地从上游拉取数据，并写入 hudi。写入是分批次的，并且可以设置批次之间的调度间隔。默认间隔为 0，类似于 Spark Streaming 的 As-soon-as-possible 策略。随着数据不断写入，会有小文件产生。对于这些小文件，DeltaStreamer 可以自动地触发小文件合并的任务。</p>
<p>在查询方面，Hudi 支持 Hive、Spark、Presto。</p>
<p>在性能方面，Hudi 设计了 <code>`</code><br>HoodieKey<br><code>，一个类似于主键的东西。</code><br>HoodieKey<br><code>有 Min/Max 统计，BloomFilter，用于快速定位 Record 所在的文件。在具体做 Upserts 时，如果 </code>HoodieKey<br><code>不存在于 BloomFilter，则执行插入，否则，确认 </code>HoodieKey<br>是否真正存在，如果真正存在，则执行 update。这种基于 HoodieKey + BloomFilter 的 upserts 方法是比较高效的，否则，需要做全表的 Join 才能实现 upserts。对于查询性能，一般需求是根据查询谓词生成过滤条件下推至 datasource。Hudi 这方面没怎么做工作，其性能完全基于引擎自带的谓词下推和 partition prune 功能。</p>
<p>Hudi 的另一大特色是支持 Copy On Write 和 Merge On Read。前者在写入时做数据的 merge，写入性能略差，但是读性能更高一些。后者读的时候做 merge，读性能查，但是写入数据会比较及时，因而后者可以提供近实时的数据分析能力。</p>
<p>最后，Hudi 提供了一个名为 run_sync_tool 的脚本同步数据的 schema 到 Hive 表。Hudi 还提供了一个命令行工具用于管理 Hudi 表。</p>
<p><strong>hudi</strong><br><img src="_v_images/20201014213247817_752642290.png" alt="image.png" title="image.png"></p>
<hr>
<h3 id="Iceberg"><a href="#Iceberg" class="headerlink" title="Iceberg"></a>Iceberg</h3><p>Iceberg 没有类似的 HoodieKey 设计，其不强调主键。上文已经说到，没有主键，做 update/delete/merge 等操作就要通过 Join 来实现，而 Join 需要有一个 类似 SQL 的执行引擎。Iceberg 并不绑定某个引擎，也没有自己的引擎，所以 Iceberg 并不支持 update/delete/merge。如果用户需要 update 数据，最好的方法就是找出哪些 partition 需要更新，然后通过 overwrite 的方式重写数据。Iceberg 官网提供的 quickstart 以及 Spark 的接口均只是提到了使用 Spark dataframe API 向 Iceberg 写数据的方式，没有提及别的数据摄入方法。至于使用 Spark Streaming 写入，代码中是实现了相应的 StreamWriteSupport，应该是支持流式写入，但是貌似官网并未明确提及这一点。支持流式写入意味着有小文件问题，对于怎么合并小文件，官网也未提及。我怀疑对于流式写入和小文件合并，可能 Iceberg 还没有很好的生产 ready，因而没有提及（纯属个人猜测）。</p>
<p>在查询方面，Iceberg 支持 Spark、Presto。</p>
<p>Iceberg 在查询性能方面做了大量的工作。值得一提的是它的 hidden partition 功能。Hidden partition 意思是说，对于用户输入的数据，用户可以选取其中某些列做适当的变换（Transform）形成一个新的列作为 partition 列。这个 partition 列仅仅为了将数据进行分区，并不直接体现在表的 schema 中。例如，用户有 timestamp 列，那么可以通过 hour(timestamp) 生成一个 timestamp_hour 的新分区列。timestamp_hour 对用户不可见，仅仅用于组织数据。Partition 列有 partition 列的统计，如该 partition 包含的数据范围。当用户查询时，可以根据 partition 的统计信息做 partition prune。</p>
<p>除了 hidden partition，Iceberg 也对普通的 column 列做了信息收集。这些统计信息非常全，包括列的 size，列的 value count，null value count，以及列的最大最小值等等。这些信息都可以用来在查询时过滤数据。</p>
<p>Iceberg 提供了建表的 API，用户可以使用该 API 指定表明、schema、partition 信息等，然后在 Hive catalog 中完成建表。</p>
<hr>
<h3 id="Delta"><a href="#Delta" class="headerlink" title="Delta"></a>Delta</h3><p>我们最后来说 Delta。Delta 的定位是流批一体的 Data Lake 存储层，支持 update/delete/merge。由于出自 Databricks，spark 的所有数据写入方式，包括基于 dataframe 的批式、流式，以及 SQL 的 Insert、Insert Overwrite 等都是支持的（开源的 SQL 写暂不支持，EMR 做了支持）。与 Iceberg 类似，Delta 不强调主键，因此其 update/delete/merge 的实现均是基于 spark 的 join 功能。在数据写入方面，Delta 与 Spark 是强绑定的，这一点 Hudi 是不同的：Hudi 的数据写入不绑定 Spark（可以用 Spark，也可以使用 Hudi 自己的写入工具写入）。</p>
<p>在查询方面，开源 Delta 目前支持 Spark 与 Presto，但是，Spark 是不可或缺的，因为 delta log 的处理需要用到 Spark。这意味着如果要用 Presto 查询 Delta，查询时还要跑一个 Spark 作业。更为蛋疼的是，Presto 查询是基于 SymlinkTextInputFormat。在查询之前，要运行 Spark 作业生成这么个 Symlink 文件。如果表数据是实时更新的，意味着每次在查询之前先要跑一个 SparkSQL，再跑 Presto。这样的话为何不都在 SparkSQL 里搞定呢？这是一个非常蛋疼的设计。为此，EMR 在这方面做了改进，支持了 DeltaInputFormat，用户可以直接使用 Presto 查询 Delta 数据，而不必事先启动一个 Spark 任务。</p>
<p>在查询性能方面，开源的 Delta 几乎没有任何优化。Iceberg 的 hidden partition 且不说，普通的 column 的统计信息也没有。Databricks 对他们引以为傲的 Data Skipping 技术做了保留。不得不说这对于推广 Delta 来说不是件好事。EMR 团队在这方面正在做一些工作，希望能弥补这方面能力的缺失。</p>
<p>Delta 在数据 merge 方面性能不如 Hudi，在查询方面性能不如 Iceberg，是不是意味着 Delta 一无是处了呢？其实不然。Delta 的一大优点就是与 Spark 的整合能力（虽然目前仍不是很完善，但 Spark-3.0 之后会好很多），尤其是其流批一体的设计，配合 multi-hop 的 data pipeline，可以支持分析、Machine learning、CDC 等多种场景。使用灵活、场景支持完善是它相比 Hudi 和 Iceberg 的最大优点。另外，Delta 号称是 Lambda 架构、Kappa 架构的改进版，无需关心流批，无需关心架构。这一点上 Hudi 和 Iceberg 是力所不及的。</p>
<p><strong>delta</strong><br><img src="_v_images/20201014213246690_850183439.png" alt="image.png" title="image.png"></p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过上面的分析能够看到，三个引擎的初衷场景并不完全相同，Hudi 为了 incremental 的 upserts，Iceberg 定位于高性能的分析与可靠的数据管理，Delta 定位于流批一体的数据处理。这种场景的不同也造成了三者在设计上的差别。尤其是 Hudi，其设计与另外两个相比差别更为明显。随着时间的发展，三者都在不断补齐自己缺失的能力，可能在将来会彼此趋同，互相侵入对方的领地。当然也有可能各自关注自己专长的场景，筑起自己的优势壁垒，因此最终谁赢谁输还是未知之数。</p>
<p>下表从多个维度对三者进行了总结，需要注意的是此表所列的能力仅代表至 2019 年底。</p>
<table>
<thead>
<tr>
<th>·</th>
<th>Delta</th>
<th>Hudi</th>
<th>Iceberg</th>
</tr>
</thead>
<tbody><tr>
<td>Incremental Ingestion</td>
<td>Spark</td>
<td>Spark</td>
<td>Spark</td>
</tr>
<tr>
<td>ACID updates</td>
<td>HDFS, S3 (Databricks), OSS</td>
<td>HDFS</td>
<td>HDFS, S3</td>
</tr>
<tr>
<td>Upserts/Delete/Merge/Update</td>
<td>Delete/Merge/Update</td>
<td>Upserts/Delete</td>
<td>No</td>
</tr>
<tr>
<td>Streaming sink</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes(not ready?)</td>
</tr>
<tr>
<td>Streaming source</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>FileFormats</td>
<td>Parquet</td>
<td>Avro,Parquet</td>
<td>Parquet, ORC</td>
</tr>
<tr>
<td>Data Skipping</td>
<td>File-Level Max-Min stats + Z-Ordering (Databricks)</td>
<td>File-Level Max-Min stats + Bloom Filter</td>
<td>File-Level Max-Min Filtering</td>
</tr>
<tr>
<td>Concurrency control</td>
<td>Optimistic</td>
<td>Optimistic</td>
<td>Optimistic</td>
</tr>
<tr>
<td>Data Validation</td>
<td>Yes (Databricks)</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Merge on read</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Schema Evolution</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>File I/O Cache</td>
<td>Yes (Databricks)</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Cleanup</td>
<td>Manual</td>
<td>Automatic</td>
<td>No</td>
</tr>
<tr>
<td>Compaction</td>
<td>Manual</td>
<td>Automatic</td>
<td>No</td>
</tr>
</tbody></table>
<p>注：限于本人水平，文中内容可能有误，也欢迎读者批评指正！</p>
<hr>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Iceberg</tag>
      </tags>
  </entry>
  <entry>
    <title>数据湖</title>
    <url>/bigdata/iceberg/%E6%95%B0%E6%8D%AE%E6%B9%96/</url>
    <content><![CDATA[<h1 id="数据湖"><a href="#数据湖" class="headerlink" title="数据湖"></a>数据湖</h1><p><img src="vx_images/4964231239501" alt="图片"></p>
<h2 id="数据仓库-VS-数据湖"><a href="#数据仓库-VS-数据湖" class="headerlink" title="数据仓库 VS 数据湖"></a>数据仓库 VS 数据湖</h2><p>相较而言，数据湖是较新的技术，拥有不断演变的架构。数据湖存储任何形式（包括结构化和非结构化）和任何格式（包括文本、音频、视频和图像）的原始数据。根据定义，<code>数据湖不会接受数据治理</code>，但专家们一致认为<code>良好的数据管理对预防数据湖转变为数据沼泽不可或缺</code>。数据湖在数据读取期间创建模式。与数据仓库相比，数据湖缺乏结构性，而且更灵活，并且提供了更高的敏捷性。值得一提的是，数据湖非常适合使用机器学习和深度学习来执行各种任务，比如数据挖掘和数据分析，以及提取非结构化数据等。<br><img src="vx_images/3593617797024" alt="图片"></p>
<p><img src="vx_images/5612546586116.png"></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Iceberg</tag>
      </tags>
  </entry>
  <entry>
    <title>kudu</title>
    <url>/bigdata/kudu/kudu/</url>
    <content><![CDATA[<h1 id="kudu"><a href="#kudu" class="headerlink" title="kudu"></a>kudu</h1><figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> `db_name`.`table_name`</span><br><span class="line">        ADD RANGE PARTITION VALUE = $&#123;partition&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>kudu</tag>
      </tags>
  </entry>
  <entry>
    <title>SolrCloud</title>
    <url>/bigdata/solr/SolrCloud/</url>
    <content><![CDATA[<h1 id="SolrCloud"><a href="#SolrCloud" class="headerlink" title="SolrCloud"></a>SolrCloud</h1><p><img src="_v_images/20200812120555513_1829511358.png"></p>
<p>物理结构：</p>
<p>三个Solr实例（ 每个实例包括两个Core），组成一个SolrCloud。</p>
<p>逻辑结构：</p>
<p>索引集合包括两个Shard（shard1和shard2），shard1和shard2分别由三个Core组成，其中一个Leader两个Replication，Leader是由zookeeper选举产生，zookeeper控制每个shard上三个Core的索引数据一致，解决高可用问题。用户发起索引请求分别从shard1和shard2上获取，解决高并发问题。</p>
<p>core：</p>
<p>每个Core是Solr中一个独立运行单位，提供 索引和搜索服务。一个shard需要由一个Core或多个Core组成。由于collection由多个shard组成所以collection一般由多个core组成。</p>
<p>Master&amp;Slave：</p>
<p>Master是master-slave构中的主结点（通常说主服务器），Slave是master-slave结构中的从结点（通常说从服务器或备服务器）。同一个Shard下master和slave存储的数据是一致的，这是为了达到高可用目的</p>
<h3 id="Logical-Concepts"><a href="#Logical-Concepts" class="headerlink" title="Logical Concepts"></a><a href="https://lucene.apache.org/solr/guide/7_1/how-solrcloud-works.html#logical-concepts">Logical Concepts</a></h3><ul>
<li><p>A Cluster can host multiple Collections of Solr Documents. 一个集群可持有多个solr文档集合</p>
</li>
<li><p>A collection can be partitioned into multiple Shards, which contain a subset of the Documents in the Collection. 一个集合可以分区为多个shards(切片), 一个shard包含文档集合的子集</p>
</li>
<li><p>The number of Shards that a Collection has determines: 集合中shard的个数取决于:</p>
<ul>
<li><p>The theoretical limit to the number of Documents that Collection can reasonably contain.  集合可以合理包含的文档数量的理论限制。</p>
</li>
<li><p>The amount of parallelization that is possible for an individual search request. 单个搜索请求可能的并行度。</p>
</li>
</ul>
</li>
</ul>
<h3 id="Physical-Concepts"><a href="#Physical-Concepts" class="headerlink" title="Physical Concepts"></a><a href="https://lucene.apache.org/solr/guide/7_1/how-solrcloud-works.html#physical-concepts">Physical Concepts</a></h3><ul>
<li><p>A Cluster is made up of one or more Solr Nodes, which are running instances of the Solr server process. 集群由一个或多个Solr节点组成，这些节点运行着Solr服务器进程的实例。</p>
</li>
<li><p>Each Node can host multiple Cores. 每个节点可以持有多个核</p>
</li>
<li><p>Each Core in a Cluster is a physical Replica for a logical Shard. 一个集群的每个核是一个shard的物理副本</p>
</li>
<li><p>Every Replica uses the same configuration specified for the Collection that it is a part of. 每个副本使用为其所属的集合指定的相同配置。</p>
</li>
<li><p>The number of Replicas that each Shard has determines: 每个shard的副本数取决于:</p>
<ul>
<li><p>The level of redundancy built into the Collection and how fault tolerant the Cluster can be in the event that some Nodes become unavailable. 集合内建的冗余级别，以及在某些节点不可用时集群的容错能力。</p>
</li>
<li><p>The theoretical limit in the number concurrent search requests that can be processed under heavy load. 在高负载下可处理的并发搜索请求数量的理论限制。</p>
</li>
</ul>
</li>
</ul>
<p><a href="https://lucene.apache.org/solr/guide/7_1/how-solrcloud-works.html">官方文档-How SolrCloud Works</a></p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>SolrCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建webDriver+firefox爬虫服务器</title>
    <url>/bigdata/spider/webDriver_firefox_on_linux/</url>
    <content><![CDATA[<blockquote>
<p>基于Docker搭建的Centos 7平台<br>最新版的firefox 59, 新版的Chrome已经不再支持Linux, Opera半死不活</p>
</blockquote>
<p>Java + Selenium + GeckoDriver + firefox 版本太难兼容<br>本文的版本供参考(验证可用)</p>
<ul>
<li>Java 1.8.0 update 91</li>
<li>Selenium-Java 3.9.1</li>
<li>GeckoDriver 0.19.1</li>
<li>Firefox 59.0b8</li>
</ul>
<h1 id="安装-Java-8"><a href="#安装-Java-8" class="headerlink" title="安装 Java 8"></a>安装 Java 8</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install java-1.8.0-openjdk.x86_64</span><br></pre></td></tr></table></figure>
<h1 id="Selenium-Java"><a href="#Selenium-Java" class="headerlink" title="Selenium-Java"></a>Selenium-Java</h1><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.seleniumhq.selenium<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>selenium-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.9.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="GeckoDriver"><a href="#GeckoDriver" class="headerlink" title="GeckoDriver"></a>GeckoDriver</h1><p>Gecko是Firefox的内核，顾名思义，<a href="https://github.com/mozilla/geckodriver/releases">GeckoDriver</a>就是驱动<br>启动后监听6411端口， Selenium通过IPC调用，访问GeckoDriver</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/mozilla/geckodriver/releases/download/v0.19.1/geckodriver-v0.19.1-linux64.tar.gz</span><br><span class="line">tar -zxvf geckodriver-v0.19.1-linux64.tar.gz</span><br><span class="line">mv geckodriver /usr/local/bin/</span><br></pre></td></tr></table></figure>
<h1 id="Firefox"><a href="#Firefox" class="headerlink" title="Firefox"></a>Firefox</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">https://ftp.mozilla.org/pub/firefox/releases/59.0b8/linux-x86_64/zh-CN/firefox-59.0b8.tar.bz2</span><br><span class="line">tar -xvf firefox-59.0b8.tar.bz2</span><br><span class="line">mv firefox /usr/local/</span><br><span class="line">ln /usr/local/firefox/firefox /usr/bin/firefox</span><br></pre></td></tr></table></figure>
<h2 id="安装虚拟桌面"><a href="#安装虚拟桌面" class="headerlink" title="安装虚拟桌面"></a>安装虚拟桌面</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装Xvfb及其他依赖</span></span><br><span class="line">yum install xorg-x11-server-Xvfb bzip gtk3</span><br></pre></td></tr></table></figure>
<h2 id="安装字体，支持中文"><a href="#安装字体，支持中文" class="headerlink" title="安装字体，支持中文"></a>安装字体，支持中文</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum groupinstall &quot;Fonts&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装后 重启</span></span><br></pre></td></tr></table></figure>
<h1 id="上代码"><a href="#上代码" class="headerlink" title="上代码"></a>上代码</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">System.setProperty(<span class="string">&quot;webdriver.gecko.driver&quot;</span>, <span class="string">&quot;/usr/local/bin/geckodriver&quot;</span>);</span><br><span class="line"></span><br><span class="line">FirefoxOptions firefoxOptions = <span class="keyword">new</span> FirefoxOptions();</span><br><span class="line">firefoxOptions.setHeadless(<span class="keyword">true</span>);</span><br><span class="line">firefoxOptions.setAcceptInsecureCerts(<span class="keyword">true</span>);</span><br><span class="line">firefoxOptions.addArguments(<span class="string">&quot;--disable-gpu&quot;</span>, <span class="string">&quot;--window-size=1920,1200&quot;</span>, <span class="string">&quot;--ignore-certificate-errors&quot;</span>);</span><br><span class="line">WebDriver driver = <span class="keyword">new</span> FirefoxDriver(firefoxOptions);</span><br><span class="line">System.out.println(<span class="string">&quot;init chromeDriver&quot;</span>);</span><br><span class="line">driver.get(<span class="string">&quot;https://www.coinone.com&quot;</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;open url&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    Thread.sleep(<span class="number">6000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">&quot;sleep over&quot;</span>);</span><br><span class="line"></span><br><span class="line">WebElement closeBtn = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        closeBtn = driver.findElement(By.id(<span class="string">&quot;close_btn&quot;</span>));</span><br><span class="line">            closeBtn.click();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchElementException e) &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    List&lt;WebElement&gt; elements = driver.findElements(By.cssSelector(<span class="string">&quot;.intro_chart_price table td&quot;</span>));</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; elements.size(); i += <span class="number">2</span>) &#123;</span><br><span class="line">        String value = elements.get(i + <span class="number">1</span>).getText().trim();</span><br><span class="line">            System.out.println(<span class="string">&quot;empty value , try &quot;</span> + tryCount);</span><br><span class="line">        System.out.println(elements.get(i).getText().trim() + <span class="string">&quot;\t&quot;</span> + value);</span><br><span class="line">    &#125;</span><br><span class="line">driver.close();</span><br></pre></td></tr></table></figure>
<p>输出结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1518339710700	geckodriver	INFO	geckodriver 0.19.1</span><br><span class="line">1518339710706	geckodriver	INFO	Listening on 127.0.0.1:6411</span><br><span class="line">1518339711356	mozrunner::runner	INFO	Running command: &quot;&#x2F;usr&#x2F;local&#x2F;firefox&#x2F;firefox&quot; &quot;-marionette&quot; &quot;-headless&quot; &quot;--disable-gpu&quot; &quot;--window-size&#x3D;1920,1200&quot; &quot;--ignore-certificate-errors&quot; &quot;-profile&quot; &quot;&#x2F;tmp&#x2F;rust_mozprofile.1ZVD24PplvDp&quot;</span><br><span class="line">*** You are running in headless mode.</span><br><span class="line">1518339712100	Marionette	INFO	Enabled via --marionette</span><br><span class="line">1518339715188	Marionette	INFO	Listening on port 36443</span><br><span class="line">1518339715212	Marionette	WARN	TLS certificate errors will be ignored for this session</span><br><span class="line">Feb 11, 2018 9:01:55 AM org.openqa.selenium.remote.ProtocolHandshake createSession</span><br><span class="line">INFO: Detected dialect: W3C</span><br><span class="line">init chromeDriver</span><br><span class="line">open url</span><br><span class="line">sleep over</span><br><span class="line"></span><br><span class="line">BTC	8,918,000</span><br><span class="line">BCH	1,197,500</span><br><span class="line">ETH	814,200</span><br><span class="line">ETC	22,720</span><br><span class="line">XRP	1,056</span><br><span class="line">QTUM	29,710</span><br><span class="line">LTC	165,050</span><br><span class="line">IOTA	1,910</span><br><span class="line">BTG	370,350</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><p>太多</p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Spider</tag>
        <tag>Crawling</tag>
      </tags>
  </entry>
  <entry>
    <title>Storm runtime</title>
    <url>/bigdata/storm/Storm-runtime/</url>
    <content><![CDATA[<h1 id="Storm-runtime"><a href="#Storm-runtime" class="headerlink" title="Storm-runtime"></a>Storm-runtime</h1><p><img src="_v_images/20210116161223695_155417172.jpg"></p>
<p>master-slave结构:</p>
<ul>
<li>Nimbus是主节点，负责分发用户代码，指派Supervisor上的worker进程，运行topology的(Spout/Bolt)Task</li>
<li>Supervisor是从节点，守护进程. 负责启动和终止worker进程. 通过Storm的配置文件中的 supervisor.slots.ports配置项，可以指定在一个Supervisor上最大允许多少个Slot，每个Slot通过端口号来唯一标识，一个端口号 对应一个Worker进程（如果该Worker进程被启动）。</li>
</ul>
<p><img src="_v_images/20210116162304428_695142382.jpg"></p>
<p>运行流程</p>
<p>1）户端提交拓扑到nimbus。</p>
<p>2） Nimbus针对该拓扑建立本地的目录根据topology的配置计算task，分配task，在zookeeper上建立assignments节点存储 task和supervisor机器节点中woker的对应关系；</p>
<p>在zookeeper上创建taskbeats节点来监控task的心跳；启动topology。</p>
<p>3） Supervisor去zookeeper上获取分配的tasks，启动多个woker进行，每个woker生成task，一个task一个线程；根据topology 信息初始化建立task之间的连接;Task和Task之间是通过zeroMQ管理的；后整个拓扑运行起来。</p>
<h2 id="内核-队列"><a href="#内核-队列" class="headerlink" title="内核-队列"></a>内核-队列</h2><p>在Storm中大量使用Disrupt Queue来解耦Storm内部的消息处理过程。分析这些Queue的分布，是分析Storm运行时态的基础。</p>
<p><img src="_v_images/20210116174558832_184704273.png"></p>
<p>在Storm的worker中，最小的执行单元是executor,一个executor只会有一个component。目前一个component只会有一个task。而一个executor会有两个Disruptor Queue, 一个用于接受数据的receive Disrupor Queue和一个用于发送send Disrupor Queue。然后在worker中有一个全局的send Disrupor Queue。分析完队列的分布，在分析topology的运行时状况。</p>
<p>当一个Topology提交到Storm集群后，task被分配到各个wrker中开始执行后，task是怎么执行的。Storm的Task分为两类，一类是消息的源头Spout,它负责在源头产生消息；然后就是Bolt，它是执行单元。但是这两者各自的工作逻辑如下。</p>
<p>我们来分析Spout在运行时的工作状况。Spout的nextTuple用于发送数据，接口注释上说明它不能阻塞，因为它与active， deactive，ack, fail在一个处理线程里面被处理。但是nextTuple被阻塞会有什么副作用列？当nextTuple被阻塞，应用代码中另起线程调用SpoutCollector会有什么后果？下图是SpoutExecutor的执行逻辑。</p>
<p><img src="_v_images/20210116174558730_1417384061.png"></p>
<p>在SpoutExecutor处理循环里面，第一步做的事情是从receive Disrupor Queue里面消费里面的消息。这里面的就是SpoutExecutor所收到的消息。处理逻辑如下图所示</p>
<p><img src="_v_images/20210116174558627_554147077.png"></p>
<p>然后SpoutExecutor会将overflow中的数据再次发送。overflow是用于接受SpoutCollector.emit()无发及时发送的数据的，具体SpoutCollector发送数据的逻辑见下文分析。但是这里在发送overflow的数据时，与SpoutCollector.emit()有个区别，就是数据还是无法被正常发送时，数据会丢弃，也就是不会被再次写入overflow中。当overflow中没有数据，以及pending中的数据量小于TOPOLOGY_MAX_SPOUT_PENDING时，判断topology的状态。当topology不是deactive状态时，如果topology有触发active命令，会调用spout的active接口，然后调用spout的nextTuple接口。否则调用deactive接口。所以这里当Spout的nextTuple被阻塞时，spout没办法处理acker回报的消息，回报的消息会阻塞在executor的receive DisruptorQueue中，当receive DisruptorQueue塞满后，是会阻塞在对应的网络处理模块中，storm中经典的是zeroMQ,老版本的zeroMQ是没有设置水位，这样会大量堆积到内存中，因为zeroMQ是C++的，占用的是堆外内存，JVM无法管理，最坏就是把机器的内存耗光。如果这个是另起线程调用SpoutCollector的emit，当emit数据速度过快，会导致overflow中堆积数据，导致worker内存消耗。</p>
<p>上面讲到SpoutCollector在emit数据会写入overflow,那什么情况下会写入overflow。SpoutCollector.emit是否真的就把数据发送到了网络。下面是SpoutCollector的处理逻辑。</p>
<p><img src="_v_images/20210116174558522_1112615304.png"></p>
<p>Spout当调用SpoutCollect.emit()发送时，首先的逻辑是根据根据消息的STREAM ID,和对应的values,得到目的端task id。当topology开启acker机制时，会生成一个随机的rootId，否则使用一个默认值作为rootId。然后为消息生成一个随机的messageId，由rootId和messageId组成对应的tuple Id。这里tuple Id是有rootId为key,messageId为value的一个HashMap。这里采用HashMap的作用会在下面Spout的ack机制是做说明。在将生成的tuple Id和用会的values组成一个tuple。并判断overflower是否有数据，让overflow中有数据时，数据会直接放入overflow中，而不会放入executor  的send Disraptor Queue中。当overflow为空时，会将tuple放入send Disraptor Queue中。当捕获Disraptor Queue的InsufficientCapacityException时，数据就放入了overflow中。然后处理ack。当开启了ack机制，会在pending中加入对应的tuple数据，然后项acker发送ack init消息。</p>
<p>根据上面的发送过程，数据emit只是被写入了executor的send Disraptor Queue。而数据在Spout端的丢失多是数据在overflow中被SpoutExecutor在次处理时，send Disraptor Queue满导致。</p>
<p>关于pending，首先它是一个RotatingMap。它通过定时旋转，以达到定时器的目的。在SpoutExecutor的RotatingMap中有两个桶，然后executor有个定时线程，会按照用户设定的message timeout second，定期向executor的receive DisruptorQueue写入SYSTEM_TICK_STREAM_ID消息，然后SpoutExecutor处理SYSTEM_TICK_STREAM_ID消息时就旋转RotatingMap，当被清除的桶中有数据时，被清除的桶中的数据会调用fail接口，通知业务逻辑fail。这就是当超时间设置比业务逻辑短时，导致数据重复的原因。还有一种是acker消息丢失，导致数据重复。由于RotatingMap的底层是HashMap，中间没有锁，overflow是个LinkedList，所以SpoutCollector和SpoutExecutor不能在两个线程中并发 处理。</p>
<p>BoltExecutor的处理逻辑非常简单，就是消费receive Disrupor Queue中数据，然后调用bolt的excue。但是这里也是单线程处理的，阻塞或者处理速度不匹配，就会导致数据在Disrupor Queue或者网络模块中堆积，其中使用zeroMQ的副作用最大。</p>
<p>BoltCollector的emit与SpoutCollector的emit处理相比，首先是少了overflow承接无法发送的数据，会直接丢弃。其次是没有pending和acker消息的发送。</p>
<p>接下来分析一下Storm的Acker机制。Storm的Ack机制在Storm刚刚开源时被大书特书，处理原理也确实非常的精彩。由于这里ID都是随机数，所以这里不会在讨论随机数的唯一问题。</p>
<p><img src="_v_images/20210116174558419_714266215.png"></p>
<p>如上图所示，spout发送t1给bolt a, bolt a 在t1的基础上生成t2,t3,t4给bolt b，bolt b ack所收到的数据。下面来追踪整个id变化的过程。</p>
<p>Spout 发送t1， message id为&lt;r_1, m_1&gt;,发送ack</p>
<p>Acker收到ack init, map中缓存&lt;r_1,m_1&gt;</p>
<p>Bolt a 收到t1, messageId为&lt;r_1,m_1&gt;,生成t2，t3, t4</p>
<p>Bolt a 发送t2, anchor t1, t2,messageId为&lt;r_1,m_2&gt;, 更新t1的ackVal为m_2</p>
<p>Bolt a 发送t3, anchor t1, t3,messageId为&lt;r_1,m_3&gt;, 更新t1的ackVal为m_2^m_3</p>
<p>Bolt a 发送t4, anchor t1, t4,messageId为&lt;r_1,m_4&gt;, 更新t1的ackVal为m_2^m_3^m_4</p>
<p>Bolt a ack t1, 向acker发送ack消息&lt;r_1, m_1^ m_2^m_3^m_4&gt;</p>
<p>Acker 收到bolt a的ack消息，更新缓存为&lt;r_1, m_1^ m_1^ m_2^m_3^m_4&gt;即&lt;r_1,  m_2^m_3^m_4&gt;</p>
<p>Bolt b ack t2, 向acker发送ack消息&lt;r_1, m_2&gt;</p>
<p>Acker 收到bolt b的ack消息，更新缓存为&lt;r_1, m_2^ m_2^m_3^m_4&gt;即&lt;r_1, m_3^m_4&gt;</p>
<p>Bolt b ack t3, 向acker发送ack消息&lt;r_1, m_3&gt;</p>
<p>Acker 收到bolt b的ack消息，更新缓存为&lt;r_1, m_3^m_3^m_4&gt;即&lt;r_1, m_4&gt;</p>
<p>Bolt b ack t4, 向acker发送ack消息&lt;r_1, m_4&gt;</p>
<p>Acker 收到bolt b的ack消息，更新缓存为&lt;r_1, m_4^m_4&gt;即&lt;r_1, 0&gt;</p>
<p>messageId确认完毕，向Spout发送ack消息。当消息没有被ack,会一直在spout的pending队列中，知道被ack或者超时。</p>
<p>它基本上使用两个long值就跟踪了一个消息在整个流中的处理过程。</p>
<p>【参考文献】</p>
<hr>
<ol>
<li><a href="https://mp.weixin.qq.com/s/PRDSu-qOxb17qjdfpO1IYA">Apache storm内核原理</a></li>
</ol>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache Storm专题</title>
    <url>/bigdata/storm/base/</url>
    <content><![CDATA[<h1 id="大数据流式计算及应用实践"><a href="#大数据流式计算及应用实践" class="headerlink" title="大数据流式计算及应用实践"></a>大数据流式计算及应用实践</h1><p>面向感知的数据流处理模型<br>R树、B+树</p>
<p>CAP（Consistency，Availability，tolerance to network Partitions） 理论说明，分布式系统中的一致性、可用性、分区容错性三者不可兼得。</p>
<p>所以，并行关系数据库必然无法获得较强的扩展性和良好的系统可用性。<br>面对这些挑战，以Google的BigTable为代表的NoSQL（notonlySQL）数据库发展起来。BigTable是一个多维稀疏排序表，由行和列组成，每个存储单元都有一个时间戳，形成三维结构。同一个数据单元的多个操作形成数据的多个版本，由时间戳来区分。</p>
<p>高性能批数据处理模式、流式数据处理模式和两者混合的模式。</p>
<p>批处理模式就是修改以Hadoop为代表的批处理框架，减少中间结果的写盘次数，增加作业间的流水化程度来提高单位时间的吞吐量。流处理模式，是针对流式数据的一种天然适合的处理方法，将到达的数据在维护的滑动窗口内进行处理，这将在下一章详细说明，典型系统如YahooS4和Storm。而两者混合的模式，主要思路是基于MapReduce模型增加或改变其中的某些处理步骤，以实现流处理。</p>
<p>四个时间点？<br>契税 多少？<br>查封 离婚 继承</p>
<p>距离 环境 学校</p>
<p>高性能批数据处理模式、流式数据处理模式和两者混合的模式。其中，批处理模式就是修改以Hadoop为代表的批处理框架，减少中间结果的写盘次数，增加作业间的流水化程度来提高单位时间的吞吐量。流处理模式，是针对流式数据的一种天然适合的处理方法，将到达的数据在维护的滑动窗口内进行处理，这将在下一章详细说明，典型系统如Yahoo S4和Storm。而两者混合的模式，主要思路是基于MapReduce模型增加或改变其中的某些处理步骤，以实现流处理。例如，DEDUCE系统扩展了IBM的流式数据处理System S，使其支持MapReduce。此外，SparkStreaming通过引入离散流（discretized streams）编程模型，改进了批处理模式，大幅提高了处理速度，并在Spark系统上实现了集成。</p>
<p>Storm 作为 一种 分布式 系统 的 体系 结构、 分布式 通信、 作业、 接 入/ 处理 组件 和 若干 进阶 的 概念。</p>
<p>丁维龙; 等. Storm：大数据流式计算及应用实践 (高端云计算与大数据丛书) (Kindle 位置 1278-1279). 电子工业出版社. Kindle 版本. </p>
<p>supervisor</p>
<p>工作进程执行指定topology的子集，而同一个topology可以由多个工作进程完成；一个工作进程由多个工作线程组成，工作线程是spout/bolt的运行时实例，数量由spout/bolt的数目及其配置确定。supervisor是分布式部署的，在Storm中的地位类似于Hadoop中的TaskTracker。</p>
<p>首先是作业在Storm系统中的部署。<br>    ① 用户将作业打包（即将topology的代码组织为jar文件），通过Storm的客户端命令或者控制台节点的Web接口，提交至Storm系统的主控节点；<br>    ② 主控节点根据系统的全局配置和作业中的局部配置，将接收的代码分发至调度的工作节点；<br>    ③ 工作节点下载来自主控节点的代码包，并根据主控节点的调度生成相关的工作进程和线程。</p>
<p>其次是系统节点状态的协调，包括如下几个部分。<br>    ①主控节点与协调节点之间：主控节点将系统全局的配置、节点局部的配置、主控节点运行时的状态，通过服务接口交由Zookeeper维护，由协调节点实现配置管理与状态监控；<br>    ②工作节点与协调节点之间：工作节点将自身的状态、工作进程和工作线程的状态，通过服务接口交由Zookeeper维护，由协调节点实现状态获取与更新；<br>    ③主控节点与控制台节点之间：控制台节点调用主控节点开放相关的接口，可以获取系统、作业、工作进程、工作线程和任务的运行时状态。</p>
<p>最后是工作节点间作业计算结果的数据传输，包括如下几个部分。<br>    ①组件间线程级的数据传递：在同一进程内，spout/bolt的工作线程将处理结果向作业的下游组件传递；<br>    ②组件间进程级的数据传递：在不同进程间（无论是否在同一台机器中），spout/bolt的工作线程将处理的结果向作业的下游组件传递。进程是操作系统中程序运行时的基本单元，线程是进程的最小调度单位，Storm的分布式数据处理，也是通过进程线程的调度实现的。<br>    注意：考虑到作业的独立性与安全性，Storm不支持跨作业的数据传递，故这里工作节点间的数据传输，一定存在于同一作业（隶属同一topology）的运行时实例进程/线程之间。</p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache Tomcat 9 源码分析</title>
    <url>/bigdata/tomcat/principle/</url>
    <content><![CDATA[<p>Apache tomcat 目前是最常用的免费开源的Java web应用容器(没有之一)，本文旨在分析<a href="https://tomcat.apache.org/download-90.cgi">Apache Tomcat 9 源码</a>，分析Tomcat高性能的原理</p>
<h2 id="Tomcat启动"><a href="#Tomcat启动" class="headerlink" title="Tomcat启动"></a>Tomcat启动</h2><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><h2 id="快速数组扩容"><a href="#快速数组扩容" class="headerlink" title="快速数组扩容"></a>快速数组扩容</h2><h2 id="classLoader"><a href="#classLoader" class="headerlink" title="classLoader"></a>classLoader</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a href="https://www.cnblogs.com/crazylqy/p/4706223.html">Tomcat服务器原理详解</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/">Tomcat 系统架构与设计模式，第1部分 工作原理</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-tomcat2">Tomcat 系统架构与设计模式，第2部分 设计模式分析</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务</title>
    <url>/bigdata/transaction/distributed-transaction/</url>
    <content><![CDATA[<h1 id="事务简介"><a href="#事务简介" class="headerlink" title="事务简介"></a>事务简介</h1><p>事务的核心是锁和并发, 采用同步控制的方式保证并发的情况下性能尽可能高, 且容易理解. 这种方式的优势是方便理解; 它的劣势是性能比较低.</p>
<p>计算机可以简单的理解为一个标准的打字机, 尽管看起来计算机可以并行处理很多事情, 但实际上每个CPU单位时间内只能做一件事, 要么读取数据、要么计算数据、要么写入数据, 所有的任务都可以看成这三件事的集合. 计算机的这种特性引出了一个问题：当多个人去读、算、写操作时, 如果不加访问控制, 系统势必会产生冲突. 而事务相当于在读、算、写操作之外增加了同步的模块, 进而保证只有一个线程进入事务当中, 而其他线程不会进入.</p>
<h2 id="单个事务单元"><a href="#单个事务单元" class="headerlink" title="单个事务单元"></a>单个事务单元</h2><p>事务的四大特性分别是：原子型、一致性、隔离性和持久性.<br><code>原子性</code>指的是事务中包含的所有操作要么全做, 要么全不做;<br><code>一致性</code>是指在事务开始以前, 数据库处于一致性的状态, 事务结束后, 数据库也必须处于一致性的状态;<br><code>隔离性</code>要求系统必须保证事务不受其他并发执行的事务的影响;<br><code>持久性</code>是指一个事务一旦成功完成, 它对数据库的改变必须是永久的, 即使是在系统遇到故障的情况下也不会丢失, 数据的重要性决定了事务的持久性的重要.</p>
<p><img src="/images/distributed/distributedTransaction/01.png"></p>
<p>事务单元是通过<code>Begin-Traction</code>, 然后<code>Commit</code>(<code>Begin-Traction</code>、<code>Commit</code>和<code>Rollback</code>之间所有针对数据的写入、读取的操作都应该添加同步访问), <code>Begin</code>和<code>Commit</code>之间就是一个同步的事务单元. 例如, Bob给Smith 100块钱就是一个事务单元, 这个过程中有很多步操作, 具体如上图所示; 但对业务来说, 仅是一个转账的操作.</p>
<h2 id="事务之间的关系"><a href="#事务之间的关系" class="headerlink" title="事务之间的关系"></a>事务之间的关系</h2><p>事务单元之间的happens-before关系: 《事务管理》</p>
<ul>
<li>读写</li>
<li>写读</li>
<li>写写</li>
<li>读读</li>
</ul>
<p><code>amdahl定律</code>: 最快并行, 最慢串行</p>
<p>最快的速度并保证逻辑顺序</p>
<p>目标–提高系统的易用性而不损失系统的性能</p>
<p><strong>数据库使用多线程的原因</strong></p>
<p>事务问题的来源</p>
<p>慢速设备：硬盘和网路 I/O PS过低,吞吐量很高</p>
<p>快速设备：内存</p>
<p><strong>一组事务单元</strong></p>
<p><img src="/images/distributed/distributedTransaction/02.png"></p>
<p>当三个账户都在进行转账操作时, 每个操作都涉及Smith账户, 所有的事务都会排队, 各自形成一组事务单元.</p>
<p>事务单元之间的<code>Happen-Before</code>关系中的四种可能性：<code>读写</code>、<code>写读</code>、<code>读读</code>、<code>写写</code>.<br>所有事务之间的关系都可以抽象成这四种之一, 来对应现在所有的业务逻辑处理. 在此基础之上, 需要用最快的速度处理多个事务单元之间的关系, 同时还能保障这四种操作的逻辑顺序.</p>
<p><strong>单个事务单元的其他例子</strong></p>
<p>除了转账操作是事务单元外, 诸如商品要建立一个基于<code>GMT_Modified</code>的索引、从数据库中读取一行记录、向数据库中写入一行记录, 同时更新这行记录的所有索引、删除整张表等都是一个事务单元.</p>
<p>也是一个事务单元:</p>
<ol>
<li>添加索引</li>
<li>从数据库读一条数据</li>
<li>向数据库写一条记录, 并更新索引</li>
<li>删除整张表</li>
</ol>
<h2 id="事务单元的实现方式"><a href="#事务单元的实现方式" class="headerlink" title="事务单元的实现方式"></a>事务单元的实现方式</h2><p><img src="/images/distributed/distributedTransaction/03.png"></p>
<p>Two Phase Lock(2PL)是数据库中非常重要的一个概念.<br><strong>数据库操作<code>Insert</code>、<code>Update</code>、<code>Delete</code>都是先读再写的操作</strong>, 例如<code>Insert</code>操作是先读取数据, 读取之后判读数据是否存在, 如果不存在, 则写入该数据, 如果数据存在, 则返回错误.<br>假设在该场景下没有读操作, 只是单纯写入数据, 则数据本身并没有事务操作, <code>Delete</code>、<code>Update</code>操作与之类似.<br><strong>数据库利用这些操作的特性, 在每一次查询过程中, 只要查到数据, 就会在该数据上加锁.理论上, 所有被读取的数据都已加锁, 不会再被其他人读到, 也就是说对数据进行的中间操作状态对所有人都不可见, 当所有中间状态完成后, 提交操作时, 解开锁, 此时数据对所有系统可见</strong> , 例如在转账过程中, 所有人只能看到两种状态：开始时, A有钱, B没钱; 结束时, B有钱, A没钱, 而中间A减掉钱, B尚未加上钱的状态被锁隐藏掉了, 这个操作就是数据库中处理事务的最标准的方式. 如上图所示：事务中的Trx2(JoeLock)与其他事务不相关, 因此可以并行执行; Trx1需要Lock两个数据Boblock和Smithlock, 而Trx3同样需要Lock这两个数据, 因此Trx3必须等待, 且等待在Boblock上; Joe事务会先结束, Trx3会等到Trx1完成后才会开始.</p>
<p>两阶段提交协议(基础是2pl): 事务单元内, 从读数据开始, 将所读的行锁住, 直到事务提交才释放.</p>
<h2 id="处理事务的常见方法"><a href="#处理事务的常见方法" class="headerlink" title="处理事务的常见方法"></a>处理事务的常见方法</h2><p>处理事务的常见方法有<code>排队法</code>、<code>排他锁</code>、<code>读写锁</code>、<code>MVCC</code>等方式, 下面来一一解析.</p>
<h3 id="排队法"><a href="#排队法" class="headerlink" title="排队法"></a>排队法</h3><p><img src="/images/distributed/distributedTransaction/04.png"></p>
<p>事务处理中最重要也是最简单的方案是排队法, 单线程地处理一堆数据. 在Redis中, 如果数据全部在内存中, 则单线程处理所有<code>Put</code>、<code>Get</code>操作效率最高.<br>这是因为多线程本质是CPU模拟多个线程, 这种模拟是以上下文切换为代价, 而对于内存的数据库来说, 没有上下文切换时效率最高. 因此, 单个CPU绑定一块内存的数据, 针对这块数据做多次读写操作时都是在单个CPU上完成的, 单线程处理方式在内存的情况是效率是最优的.</p>
<p>那么什么时候事务需要用到多线程呢？这个问题的本质取决于下层所使用的存储, 如果是内存操作, 则可以动态地申请和销毁内存块; 而磁盘的IOPS很低, 但吞吐量很高. 如果一个场景涉及多次读写操作, 单线程可以很高的效率对于内存进行读写操作; 但是, 由于磁盘的IOPS仅为内存的几千分之一, 如果依旧用操作内存的方式操作磁盘, 那系统的整体性能将会很低, 这意味着必须将大量的读写操作聚合成一个<code>Batch</code>后再提交时才能达到较好的性能. 而将大量请求攒到一起的方式一是<code>异步</code>, 也就是请求本身和线程不绑定, 线程可以不Block(本质来说还是一种多线程的方式), 处理完一个线程后再处理其他线程. 这种做法的核心是将大量不同的请求提交到一个Buffer中, 再由该Buffer统一读取或者写入磁盘, 从而提高效率. 在慢速设备中, 多线程或异步非常常见, 在设计系统时, 面对磁盘、网络、SSD等慢速设备必须考虑使用多线程.</p>
<h3 id="排他锁"><a href="#排他锁" class="headerlink" title="排他锁"></a>排他锁</h3><p><img src="/images/distributed/distributedTransaction/05.png"></p>
<p>有些场景不适合用单线程操作, 可以利用排他锁的方式来快速隔离并发读写事务. 数据库中有一些事务单元是共享的, 如图中的事务单元1是共享的, 事务单元2/3共享数据; 针对事务单元2/3共享数据的所有读写Block住, 事务单元1单独用一个锁来控制, 用这种方式完成系统的访问控制.</p>
<h3 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h3><p><img src="/images/distributed/distributedTransaction/06.png"></p>
<p>如果是一个只读的事务, 例如只对数据进行查询操作, 在该过程中数据一定不被修改, 因此多个查询操作可以并行执行, 因此一种针对读读场景的优化自然而然产生——读写锁. 读写锁的核心是在多次读的操作中, 同时允许多个读者来访问共享资源, 提高并发性.</p>
<h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><p><img src="/images/distributed/distributedTransaction/07.png"></p>
<p>在最初的数据库事务实现中是不存在MVCC的, 它是Oracle在八十年代新加的功能, 本质是<code>Copy On Write</code>, 也就是每次写都是以重新开始一个新的版本的方式写入数据,<br>因此, 数据库中也就包含了之前的所有版本. 在数据读的过程中, 先申请一个版本号, 如果该版本号小于正在写入的版本号, 则数据一定可以查询到, 无需等到新版本完全写完即可返回查询结果. 这种方式可以在读读不阻塞的前提下, 实现读写/写读不阻塞, 尽可能保证所有的读操作并行, 而写操作串行.</p>
<h2 id="事务的调优原则"><a href="#事务的调优原则" class="headerlink" title="事务的调优原则"></a>事务的调优原则</h2><p>事务的调优的思路是在不影响业务应用的前提下：</p>
<p>第一. 尽可能减少锁的覆盖范围, 例如 <code>Myisam表锁</code>到<code>Innodb行锁</code>就是一个减少锁覆盖范围的过程; 对于<code>原位锁</code>(<code>排他锁</code>、<code>读写锁</code>等)可变为<code>MVCC</code>多版本(本质仍然是减少锁的范围).<br>第二. 增加锁上可并行的线程数, 例如读锁和写锁的分离, 允许并行读取数据.<br>第三. 选择正确锁类型, 其中悲观锁适合并发争抢比较严重的场景; 乐观锁适合并发争抢不太严重的场景.</p>
<ul>
<li><p><code>悲观锁</code> 适合并发争抢比较严重的场景<br><code>Collections.sychronizedList(new ArrayList());</code></p>
</li>
<li><p><code>乐观锁</code> 适合并发争抢不太严重的场景, 如<code>自旋锁</code></p>
</li>
</ul>
<h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul>
<li>完整的事务支持<ul>
<li>像传统单机事务一样的操作方式</li>
<li>可按需无限扩展</li>
</ul>
</li>
</ul>
<p>容易理解的模型往往性能不好, 性能好的模型往往不容易理解—-这就是生活</p>
<h2 id="分布式事务带来的问题"><a href="#分布式事务带来的问题" class="headerlink" title="分布式事务带来的问题"></a>分布式事务带来的问题</h2><ul>
<li>网络带来的问题</li>
<li>基于锁的事务实现中遇到的问题<ul>
<li>从2PL到2PC</li>
<li>分布式事务的异常处理</li>
<li>分布式日志记录</li>
<li>分布式事务延迟变大的问题</li>
</ul>
</li>
<li>结合MVCC的事务实现中遇到的问题<ul>
<li>分布式顺序问题</li>
</ul>
</li>
</ul>
<p>并行与并发区别</p>
<h1 id="分布式事务-1"><a href="#分布式事务-1" class="headerlink" title="分布式事务"></a>分布式事务</h1><p>分布式事务服务(Distributed Transaction Service，DTS)</p>
<p>由于在分布式系统中经常发生丢包、网络故障，分区容忍性是必须要满足的，同时为了兼顾高可用性，绝大部分系统都将强一致性需求转化成最终一致性的需求，并通过幂等机制保证了数据的最终一致性。</p>
<p><strong>理解2PC和3PC协议</strong></p>
<p>为了解决分布式一致性问题，前人在性能和数据一致性的反反复复权衡过程中总结了许多典型的协议和算法。其中比较著名的有二阶提交协议(2 Phase Commitment Protocol)，三阶提交协议(3 Phase Commitment Protocol)。</p>
<p><strong>2PC</strong></p>
<p>分布式事务最常用的解决方案就是二阶段提交。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有参与者节点的操作结果并最终指示这些节点是否要把操作结果进行真正的提交。</p>
<p>因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。</p>
<p>所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段(执行阶段)。</p>
<p><strong>第一阶段：投票阶段</strong></p>
<p>该阶段的主要目的在于打探数据库集群中的各个参与者是否能够正常的执行事务，具体步骤如下：</p>
<ol>
<li>协调者向所有的参与者发送事务执行请求，并等待参与者反馈事务执行结果。</li>
<li>事务参与者收到请求之后，执行事务，但不提交，并记录事务日志。</li>
<li>参与者将自己事务执行情况反馈给协调者，同时阻塞等待协调者的后续指令。</li>
</ol>
<p><strong>第二阶段：事务提交阶段</strong></p>
<p>在第一阶段协调者的询盘之后，各个参与者会回复自己事务的执行情况，这时候存在三种可能：</p>
<ol>
<li>所有的参与者回复能够正常执行事务。</li>
<li>一个或多个参与者回复事务执行失败。</li>
<li>协调者等待超时。</li>
</ol>
<p>对于第一种情况，协调者将向所有的参与者发出提交事务的通知，具体步骤如下：</p>
<ol>
<li>协调者向各个参与者发送commit通知，请求提交事务。</li>
<li>参与者收到事务提交通知之后，执行commit操作，然后释放占有的资源。</li>
<li>参与者向协调者返回事务commit结果信息。</li>
</ol>
<p><img src="/images/distributed/distributedTransaction/08.jpg"></p>
<p>对于第二、三种情况，协调者均认为参与者无法正常成功执行事务，为了整个集群数据的一致性，所以要向各个参与者发送事务回滚通知，具体步骤如下：</p>
<ol>
<li>协调者向各个参与者发送事务rollback通知，请求回滚事务。</li>
<li>参与者收到事务回滚通知之后，执行rollback操作，然后释放占有的资源。</li>
<li>参与者向协调者返回事务rollback结果信息。</li>
</ol>
<p><img src="/images/distributed/distributedTransaction/09.jpg"></p>
<p>两阶段提交协议解决的是分布式数据库数据强一致性问题，其原理简单，易于实现，但是缺点也是显而易见的，主要缺点如下：</p>
<ul>
<li>单点问题：协调者在整个两阶段提交过程中扮演着举足轻重的作用，一旦协调者所在服务器宕机，那么就会影响整个数据库集群的正常运行，比如在第二阶段中，如果协调者因为故障不能正常发送事务提交或回滚通知，那么参与者们将一直处于阻塞状态，整个数据库集群将无法提供服务。</li>
<li>同步阻塞：两阶段提交执行过程中，所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率及其低下。</li>
<li>数据不一致性：两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务commit的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。</li>
</ul>
<p><strong>3PC</strong></p>
<p>针对两阶段提交存在的问题，三阶段提交协议通过引入一个“预询盘”阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。三阶段提交的三个阶段分别为：can_commit，pre_commit，do_commit。</p>
<p><strong>第一阶段：can_commit</strong></p>
<p>该阶段协调者会去询问各个参与者是否能够正常执行事务，参与者根据自身情况回复一个预估值，相对于真正的执行事务，这个过程是轻量的，具体步骤如下：</p>
<ol>
<li>协调者向各个参与者发送事务询问通知，询问是否可以执行事务操作，并等待回复。</li>
<li>各个参与者依据自身状况回复一个预估值，如果预估自己能够正常执行事务就返回确定信息，并进入预备状态，否则返回否定信息。</li>
</ol>
<p><strong>第二阶段：pre_commit</strong></p>
<p>本阶段协调者会根据第一阶段的询盘结果采取相应操作，询盘结果主要有三种：</p>
<ol>
<li>所有的参与者都返回确定信息。</li>
<li>一个或多个参与者返回否定信息。</li>
<li>协调者等待超时。</li>
</ol>
<p>针对第一种情况，协调者会向所有参与者发送事务执行请求，具体步骤如下：</p>
<ol>
<li>协调者向所有的事务参与者发送事务执行通知。</li>
<li>参与者收到通知后，执行事务，但不提交。</li>
<li>参与者将事务执行情况返回给客户端。</li>
</ol>
<p>在上面的步骤中，如果参与者等待超时，则会中断事务。 针对第二、三种情况，协调者认为事务无法正常执行，于是向各个参与者发出abort通知，请求退出预备状态，具体步骤如下：</p>
<ol>
<li>协调者向所有事务参与者发送abort通知</li>
<li>参与者收到通知后，中断事务</li>
</ol>
<p><img src="/images/distributed/distributedTransaction/10.jpg"></p>
<p><strong>第三阶段：do_commit</strong></p>
<p>如果第二阶段事务未中断，那么本阶段协调者将会依据事务执行返回的结果来决定提交或回滚事务，分为三种情况：</p>
<ol>
<li>所有的参与者都能正常执行事务。</li>
<li>一个或多个参与者执行事务失败。</li>
<li>协调者等待超时。</li>
</ol>
<p>针对第一种情况，协调者向各个参与者发起事务提交请求，具体步骤如下：</p>
<ol>
<li>协调者向所有参与者发送事务commit通知。</li>
<li>所有参与者在收到通知之后执行commit操作，并释放占有的资源。</li>
<li>参与者向协调者反馈事务提交结果。</li>
</ol>
<p><img src="/images/distributed/distributedTransaction/11.jpg"></p>
<p>针对第二、三种情况，协调者认为事务无法正常执行，于是向各个参与者发送事务回滚请求，具体步骤如下：</p>
<ol>
<li>协调者向所有参与者发送事务rollback通知。</li>
<li>所有参与者在收到通知之后执行rollback操作，并释放占有的资源。</li>
<li>参与者向协调者反馈事务提交结果。</li>
</ol>
<p><img src="/images/distributed/distributedTransaction/12.jpg"></p>
<p>在本阶段如果因为协调者或网络问题，导致参与者迟迟不能收到来自协调者的commit或rollback请求，那么参与者将不会如两阶段提交中那样陷入阻塞，而是等待超时后继续commit。相对于两阶段提交虽然降低了同步阻塞，但仍然无法避免数据的不一致性。</p>
<p>高吞吐 高性能 和单机事务一样易用</p>
<p>ACID</p>
<p>spandex</p>
<p>xa</p>
<p>java 协调器</p>
<p>分布式日志记录</p>
<p>隔离级别 事务的传递性</p>
<p>幂等</p>
<hr>
<p>【相关文献】</p>
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>Distributed</tag>
        <tag>Distributed Transaction</tag>
      </tags>
  </entry>
  <entry>
    <title>Yarn</title>
    <url>/bigdata/yarn/yarn/</url>
    <content><![CDATA[<h1 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h1><p>通信双方有一端是 Client，另一端为 Server，且 Client 总 是主动连接 Server 的</p>
<p>通信模型: pull-model</p>
<ul>
<li>步骤1: 用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。</li>
<li>步骤2: ResourceManager为该应用程序分配第一个Container，并与对应的Node-Manager通信，要求它在这个Container中启动应用程序的ApplicationMaster。</li>
<li>步骤3: ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。</li>
<li>步骤4: ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。</li>
<li>步骤5: 一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。</li>
<li>步骤6: NodeManager为任务设置好运行环境(包括环境变量、JAR包、二进制程序等)后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。</li>
<li>步骤7: 各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。</li>
<li>步骤8: 应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</li>
</ul>
<p><img src="_v_images/20201102100715955_326368511.png"></p>
<p><img src="_v_images/20201102103928512_1313552191.png"></p>
<p>Avro 是 Hadoop 生态系统中的 RPC 框架，具有平台无关、支持动态 模式(无需编译)等优点</p>
<p>cgroup相关配置</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">grep -A2 -B1 cg yarn-site.xml </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.memory-control.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.oom.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.hierarchy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop-yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/cgroup<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>yarn</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/actions/01.%20%E5%AE%9E%E6%97%B6%E5%8F%8D%E6%AC%BA%E8%AF%88/</url>
    <content><![CDATA[<h1 id="玖富实时反欺诈"><a href="#玖富实时反欺诈" class="headerlink" title="玖富实时反欺诈"></a>玖富实时反欺诈</h1><h2 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a>业务场景</h2><ul>
<li>低延迟</li>
<li>大数据</li>
<li>多维度</li>
</ul>
<p>系统获取用户产生数据最简单有效的方法就是流水式数据，单个数据包里包含了发生时间点的各个维度的所有信息量，这种场景的特性之一就是数据高并发，因此对时效要求比较高的数据分析来说是一个非常巨大的挑战</p>
<blockquote>
<p>在哪个场景下，实时宽表都是一个门槛</p>
</blockquote>
<ul>
<li><p>高并发</p>
</li>
<li><p>规则实时下发</p>
</li>
</ul>
<p>数据加工提速</p>
<p>在大量数据中做快速预查，利用Flink并发能力进行数据覆盖，最后在缓存里命中结果，从而不必重新进行网络I/O 查询、等待返回的过程。经过部分计算框架升级，最终系统实现了p99 延迟由1s 降为100ms 的优化</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/actions/02.%20%E5%AE%9E%E6%97%B6%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/</url>
    <content><![CDATA[<h1 id="实时用户画像"><a href="#实时用户画像" class="headerlink" title="实时用户画像"></a>实时用户画像</h1><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>企业面对不断增加的海量信息，其信息筛选和处理效率低下的困扰与日俱增。由于用户营销不够细化，企业App 中许多不合时宜或不合偏好的消息推送很大程度上影响了用户体验，甚至引发了用户流失</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/actions/FrundDetectedSystem/</url>
    <content><![CDATA[<h1 id="Flink-实时规则引擎实现与应用"><a href="#Flink-实时规则引擎实现与应用" class="headerlink" title="Flink 实时规则引擎实现与应用"></a>Flink 实时规则引擎实现与应用</h1><p>Rule engine</p>
<p>欺诈检测<br>实时标签工厂<br>ABT<br>CEP有什么问题？</p>
<p>Frund detected system</p>
<p>秒级规则生效<br>自定义分发，运行时动态切换<br>自定义窗口<br>实时多维聚合</p>
<p>样例:</p>
<ol>
<li>欺诈检测: 同一个用户连续往两一个账户三天内连续支付超过</li>
<li>实时标签工厂: 标签-用户近三十天访问次数、近三十天访问某个页面的次数</li>
<li>ABT</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/case/%E6%AC%BA%E8%AF%88%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="Flink实时规则引擎探究"><a href="#Flink实时规则引擎探究" class="headerlink" title="Flink实时规则引擎探究"></a>Flink实时规则引擎探究</h1><p>2020年Flink已经成为实时计算的事实标准, 以Flink高性能、灵活、易用等特性为依托，大数据计算和数据的实时性得到了较大的提升。为了解决商业运作中的业务问题，提高工作效率和经济利益，实时的商业决策势在必行，如:</p>
<ul>
<li>金融量化:  金融应用程序来查看股票市场的趋势</li>
<li>风险控制：欺诈检测–对用户异常行为模式进行实时检测，当一个用户发生了不该发生的行为，判定这个用户是不是有违规操作的嫌疑。</li>
<li>策略营销：用预先定义好的规则对用户的行为轨迹进行实时跟踪，对行为轨迹匹配预定义规则的用户实时发送相应策略的推广。</li>
<li>运维监控：灵活配置多指标、多依赖来实现更复杂的监控模式; 基于RFID的跟踪和监控系统(如检测仓库盗窃案); 通过指定可疑行为的模式来检测网络入侵。</li>
</ul>
<p>然而，对于实时规则引擎来说，既要保证事件快速处理，又要保证新规则快速生效。</p>
<p>从</p>
<h2 id="Flink-CEP-复杂事件处理"><a href="#Flink-CEP-复杂事件处理" class="headerlink" title="Flink CEP(复杂事件处理)"></a>Flink CEP(复杂事件处理)</h2><p>CEP是一个在Flink之上实现的库。在当前这个数据被认为和石油一样重要的时代，这是非常有用的，而石油一直在增长。数据源源不断地从智能设备中流出，需要大量的数据进行实时分析。CEP在这种情况下会发挥作用。</p>
<ul>
<li>解决了数据流中事件模式检测实时处理的关键问题。</li>
<li>它根据建议的模式连续匹配传入的数据。这有助于保留当前需要的数据，丢弃不相关的数据。输入立即匹配，结果直接发出。</li>
<li>它帮助您检测数据流中的模式，允许您只掌握重要的数据。</li>
</ul>
<h3 id="规则动态注入"><a href="#规则动态注入" class="headerlink" title="规则动态注入"></a>规则动态注入</h3><h2 id="Drools"><a href="#Drools" class="headerlink" title="Drools"></a>Drools</h2><h3 id="Flink-Drools"><a href="#Flink-Drools" class="headerlink" title="Flink + Drools"></a>Flink + Drools</h3><h3 id="Drools-on-Flink"><a href="#Drools-on-Flink" class="headerlink" title="Drools on Flink"></a>Drools on Flink</h3><h2 id="Broadcast-state-Groovy"><a href="#Broadcast-state-Groovy" class="headerlink" title="Broadcast state + Groovy"></a>Broadcast state + Groovy</h2><h3 id="Flink-CEP-应用场景"><a href="#Flink-CEP-应用场景" class="headerlink" title="Flink CEP 应用场景"></a>Flink CEP 应用场景</h3><p>实时规则引擎可以分为两种类型：纯Flink或Flink+离线规则引擎</p>
<p><a href="https://www.jianshu.com/p/04fd02c4db3c">Flink cep，使用groovy脚本及表达式求值</a></p>
<p><a href="">哈罗出行</a><a href="https://segmentfault.com/a/1190000021260907">Apache Flink CEP 实战</a></p>
<p><a href="http://hecenjie.cn/2019/05/28/Drools%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/">Drools规则引擎原理简介</a></p>
<p><a href="https://www.xenonstack.com/insights/flink-cep/">Flink CEP: Answer to All Stream Processing Difficulties</a></p>
<p><a href="https://blog.csdn.net/u013516966/article/details/110412808?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&spm=1001.2101.3001.4242">Flink-Cep实现规则动态更新</a></p>
<p><a href="https://developer.aliyun.com/article/738454">Apache Flink CEP 实战</a></p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/bigdata/Flink/dev_platform/Oceanus/</url>
    <content><![CDATA[<h1 id="Oceanus"><a href="#Oceanus" class="headerlink" title="Oceanus"></a>Oceanus</h1><p>org.springframework.web.servlet.HandlerInterceptor</p>
]]></content>
  </entry>
  <entry>
    <title>flink-streaming-platform-web</title>
    <url>/bigdata/Flink/dev_platform/flink-streaming-platform-web/</url>
    <content><![CDATA[<h1 id="flink-streaming-platform-web"><a href="#flink-streaming-platform-web" class="headerlink" title="flink-streaming-platform-web"></a>flink-streaming-platform-web</h1><p>~/apps/flink/bin/flink run     -c  com.flink.streaming.core.JobApplication ~/workspace/averyzhang/flink-streaming-platform-web/flink-streaming-web/target/lib/flink-streaming-core-1.2.0.RELEASE.jar -sql ~/workspace/averyzhang/flink-streaming-platform-web/flink-streaming-web/target/sql/job_sql_1.sql  -catalog memory -ynm flink@test01  -yd -m yarn-cluster</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
</search>
