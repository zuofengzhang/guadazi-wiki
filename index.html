<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/00.Flink-outline/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/00.Flink-outline/" class="post-title-link" itemprop="url">Flink-outline</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-10-15 19:47:00" itemprop="dateCreated datePublished" datetime="2021-10-15T19:47:00+08:00">2021-10-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:33:23" itemprop="dateModified" datetime="2021-04-12T17:33:23+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Flink-架构"><a href="#Flink-架构" class="headerlink" title="Flink 架构"></a>Flink 架构</h2><ul>
<li><input disabled="" type="checkbox"> CoLocationGroup</li>
<li><input disabled="" type="checkbox"> SlotSharingGroup</li>
<li><input disabled="" type="checkbox"> Flink state backend</li>
<li><input disabled="" type="checkbox"> Restart Strategies(重启策略)</li>
<li><input disabled="" type="checkbox"> Flink 2PC</li>
<li><input disabled="" type="checkbox"> Flink checkpoint与savepoint</li>
<li><input disabled="" type="checkbox"> Flink 反压</li>
<li><input disabled="" type="checkbox"> Flink 状态管理与TTL</li>
<li><input disabled="" type="checkbox"> Flink time</li>
<li><input disabled="" type="checkbox"> Flink timer</li>
<li><input disabled="" type="checkbox"> Flink window</li>
<li><input disabled="" type="checkbox"> Flink watermark</li>
</ul>
<h2 id="Flink-API"><a href="#Flink-API" class="headerlink" title="Flink API"></a>Flink API</h2><ul>
<li><input checked="" disabled="" type="checkbox"> <a href="bigdata/Flink/Flink-sink/">Flink三种Sink模式: Append、Upsert和Retract</a></li>
<li><input disabled="" type="checkbox"> Flink join: broadcast join、</li>
<li><input disabled="" type="checkbox"> Flink asyncIO</li>
</ul>
<h2 id="Flink-DataStream"><a href="#Flink-DataStream" class="headerlink" title="Flink DataStream"></a>Flink DataStream</h2><ul>
<li><input checked="" disabled="" type="checkbox"> <a href="bigdata/Flink/Flink-join/">Flink join</a></li>
</ul>
<h2 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h2><ul>
<li><input disabled="" type="checkbox"> <a href="bigdata/Flink/Flink-SQL-Join/">Flink SQL join</a></li>
<li><input disabled="" type="checkbox"> Flink interval join</li>
<li><input disabled="" type="checkbox"> Flink temporal join</li>
<li><input disabled="" type="checkbox"> Flink broadcast join</li>
<li><input disabled="" type="checkbox"> Flink SQL join的状态管理</li>
<li><input disabled="" type="checkbox"> <a href="bigdata/Flink/Flink-SQL-Window/">Flink window &amp; demo</a></li>
<li><input disabled="" type="checkbox"> Flink SQL-window aggregate与group aggregate</li>
<li><input disabled="" type="checkbox"> Flink over window与TopN</li>
<li><input disabled="" type="checkbox"> Flink SQL原理与blink优化</li>
</ul>
<h2 id="Flink-metric"><a href="#Flink-metric" class="headerlink" title="Flink metric"></a>Flink metric</h2><ul>
<li><input disabled="" type="checkbox"> Flink累加器和计数器:Accumulators &amp; Counters</li>
</ul>
<h2 id="Flink-CEP"><a href="#Flink-CEP" class="headerlink" title="Flink CEP"></a>Flink CEP</h2><h2 id="Flink-connectors"><a href="#Flink-connectors" class="headerlink" title="Flink connectors"></a>Flink connectors</h2><ul>
<li><input disabled="" type="checkbox"> kudu connector</li>
</ul>
<h2 id="Flink实践"><a href="#Flink实践" class="headerlink" title="Flink实践"></a>Flink实践</h2><ul>
<li><input disabled="" type="checkbox"> interval join实现outjoin</li>
<li><input disabled="" type="checkbox"> 双流join，一条流延迟</li>
<li><input disabled="" type="checkbox"> keyedState扩容</li>
<li><input disabled="" type="checkbox"> Flink-bloomfilter近似去重</li>
</ul>
<p><img src="_v_images/flink-structure.svg" alt="The processes involved in executing a Flink dataflow"></p>
<h2 id="stateful-stream-processing"><a href="#stateful-stream-processing" class="headerlink" title="stateful stream processing"></a>stateful stream processing</h2><p>processFunction</p>
<p>低阶API<br>构建一些新的组件<br>比如 利用定时做一定情况下的匹配和缓存<br>灵活，开发比较复杂</p>
<p>凌晨更新  注册定时器 </p>
<h2 id="state"><a href="#state" class="headerlink" title="state"></a>state</h2><p>状态托管<br>operator state 算子状态<br>keyed state<br>State Backend (rocksdb + hdfs)</p>
<h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>barrier</p>
<h3 id="如何自定义-Window？"><a href="#如何自定义-Window？" class="headerlink" title="如何自定义 Window？"></a>如何自定义 Window？</h3><p>1、Window Assigner</p>
<p>负责将元素分配到不同的 window。</p>
<p>Window API 提供了自定义的 WindowAssigner 接口，我们可以实现 WindowAssigner 的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public abstract Collection&lt;W&gt; assignWindows(T element, long timestamp)</span><br></pre></td></tr></table></figure>
<p>方法。同时，对于基于 Count 的 window 而言，默认采用了 GlobalWindow 的 window assigner，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keyBy.window(GlobalWindows.create())</span><br></pre></td></tr></table></figure>
<p>2、Trigger</p>
<p>Trigger 即触发器，定义何时或什么情况下移除 window</p>
<p>我们可以指定触发器来覆盖 WindowAssigner 提供的默认触发器。 请注意，指定的触发器不会添加其他触发条件，但会替换当前触发器。</p>
<p>3、Evictor（可选）</p>
<p>驱逐者，即保留上一 window 留下的某些元素</p>
<p>4、通过 apply WindowFunction 来返回 DataStream 类型数据。</p>
<p>利用 Flink 的内部窗口机制和 DataStream API 可以实现自定义的窗口逻辑，例如 session window。</p>
<h3 id="EventTime-amp-ProcessTime-amp-IngestionTime"><a href="#EventTime-amp-ProcessTime-amp-IngestionTime" class="headerlink" title="EventTime &amp; ProcessTime &amp; IngestionTime"></a>EventTime &amp; ProcessTime &amp; IngestionTime</h3><p> Event time programs must specify how to generate <em>Event Time Watermarks</em>, which is the mechanism that signals progress in event time</p>
<p>Internally, <em>ingestion time</em> is treated much like <em>event time</em>, but with automatic timestamp assignment and automatic watermark generation.</p>
<h2 id="watermark"><a href="#watermark" class="headerlink" title="watermark"></a>watermark</h2><p>kafka的每个分区event-time到来的时间不一致</p>
<p>using Flink’s Kafka-partition-aware watermark generation. watermarks are generated inside the Kafka consumer, per Kafka partition, and the per-partition watermarks are merged in the same way as watermarks are merged on stream shuffles.</p>
<p>watermark在每个kafka分区的kafka消费者中产生，每个分区的watermark合并起来，如在stream shuffle中合并watermark一样</p>
<h2 id="HadoopOutputFormat"><a href="#HadoopOutputFormat" class="headerlink" title="HadoopOutputFormat"></a>HadoopOutputFormat</h2><p>flink hbase connector</p>
<h2 id="算子之间数据传递，是如何序列化的"><a href="#算子之间数据传递，是如何序列化的" class="headerlink" title="算子之间数据传递，是如何序列化的"></a>算子之间数据传递，是如何序列化的</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/crestofwave1/oneFlink">Flink官方文档翻译</a></li>
</ul>
<h2 id="flink-report"><a href="#flink-report" class="headerlink" title="flink report"></a>flink report</h2><h2 id="storm-trident"><a href="#storm-trident" class="headerlink" title="storm trident"></a>storm trident</h2><p>微批</p>
<p>barrier对齐</p>
<p><img src="_v_images/20190826164001201_1759200368.png" alt="flink-rm"></p>
<h2 id="算子"><a href="#算子" class="headerlink" title="算子"></a>算子</h2><h3 id="Reduce在流计算的应用"><a href="#Reduce在流计算的应用" class="headerlink" title="Reduce在流计算的应用"></a>Reduce在流计算的应用</h3><p>org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor$LoggingHandler:140 -<br>Timestamp monotony violated: 1568772496000 &lt; 1568772500000</p>
<p>ToDo list</p>
<h1 id="avro-与-kryo-序列化的区别"><a href="#avro-与-kryo-序列化的区别" class="headerlink" title="avro 与 kryo 序列化的区别"></a>avro 与 kryo 序列化的区别</h1><p>使用场景</p>
<h2 id="storm-allGrouping-元素广播"><a href="#storm-allGrouping-元素广播" class="headerlink" title="storm allGrouping 元素广播"></a>storm allGrouping 元素广播</h2><p>flink broadcast how to use </p>
<p>broadcast vaiable value can not be modified</p>
<p>用法<br>1：初始化数据<br>DataSet<Integer> toBroadcast = env.fromElements(1, 2, 3)<br>2：广播数据<br>.withBroadcastSet(toBroadcast, “broadcastSetName”);<br>3：获取数据<br>Collection<Integer> broadcastSet = getRuntimeContext().getBroadcastVariable(“broadcastSetName”);</p>
<ul>
<li>广播变量不能太大</li>
<li>不能修改，保证数据一致性</li>
</ul>
<h2 id="spark-accumulate"><a href="#spark-accumulate" class="headerlink" title="spark accumulate"></a>spark accumulate</h2><p>用法<br>1：创建累加器<br>private IntCounter numLines = new IntCounter();<br>2：注册累加器<br>getRuntimeContext().addAccumulator(“num-lines”, this.numLines);<br>3：使用累加器<br>this.numLines.add(1);<br>4：获取累加器的结果<br>myJobExecutionResult.getAccumulatorResult(“num-lines”)</p>
<h1 id="Distributed-Cache"><a href="#Distributed-Cache" class="headerlink" title="Distributed Cache"></a>Distributed Cache</h1><blockquote>
<p>Spark 分布式缓存如何使用</p>
</blockquote>
<p>Flink提供了一个分布式缓存，类似于hadoop，可以使用户在并行函数中很方便的读取本地文件<br>此缓存的工作机制如下：程序注册一个文件或者目录(本地或者远程文件系统，例如hdfs或者s3)，通过ExecutionEnvironment注册缓存文件并为它起一个名称。当程序执行，Flink自动将文件或者目录复制到所有taskmanager节点的本地文件系统，用户可以通过这个指定的名称查找文件或者目录，然后从taskmanager节点的本地文件系统访问它<br>用法<br>1：注册一个文件<br>env.registerCachedFile(“hdfs:///path/to/your/file”, “hdfsFile”)<br>2：访问数据<br>File myFile = getRuntimeContext().getDistributedCache().getFile(“hdfsFile”);</p>
<h1 id="at-least-once-amp-exactly-once"><a href="#at-least-once-amp-exactly-once" class="headerlink" title="at least once &amp; exactly once"></a>at least once &amp; exactly once</h1><p>从容错和消息处理的语义上(at least once, exactly once)，Flink引入了state和checkpoint。</p>
<h1 id="state-1"><a href="#state-1" class="headerlink" title="state"></a>state</h1><p>默认保存在java堆中<br>checkpoint: 把state持久化存储，全局快照<br>blink做的优化</p>
<p>失败恢复机制 </p>
<p>状态分为原始状态和托管状态</p>
<p>托管状态是由Flink框架管理的状态<br>而原始状态，由用户自行管理状态具体的数据结构，框架在做checkpoint的时候，使用byte[]来读写状态内容，对其内部数据结构一无所知。<br>通常在DataStream上的状态推荐使用托管的状态，当实现一个用户自定义的operator时，会使用到原始状态。</p>
<blockquote>
<p>ReducingState 如何使用</p>
</blockquote>
<h1 id="checkpoint-1"><a href="#checkpoint-1" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>Flink的checkpoint机制可以与(stream和state)的持久化存储交互的前提：<br>持久化的source，它需要支持在一定时间内重放事件。这种sources的典型例子是持久化的消息队列（比如Apache Kafka，RabbitMQ等）或文件系统（比如HDFS，S3，GFS等）<br>用于state的持久化存储，例如分布式文件系统（比如HDFS，S3，GFS等）</p>
<p>Checkpoint是Flink实现容错机制最核心的功能，它能够根据配置周期性地基于Stream中各个Operator/task的状态来生成快照，从而将这些状态数据定期持久化存储下来，当Flink程序一旦意外崩溃时，重新运行程序时可以有选择地从这些快照进行恢复，从而修正因为故障带来的程序数据异常</p>
<p>checkpoint开启之后，默认的checkPointMode是Exactly-once<br>checkpoint的checkPointMode有两种，Exactly-once和At-least-once<br>Exactly-once对于大多数应用来说是最合适的。At-least-once可能用在某些延迟超低的应用程序（始终延迟为几毫秒）</p>
<p>ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION:表示一旦Flink处理程序被cancel后，会保留Checkpoint数据，以便根据实际需要恢复到指定的Checkpoint<br>ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION: 表示一旦Flink处理程序被cancel后，会删除Checkpoint数据，只有job执行失败的时候才会保存checkpoint</p>
<h1 id="state-backend"><a href="#state-backend" class="headerlink" title="state backend"></a>state backend</h1><p>默认情况下，state会保存在taskmanager的内存中，checkpoint会存储在JobManager的内存中。<br>state 的store和checkpoint的位置取决于State Backend的配置<br>env.setStateBackend(…)<br>一共有三种State Backend<br>MemoryStateBackend<br>FsStateBackend<br>RocksDBStateBackend</p>
<p>MemoryStateBackend<br>state数据保存在java堆内存中，执行checkpoint的时候，会把state的快照数据保存到jobmanager的内存中<br>基于内存的state backend在生产环境下不建议使用<br>FsStateBackend<br>state数据保存在taskmanager的内存中，执行checkpoint的时候，会把state的快照数据保存到配置的文件系统中<br>可以使用hdfs等分布式文件系统<br>RocksDBStateBackend<br>RocksDB跟上面的都略有不同，它会在本地文件系统中维护状态，state会直接写入本地rocksdb中。同时它需要配置一个远端的filesystem uri（一般是HDFS），在做checkpoint的时候，会把本地的数据直接复制到filesystem中。fail over的时候从filesystem中恢复到本地<br>RocksDB克服了state受内存限制的缺点，同时又能够持久化到远端文件系统中，比较适合在生产中使用</p>
<p>修改State Backend的两种方式<br>第一种：单任务调整<br>修改当前任务代码<br>env.setStateBackend(new FsStateBackend(“hdfs://namenode:9000/flink/checkpoints”));<br>或者new MemoryStateBackend()<br>或者new RocksDBStateBackend(filebackend, true);【需要添加第三方依赖】<br>第二种：全局调整<br>修改flink-conf.yaml<br>state.backend: filesystem<br>state.checkpoints.dir: hdfs://namenode:9000/flink/checkpoints<br>注意：state.backend的值可以是下面几种：jobmanager(MemoryStateBackend), filesystem(FsStateBackend), rocksdb(RocksDBStateBackend)</p>
<h1 id="Restart-Strategies-重启策略"><a href="#Restart-Strategies-重启策略" class="headerlink" title="Restart Strategies(重启策略)"></a>Restart Strategies(重启策略)</h1><p>默认重启策略通过 flink-conf.yaml 指定</p>
<p>常用的重启策略<br>固定间隔 (Fixed delay)<br>失败率 (Failure rate)<br>无重启 (No restart)<br>如果没有启用 checkpointing，则使用无重启 (no restart) 策略。<br>如果启用了 checkpointing，但没有配置重启策略，则使用固定间隔 (fixed-delay) 策略，其中 Integer.MAX_VALUE 参数是尝试重启次数<br>重启策略可以在flink-conf.yaml中配置，表示全局的配置。也可以在应用代码中动态指定，会覆盖全局配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">第一种：全局配置 flink-conf.yaml</span><br><span class="line">restart-strategy: fixed-delay</span><br><span class="line">restart-strategy.fixed-delay.attempts: <span class="number">3</span></span><br><span class="line">restart-strategy.fixed-delay.delay: <span class="number">10</span> s</span><br><span class="line">第二种：应用代码设置</span><br><span class="line">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 尝试重启的次数</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 间隔</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure>






<h2 id="Flink-table"><a href="#Flink-table" class="headerlink" title="Flink table"></a>Flink table</h2><h3 id="over-window"><a href="#over-window" class="headerlink" title="over window"></a>over window</h3><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul>
<li><input disabled="" type="checkbox"> Flink Table API office</li>
<li><input disabled="" type="checkbox"> 自定义窗口</li>
<li><input disabled="" type="checkbox"> cogroup、connect与 join</li>
<li><input disabled="" type="checkbox"> CDC</li>
<li><input disabled="" type="checkbox"> flink流测试工具</li>
<li><input disabled="" type="checkbox"> 今日活动总申购次数：并发度为1，是否windowAll都会是并发度为1，是否可以先keyBy再合并？</li>
</ul>
<p>If the parallelism of the environment is set to 3 and you are using a WindowAll operator, only the window operator runs in parallelism 1. The sink will still be running with parallelism 3. Hence, the plan looks as follows:</p>
<p>In_1 -\               /- Out_1<br>In_2 — WindowAll_1 — Out_2<br>In_3 -/               - Out_3<br>The WindowAll operator emits its output to its subsequent tasks using a round-robin strategy. That’s the reason for the different threads emitting the result records of program.</p>
<p>When you set the environment parallelism to 1, all operators run with a single task.</p>
<p>keyed-windown —分布式计算—&gt; all-windown</p>
<p>#【亿级流量 秒级统计】</p>
<p>AI、ML、DL、ANN、CNN 蛰伏数十年，就为这个大数据时代。</p>
<p>AI正以前所未有的速度改变世界，影响着我们生活的方方面面，AI走进人们的生活将成为未来的新常态。 而大数据和计算能力像水和氧气一样支撑着AI，我们的数据从手机端、服务器日志</p>
<h1 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/crestofwave1/oneFlink">Flink官方文档翻译</a></li>
</ul>
<h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><h2 id="checkpoint与savepoint区别"><a href="#checkpoint与savepoint区别" class="headerlink" title="checkpoint与savepoint区别"></a>checkpoint与savepoint区别</h2><h2 id="flink-report-1"><a href="#flink-report-1" class="headerlink" title="flink report"></a>flink report</h2><h2 id="storm-trident-1"><a href="#storm-trident-1" class="headerlink" title="storm trident"></a>storm trident</h2><p>微批</p>
<p>barrier对齐</p>
<p>![flink-rm](_v_images/20190826164001201_1759200368.png =510x)</p>
<h2 id="算子-1"><a href="#算子-1" class="headerlink" title="算子"></a>算子</h2><h3 id="Reduce在流计算的应用-1"><a href="#Reduce在流计算的应用-1" class="headerlink" title="Reduce在流计算的应用"></a>Reduce在流计算的应用</h3><p>org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor$LoggingHandler:140 -<br>Timestamp monotony violated: 1568772496000 &lt; 1568772500000</p>
<p>ToDo list</p>
<h1 id="avro-与-kryo-序列化的区别-1"><a href="#avro-与-kryo-序列化的区别-1" class="headerlink" title="avro 与 kryo 序列化的区别"></a>avro 与 kryo 序列化的区别</h1><p>使用场景</p>
<h1 id="broadcast"><a href="#broadcast" class="headerlink" title="broadcast"></a>broadcast</h1><h2 id="storm-allGrouping-元素广播-1"><a href="#storm-allGrouping-元素广播-1" class="headerlink" title="storm allGrouping 元素广播"></a>storm allGrouping 元素广播</h2><p>flink broadcast how to use </p>
<p>broadcast vaiable value can not be modified</p>
<p>用法<br>1：初始化数据<br>DataSet<Integer> toBroadcast = env.fromElements(1, 2, 3)<br>2：广播数据<br>.withBroadcastSet(toBroadcast, “broadcastSetName”);<br>3：获取数据<br>Collection<Integer> broadcastSet = getRuntimeContext().getBroadcastVariable(“broadcastSetName”);</p>
<ul>
<li>广播变量不能太大</li>
<li>不能修改，保证数据一致性</li>
</ul>
<h1 id="Accumulators-amp-Counters"><a href="#Accumulators-amp-Counters" class="headerlink" title="Accumulators &amp; Counters"></a>Accumulators &amp; Counters</h1><p>累加器与计数器</p>
<h2 id="spark-accumulate-1"><a href="#spark-accumulate-1" class="headerlink" title="spark accumulate"></a>spark accumulate</h2><p>用法<br>1：创建累加器<br>private IntCounter numLines = new IntCounter();<br>2：注册累加器<br>getRuntimeContext().addAccumulator(“num-lines”, this.numLines);<br>3：使用累加器<br>this.numLines.add(1);<br>4：获取累加器的结果<br>myJobExecutionResult.getAccumulatorResult(“num-lines”)</p>
<h1 id="Distributed-Cache-1"><a href="#Distributed-Cache-1" class="headerlink" title="Distributed Cache"></a>Distributed Cache</h1><blockquote>
<p>Spark 分布式缓存如何使用</p>
</blockquote>
<p>Flink提供了一个分布式缓存，类似于hadoop，可以使用户在并行函数中很方便的读取本地文件<br>此缓存的工作机制如下：程序注册一个文件或者目录(本地或者远程文件系统，例如hdfs或者s3)，通过ExecutionEnvironment注册缓存文件并为它起一个名称。当程序执行，Flink自动将文件或者目录复制到所有taskmanager节点的本地文件系统，用户可以通过这个指定的名称查找文件或者目录，然后从taskmanager节点的本地文件系统访问它<br>用法<br>1：注册一个文件<br>env.registerCachedFile(“hdfs:///path/to/your/file”, “hdfsFile”)<br>2：访问数据<br>File myFile = getRuntimeContext().getDistributedCache().getFile(“hdfsFile”);</p>
<h1 id="at-least-once-amp-exactly-once-1"><a href="#at-least-once-amp-exactly-once-1" class="headerlink" title="at least once &amp; exactly once"></a>at least once &amp; exactly once</h1><p>从容错和消息处理的语义上(at least once, exactly once)，Flink引入了state和checkpoint。</p>
<h1 id="state-2"><a href="#state-2" class="headerlink" title="state"></a>state</h1><p>默认保存在java堆中<br>checkpoint: 把state持久化存储，全局快照<br>blink做的优化</p>
<p>失败恢复机制 </p>
<p>状态分为原始状态和托管状态</p>
<p>托管状态是由Flink框架管理的状态<br>而原始状态，由用户自行管理状态具体的数据结构，框架在做checkpoint的时候，使用byte[]来读写状态内容，对其内部数据结构一无所知。<br>通常在DataStream上的状态推荐使用托管的状态，当实现一个用户自定义的operator时，会使用到原始状态。</p>
<blockquote>
<p>ReducingState 如何使用</p>
</blockquote>
<h1 id="checkpoint-2"><a href="#checkpoint-2" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>Flink的checkpoint机制可以与(stream和state)的持久化存储交互的前提：<br>持久化的source，它需要支持在一定时间内重放事件。这种sources的典型例子是持久化的消息队列（比如Apache Kafka，RabbitMQ等）或文件系统（比如HDFS，S3，GFS等）<br>用于state的持久化存储，例如分布式文件系统（比如HDFS，S3，GFS等）</p>
<p>Checkpoint是Flink实现容错机制最核心的功能，它能够根据配置周期性地基于Stream中各个Operator/task的状态来生成快照，从而将这些状态数据定期持久化存储下来，当Flink程序一旦意外崩溃时，重新运行程序时可以有选择地从这些快照进行恢复，从而修正因为故障带来的程序数据异常</p>
<p>checkpoint开启之后，默认的checkPointMode是Exactly-once<br>checkpoint的checkPointMode有两种，Exactly-once和At-least-once<br>Exactly-once对于大多数应用来说是最合适的。At-least-once可能用在某些延迟超低的应用程序（始终延迟为几毫秒）</p>
<p>ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION:表示一旦Flink处理程序被cancel后，会保留Checkpoint数据，以便根据实际需要恢复到指定的Checkpoint<br>ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION: 表示一旦Flink处理程序被cancel后，会删除Checkpoint数据，只有job执行失败的时候才会保存checkpoint</p>
<h1 id="state-backend-1"><a href="#state-backend-1" class="headerlink" title="state backend"></a>state backend</h1><p>默认情况下，state会保存在taskmanager的内存中，checkpoint会存储在JobManager的内存中。<br>state 的store和checkpoint的位置取决于State Backend的配置<br>env.setStateBackend(…)<br>一共有三种State Backend<br>MemoryStateBackend<br>FsStateBackend<br>RocksDBStateBackend</p>
<p>MemoryStateBackend<br>state数据保存在java堆内存中，执行checkpoint的时候，会把state的快照数据保存到jobmanager的内存中<br>基于内存的state backend在生产环境下不建议使用<br>FsStateBackend<br>state数据保存在taskmanager的内存中，执行checkpoint的时候，会把state的快照数据保存到配置的文件系统中<br>可以使用hdfs等分布式文件系统<br>RocksDBStateBackend<br>RocksDB跟上面的都略有不同，它会在本地文件系统中维护状态，state会直接写入本地rocksdb中。同时它需要配置一个远端的filesystem uri（一般是HDFS），在做checkpoint的时候，会把本地的数据直接复制到filesystem中。fail over的时候从filesystem中恢复到本地<br>RocksDB克服了state受内存限制的缺点，同时又能够持久化到远端文件系统中，比较适合在生产中使用</p>
<p>修改State Backend的两种方式<br>第一种：单任务调整<br>修改当前任务代码<br>env.setStateBackend(new FsStateBackend(“hdfs://namenode:9000/flink/checkpoints”));<br>或者new MemoryStateBackend()<br>或者new RocksDBStateBackend(filebackend, true);【需要添加第三方依赖】<br>第二种：全局调整<br>修改flink-conf.yaml<br>state.backend: filesystem<br>state.checkpoints.dir: hdfs://namenode:9000/flink/checkpoints<br>注意：state.backend的值可以是下面几种：jobmanager(MemoryStateBackend), filesystem(FsStateBackend), rocksdb(RocksDBStateBackend)</p>
<h1 id="Restart-Strategies-重启策略-1"><a href="#Restart-Strategies-重启策略-1" class="headerlink" title="Restart Strategies(重启策略)"></a>Restart Strategies(重启策略)</h1><p>默认重启策略通过 flink-conf.yaml 指定</p>
<p>常用的重启策略<br>固定间隔 (Fixed delay)<br>失败率 (Failure rate)<br>无重启 (No restart)<br>如果没有启用 checkpointing，则使用无重启 (no restart) 策略。<br>如果启用了 checkpointing，但没有配置重启策略，则使用固定间隔 (fixed-delay) 策略，其中 Integer.MAX_VALUE 参数是尝试重启次数<br>重启策略可以在flink-conf.yaml中配置，表示全局的配置。也可以在应用代码中动态指定，会覆盖全局配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">第一种：全局配置 flink-conf.yaml</span><br><span class="line">restart-strategy: fixed-delay</span><br><span class="line">restart-strategy.fixed-delay.attempts: <span class="number">3</span></span><br><span class="line">restart-strategy.fixed-delay.delay: <span class="number">10</span> s</span><br><span class="line">第二种：应用代码设置</span><br><span class="line">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 尝试重启的次数</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 间隔</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure>



      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-SQL-Window/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-SQL-Window/" class="post-title-link" itemprop="url">Flink sql window</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-04-12 19:47:00 / Modified: 17:33:23" itemprop="dateCreated datePublished" datetime="2021-04-12T19:47:00+08:00">2021-04-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>flink窗口函数包含滚动窗口、滑动窗口、会话窗口和OVER窗口</p>
<h2 id="Flink-SQL-窗口的基本概念与使用"><a href="#Flink-SQL-窗口的基本概念与使用" class="headerlink" title="Flink SQL 窗口的基本概念与使用"></a>Flink SQL 窗口的基本概念与使用</h2><h3 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h3><p>滚动窗口（TUMBLE）将每个元素分配到一个指定大小的窗口中。通常，滚动窗口有一个固定的大小，并且不会出现重叠。例如，如果指定了一个5分钟大小的滚动窗口，无限流的数据会根据时间划分为<code>[0:00 - 0:05)</code>、<code>[0:05, 0:10)</code>、<code>[0:10, 0:15)</code>等窗口。下图展示了一个30秒的滚动窗口。<br><img src="_v_images/20210412125050690_701107302"><br>使用标识函数选出窗口的起始时间或者结束时间，窗口的时间属性用于下级Window的聚合。</p>
<table>
<thead>
<tr>
<th>窗口标识函数</th>
<th>返回类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>TUMBLE_START(time-attr, size-interval)</code></td>
<td>TIMESTAMP</td>
<td>返回窗口的起始时间（包含边界）。例如<code>[00:10, 00:15)</code> 窗口，返回<code>00:10</code> 。</td>
</tr>
<tr>
<td><code>TUMBLE_END(time-attr, size-interval)</code></td>
<td>TIMESTAMP</td>
<td>返回窗口的结束时间（包含边界）。例如<code>[00:00, 00:15]</code>窗口，返回<code>00:15</code>。</td>
</tr>
<tr>
<td><code>TUMBLE_ROWTIME(time-attr, size-interval)</code></td>
<td>TIMESTAMP(rowtime-attr)</td>
<td>返回窗口的结束时间（不包含边界）。例如<code>[00:00, 00:15]</code>窗口，返回<code>00:14:59.999</code> 。返回值是一个rowtime attribute，即可以基于该字段做时间属性的操作，例如，级联窗口只能用在基于Event Time的Window上</td>
</tr>
<tr>
<td><code>TUMBLE_PROCTIME(time-attr, size-interval)</code></td>
<td>TIMESTAMP(rowtime-attr)</td>
<td>返回窗口的结束时间（不包含边界）。例如<code>[00:00, 00:15]</code>窗口，返回<code>00:14:59.999</code>。返回值是一个proctime attribute，即可以基于该字段做时间属性的操作，例如，级联窗口只能用在基于Processing Time的Window上</td>
</tr>
</tbody></table>
<p>TUMBLE window示例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.TypeHint;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.TypeInformation;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple3;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.TimeCharacteristic;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.Timestamp;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TumbleWindowExample</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1 注册环境</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        EnvironmentSettings mySetting = EnvironmentSettings</span><br><span class="line">                .newInstance()</span><br><span class="line"><span class="comment">//                .useOldPlanner()</span></span><br><span class="line">                .useBlinkPlanner()</span><br><span class="line">                .inStreamingMode()</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取 environment</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">// 指定系统时间概念为 event time</span></span><br><span class="line">        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line"></span><br><span class="line">        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env,mySetting);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 初始数据</span></span><br><span class="line">        DataStream&lt;Tuple3&lt;Long, String,Integer&gt;&gt; log = env.fromCollection(Arrays.asList(</span><br><span class="line">                <span class="comment">//时间 14:53:00</span></span><br><span class="line">                <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591180_000L</span>,<span class="string">&quot;xiao_ming&quot;</span>,<span class="number">300</span>),</span><br><span class="line">                <span class="comment">//时间 14:53:09</span></span><br><span class="line">                <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591189_000L</span>,<span class="string">&quot;zhang_san&quot;</span>,<span class="number">303</span>),</span><br><span class="line">                <span class="comment">//时间 14:53:12</span></span><br><span class="line">                <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591192_000L</span>, <span class="string">&quot;xiao_li&quot;</span>,<span class="number">204</span>),</span><br><span class="line">                <span class="comment">//时间 14:53:21</span></span><br><span class="line">                <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591201_000L</span>,<span class="string">&quot;li_si&quot;</span>, <span class="number">208</span>)</span><br><span class="line">                ));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定时间戳</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple3&lt;Long, String, Integer&gt;&gt; logWithTime = log.assignTimestampsAndWatermarks(<span class="keyword">new</span> AscendingTimestampExtractor&lt;Tuple3&lt;Long, String, Integer&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(Tuple3&lt;Long, String, Integer&gt; element)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> element.f0;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 转换为 Table</span></span><br><span class="line">        Table logT = tEnv.fromDataStream(logWithTime, <span class="string">&quot;t.rowtime, name, v&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Table result = tEnv.sqlQuery(<span class="string">&quot;SELECT TUMBLE_START(t, INTERVAL &#x27;10&#x27; SECOND) AS window_start,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;TUMBLE_END(t, INTERVAL &#x27;10&#x27; SECOND) AS window_end, SUM(v) FROM &quot;</span></span><br><span class="line">                + logT + <span class="string">&quot; GROUP BY TUMBLE(t, INTERVAL &#x27;10&#x27; SECOND)&quot;</span>);</span><br><span class="line"></span><br><span class="line">        TypeInformation&lt;Tuple3&lt;Timestamp,Timestamp,Integer&gt;&gt; tpinf = <span class="keyword">new</span> TypeHint&lt;Tuple3&lt;Timestamp,Timestamp,Integer&gt;&gt;()&#123;&#125;.getTypeInfo();</span><br><span class="line">        tEnv.toAppendStream(result, tpinf).print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>sql逻辑，每十秒钟聚合<br>执行结果：  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(2019-11-01 06:53:00.0,2019-11-01 06:53:10.0,603)  </span><br><span class="line">(2019-11-01 06:53:20.0,2019-11-01 06:53:30.0,208)  </span><br><span class="line">(2019-11-01 06:53:10.0,2019-11-01 06:53:20.0,204)</span><br></pre></td></tr></table></figure>
<h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><p>滑动窗口（HOP），也被称作Sliding Window。不同于滚动窗口，滑动窗口的窗口可以重叠。</p>
<p>滑动窗口有两个参数：slide和size。slide为每次滑动的步长，size为窗口的大小。</p>
<ul>
<li>slide &lt; size，则窗口会重叠，每个元素会被分配到多个窗口。</li>
<li>slide = size，则等同于滚动窗口（TUMBLE）。</li>
<li>slide &gt; size，则为跳跃窗口，窗口之间不重叠且有间隙。</li>
</ul>
<p>通常，大部分元素符合多个窗口情景，窗口是重叠的。因此，滑动窗口在计算移动平均数（moving averages）时很实用。例如，计算过去5分钟数据的平均值，每10秒钟更新一次，可以设置slide为10秒，size为5分钟。下图为您展示间隔为30秒，窗口大小为1分钟的滑动窗口。</p>
<p><img src="_v_images/20210412125050182_1936746176" alt="滑动窗口" title="滑动窗口"></p>
<p>使用滑动窗口标识函数选出窗口的起始时间或者结束时间，窗口的时间属性用于下级Window的聚合。</p>
<table>
<thead>
<tr>
<th>窗口标识函数</th>
<th>返回类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>HOP_START（&lt;time-attr&gt;, &lt;slide-interval&gt;, &lt;size-interval&gt;）</code></td>
<td>TIMESTAMP</td>
<td>返回窗口的起始时间（包含边界）。例如<code>[00:10, 00:15)</code> 窗口，返回<code>00:10</code> 。</td>
</tr>
<tr>
<td><code>HOP_END（&lt;time-attr&gt;, &lt;slide-interval&gt;, &lt;size-interval&gt;）</code></td>
<td>TIMESTAMP</td>
<td>返回窗口的结束时间（包含边界）。例如<code>[00:00, 00:15)</code> 窗口，返回<code>00:15</code>。</td>
</tr>
<tr>
<td><code>HOP_ROWTIME（&lt;time-attr&gt;, &lt;slide-interval&gt;, &lt;size-interval&gt;）</code></td>
<td>TIMESTAMP（rowtime-attr）</td>
<td>返回窗口的结束时间（不包含边界）。例如<code>[00:00, 00:15)</code> 窗口，返回<code>00:14:59.999</code>。返回值是一个rowtime attribute，即可以基于该字段做时间类型的操作，只能用在基于event time的window上。</td>
</tr>
<tr>
<td><code>HOP_PROCTIME（&lt;time-attr&gt;, &lt;slide-interval&gt;, &lt;size-interval&gt;）</code></td>
<td>TIMESTAMP（rowtime-attr）</td>
<td>返回窗口的结束时间（不包含边界）。例如<code>[00:00, 00:15)</code> 窗口，返回<code>00:14:59.999</code> 。返回值是一个proctime attribute</td>
</tr>
</tbody></table>
<p>滑动窗口实例：<br>java代码同上，sql语句改为：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> HOP_START(t, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span>, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">SECOND</span>) <span class="keyword">AS</span> window_start, HOP_END(t, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span>, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">SECOND</span>) <span class="keyword">AS</span> window_end, <span class="built_in">SUM</span>(v) <span class="keyword">FROM</span>   logT   <span class="keyword">GROUP</span> <span class="keyword">BY</span> HOP(t, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span>, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">SECOND</span>)</span><br></pre></td></tr></table></figure>
<p>每间隔5秒统计10秒内的数据<br>sql结果如下：  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(2019-11-01 06:53:15.0,2019-11-01 06:53:25.0,208)  </span><br><span class="line">(2019-11-01 06:53:10.0,2019-11-01 06:53:20.0,204)  </span><br><span class="line">(2019-11-01 06:53:05.0,2019-11-01 06:53:15.0,507)  </span><br><span class="line">(2019-11-01 06:53:20.0,2019-11-01 06:53:30.0,208)  </span><br><span class="line">(2019-11-01 06:53:00.0,2019-11-01 06:53:10.0,603)  </span><br><span class="line">(2019-11-01 06:52:55.0,2019-11-01 06:53:05.0,300)</span><br></pre></td></tr></table></figure>
<h3 id="会话窗口"><a href="#会话窗口" class="headerlink" title="会话窗口"></a>会话窗口</h3><p>会话窗口（SESSION）通过Session活动来对元素进行分组。会话窗口与滚动窗口和滑动窗口相比，没有窗口重叠，没有固定窗口大小。相反，当它在一个固定的时间周期内不再收到元素，即会话断开时，这个窗口就会关闭。</p>
<p>会话窗口通过一个间隔时间（Gap）来配置，这个间隔定义了非活跃周期的长度。例如，一个表示鼠标点击活动的数据流可能具有长时间的空闲时间，并在两段空闲之间散布着高浓度的点击。 如果数据在指定的间隔（Gap）之后到达，则会开始一个新的窗口。</p>
<p>会话窗口示例如下图。每个Key由于不同的数据分布，形成了不同的Window。</p>
<p><img src="_v_images/20210412125049773_363551252"><br>使用标识函数选出窗口的起始时间或者结束时间，窗口的时间属性用于下级Window的聚合。</p>
<table>
<thead>
<tr>
<th>窗口标识函数</th>
<th>返回类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>SESSION_START（&lt;time-attr&gt;, &lt;gap-interval&gt;）</code></td>
<td>Timestamp</td>
<td>返回窗口的起始时间（包含边界）。如<code>[00:10, 00:15)</code> 的窗口，返回 <code>00:10</code> ，即为此会话窗口内第一条记录的时间。</td>
</tr>
<tr>
<td><code>SESSION_END（&lt;time-attr&gt;, &lt;gap-interval&gt;）</code></td>
<td>Timestamp</td>
<td>返回窗口的结束时间（包含边界）。如<code>[00:00, 00:15)</code> 的窗口，返回 <code>00:15</code>，即为此会话窗口内最后一条记录的时间+<code>&lt;gap-interval&gt;</code>。</td>
</tr>
<tr>
<td><code>SESSION_ROWTIME（&lt;time-attr&gt;, &lt;gap-interval&gt;）</code></td>
<td>Timestamp（rowtime-attr）</td>
<td>返回窗口的结束时间（不包含边界）。如 <code>[00:00, 00:15)</code> 的窗口，返回<code>00:14:59.999</code> 。返回值是一个rowtime attribute，也就是可以基于该字段进行时间类型的操作。该参数只能用于基于event time的window 。</td>
</tr>
<tr>
<td><code>SESSION_PROCTIME（&lt;time-attr&gt;, &lt;gap-interval&gt;）</code></td>
<td>Timestamp（rowtime-attr）</td>
<td>返回窗口的结束时间（不包含边界）。如 <code>[00:00, 00:15)</code> 的窗口，返回 <code>00:14:59.999</code> 。返回值是一个 proctime attribute，也就是可以基于该字段进行时间类型的操作。该参数只能用于基于processing time的window 。</td>
</tr>
</tbody></table>
<p>会话窗口实例：<br>java代码同上<br>sql语句如下：<br>每隔5秒聚合</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> SESSION_START(t, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span>) <span class="keyword">AS</span> window_start,</span><br><span class="line">SESSION_END(t, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span>) <span class="keyword">AS</span> window_end, <span class="built_in">SUM</span>(v) <span class="keyword">FROM</span>  logT  <span class="keyword">GROUP</span> <span class="keyword">BY</span> SESSION(t, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span>)</span><br></pre></td></tr></table></figure>
<p>sql结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(2019-11-01 06:53:21.0,2019-11-01 06:53:26.0,208)  </span><br><span class="line">(2019-11-01 06:53:00.0,2019-11-01 06:53:05.0,300)  </span><br><span class="line">(2019-11-01 06:53:09.0,2019-11-01 06:53:17.0,507)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="OVER窗口"><a href="#OVER窗口" class="headerlink" title="OVER窗口"></a>OVER窗口</h3><p>OVER窗口（OVER Window）是传统数据库的标准开窗，不同于Group By Window，OVER窗口中每1个元素都对应1个窗口。窗口内的元素是当前元素往前多少个或往前多长时间的元素集合，因此流数据元素分布在多个窗口中。</p>
<p>在应用OVER窗口的流式数据中，每1个元素都对应1个OVER窗口。每1个元素都触发1次数据计算，每个触发计算的元素所确定的行，都是该元素所在窗口的最后1行。在实时计算的底层实现中，OVER窗口的数据进行全局统一管理（数据只存储1份），逻辑上为每1个元素维护1个OVER窗口，为每1个元素进行窗口计算，完成计算后会清除过期的数据。</p>
<p>Flink SQL中对OVER窗口的定义遵循标准SQL的定义语法，传统OVER窗口没有对其进行更细粒度的窗口类型命名划分。按照计算行的定义方式，OVER Window可以分为以下两类：</p>
<ul>
<li>ROWS OVER Window：每一行元素都被视为新的计算行，即每一行都是一个新的窗口。</li>
<li>RANGE OVER Window：具有相同时间值的所有元素行视为同一计算行，即具有相同时间值的所有行都是同一个窗口。</li>
</ul>
<p>Rows OVER Window语义</p>
<p>窗口数据</p>
<p>ROWS OVER Window的每个元素都确定一个窗口。ROWS OVER Window分为Unbounded（无界流）和Bounded（有界流）两种情况。<br>Unbounded ROWS OVER Window数据示例如下图所示。<br><img src="_v_images/20210412125049063_1513990833"></p>
<p>虽然上图所示窗口user1的w7、w8及user2的窗口w3、w4都是同一时刻到达，但它们仍然在不同的窗口，这一点与RANGE OVER Window不同。</p>
<p>Bounded ROWS OVER Window数据以3个元素（往前2个元素）的窗口为例，如下图所示。</p>
<p><img src="_v_images/20210412125048555_824932679"></p>
<p>虽然上图所示窗口user1的w5、w6及user2的窗口w1、w2都是同一时刻到达，但它们仍然在不同的窗口，这一点与RANGE OVER Window不同。</p>
<p>RANGE OVER Window语义</p>
<p>窗口数据</p>
<p>RANGE OVER Window所有具有共同元素值（元素时间戳）的元素行确定一个窗口，RANGE OVER Window分为Unbounded和Bounded的两种情况。<br>Unbounded RANGE OVER Window数据示例如下图所示。</p>
<p><img src="_v_images/20210412125048048_1968314666"><br>上图所示窗口user1的w7、user2的窗口w3，两个元素同一时刻到达，属于相同的window，这一点与ROWS OVER Window不同。</p>
<p>Bounded RANGE OVER Window数据，以3秒中数据<code>(INTERVAL &#39;2&#39; SECOND)</code>的窗口为例，如下图所示。</p>
<p><img src="_v_images/20210412125047258_2027952546"></p>
<p>上图所示窗口user1的w6、user2的窗口w3，元素都是同一时刻到达，属于相同的window，这一点与ROWS OVER Window不同。</p>
<p>OVER窗口实例：<br>java代码同上<br>初始数据如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始数据</span></span><br><span class="line">DataStream&lt;Tuple3&lt;Long, String,Integer&gt;&gt; log = env.fromCollection(Arrays.asList(</span><br><span class="line">        <span class="comment">//时间 14:53:00</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591180_000L</span>,<span class="string">&quot;xiao_ming&quot;</span>,<span class="number">999</span>),</span><br><span class="line">        <span class="comment">//时间 14:53:09</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591189_000L</span>,<span class="string">&quot;zhang_san&quot;</span>,<span class="number">303</span>),</span><br><span class="line">        <span class="comment">//时间 14:53:12</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591192_000L</span>, <span class="string">&quot;xiao_li&quot;</span>,<span class="number">888</span>),</span><br><span class="line">        <span class="comment">//时间 14:53:21</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591201_000L</span>,<span class="string">&quot;li_si&quot;</span>, <span class="number">908</span>),</span><br><span class="line">        <span class="comment">//2019-11-01 14:53:31</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591211_000L</span>,<span class="string">&quot;li_si&quot;</span>, <span class="number">555</span>),</span><br><span class="line">        <span class="comment">//2019-11-01 14:53:41</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591221_000L</span>,<span class="string">&quot;zhang_san&quot;</span>, <span class="number">666</span>),</span><br><span class="line">        <span class="comment">//2019-11-01 14:53:51</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591231_000L</span>,<span class="string">&quot;xiao_ming&quot;</span>, <span class="number">777</span>),</span><br><span class="line">        <span class="comment">//2019-11-01 14:54:01</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591241_000L</span>,<span class="string">&quot;xiao_ming&quot;</span>, <span class="number">213</span>),</span><br><span class="line">        <span class="comment">//2019-11-01 14:54:11</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591251_000L</span>,<span class="string">&quot;zhang_san&quot;</span>, <span class="number">300</span>),</span><br><span class="line">        <span class="comment">//2019-11-01 14:54:21</span></span><br><span class="line">        <span class="keyword">new</span> Tuple3&lt;&gt;(<span class="number">1572591261_000L</span>,<span class="string">&quot;li_si&quot;</span>, <span class="number">112</span>)</span><br><span class="line">));</span><br></pre></td></tr></table></figure>
<p>ROWS over Windown sql语句如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> name,v,<span class="built_in">MAX</span>(v) <span class="keyword">OVER</span>(</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> name </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> t </span><br><span class="line"><span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">) <span class="keyword">FROM</span> logT</span><br></pre></td></tr></table></figure>
<p>sql结果如下：  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(zhang_san,303,303)  </span><br><span class="line">(xiao_li,888,888)  </span><br><span class="line">(li_si,908,908)  </span><br><span class="line">(xiao_ming,999,999)  </span><br><span class="line">(zhang_san,666,666)  </span><br><span class="line">(li_si,555,908)  </span><br><span class="line">(xiao_ming,777,999)  </span><br><span class="line">(li_si,112,908)  </span><br><span class="line">(zhang_san,300,666)  </span><br><span class="line">(xiao_ming,213,999)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>RANGE OVER Window sql 语句如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> name,v,<span class="built_in">MAX</span>(v) <span class="keyword">OVER</span>(</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> name </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> t </span><br><span class="line"><span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="type">INTERVAL</span> <span class="string">&#x27;15&#x27;</span> <span class="keyword">SECOND</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">) <span class="keyword">FROM</span>  logT</span><br></pre></td></tr></table></figure>
<p>sql结果如下：  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(xiao_ming,999,999)  </span><br><span class="line">(xiao_li,888,888)  </span><br><span class="line">(zhang_san,303,303)  </span><br><span class="line">(li_si,908,908)  </span><br><span class="line">(li_si,555,908)  </span><br><span class="line">(xiao_ming,777,777)  </span><br><span class="line">(zhang_san,666,666)  </span><br><span class="line">(li_si,112,112)  </span><br><span class="line">(xiao_ming,213,777)  </span><br><span class="line">(zhang_san,300,300)</span><br></pre></td></tr></table></figure>
<p>本文的java代码来自：<br><a target="_blank" rel="noopener" href="https://github.com/CheckChe0803/flink-simple-tutorial/tree/master/table/src/main/java/sql/window">https://github.com/CheckChe08…</a></p>
<h2 id="底层实现"><a href="#底层实现" class="headerlink" title="底层实现"></a>底层实现</h2><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/UkpkS_JiRGR0ibZKYechbg">https://mp.weixin.qq.com/s/UkpkS_JiRGR0ibZKYechbg</a></p>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>窗口是无限流上一种核心机制，可以流分割为有限大小的“窗口”，同时，在窗口内进行聚合，从而把源源不断产生的数据根据不同的条件划分成一段一段有边界的数据区间，使用户能够利用窗口功能实现很多复杂的统计分析需求。</p>
<h3 id="Window分类"><a href="#Window分类" class="headerlink" title="Window分类"></a>Window分类</h3><p>1、TimeWindow与CountWindow Flink Window可以是时间驱动的（<code>TimeWindow</code>），也可以是数据驱动的（CountWindow）。由于flink-planner-blink SQL中目前只支持TimeWindow相应的表达语句（<code>TUMBLE</code>、<code>HOP</code>、<code>SESSION</code>），因此，本文主要介绍TimeWindow SQL示例和逻辑，CountWindow感兴趣的读者可自行分析。</p>
<p>2、TimeWindow子类型 Flink TimeWindow有滑动窗口(<code>HOP</code>)、滚动窗口(<code>TUMBLE</code>)以及会话窗口(<code>SESSION</code>)三种，所选取的字段时间，可以是系统时间(<code>PROCTIME</code>)或事件时间(<code>EVENT TIME</code>)两种，接来下依次介绍。</p>
<h4 id="Tumble-Window（滚动窗口）"><a href="#Tumble-Window（滚动窗口）" class="headerlink" title="Tumble Window（滚动窗口）"></a>Tumble Window（滚动窗口）</h4><p>翻转窗口Assigner将每个元素分配给具有指定大小的窗口。翻转窗口的大小是固定的，且不会重叠。例如，指定一个大小为5分钟的翻滚窗口，并每5分钟启动一个新窗口，如下图所示：</p>
<p><img src="_v_images/20210412125430504_1844331455" alt="图片"></p>
<p>TUMBLE ROWTIME语法示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sessionOrderTableRowtime (</span><br><span class="line">    ctime <span class="type">TIMESTAMP</span>,</span><br><span class="line">    categoryName <span class="type">VARCHAR</span>,</span><br><span class="line">    shopName <span class="type">VARCHAR</span>,</span><br><span class="line">    itemName <span class="type">VARCHAR</span>,</span><br><span class="line">    userId <span class="type">VARCHAR</span>,</span><br><span class="line">    price <span class="type">FLOAT</span>,</span><br><span class="line">    action <span class="type">BIGINT</span>,</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> ctime <span class="keyword">AS</span> withOffset(ctime, <span class="number">1000</span>),</span><br><span class="line">    proc <span class="keyword">AS</span> PROCTIME()</span><br><span class="line">) <span class="keyword">with</span> (</span><br><span class="line">    `type` <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">    format <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span>,</span><br><span class="line">    updateMode <span class="operator">=</span> <span class="string">&#x27;append&#x27;</span>,</span><br><span class="line">    `group.id` <span class="operator">=</span> <span class="string">&#x27;groupId&#x27;</span>,</span><br><span class="line">    bootstrap.servers <span class="operator">=</span> <span class="string">&#x27;xxxxx:9092&#x27;</span>,</span><br><span class="line">    version <span class="operator">=</span> <span class="string">&#x27;0.10&#x27;</span>,</span><br><span class="line">    `zookeeper.connect` <span class="operator">=</span> <span class="string">&#x27;xxxxx:2181&#x27;</span>,</span><br><span class="line">    startingOffsets <span class="operator">=</span> <span class="string">&#x27;latest&#x27;</span>,</span><br><span class="line">    topic <span class="operator">=</span> <span class="string">&#x27;sessionsourceproctime&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> popwindowsink (</span><br><span class="line">    countA <span class="type">BIGINT</span>,</span><br><span class="line">    ctime_start <span class="type">TIMESTAMP</span>,</span><br><span class="line">    ctime_end <span class="type">VARCHAR</span>,</span><br><span class="line">    ctime_rowtime <span class="type">VARCHAR</span>,</span><br><span class="line">    categoryName <span class="type">VARCHAR</span>,</span><br><span class="line">    price_sum <span class="type">FLOAT</span></span><br><span class="line">) <span class="keyword">with</span> (</span><br><span class="line">    format <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span>,</span><br><span class="line">    updateMode <span class="operator">=</span> <span class="string">&#x27;append&#x27;</span>,</span><br><span class="line">    bootstrap.servers <span class="operator">=</span> <span class="string">&#x27;xxxxx:9092&#x27;</span>,</span><br><span class="line">    version <span class="operator">=</span> <span class="string">&#x27;0.10&#x27;</span>,</span><br><span class="line">    topic <span class="operator">=</span> <span class="string">&#x27;sessionsinkproctime&#x27;</span>,</span><br><span class="line">    `type` <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> popwindowsink</span><br><span class="line">(<span class="keyword">SELECT</span></span><br><span class="line"><span class="built_in">COUNT</span>(<span class="operator">*</span>),</span><br><span class="line">TUMBLE_START(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>),</span><br><span class="line">DATE_FORMAT(TUMBLE_END(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>), <span class="string">&#x27;yyyy-MM-dd-HH-mm-ss:SSS&#x27;</span>), <span class="comment">--将TUMBLE_END转为可视化的日期</span></span><br><span class="line">DATE_FORMAT(TUMBLE_ROWTIME(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>), <span class="string">&#x27;yyyy-MM-dd-HH-mm-ss:SSS&#x27;</span>), <span class="comment">--这里TUMBLE_ROWTIME为TUMBLE_END-1ms，一般用于后续窗口级联聚合</span></span><br><span class="line">categoryName,</span><br><span class="line"><span class="built_in">SUM</span>(price)</span><br><span class="line"><span class="keyword">FROM</span> sessionOrderTableRowtime</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> TUMBLE(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>), categoryName)</span><br></pre></td></tr></table></figure>
<p>TUMBLEP ROCTIME语法示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> popwindowsink</span><br><span class="line">(<span class="keyword">SELECT</span></span><br><span class="line"><span class="built_in">COUNT</span>(<span class="operator">*</span>),</span><br><span class="line">TUMBLE_START(proc, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>),</span><br><span class="line">DATE_FORMAT(TUMBLE_END(proc, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>), <span class="string">&#x27;yyyy-MM-dd-HH-mm-ss:SSS&#x27;</span>),</span><br><span class="line">DATE_FORMAT(TUMBLE_PROCTIME(proc, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>), <span class="string">&#x27;yyyy-MM-dd-HH-mm-ss:SSS&#x27;</span>), <span class="comment">--注意这里proc字段即Source DDL中指定的PROCTIME</span></span><br><span class="line">categoryName,</span><br><span class="line"><span class="built_in">SUM</span>(price)</span><br><span class="line"><span class="keyword">FROM</span> sessionOrderTableRowtime</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> TUMBLE(proc, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>), categoryName)</span><br></pre></td></tr></table></figure>
<p>ROWTIME与PROCTIME区别：</p>
<ul>
<li>在使用上：主要是填入的ctime、proc关键字的区别，这两个字段在Source DDL中指定方式不一样.</li>
<li>在实现原理上：ROWTIME模式，根据ctime对应的值，去确定窗口的start、end；PROCTIME模式，在WindowOperator处理数据时，获取本地系统时间，去确定窗口的start、end.</li>
</ul>
<p>由于生产系统中，主要使用ROWTIME来计算、聚合、统计，PROCTIME一般用于测试或对统计精度要求不高的场景，本文后续都主要以ROWTIME进行分析。</p>
<h4 id="Hop-Window（滑动窗口）"><a href="#Hop-Window（滑动窗口）" class="headerlink" title="Hop Window（滑动窗口）"></a>Hop Window（滑动窗口）</h4><p>滑动窗口Assigner将元素分配给多个固定长度的窗口。类似于滚动窗口分配程序，窗口的大小由窗口大小参数配置。因此，如果滑动窗口小于窗口大小，则滑动窗口可以重叠。在这种情况下，元素被分配到多个窗口。其实，滚动窗口TUMBLE是滑动窗口的一个特例。例子，设置一个10分钟长度的窗口，以5分钟间隔滑动。这样，每5分钟就会出现一个窗口，其中包含最近10分钟内到达的事件，如下图：</p>
<p><img src="_v_images/20210412125430097_940076266" alt="图片"></p>
<p>HOP ROWTIME语法示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> popwindowsink</span><br><span class="line">(<span class="keyword">SELECT</span></span><br><span class="line"><span class="built_in">COUNT</span>(<span class="operator">*</span>),</span><br><span class="line">HOP_START(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>,  <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>),</span><br><span class="line">DATE_FORMAT(HOP_END(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>,  <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>), <span class="string">&#x27;yyyy-MM-dd-HH-mm-ss:SSS&#x27;</span>),</span><br><span class="line">DATE_FORMAT(HOP_ROWTIME(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>,  <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>), <span class="string">&#x27;yyyy-MM-dd-HH-mm-ss:SSS&#x27;</span>), <span class="comment">--注意这里ctime字段即Source DDL中指定的ROWTIME</span></span><br><span class="line">categoryName,</span><br><span class="line"><span class="built_in">SUM</span>(price)</span><br><span class="line"><span class="keyword">FROM</span> sessionOrderTableRowtime</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> HOP(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>,  <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>), categoryName)</span><br></pre></td></tr></table></figure>
<h4 id="Session-Window（会话窗口）"><a href="#Session-Window（会话窗口）" class="headerlink" title="Session Window（会话窗口）"></a>Session Window（会话窗口）</h4><p>会话窗口Assigner根据活动会话对元素进行分组。与翻滚窗口和滑动窗口相比，会话窗口不会重叠，也没有固定的开始和结束时间。相反，会话窗口在一段时间内不接收元素时关闭，即，当一段不活跃的间隙发生时，当前会话关闭，随后的元素被分配给新的会话。</p>
<p><img src="_v_images/20210412125429689_1075804874" alt="图片"></p>
<p>SESSION ROWTIME语法示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> popwindowsink</span><br><span class="line">(<span class="keyword">SELECT</span></span><br><span class="line"><span class="built_in">COUNT</span>(<span class="operator">*</span>),</span><br><span class="line">SESSION_START(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>),</span><br><span class="line">DATE_FORMAT(SESSION_END(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>, <span class="string">&#x27;yyyy-MM-dd-HH-mm-ss:SSS&#x27;</span>),</span><br><span class="line">DATE_FORMAT(SESSION_ROWTIME(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>), <span class="string">&#x27;yyyy-MM-dd-HH-mm-ss:SSS&#x27;</span>), <span class="comment">--注意这里ctime字段即Source DDL中指定的ROWTIME</span></span><br><span class="line">categoryName,</span><br><span class="line"><span class="built_in">SUM</span>(price)</span><br><span class="line"><span class="keyword">FROM</span> sessionOrderTableRowtime</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> SESSION(ctime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>), categoryName)</span><br></pre></td></tr></table></figure>
<h3 id="Window分类及整体流程"><a href="#Window分类及整体流程" class="headerlink" title="Window分类及整体流程"></a>Window分类及整体流程</h3><p><img src="_v_images/20210412125429282_375710651" alt="图片"></p>
<p>上图内部流程分析：</p>
<p>应用层SQL:<br>1.1 window分类及配置，包括滑动、翻转、会话类型窗口<br>1.2 window时间类型配置，默认待字段名的EventTime，也可以通过PROCTIME()配置为ProcessingTime<br>Calcite解析引擎:<br>2.1 Calcite SQL解析，包括逻辑、优化、物理计划和算子绑定(#translateToPlanInternal)，在本文特指StreamExecGroupWindowAggregateRule和StreamExecGroupWindowAggregate物理计划<br>WindowOperator算子创建相关:<br>3.1 StreamExecGroupWindowAggregate#createWindowOperator创建算子<br>3.2 WindowAssigner的创建，根据输入的数据，和窗口类型，生成多个窗口<br>3.3 processElement()真实处理数据，包括聚合运算，生成窗口，更新缓存，提交数据等功能<br>3.4 Trigger根据数据或时间，来决定窗口触发</p>
<h3 id="创建WindowOperator算子"><a href="#创建WindowOperator算子" class="headerlink" title="创建WindowOperator算子"></a>创建WindowOperator算子</h3><p>由于window语法主要是在group by语句中使用，calcite创建WindowOperator算子伴随着聚合策略的实现，包括聚合规则匹配(StreamExecGroupWindowAggregateRule)，以及生成聚合physical算子StreamExecGroupWindowAggregate两个子流程：</p>
<p><img src="_v_images/20210412125428973_1212879820" alt="图片"></p>
<p>上图内部流程分析：</p>
<p>a. StreamExecGroupWindowAggregateRule会对window进行提前匹配，<br>生成的WindowEmitStrategy内部具有：是否为EventTime表标识、是否为SessionWindow、early fire和late fire配置、延迟毫秒数（窗口结束时间加上这个毫秒数即数据清理时间）<br>b. StreamExecGroupWindowAggregateRule会获取聚合逻辑计划中，window配置的时间字段，记录时间字段index信息，window的触发和清理都会用到这个时间<br>c. StreamExecGroupWindowAggregate入口即为translateToPlanInternal，它的实现方式与spark比较类似，会先循环调用child子节点translateToPlan方法，生成inputtranform信息作为输入<br>d.创建aggregateHandler是一个代码生成的过程，其生成的创建的class实现了accumulate、retract、merge、update方法，这个handler最后也传递给了WindowOperater，处理数据时，可以进行聚合、回撤并输出最新数据给下游<br>e. StreamExecGroupWindowAggregate与window相关的最后一步就是调用#createWindowOperator创建算子，其内部先创建了一个WindowOperatorBuilder，设置window类型、retract标识、trigger(window触发条件)、聚合函数句柄等，最后创建WindowOperator</p>
<h3 id="WindowOperator处理数据图解"><a href="#WindowOperator处理数据图解" class="headerlink" title="WindowOperator处理数据图解"></a>WindowOperator处理数据图解</h3><p>在上一小节，已经完成了WindowOperator参数的设定，并创建实例，接下来我们主要分析WindowOperator真实处理数据的流程(起点在WindowOperator#processElement方法)：</p>
<p><img src="_v_images/20210412125428666_1517359800" alt="图片"></p>
<p>processElement处理数据流程：</p>
<p>a、 获取当前record具有的事件时间，如果是Processing Time模式，从时间服务Service里面获取时间即可<br>b、使用上一步获取的时间，接着调用windowFunction.assignWindow生成窗口，其内部实际上是调用各类型的WindowAssigner生成窗口，windowFunction有三大类，分别是Paned（滑动）、Merge（会话）、General（前两种以外的），WindowAssigner类型大致有5类，分别是Tumbling（翻转）、Sliding（滑动）、Session（会话）、CountTumbling 、CountSlide这几类,根据输入的一条数据和时间，可以生成1到多个窗口<br>c、接下来是遍历涉及的窗口进行聚合，包括从windowState获取聚合前值、使用句柄进行聚合、更新状态至windowState，将当前转态<br>d、上一步聚合完成后，就可以遍历窗口，使用TriggerContext（其实就是不同类型窗口Trigger触发器的代理），综合early fire、late fire、水印时间与窗口结束时间，综合判断是否触发窗口写出<br>e、如果TriggerContext判断出触发条件为true，则调用emitWindowResult写出，其内部有retract判断，更新当前state及previous state，写出数据等操作<br>f、如果TriggerContext判断出触发条件为false，则触发需要注册cleanupTimer,到达指定时间后，触发onEventTime或onProcessingTime<br>g、onEventTime或onProcessingTime功能十分类似，首先会触发emitWindowResult提交结果，另外会判断窗口结束时间+Lateness和当前时间是否相等，相等则表示可以清除窗口数据、当前state及previous state、窗口对应trigger。</p>
<h3 id="WindowOperator源码调试"><a href="#WindowOperator源码调试" class="headerlink" title="WindowOperator源码调试"></a>WindowOperator源码调试</h3><p>为了更直观的理解Window内部运行原理，这里我们引入一个Flink源码中已有的SQL Window测试用例，并进行了简单的修改（即修改为使用HOP滑动窗口）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">classWindowJoinITCase&#123;</span><br><span class="line">  <span class="meta">@Test</span></span><br><span class="line">  <span class="function">def <span class="title">testRowTimeInnerJoinWithWindowAggregateOnFirstTime</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">    val sqlQuery =</span><br><span class="line">      <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">        |SELECT t1.key, HOP_END(t1.rowtime, INTERVAL &#x27;4&#x27; SECOND, INTERVAL &#x27;20&#x27; SECOND), COUNT(t1.key)</span></span><br><span class="line"><span class="string">        |FROM T1 AS t1</span></span><br><span class="line"><span class="string">        |GROUP BY HOP(t1.rowtime, INTERVAL &#x27;4&#x27; SECOND, INTERVAL &#x27;20&#x27; SECOND), t1.key</span></span><br><span class="line"><span class="string">        |&quot;</span><span class="string">&quot;&quot;</span>.stripMargin</span><br><span class="line"></span><br><span class="line">    val data1 = <span class="keyword">new</span> mutable.MutableList[(String, String, Long)]</span><br><span class="line">    data1.+=((<span class="string">&quot;A&quot;</span>, <span class="string">&quot;L-1&quot;</span>, <span class="number">1000L</span>))</span><br><span class="line">    data1.+=((<span class="string">&quot;A&quot;</span>, <span class="string">&quot;L-2&quot;</span>, <span class="number">2000L</span>))</span><br><span class="line">    data1.+=((<span class="string">&quot;A&quot;</span>, <span class="string">&quot;L-3&quot;</span>, <span class="number">3000L</span>))</span><br><span class="line">    <span class="comment">//data1.+=((&quot;B&quot;, &quot;L-8&quot;, 2000L))</span></span><br><span class="line">    data1.+=((<span class="string">&quot;B&quot;</span>, <span class="string">&quot;L-4&quot;</span>, <span class="number">4000L</span>))</span><br><span class="line">    data1.+=((<span class="string">&quot;C&quot;</span>, <span class="string">&quot;L-5&quot;</span>, <span class="number">2100L</span>))</span><br><span class="line">    data1.+=((<span class="string">&quot;A&quot;</span>, <span class="string">&quot;L-6&quot;</span>, <span class="number">10000L</span>))</span><br><span class="line">    data1.+=((<span class="string">&quot;A&quot;</span>, <span class="string">&quot;L-7&quot;</span>, <span class="number">13000L</span>))</span><br><span class="line"></span><br><span class="line">    val t1 = env.fromCollection(data1)</span><br><span class="line">      .assignTimestampsAndWatermarks(<span class="keyword">new</span> Row3WatermarkExtractor2)</span><br><span class="line">      .toTable(tEnv, <span class="string">&#x27;key, &#x27;</span>id, <span class="string">&#x27;rowtime)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    tEnv.registerTable(&quot;T1&quot;, t1)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    val sink = new TestingAppendSink</span></span><br><span class="line"><span class="string">    val t_r = tEnv.sqlQuery(sqlQuery)</span></span><br><span class="line"><span class="string">    val result = t_r.toAppendStream[Row]</span></span><br><span class="line"><span class="string">    result.addSink(sink)</span></span><br><span class="line"><span class="string">    env.execute()</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<p>1、StreamExecGroupWindowAggregate#createWindowOperator()创建算子</p>
<p>StreamExecGroupWindowAggregate#createWindowOperator()是创建WindowOperator算子的地方，对应的代码和注释：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StreamExecGroupWindowAggregate</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> def <span class="title">createWindowOperator</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      config: TableConfig,</span></span></span><br><span class="line"><span class="function"><span class="params">      aggsHandler: GeneratedNamespaceAggsHandleFunction[_],</span></span></span><br><span class="line"><span class="function"><span class="params">      recordEqualiser: GeneratedRecordEqualiser,</span></span></span><br><span class="line"><span class="function"><span class="params">      accTypes: Array[LogicalType],</span></span></span><br><span class="line"><span class="function"><span class="params">      windowPropertyTypes: Array[LogicalType],</span></span></span><br><span class="line"><span class="function"><span class="params">      aggValueTypes: Array[LogicalType],</span></span></span><br><span class="line"><span class="function"><span class="params">      inputFields: Seq[LogicalType],</span></span></span><br><span class="line"><span class="function"><span class="params">      timeIdx: Int)</span>: WindowOperator[_, _] </span>= &#123;</span><br><span class="line"></span><br><span class="line">    val builder = WindowOperatorBuilder</span><br><span class="line">      .builder()</span><br><span class="line">      .withInputFields(inputFields.toArray)</span><br><span class="line">    val timeZoneOffset = -config.getTimeZone.getOffset(Calendar.ZONE_OFFSET)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置WindowOperatorBuilder，最后通过Builder创建WindowOperator</span></span><br><span class="line">    val newBuilder = window match &#123;</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">TumblingGroupWindow</span><span class="params">(_, timeField, size)</span> <span class="comment">//Tumble PROCTIME模式，内部设置Assiger</span></span></span><br><span class="line"><span class="function">          <span class="keyword">if</span> <span class="title">isProctimeAttribute</span><span class="params">(timeField)</span> &amp;&amp; <span class="title">hasTimeIntervalType</span><span class="params">(size)</span> </span>=&gt;</span><br><span class="line">        builder.tumble(toDuration(size), timeZoneOffset).withProcessingTime()</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">TumblingGroupWindow</span><span class="params">(_, timeField, size)</span> <span class="comment">//Tumble ROWTIME模式，内部设置Assiger</span></span></span><br><span class="line"><span class="function">          <span class="keyword">if</span> <span class="title">isRowtimeAttribute</span><span class="params">(timeField)</span> &amp;&amp; <span class="title">hasTimeIntervalType</span><span class="params">(size)</span> </span>=&gt;</span><br><span class="line">        builder.tumble(toDuration(size), timeZoneOffset).withEventTime(timeIdx)</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">SlidingGroupWindow</span><span class="params">(_, timeField, size, slide)</span> <span class="comment">//HOP PROCTIME模式，内部设置Assiger</span></span></span><br><span class="line"><span class="function">          <span class="keyword">if</span> <span class="title">isProctimeAttribute</span><span class="params">(timeField)</span> &amp;&amp; <span class="title">hasTimeIntervalType</span><span class="params">(size)</span> </span>=&gt;</span><br><span class="line">        builder.sliding(toDuration(size), toDuration(slide), timeZoneOffset)</span><br><span class="line">          .withProcessingTime()</span><br><span class="line">       .....</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">SessionGroupWindow</span><span class="params">(_, timeField, gap)</span></span></span><br><span class="line"><span class="function">          <span class="keyword">if</span> <span class="title">isRowtimeAttribute</span><span class="params">(timeField)</span> </span>=&gt;</span><br><span class="line">        builder.session(toDuration(gap)).withEventTime(timeIdx)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Retraction和Trigger设置</span></span><br><span class="line">    <span class="comment">//默认是no retract和EventTime.afterEndOfWindow</span></span><br><span class="line">    <span class="keyword">if</span> (emitStrategy.produceUpdates) &#123;</span><br><span class="line">      <span class="comment">// mark this operator will send retraction and set new trigger</span></span><br><span class="line">      newBuilder</span><br><span class="line">        .withSendRetraction()</span><br><span class="line">        .triggering(emitStrategy.getTrigger)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    newBuilder</span><br><span class="line">      .aggregate(aggsHandler, recordEqualiser, accTypes, aggValueTypes, windowPropertyTypes)</span><br><span class="line">      .withAllowedLateness(Duration.ofMillis(emitStrategy.getAllowLateness))</span><br><span class="line">      .build()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、WindowOperator#processElement()处理数据，注册Timer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StreamExecGroupWindowAggregate</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> def <span class="title">createWindowOperator</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      config: TableConfig,</span></span></span><br><span class="line"><span class="function"><span class="params">      aggsHandler: GeneratedNamespaceAggsHandleFunction[_],</span></span></span><br><span class="line"><span class="function"><span class="params">      recordEqualiser: GeneratedRecordEqualiser,</span></span></span><br><span class="line"><span class="function"><span class="params">      accTypes: Array[LogicalType],</span></span></span><br><span class="line"><span class="function"><span class="params">      windowPropertyTypes: Array[LogicalType],</span></span></span><br><span class="line"><span class="function"><span class="params">      aggValueTypes: Array[LogicalType],</span></span></span><br><span class="line"><span class="function"><span class="params">      inputFields: Seq[LogicalType],</span></span></span><br><span class="line"><span class="function"><span class="params">      timeIdx: Int)</span>: WindowOperator[_, _] </span>= &#123;</span><br><span class="line"></span><br><span class="line">    val builder = WindowOperatorBuilder</span><br><span class="line">      .builder()</span><br><span class="line">      .withInputFields(inputFields.toArray)</span><br><span class="line">    val timeZoneOffset = -config.getTimeZone.getOffset(Calendar.ZONE_OFFSET)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置WindowOperatorBuilder，最后通过Builder创建WindowOperator</span></span><br><span class="line">    val newBuilder = window match &#123;</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">TumblingGroupWindow</span><span class="params">(_, timeField, size)</span> <span class="comment">//Tumble PROCTIME模式，内部设置Assiger</span></span></span><br><span class="line"><span class="function">          <span class="keyword">if</span> <span class="title">isProctimeAttribute</span><span class="params">(timeField)</span> &amp;&amp; <span class="title">hasTimeIntervalType</span><span class="params">(size)</span> </span>=&gt;</span><br><span class="line">        builder.tumble(toDuration(size), timeZoneOffset).withProcessingTime()</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">TumblingGroupWindow</span><span class="params">(_, timeField, size)</span> <span class="comment">//Tumble ROWTIME模式，内部设置Assiger</span></span></span><br><span class="line"><span class="function">          <span class="keyword">if</span> <span class="title">isRowtimeAttribute</span><span class="params">(timeField)</span> &amp;&amp; <span class="title">hasTimeIntervalType</span><span class="params">(size)</span> </span>=&gt;</span><br><span class="line">        builder.tumble(toDuration(size), timeZoneOffset).withEventTime(timeIdx)</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">SlidingGroupWindow</span><span class="params">(_, timeField, size, slide)</span> <span class="comment">//HOP PROCTIME模式，内部设置Assiger</span></span></span><br><span class="line"><span class="function">          <span class="keyword">if</span> <span class="title">isProctimeAttribute</span><span class="params">(timeField)</span> &amp;&amp; <span class="title">hasTimeIntervalType</span><span class="params">(size)</span> </span>=&gt;</span><br><span class="line">        builder.sliding(toDuration(size), toDuration(slide), timeZoneOffset)</span><br><span class="line">          .withProcessingTime()</span><br><span class="line">       .....</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">SessionGroupWindow</span><span class="params">(_, timeField, gap)</span></span></span><br><span class="line"><span class="function">          <span class="keyword">if</span> <span class="title">isRowtimeAttribute</span><span class="params">(timeField)</span> </span>=&gt;</span><br><span class="line">        builder.session(toDuration(gap)).withEventTime(timeIdx)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Retraction和Trigger设置</span></span><br><span class="line">    <span class="comment">//默认是no retract和EventTime.afterEndOfWindow</span></span><br><span class="line">    <span class="keyword">if</span> (emitStrategy.produceUpdates) &#123;</span><br><span class="line">      <span class="comment">// mark this operator will send retraction and set new trigger</span></span><br><span class="line">      newBuilder</span><br><span class="line">        .withSendRetraction()</span><br><span class="line">        .triggering(emitStrategy.getTrigger)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    newBuilder</span><br><span class="line">      .aggregate(aggsHandler, recordEqualiser, accTypes, aggValueTypes, windowPropertyTypes)</span><br><span class="line">      .withAllowedLateness(Duration.ofMillis(emitStrategy.getAllowLateness))</span><br><span class="line">      .build()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行数据：</p>
<p><img src="_v_images/20210412125428458_505070513" alt="图片"></p>
<p>3、Timer触发 I、InternalTimerServiceImpl#advanceWatermark()</p>
<p>WindowOperator#onEventTime()的调用前，可以先看其上层调用：InternalTimerServiceImpl#advanceWatermark()</p>
<p><img src="_v_images/20210412125428150_761077256" alt="图片"></p>
<p>当获取的watermark为9999L时，把eventTimeTimerQueue队列中所有小于这个值的timer poll出来，调用WindowOperator.onEnventTime(timer)</p>
<p>II、WindwOperator#onEventTime()</p>
<p>WindwOperator#onEventTime()方法比较清晰，主要是window的触发和window的清理两段逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WindowOperator</span></span>&#123;</span><br><span class="line">    publicvoidonEventTime(InternalTimer&lt;K, W&gt; timer) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        setCurrentKey(timer.getKey());</span><br><span class="line"></span><br><span class="line">        triggerContext.window = timer.getNamespace();</span><br><span class="line">        <span class="keyword">if</span> (triggerContext.onEventTime(timer.getTimestamp())) &#123;</span><br><span class="line">            <span class="comment">// fire</span></span><br><span class="line">            emitWindowResult(triggerContext.window);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (windowAssigner.isEventTime()) &#123;</span><br><span class="line">            windowFunction.cleanWindowIfNeeded(triggerContext.window, timer.getTimestamp());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>III、emitWindowResult()提交结果</p>
<p>#emitWindowResult()重点关注下其第一行代码：BaseRow aggResult = windowFunction.getWindowAggregationResult(window); 这个表示根据具体的TimeWindow{start=4000, end=24000}，去获取聚合数据，如果是滑动窗口，需要将4000, 8000 ,12000，16000 , 20000, 24000这几段affect窗口里面的聚合值合并起来，内部逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> classPanedWindowProcessFunction&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> BaseRow <span class="title">getWindowAggregationResult</span><span class="params">(W window)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Iterable&lt;W&gt; panes = windowAssigner.splitIntoPanes(window);</span><br><span class="line">        BaseRow acc = windowAggregator.createAccumulators();</span><br><span class="line">        <span class="comment">// null namespace means use heap data views</span></span><br><span class="line">        windowAggregator.setAccumulators(<span class="keyword">null</span>, acc);</span><br><span class="line">        <span class="keyword">for</span> (W pane : panes) &#123;</span><br><span class="line">            BaseRow paneAcc = ctx.getWindowAccumulators(pane);</span><br><span class="line">            <span class="keyword">if</span> (paneAcc != <span class="keyword">null</span>) &#123;</span><br><span class="line">                windowAggregator.merge(pane, paneAcc);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> windowAggregator.getValue(window);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="_v_images/20210412125427840_804453196" alt="图片"></p>
<h3 id="Emit（Trigger）触发器"><a href="#Emit（Trigger）触发器" class="headerlink" title="Emit（Trigger）触发器"></a>Emit（Trigger）触发器</h3><ul>
<li>配置方式指定Trigger：Flink1.9.0目前支持通过TableConifg配置earlyFireInterval、lateFireInterval毫秒数，来指定窗口结束之前、窗口结束之后的触发策略（默认是watermark超过窗口结束后触发一次），策略的解析在WindowEmitStrategy，在StreamExecGroupWindowAggregateRule就会创建和解析这个策略</li>
<li>SQL方式指定Trigger：Flink1.9.0代码中calcite部分已有SqlEmit相关的实现，后续可以支持SQL 语句（INSERT INTO）中配置EMIT触发器</li>
</ul>
<p>本文Emit和Trigger都是触发器这一个概念，只是使用的方式不一样</p>
<p>1、Emit策略 Emit 策略是指在Flink SQL 中，query的输出策略（如能忍受的延迟）可能在不同的场景有不同的需求，而这部分需求，传统的 ANSI SQL 并没有对应的语法支持。比如用户需求：1小时的时间窗口，窗口触发之前希望每分钟都能看到最新的结果，窗口触发之后希望不丢失迟到一天内的数据。针对这类需求，抽象出了EMIT语法，并扩展到了SQL语法。</p>
<p>2、用途 EMIT语法的用途目前总结起来主要提供了：控制延迟、数据精确性，两方面的功能。</p>
<ul>
<li>控制延迟。针对大窗口，设置窗口触发之前的EMIT输出频率，减少用户看到结果的延迟(WITH| WITHOUT DELAY)。</li>
<li>数据精确性。不丢弃窗口触发之后的迟到的数据，修正输出结果(minIdleStateRetentionTime，在WindowEmitStrategy中生成allowLateness)。</li>
</ul>
<p>在选择EMIT策略时，还需要与处理开销进行权衡。因为越低的输出延迟、越高的数据精确性，都会带来越高的计算开销。</p>
<p>3、语法 EMIT 语法是用来定义输出的策略，即是定义在输出（INSERT INTO）上的动作。当未配置时，保持原有默认行为，即 window 只在 watermark 触发时 EMIT 一个结果。</p>
<p>语法：INSERT INTO tableName query EMIT strategy [, strategy]*</p>
<p>strategy ::= {WITH DELAY timeInterval | WITHOUT DELAY} [BEFORE WATERMARK |AFTER WATERMARK]</p>
<p>timeInterval ::=‘string’ timeUnit</p>
<p>WITH DELAY：声明能忍受的结果延迟，即按指定 interval 进行间隔输出。WITHOUT DELAY：声明不忍受延迟，即每来一条数据就进行输出。BEFORE WATERMARK：窗口结束之前的策略配置，即watermark 触发之前。AFTER WATERMARK：窗口结束之后的策略配置，即watermark 触发之后。注：</p>
<ul>
<li>其中 strategy可以定义多个，同时定义before和after的策略。但不能同时定义两个 before 或 两个after 的策略。</li>
<li>若配置了AFTER WATERMARK 策略，需要显式地在TableConfig中配置minIdleStateRetentionTime标识能忍受的最大迟到时间。</li>
<li>minIdleStateRetentionTime在window中只影响窗口何时清除，不直接影响窗口何时触发， 例如配置为3600000，最多容忍1小时的迟到数据，超过这个时间的数据会直接丢弃</li>
</ul>
<p>4、示例 如果我们已经有一个TUMBLE（ctime, INTERVAL ‘1’ HOUR）的窗口，tumble_window 的输出是需要等到一小时结束才能看到结果，我们希望能尽早能看到窗口的结果（即使是不完整的结果）。例如，我们希望每分钟看到最新的窗口结果：INSERT INTO result SELECT * FROM tumble_window EMIT WITH DELAY ‘1’ MINUTE BEFORE WATERMARK – 窗口结束之前，每隔1分钟输出一次更新结果</p>
<p>tumble_window 会忽略并丢弃窗口结束后到达的数据，而这部分数据对我们来说很重要，希望能统计进最终的结果里。而且我们知道我们的迟到数据不会太多，且迟到时间不会超过一天以上，并且希望收到迟到的数据立刻就更新结果：INSERT INTO result SELECT * FROM tumble_window EMIT WITH DELAY ‘1’ MINUTE BEFORE WATERMARK, WITHOUT DELAY AFTER WATERMARK –窗口结束之后，每条到达的数据都输出</p>
<p>tEnv.getConfig.setIdleStateRetentionTime(Time.days(1), Time.days(2))//min、max，只有Time.days(1)这个参数直接对window生效</p>
<p>补充一下WITH DELAY ‘1’这种配置的周期触发策略（即DELAY大于0），最后都是由ProcessingTime系统时间触发：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WindowEmitStrategy</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> def <span class="title">createTriggerFromInterval</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      enableDelayEmit: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">      interval: Long)</span>: Option[Trigger[TimeWindow]] </span>= &#123;</span><br><span class="line">    <span class="keyword">if</span> (!enableDelayEmit) &#123;</span><br><span class="line">      None</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (interval &gt; <span class="number">0</span>) &#123;</span><br><span class="line">       <span class="comment">// 系统时间触发，小于wm的所有timer都执行onProcessingTime()</span></span><br><span class="line">        Some(ProcessingTimeTriggers.every(Duration.ofMillis(interval)))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="comment">// 为0则每条都触发</span></span><br><span class="line">        Some(ElementTriggers.every())</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>5、Trigger类和结构关系 在源码中，Window Trigger的实现子类有10个左右，需要结合上一个小节的EMIT SQL能更容易理清他们之间的关系，这里简单介绍下：</p>
<p><img src="_v_images/20210412125427432_1763085070" alt="图片"></p>
<ul>
<li><p>AfterEndOfWindow：这个就是没配置任何EMIT策略时，默认的EvenTime、ProcTime</p>
</li>
<li><p>Window触发策略（即窗口结束后触发一次）</p>
</li>
<li><p>EveryElement：即delay=0，在processElement()时直接触发，无论是在窗口结束之前或者窗口结束之后都触发，且不再注册timer</p>
</li>
<li><p>AfterEndOfWindowNoLate：对应EMIT WITHOUT DELAY AFTER WATERMARK，窗口结束之前不输出，窗口结束之后无延迟输出</p>
</li>
<li><p>AfterFirstElementPeriodic：对应WITH DELAY ‘1’ MINUTE BEFORE| AFTER WATERMARK，即按系统时间周期执行，由ProcessingTime系统时间周期触发</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/01.%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/01.%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-12 17:33:24" itemprop="dateCreated datePublished" datetime="2021-04-12T17:33:24+08:00">2021-04-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h1><h2 id="为什么构建实时数仓"><a href="#为什么构建实时数仓" class="headerlink" title="为什么构建实时数仓"></a>为什么构建实时数仓</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Hadoop/Yarn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Hadoop/Yarn/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-12 17:33:24" itemprop="dateCreated datePublished" datetime="2021-04-12T17:33:24+08:00">2021-04-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h1><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">grep -A2 -B1 cg yarn-site.xml </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.memory-control.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.oom.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.hierarchy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop-yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/cgroup<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/distributed/02.%E9%99%90%E6%B5%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/distributed/02.%E9%99%90%E6%B5%81/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-12 17:33:24" itemprop="dateCreated datePublished" datetime="2021-04-12T17:33:24+08:00">2021-04-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="02-限流"><a href="#02-限流" class="headerlink" title="02.限流"></a>02.限流</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-SQL-Join/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-SQL-Join/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-12 17:33:24" itemprop="dateCreated datePublished" datetime="2021-04-12T17:33:24+08:00">2021-04-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-SQL-Join"><a href="#Flink-SQL-Join" class="headerlink" title="Flink SQL Join"></a>Flink SQL Join</h1><h2 id="双流Join"><a href="#双流Join" class="headerlink" title="双流Join"></a>双流Join</h2><h3 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h3><p>从 Flink 1.6 版本开始，社区引入了状态 TTL（Time-To-Live）特性。在通过Flink SQL 实现流处理时，开发者可以为作业 SQL 设置TTL，实现过期状态的自动清理，从而防止作业状态无限膨胀</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    t_date,</span><br><span class="line">    <span class="built_in">COUNT</span> ( <span class="keyword">DISTINCT</span> user_id ) <span class="keyword">AS</span> cnt_login, <span class="comment">-- 今日登录用户数</span></span><br><span class="line">    <span class="built_in">COUNT</span> ( <span class="keyword">DISTINCT</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> t_date <span class="operator">=</span> t_debut <span class="keyword">THEN</span> user_id <span class="keyword">END</span> ) <span class="keyword">AS</span> cnt_new <span class="comment">-- 今日新用户数</span></span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">  (</span><br><span class="line">    <span class="comment">-- 计算每个用户有史以来的最小登录时间</span></span><br><span class="line">    <span class="keyword">SELECT</span></span><br><span class="line">       t_date,</span><br><span class="line">       user_id,</span><br><span class="line">       <span class="built_in">MIN</span> (t_date) <span class="keyword">OVER</span> (</span><br><span class="line">             <span class="keyword">PARTITION</span> <span class="keyword">BY</span> user_id</span><br><span class="line">             <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">             <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">1</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">       ) <span class="keyword">AS</span> t_debut</span><br><span class="line">    <span class="keyword">FROM</span> Login</span><br><span class="line">) <span class="keyword">AS</span> t</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> t_date</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Query-Configuration-查询配置"><a href="#Query-Configuration-查询配置" class="headerlink" title="Query Configuration 查询配置"></a>Query Configuration 查询配置</h3><p><a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/streaming/query_configuration.html">https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/streaming/query_configuration.html</a></p>
<p>Flink Table API 和SQL接口提供参数来调整连续查询的准确性和资源消耗。参数通过 <code>QueryConfig</code> 对象指定。<code>QueryConfig</code> 可以从 <code>TableEnvironment</code> 获得。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取 query configuration</span></span><br><span class="line"><span class="keyword">val</span> qConfig: <span class="type">StreamQueryConfig</span> = tableEnv.queryConfig</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置查询参数</span></span><br><span class="line">qConfig.withIdleStateRetentionTime(<span class="type">Time</span>.hours(<span class="number">12</span>), <span class="type">Time</span>.hours(<span class="number">24</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义查询和 TableSink</span></span><br><span class="line"><span class="keyword">val</span> result: <span class="type">Table</span> = ???</span><br><span class="line"><span class="keyword">val</span> sink: <span class="type">TableSink</span>[<span class="type">Row</span>] = ???</span><br><span class="line"></span><br><span class="line"><span class="comment">// TableSink 发送结果表时传递查询参数</span></span><br><span class="line">result.writeToSink(sink, qConfig)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换为 DataStream 时传递查询参数</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Row</span>] = result.toAppendStream[<span class="type">Row</span>](qConfig)</span><br></pre></td></tr></table></figure>
<p>空闲状态保持时间（Idle State Retention Time）参数定义一个键的状态在一次更新之后保存多久后删除。</p>
<p>通过删除键的状态，连续查询会完全忘记它之前已经看过这个键。如果删除的键再次出现，则被视为具有相应键的第一个记录。对于前面的查询示例，这意味着 sessionId 的计数从0开始。</p>
<p>配置空闲状态保存时间有两个参数：</p>
<pre><code>minimum idle state retention time，定义非活动键的状态在删除前至少保持多少时间。
maximum idle state retention time，定义非活动键的状态在删除前最多保持多少时间。</code></pre>
<p>对于前面的查询示例：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> qConfig: <span class="type">StreamQueryConfig</span> = ???</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置 idle state retention time: min = 12 hours, max = 24 hours</span></span><br><span class="line">qConfig.withIdleStateRetentionTime(<span class="type">Time</span>.hours(<span class="number">12</span>), <span class="type">Time</span>.hours(<span class="number">24</span>))</span><br></pre></td></tr></table></figure>
<p>清理状态需要额外的记录，对于 minTime 和 maxTime 较大差异的情况成本更低，因此 minTime 和 maxTime 直接必须至少相差5分钟。</p>
<h2 id="维表Join"><a href="#维表Join" class="headerlink" title="维表Join"></a>维表Join</h2><h3 id="启用AsyncIO"><a href="#启用AsyncIO" class="headerlink" title="启用AsyncIO"></a>启用AsyncIO</h3><h3 id="时间表Join-Temporal-Table-Join"><a href="#时间表Join-Temporal-Table-Join" class="headerlink" title="时间表Join: Temporal Table Join"></a>时间表Join: Temporal Table Join</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">o.amout, o.currency, r.rate, o.amount <span class="operator">*</span> r.rate</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">Orders <span class="keyword">AS</span> o</span><br><span class="line"><span class="keyword">JOIN</span> LatestRates <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> o.proctime <span class="keyword">AS</span> r</span><br><span class="line"><span class="keyword">ON</span> r.currency <span class="operator">=</span> o.currency</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-backpress/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-backpress/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-12 17:33:24" itemprop="dateCreated datePublished" datetime="2021-04-12T17:33:24+08:00">2021-04-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="实时流处理系统反压机制（BackPressure）综述-转"><a href="#实时流处理系统反压机制（BackPressure）综述-转" class="headerlink" title="实时流处理系统反压机制（BackPressure）综述[转]"></a>实时流处理系统反压机制（BackPressure）综述[转]</h1><p> 发表于 2018-11-15 |  更新于 2018-12-03 |  分类于 <a target="_blank" rel="noopener" href="http://ileaf.tech/category/#/BigData">BigData </a>|  阅读次数 333</p>
<p>本文主要关于实时流处理系统反压机制，最近看到反压问题看到此文章很好，在此分享并mark一下。</p>
<blockquote>
<p>本文主要关于实时流处理系统反压机制，最近看到反压问题看到此文章很好，在此分享并mark一下。<br>(￢_￢)ﾉ最近菜叶子没自己写见谅。<br>本文转自 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21125183/article/details/80708142">实时流处理系统反压机制（BackPressure）综述</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21125183/article/details/80708142">https://blog.csdn.net/qq_21125183/article/details/80708142</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a></p>
</blockquote>
<p>反压机制（BackPressure）被广泛应用到实时流处理系统中，流处理系统需要能优雅地处理反压（backpressure）问题。<br>反压通常产生于这样的场景：短时负载高峰导致系统接收数据的速率远高于它处理数据的速率。<br>许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或者遇到大促或秒杀活动导致流量陡增。<br>反压如果不能得到正确的处理，可能会导致资源耗尽甚至系统崩溃。反压机制就是指系统能够自己检测到被阻塞的Operator，然后系统自适应地降低源头或者上游的发送速率。</p>
<p>目前主流的流处理系统 Apache Storm、JStorm、Spark Streaming、S4、Apache Flink、Twitter Heron都采用反压机制解决这个问题，不过他们的实现各自不同。</p>
<p><img src="_v_images/20201030212807758_57452691.png" alt="实时流处理系统反压机制01"></p>
<p>不同的组件可以不同的速度执行（并且每个组件中的处理速度随时间改变）。 例如，考虑一个工作流程，或由于数据倾斜或任务调度而导致数据被处理十分缓慢。<br>在这种情况下，如果上游阶段不减速，将导致缓冲区建立长队列(队列占用内存、硬盘空间，节点负载加重)，或导致系统丢弃元组。<br>如果元组在中途丢弃，那么效率可能会有损失，因为已经为这些元组产生的计算被浪费了。<br>并且在一些流处理系统中比如Strom，会将这些丢失的元组重新发送，这样会导致数据的一致性问题(at least once语义)，并且还会导致某些Operator状态叠加。<br>进而整个程序输出结果不准确。第二由于系统接收数据的速率是随着时间改变的，短时负载高峰导致系统接收数据的速率远高于它处理数据的速率的情况，也会导致Tuple在中途丢失。<br>所以实时流处理系统必须能够解决发送速率远大于系统能处理速率这个问题，大多数实时流处理系统采用反压（BackPressure）机制解决这个问题。</p>
<p>下面我们就来介绍一下不同的实时流处理系统采用的反压机制：</p>
<h1 id="Strom-反压机制"><a href="#Strom-反压机制" class="headerlink" title="Strom 反压机制"></a>Strom 反压机制</h1><h2 id="Storm-1-0-以前的反压机制"><a href="#Storm-1-0-以前的反压机制" class="headerlink" title="Storm 1.0 以前的反压机制"></a>Storm 1.0 以前的反压机制</h2><p>对于开启了acker机制的storm程序，可以通过设置conf.setMaxSpoutPending参数来实现反压效果，<strong>如果下游组件(bolt)处理速度跟不上导致spout发送的tuple没有及时确认的数超过了参数设定的值，spout会停止发送数据</strong>，这种方式的缺点是很难调优conf.setMaxSpoutPending参数的设置以达到最好的反压效果，设小了会导致吞吐上不去，设大了会导致worker OOM；有震荡，数据流会处于一个颠簸状态，效果不如逐级反压；另外对于关闭acker机制的程序无效；</p>
<h2 id="Storm-Automatic-Backpressure"><a href="#Storm-Automatic-Backpressure" class="headerlink" title="Storm Automatic Backpressure"></a>Storm Automatic Backpressure</h2><p>新的storm自动反压机制(Automatic Back Pressure)通过监控bolt中的接收队列的情况，当超过高水位值时专门的线程会将反压信息写到 Zookeeper ，Zookeeper上的watch会通知该拓扑的所有Worker都进入反压状态，最后Spout降低tuple发送的速度。</p>
<p><img src="_v_images/20201030212806451_178512803.png" alt="实时流处理系统反压机制02"></p>
<p>每个Executor都有一个接受队列和发送队列用来接收Tuple和发送Spout或者Bolt生成的Tuple元组。每个Worker进程都有一个单的的接收线程监听接收端口。<br>它从每个网络上进来的消息发送到Executor的接收队列中。Executor接收队列存放Worker或者Worker内部其他Executor发过来的消息。<br>Executor工作线程从接收队列中拿出数据，然后调用execute方法，发送Tuple到Executor的发送队列。<br>Executor的发送线程从发送队列中获取消息，按照消息目的地址选择发送到Worker的传输队列中或者其他Executor的接收队列中。<br>最后Worker的发送线程从传输队列中读取消息，然后将Tuple元组发送到网络中。</p>
<ol>
<li>当Worker进程中的Executor线程发现自己的接收队列满了时，也就是接收队列达到<code>high watermark</code>的阈值后，因此它会发送通知消息到背压线程。</li>
<li>背压线程将当前worker进程的信息注册到Zookeeper的Znode节点中。具体路径就是 <code>/Backpressure/topo1/wk1</code>下</li>
<li>Zookeepre的Znode Watcher监视/Backpreesure/topo1下的节点目录变化情况，如果发现目录增加了znode节点说明或者其他变化。这就说明该Topo1需要反压控制，然后它会通知Topo1所有的Worker进入反压状态。</li>
<li>最终Spout降低tuple发送的速度。</li>
</ol>
<h1 id="JStorm-反压机制"><a href="#JStorm-反压机制" class="headerlink" title="JStorm 反压机制"></a>JStorm 反压机制</h1><p>JStorm做了两级的反压，第一级和Jstorm类似，通过执行队列来监测，但是不会通过ZK来协调，而是通过Topology Master来协调。<br>在队列中会标记high water mark和low water mark，当执行队列超过high water mark时，就认为bolt来不及处理，则向TM发一条控制消息，上游开始减慢发送速率，直到下游低于low water mark时解除反压。</p>
<p>此外，在Netty层也做了一级反压，由于每个Worker Task都有自己的发送和接收的缓冲区，可以对缓冲区设定限额、控制大小，如果spout数据量特别大，缓冲区填满会导致下游bolt的接收缓冲区填满，造成了反压。</p>
<p><img src="_v_images/20201030212805000_1695102842.png" alt="实时流处理系统反压机制03"></p>
<p>限流机制：jstorm的限流机制， 当下游bolt发生阻塞时， 并且阻塞task的比例超过某个比例时（现在默认设置为0.1），触发反压</p>
<p>限流方式：计算阻塞Task的地方执行线程执行时间，Spout每发送一个tuple等待相应时间，然后讲这个时间发送给Spout， 于是， spout每发送一个tuple，就会等待这个执行时间。</p>
<p>Task阻塞判断方式：在jstorm 连续4次采样周期中采样，队列情况，当队列超过80%（可以设置）时，即可认为该task处在阻塞状态。</p>
<h1 id="SparkStreaming-反压机制"><a href="#SparkStreaming-反压机制" class="headerlink" title="SparkStreaming 反压机制"></a>SparkStreaming 反压机制</h1><h2 id="为什么引入反压机制Backpressure"><a href="#为什么引入反压机制Backpressure" class="headerlink" title="为什么引入反压机制Backpressure"></a>为什么引入反压机制Backpressure</h2><p>默认情况下，Spark Streaming通过Receiver以生产者生产数据的速率接收数据，计算过程中会出现<code>batch processing time &gt; batch interval</code>的情况，其中<code>batch processing time</code> 为实际计算一个批次花费时间， <code>batch interval</code>为Streaming应用设置的批处理间隔。<br>这意味着Spark Streaming的数据接收速率高于Spark从队列中移除数据的速率，也就是数据处理能力低，在设置间隔内不能完全处理当前接收速率接收的数据。如果这种情况持续过长的时间，会造成数据在内存中堆积，导致Receiver所在Executor内存溢出等问题（如果设置StorageLevel包含disk, 则内存存放不下的数据会溢写至disk, 加大延迟）。<br>Spark 1.5以前版本，用户如果要限制Receiver的数据接收速率，可以通过设置静态配制参数“<code>spark.streaming.receiver.maxRate</code>”的值来实现，此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer数据生产高于maxRate，当前集群处理能力也高于maxRate，这就会造成资源利用率下降等问题。为了更好的协调数据接收速率与资源处理能力，Spark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。</p>
<h2 id="反压机制Backpressure"><a href="#反压机制Backpressure" class="headerlink" title="反压机制Backpressure"></a>反压机制Backpressure</h2><p><code>Spark Streaming Backpressure</code>: 根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。通过属性“spark.streaming.backpressure.enabled”来控制是否启用backpressure机制，默认值false，即不启用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sparkConf.set(<span class="string">&quot;spark.streaming.backpressure.enabled&quot;</span>,”<span class="keyword">true</span>”)</span><br></pre></td></tr></table></figure>
<p>SparkStreaming 架构图如下所示:</p>
<p><img src="_v_images/20201030212803393_1135733829.png" alt="实时流处理系统反压机制04"></p>
<p>SparkStreaming 反压过程执行如下图所示：</p>
<p>在原架构的基础上加上一个新的组件RateController,这个组件负责监听“OnBatchCompleted”事件，然后从中抽取<code>processingDelay</code> 及<code>schedulingDelay</code>信息. <code>Estimator</code>依据这些信息估算出最大处理速度（rate），最后由基于<code>Receiver</code>的Input Stream将rate通过ReceiverTracker与ReceiverSupervisorImpl转发给BlockGenerator（继承自RateLimiter）.</p>
<p><img src="_v_images/20201030212801986_428923565.png" alt="实时流处理系统反压机制05"></p>
<h2 id="direct模式-BackPressure-此部分详细说明了direct模式接收：转自-开启Back-Pressure使生产环境的Spark-Streaming应用更稳定、有效"><a href="#direct模式-BackPressure-此部分详细说明了direct模式接收：转自-开启Back-Pressure使生产环境的Spark-Streaming应用更稳定、有效" class="headerlink" title="direct模式-BackPressure(此部分详细说明了direct模式接收：转自-开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效)"></a>direct模式-BackPressure(此部分详细说明了direct模式接收：转自-<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a>)</h2><p>当Spark Streaming与Kafka使用Direct API集群时，我们可以很方便的去控制最大数据摄入量–通过一个被称作spark.streaming.kafka.maxRatePerPartition的参数。根据文档描述，他的含义是：Direct API读取每一个Kafka partition数据的最大速率（每秒读取的消息量）。<br>配置项spark.streaming.kafka.maxRatePerPartition，对防止流式应用在下边两种情况下出现流量过载时尤其重要：<br>1.Kafka Topic中有大量未处理的消息，并且我们设置是Kafka auto.offset.reset参数值为smallest，他可以防止第一个批次出现数据流量过载情况。<br>2.当Kafka 生产者突然飙升流量的时候，他可以防止批次处理出现数据流量过载情况。</p>
<p>但是，配置Kafka每个partition每批次最大的摄入量是个静态值，也算是个缺点。随着时间的变化，在生产环境运行了一段时间的Spark Streaming应用，每批次每个Kafka partition摄入数据最大量的最优值也是变化的。有时候，是因为消息的大小会变，导致数据处理时间变化。有时候，是因为流计算所使用的多租户集群会变得非常繁忙，比如在白天时候，一些其他的数据应用（例如Impala/Hive/MR作业）竞争共享的系统资源时（CPU/内存/网络/磁盘IO）。<br>背压机制可以解决该问题。背压机制是呼声比较高的功能，他允许根据前一批次数据的处理情况，动态、自动的调整后续数据的摄入量，这样的反馈回路使得我们可以应对流式应用流量波动的问题。<br>Spark Streaming的背压机制是在Spark1.5版本引进的，我们可以添加如下代码启用改功能：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sparkConf.set(&quot;spark.streaming.backpressure.enabled&quot;,”true”)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>那应用启动后的第一个批次流量怎么控制呢？因为他没有前面批次的数据处理时间，所以没有参考的数据去评估这一批次最优的摄入量。在Spark官方文档中有个被称作spark.streaming.backpressure.initialRate的配置，看起来是控制开启背压机制时初始化的摄入量。其实不然，该参数只对receiver模式起作用，并不适用于direct模式。推荐的方法是使用spark.streaming.kafka.maxRatePerPartition控制背压机制起作用前的第一批次数据的最大摄入量。我通常建议设置spark.streaming.kafka.maxRatePerPartition的值为最优估计值的1.5到2倍，让背压机制的算法去调整后续的值。请注意，spark.streaming.kafka.maxRatePerPartition的值会一直控制最大的摄入量，所以背压机制的算法值不会超过他。<br>另一个需要注意的是，在第一个批次处理完成前，紧接着的批次都将使用spark.streaming.kafka.maxRatePerPartition的值作为摄入量。通过Spark UI可以看到，批次间隔为5s，当批次调度延迟31秒时候，前7个批次的摄入量是20条记录。直到第八个批次，背压机制起作用时，摄入量变为5条记录。</p>
<h1 id="Heron-反压机制"><a href="#Heron-反压机制" class="headerlink" title="Heron 反压机制"></a>Heron 反压机制</h1><p><img src="_v_images/20201030212800445_1650579597.png" alt="实时流处理系统反压机制06"></p>
<p>当下游处理速度跟不上上游发送速度时，一旦StreamManager 发现一个或多个Heron Instance 速度变慢，立刻对本地spout进行降级，降低本地Spout发送速度, 停止从这些spout读取数据。并且受影响的StreamManager 会发送一个特殊的start backpressure message 给其他的StreamManager ，要求他们对spout进行本地降级。 当其他StreamManager 接收到这个特殊消息时，他们通过不读取当地Spout中的Tuple来进行降级。一旦出问题的Heron Instance 恢复速度后，本地的SM 会发送stop backpressure message 解除降级。</p>
<p>很多Socket Channel与应用程序级别的Buffer相关联，该缓冲区由high watermark 和low watermark组成。 当缓冲区大小达到high watermark时触发反压，并保持有效，直到缓冲区大小低于low watermark。 此设计的基本原理是防止拓扑在进入和退出背压缓解模式之间快速振荡。</p>
<h1 id="Flink-反压机制"><a href="#Flink-反压机制" class="headerlink" title="Flink 反压机制"></a>Flink 反压机制</h1><p>Flink 没有使用任何复杂的机制来解决反压问题，因为根本不需要那样的方案！它利用自身作为纯数据流引擎的优势来优雅地响应反压问题。下面我们会深入分析 Flink 是如何在 Task 之间传输数据的，以及数据流如何实现自然降速的。 Flink 在运行时主要由 operators 和 streams 两大组件构成。每个 operator 会消费中间态的流，并在流上进行转换，然后生成新的流。对于 Flink 的网络机制一种形象的类比是，Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。还记得经典的线程间通信案例：生产者消费者模型吗？使用 BlockingQueue 的话，一个较慢的接受者会降低发送者的发送速率，因为一旦队列满了（有界队列）发送者会被阻塞。Flink 解决反压的方案就是这种感觉。 在 Flink 中，这些分布式阻塞队列就是这些逻辑流，而队列容量是通过缓冲池来（LocalBufferPool）实现的。每个被生产和被消费的流都会被分配一个缓冲池。缓冲池管理着一组缓冲(Buffer)，缓冲在被消费后可以被回收循环利用。这很好理解：你从池子中拿走一个缓冲，填上数据，在数据消费完之后，又把缓冲还给池子，之后你可以再次使用它。</p>
<h2 id="Flink-网络传输中的内存管理"><a href="#Flink-网络传输中的内存管理" class="headerlink" title="Flink 网络传输中的内存管理"></a>Flink 网络传输中的内存管理</h2><p>如下图所示展示了 Flink 在网络传输场景下的内存管理。网络上传输的数据会写到 Task 的 InputGate（IG） 中，经过 Task 的处理后，再由 Task 写到 ResultPartition（RS） 中。每个 Task 都包括了输入和输入，输入和输出的数据存在 Buffer 中（都是字节数据）。Buffer 是 MemorySegment 的包装类。</p>
<p><img src="_v_images/20201030212758832_1369878662.png" alt="实时流处理系统反压机制07"></p>
<ol>
<li>TaskManager（TM）在启动时，会先初始化NetworkEnvironment对象，TM 中所有与网络相关的东西都由该类来管理（如 Netty 连接），其中就包括NetworkBufferPool。根据配置，Flink 会在 NetworkBufferPool 中生成一定数量（默认2048个）的内存块 MemorySegment（关于 Flink 的内存管理，后续文章会详细谈到），内存块的总数量就代表了网络传输中所有可用的内存。NetworkEnvironment 和 NetworkBufferPool 是 Task 之间共享的，每个 TM 只会实例化一个。</li>
<li>Task 线程启动时，会向 NetworkEnvironment 注册，NetworkEnvironment 会为 Task 的 InputGate（IG）和 ResultPartition（RP） 分别创建一个 LocalBufferPool（缓冲池）并设置可申请的 MemorySegment（内存块）数量。IG 对应的缓冲池初始的内存块数量与 IG 中 InputChannel 数量一致，RP 对应的缓冲池初始的内存块数量与 RP 中的 ResultSubpartition 数量一致。不过，每当创建或销毁缓冲池时，NetworkBufferPool 会计算剩余空闲的内存块数量，并平均分配给已创建的缓冲池。注意，这个过程只是指定了缓冲池所能使用的内存块数量，并没有真正分配内存块，只有当需要时才分配。为什么要动态地为缓冲池扩容呢？因为内存越多，意味着系统可以更轻松地应对瞬时压力（如GC），不会频繁地进入反压状态，所以我们要利用起那部分闲置的内存块。</li>
<li>在 Task 线程执行过程中，当 Netty 接收端收到数据时，为了将 Netty 中的数据拷贝到 Task 中，InputChannel（实际是 RemoteInputChannel）会向其对应的缓冲池申请内存块（上图中的①）。如果缓冲池中也没有可用的内存块且已申请的数量还没到池子上限，则会向 NetworkBufferPool 申请内存块（上图中的②）并交给 InputChannel 填上数据（上图中的③和④）。如果缓冲池已申请的数量达到上限了呢？或者 NetworkBufferPool 也没有可用内存块了呢？这时候，Task 的 Netty Channel 会暂停读取，上游的发送端会立即响应停止发送，拓扑会进入反压状态。当 Task 线程写数据到 ResultPartition 时，也会向缓冲池请求内存块，如果没有可用内存块时，会阻塞在请求内存块的地方，达到暂停写入的目的。</li>
<li>当一个内存块被消费完成之后（在输入端是指内存块中的字节被反序列化成对象了，在输出端是指内存块中的字节写入到 Netty Channel 了），会调用 Buffer.recycle() 方法，会将内存块还给 LocalBufferPool （上图中的⑤）。如果LocalBufferPool中当前申请的数量超过了池子容量（由于上文提到的动态容量，由于新注册的 Task 导致该池子容量变小），则LocalBufferPool会将该内存块回收给 NetworkBufferPool（上图中的⑥）。如果没超过池子容量，则会继续留在池子中，减少反复申请的开销。</li>
</ol>
<h2 id="Flink-反压机制-1"><a href="#Flink-反压机制-1" class="headerlink" title="Flink 反压机制"></a>Flink 反压机制</h2><p>下面这张图简单展示了两个 Task 之间的数据传输以及 Flink 如何感知到反压的：</p>
<p><img src="_v_images/20201030212757424_78076714.png" alt="实时流处理系统反压机制08"></p>
<ol>
<li>记录“A”进入了 Flink 并且被 Task 1 处理。（这里省略了 Netty 接收、反序列化等过程）</li>
<li>记录被序列化到 buffer 中。</li>
<li>该 buffer 被发送到 Task 2，然后 Task 2 从这个 buffer 中读出记录。</li>
</ol>
<p><strong>不要忘了：记录能被 Flink 处理的前提是，必须有空闲可用的 Buffer。</strong></p>
<p>结合上面两张图看：Task 1 在输出端有一个相关联的 LocalBufferPool（称缓冲池1），Task 2 在输入端也有一个相关联的 LocalBufferPool（称缓冲池2）。如果缓冲池1中有空闲可用的 buffer 来序列化记录 “A”，我们就序列化并发送该 buffer。</p>
<p>这里我们需要注意两个场景：</p>
<ul>
<li>本地传输：如果 Task 1 和 Task 2 运行在同一个 worker 节点（TaskManager），该 buffer 可以直接交给下一个 Task。一旦 Task 2 消费了该 buffer，则该 buffer 会被缓冲池1回收。如果 Task 2 的速度比 1 慢，那么 buffer 回收的速度就会赶不上 Task 1 取 buffer 的速度，导致缓冲池1无可用的 buffer，Task 1 等待在可用的 buffer 上。最终形成 Task 1 的降速。</li>
<li>远程传输：如果 Task 1 和 Task 2 运行在不同的 worker 节点上，那么 buffer 会在发送到网络（TCP Channel）后被回收。在接收端，会从 LocalBufferPool 中申请 buffer，然后拷贝网络中的数据到 buffer 中。如果没有可用的 buffer，会停止从 TCP 连接中读取数据。在输出端，通过 Netty 的水位值机制来保证不往网络中写入太多数据（后面会说）。如果网络中的数据（Netty输出缓冲中的字节数）超过了高水位值，我们会等到其降到低水位值以下才继续写入数据。这保证了网络中不会有太多的数据。如果接收端停止消费网络中的数据（由于接收端缓冲池没有可用 buffer），网络中的缓冲数据就会堆积，那么发送端也会暂停发送。另外，这会使得发送端的缓冲池得不到回收，writer 阻塞在向 LocalBufferPool 请求 buffer，阻塞了 writer 往 ResultSubPartition 写数据。</li>
</ul>
<p>这种固定大小缓冲池就像阻塞队列一样，保证了 Flink 有一套健壮的反压机制，使得 Task 生产数据的速度不会快于消费的速度。我们上面描述的这个方案可以从两个 Task 之间的数据传输自然地扩展到更复杂的 pipeline 中，保证反压机制可以扩散到整个 pipeline。</p>
<h2 id="反压实验"><a href="#反压实验" class="headerlink" title="反压实验"></a>反压实验</h2><p>另外，官方博客中为了展示反压的效果，给出了一个简单的实验。下面这张图显示了：随着时间的改变，生产者（黄色线）和消费者（绿色线）每5秒的平均吞吐与最大吞吐（在单一JVM中每秒达到8百万条记录）的百分比。我们通过衡量task每5秒钟处理的记录数来衡量平均吞吐。该实验运行在单 JVM 中，不过使用了完整的 Flink 功能栈。</p>
<p><img src="_v_images/20201030212755917_1236027751.png" alt="实时流处理系统反压机制09"></p>
<p>首先，我们运行生产task到它最大生产速度的60%（我们通过Thread.sleep()来模拟降速）。消费者以同样的速度处理数据。然后，我们将消费task的速度降至其最高速度的30%。你就会看到背压问题产生了，正如我们所见，生产者的速度也自然降至其最高速度的30%。接着，停止消费task的人为降速，之后生产者和消费者task都达到了其最大的吞吐。接下来，我们再次将消费者的速度降至30%，pipeline给出了立即响应：生产者的速度也被自动降至30%。最后，我们再次停止限速，两个task也再次恢复100%的速度。总而言之，我们可以看到：生产者和消费者在 pipeline 中的处理都在跟随彼此的吞吐而进行适当的调整，这就是我们希望看到的反压的效果。</p>
<h2 id="Flink-反压监控"><a href="#Flink-反压监控" class="headerlink" title="Flink 反压监控"></a>Flink 反压监控</h2><p>在 Storm/JStorm 中，只要监控到队列满了，就可以记录下拓扑进入反压了。但是 Flink 的反压太过于天然了，导致我们无法简单地通过监控队列来监控反压状态。Flink 在这里使用了一个 trick 来实现对反压的监控。如果一个 Task 因为反压而降速了，那么它会卡在向 LocalBufferPool 申请内存块上。那么这时候，该 Task 的 stack trace 就会长下面这样：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">java.lang.Object.wait(Native Method)</span><br><span class="line">o.a.f.[...].LocalBufferPool.requestBuffer(LocalBufferPool.java:<span class="number">163</span>)</span><br><span class="line">o.a.f.[...].LocalBufferPool.requestBufferBlocking(LocalBufferPool.java:<span class="number">133</span>) &lt;--- BLOCKING request</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure>
<p>那么事情就简单了。通过不断地采样每个 task 的 stack trace 就可以实现反压监控。</p>
<p><img src="_v_images/20201030212753993_1098219801.png" alt="实时流处理系统反压机制10"></p>
<p>Flink 的实现中，只有当 Web 页面切换到某个 Job 的 Backpressure 页面，才会对这个 Job 触发反压检测，因为反压检测还是挺昂贵的。JobManager 会通过 Akka 给每个 TaskManager 发送TriggerStackTraceSample消息。默认情况下，TaskManager 会触发100次 stack trace 采样，每次间隔 50ms（也就是说一次反压检测至少要等待5秒钟）。并将这 100 次采样的结果返回给 JobManager，由 JobManager 来计算反压比率（反压出现的次数/采样的次数），最终展现在 UI 上。UI 刷新的默认周期是一分钟，目的是不对 TaskManager 造成太大的负担。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Flink不需要一种特殊的机制来处理反压，因为Flink 中的数据传输相当于已经提供了应对反压的机制。因此，Flink 所能获得的最大吞吐量由其 pipeline 中最慢的组件决定。相对于 Storm/JStorm 的实现，Flink 的实现更为简洁优雅，源码中也看不见与反压相关的代码，无需 Zookeeper/TopologyMaster 的参与也降低了系统的负载，也利于对反压更迅速的响应。</p>
<blockquote>
<p>本文转自 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21125183/article/details/80708142">实时流处理系统反压机制（BackPressure）综述</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21125183/article/details/80708142">https://blog.csdn.net/qq_21125183/article/details/80708142</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/28fcd51d4edd">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/case/%E6%AC%BA%E8%AF%88%E6%A3%80%E6%B5%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/case/%E6%AC%BA%E8%AF%88%E6%A3%80%E6%B5%8B/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-12 17:33:24" itemprop="dateCreated datePublished" datetime="2021-04-12T17:33:24+08:00">2021-04-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/actions/FrundDetectedSystem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/actions/FrundDetectedSystem/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-12 17:33:24" itemprop="dateCreated datePublished" datetime="2021-04-12T17:33:24+08:00">2021-04-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-实时规则引擎实现与应用"><a href="#Flink-实时规则引擎实现与应用" class="headerlink" title="Flink 实时规则引擎实现与应用"></a>Flink 实时规则引擎实现与应用</h1><p>Rule engine</p>
<p>欺诈检测<br>实时标签工厂<br>ABT<br>CEP有什么问题？</p>
<p>Frund detected system</p>
<p>秒级规则生效<br>自定义分发，运行时动态切换<br>自定义窗口<br>实时多维聚合</p>
<p>样例:</p>
<ol>
<li>欺诈检测: 同一个用户连续往两一个账户三天内连续支付超过</li>
<li>实时标签工厂: 标签-用户近三十天访问次数、近三十天访问某个页面的次数</li>
<li>ABT</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/actions/02.%20%E5%AE%9E%E6%97%B6%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/actions/02.%20%E5%AE%9E%E6%97%B6%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-12 17:33:24" itemprop="dateCreated datePublished" datetime="2021-04-12T17:33:24+08:00">2021-04-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="实时用户画像"><a href="#实时用户画像" class="headerlink" title="实时用户画像"></a>实时用户画像</h1><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>企业面对不断增加的海量信息，其信息筛选和处理效率低下的困扰与日俱增。由于用户营销不够细化，企业App 中许多不合时宜或不合偏好的消息推送很大程度上影响了用户体验，甚至引发了用户流失</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">235</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">126</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
