<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="flink-table-api官方文档翻译 Concept  &amp; Common APITable API和SQL集成在一个联合的API中。这个API核心概念是Table，Table可以作为查询的输入和输出。这篇文章展示了使用Table API和SQL查询的通用结构，如何去进行表的注册，如何去进行表的查询，并且展示如何去进行表的输出。 1. Structure of Table API an">
<meta property="og:type" content="article">
<meta property="og:title" content="Flink:Table API">
<meta property="og:url" content="http://example.com/bigdata/Flink/TableAPI/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:description" content="flink-table-api官方文档翻译 Concept  &amp; Common APITable API和SQL集成在一个联合的API中。这个API核心概念是Table，Table可以作为查询的输入和输出。这篇文章展示了使用Table API和SQL查询的通用结构，如何去进行表的注册，如何去进行表的查询，并且展示如何去进行表的输出。 1. Structure of Table API an">
<meta property="og:locale">
<meta property="article:published_time" content="2019-08-10T06:58:00.000Z">
<meta property="article:modified_time" content="2021-04-04T01:10:30.553Z">
<meta property="article:author" content="aaronzhang">
<meta property="article:tag" content="Java">
<meta property="article:tag" content="Flink">
<meta property="article:tag" content="HBase">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/bigdata/Flink/TableAPI/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>Flink:Table API | Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/TableAPI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Flink:Table API
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-04 09:10:30" itemprop="dateModified" datetime="2021-04-04T09:10:30+08:00">2021-04-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="flink-table-api"><a href="#flink-table-api" class="headerlink" title="flink-table-api"></a>flink-table-api</h1><p><a target="_blank" rel="noopener" href="https://github.com/crestofwave1/oneFlink/blob/master/doc/table/Concept%20%26%20Common%20API.md">官方文档翻译</a></p>
<h2 id="Concept-amp-Common-API"><a href="#Concept-amp-Common-API" class="headerlink" title="Concept  &amp; Common API"></a>Concept  &amp; Common API</h2><p>Table API和SQL集成在一个联合的API中。这个API核心概念是Table，<br>Table可以作为查询的输入和输出。这篇文章展示了使用Table API和SQL查询的通用结构，<br>如何去进行表的注册，如何去进行表的查询，并且展示如何去进行表的输出。</p>
<h2 id="1-Structure-of-Table-API-and-SQL-Programs"><a href="#1-Structure-of-Table-API-and-SQL-Programs" class="headerlink" title="1. Structure of Table API and SQL Programs"></a>1. Structure of Table API and SQL Programs</h2><p>​    所有使用批量和流式相关的Table API和SQL的程序都有以下相同模式。下面的代码实例展示了Table API和SQL程序的通用结构。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在批处理程序中使用ExecutionEnvironment代替StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册表</span></span><br><span class="line">tableEnv.registerTable(<span class="string">&quot;table1&quot;</span>, ...)           <span class="comment">// or</span></span><br><span class="line">tableEnv.registerTableSource(<span class="string">&quot;table2&quot;</span>, ...)     <span class="comment">// or</span></span><br><span class="line">tableEnv.registerExternalCatalog(<span class="string">&quot;extCat&quot;</span>, ...) </span><br><span class="line"></span><br><span class="line"><span class="comment">// 基于Table API的查询创建表</span></span><br><span class="line"><span class="keyword">val</span> tapiResult = tableEnv.scan(<span class="string">&quot;table1&quot;</span>).select(...)</span><br><span class="line"><span class="comment">// 从SQL查询创建表</span></span><br><span class="line"><span class="keyword">val</span> sqlResult  = tableEnv.sqlQuery(<span class="string">&quot;SELECT ... FROM table2 ...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表操作API查询到的结果表输出到TableSink，SQL查询到的结果一样如此</span></span><br><span class="line">tapiResult.writeToSink(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行</span></span><br><span class="line">env.execute()</span><br></pre></td></tr></table></figure>
<p>注意：Table API和SQL查询很容易集成并被嵌入到DataStream或者DataSet程序中。查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-datastream-and-dataset-api">将DataStream和DataSet API进行整合</a>章节<br>学习DataSteams和DataSets是如何转换成Table以及Table是如何转换为DataStream或DataSet</p>
<h2 id="2-Create-a-TableEnvironment"><a href="#2-Create-a-TableEnvironment" class="headerlink" title="2. Create a TableEnvironment"></a>2. Create a TableEnvironment</h2><p>TableEnvironment是Table API与SQL整合的核心概念之一，它主要有如下功能：</p>
<ul>
<li>在internal catalog注册表</li>
<li>注册external catalog</li>
<li>执行SQL查询</li>
<li>注册UDF函数（user-defined function)，例如 标量, 表或聚合</li>
<li>将DataStream或者DataSet转换为表</li>
<li>保持ExecutionEnvironment或者StreamExecutionEnvironment的引用指向</li>
</ul>
<p>一个表总是与一个特定的TableEnvironment绑定在一块，<br>相同的查询不同的TableEnvironment是无法通过join、union合并在一起。</p>
<p>创建TableEnvironment的方法通常是通过StreamExecutionEnvironment，ExecutionEnvironment对象调用其中的静态方法TableEnvironment.getTableEnvironment()，或者是TableConfig来创建。<br>TableConfig可以用作配置TableEnvironment或是对自定义查询优化器或者是编译过程进行优化(详情查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#query-optimization">查询优化</a>)</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ***************</span></span><br><span class="line"><span class="comment">// 流式查询</span></span><br><span class="line"><span class="comment">// ***************</span></span><br><span class="line"><span class="keyword">val</span> sEnv = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="comment">// 为流式查询创建一个TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> sTableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(sEnv)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ***********</span></span><br><span class="line"><span class="comment">// 批量查询</span></span><br><span class="line"><span class="comment">// ***********</span></span><br><span class="line"><span class="keyword">val</span> bEnv = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="comment">// 为批量查询创建一个TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> bTableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(bEnv)</span><br></pre></td></tr></table></figure>
<h2 id="Register-Tables-in-the-Catalog"><a href="#Register-Tables-in-the-Catalog" class="headerlink" title="Register Tables in the Catalog"></a>Register Tables in the Catalog</h2><p>TableEnvironment包含了通过名称注册表时的表的catalog信息。通常情况下有两种表，一种为输入表，<br>一种为输出表。输入表主要是在使用Table API和SQL查询时提供输入数据，输出表主要是将Table API和<br>SQL查询的结果作为输出结果对接到外部系统。</p>
<p>输入表有多种不同的输入源进行注册：</p>
<ul>
<li>已经存在的Table对象，通常是是作为Table API和SQL查询的结果</li>
<li>TableSource，可以访问外部数据如文件，数据库或者是消息系统</li>
<li>来自DataStream或是DataSet程序中的DataStream或DataSet，讨论DataStream或是DataSet<br>可以<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-datastream-and-dataset-api">整合DataStream和DataSet API</a>了解到</li>
</ul>
<p>输出表可使用TableSink进行注册</p>
<h2 id="Register-a-Table"><a href="#Register-a-Table" class="headerlink" title="Register a Table"></a>Register a Table</h2><p>Table是如何注册到TableEnvironment中如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从简单的查询结果中作为表</span></span><br><span class="line"><span class="keyword">val</span> projTable: <span class="type">Table</span> = tableEnv.scan(<span class="string">&quot;X&quot;</span>).select(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的表projTable命名为projectedTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTable(<span class="string">&quot;projectedTable&quot;</span>, projTable)</span><br></pre></td></tr></table></figure>
<p>注意：一张注册过的Table就跟关系型数据库中的视图性质相同，定义表的查询未进行优化，但在另一个查询引用已注册的表时将进行内联。<br>如果多表查询引用了相同的Table，它就会将每一个引用进行内联并且多次执行，已注册的Table的结果之间不会进行共享。</p>
<h2 id="Register-a-TableSource"><a href="#Register-a-TableSource" class="headerlink" title="Register a TableSource"></a>Register a TableSource</h2><p>TableSource可以访问外部系统存储例如数据库（Mysql,HBase），特殊格式编码的文件(CSV, Apache [Parquet, Avro, ORC], …)<br>或者是消息系统 (Apache Kafka, RabbitMQ, …)中的数据。</p>
<p>Flink旨在为通用数据格式和存储系统提供TableSource。请查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">此处</a><br>了解支持的TableSource类型与如何去自定义TableSour。</p>
<p>TableSource是如何注册到TableEnvironment中如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableSource对象</span></span><br><span class="line"><span class="keyword">val</span> csvSource: <span class="type">TableSource</span> = <span class="keyword">new</span> <span class="type">CsvTableSource</span>(<span class="string">&quot;/path/to/file&quot;</span>, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的TableSource作为表并命名为csvTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTableSource(<span class="string">&quot;CsvTable&quot;</span>, csvSource)</span><br></pre></td></tr></table></figure>
<h2 id="Register-a-TableSink"><a href="#Register-a-TableSink" class="headerlink" title="Register a TableSink"></a>Register a TableSink</h2><p>注册过的TableSink可以将SQL查询的结果以表的形式输出到外部的存储系统，例如关系型数据库，<br>Key-Value数据库(Nosql)，消息队列，或者是其他文件系统(使用不同的编码, 例如CSV, Apache [Parquet, Avro, ORC], …)</p>
<p>Flink使用TableSink的目的是为了将常用的数据进行清洗转换然后存储到不同的存储介质中。详情请查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">此处</a><br>去深入了解哪些sinks是可用的，并且如何去自定义TableSink。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableSink对象</span></span><br><span class="line"><span class="keyword">val</span> csvSink: <span class="type">TableSink</span> = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">&quot;/path/to/file&quot;</span>, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义字段的名称和类型</span></span><br><span class="line"><span class="keyword">val</span> fieldNames: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> fieldTypes: <span class="type">Array</span>[<span class="type">TypeInformation</span>[_]] = <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">INT</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的TableSink作为表并命名为CsvSinkTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTableSink(<span class="string">&quot;CsvSinkTable&quot;</span>, fieldNames, fieldTypes, csvSink)</span><br></pre></td></tr></table></figure>
<h2 id="Register-an-External-Catalog"><a href="#Register-an-External-Catalog" class="headerlink" title="Register an External Catalog"></a>Register an External Catalog</h2><p>外部目录可以提供有关外部数据库和表的信息，<br>例如其名称，模式，统计以及有关如何访问存储在外部数据库，表或文件中的数据的信息。</p>
<p>外部目录的创建方式可以通过实现ExternalCatalog接口，并且注册到TableEnvironment中，详情如下所示:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个External Catalog目录对象</span></span><br><span class="line"><span class="keyword">val</span> catalog: <span class="type">ExternalCatalog</span> = <span class="keyword">new</span> <span class="type">InMemoryExternalCatalog</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将ExternalCatalog注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerExternalCatalog(<span class="string">&quot;InMemCatalog&quot;</span>, catalog)</span><br></pre></td></tr></table></figure>
<p>一旦将External Catalog注册到TableEnvironment中，所有在ExternalCatalog中<br>定义的表可以通过完整的路径如catalog.database.table进行Table API和SQL的查询操作 </p>
<p>目前，Flink提供InMemoryExternalCatalog对象用来做demo和测试，然而，<br>ExternalCatalog对象还可用作Table API来连接catalogs，例如HCatalog 或 Metastore</p>
<h2 id="Query-a-Table"><a href="#Query-a-Table" class="headerlink" title="Query a Table"></a>Query a Table</h2><h3 id="Table-API"><a href="#Table-API" class="headerlink" title="Table API"></a>Table API</h3><p>Table API是Scala和Java语言集成查询的API，与SQL查询不同之处在于，它的查询不是像<br>SQL一样使用字符串进行查询，而是在语言中使用语法进行逐步组合使用</p>
<p>Table API是基于展示表（流或批处理）的Table类，它提供一些列操作应用相关的操作。<br>这些方法返回一个新的Table对象，该对象表示在输入表上关系运算的结果。一些关系运算是<br>由多个方法组合而成的，例如 table.groupBy(…).select()，其中groupBy()指定<br>表的分组，select()表示在分组的结果上进行查询。</p>
<p><a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/tableApi.html">Table API</a><br>描述了所有支持表的流式或者批处理相关的操作。</p>
<p>下面给出一个简单的实例去说明如何去使用Table API进行聚合查询：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册Orders表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 扫描注册过的Orders表</span></span><br><span class="line"><span class="keyword">val</span> orders = tableEnv.scan(<span class="string">&quot;Orders&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入</span></span><br><span class="line"><span class="keyword">val</span> revenue = orders</span><br><span class="line">  .filter(<span class="symbol">&#x27;cCountry</span> === <span class="string">&quot;FRANCE&quot;</span>)</span><br><span class="line">  .groupBy(<span class="symbol">&#x27;cID</span>, <span class="symbol">&#x27;cName</span>)</span><br><span class="line">  .select(<span class="symbol">&#x27;cID</span>, <span class="symbol">&#x27;cName</span>, <span class="symbol">&#x27;revenue</span>.sum <span class="type">AS</span> <span class="symbol">&#x27;revSum</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出成一张表或者是转换表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<p>注意：Scala的Table API使用Scala符号，它使用单引号加字段(‘cID)来表示表的属性的引用，<br>如果使用Scala的隐式转换的话，确保引入了org.apache.flink.api.scala._ 和 org.apache.flink.table.api.scala._<br>来确保它们之间的转换。</p>
<h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><p>Flink的SQL操作基于实现了SQL标准的<a target="_blank" rel="noopener" href="https://calcite.apache.org/">Apache Calcite</a>，SQL查询通常是使用特殊且有规律的字符串。<br><a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sql.html">SQL</a><br>描述了所有支持表的流式或者批处理相关的SQL操作。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册Orders表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入</span></span><br><span class="line"><span class="keyword">val</span> revenue = tableEnv.sqlQuery(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  |SELECT cID, cName, SUM(revenue) AS revSum</span></span><br><span class="line"><span class="string">  |FROM Orders</span></span><br><span class="line"><span class="string">  |WHERE cCountry = &#x27;FRANCE&#x27;</span></span><br><span class="line"><span class="string">  |GROUP BY cID, cName</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出成一张表或者是转换表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<p>下面的例子展示了如何去使用更新查询去插入数据到已注册的表中</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册&quot;Orders&quot;表</span></span><br><span class="line"><span class="comment">// 注册&quot;RevenueFrance&quot;输出表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入并且将结果作为结果输出到&quot;RevenueFrance&quot;中</span></span><br><span class="line">tableEnv.sqlUpdate(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  |INSERT INTO RevenueFrance</span></span><br><span class="line"><span class="string">  |SELECT cID, cName, SUM(revenue) AS revSum</span></span><br><span class="line"><span class="string">  |FROM Orders</span></span><br><span class="line"><span class="string">  |WHERE cCountry = &#x27;FRANCE&#x27;</span></span><br><span class="line"><span class="string">  |GROUP BY cID, cName</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<h2 id="Mixing-Table-API-and-SQL"><a href="#Mixing-Table-API-and-SQL" class="headerlink" title="Mixing Table API and SQL"></a>Mixing Table API and SQL</h2><p>Table API和SQL可以很轻松的混合使用因为他们两者返回的结果都为Table对象：</p>
<ul>
<li>可以在SQL查询返回的Table对象上定义Table API查询</li>
<li>通过在TableEnvironment中注册结果表并在SQL查询的FROM子句中引用它，<br>可以在Table API查询的结果上定义SQL查询。</li>
</ul>
<h2 id="Emit-a-Table"><a href="#Emit-a-Table" class="headerlink" title="Emit a Table"></a>Emit a Table</h2><p>通过将Table写入到TableSink来作为一张表的输出，TableSink是做为多种文件类型 (CSV, Apache Parquet, Apache Avro),<br>存储系统(JDBC, Apache HBase, Apache Cassandra, Elasticsearch), 或者是消息系统 (Apache Kafka, RabbitMQ).输出的通用接口，</p>
<p>Batch Table只能通过BatchTableSink来进行数据写入，而Streaming Table可以<br>选择AppendStreamTableSink，RetractStreamTableSink，UpsertStreamTableSink<br>中的任意一个来进行。</p>
<p>请查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">Table Source &amp; Sinks</a><br>来更详细的了解支持的Sinks并且如何去实现自定义的TableSink。</p>
<p>可以使用两种方式来输出一张表：</p>
<ul>
<li>Table.writeToSink(TableSink sink)方法使用提供的TableSink自动配置的表的schema来<br>进行表的输出</li>
<li>Table.insertInto（String sinkTable）方法查找在TableEnvironment目录中提供的名称下使用特定模式注册的TableSink。<br>将输出表的模式将根据已注册的TableSink的模式进行验证</li>
</ul>
<p>下面的例子展示了如何去查询结果作为一张表输出</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用Table API或者SQL 查询来查找结果</span></span><br><span class="line"><span class="keyword">val</span> result: <span class="type">Table</span> = ...</span><br><span class="line"><span class="comment">// 创建TableSink对象</span></span><br><span class="line"><span class="keyword">val</span> sink: <span class="type">TableSink</span> = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">&quot;/path/to/file&quot;</span>, fieldDelim = <span class="string">&quot;|&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法1: 使用TableSink的writeToSink()方法来将结果输出为一张表</span></span><br><span class="line">result.writeToSink(sink)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法2: 注册特殊schema的TableSink</span></span><br><span class="line"><span class="keyword">val</span> fieldNames: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> fieldTypes: <span class="type">Array</span>[<span class="type">TypeInformation</span>] = <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">INT</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>)</span><br><span class="line">tableEnv.registerTableSink(<span class="string">&quot;CsvSinkTable&quot;</span>, fieldNames, fieldTypes, sink)</span><br><span class="line"><span class="comment">// 调用注册过的TableSink中insertInto() 方法来将结果输出为一张表</span></span><br><span class="line">result.insertInto(<span class="string">&quot;CsvSinkTable&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行</span></span><br></pre></td></tr></table></figure>
<h2 id="Translate-and-Execute-a-Query"><a href="#Translate-and-Execute-a-Query" class="headerlink" title="Translate and Execute a Query"></a>Translate and Execute a Query</h2><p>Table API和SQL查询的结果转换为<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/datastream_api.html">DataStream</a><br>或是<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/">DataSet</a><br>取决于它的输入是流式输入还是批处理输入。查询逻辑在内部表示为逻辑执行计划，并分为两个阶段进行转换：</p>
<ul>
<li>优化逻辑执行计划</li>
<li>转换为DataStream或DataSet</li>
</ul>
<p>Table API或SQL查询在下面请看下进行转换：</p>
<ul>
<li>当调用Table.writeToSink() 或 Table.insertInto()进行查询结果表输出的时候</li>
<li>当调用TableEnvironment.sqlUpdate()进行SQL更新查询时</li>
<li>当表转换为DataSteam或DataSet时，详情查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-dataStream-and-dataSet-api">Integration with DataStream and DataSet API</a></li>
</ul>
<p>一旦进行转换后，Table API或SQL查询的结果就会在StreamExecutionEnvironment.execute() 或 ExecutionEnvironment.execute()<br>被调用时被当做DataStream或DataSet一样被进行处理</p>
<h2 id="Integration-with-DataStream-and-DataSet-API"><a href="#Integration-with-DataStream-and-DataSet-API" class="headerlink" title="Integration with DataStream and DataSet API"></a>Integration with DataStream and DataSet API</h2><p>Table API或SQL查询的结果很容易被<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/datastream_api.html">DataStream</a><br>或是<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/">DataSet</a>内嵌整合。举个例子，<br>我们会进行外部表的查询(像关系型数据库)，然后做像过滤，映射，聚合或者是元数据关联的一些预处理。<br>然后使用DataStream或是DataSet API(或者是基于这些基础库开发的上层API库, 例如CEP或Gelly)进一步对数据进行处理。<br>同样，Table API或SQL查询也可以应用于DataStream或DataSet程序的结果。</p>
<p>##implicit Conversion for Scala<br>Scala Table API具有DataSet，DataStream和Table Class之间的隐式转换，流式操作API中只要引入org.apache.flink.table.api.scala._<br>和 org.apache.flink.api.scala._ 便可以进行相应的隐式转换</p>
<h2 id="Register-a-DataStream-or-DataSet-as-Table"><a href="#Register-a-DataStream-or-DataSet-as-Table" class="headerlink" title="Register a DataStream or DataSet as Table"></a>Register a DataStream or DataSet as Table</h2><p>DataStream或DataSet也可以作为Table注册到TableEnvironment中。结果表的模式取决于已注册的DataStream或DataSet的数据类型，<br>详情请查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#mapping-of-data-types-to-table-schema">mapping of data types to table schema</a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream作为具有&quot;f0&quot;, &quot;f1&quot;字段的&quot;myTable&quot;表注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerDataStream(<span class="string">&quot;myTable&quot;</span>, stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream作为具有&quot;myLong&quot;, &quot;myString&quot;字段的&quot;myTable2&quot;表注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerDataStream(<span class="string">&quot;myTable2&quot;</span>, stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br></pre></td></tr></table></figure>
<p>注意：DataStream表的名称必须与^ <em>DataStreamTable</em> [0-9] +模式不匹配，<br>并且DataSet表的名称必须与^ <em>DataSetTable</em> [0-9] +模式不匹配。<br>这些模式仅供内部使用。</p>
<h2 id="Convert-a-DataStream-or-DataSet-into-a-Table"><a href="#Convert-a-DataStream-or-DataSet-into-a-Table" class="headerlink" title="Convert a DataStream or DataSet into a Table"></a>Convert a DataStream or DataSet into a Table</h2><p>如果你使用Table API或是SQL查询，你可以直接将DataStream或DataSet直接转换为表而不需要<br>再将它们注册到TableEnvironment中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1, &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table1: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;myLong, &#x27;myString将DataStram转换为Table</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> table2: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Convert-a-Table-into-a-DataStream-or-DataSet"><a href="#Convert-a-Table-into-a-DataStream-or-DataSet" class="headerlink" title="Convert a Table into a DataStream or DataSet"></a>Convert a Table into a DataStream or DataSet</h2><p>表可以转换为DataStream或DataSet，通过这种方式，自定义DataStream或DataSet<br>同样也可以作为Table API或SQL查询结果的结果。<br>当把表转换为DataStream或DataSet时，你需要指定生成的DataStream或DataSet的数据类型。<br>例如，表格行所需转换的数据类型，通常最方便的转换类型也最常用的是Row。<br>以下列表概述了不同选项的功能：</p>
<ul>
<li>Row：字段按位置，任意数量的字段映射，支持空值，无类型安全访问。</li>
<li>POJO：字段按名称(POJO字段必须与Table字段保持一致)，任意数量的字段映射，支持空值，类型安全访问。</li>
<li>Case Class：字段按位置，任意数量的字段映射，不支持空值，类型安全访问。</li>
<li>Tuple：字段按位置，Scala支持22个字段，Java 25个字段映射，不支持空值，类型安全访问。</li>
<li>Atomic Type：表必须具有单个字段，不支持空值，类型安全访问。<h3 id="Convert-a-Table-into-a-DataStream"><a href="#Convert-a-Table-into-a-DataStream" class="headerlink" title="Convert a Table into a DataStream"></a>Convert a Table into a DataStream</h3>作为流式查询结果的表将动态更新，它随着新记录到达查询的输入流而改变，于是，转换到这样的动态查询DataStream<br>需要对表的更新进行编码。<br>将表转换为DataStream有两种模式：</li>
<li>Append Mode：这种模式仅用于动态表仅仅通过INSERT来进行表的更新，它是仅可追加模式，<br>并且之前输出的表不会进行更改</li>
<li>Retract Mode：这种模式经常用到。它使用布尔值的变量来对INSERT和DELETE对表的更新做标记<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表中有两个字段(String name, Integet age)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为列的 append DataStream</span></span><br><span class="line"><span class="keyword">val</span> dsRow: <span class="type">DataStream</span>[<span class="type">Row</span>] = tableEnv.toAppendStream[<span class="type">Row</span>](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为Tubple2[String,Int]的 append DataStream</span></span><br><span class="line"><span class="comment">// convert the Table into an append DataStream of Tuple2[String, Int]</span></span><br><span class="line"><span class="keyword">val</span> dsTuple: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] dsTuple = </span><br><span class="line">  tableEnv.toAppendStream[(<span class="type">String</span>, <span class="type">Int</span>)](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert the Table into a retract DataStream of Row.</span></span><br><span class="line"><span class="comment">// Retract Mode下将表转换为列的 append DataStream</span></span><br><span class="line"><span class="comment">// 判断A retract stream X是否为DataStream[(Boolean, X)]</span></span><br><span class="line"><span class="comment">//  布尔只表示数据类型的变化,True代表为INSERT，false表示为删除</span></span><br><span class="line"><span class="keyword">val</span> retractStream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, <span class="type">Row</span>)] = tableEnv.toRetractStream[<span class="type">Row</span>](table)</span><br></pre></td></tr></table></figure>
注意：关于动态表和它的属性详情参考<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/streaming.html">Streaming Queries</a></li>
</ul>
<h3 id="Convert-a-Table-into-a-DataSet"><a href="#Convert-a-Table-into-a-DataSet" class="headerlink" title="Convert a Table into a DataSet"></a>Convert a Table into a DataSet</h3><p>表转换为DataSet如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表中有两个字段(String name, Integet age)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为列的DataSet</span></span><br><span class="line"><span class="keyword">val</span> dsRow: <span class="type">DataSet</span>[<span class="type">Row</span>] = tableEnv.toDataSet[<span class="type">Row</span>](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为Tubple2[String,Int]的DataSet</span></span><br><span class="line"><span class="keyword">val</span> dsTuple: <span class="type">DataSet</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = tableEnv.toDataSet[(<span class="type">String</span>, <span class="type">Int</span>)](table)</span><br></pre></td></tr></table></figure>
<h3 id="Mapping-of-Data-Types-to-Table-Schema"><a href="#Mapping-of-Data-Types-to-Table-Schema" class="headerlink" title="Mapping of Data Types to Table Schema"></a>Mapping of Data Types to Table Schema</h3><p>Flink的DataStream和DataSet API支持多种类型。组合类型像Tuple(内置Scala元组和Flink Java元组)，<br>POJOs，Scala case classes和Flink中具有可在表表达式中访问的多个字段允许嵌套数据结构的Row类型，<br>其他类型都被视为原子类型。接下来，我们将会描述Table API是如何将这些类型转换为内部的列展现并且<br>举例说明如何将DataStream转换为Table</p>
<h4 id="Position-based-Mapping"><a href="#Position-based-Mapping" class="headerlink" title="Position-based Mapping"></a>Position-based Mapping</h4><p>基于位置的映射通常在保持顺序的情况下给字段一个更有意义的名称，这种映射可用于有固定顺序的组合数据类型，<br>也可用于原子类型。复合数据类型（如元组，行和Case Class）具有此类字段顺序.然而，POJO的字段必须与映射的<br>表的字段名相同。</p>
<p>当定义基于位置的映射，输入的数据类型不得存在指定的名称，不然API会认为这些映射应该按名称来进行映射。<br>如果未指定字段名称，则使用复合类型的默认字段名称和字段顺序，或者使用f0作为原子类型。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1, &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table1: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;myLong, &#x27;myInt将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span> <span class="symbol">&#x27;myInt</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Name-based-Mapping"><a href="#Name-based-Mapping" class="headerlink" title="Name-based Mapping"></a>Name-based Mapping</h4><p>基于名称的映射可用于一切数据类型包括POJOs，它是定义表模式映射最灵活的一种方式。虽然查询结果的字段可能会使用别名，但<br>这种模式下所有的字段都是使用名称进行映射的。使用别名的情况下会进行重排序。<br>如果未指定字段名称，则使用复合类型的默认字段名称和字段顺序，或者使用f0作为原子类型。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1 和 &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只使用&#x27;_2字段将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换字段将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>, <span class="symbol">&#x27;_1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换后的字段给予别名&#x27;myInt, &#x27;myLong将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span> as <span class="symbol">&#x27;myInt</span>, <span class="symbol">&#x27;_1</span> as <span class="symbol">&#x27;myLong</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Atomic-Types"><a href="#Atomic-Types" class="headerlink" title="Atomic Types"></a>Atomic Types</h4><p>Flink将基础类型(Integer, Double, String)和通用类型(不能被分析和拆分的类型)视为原子类型。<br>原子类型的DataStream或DataSet转换为只有单个属性的表。从原子类型推断属性的类型，并且可以指定属性的名称。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Long</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为带默认字段&quot;f0&quot;的表</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为带字段&quot;myLong&quot;的表</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Tuples-Scala-and-Java-and-Case-Classes-Scala-only"><a href="#Tuples-Scala-and-Java-and-Case-Classes-Scala-only" class="headerlink" title="Tuples (Scala and Java) and Case Classes (Scala only)"></a>Tuples (Scala and Java) and Case Classes (Scala only)</h4><p>Flink支持内建的Tuples并且提供了自己的Tuple类给Java进行使用。DataStreams和DataSet这两种<br>Tuple都可以转换为表。提供所有字段的名称(基于位置的映射)字段可以被重命名。如果没有指定字段的名称，<br>就使用默认的字段名称。如果原始字段名(f0, f1, … for Flink Tuples and _1, _2, … for Scala Tuples)被引用了的话，<br>API就会使用基于名称的映射来代替位置的映射。基于名称的映射可以起别名并且会进行重排序。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将默认的字段重命名为&#x27;_1，&#x27;_2的DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字段名为&#x27;myLong，&#x27;myString的DataStream转换为Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将重排序后字段为&#x27;_2，&#x27;_1 的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>, <span class="symbol">&#x27;_1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将映射字段&#x27;_2的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将重排序后字段为&#x27;_2给出别名&#x27;myString，&#x27;_1给出别名&#x27;myLong 的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span> as <span class="symbol">&#x27;myString</span>, <span class="symbol">&#x27;_1</span> as <span class="symbol">&#x27;myLong</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义 case class</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">streamCC</span></span>: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将默认字段&#x27;name, &#x27;age的DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table = tableEnv.fromDataStream(streamCC)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字段名为&#x27;myName，&#x27;myAge的DataStream转换为Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table = tableEnv.fromDataStream(streamCC, <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line">将重排序后字段为<span class="symbol">&#x27;_age</span>给出别名<span class="symbol">&#x27;myAge</span>，<span class="symbol">&#x27;_name</span>给出别名<span class="symbol">&#x27;myName</span> 的<span class="type">DataStream</span>转换为<span class="type">Table</span>(基于名称)</span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="POJO-Java-and-Scala"><a href="#POJO-Java-and-Scala" class="headerlink" title="POJO (Java and Scala)"></a>POJO (Java and Scala)</h4><p>Flink支持POJO作为符合类型。决定POJO规则的文档请参考<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/api_concepts.html#pojos">这里</a></p>
<p>当将一个POJO类型的DataStream或者DataSet转换为Table而不指定字段名称时，Table的字段名称将采用JOPO原生的字段名称作为字段名称。<br>重命名原始的POJO字段需要关键字AS，因为POJO没有固定的顺序，名称映射需要原始名称并且不能通过位置来完成。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Person 是一个有两个字段&quot;name&quot;和&quot;age&quot;的POJO</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为带字段 &quot;age&quot;, &quot;name&quot; 的Table(字段通过名称进行排序)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为重命名为&quot;myAge&quot;, &quot;myName&quot;的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将带映射字段&#x27;name的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将带映射字段&#x27;name并重命名为&#x27;myName的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Row"><a href="#Row" class="headerlink" title="Row"></a>Row</h4><p>Row数据类型可以支持任意数量的字段，并且这些字段支持null值。当进行Row DataStream或Row DataSet<br>转换为Table时可以通过RowTypeInfo来指定字段的名称。Row Type支持基于位置和名称的两种映射方式。<br>通过提供所有字段的名称可以进行字段的重命名(基于位置)，或者是单独选择列来进行映射/重排序/重命名(基于名称)</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在`RowTypeInfo`中指定字段&quot;name&quot; 和 &quot;age&quot;的Row类型DataStream</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Row</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为带默认字段 &quot;age&quot;, &quot;name&quot; 的Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为重命名字段 &#x27;myName, &#x27;myAge 的Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为重命名字段 &#x27;myName, &#x27;myAge 的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为映射字段 &#x27;name的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为映射字段 &#x27;name并重命名为&#x27;myName的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Query-Optimization"><a href="#Query-Optimization" class="headerlink" title="Query Optimization"></a>Query Optimization</h4><p>Apache Flink 基于 Apache Calcite 来做转换和查询优化。当前的查询优化包括投影、过滤下推、<br>相关子查询和各种相关的查询重写。Flink不去做join优化，但是会让他们去顺序执行(FROM子句中表的顺序或者WHERE子句中连接谓词的顺序)</p>
<p>可以通过提供一个CalciteConfig对象来调整在不同阶段应用的优化规则集，<br>这个可以通过调用CalciteConfig.createBuilder())获得的builder来创建，<br>并且可以通过调用tableEnv.getConfig.setCalciteConfig(calciteConfig)来提供给TableEnvironment。</p>
<h4 id="Explaining-a-Table"><a href="#Explaining-a-Table" class="headerlink" title="Explaining a Table"></a>Explaining a Table</h4><p>Table API为计算Table提供了一个机制来解析逻辑和优化查询计划，这个可以通过TableEnvironment.explain(table)<br>来完成。它返回描述三个计划的字符串信息：</p>
<ul>
<li>关联查询抽象语法树，即未优化过的逻辑执行计划</li>
<li>优化过的逻辑执行计划</li>
<li>物理执行计划</li>
</ul>
<p>下面的实例展示了相应的输出：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> tEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> table1 = env.fromElements((<span class="number">1</span>, <span class="string">&quot;hello&quot;</span>)).toTable(tEnv, <span class="symbol">&#x27;count</span>, <span class="symbol">&#x27;word</span>)</span><br><span class="line"><span class="keyword">val</span> table2 = env.fromElements((<span class="number">1</span>, <span class="string">&quot;hello&quot;</span>)).toTable(tEnv, <span class="symbol">&#x27;count</span>, <span class="symbol">&#x27;word</span>)</span><br><span class="line"><span class="keyword">val</span> table = table1</span><br><span class="line">  .where(<span class="symbol">&#x27;word</span>.like(<span class="string">&quot;F%&quot;</span>))</span><br><span class="line">  .unionAll(table2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> explanation: <span class="type">String</span> = tEnv.explain(table)</span><br><span class="line">println(explanation)</span><br></pre></td></tr></table></figure>
<p>对应的输出如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#x3D;&#x3D; 抽象语法树 &#x3D;&#x3D;</span><br><span class="line">LogicalUnion(all&#x3D;[true])</span><br><span class="line">  LogicalFilter(condition&#x3D;[LIKE($1, &#39;F%&#39;)])</span><br><span class="line">    LogicalTableScan(table&#x3D;[[_DataStreamTable_0]])</span><br><span class="line">  LogicalTableScan(table&#x3D;[[_DataStreamTable_1]])</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D; 优化后的逻辑执行计划 &#x3D;&#x3D;</span><br><span class="line">DataStreamUnion(union&#x3D;[count, word])</span><br><span class="line">  DataStreamCalc(select&#x3D;[count, word], where&#x3D;[LIKE(word, &#39;F%&#39;)])</span><br><span class="line">    DataStreamScan(table&#x3D;[[_DataStreamTable_0]])</span><br><span class="line">  DataStreamScan(table&#x3D;[[_DataStreamTable_1]])</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D; 物理执行计划 &#x3D;&#x3D;</span><br><span class="line">Stage 1 : Data Source</span><br><span class="line">  content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">Stage 2 : Data Source</span><br><span class="line">  content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">  Stage 3 : Operator</span><br><span class="line">    content : from: (count, word)</span><br><span class="line">    ship_strategy : REBALANCE</span><br><span class="line"></span><br><span class="line">    Stage 4 : Operator</span><br><span class="line">      content : where: (LIKE(word, &#39;F%&#39;)), select: (count, word)</span><br><span class="line">      ship_strategy : FORWARD</span><br><span class="line"></span><br><span class="line">      Stage 5 : Operator</span><br><span class="line">        content : from: (count, word)</span><br><span class="line">        ship_strategy : REBALANCE</span><br></pre></td></tr></table></figure>

<h1 id="Flink用户自定义函数"><a href="#Flink用户自定义函数" class="headerlink" title="Flink用户自定义函数"></a>Flink用户自定义函数</h1><p>用户自定义函数是非常重要的一个特征，因为他极大地扩展了查询的表达能力。</p>
<p>在大多数场景下，用户自定义函数在使用之前是必须要注册的。对于Scala的Table API，udf是不需要注册的。<br>调用TableEnvironment的registerFunction()方法来实现注册。Udf注册成功之后，会被插入TableEnvironment的function catalog，这样table API和sql就能解析他了。<br>本文会主要讲三种udf：</p>
<ul>
<li>ScalarFunction</li>
<li>TableFunction</li>
<li>AggregateFunction</li>
</ul>
<h2 id="1-Scalar-Functions-标量函数"><a href="#1-Scalar-Functions-标量函数" class="headerlink" title="1. Scalar Functions 标量函数"></a>1. Scalar Functions 标量函数</h2><p>标量函数，是指指返回一个值的函数。标量函数是实现讲0，1，或者多个标量值转化为一个新值。</p>
<p>实现一个标量函数需要继承ScalarFunction，并且实现一个或者多个evaluation方法。标量函数的行为就是通过evaluation方法来实现的。evaluation方法必须定义为public，命名为eval。evaluation方法的输入参数类型和返回值类型决定着标量函数的输入参数类型和返回值类型。evaluation方法也可以被重载实现多个eval。同时evaluation方法支持变参数，例如：eval(String… strs)。</p>
<p>下面给出一个标量函数的例子。例子实现的事一个hashcode方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">12</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">HashCode</span><span class="params">(<span class="keyword">int</span> factor)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.factor = factor;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the function</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> HashCode(<span class="number">10</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in Java Table API</span></span><br><span class="line">myTable.select(<span class="string">&quot;string, string.hashCode(), hashCode(string)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in SQL API</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;</span>);</span><br><span class="line"></span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">默认情况下evaluation方法的返回值类型是由flink类型抽取工具决定。对于基础类型，简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载</span><br><span class="line">ScalarFunction#getResultType()。</span><br><span class="line"></span><br><span class="line">下面给一个例子，通过复写ScalarFunction#getResultType()，将long型的返回值在代码生成的时候翻译成Types.TIMESTAMP。</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TimestampModifier</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">eval</span><span class="params">(<span class="keyword">long</span> t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> t % <span class="number">1000</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> TypeInformation&lt;?&gt; getResultType(signature: Class&lt;?&gt;[]) &#123;</span><br><span class="line">    <span class="keyword">return</span> Types.TIMESTAMP;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-Table-Functions-表函数"><a href="#2-Table-Functions-表函数" class="headerlink" title="2. Table Functions 表函数"></a>2. Table Functions 表函数</h2><p>与标量函数相似之处是输入可以0，1，或者多个参数，但是不同之处可以输出任意数目的行数。返回的行也可以包含一个或者多个列。</p>
<p>为了自定义表函数，需要继承TableFunction，实现一个或者多个evaluation方法。表函数的行为定义在这些evaluation方法内部，函数名为eval并且必须是public。TableFunction可以重载多个eval方法。Evaluation方法的输入参数类型，决定着表函数的输入类型。Evaluation方法也支持变参，例如：eval(String… strs)。返回表的类型取决于TableFunction的基本类型。Evaluation方法使用collect(T)发射输出的rows。</p>
<p>在Table API中，表函数在scala语言中使用方法如下：.join(Expression) 或者 .leftOuterJoin(Expression)，在java语言中使用方法如下：.join(String) 或者.leftOuterJoin(String)。</p>
<p>Join操作算子会使用表值函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行。</p>
<p>leftOuterJoin操作算子会使用表值函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行，并且在表函数返回一个空表的情况下会保留所有的outer rows。</p>
<p>在sql语法中稍微有点区别：<br>cross join用法是LATERAL TABLE(<TableFunction>)。<br>LEFT JOIN用法是在join条件中加入ON TRUE。</p>
<p>下面的理智讲的是如何使用表值函数。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The generic type &quot;Tuple2&lt;String, Integer&gt;&quot; determines the schema of the returned table as (String, Integer).</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Split</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String separator = <span class="string">&quot; &quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Split</span><span class="params">(String separator)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.separator = separator;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String s : str.split(separator)) &#123;</span><br><span class="line">            <span class="comment">// use collect(...) to emit a row</span></span><br><span class="line">            collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(s, s.length()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line">Table myTable = ...         <span class="comment">// table schema: [a: String]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Register the function.</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;split&quot;</span>, <span class="keyword">new</span> Split(<span class="string">&quot;#&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use the table function in the Java Table API. &quot;as&quot; specifies the field names of the table.</span></span><br><span class="line">myTable.join(<span class="string">&quot;split(a) as (word, length)&quot;</span>).select(<span class="string">&quot;a, word, length&quot;</span>);</span><br><span class="line">myTable.leftOuterJoin(<span class="string">&quot;split(a) as (word, length)&quot;</span>).select(<span class="string">&quot;a, word, length&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use the table function in SQL with LATERAL and TABLE keywords.</span></span><br><span class="line">join.md</span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT a, word, length FROM MyTable, LATERAL TABLE(split(a)) as T(word, length)&quot;</span>);</span><br><span class="line"><span class="comment">// LEFT JOIN a table function (equivalent to &quot;leftOuterJoin&quot; in Table API).</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT a, word, length FROM MyTable LEFT JOIN LATERAL TABLE(split(a)) as T(word, length) ON TRUE&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>需要注意的是PROJO类型不需要一个确定的字段顺序。意味着你不能使用as修改表函数返回的pojo的字段的名字。</p>
<p>默认情况下TableFunction返回值类型是由flink类型抽取工具决定。对于基础类型，简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载<br>TableFunction#getResultType()。</p>
<p>下面的例子，我们通过复写TableFunction#getResultType()方法使得表返回类型是RowTypeInfo(String, Integer)。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomTypeSplit</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Row</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String s : str.split(<span class="string">&quot; &quot;</span>)) &#123;</span><br><span class="line">            Row row = <span class="keyword">new</span> Row(<span class="number">2</span>);</span><br><span class="line">            row.setField(<span class="number">0</span>, s);</span><br><span class="line">            row.setField(<span class="number">1</span>, s.length);</span><br><span class="line">            collect(row);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TypeInformation&lt;Row&gt; <span class="title">getResultType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Types.ROW(Types.STRING(), Types.INT());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-Aggregation-Functions-聚合函数"><a href="#3-Aggregation-Functions-聚合函数" class="headerlink" title="3. Aggregation Functions 聚合函数"></a>3. Aggregation Functions 聚合函数</h2><p>用户自定义聚合函数聚合一张表(一行或者多行，一行有一个或者多个属性)为一个标量的值。</p>
<p>上图中是讲的一张饮料的表这个表有是那个字段五行数据，现在要做的事求出所有饮料的最高价。</p>
<p>聚合函数需要继承AggregateFunction。聚合函数工作方式如下：<br>首先，需要一个accumulator，这个是保存聚合中间结果的数据结构。调用AggregateFunction函数的createAccumulator()方法来创建一个空的accumulator.<br>随后，每个输入行都会调用accumulate()方法来更新accumulator。一旦所有的行被处理了，getValue()方法就会被调用，计算和返回最终的结果。</p>
<p>对于每个AggregateFunction，下面三个方法都是比不可少的：<br>createAccumulator()<br>accumulate()<br>getValue()</p>
<p>flink的类型抽取机制不能识别复杂的数据类型，比如，数据类型不是基础类型或者简单的pojos类型。所以，类似于ScalarFunction 和TableFunction，AggregateFunction提供了方法去指定返回结果类型的TypeInformation，用的是AggregateFunction#getResultType()。Accumulator类型用的是AggregateFunction#getAccumulatorType()。</p>
<p>除了上面的方法，这里有一些可选的方法。尽管有些方法是让系统更加高效的执行查询，另外的一些在特定的场景下是必须的。例如，merge()方法在会话组窗口上下文中是必须的。当一行数据是被视为跟两个回话窗口相关的时候，两个会话窗口的accumulators需要被join。</p>
<p>AggregateFunction的下面几个方法，根据使用场景的不同需要被实现：<br>retract()：在bounded OVER窗口的聚合方法中是需要实现的。<br>merge()：在很多batch 聚合和会话窗口聚合是必须的。<br>resetAccumulator(): 在大多数batch聚合是必须的。</p>
<p>AggregateFunction的所有方法都是需要被声明为public，而不是static。定义聚合函数需要实现org.apache.flink.table.functions.AggregateFunction同时需要实现一个或者多个accumulate方法。该方法可以被重载为不同的数据类型，并且支持变参。</p>
<p>在这里就不贴出来AggregateFunction的源码了。</p>
<p>下面举个求加权平均的栗子<br>为了计算加权平均值，累加器需要存储已累积的所有数据的加权和及计数。在栗子中定义一个WeightedAvgAccum类作为accumulator。尽管，retract(), merge(), 和resetAccumulator()方法在很多聚合类型是不需要的，这里也给出了栗子。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Accumulator for WeightedAvg.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvgAccum</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Weighted Average user-defined aggregate function.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvg</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>&lt;<span class="title">Long</span>, <span class="title">WeightedAvgAccum</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> WeightedAvgAccum <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> WeightedAvgAccum();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Long <span class="title">getValue</span><span class="params">(WeightedAvgAccum acc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (acc.count == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> acc.sum / acc.count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accumulate</span><span class="params">(WeightedAvgAccum acc, <span class="keyword">long</span> iValue, <span class="keyword">int</span> iWeight)</span> </span>&#123;</span><br><span class="line">        acc.sum += iValue * iWeight;</span><br><span class="line">        acc.count += iWeight;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">retract</span><span class="params">(WeightedAvgAccum acc, <span class="keyword">long</span> iValue, <span class="keyword">int</span> iWeight)</span> </span>&#123;</span><br><span class="line">        acc.sum -= iValue * iWeight;</span><br><span class="line">        acc.count -= iWeight;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(WeightedAvgAccum acc, Iterable&lt;WeightedAvgAccum&gt; it)</span> </span>&#123;</span><br><span class="line">        Iterator&lt;WeightedAvgAccum&gt; iter = it.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            WeightedAvgAccum a = iter.next();</span><br><span class="line">            acc.count += a.count;</span><br><span class="line">            acc.sum += a.sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resetAccumulator</span><span class="params">(WeightedAvgAccum acc)</span> </span>&#123;</span><br><span class="line">        acc.count = <span class="number">0</span>;</span><br><span class="line">        acc.sum = <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// register function</span></span><br><span class="line">StreamTableEnvironment tEnv = ...</span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;wAvg&quot;</span>, <span class="keyword">new</span> WeightedAvg());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use function</span></span><br><span class="line">tEnv.sqlQuery(<span class="string">&quot;SELECT user, wAvg(points, level) AS avgPoints FROM userScores GROUP BY user&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="4-实现udf的最佳实践经验"><a href="#4-实现udf的最佳实践经验" class="headerlink" title="4. 实现udf的最佳实践经验"></a>4. 实现udf的最佳实践经验</h2><p>Table API和SQL 代码生成器内部会尽可能多的尝试使用原生值。用户定义的函数可能通过对象创建、强制转换(casting)和拆装箱((un)boxing)引入大量开销。因此，强烈推荐参数和返回值的类型定义为原生类型而不是他们包装类型(boxing class)。Types.DATE 和Types.TIME可以用int代替。Types.TIMESTAMP可以用long代替。</p>
<p>我们建议用户自定义函数使用java编写而不是scala编写，因为scala的类型可能会有不被flink类型抽取器兼容。</p>
<p>用Runtime集成UDFs</p>
<p>有时候udf需要获取全局runtime信息或者在进行实际工作之前做一些设置和清除工作。Udf提供了open()和close()方法，可以被复写，功能类似Dataset和DataStream API的RichFunction方法。</p>
<p>Open()方法是在evaluation方法调用前调用一次。Close()是在evaluation方法最后一次调用后调用。</p>
<p>Open()方法提共一个FunctionContext，FunctionContext包含了udf执行环境的上下文，比如，metric group，分布式缓存文件，全局的job参数。</p>
<p>通过调用FunctionContext的相关方法，可以获取到相关的信息：</p>
<p>方法描述</p>
<ul>
<li>getMetricGroup() - 并行子任务的指标组</li>
<li>getCachedFile(name) -分布式缓存文件的本地副本</li>
<li>getJobParameter(name, defaultValue) - 给定key全局job参数。</li>
</ul>
<p>下面，给出的例子就是通过FunctionContext在一个标量函数中获取全局job的参数。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(FunctionContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// access &quot;hashcode_factor&quot; parameter</span></span><br><span class="line">        <span class="comment">// &quot;12&quot; would be the default value if parameter does not exist</span></span><br><span class="line">        factor = Integer.valueOf(context.getJobParameter(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;12&quot;</span>)); </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// set job parameter</span></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.setString(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;31&quot;</span>);</span><br><span class="line">env.getConfig().setGlobalJobParameters(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the function</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> HashCode());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in Java Table API</span></span><br><span class="line">myTable.select(<span class="string">&quot;string, string.hashCode(), hashCode(string)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in SQL</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;</span>);</span><br></pre></td></tr></table></figure>
<h1 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h1><h2 id="scala"><a href="#scala" class="headerlink" title="scala"></a>scala</h2><h3 id="三元运算符"><a href="#三元运算符" class="headerlink" title="三元运算符"></a>三元运算符</h3><p>sql或者table API筛选数据，必须保证每个字段不为空，<br>Flink内部，中间结果都是通过case class传递，而case class的字段必须保证不能为空</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">BOOLEAN</span>.?(<span class="type">VALUE1</span>, <span class="type">VALUE2</span>)</span><br><span class="line"><span class="symbol">&#x27;is_active_user</span>.isNull.?(<span class="string">&quot;0&quot;</span>, <span class="string">&quot;1&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="等值判断"><a href="#等值判断" class="headerlink" title="等值判断"></a>等值判断</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&#x27;Fuin</span> === <span class="symbol">&#x27;active_user</span></span><br></pre></td></tr></table></figure>
<p>scala中的<code>===</code>是运算符重构</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Java/" rel="tag"># Java</a>
              <a href="/tags/Flink/" rel="tag"># Flink</a>
              <a href="/tags/HBase/" rel="tag"># HBase</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/bigdata/Flink/flink-on-yarn/" rel="prev" title="Flink on yarn">
      <i class="fa fa-chevron-left"></i> Flink on yarn
    </a></div>
      <div class="post-nav-item">
    <a href="/bigdata/Flink/StreamingAPI/" rel="next" title="Flink-streaming API">
      Flink-streaming API <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#flink-table-api"><span class="nav-number">1.</span> <span class="nav-text">flink-table-api</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Concept-amp-Common-API"><span class="nav-number">1.1.</span> <span class="nav-text">Concept  &amp; Common API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Structure-of-Table-API-and-SQL-Programs"><span class="nav-number">1.2.</span> <span class="nav-text">1. Structure of Table API and SQL Programs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Create-a-TableEnvironment"><span class="nav-number">1.3.</span> <span class="nav-text">2. Create a TableEnvironment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Register-Tables-in-the-Catalog"><span class="nav-number">1.4.</span> <span class="nav-text">Register Tables in the Catalog</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Register-a-Table"><span class="nav-number">1.5.</span> <span class="nav-text">Register a Table</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Register-a-TableSource"><span class="nav-number">1.6.</span> <span class="nav-text">Register a TableSource</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Register-a-TableSink"><span class="nav-number">1.7.</span> <span class="nav-text">Register a TableSink</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Register-an-External-Catalog"><span class="nav-number">1.8.</span> <span class="nav-text">Register an External Catalog</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Query-a-Table"><span class="nav-number">1.9.</span> <span class="nav-text">Query a Table</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Table-API"><span class="nav-number">1.9.1.</span> <span class="nav-text">Table API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SQL"><span class="nav-number">1.9.2.</span> <span class="nav-text">SQL</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mixing-Table-API-and-SQL"><span class="nav-number">1.10.</span> <span class="nav-text">Mixing Table API and SQL</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Emit-a-Table"><span class="nav-number">1.11.</span> <span class="nav-text">Emit a Table</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Translate-and-Execute-a-Query"><span class="nav-number">1.12.</span> <span class="nav-text">Translate and Execute a Query</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Integration-with-DataStream-and-DataSet-API"><span class="nav-number">1.13.</span> <span class="nav-text">Integration with DataStream and DataSet API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Register-a-DataStream-or-DataSet-as-Table"><span class="nav-number">1.14.</span> <span class="nav-text">Register a DataStream or DataSet as Table</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Convert-a-DataStream-or-DataSet-into-a-Table"><span class="nav-number">1.15.</span> <span class="nav-text">Convert a DataStream or DataSet into a Table</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Convert-a-Table-into-a-DataStream-or-DataSet"><span class="nav-number">1.16.</span> <span class="nav-text">Convert a Table into a DataStream or DataSet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Convert-a-Table-into-a-DataStream"><span class="nav-number">1.16.1.</span> <span class="nav-text">Convert a Table into a DataStream</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Convert-a-Table-into-a-DataSet"><span class="nav-number">1.16.2.</span> <span class="nav-text">Convert a Table into a DataSet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mapping-of-Data-Types-to-Table-Schema"><span class="nav-number">1.16.3.</span> <span class="nav-text">Mapping of Data Types to Table Schema</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Position-based-Mapping"><span class="nav-number">1.16.3.1.</span> <span class="nav-text">Position-based Mapping</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Name-based-Mapping"><span class="nav-number">1.16.3.2.</span> <span class="nav-text">Name-based Mapping</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Atomic-Types"><span class="nav-number">1.16.3.3.</span> <span class="nav-text">Atomic Types</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tuples-Scala-and-Java-and-Case-Classes-Scala-only"><span class="nav-number">1.16.3.4.</span> <span class="nav-text">Tuples (Scala and Java) and Case Classes (Scala only)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#POJO-Java-and-Scala"><span class="nav-number">1.16.3.5.</span> <span class="nav-text">POJO (Java and Scala)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Row"><span class="nav-number">1.16.3.6.</span> <span class="nav-text">Row</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Query-Optimization"><span class="nav-number">1.16.3.7.</span> <span class="nav-text">Query Optimization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Explaining-a-Table"><span class="nav-number">1.16.3.8.</span> <span class="nav-text">Explaining a Table</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Flink%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0"><span class="nav-number">2.</span> <span class="nav-text">Flink用户自定义函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Scalar-Functions-%E6%A0%87%E9%87%8F%E5%87%BD%E6%95%B0"><span class="nav-number">2.1.</span> <span class="nav-text">1. Scalar Functions 标量函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Table-Functions-%E8%A1%A8%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.</span> <span class="nav-text">2. Table Functions 表函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Aggregation-Functions-%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0"><span class="nav-number">2.3.</span> <span class="nav-text">3. Aggregation Functions 聚合函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E5%AE%9E%E7%8E%B0udf%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%E7%BB%8F%E9%AA%8C"><span class="nav-number">2.4.</span> <span class="nav-text">4. 实现udf的最佳实践经验</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0"><span class="nav-number">3.</span> <span class="nav-text">内置函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#scala"><span class="nav-number">3.1.</span> <span class="nav-text">scala</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E5%85%83%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="nav-number">3.1.1.</span> <span class="nav-text">三元运算符</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AD%89%E5%80%BC%E5%88%A4%E6%96%AD"><span class="nav-number">3.1.2.</span> <span class="nav-text">等值判断</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">240</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">120</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
