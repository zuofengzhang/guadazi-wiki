<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/page/9/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/9/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-VS-Spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-VS-Spark/" class="post-title-link" itemprop="url">Flink VS Spark</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-VS-Spark"><a href="#Flink-VS-Spark" class="headerlink" title="Flink VS Spark"></a>Flink VS Spark</h1><p>Spark Structure Streaming 是什么？</p>
<h3 id="1、抽象-Abstraction"><a href="#1、抽象-Abstraction" class="headerlink" title="1、抽象 Abstraction"></a>1、抽象 Abstraction</h3><p>　　Spark中，对于批处理我们有RDD,对于流式，我们有DStream，不过内部实际还是RDD.所以所有的数据表示本质上还是RDD抽象。在Flink中，对于批处理有DataSet，对于流式我们有DataStreams。看起来和Spark类似，他们的不同点在于：</p>
<p>　　<strong>（一）DataSet在运行时是表现为运行计划(runtime plans)的</strong></p>
<p>　　在Spark中，RDD在运行时是表现为java objects的。通过引入Tungsten，这块有了些许的改变。但是在Flink中是被表现为logical plan(逻辑计划)的, 就是类似于Spark中的dataframes。所以在Flink中你使用的类Dataframe api是被作为第一优先级来优化的。但是相对来说在Spark RDD中就没有了这块的优化了。<br>　　Flink中的Dataset，对标Spark中的Dataframe，在运行前会经过优化。在Spark 1.6，dataset API已经被引入Spark了，也许最终会取代RDD 抽象。</p>
<p>　　<strong>(二）Dataset和DataStream是独立的API</strong></p>
<p>　　在Spark中，所有不同的API，例如DStream，Dataframe都是基于RDD抽象的。但是在Flink中，Dataset和DataStream是同一个公用的引擎之上两个独立的抽象。所以你不能把这两者的行为合并在一起操作，当然，Flink社区目前在朝这个方向努力(<code>https://issues.apache.org/jira/browse/Flink-2320</code>)，但是目前还不能轻易断言最后的结果。</p>
<h3 id="2、内存管理"><a href="#2、内存管理" class="headerlink" title="2、内存管理"></a>2、内存管理</h3><p>　　一直到1.5版本，Spark都是试用java的内存管理来做数据缓存，明显很容易导致OOM或者gc。所以从1.5开始，Spark开始转向精确的控制内存的使用，这就是tungsten项目了。</p>
<p>　　而Flink从第一天开始就坚持自己控制内存试用。这个也是启发了Spark走这条路的原因之一。Flink除了把数据存在自己管理的内存以外，还直接操作二进制数据。在Spark中，从1.5开始，所有的dataframe操作都是直接作用在tungsten的二进制数据上。</p>
<h3 id="3、语言实现"><a href="#3、语言实现" class="headerlink" title="3、语言实现"></a>3、语言实现</h3><ul>
<li><p>实现语言</p>
<p>Spark和Flink均有Scala/Java混合编程实现，Spark的核心逻辑由Scala完成，Flink的主要核心逻辑由Java完成</p>
</li>
<li><p>支持应用语言<br> Flink主要支持Scala，和Java编程，部分API支持python应用<br> Spark主要支持Scala，Java，Python,R语言编程，部分API暂不支持Python和R</p>
</li>
</ul>
<h3 id="4、API"><a href="#4、API" class="headerlink" title="4、API"></a>4、API</h3><table>
<thead>
<tr>
<th>API对比</th>
<th>Flink</th>
<th></th>
<th>Spark</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>应用类型</td>
<td>Batch</td>
<td>Streaming</td>
<td>Batch</td>
<td>Structed Streaming</td>
<td>SparkStreaming</td>
</tr>
<tr>
<td>数据表示</td>
<td>Dataset</td>
<td>datastream</td>
<td>RDD,Dataset</td>
<td>Dataset</td>
<td>Dtream</td>
</tr>
<tr>
<td>主要支持API</td>
<td>map,filter,flatMap等</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>转换后数据类型</td>
<td>Dataset</td>
<td>datastream</td>
<td>RDD,Dataset</td>
<td>Dataset</td>
<td>Dtream</td>
</tr>
</tbody></table>
<h4 id="批处理："><a href="#批处理：" class="headerlink" title="批处理："></a>批处理：</h4><p>Spark批处理的数据表示经历了从<code>RDD -&gt; DataFrame -&gt; Dataset</code>的变化，均具有不可变，lazy执行，可分区等特性，是Spark框架的核心，rdd经过map等函数操作后，并没有改变而是生成新的RDD，Spark的Dataset（DataFrame是一种特殊的Dataset，已经不推荐使用）还包含数据类型信息</p>
<p>Flink批处理的API是Dataset,同样具有不可变，lazy执行，可分区等特性，是Flink框架的核心，Dataset经过map等函数操作后，并没有改变而是生成新的Dataset</p>
<h4 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h4><ul>
<li><p>Spark Streaming</p>
<p>Spark在1.*版本引入的spark streaming作为流处理模块，抽象出Dstream的API来进行流数据处理，同时抽象出通过receiver获取消息数据，然后启动task处理的模式，以及直接启动task消费处理两种方式的流式数据处理。receiver模式由于稳定性不足被遗弃，推荐使用的是直接消费模式；然而本质上讲，Sparkstreaming的流处理是micro-batch的处理模式，将一定时间的流数据作为一个block/RDD，然后使用批处理的rdd的api来完成数据的处理。</p>
</li>
<li><p>Structed streaming</p>
<p>随着Spark在2.*版本的Structed streaming的推出，Spark streaming模块进入了维护模式，从Spark2.*版本以来没有已经没有更新，当前社区主推使用Structed streaming进行流处理。Structed streaming在流处理中有两种流处理模式，一种是microbatch模式；一种是continuous模式；</p>
<ul>
<li><p>microbatch模式与spark streaming的microbatch模式大致相当，分批处理消息，但可通过设置连续的批次处理，即一个批次执行完之后立即进入下一个批次的处理</p>
</li>
<li><p>continuous模式，可以实现真正的流数据处理，端到端的毫秒级，当前处于Experiment状态，也只能支持简单的map,filter操作，当前不支持聚合，<code>current_timestamp</code>，<code>current_date</code>等操作</p>
</li>
<li><p>PS : microbatch &lt;—-&gt; continuous 两种模式可以相互切换且无需改动代码</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>Flink Streaming</p>
<p>Flink Streaming以流的方式处理流数据，可以实现简单map,fliter等操作，也可以实现复杂的聚合，关联操作，以完善的处理模型及high throughout得到了广泛的应用。</p>
</li>
</ul>
<p>　　Spark和Flink都在模仿scala的collection API.所以从表面看起来，两者都很类似。下面是分别用RDD和DataSet API实现的word count</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Spark wordcount</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="keyword">new</span> <span class="type">SparkContext</span>(<span class="string">&quot;local&quot;</span>,<span class="string">&quot;wordCount&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> data = <span class="type">List</span>(<span class="string">&quot;hi&quot;</span>,<span class="string">&quot;how are you&quot;</span>,<span class="string">&quot;hi&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> dataSet = env.parallelize(data)</span><br><span class="line">    <span class="keyword">val</span> words = dataSet.flatMap(value =&gt; value.split(<span class="string">&quot;\\s+&quot;</span>))</span><br><span class="line">    <span class="keyword">val</span> mappedWords = words.map(value =&gt; (value,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">val</span> sum = mappedWords.reduceByKey(_+_)</span><br><span class="line">    println(sum.collect())</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// Flink wordcount</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">　　<span class="keyword">val</span> env = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">　　<span class="keyword">val</span> data = <span class="type">List</span>(<span class="string">&quot;hi&quot;</span>,<span class="string">&quot;how are you&quot;</span>,<span class="string">&quot;hi&quot;</span>)</span><br><span class="line">　　<span class="keyword">val</span> dataSet = env.fromCollection(data)</span><br><span class="line">　　<span class="keyword">val</span> words = dataSet.flatMap(value =&gt; value.split(<span class="string">&quot;\\s+&quot;</span>))</span><br><span class="line">　　<span class="keyword">val</span> mappedWords = words.map(value =&gt; (value,<span class="number">1</span>))</span><br><span class="line">　　<span class="keyword">val</span> grouped = mappedWords.groupBy(<span class="number">0</span>)</span><br><span class="line">　　<span class="keyword">val</span> sum = grouped.sum(<span class="number">1</span>)</span><br><span class="line">　　println(sum.collect())</span><br><span class="line">　&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>　　不知道是偶然还是故意的，API都长得很像，这样很方便开发者从一个引擎切换到另外一个引擎。我感觉以后这种Collection API会成为写data pipeline的标配。</p>
<h3 id="5、Steaming"><a href="#5、Steaming" class="headerlink" title="5、Steaming"></a>5、Steaming</h3><p>　　Spark把streaming看成是更快的批处理，而Flink把批处理看成streaming的special case。这里面的思路决定了各自的方向，其中两者的差异点有如下这些：</p>
<p><strong>实时 vs 近实时的角度</strong></p>
<p>　　Flink提供了基于每个事件的流式处理机制，所以可以被认为是一个真正的流式计算。它非常像storm的model。而Spark，不是基于事件的粒度，而是用小批量来模拟流式，也就是多个事件的集合。所以Spark被认为是近实时的处理系统。</p>
<p>　　Spark streaming 是更快的批处理，而Flink Batch是有限数据的流式计算。虽然大部分应用对准实时是可以接受的，但是也还是有很多应用需要event level的流式计算。这些应用更愿意选择storm而非Spark streaming，现在，Flink也许是一个更好的选择。</p>
<p><strong>流式计算和批处理计算的表示</strong></p>
<p>　　Spark对于批处理和流式计算，都是用的相同的抽象：RDD，这样很方便这两种计算合并起来表示。而Flink这两者分为了DataSet和DataStream，相比Spark，这个设计算是一个糟糕的设计。</p>
<p><strong>对 windowing 的支持</strong></p>
<p>　　因为Spark的小批量机制，Spark对于windowing的支持非常有限。只能基于process time，且只能对batches来做window。而Flink对window的支持非常到位，且Flink对windowing API的支持是相当给力的，允许基于process time,data time,record 来做windowing。我不太确定Spark是否能引入这些API，不过到目前为止，Flink的windowing支持是要比Spark好的。Steaming这部分Flink胜</p>
<table>
<thead>
<tr>
<th>Window 类型</th>
<th>Window 含义</th>
<th>Flink Streaming</th>
<th>SparkStreaming</th>
<th>Structed Streaming</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>tumblingWindow</td>
<td>一个滚动的window</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>Sliding window</td>
<td>滑动的window</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>Global window</td>
<td>全局window</td>
<td>支持</td>
<td>间接实现</td>
<td>间接支持</td>
<td>间接支持的含义是可以时间类似功能，但没有抽象出该window</td>
</tr>
<tr>
<td>Session window</td>
<td>以接收到数据开始，一定时间没有接收到数据，则结束</td>
<td>支持</td>
<td>不支持</td>
<td>不支持</td>
<td></td>
</tr>
</tbody></table>
<p><strong>流join分析：</strong></p>
<p>由于Spark streaming中不支持event time的概念，其只能支持window不同Dstream的RDD的join，不同window间无法join</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>event-time</th>
<th>流join</th>
<th>join实现方式</th>
<th>处理方式</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Spark streaming</td>
<td>不支持</td>
<td>支持</td>
<td>window内</td>
<td>processingTime</td>
<td>micro-batch处理</td>
</tr>
<tr>
<td>FLink1.5之前</td>
<td>支持</td>
<td>支持</td>
<td>window内</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime ／ element Number</td>
</tr>
<tr>
<td>FLink1.6之后</td>
<td>支持</td>
<td>支持</td>
<td>window内，跨window</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime ／ element Number</td>
</tr>
<tr>
<td>Structed Streaming 2.2</td>
<td>支持</td>
<td>不支持</td>
<td>仅支持流数据和静态数据的join</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime</td>
</tr>
<tr>
<td>Structed Streaming 2.3+</td>
<td>支持</td>
<td>支持</td>
<td>跨window</td>
<td>native处理，join时（proocessingTime（interval）触发）</td>
<td>Processing Time／ EventTime</td>
</tr>
</tbody></table>
<p>PS:</p>
<ul>
<li>Flink／structed streaming开发难度相当，FLink略复杂，但灵活度更高</li>
<li>Flink的inteval join</li>
<li>Structed Streaming支持数据去重（同个imsi的数据的多个不同join结果的去重）</li>
<li>FLink的窗口操作相当于structed streaming的update模式</li>
<li>Flink的单流的watermark更新时实时的，有专门线程处理</li>
<li>Structed streaming的watermark更新时间基于批的，每个批次共用同一个watermark，如果有多个流，多个流共用一个watermark</li>
<li>structed Streaming的watermark更新方法：<br> 基于每个流找出该流的watermark：Max_event_time - lateness<br> 找出所有流中最小/最大的watermark设置为batch的watermark</li>
<li>Flink专门抽象了类以便不同场景下使用自定义的eventTime的waterMark获取/设置方法,且提供了一般场景下的的类以便使用</li>
<li>Flink抽象了trigger和evictor来实现触发计算和清理数据的逻辑，以便自定义相关逻辑</li>
<li>FLink 支持sideoutput输出，如迟到的数据可以单独输出</li>
</ul>
<h3 id="6、SQL-interface"><a href="#6、SQL-interface" class="headerlink" title="6、SQL interface"></a>6、SQL interface</h3><p>　　目前Spark-sql是Spark里面最活跃的组件之一，Spark提供了类似Hive的sql和Dataframe这种DSL来查询结构化数据，API很成熟，在流式计算中使用很广，预计在流式计算中也会发展得很快。至于Flink，到目前为止，Flink Table API只支持类似DataFrame这种DSL，并且还是处于beta状态，社区有计划增加SQL 的interface，但是目前还不确定什么时候才能在框架中用上。所以这个部分，Spark胜出。目前Flink已经支持SQL API</p>
<h3 id="7、外部数据源的整合"><a href="#7、外部数据源的整合" class="headerlink" title="7、外部数据源的整合"></a>7、外部数据源的整合</h3><p>　　Spark的数据源 API是整个框架中最好的，支持的数据源包括NoSql db,parquet,ORC等，并且支持一些高级的操作，例如predicate push down。Flink目前还依赖map/reduce InputFormat来做数据源聚合。这一场Spark胜，目前已经提供 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">env.readTextFile(path_i)</span><br><span class="line">env.writeTextFile(path_i)</span><br></pre></td></tr></table></figure>


<h3 id="8、Iterative-processing"><a href="#8、Iterative-processing" class="headerlink" title="8、Iterative processing"></a>8、Iterative processing</h3><p>![Flink 迭代处理](_v_images/20190723102241286_1833770582.png =519x)<br>![Spark迭代处理](_v_images/20190723102318593_811318029.png =519x)<br>　　Spark对机器学习的支持较好，因为利用内存cache来加速机器学习算法。然而大部分机器学习算法其实是一个有环的数据流，但是在Spark中，实际是用无环图来表示的，一般的分布式处理引擎都是不鼓励试用有环图的。但是Flink这里又有点不一样，Flink支持在runtime中的有环数据流，这样表示机器学习算法更有效而且更有效率。这一点Flink胜出。</p>
<h3 id="9、Stream-as-platform-vs-Batch-as-Platform"><a href="#9、Stream-as-platform-vs-Batch-as-Platform" class="headerlink" title="9、Stream as platform vs Batch as Platform"></a>9、Stream as platform vs Batch as Platform</h3><ul>
<li><p>Spark诞生在Map/Reduce的时代，数据都是以文件的形式保存在磁盘中，这样非常方便做容错处理。</p>
</li>
<li><p>Flink把纯流式数据计算引入大数据时代，无疑给业界带来了一股清新的空气。这个idea非常类似akka-streams这种。</p>
</li>
</ul>
<p>【参考文献】</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://www.iteblog.com/archives/1624.html">Apache Flink vs Apache Spark</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/da1910535f73">Flink vs Spark</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/%E8%BF%BD%E6%BA%90%E7%B4%A2%E9%AA%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/%E8%BF%BD%E6%BA%90%E7%B4%A2%E9%AA%A5/" class="post-title-link" itemprop="url">【转载】Flink追源索骥</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="追源索骥：透过源码看懂Flink核心框架的执行流程"><a href="#追源索骥：透过源码看懂Flink核心框架的执行流程" class="headerlink" title="追源索骥：透过源码看懂Flink核心框架的执行流程"></a>追源索骥：透过源码看懂Flink核心框架的执行流程</h1><p>标签（空格分隔）： flink</p>
<hr>
<p>[TOC]</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Flink是大数据处理领域最近很火的一个开源的分布式、高性能的流式处理框架，其对数据的处理可以达到毫秒级别。本文以一个来自官网的WordCount例子为引，全面阐述flink的核心架构及执行流程，希望读者可以借此更加深入的理解Flink逻辑。</p>
<blockquote>
<p>本文跳过了一些基本概念，如果对相关概念感到迷惑，请参考官网文档。另外在本文写作过程中，Flink正式发布了其1.5 RELEASE版本，在其发布之后完成的内容将按照1.5的实现来组织。</p>
</blockquote>
<h2 id="1-从-Hello-World-WordCount开始"><a href="#1-从-Hello-World-WordCount开始" class="headerlink" title="1.从 Hello,World WordCount开始"></a>1.从 <del>Hello,World</del> WordCount开始</h2><p>首先，我们把WordCount的例子再放一遍：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SocketTextStreamWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (args.length != <span class="number">2</span>)&#123;</span><br><span class="line">		System.err.println(<span class="string">&quot;USAGE:\nSocketTextStreamWordCount &lt;hostname&gt; &lt;port&gt;&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	String hostName = args[<span class="number">0</span>];</span><br><span class="line">	Integer port = Integer.parseInt(args[<span class="number">1</span>]);</span><br><span class="line">	<span class="comment">// set up the execution environment</span></span><br><span class="line">	<span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment</span><br><span class="line">			.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// get input data</span></span><br><span class="line">	DataStream&lt;String&gt; text = env.socketTextStream(hostName, port);</span><br><span class="line">	</span><br><span class="line">	text.flatMap(<span class="keyword">new</span> LineSplitter()).setParallelism(<span class="number">1</span>)</span><br><span class="line">	<span class="comment">// group by the tuple field &quot;0&quot; and sum up tuple field &quot;1&quot;</span></span><br><span class="line">			.keyBy(<span class="number">0</span>)</span><br><span class="line">			.sum(<span class="number">1</span>).setParallelism(<span class="number">1</span>)</span><br><span class="line">			.print();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// execute program</span></span><br><span class="line">	env.execute(<span class="string">&quot;Java WordCount from SocketTextStream Example&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Implements the string tokenizer that splits sentences into words as a user-defined</span></span><br><span class="line"><span class="comment">	 * FlatMapFunction. The function takes a line (String) and splits it into</span></span><br><span class="line"><span class="comment">	 * multiple pairs in the form of &quot;(word,1)&quot; (Tuple2&amp;lt;String, Integer&amp;gt;).</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">LineSplitter</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">			<span class="comment">// normalize and split the line</span></span><br><span class="line">			String[] tokens = value.toLowerCase().split(<span class="string">&quot;\\W+&quot;</span>);</span><br><span class="line">			<span class="comment">// emit the pairs</span></span><br><span class="line">			<span class="keyword">for</span> (String token : tokens) &#123;</span><br><span class="line">				<span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">					out.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(token, <span class="number">1</span>));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>首先从命令行中获取socket对端的ip和端口，然后启动一个执行环境，从socket中读取数据，split成单个单词的流，并按单词进行总和的计数，最后打印出来。这个例子相信接触过大数据计算或者函数式编程的人都能看懂，就不过多解释了。</p>
<h3 id="1-1-flink执行环境"><a href="#1-1-flink执行环境" class="headerlink" title="1.1 flink执行环境"></a>1.1 flink执行环境</h3><p>程序的启动，从这句开始：<code> final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()</code>。<br>这行代码会返回一个可用的执行环境。执行环境是整个flink程序执行的上下文，记录了相关配置（如并行度等），并提供了一系列方法，如读取输入流的方法，以及真正开始运行整个代码的execute方法等。对于分布式流处理程序来说，我们在代码中定义的flatMap,keyBy等等操作，事实上可以理解为一种声明，告诉整个程序我们采用了什么样的算子，而真正开启计算的代码不在此处。由于我们是在本地运行flink程序，因此这行代码会返回一个LocalStreamEnvironment，最后我们要调用它的execute方法来开启真正的任务。我们先接着往下看。</p>
<h3 id="1-2-算子（Operator）的注册（声明）"><a href="#1-2-算子（Operator）的注册（声明）" class="headerlink" title="1.2 算子（Operator）的注册（声明）"></a>1.2 算子（Operator）的注册（声明）</h3><p>我们以flatMap为例,<code>text.flatMap(new LineSplitter())</code>这一句话跟踪进去是这样的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">flatMap</span><span class="params">(FlatMapFunction&lt;T, R&gt; flatMapper)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">		TypeInformation&lt;R&gt; outType = TypeExtractor.getFlatMapReturnTypes(clean(flatMapper),</span><br><span class="line">				getType(), Utils.getCallLocationName(), <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> transform(<span class="string">&quot;Flat Map&quot;</span>, outType, <span class="keyword">new</span> StreamFlatMap&lt;&gt;(clean(flatMapper)));</span><br><span class="line"></span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>里面完成了两件事，一是用反射拿到了flatMap算子的输出类型，二是生成了一个Operator。flink流式计算的核心概念，就是将数据从输入流一个个传递给Operator进行链式处理，最后交给输出流的过程。对数据的每一次处理在逻辑上成为一个operator，并且为了本地化处理的效率起见，operator之间也可以串成一个chain一起处理（可以参考责任链模式帮助理解）。下面这张图表明了flink是如何看待用户的处理流程的：抽象化为一系列operator，以source开始，以sink结尾，中间的operator做的操作叫做transform，并且可以把几个操作串在一起执行。<br><img src="http://static.zybuluo.com/bethunebtj/jal2x1y6zqs4jug4ryqnvu3l/image_1cae39t06eoo3ml1be8o0412c69.png" alt="image_1cae39t06eoo3ml1be8o0412c69.png-43.5kB"><br>我们也可以更改flink的设置，要求它不要对某个操作进行chain处理，或者从某个操作开启一个新chain等。<br>上面代码中的最后一行transform方法的作用是返回一个SingleOutputStreamOperator，它继承了Datastream类并且定义了一些辅助方法，方便对流的操作。在返回之前，transform方法还把它注册到了执行环境中（后面生成执行图的时候还会用到它）。其他的操作，包括keyBy，sum和print，都只是不同的算子，在这里出现都是一样的效果，即生成一个operator并注册给执行环境用于生成DAG。</p>
<h3 id="1-3-程序的执行"><a href="#1-3-程序的执行" class="headerlink" title="1.3 程序的执行"></a>1.3 程序的执行</h3><p>程序执行即<code>env.execute(&quot;Java WordCount from SocketTextStream Example&quot;)</code>这行代码。</p>
<h4 id="1-3-1-本地模式下的execute方法"><a href="#1-3-1-本地模式下的execute方法" class="headerlink" title="1.3.1 本地模式下的execute方法"></a>1.3.1 本地模式下的execute方法</h4><p>这行代码主要做了以下事情：</p>
<ul>
<li>生成StreamGraph。代表程序的拓扑结构，是从用户代码直接生成的图。</li>
<li>生成JobGraph。这个图是要交给flink去生成task的图。</li>
<li>生成一系列配置</li>
<li>将JobGraph和配置交给flink集群去运行。如果不是本地运行的话，还会把jar文件通过网络发给其他节点。</li>
<li>以本地模式运行的话，可以看到启动过程，如启动性能度量、web模块、JobManager、ResourceManager、taskManager等等</li>
<li>启动任务。值得一提的是在启动任务之前，先启动了一个用户类加载器，这个类加载器可以用来做一些在运行时动态加载类的工作。</li>
</ul>
<h4 id="1-3-2-远程模式（RemoteEnvironment）的execute方法"><a href="#1-3-2-远程模式（RemoteEnvironment）的execute方法" class="headerlink" title="1.3.2 远程模式（RemoteEnvironment）的execute方法"></a>1.3.2 远程模式（RemoteEnvironment）的execute方法</h4><p>远程模式的程序执行更加有趣一点。第一步仍然是获取StreamGraph，然后调用executeRemotely方法进行远程执行。<br>该方法首先创建一个用户代码加载器</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ClassLoader usercodeClassLoader = JobWithJars.buildUserCodeClassLoader(jarFiles, globalClasspaths,   getClass().getClassLoader());</span><br></pre></td></tr></table></figure>
<p>然后创建一系列配置，交给Client对象。Client这个词有意思，看见它就知道这里绝对是跟远程集群打交道的客户端。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ClusterClient client;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	client = <span class="keyword">new</span> StandaloneClusterClient(configuration);</span><br><span class="line">	client.setPrintStatusDuringExecution(getConfig().isSysoutLoggingEnabled());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> client.run(streamGraph, jarFiles, globalClasspaths, usercodeClassLoader).getJobExecutionResult();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>client的run方法首先生成一个JobGraph，然后将其传递给JobClient。关于Client、JobClient、JobManager到底谁管谁，可以看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/6hhl3e1fumlr0aq78d2m35nt/image_1cae7g15p6k94no1ves121c5pd9.png" alt="image_1cae7g15p6k94no1ves121c5pd9.png-19.7kB"><br>确切的说，JobClient负责以异步的方式和JobManager通信（Actor是scala的异步模块），具体的通信任务由JobClientActor完成。相对应的，JobManager的通信任务也由一个Actor完成。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JobListeningContext jobListeningContext = submitJob(actorSystem, config, highAvailabilityServices, jobGraph, timeout, sysoutLogUpdates,	classLoader);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> awaitJobResult(jobListeningContext);</span><br></pre></td></tr></table></figure>
<p>可以看到，该方法阻塞在awaitJobResult方法上，并最终返回了一个JobListeningContext，透过这个Context可以得到程序运行的状态和结果。</p>
<h4 id="1-3-3-程序启动过程"><a href="#1-3-3-程序启动过程" class="headerlink" title="1.3.3 程序启动过程"></a>1.3.3 程序启动过程</h4><p>上面提到，整个程序真正意义上开始执行，是这里：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.execute(<span class="string">&quot;Java WordCount from SocketTextStream Example&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>远程模式和本地模式有一点不同，我们先按本地模式来调试。<br>我们跟进源码，（在本地调试模式下）会启动一个miniCluster，然后开始执行代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LocalStreamEnvironment.java</span></span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">execute</span><span class="params">(String jobName)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//生成各种图结构</span></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">		    <span class="comment">//启动集群，包括启动JobMaster，进行leader选举等等</span></span><br><span class="line">			miniCluster.start();</span><br><span class="line">			configuration.setInteger(RestOptions.PORT, miniCluster.getRestAddress().getPort());</span><br><span class="line">            </span><br><span class="line">            <span class="comment">//提交任务到JobMaster</span></span><br><span class="line">			<span class="keyword">return</span> miniCluster.executeJobBlocking(jobGraph);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">finally</span> &#123;</span><br><span class="line">			transformations.clear();</span><br><span class="line">			miniCluster.close();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>这个方法里有一部分逻辑是与生成图结构相关的，我们放在第二章里讲；现在我们先接着往里跟：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//MiniCluster.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">executeJobBlocking</span><span class="params">(JobGraph job)</span> <span class="keyword">throws</span> JobExecutionException, InterruptedException </span>&#123;</span><br><span class="line">		checkNotNull(job, <span class="string">&quot;job is null&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//在这里，最终把job提交给了jobMaster</span></span><br><span class="line">		<span class="keyword">final</span> CompletableFuture&lt;JobSubmissionResult&gt; submissionFuture = submitJob(job);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">final</span> CompletableFuture&lt;JobResult&gt; jobResultFuture = submissionFuture.thenCompose(</span><br><span class="line">			(JobSubmissionResult ignored) -&gt; requestJobResult(job.getJobID()));</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>正如我在注释里写的，这一段代码核心逻辑就是调用那个<code>submitJob</code>方法。那么我们再接着看这个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;JobSubmissionResult&gt; <span class="title">submitJob</span><span class="params">(JobGraph jobGraph)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">final</span> DispatcherGateway dispatcherGateway;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		dispatcherGateway = getDispatcherGateway();</span><br><span class="line">	&#125; <span class="keyword">catch</span> (LeaderRetrievalException | InterruptedException e) &#123;</span><br><span class="line">		ExceptionUtils.checkInterrupted(e);</span><br><span class="line">		<span class="keyword">return</span> FutureUtils.completedExceptionally(e);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// we have to allow queued scheduling in Flip-6 mode because we need to request slots</span></span><br><span class="line">	<span class="comment">// from the ResourceManager</span></span><br><span class="line">	jobGraph.setAllowQueuedScheduling(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Void&gt; jarUploadFuture = uploadAndSetJarFiles(dispatcherGateway, jobGraph);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; acknowledgeCompletableFuture = jarUploadFuture.thenCompose(</span><br><span class="line">	</span><br><span class="line">	<span class="comment">//在这里执行了真正的submit操作</span></span><br><span class="line">		(Void ack) -&gt; dispatcherGateway.submitJob(jobGraph, rpcTimeout));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> acknowledgeCompletableFuture.thenApply(</span><br><span class="line">		(Acknowledge ignored) -&gt; <span class="keyword">new</span> JobSubmissionResult(jobGraph.getJobID()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的<code>Dispatcher</code>是一个接收job，然后指派JobMaster去启动任务的类,我们可以看看它的类结构，有两个实现。在本地环境下启动的是<code>MiniDispatcher</code>，在集群上提交任务时，集群上启动的是<code>StandaloneDispatcher</code>。</p>
<p><img src="http://static.zybuluo.com/bethunebtj/y9hjeinc58dqc7wiepv2iim4/image_1cenfj3p9fp110p0a8unn1mrh9.png" alt="image_1cenfj3p9fp110p0a8unn1mrh9.png-27.4kB"></p>
<p>那么这个Dispatcher又做了什么呢？它启动了一个<code>JobManagerRunner</code>（这里我要吐槽Flink的命名，这个东西应该叫做JobMasterRunner才对，flink里的JobMaster和JobManager不是一个东西），委托JobManagerRunner去启动该Job的<code>JobMaster</code>。我们看一下对应的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//jobManagerRunner.java</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">verifyJobSchedulingStatusAndStartJobManager</span><span class="params">(UUID leaderSessionId)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">	    <span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; startFuture = jobMaster.start(<span class="keyword">new</span> JobMasterId(leaderSessionId), rpcTimeout);</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>然后，JobMaster经过了一堆方法嵌套之后，执行到了这里：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">scheduleExecutionGraph</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	checkState(jobStatusListener == <span class="keyword">null</span>);</span><br><span class="line">	<span class="comment">// register self as job status change listener</span></span><br><span class="line">	jobStatusListener = <span class="keyword">new</span> JobManagerJobStatusListener();</span><br><span class="line">	executionGraph.registerJobStatusListener(jobStatusListener);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">	    <span class="comment">//这里调用了ExecutionGraph的启动方法</span></span><br><span class="line">		executionGraph.scheduleForExecution();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">		executionGraph.failGlobal(t);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们知道，flink的框架里有三层图结构，其中ExecutionGraph就是真正被执行的那一层，所以到这里为止，一个任务从提交到真正执行的流程就走完了，我们再回顾一下（顺便提一下远程提交时的流程区别）：</p>
<ul>
<li>客户端代码的execute方法执行；</li>
<li>本地环境下，MiniCluster完成了大部分任务，直接把任务委派给了MiniDispatcher；</li>
<li>远程环境下，启动了一个<code>RestClusterClient</code>，这个类会以HTTP Rest的方式把用户代码提交到集群上；</li>
<li>远程环境下，请求发到集群上之后，必然有个handler去处理，在这里是<code>JobSubmitHandler</code>。这个类接手了请求后，委派StandaloneDispatcher启动job，到这里之后，本地提交和远程提交的逻辑往后又统一了；</li>
<li>Dispatcher接手job之后，会实例化一个<code>JobManagerRunner</code>，然后用这个runner启动job；</li>
<li>JobManagerRunner接下来把job交给了<code>JobMaster</code>去处理；</li>
<li>JobMaster使用<code>ExecutionGraph</code>的方法启动了整个执行图；整个任务就启动起来了。</li>
</ul>
<p>至此，第一部分就讲完了。</p>
<h2 id="2-理解flink的图结构"><a href="#2-理解flink的图结构" class="headerlink" title="2.理解flink的图结构"></a>2.理解flink的图结构</h2><p>第一部分讲到，我们的主函数最后一项任务就是生成StreamGraph，然后生成JobGraph，然后以此开始调度任务运行，所以接下来我们从这里入手，继续探索flink。</p>
<h3 id="2-1-flink的三层图结构"><a href="#2-1-flink的三层图结构" class="headerlink" title="2.1 flink的三层图结构"></a>2.1 flink的三层图结构</h3><p>事实上，flink总共提供了三种图的抽象，我们前面已经提到了StreamGraph和JobGraph，还有一种是ExecutionGraph，是用于调度的基本数据结构。<br><img src="http://static.zybuluo.com/bethunebtj/nseitc0kyuq0n44s7qcp6ij9/image_1caf1oll019fp1odv1bh9idosr79.png" alt="image_1caf1oll019fp1odv1bh9idosr79.png-486.3kB"><br>上面这张图清晰的给出了flink各个图的工作原理和转换过程。其中最后一个物理执行图并非flink的数据结构，而是程序开始执行后，各个task分布在不同的节点上，所形成的物理上的关系表示。</p>
<ul>
<li>从JobGraph的图里可以看到，数据从上一个operator流到下一个operator的过程中，上游作为生产者提供了IntermediateDataSet，而下游作为消费者需要JobEdge。事实上，JobEdge是一个通信管道，连接了上游生产的dataset和下游的JobVertex节点。</li>
<li>在JobGraph转换到ExecutionGraph的过程中，主要发生了以下转变：</li>
<li> 加入了并行度的概念，成为真正可调度的图结构</li>
<li> 生成了与JobVertex对应的ExecutionJobVertex，ExecutionVertex，与IntermediateDataSet对应的IntermediateResult和IntermediateResultPartition等，并行将通过这些类实现</li>
<li>ExecutionGraph已经可以用于调度任务。我们可以看到，flink根据该图生成了一一对应的Task，每个task对应一个ExecutionGraph的一个Execution。Task用InputGate、InputChannel和ResultPartition对应了上面图中的IntermediateResult和ExecutionEdge。</li>
</ul>
<p>那么，flink抽象出这三层图结构，四层执行逻辑的意义是什么呢？<br>StreamGraph是对用户逻辑的映射。JobGraph在此基础上进行了一些优化，比如把一部分操作串成chain以提高效率。ExecutionGraph是为了调度存在的，加入了并行处理的概念。而在此基础上真正执行的是Task及其相关结构。</p>
<h3 id="2-2-StreamGraph的生成"><a href="#2-2-StreamGraph的生成" class="headerlink" title="2.2 StreamGraph的生成"></a>2.2 StreamGraph的生成</h3><p>在第一节的算子注册部分，我们可以看到，flink把每一个算子transform成一个对流的转换（比如上文中返回的SingleOutputStreamOperator是一个DataStream的子类），并且注册到执行环境中，用于生成StreamGraph。实际生成StreamGraph的入口是<code>StreamGraphGenerator.generate(env, transformations)</code> 其中的transformations是一个list，里面记录的就是我们在transform方法中放进来的算子。</p>
<h4 id="2-2-1-StreamTransformation类代表了流的转换"><a href="#2-2-1-StreamTransformation类代表了流的转换" class="headerlink" title="2.2.1 StreamTransformation类代表了流的转换"></a>2.2.1 StreamTransformation类代表了流的转换</h4><p>StreamTransformation代表了从一个或多个DataStream生成新DataStream的操作。顺便，DataStream类在内部组合了一个StreamTransformation类，实际的转换操作均通过该类完成。<br><img src="http://static.zybuluo.com/bethunebtj/69v9syr2p5k5om3c4jox9wh0/image_1caf64b7c1gjnv2eebi1v9e1cvum.png" alt="image_1caf64b7c1gjnv2eebi1v9e1cvum.png-129.4kB"><br>我们可以看到，从source到各种map,union再到sink操作全部被映射成了StreamTransformation。<br>其映射过程如下所示：<br><img src="http://static.zybuluo.com/bethunebtj/a8sjspg8agzl3utnncntds9q/image_1caf6ak4rkqsc1u1hci93fe0d13.png" alt="image_1caf6ak4rkqsc1u1hci93fe0d13.png-36.6kB"></p>
<p>以MapFunction为例：</p>
<ul>
<li><p>首先，用户代码里定义的UDF会被当作其基类对待，然后交给StreamMap这个operator做进一步包装。事实上，每一个Transformation都对应了一个StreamOperator。</p>
</li>
<li><p>由于map这个操作只接受一个输入，所以再被进一步包装为OneInputTransformation。</p>
</li>
<li><p>最后，将该transformation注册到执行环境中，当执行上文提到的generate方法时，生成StreamGraph图结构。</p>
<blockquote>
<p>另外，并不是每一个 StreamTransformation 都会转换成runtime层中的物理操作。有一些只是逻辑概念，比如union、split/select、partition等。如下图所示的转换树，在运行时会优化成下方的操作图。<br><img src="http://static.zybuluo.com/bethunebtj/6zmlsivd9cjdm5nhsacuk3o1/image_1caf71h79s0s3fodem1aeb1j3m1g.png" alt="image_1caf71h79s0s3fodem1aeb1j3m1g.png-83.8kB"></p>
</blockquote>
</li>
</ul>
<h4 id="2-2-2-StreamGraph生成函数分析"><a href="#2-2-2-StreamGraph生成函数分析" class="headerlink" title="2.2.2 StreamGraph生成函数分析"></a>2.2.2 StreamGraph生成函数分析</h4><p>我们从StreamGraphGenerator.generate()方法往下看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">public static StreamGraph generate(StreamExecutionEnvironment env, List&lt;StreamTransformation&lt;?&gt;&gt; transformations) &#123;</span><br><span class="line">	return new StreamGraphGenerator(env).generateInternal(transformations);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">   &#x2F;&#x2F;注意，StreamGraph的生成是从sink开始的</span><br><span class="line">private StreamGraph generateInternal(List&lt;StreamTransformation&lt;?&gt;&gt; transformations) &#123;</span><br><span class="line">	for (StreamTransformation&lt;?&gt; transformation: transformations) &#123;</span><br><span class="line">		transform(transformation);</span><br><span class="line">	&#125;</span><br><span class="line">	return streamGraph;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;这个方法的核心逻辑就是判断传入的steamOperator是哪种类型，并执行相应的操作，详情见下面那一大堆if-else</span><br><span class="line">private Collection&lt;Integer&gt; transform(StreamTransformation&lt;?&gt; transform) &#123;</span><br><span class="line"></span><br><span class="line">	if (alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">		return alreadyTransformed.get(transform);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	LOG.debug(&quot;Transforming &quot; + transform);</span><br><span class="line"></span><br><span class="line">	if (transform.getMaxParallelism() &lt;&#x3D; 0) &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; if the max parallelism hasn&#39;t been set, then first use the job wide max parallelism</span><br><span class="line">		&#x2F;&#x2F; from theExecutionConfig.</span><br><span class="line">		int globalMaxParallelismFromConfig &#x3D; env.getConfig().getMaxParallelism();</span><br><span class="line">		if (globalMaxParallelismFromConfig &gt; 0) &#123;</span><br><span class="line">			transform.setMaxParallelism(globalMaxParallelismFromConfig);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; call at least once to trigger exceptions about MissingTypeInfo</span><br><span class="line">	transform.getOutputType();</span><br><span class="line"></span><br><span class="line">	Collection&lt;Integer&gt; transformedIds;</span><br><span class="line">	&#x2F;&#x2F;这里对操作符的类型进行判断，并以此调用相应的处理逻辑.简而言之，处理的核心无非是递归的将该节点和节点的上游节点加入图</span><br><span class="line">	if (transform instanceof OneInputTransformation&lt;?, ?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformOneInputTransform((OneInputTransformation&lt;?, ?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof TwoInputTransformation&lt;?, ?, ?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformTwoInputTransform((TwoInputTransformation&lt;?, ?, ?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SourceTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSource((SourceTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SinkTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSink((SinkTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof UnionTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformUnion((UnionTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SplitTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSplit((SplitTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SelectTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSelect((SelectTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof FeedbackTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformFeedback((FeedbackTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof CoFeedbackTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformCoFeedback((CoFeedbackTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof PartitionTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformPartition((PartitionTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SideOutputTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSideOutput((SideOutputTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		throw new IllegalStateException(&quot;Unknown transformation: &quot; + transform);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F;注意这里和函数开始时的方法相对应，在有向图中要注意避免循环的产生</span><br><span class="line">	&#x2F;&#x2F; need this check because the iterate transformation adds itself before</span><br><span class="line">	&#x2F;&#x2F; transforming the feedback edges</span><br><span class="line">	if (!alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">		alreadyTransformed.put(transform, transformedIds);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (transform.getBufferTimeout() &gt; 0) &#123;</span><br><span class="line">		streamGraph.setBufferTimeout(transform.getId(), transform.getBufferTimeout());</span><br><span class="line">	&#125;</span><br><span class="line">	if (transform.getUid() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setTransformationUID(transform.getId(), transform.getUid());</span><br><span class="line">	&#125;</span><br><span class="line">	if (transform.getUserProvidedNodeHash() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setTransformationUserHash(transform.getId(), transform.getUserProvidedNodeHash());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (transform.getMinResources() !&#x3D; null &amp;&amp; transform.getPreferredResources() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setResources(transform.getId(), transform.getMinResources(), transform.getPreferredResources());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return transformedIds;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为map，filter等常用操作都是OneInputStreamOperator,我们就来看看<code>transformOneInputTransform((OneInputTransformation&lt;?, ?&gt;) transform)</code>方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line">private &lt;IN, OUT&gt; Collection&lt;Integer&gt; transformOneInputTransform(OneInputTransformation&lt;IN, OUT&gt; transform) &#123;</span><br><span class="line"></span><br><span class="line">		Collection&lt;Integer&gt; inputIds &#x3D; transform(transform.getInput());</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 在递归处理节点过程中，某个节点可能已经被其他子节点先处理过了，需要跳过</span><br><span class="line">		if (alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">			return alreadyTransformed.get(transform);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;这里是获取slotSharingGroup。这个group用来定义当前我们在处理的这个操作符可以跟什么操作符chain到一个slot里进行操作</span><br><span class="line">        &#x2F;&#x2F;因为有时候我们可能不满意flink替我们做的chain聚合</span><br><span class="line">        &#x2F;&#x2F;一个slot就是一个执行task的基本容器</span><br><span class="line">		String slotSharingGroup &#x3D; determineSlotSharingGroup(transform.getSlotSharingGroup(), inputIds);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;把该operator加入图</span><br><span class="line">		streamGraph.addOperator(transform.getId(),</span><br><span class="line">				slotSharingGroup,</span><br><span class="line">				transform.getOperator(),</span><br><span class="line">				transform.getInputType(),</span><br><span class="line">				transform.getOutputType(),</span><br><span class="line">				transform.getName());</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F;对于keyedStream，我们还要记录它的keySelector方法</span><br><span class="line">        &#x2F;&#x2F;flink并不真正为每个keyedStream保存一个key，而是每次需要用到key的时候都使用keySelector方法进行计算</span><br><span class="line">        &#x2F;&#x2F;因此，我们自定义的keySelector方法需要保证幂等性</span><br><span class="line">        &#x2F;&#x2F;到后面介绍keyGroup的时候我们还会再次提到这一点</span><br><span class="line">		if (transform.getStateKeySelector() !&#x3D; null) &#123;</span><br><span class="line">			TypeSerializer&lt;?&gt; keySerializer &#x3D; transform.getStateKeyType().createSerializer(env.getConfig());</span><br><span class="line">			streamGraph.setOneInputStateKey(transform.getId(), transform.getStateKeySelector(), keySerializer);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		streamGraph.setParallelism(transform.getId(), transform.getParallelism());</span><br><span class="line">		streamGraph.setMaxParallelism(transform.getId(), transform.getMaxParallelism());</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F;为当前节点和它的依赖节点建立边</span><br><span class="line">        &#x2F;&#x2F;这里可以看到之前提到的select union partition等逻辑节点被合并入edge的过程</span><br><span class="line">		for (Integer inputId: inputIds) &#123;</span><br><span class="line">			streamGraph.addEdge(inputId, transform.getId(), 0);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return Collections.singleton(transform.getId());</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	public void addEdge(Integer upStreamVertexID, Integer downStreamVertexID, int typeNumber) &#123;</span><br><span class="line">		addEdgeInternal(upStreamVertexID,</span><br><span class="line">				downStreamVertexID,</span><br><span class="line">				typeNumber,</span><br><span class="line">				null,</span><br><span class="line">				new ArrayList&lt;String&gt;(),</span><br><span class="line">				null);</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">    &#x2F;&#x2F;addEdge的实现，会合并一些逻辑节点</span><br><span class="line">	private void addEdgeInternal(Integer upStreamVertexID,</span><br><span class="line">			Integer downStreamVertexID,</span><br><span class="line">			int typeNumber,</span><br><span class="line">			StreamPartitioner&lt;?&gt; partitioner,</span><br><span class="line">			List&lt;String&gt; outputNames,</span><br><span class="line">			OutputTag outputTag) &#123;</span><br><span class="line">        &#x2F;&#x2F;如果输入边是侧输出节点，则把side的输入边作为本节点的输入边，并递归调用</span><br><span class="line">		if (virtualSideOutputNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualSideOutputNodes.get(virtualId).f0;</span><br><span class="line">			if (outputTag &#x3D;&#x3D; null) &#123;</span><br><span class="line">				outputTag &#x3D; virtualSideOutputNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, null, outputTag);</span><br><span class="line">			&#x2F;&#x2F;如果输入边是select，则把select的输入边作为本节点的输入边</span><br><span class="line">		&#125; else if (virtualSelectNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualSelectNodes.get(virtualId).f0;</span><br><span class="line">			if (outputNames.isEmpty()) &#123;</span><br><span class="line">				&#x2F;&#x2F; selections that happen downstream override earlier selections</span><br><span class="line">				outputNames &#x3D; virtualSelectNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, outputNames, outputTag);</span><br><span class="line">			&#x2F;&#x2F;如果是partition节点</span><br><span class="line">		&#125; else if (virtualPartitionNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualPartitionNodes.get(virtualId).f0;</span><br><span class="line">			if (partitioner &#x3D;&#x3D; null) &#123;</span><br><span class="line">				partitioner &#x3D; virtualPartitionNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, outputNames, outputTag);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">		&#x2F;&#x2F;正常的edge处理逻辑</span><br><span class="line">			StreamNode upstreamNode &#x3D; getStreamNode(upStreamVertexID);</span><br><span class="line">			StreamNode downstreamNode &#x3D; getStreamNode(downStreamVertexID);</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; If no partitioner was specified and the parallelism of upstream and downstream</span><br><span class="line">			&#x2F;&#x2F; operator matches use forward partitioning, use rebalance otherwise.</span><br><span class="line">			if (partitioner &#x3D;&#x3D; null &amp;&amp; upstreamNode.getParallelism() &#x3D;&#x3D; downstreamNode.getParallelism()) &#123;</span><br><span class="line">				partitioner &#x3D; new ForwardPartitioner&lt;Object&gt;();</span><br><span class="line">			&#125; else if (partitioner &#x3D;&#x3D; null) &#123;</span><br><span class="line">				partitioner &#x3D; new RebalancePartitioner&lt;Object&gt;();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (partitioner instanceof ForwardPartitioner) &#123;</span><br><span class="line">				if (upstreamNode.getParallelism() !&#x3D; downstreamNode.getParallelism()) &#123;</span><br><span class="line">					throw new UnsupportedOperationException(&quot;Forward partitioning does not allow &quot; +</span><br><span class="line">							&quot;change of parallelism. Upstream operation: &quot; + upstreamNode + &quot; parallelism: &quot; + upstreamNode.getParallelism() +</span><br><span class="line">							&quot;, downstream operation: &quot; + downstreamNode + &quot; parallelism: &quot; + downstreamNode.getParallelism() +</span><br><span class="line">							&quot; You must use another partitioning strategy, such as broadcast, rebalance, shuffle or global.&quot;);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			StreamEdge edge &#x3D; new StreamEdge(upstreamNode, downstreamNode, typeNumber, outputNames, partitioner, outputTag);</span><br><span class="line"></span><br><span class="line">			getStreamNode(edge.getSourceId()).addOutEdge(edge);</span><br><span class="line">			getStreamNode(edge.getTargetId()).addInEdge(edge);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-2-3-WordCount函数的StreamGraph"><a href="#2-2-3-WordCount函数的StreamGraph" class="headerlink" title="2.2.3 WordCount函数的StreamGraph"></a>2.2.3 WordCount函数的StreamGraph</h4><p>flink提供了一个StreamGraph可视化显示工具，<a target="_blank" rel="noopener" href="http://flink.apache.org/visualizer/">在这里</a><br>我们可以把我们的程序的执行计划打印出来<code>System.out.println(env.getExecutionPlan());</code> 复制到这个网站上，点击生成，如图所示：<br><img src="http://static.zybuluo.com/bethunebtj/sfckex3xgu33m3srk2bc5hgk/image_1cafgsliu1n2n1uj21p971b0h6m71t.png" alt="image_1cafgsliu1n2n1uj21p971b0h6m71t.png-25.7kB"><br>可以看到，我们源程序被转化成了4个operator。<br>另外，在operator之间的连线上也显示出了flink添加的一些逻辑流程。由于我设定了每个操作符的并行度都是1，所以在每个操作符之间都是直接FORWARD，不存在shuffle的过程。</p>
<h3 id="2-3-JobGraph的生成"><a href="#2-3-JobGraph的生成" class="headerlink" title="2.3 JobGraph的生成"></a>2.3 JobGraph的生成</h3><p>flink会根据上一步生成的StreamGraph生成JobGraph，然后将JobGraph发送到server端进行ExecutionGraph的解析。</p>
<h4 id="2-3-1-JobGraph生成源码"><a href="#2-3-1-JobGraph生成源码" class="headerlink" title="2.3.1 JobGraph生成源码"></a>2.3.1 JobGraph生成源码</h4><p>与StreamGraph类似，JobGraph的入口方法是<code>StreamingJobGraphGenerator.createJobGraph()</code>。我们直接来看源码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">private JobGraph createJobGraph() &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 设置启动模式为所有节点均在一开始就启动</span><br><span class="line">		jobGraph.setScheduleMode(ScheduleMode.EAGER);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 为每个节点生成hash id</span><br><span class="line">		Map&lt;Integer, byte[]&gt; hashes &#x3D; defaultStreamGraphHasher.traverseStreamGraphAndGenerateHashes(streamGraph);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 为了保持兼容性创建的hash</span><br><span class="line">		List&lt;Map&lt;Integer, byte[]&gt;&gt; legacyHashes &#x3D; new ArrayList&lt;&gt;(legacyStreamGraphHashers.size());</span><br><span class="line">		for (StreamGraphHasher hasher : legacyStreamGraphHashers) &#123;</span><br><span class="line">			legacyHashes.add(hasher.traverseStreamGraphAndGenerateHashes(streamGraph));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		Map&lt;Integer, List&lt;Tuple2&lt;byte[], byte[]&gt;&gt;&gt; chainedOperatorHashes &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        &#x2F;&#x2F;生成jobvertex，串成chain等</span><br><span class="line">        &#x2F;&#x2F;这里的逻辑大致可以理解为，挨个遍历节点，如果该节点是一个chain的头节点，就生成一个JobVertex，如果不是头节点，就要把自身配置并入头节点，然后把头节点和自己的出边相连；对于不能chain的节点，当作只有头节点处理即可</span><br><span class="line">		setChaining(hashes, legacyHashes, chainedOperatorHashes);</span><br><span class="line">        &#x2F;&#x2F;设置输入边edge</span><br><span class="line">		setPhysicalEdges();</span><br><span class="line">        &#x2F;&#x2F;设置slot共享group</span><br><span class="line">		setSlotSharing();</span><br><span class="line">        &#x2F;&#x2F;配置检查点</span><br><span class="line">		configureCheckpointing();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 如果有之前的缓存文件的配置的话，重新读入</span><br><span class="line">		for (Tuple2&lt;String, DistributedCache.DistributedCacheEntry&gt; e : streamGraph.getEnvironment().getCachedFiles()) &#123;</span><br><span class="line">			DistributedCache.writeFileInfoToConfig(e.f0, e.f1, jobGraph.getJobConfiguration());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 传递执行环境配置</span><br><span class="line">		try &#123;</span><br><span class="line">			jobGraph.setExecutionConfig(streamGraph.getExecutionConfig());</span><br><span class="line">		&#125;</span><br><span class="line">		catch (IOException e) &#123;</span><br><span class="line">			throw new IllegalConfigurationException(&quot;Could not serialize the ExecutionConfig.&quot; +</span><br><span class="line">					&quot;This indicates that non-serializable types (like custom serializers) were registered&quot;);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return jobGraph;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-3-2-operator-chain的逻辑"><a href="#2-3-2-operator-chain的逻辑" class="headerlink" title="2.3.2 operator chain的逻辑"></a>2.3.2 operator chain的逻辑</h4><blockquote>
<p>为了更高效地分布式执行，Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。将operators链接成task是非常有效的优化：它能减少线程之间的切换，减少消息的序列化/反序列化，减少数据在缓冲区的交换，减少了延迟的同时提高整体的吞吐量。</p>
</blockquote>
<p><img src="http://static.zybuluo.com/bethunebtj/jcjalvv130ex52vkglkt56r2/image_1cafj7s6bittk5tt0bequlig2a.png" alt="image_1cafj7s6bittk5tt0bequlig2a.png-158.7kB"><br>上图中将KeyAggregation和Sink两个operator进行了合并，因为这两个合并后并不会改变整体的拓扑结构。但是，并不是任意两个 operator 就能 chain 一起的,其条件还是很苛刻的：</p>
<blockquote>
<ul>
<li>上下游的并行度一致</li>
<li>下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）</li>
<li>上下游节点都在同一个 slot group 中（下面会解释 slot group）</li>
<li>下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）</li>
<li>上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）</li>
<li>两个节点间数据分区方式是 forward（参考理解数据流的分区）</li>
<li>用户没有禁用 chain</li>
</ul>
</blockquote>
<p>flink的chain逻辑是一种很常见的设计，比如spring的interceptor也是类似的实现方式。通过把操作符串成一个大操作符，flink避免了把数据序列化后通过网络发送给其他节点的开销，能够大大增强效率。</p>
<h4 id="2-3-3-JobGraph的提交"><a href="#2-3-3-JobGraph的提交" class="headerlink" title="2.3.3 JobGraph的提交"></a>2.3.3 JobGraph的提交</h4><p>前面已经提到，JobGraph的提交依赖于JobClient和JobManager之间的异步通信，如图所示：<br><img src="http://static.zybuluo.com/bethunebtj/dj015uuqpnb4ct7810qfilhe/image_1cafn516r1p68kt31g7r196rcsv2n.png" alt="image_1cafn516r1p68kt31g7r196rcsv2n.png-40.1kB"><br>在submitJobAndWait方法中，其首先会创建一个JobClientActor的ActorRef,然后向其发起一个SubmitJobAndWait消息，该消息将JobGraph的实例提交给JobClientActor。发起模式是ask，它表示需要一个应答消息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Future&lt;Object&gt; future &#x3D; Patterns.ask(jobClientActor, new JobClientMessages.SubmitJobAndWait(jobGraph), new Timeout(AkkaUtils.INF_TIMEOUT()));</span><br><span class="line">answer &#x3D; Await.result(future, AkkaUtils.INF_TIMEOUT());</span><br></pre></td></tr></table></figure>
<p>该SubmitJobAndWait消息被JobClientActor接收后，最终通过调用tryToSubmitJob方法触发真正的提交动作。当JobManager的actor接收到来自client端的请求后，会执行一个submitJob方法，主要做以下事情：</p>
<blockquote>
<ul>
<li>向BlobLibraryCacheManager注册该Job；</li>
<li>构建ExecutionGraph对象；</li>
<li>对JobGraph中的每个顶点进行初始化；</li>
<li>将DAG拓扑中从source开始排序，排序后的顶点集合附加到Exec&gt; - utionGraph对象；</li>
<li>获取检查点相关的配置，并将其设置到ExecutionGraph对象；</li>
<li>向ExecutionGraph注册相关的listener；</li>
<li>执行恢复操作或者将JobGraph信息写入SubmittedJobGraphStore以在后续用于恢复目的；</li>
<li>响应给客户端JobSubmitSuccess消息；</li>
<li>对ExecutionGraph对象进行调度执行；</li>
</ul>
</blockquote>
<p>最后，JobManger会返回消息给JobClient，通知该任务是否提交成功。</p>
<h3 id="2-4-ExecutionGraph的生成"><a href="#2-4-ExecutionGraph的生成" class="headerlink" title="2.4 ExecutionGraph的生成"></a>2.4 ExecutionGraph的生成</h3><p>与StreamGraph和JobGraph不同，ExecutionGraph并不是在我们的客户端程序生成，而是在服务端（JobManager处）生成的，顺便flink只维护一个JobManager。其入口代码是<code>ExecutionGraphBuilder.buildGraph（...）</code><br>该方法长200多行，其中一大半是checkpoiont的相关逻辑，我们暂且略过，直接看核心方法<code>executionGraph.attachJobGraph(sortedTopology)</code><br>因为ExecutionGraph事实上只是改动了JobGraph的每个节点，而没有对整个拓扑结构进行变动，所以代码里只是挨个遍历jobVertex并进行处理：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">for (JobVertex jobVertex : topologiallySorted) &#123;</span><br><span class="line"></span><br><span class="line">			if (jobVertex.isInputVertex() &amp;&amp; !jobVertex.isStoppable()) &#123;</span><br><span class="line">				this.isStoppable &#x3D; false;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F;在这里生成ExecutionGraph的每个节点</span><br><span class="line">			&#x2F;&#x2F;首先是进行了一堆赋值，将任务信息交给要生成的图节点，以及设定并行度等等</span><br><span class="line">			&#x2F;&#x2F;然后是创建本节点的IntermediateResult，根据本节点的下游节点的个数确定创建几份</span><br><span class="line">			&#x2F;&#x2F;最后是根据设定好的并行度创建用于执行task的ExecutionVertex</span><br><span class="line">			&#x2F;&#x2F;如果job有设定inputsplit的话，这里还要指定inputsplits</span><br><span class="line">			ExecutionJobVertex ejv &#x3D; new ExecutionJobVertex(</span><br><span class="line">				this,</span><br><span class="line">				jobVertex,</span><br><span class="line">				1,</span><br><span class="line">				rpcCallTimeout,</span><br><span class="line">				globalModVersion,</span><br><span class="line">				createTimestamp);</span><br><span class="line">            </span><br><span class="line">            &#x2F;&#x2F;这里要处理所有的JobEdge</span><br><span class="line">            &#x2F;&#x2F;对每个edge，获取对应的intermediateResult，并记录到本节点的输入上</span><br><span class="line">            &#x2F;&#x2F;最后，把每个ExecutorVertex和对应的IntermediateResult关联起来</span><br><span class="line">			ejv.connectToPredecessors(this.intermediateResults);</span><br><span class="line"></span><br><span class="line">			ExecutionJobVertex previousTask &#x3D; this.tasks.putIfAbsent(jobVertex.getID(), ejv);</span><br><span class="line">			if (previousTask !&#x3D; null) &#123;</span><br><span class="line">				throw new JobException(String.format(&quot;Encountered two job vertices with ID %s : previous&#x3D;[%s] &#x2F; new&#x3D;[%s]&quot;,</span><br><span class="line">						jobVertex.getID(), ejv, previousTask));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			for (IntermediateResult res : ejv.getProducedDataSets()) &#123;</span><br><span class="line">				IntermediateResult previousDataSet &#x3D; this.intermediateResults.putIfAbsent(res.getId(), res);</span><br><span class="line">				if (previousDataSet !&#x3D; null) &#123;</span><br><span class="line">					throw new JobException(String.format(&quot;Encountered two intermediate data set with ID %s : previous&#x3D;[%s] &#x2F; new&#x3D;[%s]&quot;,</span><br><span class="line">							res.getId(), res, previousDataSet));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			this.verticesInCreationOrder.add(ejv);</span><br><span class="line">			this.numVerticesTotal +&#x3D; ejv.getParallelism();</span><br><span class="line">			newExecJobVertices.add(ejv);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>
<p>至此，ExecutorGraph就创建完成了。</p>
<h2 id="3-任务的调度与执行"><a href="#3-任务的调度与执行" class="headerlink" title="3. 任务的调度与执行"></a>3. 任务的调度与执行</h2><p>关于flink的任务执行架构，官网的这两张图就是最好的说明：<br><img src="http://static.zybuluo.com/bethunebtj/qiv2wip1rok62ljo0tef3qf0/image_1cafnu1pl1d8c15m219b8vkb2334.png" alt="image_1cafnu1pl1d8c15m219b8vkb2334.png-112.9kB"><br>Flink 集群启动后，首先会启动一个 JobManger 和多个的 TaskManager。用户的代码会由JobClient 提交给 JobManager，JobManager 再把来自不同用户的任务发给 不同的TaskManager 去执行，每个TaskManager管理着多个task，task是执行计算的最小结构， TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述除了task外的三者均为独立的 JVM 进程。<br>要注意的是，TaskManager和job并非一一对应的关系。flink调度的最小单元是task而非TaskManager，也就是说，来自不同job的不同task可能运行于同一个TaskManager的不同线程上。<br><img src="http://static.zybuluo.com/bethunebtj/b7cmjn41b1zp5sco34kgvusn/image_1cclle7ui2j41nf611gs1is18m19.png" alt="image_1cclle7ui2j41nf611gs1is18m19.png-127.5kB"><br>一个flink任务所有可能的状态如上图所示。图上画的很明白，就不再赘述了。</p>
<h3 id="3-1-计算资源的调度"><a href="#3-1-计算资源的调度" class="headerlink" title="3.1 计算资源的调度"></a>3.1 计算资源的调度</h3><p>Task slot是一个TaskManager内资源分配的最小载体，代表了一个固定大小的资源子集，每个TaskManager会将其所占有的资源平分给它的slot。<br>通过调整 task slot 的数量，用户可以定义task之间是如何相互隔离的。每个 TaskManager 有一个slot，也就意味着每个task运行在独立的 JVM 中。每个 TaskManager 有多个slot的话，也就是说多个task运行在同一个JVM中。<br>而在同一个JVM进程中的task，可以共享TCP连接（基于多路复用）和心跳消息，可以减少数据的网络传输，也能共享一些数据结构，一定程度上减少了每个task的消耗。<br>每个slot可以接受单个task，也可以接受多个连续task组成的pipeline，如下图所示，FlatMap函数占用一个taskslot，而key Agg函数和sink函数共用一个taskslot：<br><img src="http://static.zybuluo.com/bethunebtj/6ypu9v09z0mit936uk0mcddi/image_1cafpf21c1jh3s5ap1fisu4v23h.png" alt="image_1cafpf21c1jh3s5ap1fisu4v23h.png-44.7kB"><br>为了达到共用slot的目的，除了可以以chain的方式pipeline算子，我们还可以允许SlotSharingGroup，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/tgamd7vw9qcdttvihlmvhie9/image_1cafpko68b3r1lk0dpsnmbj3c3u.png" alt="image_1cafpko68b3r1lk0dpsnmbj3c3u.png-61.2kB"><br>我们可以把不能被chain成一条的两个操作如flatmap和key&amp;sink放在一个TaskSlot里执行，这样做可以获得以下好处：</p>
<ul>
<li>共用slot使得我们不再需要计算每个任务需要的总task数目，直接取最高算子的并行度即可</li>
<li>对计算资源的利用率更高。例如，通常的轻量级操作map和重量级操作Aggregate不再分别需要一个线程，而是可以在同一个线程内执行，而且对于slot有限的场景，我们可以增大每个task的并行度了。<br>接下来我们还是用官网的图来说明flink是如何重用slot的：<br><img src="http://static.zybuluo.com/bethunebtj/l0n9ny2y198x0daucmyo0zb4/image_1cafqroarkjkuje1hfi18gor654b.png" alt="image_1cafqroarkjkuje1hfi18gor654b.png-137kB"></li>
</ul>
<ol>
<li>TaskManager1分配一个SharedSlot0</li>
<li>把source task放入一个SimpleSlot0，再把该slot放入SharedSlot0</li>
<li>把flatmap task放入一个SimpleSlot1，再把该slot放入SharedSlot0</li>
<li>因为我们的flatmap task并行度是2，因此不能再放入SharedSlot0，所以向TaskMange21申请了一个新的SharedSlot0</li>
<li>把第二个flatmap task放进一个新的SimpleSlot，并放进TaskManager2的SharedSlot0</li>
<li>开始处理key&amp;sink task，因为其并行度也是2，所以先把第一个task放进TaskManager1的SharedSlot</li>
<li>把第二个key&amp;sink放进TaskManager2的SharedSlot</li>
</ol>
<h3 id="3-2-JobManager执行job"><a href="#3-2-JobManager执行job" class="headerlink" title="3.2 JobManager执行job"></a>3.2 JobManager执行job</h3><p>JobManager负责接收 flink 的作业，调度 task，收集 job 的状态、管理 TaskManagers。被实现为一个 akka actor。</p>
<h4 id="3-2-1-JobManager的组件"><a href="#3-2-1-JobManager的组件" class="headerlink" title="3.2.1 JobManager的组件"></a>3.2.1 JobManager的组件</h4><ul>
<li>BlobServer 是一个用来管理二进制大文件的服务，比如保存用户上传的jar文件，该服务会将其写到磁盘上。还有一些相关的类，如BlobCache，用于TaskManager向JobManager下载用户的jar文件</li>
<li>InstanceManager 用来管理当前存活的TaskManager的组件，记录了TaskManager的心跳信息等</li>
<li>CompletedCheckpointStore 用于保存已完成的checkpoint相关信息，持久化到内存中或者zookeeper上</li>
<li>MemoryArchivist 保存了已经提交到flink的作业的相关信息，如JobGraph等</li>
</ul>
<h4 id="3-2-2-JobManager的启动过程"><a href="#3-2-2-JobManager的启动过程" class="headerlink" title="3.2.2 JobManager的启动过程"></a>3.2.2 JobManager的启动过程</h4><p>先列出JobManager启动的核心代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">def runJobManager(</span><br><span class="line">      configuration: Configuration,</span><br><span class="line">      executionMode: JobManagerMode,</span><br><span class="line">      listeningAddress: String,</span><br><span class="line">      listeningPort: Int)</span><br><span class="line">    : Unit &#x3D; &#123;</span><br><span class="line"></span><br><span class="line">    val numberProcessors &#x3D; Hardware.getNumberCPUCores()</span><br><span class="line"></span><br><span class="line">    val futureExecutor &#x3D; Executors.newScheduledThreadPool(</span><br><span class="line">      numberProcessors,</span><br><span class="line">      new ExecutorThreadFactory(&quot;jobmanager-future&quot;))</span><br><span class="line"></span><br><span class="line">    val ioExecutor &#x3D; Executors.newFixedThreadPool(</span><br><span class="line">      numberProcessors,</span><br><span class="line">      new ExecutorThreadFactory(&quot;jobmanager-io&quot;))</span><br><span class="line"></span><br><span class="line">    val timeout &#x3D; AkkaUtils.getTimeout(configuration)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; we have to first start the JobManager ActorSystem because this determines the port if 0</span><br><span class="line">    &#x2F;&#x2F; was chosen before. The method startActorSystem will update the configuration correspondingly.</span><br><span class="line">    val jobManagerSystem &#x3D; startActorSystem(</span><br><span class="line">      configuration,</span><br><span class="line">      listeningAddress,</span><br><span class="line">      listeningPort)</span><br><span class="line"></span><br><span class="line">    val highAvailabilityServices &#x3D; HighAvailabilityServicesUtils.createHighAvailabilityServices(</span><br><span class="line">      configuration,</span><br><span class="line">      ioExecutor,</span><br><span class="line">      AddressResolution.NO_ADDRESS_RESOLUTION)</span><br><span class="line"></span><br><span class="line">    val metricRegistry &#x3D; new MetricRegistryImpl(</span><br><span class="line">      MetricRegistryConfiguration.fromConfiguration(configuration))</span><br><span class="line"></span><br><span class="line">    metricRegistry.startQueryService(jobManagerSystem, null)</span><br><span class="line"></span><br><span class="line">    val (_, _, webMonitorOption, _) &#x3D; try &#123;</span><br><span class="line">      startJobManagerActors(</span><br><span class="line">        jobManagerSystem,</span><br><span class="line">        configuration,</span><br><span class="line">        executionMode,</span><br><span class="line">        listeningAddress,</span><br><span class="line">        futureExecutor,</span><br><span class="line">        ioExecutor,</span><br><span class="line">        highAvailabilityServices,</span><br><span class="line">        metricRegistry,</span><br><span class="line">        classOf[JobManager],</span><br><span class="line">        classOf[MemoryArchivist],</span><br><span class="line">        Option(classOf[StandaloneResourceManager])</span><br><span class="line">      )</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case t: Throwable &#x3D;&gt;</span><br><span class="line">        futureExecutor.shutdownNow()</span><br><span class="line">        ioExecutor.shutdownNow()</span><br><span class="line"></span><br><span class="line">        throw t</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; block until everything is shut down</span><br><span class="line">    jobManagerSystem.awaitTermination()</span><br><span class="line">    </span><br><span class="line">    .......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>配置Akka并生成ActorSystem，启动JobManager</li>
<li>启动HA和metric相关服务</li>
<li>在<code>startJobManagerActors()</code>方法中启动JobManagerActors，以及webserver，TaskManagerActor，ResourceManager等等</li>
<li>阻塞等待终止</li>
<li>集群通过LeaderService等选出JobManager的leader</li>
</ul>
<h4 id="3-2-3-JobManager启动Task"><a href="#3-2-3-JobManager启动Task" class="headerlink" title="3.2.3 JobManager启动Task"></a>3.2.3 JobManager启动Task</h4><p>JobManager 是一个Actor，通过各种消息来完成核心逻辑：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">override def handleMessage: Receive &#x3D; &#123;</span><br><span class="line">  case GrantLeadership(newLeaderSessionID) &#x3D;&gt;</span><br><span class="line">    log.info(s&quot;JobManager $getAddress was granted leadership with leader session ID &quot; +</span><br><span class="line">      s&quot;$newLeaderSessionID.&quot;)</span><br><span class="line">    leaderSessionID &#x3D; newLeaderSessionID</span><br><span class="line">    </span><br><span class="line">    .......</span><br></pre></td></tr></table></figure>
<p>有几个比较重要的消息：</p>
<ul>
<li>GrantLeadership 获得leader授权，将自身被分发到的 session id 写到 zookeeper，并恢复所有的 jobs</li>
<li>RevokeLeadership 剥夺leader授权，打断清空所有的 job 信息，但是保留作业缓存，注销所有的 TaskManagers</li>
<li>RegisterTaskManagers 注册 TaskManager，如果之前已经注册过，则只给对应的 Instance 发送消息，否则启动注册逻辑：在 InstanceManager 中注册该 Instance 的信息，并停止 Instance BlobLibraryCacheManager 的端口【供下载 lib 包用】，同时使用 watch 监听 task manager 的存活</li>
<li>SubmitJob 提交 jobGraph<br>最后一项SubmintJob就是我们要关注的，从客户端收到JobGraph，转换为ExecutionGraph并执行的过程。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">private def submitJob(jobGraph: JobGraph, jobInfo: JobInfo, isRecovery: Boolean &#x3D; false): Unit &#x3D; &#123;</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">    executionGraph &#x3D; ExecutionGraphBuilder.buildGraph(</span><br><span class="line">          executionGraph,</span><br><span class="line">          jobGraph,</span><br><span class="line">          flinkConfiguration,</span><br><span class="line">          futureExecutor,</span><br><span class="line">          ioExecutor,</span><br><span class="line">          scheduler,</span><br><span class="line">          userCodeLoader,</span><br><span class="line">          checkpointRecoveryFactory,</span><br><span class="line">          Time.of(timeout.length, timeout.unit),</span><br><span class="line">          restartStrategy,</span><br><span class="line">          jobMetrics,</span><br><span class="line">          numSlots,</span><br><span class="line">          blobServer,</span><br><span class="line">          log.logger)</span><br><span class="line">          </span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">    if (leaderElectionService.hasLeadership) &#123;</span><br><span class="line">            log.info(s&quot;Scheduling job $jobId ($jobName).&quot;)</span><br><span class="line">            </span><br><span class="line">            executionGraph.scheduleForExecution()</span><br><span class="line">            </span><br><span class="line">          &#125; else &#123;</span><br><span class="line">            self ! decorateMessage(RemoveJob(jobId, removeJobFromStateBackend &#x3D; false))</span><br><span class="line"></span><br><span class="line">            log.warn(s&quot;Submitted job $jobId, but not leader. The other leader needs to recover &quot; +</span><br><span class="line">              &quot;this. I am not scheduling the job for execution.&quot;)</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
首先做一些准备工作，然后获取一个ExecutionGraph，判断是否是恢复的job，然后将job保存下来，并且通知客户端本地已经提交成功了，最后如果确认本JobManager是leader，则执行<code>executionGraph.scheduleForExecution()</code>方法，这个方法经过一系列调用，把每个ExecutionVertex传递给了Excution类的deploy方法：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public void deploy() throws JobException &#123;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			&#x2F;&#x2F; good, we are allowed to deploy</span><br><span class="line">			if (!slot.setExecutedVertex(this)) &#123;</span><br><span class="line">				throw new JobException(&quot;Could not assign the ExecutionVertex to the slot &quot; + slot);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; race double check, did we fail&#x2F;cancel and do we need to release the slot?</span><br><span class="line">			if (this.state !&#x3D; DEPLOYING) &#123;</span><br><span class="line">				slot.releaseSlot();</span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (LOG.isInfoEnabled()) &#123;</span><br><span class="line">				LOG.info(String.format(&quot;Deploying %s (attempt #%d) to %s&quot;, vertex.getTaskNameWithSubtaskIndex(),</span><br><span class="line">						attemptNumber, getAssignedResourceLocation().getHostname()));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			final TaskDeploymentDescriptor deployment &#x3D; vertex.createDeploymentDescriptor(</span><br><span class="line">				attemptId,</span><br><span class="line">				slot,</span><br><span class="line">				taskState,</span><br><span class="line">				attemptNumber);</span><br><span class="line"></span><br><span class="line">			final TaskManagerGateway taskManagerGateway &#x3D; slot.getTaskManagerGateway();</span><br><span class="line"></span><br><span class="line">			final CompletableFuture&lt;Acknowledge&gt; submitResultFuture &#x3D; taskManagerGateway.submitTask(deployment, timeout);</span><br><span class="line"></span><br><span class="line">            ......</span><br><span class="line">		&#125;</span><br><span class="line">		catch (Throwable t) &#123;</span><br><span class="line">			markFailed(t);</span><br><span class="line">			ExceptionUtils.rethrow(t);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
我们首先生成了一个TaskDeploymentDescriptor，然后交给了<code>taskManagerGateway.submitTask()</code>方法执行。接下来的部分，就属于TaskManager的范畴了。<h3 id="3-3-TaskManager执行task"><a href="#3-3-TaskManager执行task" class="headerlink" title="3.3 TaskManager执行task"></a>3.3 TaskManager执行task</h3><h4 id="3-3-1-TaskManager的基本组件"><a href="#3-3-1-TaskManager的基本组件" class="headerlink" title="3.3.1 TaskManager的基本组件"></a>3.3.1 TaskManager的基本组件</h4>TaskManager是flink中资源管理的基本组件，是所有执行任务的基本容器，提供了内存管理、IO管理、通信管理等一系列功能，本节对各个模块进行简要介绍。</li>
</ul>
<ol>
<li>MemoryManager flink并没有把所有内存的管理都委托给JVM，因为JVM普遍存在着存储对象密度低、大内存时GC对系统影响大等问题。所以flink自己抽象了一套内存管理机制，将所有对象序列化后放在自己的MemorySegment上进行管理。MemoryManger涉及内容较多，将在后续章节进行继续剖析。</li>
<li>IOManager flink通过IOManager管理磁盘IO的过程，提供了同步和异步两种写模式，又进一步区分了block、buffer和bulk三种读写方式。<br>IOManager提供了两种方式枚举磁盘文件，一种是直接遍历文件夹下所有文件，另一种是计数器方式，对每个文件名以递增顺序访问。<br>在底层，flink将文件IO抽象为FileIOChannle，封装了底层实现。<br><img src="http://static.zybuluo.com/bethunebtj/d3j6qnbjywjzknu6pb3pou6i/image_1cag7idg4vfj1l871n0l1k0e1f7u4o.png" alt="image_1cag7idg4vfj1l871n0l1k0e1f7u4o.png-194.1kB"><br>可以看到，flink在底层实际上都是以异步的方式进行读写。</li>
<li>NetworkEnvironment 是TaskManager的网络 IO 组件，包含了追踪中间结果和数据交换的数据结构。它的构造器会统一将配置的内存先分配出来，抽象成 NetworkBufferPool 统一管理内存的申请和释放。意思是说，在输入和输出数据时，不管是保留在本地内存，等待chain在一起的下个操作符进行处理，还是通过网络把本操作符的计算结果发送出去，都被抽象成了NetworkBufferPool。后续我们还将对这个组件进行详细分析。</li>
</ol>
<h4 id="3-3-2-TaskManager执行Task"><a href="#3-3-2-TaskManager执行Task" class="headerlink" title="3.3.2 TaskManager执行Task"></a>3.3.2 TaskManager执行Task</h4><p>对于TM来说，执行task就是把收到的<code>TaskDeploymentDescriptor</code>对象转换成一个task并执行的过程。TaskDeploymentDescriptor这个类保存了task执行所必须的所有内容，例如序列化的算子，输入的InputGate和输出的ResultPartition的定义，该task要作为几个subtask执行等等。<br>按照正常逻辑思维，很容易想到TM的submitTask方法的行为：首先是确认资源，如寻找JobManager和Blob，而后建立连接，解序列化算子，收集task相关信息，接下来就是创建一个新的<code>Task</code>对象，这个task对象就是真正执行任务的关键所在。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">val task &#x3D; new Task(</span><br><span class="line">        jobInformation,</span><br><span class="line">        taskInformation,</span><br><span class="line">        tdd.getExecutionAttemptId,</span><br><span class="line">        tdd.getAllocationId,</span><br><span class="line">        tdd.getSubtaskIndex,</span><br><span class="line">        tdd.getAttemptNumber,</span><br><span class="line">        tdd.getProducedPartitions,</span><br><span class="line">        tdd.getInputGates,</span><br><span class="line">        tdd.getTargetSlotNumber,</span><br><span class="line">        tdd.getTaskStateHandles,</span><br><span class="line">        memoryManager,</span><br><span class="line">        ioManager,</span><br><span class="line">        network,</span><br><span class="line">        bcVarManager,</span><br><span class="line">        taskManagerConnection,</span><br><span class="line">        inputSplitProvider,</span><br><span class="line">        checkpointResponder,</span><br><span class="line">        blobCache,</span><br><span class="line">        libCache,</span><br><span class="line">        fileCache,</span><br><span class="line">        config,</span><br><span class="line">        taskMetricGroup,</span><br><span class="line">        resultPartitionConsumableNotifier,</span><br><span class="line">        partitionStateChecker,</span><br><span class="line">        context.dispatcher)</span><br></pre></td></tr></table></figure>
<p>如果读者是从头开始看这篇blog，里面有很多对象应该已经比较明确其作用了（除了那个brVarManager，这个是管理广播变量的，广播变量是一类会被分发到每个任务中的共享变量）。接下来的主要任务，就是把这个task启动起来,然后报告说已经启动task了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; all good, we kick off the task, which performs its own initialization</span><br><span class="line">task.startTaskThread()</span><br><span class="line"></span><br><span class="line">sender ! decorateMessage(Acknowledge.get())</span><br></pre></td></tr></table></figure>
<h4 id="3-3-2-1-生成Task对象"><a href="#3-3-2-1-生成Task对象" class="headerlink" title="3.3.2.1 生成Task对象"></a>3.3.2.1 生成Task对象</h4><p>在执行new Task()方法时，第一步是把构造函数里的这些变量赋值给当前task的fields。<br>接下来是初始化ResultPartition和InputGate。这两个类描述了task的输出数据和输入数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">for (ResultPartitionDeploymentDescriptor desc: resultPartitionDeploymentDescriptors) &#123;</span><br><span class="line">	ResultPartitionID partitionId &#x3D; new ResultPartitionID(desc.getPartitionId(), executionId);</span><br><span class="line"></span><br><span class="line">	this.producedPartitions[counter] &#x3D; new ResultPartition(</span><br><span class="line">	    taskNameWithSubtaskAndId,</span><br><span class="line">		this,</span><br><span class="line">		jobId,</span><br><span class="line">		partitionId,</span><br><span class="line">		desc.getPartitionType(),</span><br><span class="line">		desc.getNumberOfSubpartitions(),</span><br><span class="line">		desc.getMaxParallelism(),</span><br><span class="line">		networkEnvironment.getResultPartitionManager(),</span><br><span class="line">		resultPartitionConsumableNotifier,</span><br><span class="line">		ioManager,</span><br><span class="line">		desc.sendScheduleOrUpdateConsumersMessage());		</span><br><span class="line">	&#x2F;&#x2F;为每个partition初始化对应的writer </span><br><span class="line">	writers[counter] &#x3D; new ResultPartitionWriter(producedPartitions[counter]);</span><br><span class="line"></span><br><span class="line">	++counter;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Consumed intermediate result partitions</span><br><span class="line">this.inputGates &#x3D; new SingleInputGate[inputGateDeploymentDescriptors.size()];</span><br><span class="line">this.inputGatesById &#x3D; new HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">counter &#x3D; 0;</span><br><span class="line"></span><br><span class="line">for (InputGateDeploymentDescriptor inputGateDeploymentDescriptor: inputGateDeploymentDescriptors) &#123;</span><br><span class="line">	SingleInputGate gate &#x3D; SingleInputGate.create(</span><br><span class="line">		taskNameWithSubtaskAndId,</span><br><span class="line">		jobId,</span><br><span class="line">		executionId,</span><br><span class="line">		inputGateDeploymentDescriptor,</span><br><span class="line">		networkEnvironment,</span><br><span class="line">		this,</span><br><span class="line">		metricGroup.getIOMetricGroup());</span><br><span class="line"></span><br><span class="line">	inputGates[counter] &#x3D; gate;</span><br><span class="line">	inputGatesById.put(gate.getConsumedResultId(), gate);</span><br><span class="line"></span><br><span class="line">	++counter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后，创建一个Thread对象，并把自己放进该对象，这样在执行时，自己就有了自身的线程的引用。</p>
<h4 id="3-3-2-2-运行Task对象"><a href="#3-3-2-2-运行Task对象" class="headerlink" title="3.3.2.2 运行Task对象"></a>3.3.2.2 运行Task对象</h4><p> Task对象本身就是一个Runable，因此在其run方法里定义了运行逻辑。<br> 第一步是切换Task的状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">      while (true) &#123;</span><br><span class="line">	ExecutionState current &#x3D; this.executionState;</span><br><span class="line">	&#x2F;&#x2F;&#x2F;&#x2F;如果当前的执行状态为CREATED，则将其设置为DEPLOYING状态</span><br><span class="line">	if (current &#x3D;&#x3D; ExecutionState.CREATED) &#123;</span><br><span class="line">		if (transitionState(ExecutionState.CREATED, ExecutionState.DEPLOYING)) &#123;</span><br><span class="line">			&#x2F;&#x2F; success, we can start our work</span><br><span class="line">			break;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;如果当前执行状态为FAILED，则发出通知并退出run方法</span><br><span class="line">	else if (current &#x3D;&#x3D; ExecutionState.FAILED) &#123;</span><br><span class="line">		&#x2F;&#x2F; we were immediately failed. tell the TaskManager that we reached our final state</span><br><span class="line">		notifyFinalState();</span><br><span class="line">		if (metrics !&#x3D; null) &#123;</span><br><span class="line">			metrics.close();</span><br><span class="line">		&#125;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;如果当前执行状态为CANCELING，则将其修改为CANCELED状态，并退出run</span><br><span class="line">	else if (current &#x3D;&#x3D; ExecutionState.CANCELING) &#123;</span><br><span class="line">		if (transitionState(ExecutionState.CANCELING, ExecutionState.CANCELED)) &#123;</span><br><span class="line">			&#x2F;&#x2F; we were immediately canceled. tell the TaskManager that we reached our final state</span><br><span class="line">			notifyFinalState();</span><br><span class="line">			if (metrics !&#x3D; null) &#123;</span><br><span class="line">				metrics.close();</span><br><span class="line">			&#125;</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;否则说明发生了异常</span><br><span class="line">	else &#123;</span><br><span class="line">		if (metrics !&#x3D; null) &#123;</span><br><span class="line">			metrics.close();</span><br><span class="line">		&#125;</span><br><span class="line">		throw new IllegalStateException(&quot;Invalid state for beginning of operation of task &quot; + this + &#39;.&#39;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实这里有个值得关注的点，就是flink里大量使用了这种while(true)的写法来修改和检测状态，emmm…<br>接下来，就是导入用户类加载器并加载用户代码。<br>然后，是向网络管理器注册当前任务（flink的各个算子在运行时进行数据交换需要依赖网络管理器），分配一些缓存以保存数据<br>然后，读入指定的缓存文件。<br>然后，再把task创建时传入的那一大堆变量用于创建一个执行环境Envrionment。<br>再然后，对于那些并不是第一次执行的task（比如失败后重启的）要恢复其状态。<br>接下来最重要的是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">invokable.invoke();</span><br></pre></td></tr></table></figure>
<p>方法。为什么这么说呢，因为这个方法就是用户代码所真正被执行的入口。比如我们写的什么new MapFunction()的逻辑，最终就是在这里被执行的。这里说一下这个invokable，这是一个抽象类，提供了可以被TaskManager执行的对象的基本抽象。<br>这个invokable是在解析JobGraph的时候生成相关信息的，并在此处形成真正可执行的对象</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; now load the task&#39;s invokable code</span><br><span class="line">&#x2F;&#x2F;通过反射生成对象</span><br><span class="line">invokable &#x3D; loadAndInstantiateInvokable(userCodeClassLoader, nameOfInvokableClass);</span><br></pre></td></tr></table></figure>
<p><img src="http://static.zybuluo.com/bethunebtj/9bemw0us5cocnej8lq4x64rk/image_1cbkaa8r9182i18ct1kfu8g829m9.png" alt="image_1cbkaa8r9182i18ct1kfu8g829m9.png-29.9kB"><br>上图显示了flink提供的可被执行的Task类型。从名字上就可以看出各个task的作用，在此不再赘述。<br>接下来就是invoke方法了，因为我们的wordcount例子用了流式api，在此我们以StreamTask的invoke方法为例进行说明。</p>
<h4 id="3-3-2-3-StreamTask的执行逻辑"><a href="#3-3-2-3-StreamTask的执行逻辑" class="headerlink" title="3.3.2.3 StreamTask的执行逻辑"></a>3.3.2.3 StreamTask的执行逻辑</h4><p>先上部分核心代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">public final void invoke() throws Exception &#123;</span><br><span class="line"></span><br><span class="line">	boolean disposed &#x3D; false;</span><br><span class="line">    try &#123;</span><br><span class="line">			&#x2F;&#x2F; -------- Initialize ---------</span><br><span class="line">			&#x2F;&#x2F;先做一些赋值操作</span><br><span class="line">            ......</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; if the clock is not already set, then assign a default TimeServiceProvider</span><br><span class="line">	&#x2F;&#x2F;处理timer</span><br><span class="line">	if (timerService &#x3D;&#x3D; null) &#123;</span><br><span class="line">		ThreadFactory timerThreadFactory &#x3D;</span><br><span class="line">			new DispatcherThreadFactory(TRIGGER_THREAD_GROUP, &quot;Time Trigger for &quot; + getName());</span><br><span class="line"></span><br><span class="line">		timerService &#x3D; new SystemProcessingTimeService(this, getCheckpointLock(), timerThreadFactory);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;把之前JobGraph串起来的chain的信息形成实现</span><br><span class="line">	operatorChain &#x3D; new OperatorChain&lt;&gt;(this);</span><br><span class="line">	headOperator &#x3D; operatorChain.getHeadOperator();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; task specific initialization</span><br><span class="line">	&#x2F;&#x2F;这个init操作的起名非常诡异，因为这里主要是处理算子采用了自定义的checkpoint检查机制的情况，但是起了一个非常大众脸的名字</span><br><span class="line">	init();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; save the work of reloading state, etc, if the task is already canceled</span><br><span class="line">	if (canceled) &#123;</span><br><span class="line">		throw new CancelTaskException();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; -------- Invoke --------</span><br><span class="line">	LOG.debug(&quot;Invoking &#123;&#125;&quot;, getName());</span><br><span class="line">			</span><br><span class="line">	&#x2F;&#x2F; we need to make sure that any triggers scheduled in open() cannot be</span><br><span class="line">	&#x2F;&#x2F; executed before all operators are opened</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; both the following operations are protected by the lock</span><br><span class="line">		&#x2F;&#x2F; so that we avoid race conditions in the case that initializeState()</span><br><span class="line">		&#x2F;&#x2F; registers a timer, that fires before the open() is called.</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;初始化操作符状态，主要是一些state啥的</span><br><span class="line">		initializeState();</span><br><span class="line">		&#x2F;&#x2F;对于富操作符，执行其open操作</span><br><span class="line">		openAllOperators();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; final check to exit early before starting to run</span><br><span class="line">	f (canceled) &#123;</span><br><span class="line">	    throw new CancelTaskException();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; let the task do its work</span><br><span class="line">	&#x2F;&#x2F;真正开始执行的代码</span><br><span class="line">	isRunning &#x3D; true;</span><br><span class="line">	run();</span><br></pre></td></tr></table></figure>
<p>StreamTask.invoke()方法里，第一个值得一说的是<code>TimerService</code>。Flink在2015年决定向StreamTask类加入timer service的时候解释到：</p>
<blockquote>
<p>This integrates the timer as a service in StreamTask that StreamOperators can use by calling a method on the StreamingRuntimeContext. This also ensures that the timer callbacks can not be called concurrently with other methods on the StreamOperator. This behaviour is ensured by an ITCase.</p>
</blockquote>
<p>第二个要注意的是chain操作。前面提到了，flink会出于优化的角度，把一些算子chain成一个整体的算子作为一个task来执行。比如wordcount例子中，Source和FlatMap算子就被chain在了一起。在进行chain操作的时候，会设定头节点，并且指定输出的RecordWriter。</p>
<p>接下来不出所料仍然是初始化，只不过初始化的对象变成了各个operator。如果是有checkpoint的，那就从state信息里恢复，不然就作为全新的算子处理。从源码中可以看到，flink针对keyed算子和普通算子做了不同的处理。keyed算子在初始化时需要计算出一个group区间，这个区间的值在整个生命周期里都不会再变化，后面key就会根据hash的不同结果，分配到特定的group中去计算。顺便提一句，flink的keyed算子保存的是对每个数据的key的计算方法，而非真实的key，用户需要自己保证对每一行数据提供的keySelector的幂等性。至于为什么要用KeyGroup的设计，这就牵扯到扩容的范畴了，将在后面的章节进行讲述。<br>对于<code>openAllOperators()</code>方法，就是对各种RichOperator执行其open方法，通常可用于在执行计算之前加载资源。<br>最后，run方法千呼万唤始出来，该方法经过一系列跳转，最终调用chain上的第一个算子的run方法。在wordcount的例子中，它最终调用了SocketTextStreamFunction的run，建立socket连接并读入文本。</p>
<h3 id="3-4-StreamTask与StreamOperator"><a href="#3-4-StreamTask与StreamOperator" class="headerlink" title="3.4 StreamTask与StreamOperator"></a>3.4 StreamTask与StreamOperator</h3><p>前面提到，Task对象在执行过程中，把执行的任务交给了StreamTask这个类去执行。在我们的wordcount例子中，实际初始化的是OneInputStreamTask的对象（参考上面的类图）。那么这个对象是如何执行用户的代码的呢？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">protected void run() throws Exception &#123;</span><br><span class="line">	&#x2F;&#x2F; cache processor reference on the stack, to make the code more JIT friendly</span><br><span class="line">	final StreamInputProcessor&lt;IN&gt; inputProcessor &#x3D; this.inputProcessor;</span><br><span class="line"></span><br><span class="line">	while (running &amp;&amp; inputProcessor.processInput()) &#123;</span><br><span class="line">		&#x2F;&#x2F; all the work happens in the &quot;processInput&quot; method</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它做的，就是把任务直接交给了InputProcessor去执行processInput方法。这是一个<code>StreamInputProcessor</code>的实例，该processor的任务就是处理输入的数据，包括用户数据、watermark和checkpoint数据等。我们先来看看这个processor是如何产生的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">public void init() throws Exception &#123;</span><br><span class="line">	StreamConfig configuration &#x3D; getConfiguration();</span><br><span class="line"></span><br><span class="line">	TypeSerializer&lt;IN&gt; inSerializer &#x3D; configuration.getTypeSerializerIn1(getUserCodeClassLoader());</span><br><span class="line">	int numberOfInputs &#x3D; configuration.getNumberOfInputs();</span><br><span class="line"></span><br><span class="line">	if (numberOfInputs &gt; 0) &#123;</span><br><span class="line">		InputGate[] inputGates &#x3D; getEnvironment().getAllInputGates();</span><br><span class="line"></span><br><span class="line">		inputProcessor &#x3D; new StreamInputProcessor&lt;&gt;(</span><br><span class="line">				inputGates,</span><br><span class="line">				inSerializer,</span><br><span class="line">				this,</span><br><span class="line">				configuration.getCheckpointMode(),</span><br><span class="line">				getCheckpointLock(),</span><br><span class="line">				getEnvironment().getIOManager(),</span><br><span class="line">				getEnvironment().getTaskManagerInfo().getConfiguration(),</span><br><span class="line">				getStreamStatusMaintainer(),</span><br><span class="line">				this.headOperator);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; make sure that stream tasks report their I&#x2F;O statistics</span><br><span class="line">		inputProcessor.setMetricGroup(getEnvironment().getMetricGroup().getIOMetricGroup());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是OneInputStreamTask的init方法，从configs里面获取StreamOperator信息，生成自己的inputProcessor。那么inputProcessor是如何处理数据的呢？我们接着跟进源码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">public boolean processInput() throws Exception &#123;</span><br><span class="line">		if (isFinished) &#123;</span><br><span class="line">			return false;</span><br><span class="line">		&#125;</span><br><span class="line">		if (numRecordsIn &#x3D;&#x3D; null) &#123;</span><br><span class="line">			numRecordsIn &#x3D; ((OperatorMetricGroup) streamOperator.getMetricGroup()).getIOMetricGroup().getNumRecordsInCounter();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;这个while是用来处理单个元素的（不要想当然以为是循环处理元素的）</span><br><span class="line">		while (true) &#123;</span><br><span class="line">		    &#x2F;&#x2F;注意 1在下面</span><br><span class="line">		    &#x2F;&#x2F;2.接下来，会利用这个反序列化器得到下一个数据记录，并进行解析（是用户数据还是watermark等等），然后进行对应的操作</span><br><span class="line">			if (currentRecordDeserializer !&#x3D; null) &#123;</span><br><span class="line">				DeserializationResult result &#x3D; currentRecordDeserializer.getNextRecord(deserializationDelegate);</span><br><span class="line"></span><br><span class="line">				if (result.isBufferConsumed()) &#123;</span><br><span class="line">					currentRecordDeserializer.getCurrentBuffer().recycle();</span><br><span class="line">					currentRecordDeserializer &#x3D; null;</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				if (result.isFullRecord()) &#123;</span><br><span class="line">					StreamElement recordOrMark &#x3D; deserializationDelegate.getInstance();</span><br><span class="line"></span><br><span class="line">                    &#x2F;&#x2F;如果元素是watermark，就准备更新当前channel的watermark值（并不是简单赋值，因为有乱序存在），</span><br><span class="line">					if (recordOrMark.isWatermark()) &#123;</span><br><span class="line">						&#x2F;&#x2F; handle watermark</span><br><span class="line">						statusWatermarkValve.inputWatermark(recordOrMark.asWatermark(), currentChannel);</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else if (recordOrMark.isStreamStatus()) &#123;</span><br><span class="line">					&#x2F;&#x2F;如果元素是status，就进行相应处理。可以看作是一个flag，标志着当前stream接下来即将没有元素输入（idle），或者当前即将由空闲状态转为有元素状态（active）。同时，StreamStatus还对如何处理watermark有影响。通过发送status，上游的operator可以很方便的通知下游当前的数据流的状态。</span><br><span class="line">						&#x2F;&#x2F; handle stream status</span><br><span class="line">						statusWatermarkValve.inputStreamStatus(recordOrMark.asStreamStatus(), currentChannel);</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else if (recordOrMark.isLatencyMarker()) &#123;</span><br><span class="line">					&#x2F;&#x2F;LatencyMarker是用来衡量代码执行时间的。在Source处创建，携带创建时的时间戳，流到Sink时就可以知道经过了多长时间</span><br><span class="line">						&#x2F;&#x2F; handle latency marker</span><br><span class="line">						synchronized (lock) &#123;</span><br><span class="line">							streamOperator.processLatencyMarker(recordOrMark.asLatencyMarker());</span><br><span class="line">						&#125;</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else &#123;</span><br><span class="line">					&#x2F;&#x2F;这里就是真正的，用户的代码即将被执行的地方。从章节1到这里足足用了三万字，有点万里长征的感觉</span><br><span class="line">						&#x2F;&#x2F; now we can do the actual processing</span><br><span class="line">						StreamRecord&lt;IN&gt; record &#x3D; recordOrMark.asRecord();</span><br><span class="line">						synchronized (lock) &#123;</span><br><span class="line">							numRecordsIn.inc();</span><br><span class="line">							streamOperator.setKeyContextElement1(record);</span><br><span class="line">							streamOperator.processElement(record);</span><br><span class="line">						&#125;</span><br><span class="line">						return true;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;1.程序首先获取下一个buffer</span><br><span class="line">            &#x2F;&#x2F;这一段代码是服务于flink的FaultTorrent机制的，后面我会讲到，这里只需理解到它会尝试获取buffer，然后赋值给当前的反序列化器</span><br><span class="line">			final BufferOrEvent bufferOrEvent &#x3D; barrierHandler.getNextNonBlocked();</span><br><span class="line">			if (bufferOrEvent !&#x3D; null) &#123;</span><br><span class="line">				if (bufferOrEvent.isBuffer()) &#123;</span><br><span class="line">					currentChannel &#x3D; bufferOrEvent.getChannelIndex();</span><br><span class="line">					currentRecordDeserializer &#x3D; recordDeserializers[currentChannel];</span><br><span class="line">					currentRecordDeserializer.setNextBuffer(bufferOrEvent.getBuffer());</span><br><span class="line">				&#125;</span><br><span class="line">				else &#123;</span><br><span class="line">					&#x2F;&#x2F; Event received</span><br><span class="line">					final AbstractEvent event &#x3D; bufferOrEvent.getEvent();</span><br><span class="line">					if (event.getClass() !&#x3D; EndOfPartitionEvent.class) &#123;</span><br><span class="line">						throw new IOException(&quot;Unexpected event: &quot; + event);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			else &#123;</span><br><span class="line">				isFinished &#x3D; true;</span><br><span class="line">				if (!barrierHandler.isEmpty()) &#123;</span><br><span class="line">					throw new IllegalStateException(&quot;Trailing data in checkpoint barrier handler.&quot;);</span><br><span class="line">				&#125;</span><br><span class="line">				return false;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>到此为止，以上部分就是一个flink程序启动后，到执行用户代码之前，flink框架所做的准备工作。回顾一下：</p>
<ul>
<li>启动一个环境</li>
<li>生成StreamGraph</li>
<li>注册和选举JobManager</li>
<li>在各节点生成TaskManager，并根据JobGraph生成对应的Task</li>
<li>启动各个task，准备执行代码</li>
</ul>
<p>接下来，我们挑几个Operator看看flink是如何抽象这些算子的。</p>
<h2 id="4-StreamOperator的抽象与实现"><a href="#4-StreamOperator的抽象与实现" class="headerlink" title="4. StreamOperator的抽象与实现"></a>4. StreamOperator的抽象与实现</h2><h3 id="4-1-数据源的逻辑——StreamSource与时间模型"><a href="#4-1-数据源的逻辑——StreamSource与时间模型" class="headerlink" title="4.1 数据源的逻辑——StreamSource与时间模型"></a>4.1 数据源的逻辑——StreamSource与时间模型</h3><p>StreamSource抽象了一个数据源，并且指定了一些如何处理数据的模式。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">public class StreamSource&lt;OUT, SRC extends SourceFunction&lt;OUT&gt;&gt;</span><br><span class="line">		extends AbstractUdfStreamOperator&lt;OUT, SRC&gt; implements StreamOperator&lt;OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">	public void run(final Object lockingObject, final StreamStatusMaintainer streamStatusMaintainer) throws Exception &#123;</span><br><span class="line">		run(lockingObject, streamStatusMaintainer, output);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void run(final Object lockingObject,</span><br><span class="line">			final StreamStatusMaintainer streamStatusMaintainer,</span><br><span class="line">			final Output&lt;StreamRecord&lt;OUT&gt;&gt; collector) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">		final TimeCharacteristic timeCharacteristic &#x3D; getOperatorConfig().getTimeCharacteristic();</span><br><span class="line"></span><br><span class="line">		LatencyMarksEmitter latencyEmitter &#x3D; null;</span><br><span class="line">		if (getExecutionConfig().isLatencyTrackingEnabled()) &#123;</span><br><span class="line">			latencyEmitter &#x3D; new LatencyMarksEmitter&lt;&gt;(</span><br><span class="line">				getProcessingTimeService(),</span><br><span class="line">				collector,</span><br><span class="line">				getExecutionConfig().getLatencyTrackingInterval(),</span><br><span class="line">				getOperatorConfig().getVertexID(),</span><br><span class="line">				getRuntimeContext().getIndexOfThisSubtask());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		final long watermarkInterval &#x3D; getRuntimeContext().getExecutionConfig().getAutoWatermarkInterval();</span><br><span class="line"></span><br><span class="line">		this.ctx &#x3D; StreamSourceContexts.getSourceContext(</span><br><span class="line">			timeCharacteristic,</span><br><span class="line">			getProcessingTimeService(),</span><br><span class="line">			lockingObject,</span><br><span class="line">			streamStatusMaintainer,</span><br><span class="line">			collector,</span><br><span class="line">			watermarkInterval,</span><br><span class="line">			-1);</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			userFunction.run(ctx);</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; if we get here, then the user function either exited after being done (finite source)</span><br><span class="line">			&#x2F;&#x2F; or the function was canceled or stopped. For the finite source case, we should emit</span><br><span class="line">			&#x2F;&#x2F; a final watermark that indicates that we reached the end of event-time</span><br><span class="line">			if (!isCanceledOrStopped()) &#123;</span><br><span class="line">				ctx.emitWatermark(Watermark.MAX_WATERMARK);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			&#x2F;&#x2F; make sure that the context is closed in any case</span><br><span class="line">			ctx.close();</span><br><span class="line">			if (latencyEmitter !&#x3D; null) &#123;</span><br><span class="line">				latencyEmitter.close();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">	private static class LatencyMarksEmitter&lt;OUT&gt; &#123;</span><br><span class="line">		private final ScheduledFuture&lt;?&gt; latencyMarkTimer;</span><br><span class="line"></span><br><span class="line">		public LatencyMarksEmitter(</span><br><span class="line">				final ProcessingTimeService processingTimeService,</span><br><span class="line">				final Output&lt;StreamRecord&lt;OUT&gt;&gt; output,</span><br><span class="line">				long latencyTrackingInterval,</span><br><span class="line">				final int vertexID,</span><br><span class="line">				final int subtaskIndex) &#123;</span><br><span class="line"></span><br><span class="line">			latencyMarkTimer &#x3D; processingTimeService.scheduleAtFixedRate(</span><br><span class="line">				new ProcessingTimeCallback() &#123;</span><br><span class="line">					@Override</span><br><span class="line">					public void onProcessingTime(long timestamp) throws Exception &#123;</span><br><span class="line">						try &#123;</span><br><span class="line">							&#x2F;&#x2F; ProcessingTimeService callbacks are executed under the checkpointing lock</span><br><span class="line">							output.emitLatencyMarker(new LatencyMarker(timestamp, vertexID, subtaskIndex));</span><br><span class="line">						&#125; catch (Throwable t) &#123;</span><br><span class="line">							&#x2F;&#x2F; we catch the Throwables here so that we don&#39;t trigger the processing</span><br><span class="line">							&#x2F;&#x2F; timer services async exception handler</span><br><span class="line">							LOG.warn(&quot;Error while emitting latency marker.&quot;, t);</span><br><span class="line">						&#125;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;,</span><br><span class="line">				0L,</span><br><span class="line">				latencyTrackingInterval);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		public void close() &#123;</span><br><span class="line">			latencyMarkTimer.cancel(true);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在StreamSource生成上下文之后，接下来就是把上下文交给SourceFunction去执行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">userFunction.run(ctx);</span><br></pre></td></tr></table></figure>
<p>SourceFunction是对Function的一个抽象，就好像MapFunction，KeyByFunction一样，用户选择实现这些函数，然后flink框架就能利用这些函数进行计算，完成用户逻辑。<br>我们的wordcount程序使用了flink提供的一个<code>SocketTextStreamFunction</code>。我们可以看一下它的实现逻辑，对source如何运行有一个基本的认识：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">public void run(SourceContext&lt;String&gt; ctx) throws Exception &#123;</span><br><span class="line">		final StringBuilder buffer &#x3D; new StringBuilder();</span><br><span class="line">		long attempt &#x3D; 0;</span><br><span class="line"></span><br><span class="line">		while (isRunning) &#123;</span><br><span class="line"></span><br><span class="line">			try (Socket socket &#x3D; new Socket()) &#123;</span><br><span class="line">				currentSocket &#x3D; socket;</span><br><span class="line"></span><br><span class="line">				LOG.info(&quot;Connecting to server socket &quot; + hostname + &#39;:&#39; + port);</span><br><span class="line">				socket.connect(new InetSocketAddress(hostname, port), CONNECTION_TIMEOUT_TIME);</span><br><span class="line">				BufferedReader reader &#x3D; new BufferedReader(new InputStreamReader(socket.getInputStream()));</span><br><span class="line"></span><br><span class="line">				char[] cbuf &#x3D; new char[8192];</span><br><span class="line">				int bytesRead;</span><br><span class="line">				&#x2F;&#x2F;核心逻辑就是一直读inputSocket,然后交给collect方法</span><br><span class="line">				while (isRunning &amp;&amp; (bytesRead &#x3D; reader.read(cbuf)) !&#x3D; -1) &#123;</span><br><span class="line">					buffer.append(cbuf, 0, bytesRead);</span><br><span class="line">					int delimPos;</span><br><span class="line">					while (buffer.length() &gt;&#x3D; delimiter.length() &amp;&amp; (delimPos &#x3D; buffer.indexOf(delimiter)) !&#x3D; -1) &#123;</span><br><span class="line">						String record &#x3D; buffer.substring(0, delimPos);</span><br><span class="line">						&#x2F;&#x2F; truncate trailing carriage return</span><br><span class="line">						if (delimiter.equals(&quot;\n&quot;) &amp;&amp; record.endsWith(&quot;\r&quot;)) &#123;</span><br><span class="line">							record &#x3D; record.substring(0, record.length() - 1);</span><br><span class="line">						&#125;</span><br><span class="line">						&#x2F;&#x2F;读到数据后，把数据交给collect方法，collect方法负责把数据交到合适的位置（如发布为br变量，或者交给下个operator，或者通过网络发出去）</span><br><span class="line">						ctx.collect(record);</span><br><span class="line">						buffer.delete(0, delimPos + delimiter.length());</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; if we dropped out of this loop due to an EOF, sleep and retry</span><br><span class="line">			if (isRunning) &#123;</span><br><span class="line">				attempt++;</span><br><span class="line">				if (maxNumRetries &#x3D;&#x3D; -1 || attempt &lt; maxNumRetries) &#123;</span><br><span class="line">					LOG.warn(&quot;Lost connection to server socket. Retrying in &quot; + delayBetweenRetries + &quot; msecs...&quot;);</span><br><span class="line">					Thread.sleep(delayBetweenRetries);</span><br><span class="line">				&#125;</span><br><span class="line">				else &#123;</span><br><span class="line">					&#x2F;&#x2F; this should probably be here, but some examples expect simple exists of the stream source</span><br><span class="line">					&#x2F;&#x2F; throw new EOFException(&quot;Reached end of stream and reconnects are not enabled.&quot;);</span><br><span class="line">					break;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; collect trailing data</span><br><span class="line">		if (buffer.length() &gt; 0) &#123;</span><br><span class="line">			ctx.collect(buffer.toString());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>整段代码里，只有collect方法有些复杂度，后面我们在讲到flink的对象机制时会结合来讲，此处知道collect方法会收集结果，然后发送给接收者即可。在我们的wordcount里，这个算子的接收者就是被chain在一起的flatmap算子，不记得这个示例程序的话，可以返回第一章去看一下。</p>
<h3 id="4-2-从数据输入到数据处理——OneInputStreamOperator-amp-AbstractUdfStreamOperator"><a href="#4-2-从数据输入到数据处理——OneInputStreamOperator-amp-AbstractUdfStreamOperator" class="headerlink" title="4.2 从数据输入到数据处理——OneInputStreamOperator &amp; AbstractUdfStreamOperator"></a>4.2 从数据输入到数据处理——OneInputStreamOperator &amp; AbstractUdfStreamOperator</h3><p>StreamSource是用来开启整个流的算子，而承接输入数据并进行处理的算子就是OneInputStreamOperator、TwoInputStreamOperator等。<br><img src="http://static.zybuluo.com/bethunebtj/9itne7dj58lkkb4mtrt9c8q5/image_1cdc1tbgs136k1ppf17at14fumjf2d.png" alt="image_1cdc1tbgs136k1ppf17at14fumjf2d.png-126.7kB"><br>整个StreamOperator的继承关系如上图所示（图很大，建议点开放大看）。<br>OneInputStreamOperator这个接口的逻辑很简单：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public interface OneInputStreamOperator&lt;IN, OUT&gt; extends StreamOperator&lt;OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * Processes one element that arrived at this operator.</span><br><span class="line">	 * This method is guaranteed to not be called concurrently with other methods of the operator.</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	void processElement(StreamRecord&lt;IN&gt; element) throws Exception;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * Processes a &#123;@link Watermark&#125;.</span><br><span class="line">	 * This method is guaranteed to not be called concurrently with other methods of the operator.</span><br><span class="line">	 *</span><br><span class="line">	 * @see org.apache.flink.streaming.api.watermark.Watermark</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	void processWatermark(Watermark mark) throws Exception;</span><br><span class="line"></span><br><span class="line">	void processLatencyMarker(LatencyMarker latencyMarker) throws Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而实现了这个接口的StreamFlatMap算子也很简单，没什么可说的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public class StreamFlatMap&lt;IN, OUT&gt;</span><br><span class="line">		extends AbstractUdfStreamOperator&lt;OUT, FlatMapFunction&lt;IN, OUT&gt;&gt;</span><br><span class="line">		implements OneInputStreamOperator&lt;IN, OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">	private static final long serialVersionUID &#x3D; 1L;</span><br><span class="line"></span><br><span class="line">	private transient TimestampedCollector&lt;OUT&gt; collector;</span><br><span class="line"></span><br><span class="line">	public StreamFlatMap(FlatMapFunction&lt;IN, OUT&gt; flatMapper) &#123;</span><br><span class="line">		super(flatMapper);</span><br><span class="line">		chainingStrategy &#x3D; ChainingStrategy.ALWAYS;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void open() throws Exception &#123;</span><br><span class="line">		super.open();</span><br><span class="line">		collector &#x3D; new TimestampedCollector&lt;&gt;(output);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void processElement(StreamRecord&lt;IN&gt; element) throws Exception &#123;</span><br><span class="line">		collector.setTimestamp(element);</span><br><span class="line">		userFunction.flatMap(element.getValue(), collector);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从类图里可以看到，flink为我们封装了一个算子的基类<code>AbstractUdfStreamOperator</code>，提供了一些通用功能，比如把context赋给算子，保存快照等等，其中最为大家了解的应该是这两个：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void open() throws Exception &#123;</span><br><span class="line">	super.open();</span><br><span class="line">	FunctionUtils.openFunction(userFunction, new Configuration());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void close() throws Exception &#123;</span><br><span class="line">	super.close();</span><br><span class="line">	functionsClosed &#x3D; true;</span><br><span class="line">	FunctionUtils.closeFunction(userFunction);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这两个就是flink提供的<code>Rich***Function</code>系列算子的open和close方法被执行的地方。</p>
<h3 id="4-3-StreamSink"><a href="#4-3-StreamSink" class="headerlink" title="4.3 StreamSink"></a>4.3 StreamSink</h3><p>StreamSink着实没什么可说的，逻辑很简单，值得一提的只有两个方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void processElement(StreamRecord&lt;IN&gt; element) throws Exception &#123;</span><br><span class="line">	sinkContext.element &#x3D; element;</span><br><span class="line">	userFunction.invoke(element.getValue(), sinkContext);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">protected void reportOrForwardLatencyMarker(LatencyMarker maker) &#123;</span><br><span class="line">	&#x2F;&#x2F; all operators are tracking latencies</span><br><span class="line">	this.latencyGauge.reportLatency(maker, true);</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; sinks don&#39;t forward latency markers</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>processElement</code> 是继承自StreamOperator的方法。<code>reportOrForwardLatencyMarker</code>是用来计算延迟的，前面提到StreamSource会产生LateMarker，用于记录数据计算时间，就是在这里完成了计算。</p>
<p>算子这部分逻辑相对简单清晰，就讲这么多吧。</p>
<h2 id="5-为执行保驾护航——Fault-Tolerant与保证Exactly-Once语义"><a href="#5-为执行保驾护航——Fault-Tolerant与保证Exactly-Once语义" class="headerlink" title="5. 为执行保驾护航——Fault Tolerant与保证Exactly-Once语义"></a>5. 为执行保驾护航——Fault Tolerant与保证Exactly-Once语义</h2><h3 id="5-1-Fault-Tolerant演进之路"><a href="#5-1-Fault-Tolerant演进之路" class="headerlink" title="5.1 Fault Tolerant演进之路"></a>5.1 Fault Tolerant演进之路</h3><p>对于7×24小时不间断运行的流程序来说，要保证fault tolerant是很难的，这不像是离线任务，如果失败了只需要清空已有结果，重新跑一次就可以了。对于流任务，如果要保证能够重新处理已处理过的数据，就要把数据保存下来；而这就面临着几个问题：比如一是保存多久的数据？二是重复计算的数据应该怎么处理，怎么保证幂等性？<br>对于一个流系统，我们有以下希望：</p>
<ol>
<li>最好能做到exactly-once</li>
<li>处理延迟越低越好</li>
<li>吞吐量越高越好</li>
<li>计算模型应当足够简单易用，又具有足够的表达力</li>
<li>从错误恢复的开销越低越好</li>
<li>足够的流控制能力（背压能力）</li>
</ol>
<h4 id="5-1-1-Storm的Record-acknowledgement模式"><a href="#5-1-1-Storm的Record-acknowledgement模式" class="headerlink" title="5.1.1 Storm的Record acknowledgement模式"></a>5.1.1 Storm的Record acknowledgement模式</h4><p>storm的fault tolerant是这样工作的：每一个被storm的operator处理的数据都会向其上一个operator发送一份应答消息，通知其已被下游处理。storm的源operator保存了所有已发送的消息的每一个下游算子的应答消息，当它收到来自sink的应答时，它就知道该消息已经被完整处理，可以移除了。<br>如果没有收到应答，storm就会重发该消息。显而易见，这是一种at least once的逻辑。另外，这种方式面临着严重的幂等性问题，例如对一个count算子，如果count的下游算子出错，source重发该消息，那么防止该消息被count两遍的逻辑需要程序员自己去实现。最后，这样一种处理方式非常低效，吞吐量很低。</p>
<h4 id="5-1-2-Spark-streaming的micro-batch模式"><a href="#5-1-2-Spark-streaming的micro-batch模式" class="headerlink" title="5.1.2 Spark streaming的micro batch模式"></a>5.1.2 Spark streaming的micro batch模式</h4><p>前面提到，storm的实现方式就注定了与高吞吐量无缘。那么，为了提高吞吐量，把一批数据聚集在一起处理就是很自然的选择。Spark Streaming的实现就是基于这样的思路：<br>我们可以在完全的连续计算与完全的分批计算中间取折中，通过控制每批计算数据的大小来控制延迟与吞吐量的制约，如果想要低延迟，就用小一点的batch，如果想要大吞吐量，就不得不忍受更高的延迟（更久的等待数据到来的时间和更多的计算），如下图所示。<br><img src="http://static.zybuluo.com/bethunebtj/1uwp211uaxpb6nqbztfkh3u1/image_1ceop58ha180p1h3ren58jk15gb9.png" alt="image_1ceop58ha180p1h3ren58jk15gb9.png-105.7kB"><br>以这样的方式，可以在每个batch中做到exactly-once，但是这种方式也有其弊端：<br>首先，batch的方式使得一些需要跨batch的操作变得非常困难，例如session window；用户不得不自己想办法去实现相关逻辑。<br>其次，batch模式很难做好背压。当一个batch因为种种原因处理慢了，那么下一个batch要么不得不容纳更多的新来数据，要么不得不堆积更多的batch，整个任务可能会被拖垮，这是一个非常致命的问题。<br>最后，batch的方式基本意味着其延迟是有比较高的下限的，实时性上不好。</p>
<h4 id="5-1-3-Google-Cloud-Dataflow的事务式模型"><a href="#5-1-3-Google-Cloud-Dataflow的事务式模型" class="headerlink" title="5.1.3 Google Cloud Dataflow的事务式模型"></a>5.1.3 Google Cloud Dataflow的事务式模型</h4><p>我们在传统数据库，如mysql中使用binlog来完成事务，这样的思路也可以被用在实现exactly-once模型中。例如，我们可以log下每个数据元素每一次被处理时的结果和当时所处的操作符的状态。这样，当我们需要fault tolerant时，我们只需要读一下log就可以了。这种模式规避了storm和spark所面临的问题，并且能够很好的实现exactly-once，唯一的弊端是：如何尽可能的减少log的成本？Flink给了我们答案。</p>
<h4 id="5-1-4-Flink的分布式快照机制"><a href="#5-1-4-Flink的分布式快照机制" class="headerlink" title="5.1.4 Flink的分布式快照机制"></a>5.1.4 Flink的分布式快照机制</h4><p> 实现exactly-once的关键是什么？是能够准确的知道和快速记录下来当前的operator的状态、当前正在处理的元素（以及正处在不同算子之间传递的元素）。如果上面这些可以做到，那么fault tolerant无非就是从持久化存储中读取上次记录的这些元信息，并且恢复到程序中。那么Flink是如何实现的呢？</p>
<p>Flink的分布式快照的核心是其轻量级异步分布式快照机制。为了实现这一机制，flink引入了一个概念，叫做Barrier。Barrier是一种标记，它被source产生并且插入到流数据中，被发送到下游节点。当下游节点处理到该barrier标志时，这就意味着在该barrier插入到流数据时，已经进入系统的数据在当前节点已经被处理完毕。<br><img src="http://static.zybuluo.com/bethunebtj/r0h3z9im5o9ijqlvvl7vjgrt/image_1ceos05badva20hb5glen1voqm.png" alt="image_1ceos05badva20hb5glen1voqm.png-15.3kB"></p>
<p>如图所示，每当一个barrier流过一个算子节点时，就说明了在该算子上，可以触发一次检查点，用以保存当前节点的状态和已经处理过的数据，这就是一份快照。（在这里可以联想一下micro-batch，把barrier想象成分割每个batch的逻辑，会好理解一点）这样的方式下，记录快照就像和前面提到的micro-batch一样容易。</p>
<p>与此同时，该算子会向下游发送该barrier。因为数据在算子之间是按顺序发送的，所以当下游节点收到该barrier时，也就意味着同样的一批数据在下游节点上也处理完毕，可以进行一次checkpoint，保存基于该节点的一份快照，快照完成后，会通知JobMananger自己完成了这个快照。这就是分布式快照的基本含义。</p>
<p>再看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/fp1rtm1pjv12lo6nld7bns5j/image_1ceot7q13apu1a04170af7j1jao34.png" alt="image_1ceot7q13apu1a04170af7j1jao34.png-66.6kB"><br>有时，有的算子的上游节点和下游节点都不止一个，应该怎么处理呢？如果有不止一个下游节点，就向每个下游发送barrier。同理，如果有不止一个上游节点，那么就要等到所有上游节点的同一批次的barrier到达之后，才能触发checkpoint。因为每个节点运算速度不同，所以有的上游节点可能已经在发下个barrier周期的数据了，有的上游节点还没发送本次的barrier，这时候，当前算子就要缓存一下提前到来的数据，等比较慢的上游节点发送barrier之后，才能处理下一批数据。</p>
<p>当整个程序的最后一个算子sink都收到了这个barrier，也就意味着这个barrier和上个barrier之间所夹杂的这批元素已经全部落袋为安。这时，最后一个算子通知JobManager整个流程已经完成，而JobManager随后发出通知，要求所有算子删除本次快照内容，以完成清理。这整个部分，就是Flink的<strong>两阶段提交的checkpoint过程</strong>，如下面四幅图所示：<br><img src="http://static.zybuluo.com/bethunebtj/achr7r6gcstodi7m9gc270r5/image_1ceot517e14g31u2u1mnt12o91dkb1g.png" alt="image_1ceot517e14g31u2u1mnt12o91dkb1g.png-175.5kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/sibwkuskxs20xjcqkn872xg5/image_1ceot5kqbnik1f2i1dss1q5c1a1t.png" alt="image_1ceot5kqbnik1f2i1dss1q5c1a1t.png-221.3kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/0ly9zl3w3twknw7ftalv722a/image_1ceot64dppjtojkq3n1jl5j0h2a.png" alt="image_1ceot64dppjtojkq3n1jl5j0h2a.png-297.8kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/b5wrovrsrghkxuumgf6rgabc/image_1ceot6kes56sidn1f2u1voo19kf2n.png" alt="image_1ceot6kes56sidn1f2u1voo19kf2n.png-255.5kB"></p>
<p>总之，通过这种方式，flink实现了我们前面提到的六项对流处理框架的要求：exactly-once、低延迟、高吞吐、易用的模型、方便的恢复机制。</p>
<p>最后，贴一个美团做的flink与storm的性能对比：<a target="_blank" rel="noopener" href="https://tech.meituan.com/Flink_Benchmark.html">flink与storm的性能对比</a></p>
<h3 id="5-2-checkpoint的生命周期"><a href="#5-2-checkpoint的生命周期" class="headerlink" title="5.2 checkpoint的生命周期"></a>5.2 checkpoint的生命周期</h3><p>接下来，我们结合源码来看看flink的checkpoint到底是如何实现其生命周期的：</p>
<blockquote>
<p>由于flink提供的SocketSource并不支持checkpoint，所以这里我以<code>FlinkKafkaConsumer010</code>作为sourceFunction。</p>
</blockquote>
<h4 id="5-2-1-触发checkpoint"><a href="#5-2-1-触发checkpoint" class="headerlink" title="5.2.1 触发checkpoint"></a>5.2.1 触发checkpoint</h4><p>要完成一次checkpoint，第一步必然是发起checkpoint请求。那么，这个请求是哪里发出的，怎么发出的，又由谁控制呢？<br>还记得如果我们要设置checkpoint的话，需要指定checkpoint间隔吧？既然是一个指定间隔触发的功能，那应该会有类似于Scheduler的东西存在，flink里，这个负责触发checkpoint的类是<code>CheckpointCoordinator</code>。</p>
<p>flink在提交job时，会启动这个类的<code>startCheckpointScheduler</code>方法，如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public void startCheckpointScheduler() &#123;</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (shutdown) &#123;</span><br><span class="line">			throw new IllegalArgumentException(&quot;Checkpoint coordinator is shut down&quot;);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; make sure all prior timers are cancelled</span><br><span class="line">		stopCheckpointScheduler();</span><br><span class="line"></span><br><span class="line">		periodicScheduling &#x3D; true;</span><br><span class="line">		currentPeriodicTrigger &#x3D; timer.scheduleAtFixedRate(</span><br><span class="line">				new ScheduledTrigger(), </span><br><span class="line">				baseInterval, baseInterval, TimeUnit.MILLISECONDS);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private final class ScheduledTrigger implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void run() &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			triggerCheckpoint(System.currentTimeMillis(), true);</span><br><span class="line">		&#125;</span><br><span class="line">		catch (Exception e) &#123;</span><br><span class="line">			LOG.error(&quot;Exception while triggering checkpoint.&quot;, e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>启动之后，就会以设定好的频率调用<code>triggerCheckPoint()</code>方法。这个方法太长，我大概说一下都做了什么：</p>
<ul>
<li>检查符合触发checkpoint的条件，例如如果禁止了周期性的checkpoint，尚未达到触发checkpoint的最小间隔等等，就直接return</li>
<li>检查是否所有需要checkpoint和需要响应checkpoint的ACK（ack涉及到checkpoint的两阶段提交，后面会讲）的task都处于running状态，否则return</li>
<li>如果都符合，那么执行<code>checkpointID = checkpointIdCounter.getAndIncrement();</code>以生成一个新的id，然后生成一个<code>PendingCheckpoint</code>。PendingCheckpoint是一个启动了的checkpoint，但是还没有被确认。等到所有的task都确认了本次checkpoint，那么这个checkpoint对象将转化为一个<code>CompletedCheckpoint</code>。</li>
<li>定义一个超时callback，如果checkpoint执行了很久还没完成，就把它取消</li>
<li>触发MasterHooks，用户可以定义一些额外的操作，用以增强checkpoint的功能（如准备和清理外部资源）</li>
<li>接下来是核心逻辑：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  &#x2F;&#x2F; send the messages to the tasks that trigger their checkpoint</span><br><span class="line">for (Execution execution: executions) &#123;</span><br><span class="line">	execution.triggerCheckpoint(checkpointID, timestamp, checkpointOptions);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里是调用了Execution的triggerCheckpoint方法，一个execution就是一个executionVertex的实际执行者。我们看一下这个方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public void triggerCheckpoint(long checkpointId, long timestamp, CheckpointOptions checkpointOptions) &#123;</span><br><span class="line">	final LogicalSlot slot &#x3D; assignedResource;</span><br><span class="line"></span><br><span class="line">	if (slot !&#x3D; null) &#123;</span><br><span class="line">	&#x2F;&#x2F;TaskManagerGateway是用来跟taskManager进行通信的组件</span><br><span class="line">		final TaskManagerGateway taskManagerGateway &#x3D; slot.getTaskManagerGateway();</span><br><span class="line"></span><br><span class="line">		taskManagerGateway.triggerCheckpoint(attemptId, getVertex().getJobId(), checkpointId, timestamp, checkpointOptions);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		LOG.debug(&quot;The execution has no slot assigned. This indicates that the execution is &quot; +</span><br><span class="line">			&quot;no longer running.&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再往下跟就进入了<code>Task</code>类的范畴，我们将在下一小节进行解读。本小节主要讲了<code>CheckpointCoordinator</code>类是如何触发一次checkpoint，从其名字也可以看出来其功能：检查点协调器。</p>
<h4 id="5-2-2-Task层面checkpoint的准备工作"><a href="#5-2-2-Task层面checkpoint的准备工作" class="headerlink" title="5.2.2 Task层面checkpoint的准备工作"></a>5.2.2 Task层面checkpoint的准备工作</h4><p>先说Task类中的部分，该类创建了一个<code>CheckpointMetaData</code>的对象，并且生成了一个Runable匿名类用于执行checkpoint，然后以异步的方式触发了该Runable：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">public void triggerCheckpointBarrier(</span><br><span class="line">		final long checkpointID,</span><br><span class="line">		long checkpointTimestamp,</span><br><span class="line">		final CheckpointOptions checkpointOptions) &#123;</span><br><span class="line"></span><br><span class="line">           ......</span><br><span class="line"></span><br><span class="line">		Runnable runnable &#x3D; new Runnable() &#123;</span><br><span class="line">			@Override</span><br><span class="line">			public void run() &#123;</span><br><span class="line">				&#x2F;&#x2F; set safety net from the task&#39;s context for checkpointing thread</span><br><span class="line">				LOG.debug(&quot;Creating FileSystem stream leak safety net for &#123;&#125;&quot;, Thread.currentThread().getName());</span><br><span class="line">				FileSystemSafetyNet.setSafetyNetCloseableRegistryForThread(safetyNetCloseableRegistry);</span><br><span class="line"></span><br><span class="line">				try &#123;</span><br><span class="line">					boolean success &#x3D; invokable.triggerCheckpoint(checkpointMetaData, checkpointOptions);</span><br><span class="line">					if (!success) &#123;</span><br><span class="line">						checkpointResponder.declineCheckpoint(</span><br><span class="line">								getJobID(), getExecutionId(), checkpointID,</span><br><span class="line">								new CheckpointDeclineTaskNotReadyException(taskName));</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">				</span><br><span class="line">                   ......</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;;</span><br><span class="line">		executeAsyncCallRunnable(runnable, String.format(&quot;Checkpoint Trigger for %s (%s).&quot;, taskNameWithSubtask, executionId));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上面代码里的invokable事实上就是我们的StreamTask了。Task类实际上是将checkpoint委托给了更具体的类去执行，而StreamTask也将委托给更具体的类，直到业务代码。<br>StreamTask是这样实现的：</p>
<ul>
<li>如果task还在运行，那就可以进行checkpoint。方法是先向下游所有出口广播一个Barrier，然后触发本task的State保存。</li>
<li>如果task结束了，那我们就要通知下游取消本次checkpoint，方法是发送一个CancelCheckpointMarker，这是类似于Barrier的另一种消息。</li>
<li>注意，从这里开始，整个执行链路上开始出现Barrier，可以和前面讲Fault Tolerant原理的地方结合看一下。 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">private boolean performCheckpoint(</span><br><span class="line">		CheckpointMetaData checkpointMetaData,</span><br><span class="line">		CheckpointOptions checkpointOptions,</span><br><span class="line">		CheckpointMetrics checkpointMetrics) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (isRunning) &#123;</span><br><span class="line">		</span><br><span class="line">			operatorChain.broadcastCheckpointBarrier(</span><br><span class="line">					checkpointMetaData.getCheckpointId(),</span><br><span class="line">					checkpointMetaData.getTimestamp(),</span><br><span class="line">					checkpointOptions);</span><br><span class="line"></span><br><span class="line">			checkpointState(checkpointMetaData, checkpointOptions, checkpointMetrics);</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line"></span><br><span class="line">               ......</span><br><span class="line">               </span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
完成<code>broadcastCheckpointBarrier</code>方法后，在<code>checkpointState()</code>方法中，StreamTask还做了很多别的工作：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public void executeCheckpointing() throws Exception &#123;</span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line"></span><br><span class="line">	try &#123;</span><br><span class="line">	    &#x2F;&#x2F;这里，就是调用StreamOperator进行snapshotState的入口方法</span><br><span class="line">		for (StreamOperator&lt;?&gt; op : allOperators) &#123;</span><br><span class="line">			checkpointStreamOperator(op);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit</span><br><span class="line">		AsyncCheckpointRunnable asyncCheckpointRunnable &#x3D; new AsyncCheckpointRunnable(</span><br><span class="line">			owner,</span><br><span class="line">			operatorSnapshotsInProgress,</span><br><span class="line">			checkpointMetaData,</span><br><span class="line">			checkpointMetrics,</span><br><span class="line">			startAsyncPartNano);</span><br><span class="line"></span><br><span class="line">		owner.cancelables.registerCloseable(asyncCheckpointRunnable);</span><br><span class="line">		&#x2F;&#x2F;这里注册了一个Runnable，在执行完checkpoint之后向JobManager发出CompletedCheckPoint消息，这也是fault tolerant两阶段提交的一部分</span><br><span class="line">		owner.asyncOperationsThreadPool.submit(asyncCheckpointRunnable);</span><br><span class="line">		</span><br><span class="line">		......</span><br><span class="line">	</span><br><span class="line">	&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
说到checkpoint，我们印象里最直观的感受肯定是我们的一些做聚合的操作符的状态保存，比如sum的和以及count的值等等。这些内容就是StreamOperator部分将要触发保存的内容。可以看到，除了我们直观的这些操作符的状态保存外，flink的checkpoint做了大量的其他工作。</li>
</ul>
<p>接下来，我们就把目光转向操作符的checkpoint机制。</p>
<h4 id="5-2-3-操作符的状态保存及barrier传递"><a href="#5-2-3-操作符的状态保存及barrier传递" class="headerlink" title="5.2.3 操作符的状态保存及barrier传递"></a>5.2.3 操作符的状态保存及barrier传递</h4><p>第四章时，我们已经了解了StreamOperator的类关系，这里，我们就直接接着上一节的<code>checkpointStreamOperator(op)</code>方法往下讲。<br>顺便，前面也提到了，在进行checkpoint之前，operator初始化时，会执行一个<code>initializeState</code>方法，在该方法中，如果task是从失败中恢复的话，其保存的state也会被restore进来。</p>
<p>传递barrier是在进行本operator的statesnapshot之前完成的，我们先来看看其逻辑，其实和传递一条数据是类似的，就是生成一个<code>CheckpointBarrier</code>对象，然后向每个streamOutput写进去：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">   public void broadcastCheckpointBarrier(long id, long timestamp, CheckpointOptions checkpointOptions) throws IOException &#123;</span><br><span class="line">	try &#123;</span><br><span class="line">		CheckpointBarrier barrier &#x3D; new CheckpointBarrier(id, timestamp, checkpointOptions);</span><br><span class="line">		for (RecordWriterOutput&lt;?&gt; streamOutput : streamOutputs) &#123;</span><br><span class="line">			streamOutput.broadcastEvent(barrier);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	catch (InterruptedException e) &#123;</span><br><span class="line">		throw new IOException(&quot;Interrupted while broadcasting checkpoint barrier&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下游的operator接收到本barrier，就会触发其自身的checkpoint。</p>
<p>StreamTask在执行完broadcastCheckpointBarrier之后，<br>我们当前的wordcount程序里有两个operator chain，分别是：</p>
<ul>
<li>kafka source -&gt; flatmap</li>
<li>keyed aggregation -&gt; sink</li>
</ul>
<p>我们就按这个顺序来捋一下checkpoint的过程。</p>
<p>1.kafka source的checkpoint过程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">public final void snapshotState(FunctionSnapshotContext context) throws Exception &#123;</span><br><span class="line">	if (!running) &#123;</span><br><span class="line">		LOG.debug(&quot;snapshotState() called on closed source&quot;);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		unionOffsetStates.clear();</span><br><span class="line"></span><br><span class="line">		final AbstractFetcher&lt;?, ?&gt; fetcher &#x3D; this.kafkaFetcher;</span><br><span class="line">		if (fetcher &#x3D;&#x3D; null) &#123;</span><br><span class="line">			&#x2F;&#x2F; the fetcher has not yet been initialized, which means we need to return the</span><br><span class="line">			&#x2F;&#x2F; originally restored offsets or the assigned partitions</span><br><span class="line">			for (Map.Entry&lt;KafkaTopicPartition, Long&gt; subscribedPartition : subscribedPartitionsToStartOffsets.entrySet()) &#123;</span><br><span class="line">				unionOffsetStates.add(Tuple2.of(subscribedPartition.getKey(), subscribedPartition.getValue()));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">				&#x2F;&#x2F; the map cannot be asynchronously updated, because only one checkpoint call can happen</span><br><span class="line">				&#x2F;&#x2F; on this function at a time: either snapshotState() or notifyCheckpointComplete()</span><br><span class="line">				pendingOffsetsToCommit.put(context.getCheckpointId(), restoredState);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			HashMap&lt;KafkaTopicPartition, Long&gt; currentOffsets &#x3D; fetcher.snapshotCurrentState();</span><br><span class="line"></span><br><span class="line">			if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">				&#x2F;&#x2F; the map cannot be asynchronously updated, because only one checkpoint call can happen</span><br><span class="line">				&#x2F;&#x2F; on this function at a time: either snapshotState() or notifyCheckpointComplete()</span><br><span class="line">				pendingOffsetsToCommit.put(context.getCheckpointId(), currentOffsets);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			for (Map.Entry&lt;KafkaTopicPartition, Long&gt; kafkaTopicPartitionLongEntry : currentOffsets.entrySet()) &#123;</span><br><span class="line">				unionOffsetStates.add(</span><br><span class="line">						Tuple2.of(kafkaTopicPartitionLongEntry.getKey(), kafkaTopicPartitionLongEntry.getValue()));</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">			&#x2F;&#x2F; truncate the map of pending offsets to commit, to prevent infinite growth</span><br><span class="line">			while (pendingOffsetsToCommit.size() &gt; MAX_NUM_PENDING_CHECKPOINTS) &#123;</span><br><span class="line">				pendingOffsetsToCommit.remove(0);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>kafka的snapshot逻辑就是记录一下当前消费的offsets，然后做成tuple（partitiion，offset）放进一个<code>StateBackend</code>里。StateBackend是flink抽象出来的一个用于保存状态的接口。</p>
<p>2.<strong>FlatMap算子的checkpoint过程</strong><br>没什么可说的，就是调用了snapshotState()方法而已。</p>
<p>3.<strong>本operator chain的state保存过程</strong><br>细心的同学应该注意到了，各个算子的snapshot方法只把自己的状态保存到了StateBackend里，没有写入的持久化操作。这部分操作被放到了<code>AbstractStreamOperator</code>中，由flink统一负责持久化。其实不需要看源码我们也能想出来，持久化无非就是把这些数据用一个流写到磁盘或者别的地方，接下来我们来看看是不是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">         &#x2F;&#x2F;还是AbstractStreamOperator.java的snapshotState方法</span><br><span class="line">if (null !&#x3D; operatorStateBackend) &#123;</span><br><span class="line">	snapshotInProgress.setOperatorStateManagedFuture(</span><br><span class="line">		operatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么这个operatorStateBackend是怎么保存状态的呢？</p>
<ul>
<li>首先把各个算子的state做了一份深拷贝；</li>
<li>然后以异步的方式执行了一个内部类的runnable，该内部类的run方法实现了一个模版方法，首先打开stream，然后写入数据，然后再关闭stream。</li>
</ul>
<p>我们来看看这个写入数据的方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">            public SnapshotResult&lt;OperatorStateHandle&gt; performOperation() throws Exception &#123;</span><br><span class="line">	long asyncStartTime &#x3D; System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line">	CheckpointStreamFactory.CheckpointStateOutputStream localOut &#x3D; this.out;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; get the registered operator state infos ...</span><br><span class="line">	List&lt;RegisteredOperatorBackendStateMetaInfo.Snapshot&lt;?&gt;&gt; operatorMetaInfoSnapshots &#x3D;</span><br><span class="line">		new ArrayList&lt;&gt;(registeredOperatorStatesDeepCopies.size());</span><br><span class="line"></span><br><span class="line">	for (Map.Entry&lt;String, PartitionableListState&lt;?&gt;&gt; entry : registeredOperatorStatesDeepCopies.entrySet()) &#123;</span><br><span class="line">		operatorMetaInfoSnapshots.add(entry.getValue().getStateMetaInfo().snapshot());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; ... write them all in the checkpoint stream ...</span><br><span class="line">	DataOutputView dov &#x3D; new DataOutputViewStreamWrapper(localOut);</span><br><span class="line"></span><br><span class="line">	OperatorBackendSerializationProxy backendSerializationProxy &#x3D;</span><br><span class="line">		new OperatorBackendSerializationProxy(operatorMetaInfoSnapshots, broadcastMetaInfoSnapshots);</span><br><span class="line"></span><br><span class="line">	backendSerializationProxy.write(dov);</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注释写的很清楚，我就不多说了。</p>
<p>4.<strong>后继operatorChain的checkpoint过程</strong><br>前面说到，在flink的流中，barrier流过时会触发checkpoint。在上面第1步中，上游节点已经发出了Barrier，所以在我们的keyed aggregation -&gt; sink 这个operatorchain中，我们将首先捕获这个barrier。</p>
<p>捕获barrier的过程其实就是处理input数据的过程，对应着<code>StreamInputProcessor.processInput()</code>方法，该方法我们在第四章已经讲过，这里我们简单回顾一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">         &#x2F;&#x2F;每个元素都会触发这一段逻辑，如果下一个数据是buffer，则从外围的while循环里进入处理用户数据的逻辑；这个方法里默默的处理了barrier的逻辑</span><br><span class="line">         final BufferOrEvent bufferOrEvent &#x3D; barrierHandler.getNextNonBlocked();</span><br><span class="line">if (bufferOrEvent !&#x3D; null) &#123;</span><br><span class="line">	if (bufferOrEvent.isBuffer()) &#123;</span><br><span class="line">		currentChannel &#x3D; bufferOrEvent.getChannelIndex();</span><br><span class="line">		currentRecordDeserializer &#x3D; recordDeserializers[currentChannel];</span><br><span class="line">		currentRecordDeserializer.setNextBuffer(bufferOrEvent.getBuffer());</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		&#x2F;&#x2F; Event received</span><br><span class="line">		final AbstractEvent event &#x3D; bufferOrEvent.getEvent();</span><br><span class="line">		if (event.getClass() !&#x3D; EndOfPartitionEvent.class) &#123;</span><br><span class="line">			throw new IOException(&quot;Unexpected event: &quot; + event);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>处理barrier的过程在这段代码里没有体现，因为被包含在了<code>getNextNonBlocked()</code>方法中，我们看下这个方法的核心逻辑：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">         &#x2F;&#x2F;BarrierBuffer.getNextNonBlocked方法</span><br><span class="line">else if (bufferOrEvent.getEvent().getClass() &#x3D;&#x3D; CheckpointBarrier.class) &#123;</span><br><span class="line">	if (!endOfStream) &#123;</span><br><span class="line">		&#x2F;&#x2F; process barriers only if there is a chance of the checkpoint completing</span><br><span class="line">		processBarrier((CheckpointBarrier) bufferOrEvent.getEvent(), bufferOrEvent.getChannelIndex());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">else if (bufferOrEvent.getEvent().getClass() &#x3D;&#x3D; CancelCheckpointMarker.class) &#123;</span><br><span class="line">	processCancellationBarrier((CancelCheckpointMarker) bufferOrEvent.getEvent());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先提一嘴，大家还记得之前的部分也提到过CheckpointMarker吧，这里正好也对上了。</p>
<p>处理barrier也是个麻烦事，大家回想一下5.1节提到的屏障的原理图，一个opertor必须收到从每个inputchannel发过来的同一序号的barrier之后才能发起本节点的checkpoint，如果有的channel的数据处理的快了，那该barrier后的数据还需要缓存起来，如果有的inputchannel被关闭了，那它就不会再发送barrier过来了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">private void processBarrier(CheckpointBarrier receivedBarrier, int channelIndex) throws Exception &#123;</span><br><span class="line">		final long barrierId &#x3D; receivedBarrier.getId();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; fast path for single channel cases</span><br><span class="line">		if (totalNumberOfInputChannels &#x3D;&#x3D; 1) &#123;</span><br><span class="line">			if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; new checkpoint</span><br><span class="line">				currentCheckpointId &#x3D; barrierId;</span><br><span class="line">				notifyCheckpoint(receivedBarrier);</span><br><span class="line">			&#125;</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; -- general code path for multiple input channels --</span><br><span class="line"></span><br><span class="line">		if (numBarriersReceived &gt; 0) &#123;</span><br><span class="line">			&#x2F;&#x2F; this is only true if some alignment is already progress and was not canceled</span><br><span class="line"></span><br><span class="line">			if (barrierId &#x3D;&#x3D; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; regular case</span><br><span class="line">				onBarrier(channelIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			else if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; we did not complete the current checkpoint, another started before</span><br><span class="line">				LOG.warn(&quot;Received checkpoint barrier for checkpoint &#123;&#125; before completing current checkpoint &#123;&#125;. &quot; +</span><br><span class="line">						&quot;Skipping current checkpoint.&quot;, barrierId, currentCheckpointId);</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; let the task know we are not completing this</span><br><span class="line">				notifyAbort(currentCheckpointId, new CheckpointDeclineSubsumedException(barrierId));</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; abort the current checkpoint</span><br><span class="line">				releaseBlocksAndResetBarriers();</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; begin a the new checkpoint</span><br><span class="line">				beginNewAlignment(barrierId, channelIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			else &#123;</span><br><span class="line">				&#x2F;&#x2F; ignore trailing barrier from an earlier checkpoint (obsolete now)</span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		else if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">			&#x2F;&#x2F; first barrier of a new checkpoint</span><br><span class="line">			beginNewAlignment(barrierId, channelIndex);</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line">			&#x2F;&#x2F; either the current checkpoint was canceled (numBarriers &#x3D;&#x3D; 0) or</span><br><span class="line">			&#x2F;&#x2F; this barrier is from an old subsumed checkpoint</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; check if we have all barriers - since canceled checkpoints always have zero barriers</span><br><span class="line">		&#x2F;&#x2F; this can only happen on a non canceled checkpoint</span><br><span class="line">		if (numBarriersReceived + numClosedChannels &#x3D;&#x3D; totalNumberOfInputChannels) &#123;</span><br><span class="line">			&#x2F;&#x2F; actually trigger checkpoint</span><br><span class="line">			if (LOG.isDebugEnabled()) &#123;</span><br><span class="line">				LOG.debug(&quot;Received all barriers, triggering checkpoint &#123;&#125; at &#123;&#125;&quot;,</span><br><span class="line">						receivedBarrier.getId(), receivedBarrier.getTimestamp());</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			releaseBlocksAndResetBarriers();</span><br><span class="line">			notifyCheckpoint(receivedBarrier);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>总之，当收到全部的barrier之后，就会触发<code>notifyCheckpoint()</code>，该方法又会调用StreamTask的<code>triggerCheckpoint</code>，和之前的operator是一样的。</p>
<p>如果还有后续的operator的话，就是完全相同的循环，不再赘述。</p>
<p>5.<strong>报告完成checkpoint事件</strong><br>当一个operator保存完checkpoint数据后，就会启动一个异步对象<code>AsyncCheckpointRunnable</code>，用以报告该检查点已完成，其具体逻辑在reportCompletedSnapshotStates中。这个方法把任务又最终委托给了<code>RpcCheckpointResponder</code>这个类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">checkpointResponder.acknowledgeCheckpoint(</span><br><span class="line">			jobId,</span><br><span class="line">			executionAttemptID,</span><br><span class="line">			checkpointId,</span><br><span class="line">			checkpointMetrics,</span><br><span class="line">			acknowledgedState);</span><br></pre></td></tr></table></figure>
<p>从这个类也可以看出来，它的逻辑是通过rpc的方式远程调JobManager的相关方法完成报告事件，底层也是通过akka实现的。<br>那么，谁响应了这个rpc调用呢？是该任务的JobMaster。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;JobMaster.java</span><br><span class="line">public void acknowledgeCheckpoint(</span><br><span class="line">		final JobID jobID,</span><br><span class="line">		final ExecutionAttemptID executionAttemptID,</span><br><span class="line">		final long checkpointId,</span><br><span class="line">		final CheckpointMetrics checkpointMetrics,</span><br><span class="line">		final TaskStateSnapshot checkpointState) &#123;</span><br><span class="line"></span><br><span class="line">	final CheckpointCoordinator checkpointCoordinator &#x3D; executionGraph.getCheckpointCoordinator();</span><br><span class="line">	final AcknowledgeCheckpoint ackMessage &#x3D; new AcknowledgeCheckpoint(</span><br><span class="line">		jobID,</span><br><span class="line">		executionAttemptID,</span><br><span class="line">		checkpointId,</span><br><span class="line">		checkpointMetrics,</span><br><span class="line">		checkpointState);</span><br><span class="line"></span><br><span class="line">	if (checkpointCoordinator !&#x3D; null) &#123;</span><br><span class="line">		getRpcService().execute(() -&gt; &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				checkpointCoordinator.receiveAcknowledgeMessage(ackMessage);</span><br><span class="line">			&#125; catch (Throwable t) &#123;</span><br><span class="line">				log.warn(&quot;Error while processing checkpoint acknowledgement message&quot;);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		log.error(&quot;Received AcknowledgeCheckpoint message for job &#123;&#125; with no CheckpointCoordinator&quot;,</span><br><span class="line">				jobGraph.getJobID());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>JobMaster反手<del>就是一巴掌</del>就把任务又rpc给了<code>CheckpointCoordinator.receiveAcknowledgeMessage()</code>方法。</p>
<p>之前提到，coordinator在触发checkpoint时，生成了一个<code>PendingCheckpoint</code>，保存了所有operator的id。</p>
<p>当PendingCheckpoint收到一个operator的完成checkpoint的消息时，它就把这个operator从未完成checkpoint的节点集合移动到已完成的集合。当所有的operator都报告完成了checkpoint时，CheckpointCoordinator会触发<code>completePendingCheckpoint()</code>方法，该方法做了以下事情：</p>
<ul>
<li>把pendinCgCheckpoint转换为CompletedCheckpoint</li>
<li>把CompletedCheckpoint加入已完成的检查点集合，并从未完成检查点集合删除该检查点</li>
<li>再度向各个operator发出rpc，通知该检查点已完成</li>
</ul>
<p>本文里，收到这个远程调用的就是那两个operator chain，我们来看看其逻辑:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public void notifyCheckpointComplete(long checkpointId) throws Exception &#123;</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (isRunning) &#123;</span><br><span class="line">			LOG.debug(&quot;Notification of complete checkpoint for task &#123;&#125;&quot;, getName());</span><br><span class="line"></span><br><span class="line">			for (StreamOperator&lt;?&gt; operator : operatorChain.getAllOperators()) &#123;</span><br><span class="line">				if (operator !&#x3D; null) &#123;</span><br><span class="line">					operator.notifyCheckpointComplete(checkpointId);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line">			LOG.debug(&quot;Ignoring notification of complete checkpoint for not-running task &#123;&#125;&quot;, getName());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再接下来无非就是层层通知对应的算子做出响应罢了。</p>
<p>至此，flink的两阶段提交的checkpoint逻辑全部完成。</p>
<h3 id="5-3-承载checkpoint数据的抽象：State-amp-StateBackend"><a href="#5-3-承载checkpoint数据的抽象：State-amp-StateBackend" class="headerlink" title="5.3 承载checkpoint数据的抽象：State &amp; StateBackend"></a>5.3 承载checkpoint数据的抽象：State &amp; StateBackend</h3><p>State是快照数据的载体，StateBackend是快照如何被保存的抽象。</p>
<p>State分为 KeyedState和OperatorState，从名字就可以看出来分别对应着keyedStream和其他的oeprator。从State由谁管理上，也可以区分为raw state和Managed state。Flink管理的就是Managed state，用户自己管理的就是raw state。Managed State又分为ValueState、ListState、ReducingState、AggregatingState、FoldingState、MapState这么几种，看名字知用途。</p>
<p>StateBackend目前提供了三个backend，MemoryStateBackend，FsStateBackend，RocksDBStateBackend，都是看名字知用途系列。</p>
<p>State接口、StateBackend接口及其实现都比较简单，代码就不贴了， 尤其State本质上就是一层容器封装。</p>
<p>贴个别人写的状态管理的文章吧：<a target="_blank" rel="noopener" href="https://yq.aliyun.com/articles/225623?spm=a2c4e.11153940.blogcont225624.12.7c797f6bZo3tiM">详解Flink中的状态管理</a></p>
<h2 id="6-数据流转——Flink的数据抽象及数据交换过程"><a href="#6-数据流转——Flink的数据抽象及数据交换过程" class="headerlink" title="6.数据流转——Flink的数据抽象及数据交换过程"></a>6.数据流转——Flink的数据抽象及数据交换过程</h2><p>本章打算讲一下flink底层是如何定义和在操作符之间传递数据的。</p>
<h3 id="6-1-flink的数据抽象"><a href="#6-1-flink的数据抽象" class="headerlink" title="6.1 flink的数据抽象"></a>6.1 flink的数据抽象</h3><h4 id="6-1-1-MemorySegment"><a href="#6-1-1-MemorySegment" class="headerlink" title="6.1.1 MemorySegment"></a>6.1.1 MemorySegment</h4><p>Flink作为一个高效的流框架，为了避免JVM的固有缺陷（java对象存储密度低，FGC影响吞吐和响应等），必然走上自主管理内存的道路。</p>
<p>这个<code>MemorySegment</code>就是Flink的内存抽象。默认情况下，一个MemorySegment可以被看做是一个32kb大的内存块的抽象。这块内存既可以是JVM里的一个byte[]，也可以是堆外内存（DirectByteBuffer）。</p>
<p>如果说byte[]数组和direct memory是最底层的存储，那么memorysegment就是在其上覆盖的一层统一抽象。它定义了一系列抽象方法，用于控制和底层内存的交互，如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public abstract class MemorySegment &#123;</span><br><span class="line"></span><br><span class="line">    public abstract byte get(int index);</span><br><span class="line">    </span><br><span class="line">    public abstract void put(int index, byte b);</span><br><span class="line">    </span><br><span class="line">    public int size() ;</span><br><span class="line">    </span><br><span class="line">    public abstract ByteBuffer wrap(int offset, int length);</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以看到，它在提供了诸多直接操作内存的方法外，还提供了一个<code>wrap()</code>方法，将自己包装成一个ByteBuffer，我们待会儿讲这个ByteBuffer。</p>
<p>Flink为MemorySegment提供了两个实现类：<code>HeapMemorySegment</code>和<code>HybridMemorySegment</code>。他们的区别在于前者只能分配堆内存，而后者能用来分配堆内和堆外内存。事实上，Flink框架里，只使用了后者。这是为什么呢？</p>
<p>如果HybridMemorySegment只能用于分配堆外内存的话，似乎更合常理。但是在JVM的世界中，如果一个方法是一个虚方法，那么每次调用时，JVM都要花时间去确定调用的到底是哪个子类实现的该虚方法（方法重写机制，不明白的去看JVM的invokeVirtual指令），也就意味着每次都要去翻方法表；而如果该方法虽然是个虚方法，但实际上整个JVM里只有一个实现（就是说只加载了一个子类进来），那么JVM会很聪明的把它去虚化处理，这样就不用每次调用方法时去找方法表了，能够大大提升性能。但是只分配堆内或者堆外内存不能满足我们的需要，所以就出现了HybridMemorySegment同时可以分配两种内存的设计。</p>
<p>我们可以看看HybridMemorySegment的构造代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">HybridMemorySegment(ByteBuffer buffer, Object owner) &#123;</span><br><span class="line">	super(checkBufferAndGetAddress(buffer), buffer.capacity(), owner);</span><br><span class="line">	this.offHeapBuffer &#x3D; buffer;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	HybridMemorySegment(byte[] buffer, Object owner) &#123;</span><br><span class="line">	super(buffer, owner);</span><br><span class="line">	this.offHeapBuffer &#x3D; null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，第一个构造函数的<code>checkBufferAndGetAddress()</code>方法能够得到direct buffer的内存地址，因此可以操作堆外内存。</p>
<h4 id="6-1-2-ByteBuffer与NetworkBufferPool"><a href="#6-1-2-ByteBuffer与NetworkBufferPool" class="headerlink" title="6.1.2 ByteBuffer与NetworkBufferPool"></a>6.1.2 ByteBuffer与NetworkBufferPool</h4><p>在<code>MemorySegment</code>这个抽象之上，Flink在数据从operator内的数据对象在向TaskManager上转移，预备被发给下个节点的过程中，使用的抽象或者说内存对象是<code>Buffer</code>。</p>
<p><strong>注意</strong>，这个Buffer是个flink接口，不是java.nio提供的那个Buffer抽象类。Flink在这一层面同时使用了这两个同名概念，用来存储对象，直接看代码时到处都是各种xxxBuffer很容易混淆：</p>
<ul>
<li>java提供的那个Buffer抽象类在这一层主要用于构建<code>HeapByteBuffer</code>，这个主要是当数据从jvm里的一个对象被序列化成字节数组时用的；</li>
<li>Flink的这个Buffer接口主要是一种flink层面用于传输数据和事件的统一抽象，其实现类是<code>NetworkBuffer</code>，是对<code>MemorySegment</code>的包装。Flink在各个TaskManager之间传递数据时，使用的是这一层的抽象。</li>
</ul>
<p>因为Buffer的底层是MemorySegment，这可能不是JVM所管理的，所以为了知道什么时候一个Buffer用完了可以回收，Flink引入了引用计数的概念，当确认这个buffer没有人引用，就可以回收这一片MemorySegment用于别的地方了（JVM的垃圾回收为啥不用引用计数？读者思考一下）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public abstract class AbstractReferenceCountedByteBuf extends AbstractByteBuf &#123;</span><br><span class="line"></span><br><span class="line">    private volatile int refCnt &#x3D; 1;</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了方便管理<code>NetworkBuffer</code>，Flink提供了<code>BufferPoolFactory</code>，并且提供了唯一实现<code>NetworkBufferPool</code>，这是个工厂模式的应用。</p>
<p>NetworkBufferPool在每个TaskManager上只有一个，负责所有子task的内存管理。其实例化时就会尝试获取所有可由它管理的内存（对于堆内存来说，直接获取所有内存并放入老年代，并令用户对象只在新生代存活，可以极大程度的减少Full GC），我们看看其构造方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public NetworkBufferPool(int numberOfSegmentsToAllocate, int segmentSize) &#123;</span><br><span class="line"></span><br><span class="line">		......</span><br><span class="line">		</span><br><span class="line">		try &#123;</span><br><span class="line">			this.availableMemorySegments &#x3D; new ArrayBlockingQueue&lt;&gt;(numberOfSegmentsToAllocate);</span><br><span class="line">		&#125;</span><br><span class="line">		catch (OutOfMemoryError err) &#123;</span><br><span class="line">			throw new OutOfMemoryError(&quot;Could not allocate buffer queue of length &quot;</span><br><span class="line">					+ numberOfSegmentsToAllocate + &quot; - &quot; + err.getMessage());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			for (int i &#x3D; 0; i &lt; numberOfSegmentsToAllocate; i++) &#123;</span><br><span class="line">				ByteBuffer memory &#x3D; ByteBuffer.allocateDirect(segmentSize);</span><br><span class="line">				availableMemorySegments.add(MemorySegmentFactory.wrapPooledOffHeapMemory(memory, null));</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">        </span><br><span class="line">		long allocatedMb &#x3D; (sizeInLong * availableMemorySegments.size()) &gt;&gt; 20;</span><br><span class="line"></span><br><span class="line">		LOG.info(&quot;Allocated &#123;&#125; MB for network buffer pool (number of memory segments: &#123;&#125;, bytes per segment: &#123;&#125;).&quot;,</span><br><span class="line">				allocatedMb, availableMemorySegments.size(), segmentSize);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>由于NetworkBufferPool只是个工厂，实际的内存池是<code>LocalBufferPool</code>。每个TaskManager都只有一个NetworkBufferPool工厂，但是上面运行的每个task都要有一个和其他task隔离的LocalBufferPool池，这从逻辑上很好理解。另外，NetworkBufferPool会计算自己所拥有的所有内存分片数，在分配新的内存池时对每个内存池应该占有的内存分片数重分配，步骤是：</p>
<ul>
<li>首先，从整个工厂管理的内存片中拿出所有的内存池所需要的最少Buffer数目总和</li>
<li>如果正好分配完，就结束</li>
<li>其次，把所有的剩下的没分配的内存片，按照每个LocalBufferPool内存池的剩余想要容量大小进行按比例分配</li>
<li>剩余想要容量大小是这么个东西：如果该内存池至少需要3个buffer，最大需要10个buffer，那么它的剩余想要容量就是7</li>
</ul>
<p>实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">   private void redistributeBuffers() throws IOException &#123;</span><br><span class="line">	assert Thread.holdsLock(factoryLock);</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; All buffers, which are not among the required ones</span><br><span class="line">	final int numAvailableMemorySegment &#x3D; totalNumberOfMemorySegments - numTotalRequiredBuffers;</span><br><span class="line"></span><br><span class="line">	if (numAvailableMemorySegment &#x3D;&#x3D; 0) &#123;</span><br><span class="line">		&#x2F;&#x2F; in this case, we need to redistribute buffers so that every pool gets its minimum</span><br><span class="line">		for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">			bufferPool.setNumBuffers(bufferPool.getNumberOfRequiredMemorySegments());</span><br><span class="line">		&#125;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	long totalCapacity &#x3D; 0; &#x2F;&#x2F; long to avoid int overflow</span><br><span class="line"></span><br><span class="line">	for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">		int excessMax &#x3D; bufferPool.getMaxNumberOfMemorySegments() -</span><br><span class="line">			bufferPool.getNumberOfRequiredMemorySegments();</span><br><span class="line">		totalCapacity +&#x3D; Math.min(numAvailableMemorySegment, excessMax);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; no capacity to receive additional buffers?</span><br><span class="line">	if (totalCapacity &#x3D;&#x3D; 0) &#123;</span><br><span class="line">		return; &#x2F;&#x2F; necessary to avoid div by zero when nothing to re-distribute</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	final int memorySegmentsToDistribute &#x3D; MathUtils.checkedDownCast(</span><br><span class="line">			Math.min(numAvailableMemorySegment, totalCapacity));</span><br><span class="line"></span><br><span class="line">	long totalPartsUsed &#x3D; 0; &#x2F;&#x2F; of totalCapacity</span><br><span class="line">	int numDistributedMemorySegment &#x3D; 0;</span><br><span class="line">	for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">		int excessMax &#x3D; bufferPool.getMaxNumberOfMemorySegments() -</span><br><span class="line">			bufferPool.getNumberOfRequiredMemorySegments();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; shortcut</span><br><span class="line">		if (excessMax &#x3D;&#x3D; 0) &#123;</span><br><span class="line">			continue;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		totalPartsUsed +&#x3D; Math.min(numAvailableMemorySegment, excessMax);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		final int mySize &#x3D; MathUtils.checkedDownCast(</span><br><span class="line">				memorySegmentsToDistribute * totalPartsUsed &#x2F; totalCapacity - numDistributedMemorySegment);</span><br><span class="line"></span><br><span class="line">		numDistributedMemorySegment +&#x3D; mySize;</span><br><span class="line">		bufferPool.setNumBuffers(bufferPool.getNumberOfRequiredMemorySegments() + mySize);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	assert (totalPartsUsed &#x3D;&#x3D; totalCapacity);</span><br><span class="line">	assert (numDistributedMemorySegment &#x3D;&#x3D; memorySegmentsToDistribute);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来说说这个<code>LocalBufferPool</code>内存池。<br>LocalBufferPool的逻辑想想无非是<del>增删改查</del>，值得说的是其fields：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;** 该内存池需要的最少内存片数目*&#x2F;</span><br><span class="line">private final int numberOfRequiredMemorySegments;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 当前已经获得的内存片中，还没有写入数据的空白内存片</span><br><span class="line"> *&#x2F;</span><br><span class="line">private final ArrayDeque&lt;MemorySegment&gt; availableMemorySegments &#x3D; new ArrayDeque&lt;MemorySegment&gt;();</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 注册的所有监控buffer可用性的监听器</span><br><span class="line"> *&#x2F;</span><br><span class="line">private final ArrayDeque&lt;BufferListener&gt; registeredListeners &#x3D; new ArrayDeque&lt;&gt;();</span><br><span class="line"></span><br><span class="line">&#x2F;** 能给内存池分配的最大分片数*&#x2F;</span><br><span class="line">private final int maxNumberOfMemorySegments;</span><br><span class="line"></span><br><span class="line">&#x2F;** 当前内存池大小 *&#x2F;</span><br><span class="line">private int currentPoolSize;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 所有经由NetworkBufferPool分配的，被本内存池引用到的（非直接获得的）分片数</span><br><span class="line"> *&#x2F;</span><br><span class="line">private int numberOfRequestedMemorySegments;</span><br></pre></td></tr></table></figure>
<p>承接NetworkBufferPool的重分配方法，我们来看看LocalBufferPool的<code>setNumBuffers()</code>方法，代码很短，逻辑也相当简单，就不展开说了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public void setNumBuffers(int numBuffers) throws IOException &#123;</span><br><span class="line">	synchronized (availableMemorySegments) &#123;</span><br><span class="line">		checkArgument(numBuffers &gt;&#x3D; numberOfRequiredMemorySegments,</span><br><span class="line">				&quot;Buffer pool needs at least %s buffers, but tried to set to %s&quot;,</span><br><span class="line">				numberOfRequiredMemorySegments, numBuffers);</span><br><span class="line"></span><br><span class="line">		if (numBuffers &gt; maxNumberOfMemorySegments) &#123;</span><br><span class="line">			currentPoolSize &#x3D; maxNumberOfMemorySegments;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			currentPoolSize &#x3D; numBuffers;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		returnExcessMemorySegments();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; If there is a registered owner and we have still requested more buffers than our</span><br><span class="line">		&#x2F;&#x2F; size, trigger a recycle via the owner.</span><br><span class="line">		if (owner !&#x3D; null &amp;&amp; numberOfRequestedMemorySegments &gt; currentPoolSize) &#123;</span><br><span class="line">			owner.releaseMemory(numberOfRequestedMemorySegments - numBuffers);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="6-1-3-RecordWriter与Record"><a href="#6-1-3-RecordWriter与Record" class="headerlink" title="6.1.3 RecordWriter与Record"></a>6.1.3 RecordWriter与Record</h4><p>我们接着往高层抽象走，刚刚提到了最底层内存抽象是MemorySegment，用于数据传输的是Buffer，那么，承上启下对接从Java对象转为Buffer的中间对象是什么呢？是<code>StreamRecord</code>。</p>
<p>从<code>StreamRecord&lt;T&gt;</code>这个类名字就可以看出来，这个类就是个wrap，里面保存了原始的Java对象。另外，StreamRecord还保存了一个timestamp。</p>
<p>那么这个对象是怎么变成LocalBufferPool内存池里的一个大号字节数组的呢？借助了<code>StreamWriter</code>这个类。</p>
<p>我们直接来看把数据序列化交出去的方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">private void sendToTarget(T record, int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	RecordSerializer&lt;T&gt; serializer &#x3D; serializers[targetChannel];</span><br><span class="line"></span><br><span class="line">	SerializationResult result &#x3D; serializer.addRecord(record);</span><br><span class="line"></span><br><span class="line">	while (result.isFullBuffer()) &#123;</span><br><span class="line">		if (tryFinishCurrentBufferBuilder(targetChannel, serializer)) &#123;</span><br><span class="line">			&#x2F;&#x2F; If this was a full record, we are done. Not breaking</span><br><span class="line">			&#x2F;&#x2F; out of the loop at this point will lead to another</span><br><span class="line">			&#x2F;&#x2F; buffer request before breaking out (that would not be</span><br><span class="line">			&#x2F;&#x2F; a problem per se, but it can lead to stalls in the</span><br><span class="line">			&#x2F;&#x2F; pipeline).</span><br><span class="line">			if (result.isFullRecord()) &#123;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		BufferBuilder bufferBuilder &#x3D; requestNewBufferBuilder(targetChannel);</span><br><span class="line"></span><br><span class="line">		result &#x3D; serializer.continueWritingWithNextBufferBuilder(bufferBuilder);</span><br><span class="line">	&#125;</span><br><span class="line">	checkState(!serializer.hasSerializedData(), &quot;All data should be written at once&quot;);</span><br><span class="line">       </span><br><span class="line">       </span><br><span class="line">       </span><br><span class="line">	if (flushAlways) &#123;</span><br><span class="line">		targetPartition.flush(targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先说最后一行，如果配置为flushAlways，那么会立刻把元素发送出去，但是这样吞吐量会下降；Flink的默认设置其实也不是一个元素一个元素的发送，是单独起了一个线程，每隔固定时间flush一次所有channel，较真起来也算是mini batch了。</p>
<p>再说序列化那一句:<code>SerializationResult result = serializer.addRecord(record);</code>。在这行代码中，Flink把对象调用该对象所属的序列化器序列化为字节数组。</p>
<h3 id="6-2-数据流转过程"><a href="#6-2-数据流转过程" class="headerlink" title="6.2 数据流转过程"></a>6.2 数据流转过程</h3><p>上一节讲了各层数据的抽象，这一节讲讲数据在各个task之间exchange的过程。</p>
<h4 id="6-2-1-整体过程"><a href="#6-2-1-整体过程" class="headerlink" title="6.2.1 整体过程"></a>6.2.1 整体过程</h4><p>看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/e5m0ggy1t6z8tjgfn52cr31r/image_1cetavukjja42ce1261v5k57i9.png" alt="image_1cetavukjja42ce1261v5k57i9.png-821.8kB"></p>
<ol>
<li>第一步必然是准备一个ResultPartition；</li>
<li>通知JobMaster；</li>
<li>JobMaster通知下游节点；如果下游节点尚未部署，则部署之；</li>
<li>下游节点向上游请求数据</li>
<li>开始传输数据</li>
</ol>
<h4 id="6-2-2-数据跨task传递"><a href="#6-2-2-数据跨task传递" class="headerlink" title="6.2.2 数据跨task传递"></a>6.2.2 数据跨task传递</h4><p>本节讲一下算子之间具体的数据传输过程。也先上一张图：<br><img src="http://static.zybuluo.com/bethunebtj/d9pmni04fg8i11xotv4xqxh7/image_1cfmpba9v15anggtvsba2o1277m.png" alt="image_1cfmpba9v15anggtvsba2o1277m.png-357.5kB"><br>数据在task之间传递有如下几步：</p>
<ol>
<li>数据在本operator处理完后，交给<code>RecordWriter</code>。每条记录都要选择一个下游节点，所以要经过<code>ChannelSelector</code>。</li>
<li>每个channel都有一个serializer（我认为这应该是为了避免多线程写的麻烦），把这条Record序列化为ByteBuffer</li>
<li>接下来数据被写入ResultPartition下的各个subPartition里，此时该数据已经存入DirectBuffer（MemorySegment）</li>
<li>单独的线程控制数据的flush速度，一旦触发flush，则通过Netty的nio通道向对端写入</li>
<li>对端的netty client接收到数据，decode出来，把数据拷贝到buffer里，然后通知<code>InputChannel</code></li>
<li>有可用的数据时，下游算子从阻塞醒来，从InputChannel取出buffer，再解序列化成record，交给算子执行用户代码</li>
</ol>
<p>数据在不同机器的算子之间传递的步骤就是以上这些。</p>
<p>了解了步骤之后，再来看一下部分关键代码：<br>首先是把数据交给recordwriter。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;RecordWriterOutput.java</span><br><span class="line">@Override</span><br><span class="line">public void collect(StreamRecord&lt;OUT&gt; record) &#123;</span><br><span class="line">	if (this.outputTag !&#x3D; null) &#123;</span><br><span class="line">		&#x2F;&#x2F; we are only responsible for emitting to the main input</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">       &#x2F;&#x2F;这里可以看到把记录交给了recordwriter</span><br><span class="line">	pushToRecordWriter(record);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后recordwriter把数据发送到对应的通道。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;RecordWriter.java</span><br><span class="line">public void emit(T record) throws IOException, InterruptedException &#123;</span><br><span class="line">    &#x2F;&#x2F;channelselector登场了</span><br><span class="line">	for (int targetChannel : channelSelector.selectChannels(record, numChannels)) &#123;</span><br><span class="line">		sendToTarget(record, targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	private void sendToTarget(T record, int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	</span><br><span class="line">	&#x2F;&#x2F;选择序列化器并序列化数据</span><br><span class="line">	RecordSerializer&lt;T&gt; serializer &#x3D; serializers[targetChannel];</span><br><span class="line"></span><br><span class="line">	SerializationResult result &#x3D; serializer.addRecord(record);</span><br><span class="line"></span><br><span class="line">	while (result.isFullBuffer()) &#123;</span><br><span class="line">		if (tryFinishCurrentBufferBuilder(targetChannel, serializer)) &#123;</span><br><span class="line">			&#x2F;&#x2F; If this was a full record, we are done. Not breaking</span><br><span class="line">			&#x2F;&#x2F; out of the loop at this point will lead to another</span><br><span class="line">			&#x2F;&#x2F; buffer request before breaking out (that would not be</span><br><span class="line">			&#x2F;&#x2F; a problem per se, but it can lead to stalls in the</span><br><span class="line">			&#x2F;&#x2F; pipeline).</span><br><span class="line">			if (result.isFullRecord()) &#123;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		BufferBuilder bufferBuilder &#x3D; requestNewBufferBuilder(targetChannel);</span><br><span class="line"></span><br><span class="line">           &#x2F;&#x2F;写入channel</span><br><span class="line">		result &#x3D; serializer.continueWritingWithNextBufferBuilder(bufferBuilder);</span><br><span class="line">	&#125;</span><br><span class="line">	checkState(!serializer.hasSerializedData(), &quot;All data should be written at once&quot;);</span><br><span class="line"></span><br><span class="line">	if (flushAlways) &#123;</span><br><span class="line">		targetPartition.flush(targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来是把数据推给底层设施（netty）的过程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;ResultPartition.java</span><br><span class="line">@Override</span><br><span class="line">public void flushAll() &#123;</span><br><span class="line">	for (ResultSubpartition subpartition : subpartitions) &#123;</span><br><span class="line">		subpartition.flush();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;PartitionRequestQueue.java</span><br><span class="line">	void notifyReaderNonEmpty(final NetworkSequenceViewReader reader) &#123;</span><br><span class="line">	&#x2F;&#x2F;这里交给了netty server线程去推</span><br><span class="line">	ctx.executor().execute(new Runnable() &#123;</span><br><span class="line">		@Override</span><br><span class="line">		public void run() &#123;</span><br><span class="line">			ctx.pipeline().fireUserEventTriggered(reader);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>netty相关的部分：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;AbstractChannelHandlerContext.java</span><br><span class="line">public ChannelHandlerContext fireUserEventTriggered(final Object event) &#123;</span><br><span class="line">    if (event &#x3D;&#x3D; null) &#123;</span><br><span class="line">        throw new NullPointerException(&quot;event&quot;);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        final AbstractChannelHandlerContext next &#x3D; this.findContextInbound();</span><br><span class="line">        EventExecutor executor &#x3D; next.executor();</span><br><span class="line">        if (executor.inEventLoop()) &#123;</span><br><span class="line">            next.invokeUserEventTriggered(event);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            executor.execute(new OneTimeTask() &#123;</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    next.invokeUserEventTriggered(event);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return this;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后真实的写入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;PartittionRequesetQueue.java</span><br><span class="line">private void enqueueAvailableReader(final NetworkSequenceViewReader reader) throws Exception &#123;</span><br><span class="line">	if (reader.isRegisteredAsAvailable() || !reader.isAvailable()) &#123;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F; Queue an available reader for consumption. If the queue is empty,</span><br><span class="line">	&#x2F;&#x2F; we try trigger the actual write. Otherwise this will be handled by</span><br><span class="line">	&#x2F;&#x2F; the writeAndFlushNextMessageIfPossible calls.</span><br><span class="line">	boolean triggerWrite &#x3D; availableReaders.isEmpty();</span><br><span class="line">	registerAvailableReader(reader);</span><br><span class="line"></span><br><span class="line">	if (triggerWrite) &#123;</span><br><span class="line">		writeAndFlushNextMessageIfPossible(ctx.channel());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void writeAndFlushNextMessageIfPossible(final Channel channel) throws IOException &#123;</span><br><span class="line">	</span><br><span class="line">       ......</span><br><span class="line"></span><br><span class="line">			next &#x3D; reader.getNextBuffer();</span><br><span class="line">			if (next &#x3D;&#x3D; null) &#123;</span><br><span class="line">				if (!reader.isReleased()) &#123;</span><br><span class="line">					continue;</span><br><span class="line">				&#125;</span><br><span class="line">				markAsReleased(reader.getReceiverId());</span><br><span class="line"></span><br><span class="line">				Throwable cause &#x3D; reader.getFailureCause();</span><br><span class="line">				if (cause !&#x3D; null) &#123;</span><br><span class="line">					ErrorResponse msg &#x3D; new ErrorResponse(</span><br><span class="line">						new ProducerFailedException(cause),</span><br><span class="line">						reader.getReceiverId());</span><br><span class="line"></span><br><span class="line">					ctx.writeAndFlush(msg);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				&#x2F;&#x2F; This channel was now removed from the available reader queue.</span><br><span class="line">				&#x2F;&#x2F; We re-add it into the queue if it is still available</span><br><span class="line">				if (next.moreAvailable()) &#123;</span><br><span class="line">					registerAvailableReader(reader);</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				BufferResponse msg &#x3D; new BufferResponse(</span><br><span class="line">					next.buffer(),</span><br><span class="line">					reader.getSequenceNumber(),</span><br><span class="line">					reader.getReceiverId(),</span><br><span class="line">					next.buffersInBacklog());</span><br><span class="line"></span><br><span class="line">				if (isEndOfPartitionEvent(next.buffer())) &#123;</span><br><span class="line">					reader.notifySubpartitionConsumed();</span><br><span class="line">					reader.releaseAllResources();</span><br><span class="line"></span><br><span class="line">					markAsReleased(reader.getReceiverId());</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; Write and flush and wait until this is done before</span><br><span class="line">				&#x2F;&#x2F; trying to continue with the next buffer.</span><br><span class="line">				channel.writeAndFlush(msg).addListener(writeListener);</span><br><span class="line"></span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面这段代码里第二个方法中调用的<code>writeAndFlush(msg)</code>就是真正往netty的nio通道里写入的地方了。在这里，写入的是一个RemoteInputChannel，对应的就是下游节点的InputGate的channels。</p>
<p>有写就有读，nio通道的另一端需要读入buffer，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;CreditBasedPartitionRequestClientHandler.java</span><br><span class="line">private void decodeMsg(Object msg) throws Throwable &#123;</span><br><span class="line">	final Class&lt;?&gt; msgClazz &#x3D; msg.getClass();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; ---- Buffer --------------------------------------------------------</span><br><span class="line">	if (msgClazz &#x3D;&#x3D; NettyMessage.BufferResponse.class) &#123;</span><br><span class="line">		NettyMessage.BufferResponse bufferOrEvent &#x3D; (NettyMessage.BufferResponse) msg;</span><br><span class="line"></span><br><span class="line">		RemoteInputChannel inputChannel &#x3D; inputChannels.get(bufferOrEvent.receiverId);</span><br><span class="line">		if (inputChannel &#x3D;&#x3D; null) &#123;</span><br><span class="line">			bufferOrEvent.releaseBuffer();</span><br><span class="line"></span><br><span class="line">			cancelRequestFor(bufferOrEvent.receiverId);</span><br><span class="line"></span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		decodeBufferOrEvent(inputChannel, bufferOrEvent);</span><br><span class="line"></span><br><span class="line">	&#125; </span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>插一句，Flink其实做阻塞和获取数据的方式非常自然，利用了生产者和消费者模型，当获取不到数据时，消费者自然阻塞；当数据被加入队列，消费者被notify。Flink的背压机制也是借此实现。</p>
<p>然后在这里又反序列化成<code>StreamRecord</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;StreamElementSerializer.java</span><br><span class="line">public StreamElement deserialize(DataInputView source) throws IOException &#123;</span><br><span class="line">	int tag &#x3D; source.readByte();</span><br><span class="line">	if (tag &#x3D;&#x3D; TAG_REC_WITH_TIMESTAMP) &#123;</span><br><span class="line">		long timestamp &#x3D; source.readLong();</span><br><span class="line">		return new StreamRecord&lt;T&gt;(typeSerializer.deserialize(source), timestamp);</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_REC_WITHOUT_TIMESTAMP) &#123;</span><br><span class="line">		return new StreamRecord&lt;T&gt;(typeSerializer.deserialize(source));</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_WATERMARK) &#123;</span><br><span class="line">		return new Watermark(source.readLong());</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_STREAM_STATUS) &#123;</span><br><span class="line">		return new StreamStatus(source.readInt());</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_LATENCY_MARKER) &#123;</span><br><span class="line">		return new LatencyMarker(source.readLong(), new OperatorID(source.readLong(), source.readLong()), source.readInt());</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		throw new IOException(&quot;Corrupt stream, found tag: &quot; + tag);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后再次在<code>StreamInputProcessor.processInput()</code>循环中得到处理。</p>
<p>至此，数据在跨jvm的节点之间的流转过程就讲完了。</p>
<h3 id="6-3-Credit漫谈"><a href="#6-3-Credit漫谈" class="headerlink" title="6.3 Credit漫谈"></a>6.3 Credit漫谈</h3><p>在看上一部分的代码时，有一个小细节不知道读者有没有注意到，我们的数据发送端的代码叫做<code>PartittionRequesetQueue.java</code>，而我们的接收端却起了一个完全不相干的名字：<code>CreditBasedPartitionRequestClientHandler.java</code>。为什么前面加了CreditBased的前缀呢？</p>
<h4 id="6-3-1-背压问题"><a href="#6-3-1-背压问题" class="headerlink" title="6.3.1 背压问题"></a>6.3.1 背压问题</h4><p>在流模型中，我们期待数据是像水流一样平滑的流过我们的引擎，但现实生活不会这么美好。数据的上游可能因为各种原因数据量暴增，远远超出了下游的瞬时处理能力（回忆一下98年大洪水），导致系统崩溃。<br>那么框架应该怎么应对呢？和人类处理自然灾害的方式类似，我们修建了三峡大坝，当洪水来临时把大量的水囤积在大坝里；对于Flink来说，就是在数据的接收端和发送端放置了缓存池，用以缓冲数据，并且设置闸门阻止数据向下流。</p>
<p>那么Flink又是如何处理背压的呢？答案也是靠这些缓冲池。<br><img src="http://static.zybuluo.com/bethunebtj/1r40q9nbeuxh4j0omiic5tob/image_1cfksrl5cd4m1lbqqqgvc811349.png" alt="image_1cfksrl5cd4m1lbqqqgvc811349.png-43.1kB"><br>这张图说明了Flink在生产和消费数据时的大致情况。<code>ResultPartition</code>和<code>InputGate</code>在输出和输入数据时，都要向<code>NetworkBufferPool</code>申请一块<code>MemorySegment</code>作为缓存池。<br>接下来的情况和生产者消费者很类似。当数据发送太多，下游处理不过来了，那么首先InputChannel会被填满，然后是InputChannel能申请到的内存达到最大，于是下游停止读取数据，上游负责发送数据的nettyServer会得到响应，停止从ResultSubPartition读取缓存，那么ResultPartition很快也将存满数据不能被消费，从而生产数据的逻辑被阻塞在获取新buffer上，非常自然地形成背压的效果。</p>
<p>Flink自己做了个试验用以说明这个机制的效果：<br><img src="http://static.zybuluo.com/bethunebtj/xxqpmehf1w4un8leyc9itr9y/image_1cfkta54rkdd1od4aau1e3n7nhm.png" alt="image_1cfkta54rkdd1od4aau1e3n7nhm.png-240.6kB"><br>我们首先设置生产者的发送速度为60%，然后下游的算子以同样的速度处理数据。然后我们将下游算子的处理速度降低到30%，可以看到上游的生产者的数据产生曲线几乎与消费者同步下滑。而后当我们解除限速，整个流的速度立刻提高到了100%。</p>
<h4 id="6-3-2-使用Credit实现ATM网络流控"><a href="#6-3-2-使用Credit实现ATM网络流控" class="headerlink" title="6.3.2 使用Credit实现ATM网络流控"></a>6.3.2 使用Credit实现ATM网络流控</h4><p>上文已经提到，对于流量控制，一个朴素的思路就是在<del>长江上建三峡</del>链路上建立一个拦截的dam，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/1wc3o2qo6ozsyxqebnn2xw0j/image_1cfku114lf7hpqf3lmcl0116c13.png" alt="image_1cfku114lf7hpqf3lmcl0116c13.png-22.7kB"><br>基于Credit的流控就是这样一种建立在信用（消费数据的能力)上的，面向每个虚链路（而非端到端的）流模型，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/on4kd4bzvoozbo6yk6n2but6/image_1cfku4g4g174d7gb5ecbfcib71g.png" alt="image_1cfku4g4g174d7gb5ecbfcib71g.png-22.5kB"><br>首先，下游会向上游发送一条credit message，用以通知其目前的信用（可联想信用卡的可用额度），然后上游会根据这个信用消息来决定向下游发送多少数据。当上游把数据发送给下游时，它就从下游的信用卡上划走相应的额度（credit balance）：<br><img src="http://static.zybuluo.com/bethunebtj/i8t1qvlib162x1i6lm0qruju/image_1cfkug5sm1v4l15pbgj4jntc7q1t.png" alt="image_1cfkug5sm1v4l15pbgj4jntc7q1t.png-12.9kB"><br>下游总共获得的credit数目是Buf_Alloc，已经消费的数据是Fwd_Cnt，上游发送出来的数据是Tx_Cnt，那么剩下的那部分就是Crd_Bal:<br>Crd_Bal = Buf_Alloc - ( Tx_Cnt - Fwd_Cnt )<br>上面这个式子应该很好理解。</p>
<p>可以看到，Credit Based Flow Control的关键是buffer分配。这种分配可以在数据的发送端完成，也可以在接收端完成。对于下游可能有多个上游节点的情况（比如Flink），使用接收端的credit分配更加合理：<br><img src="http://static.zybuluo.com/bethunebtj/o09mav0lfnk7iqar98iphr7o/image_1cfkvpmlh1gl31ef41cvh1c903a19.png" alt="image_1cfkvpmlh1gl31ef41cvh1c903a19.png-13.1kB"><br>上图中，接收者可以观察到每个上游连接的带宽情况，而上游的节点Snd1却不可能轻易知道发往同一个下游节点的其他Snd2的带宽情况，从而如果在上游控制流量将会很困难，而在下游控制流量将会很方便。</p>
<p>因此，这就是为何Flink在接收端有一个基于Credit的Client，而不是在发送端有一个CreditServer的原因。</p>
<p>最后，再讲一下Credit的面向虚链路的流设计和端到端的流设计的区别：<br><img src="http://static.zybuluo.com/bethunebtj/1mm2eqnuop9rcccap915qrzx/image_1cfl05d2f1ub879c1lc5qsq14n9m.png" alt="image_1cfl05d2f1ub879c1lc5qsq14n9m.png-13.4kB"><br>如上图所示，a是面向连接的流设计，b是端到端的流设计。其中，a的设计使得当下游节点3因某些情况必须缓存数据暂缓处理时，每个上游节点（1和2）都可以利用其缓存保存数据；而端到端的设计b里，只有节点3的缓存才可以用于保存数据（读者可以从如何实现上想想为什么）。</p>
<p>对流控制感兴趣的读者，可以看这篇文章：<a target="_blank" rel="noopener" href="https://www.nap.edu/read/5769/chapter/1">Traffic Management For High-Speed Networks</a>。</p>
<h2 id="7-其他核心概念"><a href="#7-其他核心概念" class="headerlink" title="7.其他核心概念"></a>7.其他核心概念</h2><p>截至第六章，和执行过程相关的部分就全部讲完，告一段落了。第七章主要讲一点杂七杂八的内容，有时间就不定期更新。</p>
<h3 id="7-1-EventTime时间模型"><a href="#7-1-EventTime时间模型" class="headerlink" title="7.1 EventTime时间模型"></a>7.1 EventTime时间模型</h3><p>flink有三种时间模型：ProcessingTime，EventTime和IngestionTime。<br>关于时间模型看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/kcp52h1se5xzocfqcigcv9oh/image_1cdbotdcmoe11q961st5lbn1j4n9.png" alt="image_1cdbotdcmoe11q961st5lbn1j4n9.png-38.4kB"><br>从这张图里可以很清楚的看到三种Time模型的区别。</p>
<ul>
<li>EventTime是数据被生产出来的时间，可以是比如传感器发出信号的时间等（此时数据还没有被传输给flink）。</li>
<li>IngestionTime是数据进入flink的时间，也就是从Source进入flink流的时间（此时数据刚刚被传给flink）</li>
<li>ProcessingTime是针对当前算子的系统时间，是指该数据已经进入某个operator时，operator所在系统的当前时间</li>
</ul>
<p>例如，我在写这段话的时间是2018年5月13日03点47分，但是我引用的这张EventTime的图片，是2015年画出来的，那么这张图的EventTime是2015年，而ProcessingTime是现在。<br>Flink官网对于时间戳的解释非常详细：<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-master/dev/event_time.html">点我</a><br>Flink对于EventTime模型的实现，依赖的是一种叫做<code>watermark</code>的对象。watermark是携带有时间戳的一个对象，会按照程序的要求被插入到数据流中，用以标志某个事件在该时间发生了。<br>我再做一点简短的说明，还是以官网的图为例：<br><img src="http://static.zybuluo.com/bethunebtj/f4k8110qo8arjey5zbp75xz3/image_1cdbt8v5jl2ujn91uu1joh1p4gm.png" alt="image_1cdbt8v5jl2ujn91uu1joh1p4gm.png-11.3kB"><br>对于有序到来的数据，假设我们在timestamp为11的元素后加入一个watermark，时间记录为11，则下个元素收到该watermark时，认为所有早于11的元素均已到达。这是非常理想的情况。<br><img src="http://static.zybuluo.com/bethunebtj/3aqwmrc5hg054b09z47lwsvp/image_1cdbtcc5c1a6i1tuaadb1rd5136913.png" alt="image_1cdbtcc5c1a6i1tuaadb1rd5136913.png-11.6kB"><br>而在现实生活中，经常会遇到乱序的数据。这时，我们虽然在timestamp为7的元素后就收到了11，但是我们一直等到了收到元素12之后，才插入了watermark为11的元素。与上面的图相比，如果我们仍然在11后就插入11的watermark，那么元素9就会被丢弃，造成数据丢失。而我们在12之后插入watermark11，就保证了9仍然会被下一个operator处理。当然，我们不可能无限制的永远等待迟到元素，所以要在哪个元素后插入11需要根据实际场景权衡。</p>
<p>对于来自多个数据源的watermark，可以看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/pu1cr48mq9340g5embaig9b5/image_1cdbufp4a1opmsit5n61mial4520.png" alt="image_1cdbufp4a1opmsit5n61mial4520.png-72kB"><br>可以看到，当一个operator收到多个watermark时，它遵循最小原则（或者说最早），即算子的当前watermark是流经该算子的最小watermark，以容许来自不同的source的乱序数据到来。<br>关于事件时间模型，更多内容可以参考<a target="_blank" rel="noopener" href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101">Stream 101</a> 和谷歌的这篇论文：<a target="_blank" rel="noopener" href="https://research.google.com/pubs/archive/43864.pdf">Dataflow Model paper</a></p>
<h3 id="7-2-FLIP-6-部署及处理模型演进"><a href="#7-2-FLIP-6-部署及处理模型演进" class="headerlink" title="7.2 FLIP-6 部署及处理模型演进"></a>7.2 FLIP-6 部署及处理模型演进</h3><p>就在老白写这篇blog的时候，Flink发布了其1.5 RELEASE版本，号称实现了其部署及处理模型（也就是FLIP-6)，所以打算简略地说一下FLIP-6的主要内容。</p>
<h4 id="7-2-1-现有模型不足"><a href="#7-2-1-现有模型不足" class="headerlink" title="7.2.1 现有模型不足"></a>7.2.1 现有模型不足</h4><p>1.5之前的Flink模型有很多不足，包括：</p>
<ul>
<li>只能静态分配计算资源</li>
<li>在YARN上所有的资源分配都是一碗水端平的</li>
<li>与Docker/k8s的集成非常之蠢，颇有脱裤子放屁的神韵</li>
<li>JobManager没有任务调度逻辑</li>
<li>任务在YARN上执行结束后web dashboard就不可用</li>
<li>集群的session模式和per job模式混淆难以理解</li>
</ul>
<p>就我个人而言，我觉得Flink有一个这里完全没提到的不足才是最应该修改的：针对任务的完全的资源隔离。尤其是如果用Standalone集群，一个用户的task跑挂了TaskManager，然后拖垮了整个集群的情况简直不要太多。</p>
<h4 id="7-2-2-核心变更"><a href="#7-2-2-核心变更" class="headerlink" title="7.2.2 核心变更"></a>7.2.2 核心变更</h4><p><strong>Single Job JobManager</strong><br>最重要的变更是一个JobManager只处理一个job。当我们生成JobGraph时就顺便起一个JobManager，这显然更加自然。</p>
<p><strong>ResourceManager</strong><br>其职责包括获取新的TM和slot，通知失败，释放资源以及缓存TM以用于重用等。重要的是，这个组件要能做到挂掉时不要搞垮正在运行的好好的任务。其职责和与JobManager、TaskManager的交互图如下：<br><img src="http://static.zybuluo.com/bethunebtj/pzuvevivascmk2xky450ll87/image_1cfl9453k1gld4acr1m13j3195sg.png" alt="image_1cfl9453k1gld4acr1m13j3195sg.png-23.9kB"></p>
<p><strong>TaskManager</strong><br>TM要与上面的两个组件交互。与JobManager交互时，要能提供slot，要能与所有给出slot的JM交互。丢失与JM的连接时要能试图把本TM上的slot的情况通告给新JM，如果这一步失败，就要能重新分配slot。<br>与ResourceManager交互时，要通知RM自己的资源和当前的Job分配情况，能按照RM的要求分配资源或者关闭自身。</p>
<p><strong>JobManager Slot Pool</strong><br>这个pool要持有所有分配给当前job的slot资源，并且能在RM挂掉的情况下管理当前已经持有的slot。</p>
<p><strong>Dispatcher</strong><br>需要一个Job的分发器的主要原因是在有的集群环境下我们可能需要一个统一的提交和监控点，以及替代之前的Standalone模式下的JobManager。将来对分发器的期望可能包括权限控制等。<br><img src="http://static.zybuluo.com/bethunebtj/on7x5expzpyvtyqvkjm1si9e/image_1cfl9ju2617bh1s191mar1jsp12vot.png" alt="image_1cfl9ju2617bh1s191mar1jsp12vot.png-31.4kB"></p>
<h4 id="7-2-3-Cluster-Manager的架构"><a href="#7-2-3-Cluster-Manager的架构" class="headerlink" title="7.2.3 Cluster Manager的架构"></a>7.2.3 Cluster Manager的架构</h4><p><strong>YARN</strong><br>新的基于YARN的架构主要包括不再需要先在容器里启动集群，然后提交任务；用户代码不再使用动态ClassLoader加载；不用的资源可以释放；可以按需分配不同大小的容器等。其执行过程如下：<br>无Dispatcher时<br><img src="http://static.zybuluo.com/bethunebtj/w3z5qz98tq5q4jtndka8kdhp/image_1cfla0n7u1lg21n3o36uu0c1o5h1a.png" alt="image_1cfla0n7u1lg21n3o36uu0c1o5h1a.png-46.2kB"><br>有Dispatcher时<br><img src="http://static.zybuluo.com/bethunebtj/ukhd6f3480du2nsx2wnl56g3/image_1cfla15os15i3qcsu6c4p4clk1n.png" alt="image_1cfla15os15i3qcsu6c4p4clk1n.png-50.7kB"></p>
<p><strong>Mesos</strong><br>与基于YARN的模式很像，但是只有带Dispatcher模式，因为只有这样才能在Mesos集群里跑其RM。<br><img src="http://static.zybuluo.com/bethunebtj/k0b95bqzs9crsj2jwk8oy33n/image_1cfla4tka101n18bf1mno4npu9s24.png" alt="image_1cfla4tka101n18bf1mno4npu9s24.png-49.2kB"><br>Mesos的Fault Tolerance是类似这样的：<br><img src="http://static.zybuluo.com/bethunebtj/app8m86al53shk2a83w14x0r/image_1cfla6eka1ph71mu1pll1q0mgqq2h.png" alt="image_1cfla6eka1ph71mu1pll1q0mgqq2h.png-12.1kB"><br>必须用类似Marathon之类的技术保证Dispatcher的HA。</p>
<p><strong>Standalone</strong><br>其实没啥可说的，把以前的JobManager的职责换成现在的Dispatcher就行了。<br><img src="http://static.zybuluo.com/bethunebtj/nn4vbn25yojf3vq80yffr20v/image_1cflaaim2ih2v54umsmq01lqc2u.png" alt="image_1cflaaim2ih2v54umsmq01lqc2u.png-36.8kB"><br>将来可能会实现一个类似于轻量级Yarn的模式。</p>
<p><strong>Docker/k8s</strong><br>用户定义好容器，至少有一个是job specific的（不然怎么启动任务）；还有用于启动TM的，可以不是job specific的。启动过程如下<br><img src="http://static.zybuluo.com/bethunebtj/vcow51koxy17wd3qxj60y4lj/image_1cflafs2o1trgicjmdbndn1bdq3b.png" alt="image_1cflafs2o1trgicjmdbndn1bdq3b.png-24.2kB"></p>
<h4 id="7-2-4-组件设计及细节"><a href="#7-2-4-组件设计及细节" class="headerlink" title="7.2.4 组件设计及细节"></a>7.2.4 组件设计及细节</h4><p><strong>分配slot相关细节</strong><br>从新的TM取slot过程：<br><img src="http://static.zybuluo.com/bethunebtj/r1anoecf2er16nuh3h9r9jb8/image_1cflakoadvjm8pf6nt1k331qj33o.png" alt="image_1cflakoadvjm8pf6nt1k331qj33o.png-77.2kB"></p>
<p>从Cached TM取slot过程：<br><img src="http://static.zybuluo.com/bethunebtj/2uyr1ynvj8ieqi8rth8h8bub/image_1cflambu91ufi5fl1cg9gimdff45.png" alt="image_1cflambu91ufi5fl1cg9gimdff45.png-63.4kB"></p>
<p><strong>失败处理</strong></p>
<ol>
<li><p>TM失败<br>TM失败时，RM要能检测到失败，更新自己的状态，发送消息给JM，重启一份TM；JM要能检测到失败，从状态移除失效slot，标记该TM的task为失败，并在没有足够slot继续任务时调整规模；TM自身则要能从Checkpoint恢复</p>
</li>
<li><p>RM失败<br>此时TM要能检测到失败，并准备向新的RM注册自身，并且向新的RM传递自身的资源情况；JM要能检测到失败并且等待新的RM可用，重新请求需要的资源；丢失的数据要能从Container、TM等处恢复。</p>
</li>
<li><p>JM失败<br>TM释放所有task，向新JM注册资源，并且如果不成功，就向RM报告这些资源可用于重分配；RM坐等；JM丢失的数据从持久化存储中获得，已完成的checkpoints从HA恢复，从最近的checkpoint重启task，并申请资源。</p>
</li>
<li><p>JM &amp; RM 失败<br>TM将在一段时间内试图把资源交给新上任的JM，如果失败，则把资源交给新的RM</p>
</li>
<li><p>TM &amp; RM失败<br>JM如果正在申请资源，则要等到新的RM启动后才能获得；JM可能需要调整其规模，因为损失了TM的slot。</p>
</li>
</ol>
<h2 id="8-后记"><a href="#8-后记" class="headerlink" title="8.后记"></a>8.后记</h2><p>Flink是当前流处理领域的优秀框架，其设计思想和代码实现都蕴含着许多人的智慧结晶。这篇解读花了很多时间，篇幅也写了很长，也仍然不能能覆盖Flink的方方面面，也肯定有很多错误之处，欢迎大家批评指正！Flink生态里中文资料确实不多，对Flink源码有兴趣的读者，可以参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/yanghua_kobe/article/category/6170573/4">VinoYang的专栏</a>，继续学习之旅。</p>
<p>本文至此结束。</p>
<p>最后，欢迎关注我的微信公众号，一起交流技术，或者职业生涯？<br><img src="http://static.zybuluo.com/bethunebtj/daydmugl837tmw92klc6rqxz/image_1cfhqfqgt17r89b4156i1bni1hqq9.png" alt="老白讲互联网"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/01_tuner/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/01_tuner/" class="post-title-link" itemprop="url">Java性能调优</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h1><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>jhat<br>vmstat</p>
<h2 id="测试样例"><a href="#测试样例" class="headerlink" title="测试样例"></a>测试样例</h2><p>新docker container，全新的系统，以纯净的系统Centos为例</p>
<h3 id="安装java"><a href="#安装java" class="headerlink" title="安装java"></a>安装java</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装java8</span></span><br><span class="line">[root@centos ~]# yum install -y java-1.8.0-openjdk*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建deploy用户，用于折腾</span></span><br><span class="line">[root@centos ~]# useradd deploy</span><br><span class="line">[root@centos ~]# su deploy</span><br><span class="line">[root@centos ~]# cd</span><br></pre></td></tr></table></figure>


<h3 id="创建工作目录"><a href="#创建工作目录" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建并切换到工作目录</span></span><br><span class="line">[deploy@centos ~]$ mkdir -p lk-optimization</span><br><span class="line">[deploy@centos ~]$ cd !$</span><br></pre></td></tr></table></figure>
<p>创建package，用于存放java源文件和编译后的class文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[deploy@centos ~]$ mkdir -p src/com/lk/optimization/demo target</span><br><span class="line">[deploy@centos ~]$ vim !$/DemoTest.java</span><br></pre></td></tr></table></figure>
<h3 id="新建Java文件"><a href="#新建Java文件" class="headerlink" title="新建Java文件"></a>新建Java文件</h3><p>//        Thread thread = Thread.currentThread();</p>
<p>//        System.out.println(thread.getName());<br>//        thread.join();<br>        System.out.println(“join over”);</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lk.optimization.demo;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoTest</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] atgs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">		<span class="keyword">new</span> Handler().doHandle();</span><br><span class="line">		Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">				System.out.println(<span class="keyword">this</span>.getName() + <span class="string">&quot; is shutting down ....&quot;</span>);</span><br><span class="line">				&#125;</span><br><span class="line">				&#125;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doHandle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">			String workerName=<span class="string">&quot;worker-&quot;</span>+(i+<span class="number">1</span>);</span><br><span class="line">			<span class="keyword">new</span> Thread(<span class="keyword">new</span> Worker(workerName), <span class="string">&quot;handler-&quot;</span> + i).start();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> String workerName;</span><br><span class="line">	<span class="keyword">private</span> List&lt;String&gt; list;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Worker</span><span class="params">(String workerName)</span></span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.workerName=workerName;</span><br><span class="line">		<span class="keyword">this</span>.list=<span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">1000</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">			System.out.println(workerName+<span class="string">&quot; start!&quot;</span>);</span><br><span class="line">			<span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">				<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">100</span>;i++)&#123;</span><br><span class="line">					list.add(<span class="string">&quot;&quot;</span>+i);</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">if</span>(list.size()&gt;<span class="number">1000</span>)&#123;</span><br><span class="line">					list.clear();</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">try</span> &#123;</span><br><span class="line">					Thread.sleep(<span class="number">100</span>);</span><br><span class="line">					System.out.println(workerName+<span class="string">&quot;: sleep over&quot;</span>);</span><br><span class="line">				&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">					e.printStackTrace();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[deploy@centos ~]$ find src -name &quot;*.java&quot; | xargs javac -d target</span><br><span class="line"></span><br><span class="line">[deploy@centos ~]$ tree</span><br><span class="line">.</span><br><span class="line">├── src</span><br><span class="line">│   └── com</span><br><span class="line">│       └── lk</span><br><span class="line">│           └── optimization</span><br><span class="line">│               └── demo</span><br><span class="line">│                   └── DemoTest.java</span><br><span class="line">└── target</span><br><span class="line">    └── com</span><br><span class="line">        └── lk</span><br><span class="line">            └── optimization</span><br><span class="line">                └── demo</span><br><span class="line">                    ├── DemoTest$1.class</span><br><span class="line">                    ├── DemoTest.class</span><br><span class="line">                    ├── Handler.class</span><br><span class="line">                    └── Worker.class</span><br><span class="line"></span><br><span class="line">10 directories, 5 files</span><br></pre></td></tr></table></figure>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[deploy@centos ~]$ nohup java -cp target  -Xcomp -XX:MaxNewSize=1000000  -XX:MaxHeapSize=2000000 com.lk.optimization.demo.DemoTest &amp;</span><br><span class="line">main</span><br></pre></td></tr></table></figure>


<h2 id="ps-查看进程和线程信息"><a href="#ps-查看进程和线程信息" class="headerlink" title="ps 查看进程和线程信息"></a>ps 查看进程和线程信息</h2><p>ps命令选项:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">********* simple selection *********  ********* selection by list *********</span><br><span class="line">-A all processes                      -C by command name</span><br><span class="line">-N negate selection                   -G by real group ID (supports names)</span><br><span class="line">-a all w/ tty except session leaders  -U by real user ID (supports names)</span><br><span class="line">-d all except session leaders         -g by session OR by effective group name</span><br><span class="line">-e all processes                      -p by process ID</span><br><span class="line">T  all processes on this terminal     -s processes in the sessions given</span><br><span class="line">a  all w/ tty, including other users  -t by tty</span><br><span class="line">g  OBSOLETE -- DO NOT USE             -u by effective user ID (supports names)</span><br><span class="line">r  only running processes             U  processes for specified users</span><br><span class="line">x  processes w/o controlling ttys     t  by tty</span><br><span class="line">*********** output format **********  *********** long options ***********</span><br><span class="line">-o,o user-defined  -f full            --Group --User --pid --cols --ppid</span><br><span class="line">-j,j job control   s  signal          --group --user --sid --rows --info</span><br><span class="line">-O,O preloaded -o  v  virtual memory  --cumulative --format --deselect</span><br><span class="line">-l,l long          u  user-oriented   --sort --tty --forest --version</span><br><span class="line">-F   extra full    X  registers       --heading --no-heading --context</span><br><span class="line">                         ********* misc options *********</span><br><span class="line">-V,V  show version      L  list format codes  f  ASCII art forest</span><br><span class="line">-m,m,-L,-T,H  threads   S  children in sum    -y change -l format</span><br><span class="line">-M,Z  security data     c  true command name  -c scheduling class</span><br><span class="line">-w,w  wide output       n  numeric WCHAN,UID  -H process hierarchy</span><br></pre></td></tr></table></figure>


<p>root用户查看进程信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@centos ~]# ps -ef  | grep -v ps</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 13:16 ?        00:00:00 /usr/sbin/sshd -D</span><br><span class="line">root        14     0  0 13:23 pts/0    00:00:00 /bin/bash</span><br><span class="line">root       421     1  0 13:58 ?        00:00:00 sshd: root@pts/1</span><br><span class="line">root       423   421  0 13:58 pts/1    00:00:00 -bash</span><br><span class="line">root       461     1  0 14:15 ?        00:00:00 sshd: root@pts/2</span><br><span class="line">root       463   461  0 14:15 pts/2    00:00:00 -bash</span><br><span class="line">root       519     1  0 14:16 ?        00:00:00 sshd: root@pts/3</span><br><span class="line">root       521   519  0 14:16 pts/3    00:00:00 -bash</span><br><span class="line">root       785   423  0 14:59 pts/1    00:00:00 su deploy</span><br><span class="line">deploy     786   785  0 14:59 pts/1    00:00:00 bash</span><br><span class="line">deploy    1129   786  0 15:32 pts/1    00:00:02 java -cp target com.lk.optimization.demo.DemoTest</span><br></pre></td></tr></table></figure>
<p>ps 命令</p>
<ul>
<li>-e 显示所有进程信息</li>
<li>-f 显示所有的字段</li>
<li>-l long format</li>
<li>-L 显示NLWP (number of threads) and LWP (thread ID) 显示线程信息</li>
<li>-p 只显示指定的PID</li>
</ul>
<p>字段的解释可以在man页的<code>STANDARD FORMAT SPECIFIERS</code>中查找</p>
<p>默认情况下，ps显示与当前用户相同EUID以及调用了同一个终端的进程。</p>
<ul>
<li>PID是进程ID</li>
<li>TTY为与进程关联的终端名称</li>
<li>TIME为以<code>[dd-]hh:mm:ss</code>格式显示的CPU时间</li>
<li>CMD为执行的名称, 默认不排序</li>
<li>PPID为父进程ID，根据ID可以找到进程的调用关系</li>
</ul>
<p>样例中的进程信息:</p>
<table>
<thead>
<tr>
<th>进程id</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0号进程是根进程</td>
</tr>
<tr>
<td>1</td>
<td>通过sshd发起的ssh连接</td>
</tr>
<tr>
<td>421</td>
<td>ssh连接，用户为root，终端为pts/1，子进程全部这个终端</td>
</tr>
<tr>
<td>423</td>
<td>bash shell</td>
</tr>
<tr>
<td>785</td>
<td>切换deploy账户</td>
</tr>
<tr>
<td>786</td>
<td>deploy账户的bash shell</td>
</tr>
<tr>
<td>1129</td>
<td>java启动进程</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@centos ~]# ps -flL -p 1129</span><br><span class="line">F S UID        PID  PPID   LWP  C NLWP PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD</span><br><span class="line">0 S deploy    1129   786  1129  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">5 S deploy    1129   786  1130  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1131  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1132  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1133  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1134  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1135  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1136  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1137  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1138  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1139  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1140  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br></pre></td></tr></table></figure>
<h3 id="Process-Format"><a href="#Process-Format" class="headerlink" title="Process Format"></a>Process Format</h3><ol>
<li>F PROCESS FLAGS   1 forked但没有执行 5超级用户权限</li>
<li>S PROCESS STATE CODES<pre><code>D    Uninterruptible sleep (usually IO)
R    Running or runnable (on run queue)
S    Interruptible sleep (waiting for an event to complete)
T    Stopped, either by a job control signal or because it is being traced.
W    paging (not valid since the 2.6.xx kernel)
X    dead (should never be seen)
Z    Defunct (&quot;zombie&quot;) process, terminated but not reaped by its parent.</code></pre>
</li>
<li>lwp (light weight process, or thread) ID 线程ID</li>
<li>C  processor utilization. Currently, this is the integer value of the percent usage over the lifetime of the process.</li>
<li>NLWP 轻量级进程的个数</li>
<li>ni         NI       nice value. This ranges from 19 (nicest) to -20 (not nice to others)</li>
<li>size       SZ       approximate amount of swap space that would be required if the process were to dirty all writable pages and then be swapped out. This number is very rough!</li>
<li>wchan      WCHAN    name of the kernel function in which the process is sleeping, a “-“ if the process is running, or a “*” if the process is multi-threaded and ps is not displaying threads.</li>
</ol>
<h3 id="线程信息"><a href="#线程信息" class="headerlink" title="线程信息"></a>线程信息</h3><p>线程线程的选项:</p>
<ul>
<li>H     Show threads as if they were processes 显示正在处理的线程</li>
<li>-L     Show threads, possibly with LWP and NLWP columns 显示线程</li>
<li>-T     Show threads, possibly with SPID column 显示线程</li>
<li>m     Show threads after processes</li>
<li>-m    Show threads after processes</li>
</ul>
<p>通过上面的例子，可以看出</p>
<p>线程id是1129~1154, 共27个线程<br>实际handler线程和main线程加起来是11个，为什么是27个线程呢</p>
<h2 id="top-查看资源"><a href="#top-查看资源" class="headerlink" title="top 查看资源"></a>top 查看资源</h2><p>以线程模式查看下进程31951的所有线程情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top -Hp 31951</span><br></pre></td></tr></table></figure>
<p>![top-thread](images/20190728100827299_123372753.png =634x)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-H : Threads toggle</span><br><span class="line">            Starts  top with the last remembered ’H’ state reversed.  When this toggle is On, all individual threads will be displayed.  Otherwise, top displays a summation of all threads in a process. 当此开关打开时，将显示所有单个线程。否则，top显示进程中所有线程的总和。</span><br><span class="line"></span><br><span class="line">-p : Monitor PIDs as:  -pN1 -pN2 ...  or  -pN1, N2 [,...]</span><br><span class="line">            Monitor only processes with specified process IDs.  This option can be given up to 20 times, or you can provide a comma delimited list with up  to  20 pids.  Co-mingling both approaches is permitted. This  is  a  command-line  option  only.  And should you wish to return to normal operation, it is not necessary to quit and and restart top  --  just issue the ’&#x3D;’ interactive command.</span><br><span class="line">            打开top后，&#x3D; 可以切换回全部进程</span><br></pre></td></tr></table></figure>


<h2 id="jstack-Java线程栈信息"><a href="#jstack-Java线程栈信息" class="headerlink" title="jstack Java线程栈信息"></a>jstack Java线程栈信息</h2><p>jstack中的线程id为16进制，需要将从top或ps获取的线程id转换为16进制,</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">printf %x &lt;tid&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意:</p>
<ol>
<li>jstack必须和运行的JVM进程是同一个用户</li>
</ol>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">    -F  to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung)</span><br><span class="line">    -m  to print both java and native frames (mixed mode)</span><br><span class="line">    -l  long listing. Prints additional information about locks</span><br><span class="line">    -h or -help to print this help message</span><br></pre></td></tr></table></figure>
<h2 id="虚拟机信息flag"><a href="#虚拟机信息flag" class="headerlink" title="虚拟机信息flag"></a>虚拟机信息flag</h2><p>打印虚拟机所有的参数</p>
<p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html">java 命令文档</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">java -XX:+PrintFlagsFinal -version | grep :</span><br><span class="line">java -XX:+PrintFlagsInitial -version</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">java -XX:+PrintFlagsFinal -version | grep -v :&#x3D;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">The -XX:+PrintFlagsFinal (emphasis on &quot;Final&quot;) option displays what options HotSpot ended up using for running Java code while </span><br><span class="line">-XX:+PrintFlagsInitial (emphasis on &quot;Initial&quot;) displays what options were provided to HotSpot initially, before HotSpot has made its own tweaks.</span><br></pre></td></tr></table></figure>

<h2 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a>jinfo</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">jinfo -flags <span class="variable">$PID</span></span><br><span class="line"></span><br><span class="line">Attaching to process ID 29893, please <span class="built_in">wait</span>...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.  <span class="comment"># 服务器版本的编译器</span></span><br><span class="line">JVM version is 25.232-b09 <span class="comment"># jvm版本</span></span><br><span class="line">Non-default VM flags:</span><br><span class="line">-XX:CICompilerCount=2</span><br><span class="line">-XX:InitialHeapSize=33554432 <span class="comment"># 初始堆大小 33M</span></span><br><span class="line">-XX:MaxHeapSize=524288000 <span class="comment"># 最大堆大小 524M</span></span><br><span class="line">-XX:MaxNewSize=174718976  <span class="comment">#年轻代最大大小 174M</span></span><br><span class="line">-XX:MinHeapDeltaBytes=196608 <span class="comment">#堆自动增加步长最小196K</span></span><br><span class="line">-XX:NewSize=11141120  <span class="comment">#年轻代大小11M</span></span><br><span class="line">-XX:OldSize=22413312 <span class="comment">#老年代大小22M</span></span><br><span class="line">-XX:+UseCompressedClassPointers  <span class="comment">#压缩类指针</span></span><br><span class="line">-XX:+UseCompressedOops <span class="comment">#压缩</span></span><br><span class="line">-XX:+UseParallelGC <span class="comment"># 使用并行回收器</span></span><br><span class="line"></span><br><span class="line">Command line:</span><br></pre></td></tr></table></figure>
<h2 id="jstat查看jvm统计信息和垃圾回收信息"><a href="#jstat查看jvm统计信息和垃圾回收信息" class="headerlink" title="jstat查看jvm统计信息和垃圾回收信息"></a>jstat查看jvm统计信息和垃圾回收信息</h2><p>JVM statistics</p>
<p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jstat.html#BEHHGFAE">jstat docs</a></p>
<p><a target="_blank" rel="noopener" href="https://app.yinxiang.com/shard/s30/nl/6747836/1db66cb0-6a66-4766-84ba-5d5b51df1fd2">jstat 命令使用样例</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">➜ jstat -options</span><br><span class="line">-<span class="class"><span class="keyword">class</span> # <span class="title">classLoader</span>行为的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">compiler</span> #  <span class="title">Java</span> <span class="title">HotSpot</span> <span class="title">VM</span> <span class="title">Just</span>-<span class="title">in</span>-<span class="title">Time</span> <span class="title">compiler</span>行为的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">gc</span> # 垃圾回收堆的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">gccapacity</span> # 每代的大小和容量</span></span><br><span class="line"><span class="class">-<span class="title">gccause</span> # 垃圾收集统计及回收原因</span></span><br><span class="line"><span class="class">-<span class="title">gcmetacapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcnew</span></span></span><br><span class="line"><span class="class">-<span class="title">gcnewcapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcold</span></span></span><br><span class="line"><span class="class">-<span class="title">gcoldcapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcutil</span> # <span class="title">gc</span>统计信息汇总，展示<span class="title">gc</span>次数、耗时和各个分区的大小</span></span><br><span class="line"><span class="class">-<span class="title">printcompilation</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line">class: Displays statistics about the behavior of the class loader.</span><br><span class="line">compiler: Displays statistics about the behavior of the Java HotSpot VM Just-in-Time compiler.</span><br><span class="line">gc: Displays statistics about the behavior of the garbage collected heap.</span><br><span class="line">gccapacity: Displays statistics about the capacities of the generations and their corresponding spaces.</span><br><span class="line">gccause: <span class="function">Displays a summary about garbage collection <span class="title">statistics</span> <span class="params">(same as -gcutil)</span>, with the cause of the last and <span class="title">current</span> <span class="params">(when applicable)</span> garbage collection events.</span></span><br><span class="line"><span class="function">gcnew: Displays statistics of the behavior of the new generation.</span></span><br><span class="line"><span class="function">gcnewcapacity: Displays statistics about the sizes of the new generations and its corresponding spaces.</span></span><br><span class="line"><span class="function">gcold: Displays statistics about the behavior of the old generation and metaspace statistics.</span></span><br><span class="line"><span class="function">gcoldcapacity: Displays statistics about the sizes of the old generation.</span></span><br><span class="line"><span class="function">gcmetacapacity: Displays statistics about the sizes of the metaspace.</span></span><br><span class="line"><span class="function">gcutil: Displays a summary about garbage collection statistics.</span></span><br><span class="line"><span class="function">printcompilation: Displays Java HotSpot VM compilation method statistics.</span></span><br></pre></td></tr></table></figure>
<p>GC堆统计</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">jstat -gc <span class="number">12196</span></span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   </span><br><span class="line"><span class="number">512.0</span>  <span class="number">1024.0</span> <span class="number">496.0</span>   <span class="number">0.0</span>   <span class="number">67584.0</span>  <span class="number">38337.9</span>   <span class="number">437248.0</span>   <span class="number">75268.8</span>   <span class="number">83992.0</span> <span class="number">80411.0</span> <span class="number">9496.0</span> <span class="number">8854.4</span>    <span class="number">388</span>    <span class="number">5.643</span>   <span class="number">3</span>      <span class="number">0.390</span>    <span class="number">6.033</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-gc option</span><br><span class="line">Garbage-collected heap statistics.</span><br><span class="line"></span><br><span class="line">S0C: Current survivor space 0 capacity (kB).   #s0区当前容量</span><br><span class="line">S1C: Current survivor space 1 capacity (kB). #s1区当前容量</span><br><span class="line">S0U: Survivor space 0 utilization (kB). #s0区使用量</span><br><span class="line">S1U: Survivor space 1 utilization (kB). #s1区使用量</span><br><span class="line">EC: <span class="function">Current eden space <span class="title">capacity</span> <span class="params">(kB)</span>. #eden区容量</span></span><br><span class="line"><span class="function">EU: Eden space <span class="title">utilization</span> <span class="params">(kB)</span>. #eden区使用量</span></span><br><span class="line"><span class="function">OC: Current old space <span class="title">capacity</span> <span class="params">(kB)</span>. #old区容量</span></span><br><span class="line"><span class="function">OU: Old space <span class="title">utilization</span> <span class="params">(kB)</span>. #old区使用量</span></span><br><span class="line"><span class="function">MC: Metaspace <span class="title">capacity</span> <span class="params">(kB)</span>. #metaspace容量</span></span><br><span class="line"><span class="function">MU: Metacspace <span class="title">utilization</span> <span class="params">(kB)</span>. #metaspace使用量</span></span><br><span class="line"><span class="function">CCSC: Compressed class space <span class="title">capacity</span> <span class="params">(kB)</span>. #压缩类空间容量</span></span><br><span class="line"><span class="function">CCSU: Compressed class space <span class="title">used</span> <span class="params">(kB)</span>. #压缩类空间使用量</span></span><br><span class="line"><span class="function">YGC: Number of young generation garbage collection events.  # YGC次数</span></span><br><span class="line"><span class="function">YGCT: Young generation garbage collection time. #YGC耗时</span></span><br><span class="line"><span class="function">FGC: Number of full GC events. # Full GC次数</span></span><br><span class="line"><span class="function">FGCT: Full garbage collection time. # Full GC耗时</span></span><br><span class="line"><span class="function">GCT: Total garbage collection time. # GC总耗时</span></span><br></pre></td></tr></table></figure>
<p>GC统计</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jstat -gcutil <span class="number">12196</span></span><br><span class="line">  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> <span class="number">96.88</span>   <span class="number">0.00</span>  <span class="number">89.96</span>  <span class="number">17.21</span>  <span class="number">95.74</span>  <span class="number">93.24</span>    <span class="number">388</span>    <span class="number">5.643</span>     <span class="number">3</span>    <span class="number">0.390</span>    <span class="number">6.033</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">-gcutil option</span><br><span class="line">Summary of garbage collection statistics.</span><br><span class="line"></span><br><span class="line">S0: Survivor space <span class="number">0</span> utilization as a percentage of the space<span class="string">&#x27;s current capacity. # s0区使用率</span></span><br><span class="line">S1: Survivor space 1 utilization as a percentage of the space&#x27;s current capacity. # S1区使用率</span><br><span class="line">E: Eden space utilization as a percentage of the space<span class="string">&#x27;s current capacity. # eden区使用率</span></span><br><span class="line">O: Old space utilization as a percentage of the space&#x27;s current capacity. # old区使用率</span><br><span class="line">M: Metaspace utilization as a percentage of the space<span class="string">&#x27;s current capacity. # Metaspace使用率</span></span><br><span class="line"><span class="string">CCS: Compressed class space utilization as a percentage. # 压缩类空间使用率</span></span><br><span class="line"><span class="string">YGC: Number of young generation GC events. # YGC次数</span></span><br><span class="line"><span class="string">YGCT: Young generation garbage collection time. # YGC耗时</span></span><br><span class="line"><span class="string">FGC: Number of full GC events. # Full GC次数</span></span><br><span class="line"><span class="string">FGCT: Full garbage collection time. # Full GC耗时</span></span><br><span class="line"><span class="string">GCT: Total garbage collection time. # GC总耗时</span></span><br></pre></td></tr></table></figure>

<h2 id="堆dump"><a href="#堆dump" class="headerlink" title="堆dump"></a>堆dump</h2><p>full gc前后dump</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -XX:HeapDumpPath=./heap/ -XX:+HeapDumpOnOutOfMemoryError -XX:+HeapDumpAfterFullGC</span><br></pre></td></tr></table></figure>
<p><code>HeapDumpPath</code>: dump path<br><code>HeapDumpOnOutOfMemoryError</code> 内存溢出dump<br><code>HeapDumpAfterFullGC</code>、<code>HeapDumpBeforeFullGC</code> ：Full GC前后dump</p>
<h3 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h3><p>Prints shared object memory maps or heap memory details for a process, core file, or remote debug server. This command is experimental and unsupported.<br>打印进程、核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息</p>
<p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jmap.html#BEHHGFAE">jmap docs</a></p>
<p>jmap -heap <pid></p>
<p>堆的各个分区大小</p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000010648021">堆内存分析-GC日志解读</a></p>
<p>展示堆满的情况下的各个分区大小</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&gt; jmap -heap <span class="number">16186</span></span><br><span class="line">Attaching to process ID <span class="number">16186</span>, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is <span class="number">25.242</span>-b08</span><br><span class="line"></span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Parallel GC with <span class="number">6</span> thread(s)</span><br><span class="line"></span><br><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio         = <span class="number">0</span></span><br><span class="line">   MaxHeapFreeRatio         = <span class="number">100</span></span><br><span class="line">   MaxHeapSize              = <span class="number">522190848</span> (<span class="number">498.</span>0MB)</span><br><span class="line">   NewSize                  = <span class="number">11010048</span> (<span class="number">10.</span>5MB)</span><br><span class="line">   MaxNewSize               = <span class="number">174063616</span> (<span class="number">166.</span>0MB)</span><br><span class="line">   OldSize                  = <span class="number">22544384</span> (<span class="number">21.</span>5MB)</span><br><span class="line">   NewRatio                 = <span class="number">2</span></span><br><span class="line">   SurvivorRatio            = <span class="number">8</span></span><br><span class="line">   MetaspaceSize            = <span class="number">21807104</span> (<span class="number">20.</span>796875MB)</span><br><span class="line">   CompressedClassSpaceSize = <span class="number">1073741824</span> (<span class="number">1024.</span>0MB)</span><br><span class="line">   MaxMetaspaceSize         = <span class="number">17592186044415</span> MB</span><br><span class="line">   G1HeapRegionSize         = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line"></span><br><span class="line">Heap Usage:</span><br><span class="line">PS Young Generation</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity = <span class="number">58720256</span> (<span class="number">56.</span>0MB)</span><br><span class="line">   used     = <span class="number">49193976</span> (<span class="number">46.</span>91503143310547MB)</span><br><span class="line">   free     = <span class="number">9526280</span> (<span class="number">9.</span>084968566894531MB)</span><br><span class="line">   <span class="number">83.7768418448312</span>% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity = <span class="number">57147392</span> (<span class="number">54.</span>5MB)</span><br><span class="line">   used     = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line">   free     = <span class="number">57147392</span> (<span class="number">54.</span>5MB)</span><br><span class="line">   <span class="number">0.0</span>% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity = <span class="number">57671680</span> (<span class="number">55.</span>0MB)</span><br><span class="line">   used     = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line">   free     = <span class="number">57671680</span> (<span class="number">55.</span>0MB)</span><br><span class="line">   <span class="number">0.0</span>% used</span><br><span class="line">PS Old Generation</span><br><span class="line">   capacity = <span class="number">348127232</span> (<span class="number">332.</span>0MB)</span><br><span class="line">   used     = <span class="number">347644232</span> (<span class="number">331.</span>5393753051758MB)</span><br><span class="line">   free     = <span class="number">483000</span> (<span class="number">0.</span>46062469482421875MB)</span><br><span class="line">   <span class="number">99.8612576220409</span>% used</span><br><span class="line"></span><br><span class="line"><span class="number">10381</span> interned Strings occupying <span class="number">935984</span> bytes.</span><br></pre></td></tr></table></figure>

<h2 id="远程监控"><a href="#远程监控" class="headerlink" title="远程监控"></a>远程监控</h2><h3 id="JVM开启远程JMX"><a href="#JVM开启远程JMX" class="headerlink" title="JVM开启远程JMX"></a>JVM开启远程JMX</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启远程调试端口</span></span><br><span class="line">-Dcom.sun.management.jmxremote.port=8777</span><br><span class="line"><span class="comment"># 开启本地调试端口</span></span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port=8777</span><br><span class="line"><span class="comment"># jmx远程服务默认是开启ssl和认证功能功能的，也可以通过jvm选项把这两个功能关闭</span></span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate=<span class="literal">false</span></span><br><span class="line">-Dcom.sun.management.jmxremote.ssl=<span class="literal">false</span></span><br><span class="line"><span class="comment"># jmx默认是通过localhost的ip地址提供RMI服务的，如果要明确指定RMI服务地址或主机名（比如主机有多个接口，想使用非hostname关联的接口）</span></span><br><span class="line">-Djava.rmi.server.hostname=10.242.93.40</span><br></pre></td></tr></table></figure>
<p>例子:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">java \</span><br><span class="line">-Djava.rmi.server.hostname=0.0.0.0 \</span><br><span class="line">-Dcom.sun.management.jmxremote \</span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port=8000 \</span><br><span class="line">-Dcom.sun.management.jmxremote.port=8001 \</span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate=false \</span><br><span class="line">-Dcom.sun.management.jmxremote.ssl=false \</span><br><span class="line">-jar demo-0.0.1-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>
<h3 id="Tomcat-开启远程"><a href="#Tomcat-开启远程" class="headerlink" title="Tomcat 开启远程"></a>Tomcat 开启远程</h3><p>修改<code>catalina.sh</code>,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS&#x3D;&quot;$JAVA_OPTS -Djava.rmi.server.hostname&#x3D;0.0.0.0 </span><br><span class="line">-Dcom.sun.management.jmxremote </span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port&#x3D;8000 </span><br><span class="line">-Dcom.sun.management.jmxremote.port&#x3D;8001 </span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate&#x3D;false </span><br><span class="line">-Dcom.sun.management.jmxremote.ssl&#x3D;false &quot;</span><br></pre></td></tr></table></figure>
<h3 id="jvisualvm"><a href="#jvisualvm" class="headerlink" title="jvisualvm"></a>jvisualvm</h3><p><a target="_blank" rel="noopener" href="https://visualvm.github.io/pluginscenters.html">插件中心</a></p>
<ul>
<li>新建远程主机0.0.0.0</li>
<li>新建JMX链接: 端口是8001</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://visualvm.github.io/documentation.html">中文文档</a></p>
<h2 id="开启jstatd连接"><a href="#开启jstatd连接" class="headerlink" title="开启jstatd连接"></a>开启jstatd连接</h2><h2 id="BTrace"><a href="#BTrace" class="headerlink" title="BTrace"></a>BTrace</h2><p><a target="_blank" rel="noopener" href="https://github.com/btraceio/btrace">官网</a></p>
<h2 id="JDWP与tomcat远程调试"><a href="#JDWP与tomcat远程调试" class="headerlink" title="JDWP与tomcat远程调试"></a>JDWP与tomcat远程调试</h2><h2 id="Tomcat-监控"><a href="#Tomcat-监控" class="headerlink" title="Tomcat 监控"></a>Tomcat 监控</h2><h3 id="JDWP"><a href="#JDWP" class="headerlink" title="JDWP"></a>JDWP</h3><h3 id="Tomcat-manager"><a href="#Tomcat-manager" class="headerlink" title="Tomcat-manager"></a>Tomcat-manager</h3><h3 id="psi-probe监控"><a href="#psi-probe监控" class="headerlink" title="psi-probe监控"></a>psi-probe监控</h3><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><h3 id="ngx-http-stub-status监控连接信息"><a href="#ngx-http-stub-status监控连接信息" class="headerlink" title="ngx_http_stub_status监控连接信息"></a>ngx_http_stub_status监控连接信息</h3><h3 id="ngxtop监控请求信息"><a href="#ngxtop监控请求信息" class="headerlink" title="ngxtop监控请求信息"></a>ngxtop监控请求信息</h3><h2 id="字节码"><a href="#字节码" class="headerlink" title="字节码"></a>字节码</h2><p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html#jvms-4.4">常量池官方文档</a></p>
<h3 id="深入解析String-intern"><a href="#深入解析String-intern" class="headerlink" title="深入解析String#intern"></a>深入解析String#intern</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/goldenfish1919/article/details/80410349">深入解析String.intern</a><br><a target="_blank" rel="noopener" href="https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html">原文出处: 深入解析String.intern</a></p>
<p>字符串的常量池</p>
<p>常量池在哪里？</p>
<ul>
<li>Jdk1.6及之前： 有永久代, 常量池在方法区</li>
<li>Jdk1.7：       有永久代，但已经逐步“去永久代”，常量池在堆</li>
<li>Jdk1.8及之后： 无永久代，常量池在元空间</li>
</ul>
<h3 id="String去重"><a href="#String去重" class="headerlink" title="String去重"></a>String去重</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/goldenfish1919/article/details/20233263">String Deduplication in G1</a></p>
<p>-XX:+UseStringDeduplication   开启String去重<br>-XX:+PrintStringDeduplicationStatistics 打印详细的去重统计<br>-XX:StringDeduplicationAgeThreshold=15 达到这个年龄的String对象才会去重</p>
<h2 id="重用代码优化方法"><a href="#重用代码优化方法" class="headerlink" title="重用代码优化方法"></a>重用代码优化方法</h2><ul>
<li>尽量重用对象，不要循环创建对象，比如：for循环字符串拼接</li>
<li>容器类初始化的时候指定长度</li>
<li>ArrayList随机遍历快，LinkedList添加删除快</li>
<li>集合遍历尽量减少重复计算  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;collection.size();i++) <span class="comment">// collection.size() 提取成常量</span></span><br></pre></td></tr></table></figure></li>
<li>使用Entry遍历Map  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(Map.Entry&lt;String,String&gt; entry:map.entrySet())&#123;</span><br><span class="line">    String key=entry.getKey();</span><br><span class="line">    String value=entry.getValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>大数组复制用<code>System.arrayCopy()</code></li>
<li>尽量使用基本类型而不是包装类型  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Integer i=<span class="number">100</span>;</span><br><span class="line">System.out.println(i);</span><br></pre></td></tr></table></figure>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack&#x3D;2, locals&#x3D;2, args_size&#x3D;1</span><br><span class="line">     0: bipush        100                 &#x2F;&#x2F; 将100压入栈</span><br><span class="line">     2: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">     5: astore_1</span><br><span class="line">     6: getstatic     #3                  &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;</span><br><span class="line">     9: aload_1</span><br><span class="line">    10: invokevirtual #4                  &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;Object;)V</span><br><span class="line">    13: return</span><br></pre></td></tr></table></figure>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Integer i1=<span class="number">100</span>;</span><br><span class="line">Integer i2=<span class="number">100</span>;</span><br><span class="line">System.out.println(i1==i2); <span class="comment">// true</span></span><br></pre></td></tr></table></figure>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack&#x3D;3, locals&#x3D;3, args_size&#x3D;1</span><br><span class="line">     0: bipush        100</span><br><span class="line">     2: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">     5: astore_1</span><br><span class="line">     6: bipush        100</span><br><span class="line">     8: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">    11: astore_2</span><br><span class="line">    12: getstatic     #3                  &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;</span><br><span class="line">    15: aload_1</span><br><span class="line">    16: aload_2</span><br><span class="line">    17: if_acmpne     24</span><br><span class="line">    20: iconst_1</span><br><span class="line">    21: goto          25</span><br><span class="line">    24: iconst_0</span><br><span class="line">    25: invokevirtual #5                  &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Z)V</span><br><span class="line">    28: return</span><br></pre></td></tr></table></figure>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Integer i1=<span class="number">1000</span>;</span><br><span class="line">Integer i2=<span class="number">1000</span>;</span><br><span class="line">System.out.println(i1==i2);  <span class="comment">// false</span></span><br></pre></td></tr></table></figure>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack=3, locals=3, args_size=1</span><br><span class="line">     0: sipush        1000</span><br><span class="line">     3: invokestatic  #2                  // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;</span><br><span class="line">     6: astore_1</span><br><span class="line">     7: sipush        1000</span><br><span class="line">    10: invokestatic  #2                  // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;</span><br><span class="line">    13: astore_2</span><br><span class="line">    14: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;</span><br><span class="line">    17: aload_1</span><br><span class="line">    18: aload_2</span><br><span class="line">    19: if_acmpne     26</span><br><span class="line">    22: iconst_1</span><br><span class="line">    23: goto          27</span><br><span class="line">    26: iconst_0</span><br><span class="line">    27: invokevirtual #5                  // Method java/io/PrintStream.println:(Z)V</span><br><span class="line">    30: return</span><br></pre></td></tr></table></figure>
  Integer.valueOf 内部有缓存，如果大于-128且小于<code>java.lang.Integer.IntegerCache.high</code>(默认值是127)，则返回缓存</li>
<li>尽量使用非同步的容器，vector和ArrayList</li>
<li>尽量减少同步作用范围，synchronized方法vs代码块  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">f1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;f1&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">f2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;f4&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">f3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;f3&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">f4</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (TestPrimaryType.class) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;f4&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>使用ThreadLocal缓存线程不安全对象，simpleDateFormat</li>
<li>尽量使用延迟加载，懒惰单例模式  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPrimaryType</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">TestPrimaryType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPrimaryTypeHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> TestPrimaryType instance = <span class="keyword">new</span> TestPrimaryType();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    ** 调用这个方法时，发生对TestPrimaryTypeHolder的引用，才创建instance对象</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> TestPrimaryType <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> TestPrimaryTypeHolder.instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>尽量减少使用反射，加缓存</li>
<li>尽量使用连接池、线程池、对象池、缓存</li>
<li>及时释放资源，I/O流、socket、数据库连接</li>
<li>慎用异常，不要用抛异常来标示正常的业务逻辑</li>
<li>String操作尽量少用正则表达式  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">replace VS replaceAll: 尽量用replace</span><br><span class="line">split</span><br></pre></td></tr></table></figure></li>
<li>日志输出注意使用不同的级别</li>
<li>日志中参数拼接使用占位符  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log.info(“orderId:”+orgerId); &#x2F;&#x2F; 不推荐</span><br><span class="line">log.info(“orderId:&#123;&#125;”,orgerId); &#x2F;&#x2F;推荐</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-StreamingAPI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-StreamingAPI/" class="post-title-link" itemprop="url">Flink-streaming API</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-Streaming-API"><a href="#Flink-Streaming-API" class="headerlink" title="Flink Streaming API"></a>Flink Streaming API</h1><h2 id="org-apache-flink-streaming-api-functions-source-SourceFunction"><a href="#org-apache-flink-streaming-api-functions-source-SourceFunction" class="headerlink" title="org.apache.flink.streaming.api.functions.source.SourceFunction"></a>org.apache.flink.streaming.api.functions.source.SourceFunction</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-StateManagement/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-StateManagement/" class="post-title-link" itemprop="url">Flink状态管理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="state-management"><a href="#state-management" class="headerlink" title="state-management"></a>state-management</h1><h2 id="org-apache-flink-streaming-api-checkpoint-CheckpointedFunction"><a href="#org-apache-flink-streaming-api-checkpoint-CheckpointedFunction" class="headerlink" title="org.apache.flink.streaming.api.checkpoint.CheckpointedFunction"></a>org.apache.flink.streaming.api.checkpoint.CheckpointedFunction</h2><ul>
<li>CheckpointedFunction是stateful transformation functions的核心接口，用于跨stream维护state<ul>
<li>snapshotState 在checkpoint的时候会被调用，用于snapshot state，通常用于flush、commit、synchronize外部系统</li>
<li>initializeState 在parallel function初始化的时候(<strong>第一次初始化或者从前一次checkpoint recover的时候</strong>)被调用，通常用来初始化state，以及处理state recovery的逻辑</li>
</ul>
</li>
</ul>
<p>从checkpoint中恢复数据时，需要判断snapshot当前的情况，</p>
<p>FunctionSnapshotContext实现了ManagedSnapshotContext, 父类中的方法: <code>getCheckpointId</code>,<code>getCheckpointTimestamp</code><br>FunctionInitializationContext实现了ManagedInitializationContext接口, 实现了<code>isRestored</code>、<code>getOperatorStateStore</code>、<code>getKeyedStateStore</code>方法</p>
<p>在初始化容器之后，我们使用上下文的<code>isrestore()</code>方法检查失败后是否正在恢复。如果是true，即正在恢复，则应用恢复逻辑。</p>
<blockquote>
<p>样例: HBase写入OutPutFormat</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">PortraitOutputFormat</span> <span class="keyword">extends</span> <span class="title">RichOutputFormat</span>&lt;<span class="title">EventItem</span>&gt; <span class="keyword">implements</span> <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 输出阈值，批量写入的条数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> threshold;</span><br><span class="line">    <span class="comment">// 维护在状态中的数据</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> ListState&lt;EventItem&gt; checkpointState;</span><br><span class="line">    <span class="comment">// 内存中的数据</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;EventItem&gt; bufferedEventItem;</span><br><span class="line">    <span class="comment">// HBase客户端</span></span><br><span class="line">    <span class="keyword">private</span> HBaseClient hbaseClient;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PortraitOutputFormat</span><span class="params">(HBaseClient hbaseClient)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.hbaseClient = hbaseClient;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * checkpoint时调用</span></span><br><span class="line"><span class="comment">    * 执行snapshot操作，将内存中的数据写入到内存</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext functionSnapshotContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        checkpointState.clear();</span><br><span class="line">        <span class="keyword">for</span> (EventItem eventItem : bufferedEventItem) &#123;</span><br><span class="line">            checkpointState.add(eventItem);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 创建state，判断是否存在需要恢复的状态，如果有则需要恢复到bufferedEventItem</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ListStateDescriptor&lt;EventItem&gt; descriptor = <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(<span class="string">&quot;buf-p&quot;</span>, EventItem.class);</span><br><span class="line">        checkpointState = context.getOperatorStateStore().getListState(descriptor);</span><br><span class="line">        <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (EventItem eventItem : checkpointState.get()) &#123;</span><br><span class="line">                bufferedEventItem.add(eventItem);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Configuration configuration)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(<span class="keyword">int</span> taskNumber, <span class="keyword">int</span> numTasks)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 将新消息写入到缓存bufferedEventItem，缓存个数大约threshold,则执行sink写入，然后清空bufferedEventItem</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeRecord</span><span class="params">(EventItem value)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (value.getAttachUserId() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        bufferedEventItem.add(value);</span><br><span class="line">        <span class="keyword">int</span> size = bufferedEventItem.size();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (size &gt;= threshold) &#123;</span><br><span class="line">            List&lt;Put&gt; puts = bufferedEventItem</span><br><span class="line">                    .stream()</span><br><span class="line">                    .map(eventItem -&gt; &#123;</span><br><span class="line">                        String rowKey1 = portraitDataGenerator.rowKey(eventItem);</span><br><span class="line">                        Map&lt;String, String&gt; data = portraitDataGenerator.data(eventItem);</span><br><span class="line">                        Put put = <span class="keyword">new</span> Put(rowKey1.getBytes());</span><br><span class="line">                        <span class="keyword">for</span> (String cfc : data.keySet()) &#123;</span><br><span class="line">                            String[] cfcs = cfc.split(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">                            String cf = cfcs[<span class="number">0</span>];</span><br><span class="line">                            String c = cfcs[<span class="number">1</span>];</span><br><span class="line">                            String dataOne = data.get(cfc);</span><br><span class="line">                            put.addColumn(cf.getBytes(), c.getBytes(), dataOne.getBytes());</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> put;</span><br><span class="line">                    &#125;)</span><br><span class="line">                    .collect(Collectors.toList());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                hbaseClient.putAndFlush(puts);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            bufferedEventItem.clear();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hTable != <span class="keyword">null</span>) &#123;</span><br><span class="line">            hTable.flushCommits();</span><br><span class="line">            hTable.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




<h2 id="org-apache-flink-runtime-state-CheckpointListener"><a href="#org-apache-flink-runtime-state-CheckpointListener" class="headerlink" title="org.apache.flink.runtime.state.CheckpointListener"></a>org.apache.flink.runtime.state.CheckpointListener</h2><p>一旦所有checkpoint参与者确认完全，该接口必须由想要接收提交通知的功能/操作来实现。</p>
<h1 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h1><p>1.8 自动清理原理</p>
<p>Apache Flink的1.6.0版本引入了State TTL功能。它使流处理应用程序的开发人员配置过期时间，并在定义时间超时（Time to Live）之后进行清理。在Flink 1.8.0中，该功能得到了扩展，包括对RocksDB和堆状态后端（FSStateBackend和MemoryStateBackend）的历史数据进行持续清理，从而实现旧条目的连续清理过程（根据TTL设置）。</p>
<p>RocksDB后台压缩可以过滤掉过期状态<br>如果你的Flink应用程序使用RocksDB作为状态后端存储，则可以启用另一个基于Flink特定压缩过滤器的清理策略。RocksDB定期运行异步压缩以合并状态更新并减少存储。Flink压缩过滤器使用TTL检查状态条目的到期时间戳，并丢弃所有过期值。</p>
<p>激活此功能的第一步是通过设置以下Flink配置选项来配置RocksDB状态后端：</p>
<p>state.backend.rocksdb.ttl.compaction.filter.enabled</p>
<p>配置RocksDB状态后端后，将为状态启用压缩清理策略，如以下代码示例所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">StateTtlConfig ttlConfig &#x3D; StateTtlConfig</span><br><span class="line">    .newBuilder(Time.days(7))</span><br><span class="line">    .cleanupInRocksdbCompactFilter()</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure>


<h2 id="backend-状态后端"><a href="#backend-状态后端" class="headerlink" title="backend 状态后端"></a>backend 状态后端</h2><table>
<thead>
<tr>
<th>state</th>
<th>保存</th>
<th>snapshot与restore</th>
<th>大小</th>
</tr>
</thead>
<tbody><tr>
<td>keyed state</td>
<td>堆内或堆外(RocksDB)</td>
<td>backend自行实现，用户不关心</td>
<td>大</td>
</tr>
<tr>
<td>operator state</td>
<td>堆内</td>
<td>用户自行实现</td>
<td>小</td>
</tr>
</tbody></table>
<p><img src="_v_images/20201208101748835_1926021392.png"></p>
<p>Flink 的 keyed state 本质上来说就是一个键值对，所以与 RocksDB 的数据模型是吻合的。下图分别是 “window state” 和 “value state” 在 RocksDB 中的存储格式，所有存储的 key，value 均被序列化成 bytes 进行存储。</p>
<p><img src="_v_images/20201208113819762_751391291.png"></p>
<p>在 RocksDB 中，每个 state 独享一个 Column Family，而每个 Column family 使用各自独享的 write buffer 和 block cache，上图中的 window state 和 value state实际上分属不同的 column family。</p>
<h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="operator-state"><a href="#operator-state" class="headerlink" title="operator state"></a>operator state</h4><h5 id="慎重使用长-list"><a href="#慎重使用长-list" class="headerlink" title="慎重使用长 list"></a>慎重使用长 list</h5><p>下图展示的是目前 task 端 operator state 在执行完 checkpoint 返回给 job master 端的 StateMetaInfo 的代码片段。</p>
<p><img src="_v_images/20201208113527702_980726558.png"></p>
<p>由于 operator state 没有 key group 的概念，所以为了实现改并发恢复的功能，需要对 operator state 中的每一个序列化后的元素存储一个位置偏移 offset，也就是构成了上图红框中的 offset 数组。  </p>
<p>那么如果你的 operator state 中的 list 长度达到一定规模时，这个 offset 数组就可能会有几十 MB 的规模，关键这个数组是会返回给 job master，当 operator 的并发数目很大时，很容易触发 job master 的内存超用问题。我们遇到过用户把 operator state 当做黑名单存储，结果这个黑名单规模很大，导致一旦开始执行 checkpoint，job master 就会因为收到 task 发来的“巨大”的 offset 数组，而内存不断增长直到超用无法正常响应。</p>
<h5 id="正确使用-UnionListState"><a href="#正确使用-UnionListState" class="headerlink" title="正确使用 UnionListState"></a>正确使用 UnionListState</h5><p>union list state 目前被广泛使用在 kafka connector 中，不过可能用户日常开发中较少遇到，他的语义是从检查点恢复之后每个并发 task 内拿到的是原先所有operator 上的 state，如下图所示：</p>
<p><img src="_v_images/20201208113559017_2066750174.png"></p>
<p>kafka connector 使用该功能，为的是从检查点恢复时，可以拿到之前的全局信息，如果用户需要使用该功能，需要切记恢复的 task 只取其中的一部分进行处理和用于下一次 snapshot，否则有可能随着作业不断的重启而导致 state 规模不断增长。</p>
<h4 id="Keyed-state-使用建议"><a href="#Keyed-state-使用建议" class="headerlink" title="Keyed state 使用建议"></a>Keyed state 使用建议</h4><h5 id="如何正确清空当前的-state"><a href="#如何正确清空当前的-state" class="headerlink" title="如何正确清空当前的 state"></a>如何正确清空当前的 state</h5><p>state.clear() 实际上只能清理当前 key 对应的 value 值，如果想要清空整个 state，需要借助于 applyToAllKeys 方法，具体代码片段如下：</p>
<p><img src="_v_images/20201208113620034_1338097160.png"></p>
<p>如果你的需求中只是对 state 有过期需求，借助于 state TTL 功能来清理会是一个性能更好的方案。</p>
<h5 id="RocksDB-中考虑-value-值很大的极限场景"><a href="#RocksDB-中考虑-value-值很大的极限场景" class="headerlink" title="RocksDB 中考虑 value 值很大的极限场景"></a>RocksDB 中考虑 value 值很大的极限场景</h5><p>受限于 JNI bridge API 的限制，单个 value 只支持 2^31 bytes 大小，如果存在很极限的情况，可以考虑使用 MapState 来替代 ListState 或者 ValueState，因为RocksDB 的 map state 并不是将整个 map 作为 value 进行存储，而是将 map 中的一个条目作为键值对进行存储。</p>
<h5 id="如何知道当前-RocksDB-的运行情况"><a href="#如何知道当前-RocksDB-的运行情况" class="headerlink" title="如何知道当前 RocksDB 的运行情况"></a>如何知道当前 RocksDB 的运行情况</h5><p>比较直观的方式是打开 RocksDB 的 native metrics ，在默认使用 Flink managed memory 方式的情况下，state.backend.rocksdb.metrics.block-cache-usage ，state.backend.rocksdb.metrics.mem-table-flush-pending，state.backend.rocksdb.metrics.num-running-compactions 以及 state.backend.rocksdb.metrics.num-running-flushes 是比较重要的相关 metrics。</p>
<h4 id="使用-checkpoint-的使用建议"><a href="#使用-checkpoint-的使用建议" class="headerlink" title="使用 checkpoint 的使用建议"></a>使用 checkpoint 的使用建议</h4><h5 id="Checkpoint-间隔不要太短"><a href="#Checkpoint-间隔不要太短" class="headerlink" title="Checkpoint 间隔不要太短"></a>Checkpoint 间隔不要太短</h5><p>虽然理论上 Flink 支持很短的 checkpoint 间隔，但是在实际生产中，过短的间隔对于底层分布式文件系统而言，会带来很大的压力。另一方面，由于检查点的语义，所以实际上 Flink 作业处理 record 与执行 checkpoint 存在互斥锁，过于频繁的 checkpoint，可能会影响整体的性能。当然，这个建议的出发点是底层分布式文件系统的压力考虑。 </p>
<h5 id="合理设置超时时间"><a href="#合理设置超时时间" class="headerlink" title="合理设置超时时间"></a>合理设置超时时间</h5><p>默认的超时时间是 10min，如果 state 规模大，则需要合理配置。最坏情况是分布式地创建速度大于单点（job master 端）的删除速度，导致整体存储集群可用空间压力较大。建议当检查点频繁因为超时而失败时，增大超时时间。</p>
<p>【参考文献】</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6ed0ef5e2b74">Flink Streaming状态处理（Working with State）</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/yarn/yarn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/yarn/yarn/" class="post-title-link" itemprop="url">Yarn</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h1><p>通信双方有一端是 Client，另一端为 Server，且 Client 总 是主动连接 Server 的</p>
<p>通信模型: pull-model</p>
<ul>
<li>步骤1: 用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。</li>
<li>步骤2: ResourceManager为该应用程序分配第一个Container，并与对应的Node-Manager通信，要求它在这个Container中启动应用程序的ApplicationMaster。</li>
<li>步骤3: ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。</li>
<li>步骤4: ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。</li>
<li>步骤5: 一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。</li>
<li>步骤6: NodeManager为任务设置好运行环境(包括环境变量、JAR包、二进制程序等)后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。</li>
<li>步骤7: 各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。</li>
<li>步骤8: 应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</li>
</ul>
<p><img src="_v_images/20201102100715955_326368511.png"></p>
<p><img src="_v_images/20201102103928512_1313552191.png"></p>
<p>Avro 是 Hadoop 生态系统中的 RPC 框架，具有平台无关、支持动态 模式(无需编译)等优点</p>
<p>cgroup相关配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">grep -A2 -B1 cg yarn-site.xml </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.memory-control.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.oom.policy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.hierarchy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop-yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/cgroup<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">--</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/tool/01.%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/tool/01.%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" class="post-title-link" itemprop="url">正则表达式</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tool/" itemprop="url" rel="index"><span itemprop="name">tool</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="01-正则表达式"><a href="#01-正则表达式" class="headerlink" title="01.正则表达式"></a>01.正则表达式</h1><p>To use regular expressions effectively in Java, you need to know the syntax. The syntax is extensive, enabling you to write very advanced regular expressions. It may take a lot of exercise to fully master the syntax.</p>
<p>In this text I will go through the basics of the syntax with examples. I will not cover every little detail of the syntax, but focus on the main concepts you need to understand, in order to work with regular expressions. For a full explanation, see the <a target="_blank" rel="noopener" href="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html"><code>Pattern</code> class JavaDoc page</a>.</p>
<p>Before showing all the advanced options you can use in Java regular expressions, I will give you a quick run-down of the Java regular expression syntax basics.</p>
<p>The most basic form of regular expressions is an expression that simply matches certain characters. Here is an example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>This simple regular expression will match occurences of the text “John” in a given input text.</p>
<p>You can use any characters in the alphabet in a regular expression.</p>
<p>You can also refer to characters via their octal, hexadecimal or unicode codes. Here are two examples:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>These three expressions all refer to the uppercase <code>A</code> character. The first uses the octal code (<code>101</code>) for <code>A</code>, the second uses the hexadecimal code (<code>41</code>) and the third uses the unicode code (<code>0041</code>).</p>
<p>Character classes are constructst that enable you to specify a match against multiple characters instead of just one. In other words, a character class matches a single character in the input text against multiple allowed characters in the character class. For instance, you can match either of the characters <code>a</code>, <code>b</code> or <code>c</code> like this:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>Character classes are nested inside a pair of square brackets <code>[]</code>. The brackets themselves are not part of what is being matched.</p>
<p>You can use character classes for many things. For instance, this example finds all occurrences of the word <code>John</code>, with either a lowercase or uppercase <code>J</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The character class <code>[Jj]</code> will match either a <code>J</code> or a <code>j</code>, and the rest of the expression will match the characters <code>ohn</code> in that exact sequence.</p>
<p>There are several other character classes you can use. See the character class table later in this text.</p>
<p>The Java regular expression syntax has a few predefined character classes you can use. For instance, the <code>\d</code> character class matches any digit, the <code>\s</code> character class matches any white space character, and the <code>\w</code> character matches any word character.</p>
<p>The predefined character classes do not have to be enclosed in square brackets, but you can if you want to combine them. Here are a few examples:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The first example matches any digit character. The second example matches any digit or any white space character.</p>
<p>The predefined character classes are listed in a table later in this text.</p>
<p>The syntax also include matchers for matching boundaries, like boundaries between words, the beginning and end of the input text etc. For instance, the <code>\w</code> matches boundaries between words, the <code>^</code> matches the beginning of a line, and the <code>$</code> matches the end of a line.</p>
<p>Here is a boundary matcher example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>This expression matches a line of text with only the text <code>This is a single line</code>. Notice the start-of-line and end-of-line matchers in the expression. These state that there can be nothing before or after the text, except the beginning and end of a line.</p>
<p>There is a full list of boundary matchers later in this text.</p>
<p>Quantifiers enables you to match a given expression or subexpression multiple times. For instance, the following expression matches the letter <code>A</code> zero or more times:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The <code>*</code> character is a quantifier that means “zero or more times”. There is also a <code>+</code> quantifier meaning “one or more times”, a <code>?</code> quantifier meaning “zero or one time”, and a few others which you can see in the quantifier table later in this text.</p>
<p>Quantifiers can be either “reluctant”, “greedy” or “possesive”. A reluctant quantifier will match as little as possible of the input text. A greedy quantifier will match as much as possible of the input text. A possesive quantifier will match as much as possible, even if it makes the rest of the expression not match anything, and the expression to fail finding a match.</p>
<p>I will illustrate the difference between reluctant, greedy and possesive quantifiers with an example. Here is an input text:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>Then look at the following expression with a reluctant quantifier:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>This expression will match the word <code>John</code> followed by zero or more characters The <code>.</code> means “any character”, and the <code>*</code> means “zero or more times”. The <code>?</code> after the <code>*</code> makes the <code>*</code> a reluctant quantifier.</p>
<p>Being a reluctant quantifier, the quantifier will match as little as possible, meaning zero characters. The expression will thus find the word <code>John</code> with zero characters after, 3 times in the above input text.</p>
<p>If we change the quantifier to a greedy quantifier, the expression will look like this:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The greedy quantifier will match as many characters as possible. Now the expression will only match the first occurrence of <code>John</code>, and the greedy quantifier will match the rest of the characters in the input text. Thus, only a single match is found.</p>
<p>Finally, lets us change the expression a bit to contain a possesive quantifier:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>The <code>+</code> after the <code>*</code> makes it a possesive quantifier.</p>
<p>This expression will not match the input text given above, even if both the words <code>John</code> and <code>hurt</code> are found in the input text. Why is that? Because the <code>.*+</code> is possesive. Instead of matching as much as possible to make the expression match, as a greedy quantifier would have done, the possesive quantifier matches as much as possible, regardless of whether the expression will match or not.</p>
<p>The <code>.*+</code> will match all characters after the first occurrence of <code>John</code> in the input text, including the word <code>hurt</code>. Thus, there is no <code>hurt</code> word left to match, when the possesive quantifier has claimed its match.</p>
<p>If you change the quantifier to a greedy quantifier, the expression will match the input text one time. Here is how the expression looks with a greedy quantifier:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>You will have to play around with the different quantifiers and types to understand how they work. See the table later in this text for a full list of quantifiers.</p>
<p>The Java regular expression syntax also has support for a few logical operators (and, or, not).</p>
<p>The <code>and</code> operator is implicit. When you write the expression <code>John</code>, then it means “<code>J</code> and <code>o</code> and <code>h</code> and <code>n</code>“.</p>
<p>The <code>or</code> operator is explicit, and is written with a <code>|</code>. For instance, the expression <code>John|hurt</code> will match either the word <code>John</code>, or the word <code>hurt</code>.</p>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>x</code></td>
<td>The character x. Any character in the alphabet can be used in place of x.</td>
</tr>
<tr>
<td><code>\\</code></td>
<td>The backslash character. A single backslash is used as escape character in conjunction with other characters to signal special matching, so to match just the backslash character itself, you need to escape with a backslash character. Hence the double backslash to match a single backslash character.</td>
</tr>
<tr>
<td><code>\0n</code></td>
<td>The character with octal value <code>0n</code>. n has to be between 0 and 7.</td>
</tr>
<tr>
<td><code>\0nn</code></td>
<td>The character with octal value <code>0nn</code>. n has to be between 0 and 7.</td>
</tr>
<tr>
<td><code>\0mnn</code></td>
<td>The character with octal value <code>0mnn</code>. m has to be between 0 and 3, n has to be between 0 and 7.</td>
</tr>
<tr>
<td><code>\xhh</code></td>
<td>The character with the hexadecimal value <code>0xhh</code>.</td>
</tr>
<tr>
<td><code>\uhhhh</code></td>
<td>The character with the hexadecimal value <code>0xhhhh</code>. This construct is used to match unicode characters.</td>
</tr>
<tr>
<td><code>\t</code></td>
<td>The tab character.</td>
</tr>
<tr>
<td><code>\n</code></td>
<td>The newline (line feed) character (unicode: <code>&#39;\u000A&#39;</code>).</td>
</tr>
<tr>
<td><code>\r</code></td>
<td>The carriage-return character (unicode: <code>&#39;\u000D&#39;</code>).</td>
</tr>
<tr>
<td><code>\f</code></td>
<td>The form-feed character (unicode: <code>&#39;\u000C&#39;</code>).</td>
</tr>
<tr>
<td><code>\a</code></td>
<td>The alert (bell) character (unicode: <code>&#39;\u0007&#39;</code>).</td>
</tr>
<tr>
<td><code>\e</code></td>
<td>The escape character (unicode: <code>&#39;\u001B&#39;</code>).</td>
</tr>
<tr>
<td><code>\cx</code></td>
<td>The control character corresponding to <code>x</code></td>
</tr>
<tr>
<td>``</td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>[abc]</code></td>
<td>Matches <code>a</code>, or <code>b</code> or <code>c</code>. This is called a simple class, and it matches any of the characters in the class.</td>
</tr>
<tr>
<td><code>[^abc]</code></td>
<td>Matches any character except <code>a</code>, <code>b</code>, and <code>c</code>. This is a negation.</td>
</tr>
<tr>
<td><code>[a-zA-Z]</code></td>
<td>Matches any character from <code>a</code> to <code>z</code>, or <code>A</code> to <code>Z</code>, including <code>a</code>, <code>A</code>, <code>z</code> and <code>Z</code>. This called a range.</td>
</tr>
<tr>
<td><code>[a-d[m-p]]</code></td>
<td>Matches any character from <code>a</code> to <code>d</code>, or from <code>m</code> to <code>p</code>. This is called a union.</td>
</tr>
<tr>
<td><code>[a-z&amp;&amp;[def]]</code></td>
<td>Matches <code>d</code>, <code>e</code>, or <code>f</code>. This is called an intersection (here between the range <code>a-z</code> and the characters <code>def</code>).</td>
</tr>
<tr>
<td><code>[a-z&amp;&amp;[^bc]]</code></td>
<td>Matches all characters from <code>a</code> to <code>z</code> except <code>b</code> and <code>c</code>. This is called a subtraction.</td>
</tr>
<tr>
<td><code>[a-z&amp;&amp;[^m-p]]</code></td>
<td>Matches all characters from <code>a</code> to <code>z</code> except the characters from <code>m</code> to <code>p</code>. This is also called a subtraction.</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>.</code></td>
<td>Matches any single character. May or may not match line terminators, depending on what flags were used to compile the <code>Pattern</code>.</td>
</tr>
<tr>
<td><code>\d</code></td>
<td>Matches any digit [0-9]</td>
</tr>
<tr>
<td><code>\D</code></td>
<td>Matches any non-digit character [^0-9]</td>
</tr>
<tr>
<td><code>\s</code></td>
<td>Matches any white space character (space, tab, line break, carriage return)</td>
</tr>
<tr>
<td><code>\S</code></td>
<td>Matches any non-white space character.</td>
</tr>
<tr>
<td><code>\w</code></td>
<td>Matches any word character.</td>
</tr>
<tr>
<td><code>\W</code></td>
<td>Matches any non-word character.</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>^</code></td>
<td>Matches the beginning of a line.</td>
</tr>
<tr>
<td><code>$</code></td>
<td>Matches then end of a line.</td>
</tr>
<tr>
<td><code>\b</code></td>
<td>Matches a word boundary.</td>
</tr>
<tr>
<td><code>\B</code></td>
<td>Matches a non-word boundary.</td>
</tr>
<tr>
<td><code>\A</code></td>
<td>Matches the beginning of the input text.</td>
</tr>
<tr>
<td><code>\G</code></td>
<td>Matches the end of the previous match</td>
</tr>
<tr>
<td><code>\Z</code></td>
<td>Matches the end of the input text except the final terminator if any.</td>
</tr>
<tr>
<td><code>\z</code></td>
<td>Matches the end of the input text.</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Greedy</th>
<th>Reluctant</th>
<th>Possessive</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>X?</code></td>
<td><code>X??</code></td>
<td><code>X?+</code></td>
<td>Matches X once, or not at all (0 or 1 time).</td>
</tr>
<tr>
<td><code>X*</code></td>
<td><code>X*?</code></td>
<td><code>X*+</code></td>
<td>Matches X zero or more times.</td>
</tr>
<tr>
<td><code>X+</code></td>
<td><code>X+?</code></td>
<td><code>X++</code></td>
<td>Matches X one or more times.</td>
</tr>
<tr>
<td><code>X&#123;n&#125;</code></td>
<td><code>X&#123;n&#125;?</code></td>
<td><code>X&#123;n&#125;+</code></td>
<td>Matches X exactly n times.</td>
</tr>
<tr>
<td><code>X&#123;n,&#125;</code></td>
<td><code>X&#123;n,&#125;?</code></td>
<td><code>X&#123;n,&#125;+</code></td>
<td>Matches X at least n times.</td>
</tr>
<tr>
<td><code>X&#123;n, m)</code></td>
<td><code>X&#123;n, m)?</code></td>
<td><code>X&#123;n, m)+</code></td>
<td>Matches X at least n time, but at most m times.</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Construct</th>
<th>Matches</th>
</tr>
</thead>
<tbody><tr>
<td><code>XY</code></td>
<td>Matches X and Y (X followed by Y).</td>
</tr>
<tr>
<td>`X</td>
<td>Y`</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/tool/02.RAID/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/tool/02.RAID/" class="post-title-link" itemprop="url">磁盘Raid机制</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tool/" itemprop="url" rel="index"><span itemprop="name">tool</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Raid"><a href="#Raid" class="headerlink" title="Raid"></a>Raid</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/tool/04.Mac/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/tool/04.Mac/" class="post-title-link" itemprop="url">MacOS操作经验</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tool/" itemprop="url" rel="index"><span itemprop="name">tool</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><p>因为苹果在OS X 10.11中引入的SIP特性使得即使加了sudo（也就是具有root权限）也无法修改系统级的目录，其中就包括了/usr/bin。要解决这个问题有两种做法：</p>
<p>一种是比较不安全的就是关闭SIP，也就是rootless特性；</p>
<p>另一种是将本要链接到/usr/bin下的改链接到/usr/local/bin下就好了。</p>
<p>解决办法</p>
<p>sudo ln -s /usr/local/mysql/bin/mysql /usr/local/bin</p>
<p>mysql 启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqld --user mysql</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-SQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-SQL/" class="post-title-link" itemprop="url">FlinkSQL与动态表</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-19 15:02:11" itemprop="dateModified" datetime="2021-04-19T15:02:11+08:00">2021-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h1><h2 id="Retract-mode-和-Append-mode"><a href="#Retract-mode-和-Append-mode" class="headerlink" title="Retract mode 和 Append mode"></a>Retract mode 和 Append mode</h2><p>toAppendStream  只支持insert<br>toRetractStream  其余模式都可以</p>
<p>如果动态表仅只有Insert操作，即之前输出的结果不会被更新，则使用该模式。如果更新或删除操作使用追加模式会失败报错，始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回。</p>
<p>使用flinkSQL处理实时数据当我们把表转化成流的时候，需要用toAppendStream与toRetractStream这两个方法。稍不注意可能直接选择了toAppendStream。</p>
<p>始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回。</p>
<p>当我们使用的sql语句包含：count() group by时，必须使用缩进模式</p>
<p><img src="_v_images/20201111111954370_1165111473.png"><br><img src="_v_images/20201111112036578_1272633365.png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取StreamTableEnvironment.</span></span><br><span class="line">StreamTableEnvironment tableEnv = ...;</span><br><span class="line"><span class="comment">// 包含两个字段的表(String name, Integer age)</span></span><br><span class="line">Table table = ...</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用Append Mode追加模式，数据类型为Row</span></span><br><span class="line">DataStream&lt;Row&gt; dsRow = tableEnv.toAppendStream(table, Row.class);</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用Append Mode追加模式，数据类型为定义好的TypeInformation</span></span><br><span class="line">TupleTypeInfo&lt;Tuple2&lt;String, Integer&gt;&gt; tupleType = <span class="keyword">new</span> TupleTypeInfo&lt;&gt;(</span><br><span class="line">  Types.STRING(),</span><br><span class="line">  Types.INT());</span><br><span class="line">  DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dsTuple =</span><br><span class="line">  tableEnv.toAppendStream(table, tupleType);</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用的模式为Retract Mode撤回模式，类型为Row</span></span><br><span class="line"><span class="comment">// 对于转换后的DataStream&lt;Tuple2&lt;Boolean, X&gt;&gt;，X表示流的数据类型，</span></span><br><span class="line"><span class="comment">// boolean值表示数据改变的类型，其中INSERT返回true，DELETE返回的是false</span></span><br><span class="line">DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; retractStream</span><br><span class="line">  tableEnv.toRetractStream(table, Row.class);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="如何实现回退更新"><a href="#如何实现回退更新" class="headerlink" title="如何实现回退更新?"></a>如何实现回退更新?</h3><p>flink-connector-jdbc 最终使用的是SQL引擎的upsert语法:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tbl() <span class="keyword">values</span> ( ),( ) <span class="keyword">on</span> duplicate key <span class="keyword">update</span></span><br></pre></td></tr></table></figure>
<p>可以看下 MySQL/upsert 一节</p>
<p>对应flink 源码</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.flink.connector.jdbc.dialect.MySQLDialect#getUpsertStatement</span><br></pre></td></tr></table></figure>



<h2 id="keyedBy与group-by区别"><a href="#keyedBy与group-by区别" class="headerlink" title="keyedBy与group by区别"></a>keyedBy与group by区别</h2><h2 id="SQL解析工具"><a href="#SQL解析工具" class="headerlink" title="SQL解析工具"></a>SQL解析工具</h2><p>hive使用了antlr3实现了自己的HQL,<br>Flink使用Apache Calcite,<br>而Calcite的解析器是使用JavaCC实现的,<br>Spark2.x以后采用了antlr4实现自己的解析器,<br>Presto也是使用antlr4。</p>
<h2 id="通过Table-api创建表"><a href="#通过Table-api创建表" class="headerlink" title="通过Table api创建表"></a>通过Table api创建表</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># create a <span class="type">Table</span> from a <span class="type">Table</span> <span class="type">API</span> query</span><br><span class="line">tapi_result = table_env.from_path(<span class="string">&quot;table1&quot;</span>).select(...)</span><br></pre></td></tr></table></figure>
<h2 id="视图-view"><a href="#视图-view" class="headerlink" title="视图 view"></a>视图 view</h2><h2 id="window-aggregate与group-aggregate区别"><a href="#window-aggregate与group-aggregate区别" class="headerlink" title="window aggregate与group aggregate区别"></a>window aggregate与group aggregate区别</h2><p>参考自<a target="_blank" rel="noopener" href="https://ververica.cn/developers/flink-sql-programming-practice/">Apache Flink 零基础入门（九）：Flink SQL 编程实践</a></p>
<h3 id="Group-Aggregate的例子"><a href="#Group-Aggregate的例子" class="headerlink" title="Group Aggregate的例子"></a>Group Aggregate的例子</h3><p>这是一个group aggregate, 内存中累计每个分类的数据，有变化时，update sink</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> psgCnt, <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> cnt </span><br><span class="line"><span class="keyword">FROM</span> Rides </span><br><span class="line"><span class="keyword">WHERE</span> isInNYC(lon, lat)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> psgCnt;</span><br></pre></td></tr></table></figure>
<h3 id="Window-Aggregate"><a href="#Window-Aggregate" class="headerlink" title="Window Aggregate"></a>Window Aggregate</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">  toAreaId(lon, lat) <span class="keyword">AS</span> area, <span class="comment">-- toAreaId为UDF</span></span><br><span class="line">  TUMBLE_END(rideTime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> window_end, </span><br><span class="line">  <span class="comment">--滚动窗口的结束时间: </span></span><br><span class="line">  <span class="comment">-- ① 可以时间不同吗?</span></span><br><span class="line">  <span class="comment">-- ② 窗口可以别名吗?</span></span><br><span class="line">  <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> cnt </span><br><span class="line"><span class="keyword">FROM</span> Rides </span><br><span class="line"><span class="keyword">WHERE</span> isInNYC(lon, lat) <span class="keyword">and</span> isStart</span><br><span class="line"><span class="comment">-- isStart 为boolean</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> </span><br><span class="line">  toAreaId(lon, lat), </span><br><span class="line">  TUMBLE(rideTime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>) </span><br><span class="line">  <span class="comment">-- 定义窗口</span></span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="operator">&gt;=</span> <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 5分钟超过5次才输出</span></span><br></pre></td></tr></table></figure>
<h3 id="Window-Aggregate-与-Group-Aggregate-的区别"><a href="#Window-Aggregate-与-Group-Aggregate-的区别" class="headerlink" title="Window Aggregate 与 Group Aggregate 的区别"></a>Window Aggregate 与 Group Aggregate 的区别</h3><p>Window Aggregate 是当window结束时才输出，其输出的结果是最终值，不会再进行修改，其输出流是一个 Append 流。而 Group Aggregate 是每处理一条数据，就输出最新的结果，其结果是在不断更新的，就好像数据库中的数据一样，其输出流是一个 Update 流。</p>
<p>window 由于有 watermark ，可以精确知道哪些窗口已经过期了，所以可以及时清理过期状态，保证状态维持在稳定的大小。而 Group Aggregate 因为不知道哪些数据是过期的，所以状态会无限增长，这对于生产作业来说不是很稳定，所以建议对 Group Aggregate 的作业配上 State TTL 的配置。</p>
<p><img src="_v_images/20210410180758564_1166368853.png"></p>
<p>例如统计每个店铺每天的实时PV，那么就可以将 TTL 配置成 24+ 小时，因为一天前的状态一般来说就用不到了。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  DATE_FORMAT(ts, <span class="string">&#x27;yyyy-MM-dd&#x27;</span>), shop_id, <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">as</span> pv</span><br><span class="line"><span class="keyword">FROM</span> T</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> DATE_FORMAT(ts, <span class="string">&#x27;yyyy-MM-dd&#x27;</span>), shop_id</span><br></pre></td></tr></table></figure>
<p>当然，如果 TTL 配置地太小，可能会清除掉一些有用的状态和数据，从而导致数据精确性地问题。这也是用户需要权衡地一个参数。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><p><a target="_blank" rel="noopener" href="http://www.10tiao.com/html/157/201707/2653162664/1.html">在数据流中使用SQL查询：Apache Flink中的动态表的持续查询</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://jiamaoxiang.top/2020/05/25/Flink-Table-API-SQL%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/">Flink Table API &amp; SQL编程指南(1)</a></p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/8/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/10/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">237</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">127</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
