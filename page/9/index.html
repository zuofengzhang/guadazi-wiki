<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/page/9/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/9/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/JMeter/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/JMeter/" class="post-title-link" itemprop="url">JMeter与性能压测</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="JMeter与性能压测"><a href="#JMeter与性能压测" class="headerlink" title="JMeter与性能压测"></a>JMeter与性能压测</h1><p> jmeter是一款纯java的性能测试工具，跨平台运行方便、提供图形化界面设置、简单易用。</p>
<p>在性能测试方法论中，很典型的方法就是二八原则，量化业务需求。</p>
<p>二八原则：指80%的业务量在20%的时间里完成。</p>
<p>如何理解，下面我们来个例子吧</p>
<p>用户登录场景：早高峰时段，8：50—9：10，5000坐席上线登陆。</p>
<pre><code>  业务量：5000个 

  时间：20x60=1200秒

吞吐量=80%x业务量/(20%*时间)=4000/240=16.7/秒</code></pre>
<p>而并非5000/1200=4.1/秒</p>
<p>实际上，登录请求数分布是一个正态分布，最高峰时肯定比4.1/秒更高，高峰段实际上完成了80%的业务量，却只花了20%的时间。</p>
<p>温馨提示：</p>
<p>1.二八原则计算的结果并非在线并发用户数，是系统要达到的处理能力（吞吐量），初学者容易被误导，那这这个数据就去设置并发数，这是错误滴。</p>
<p>2.如果你的系统性能要求更高，也可以选择一九原则或更严格的算法，二八原则比较通用，一般系统性能比较接近这个算法而已，大家应该活用。</p>
<p>3.tps、响应时间、在线并发数三者关系详解：<a target="_blank" rel="noopener" href="http://blog.csdn.net/musen518/article/details/43795047">点击打开链接</a></p>
<p>  三者关系图</p>
<p><img src="_v_images/20200121162958712_1262110967"></p>
<ol start="2">
<li> 结论</li>
</ol>
<ul>
<li>小并发数区间测试，找拐点（如：100-300并发持续5分钟，可以发现上图中200并发时出现拐点）</li>
<li>大并发数区间测试，找符合需求的最大并发数（如：1800-2200并发持续5分钟，可以找到满足响应时间在3秒内的最大并发数2000）</li>
<li>利用最大并发数，压测环境在极限时的资源消耗（压测时间1小时以内）</li>
<li>80%最大并发数，进行稳定性测试（压测时间1小时以上）</li>
</ul>
<p>注：执行机资源消耗必须监控上，保证能提供稳定的并发负载。</p>
<p>注：这里的响应时间是90%响应时间</p>
<p>tps:</p>
<p>每秒事务处理量 - <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95">性能测试</a>的术语介绍</p>
<p>TPS(Transaction Per Second)</p>
<p>每秒钟系统能够处理的交易或事务的数量。它是衡量系统处理能力的重要指标。TPS是<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/LoadRunner">LoadRunner</a>中重要的性能参数指标。</p>
<p> 1.下载安装</p>
<p>仅仅需要从apache的网站找到下载包，解压到本地文件目录即可。</p>
<p><a target="_blank" rel="noopener" href="http://jmeter.apache.org/download_jmeter.cgi">http://jmeter.apache.org/download_jmeter.cgi</a></p>
<p>2.启动</p>
<p>解压目录中存在一个bin的目录，里面有很多批处理文件和脚本文件，window系统运行jmeter.bat即可。需要关注的是bin目录中的jmeter.properties文件，这是运行相关的配置文件. 特别是TCP Sampler configuration部分几个配置会和后面内容相关</p>
<p>3.建立一种类型测试</p>
<p>这里只描述简单的tcp测试建立步骤，因为目前支持的测试类型很多，无法一一陈述，功能细节部分可以参考JMeter文档</p>
<p>1）创建测试线程组</p>
<p><strong>1. 启动测试用接口</strong><br>首先我们写一段 php 代码，通过 PHP 内置的 Server 启动它。</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$user_id</span> = <span class="variable">$_GET</span>[<span class="string">&#x27;user_id&#x27;</span>];</span><br><span class="line">file_put_contents(<span class="string">&#x27;/tmp/1.log&#x27;</span>, <span class="variable">$user_id</span>.PHP_EOL,  FILE_APPEND);</span><br><span class="line"><span class="keyword">echo</span> <span class="variable">$user_id</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以上代码保存为 <code>index.php</code></p>
<p>命令中执行 <code>php -S 127.0.0.1:8080</code></p>
<p>在浏览器访问 <code>http://127.0.0.1:8080/index.php?user_id=1</code> , 输出 <code>1</code> 说明服务接口正常</p>
<p><strong>2. 创建线程组</strong><br>使用 JMeter 测试应用性能首先要创建一个线程组<br>右键 “Text Plan”, 在弹出的菜单栏选择 “Add-&gt;Threads(Users)-&gt;Thread Group”</p>
<p>就创建了一个线程组：</p>
<p><img src="_v_images/20200121162958609_236107942.png"></p>
<p>“Number of Threads (users): ” 即并发用户数，相当于 ab 命令的 -c 参数<br>“Loop Count:” 循环请求次数， 即每个线程请求多少次， 这个数据乘以线程数相当于 ab 命令的 -n 参数</p>
<p>我们设置了 “Number of Threads (users)” 为 5 ， “Loop Count” 为 60 ， 相当于ab 命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ab -c 5 -n 300 http:&#x2F;&#x2F;xxx.com</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>2. 创建测试请求</strong><br>右键我们刚刚创建的线程组“Thread Group”, 选择 “Add-&gt; Sampler-&gt; HTTP Request”</p>
<p><img src="_v_images/20200121162958391_1716814489.png"></p>
<p>这一步相当于通过多个参数拼出要测试的接口地址。</p>
<p>注意<code>Path</code>中， <code>$&#123;__counter(false)&#125;</code> 为 JMeter 内置的函数， 它的返回值为当前请求次数<br>**这样保证了我们每次向服务器请求的 <code>user_id</code> 的值都不一样 **</p>
<p>此时我们将要进行的测试等同于 ab 测试命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ab -c 5 -n 300 http:&#x2F;&#x2F;127.0.0.1&#x2F;index.php?user_id&#x3D;1</span><br></pre></td></tr></table></figure>
<h2 id="、-Counter-函数"><a href="#、-Counter-函数" class="headerlink" title="、_Counter 函数"></a>、_Counter 函数</h2><p>每次调用计数器函数都会产生一个新值，从1开始每次加1。计数器既可以被配置成针对每个虚拟用户是独立的，也可以被配置成所有虚拟用户公用的。如果每个虚拟用户的计数器是独立增长的，那么通常被用于记录测试计划运行了多少遍。全局计数器通常被用于记录发送了多少次请求。</p>
<p>计数器使用一个整数值来记录，允许的最大值为2,147,483,647。</p>
<p>功能：这个函数是一个计数器，用于统计函数的使用次数，它从1开始，每调用这个函数一次它就会自动加1，它有两个参数，第一个参数是布尔型的，只能设置成“TRUE”或者“FALSE”，如果是TRUE，那么每个用户有自己的计数器，可以用于统计每个线程歌执行了多少次。如果是FALSE，那就使用全局计数器，可以统计出这次测试共运行了多少次。第二个参数是“函数名称”</p>
<p><strong>格式：</strong>${__counter(FALSE,test)}</p>
<p><strong>使用：</strong>我们将“_counter”函数生成的参数复制到某个参数下面，如果为TRUE格式，则每个线程各自统计，最大数为循环数，如果为FALSE，则所有线程一起统计，最大数为线程数乘以循环数</p>
<p><strong>参数：</strong></p>
<p>第一个参数：True，如果测试人员希望每个虚拟用户的计数器保持独立，与其他用户的计数器相区别。False，全局计数器</p>
<p>第二个参数：重用计数器函数创建值的引用名。测试人员可以这样引用计数器的值：${test}。这样一来，测试人员就可以创建一个计数器后，在多个地方引用它的值。</p>
<p>以上，摘自网络（不知道怎么用，只好摘抄，记录下来等灵感~~~~(&gt;_&lt;)~~~~ ）。</p>
<p>目前，我测试_Counter函数，就是在参数列表加一个参数，值填写为${__counter(FALSE,test)}</p>
<p>）  </p>
<p><strong>3.开始测试</strong><br>右键线程组 “Thread Group”， 选择 “Add-&gt; Listener-&gt;Summary Report “, 创建一个结果报表</p>
<p>然后点击， 菜单栏中的绿色按钮, 开始测试：</p>
<p><img src="_v_images/20200121162958170_1920589116.png"></p>
<p>结果如图:</p>
<p> <img src="_v_images/20200121162957964_563024753.png"></p>
<p>打开 ‘/tmp/1.log’ 可以看到，每次请求的 user_id的值都是不同的。</p>
<h1 id="Thread-Group-线程组"><a href="#Thread-Group-线程组" class="headerlink" title="Thread Group(线程组)"></a>Thread Group(线程组)</h1><blockquote>
<p>1.线程组，或者可以叫用户组，进行性能测试时的用户资源池。</p>
<p>2.是任何一个测试计划执行的开始点。</p>
<p>3.上一篇提到的“控制器”和“HTTP请求”(采集器)必须在线程组内；监听器等其他组件，可以直接放在测试计划下。</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/linglingyuese/archive/2013/03/06/linglingyuese-three.html">https://www.cnblogs.com/linglingyuese/archive/2013/03/06/linglingyuese-three.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hait1234/p/6767212.html">https://www.cnblogs.com/hait1234/p/6767212.html</a></p>
</blockquote>
<p>二、Thread Group线程组功能分区</p>
<p>总的来说，一个线程组有三个功能分区，这里分别标注为区域1、区域2、区域3。</p>
<p><img src="_v_images/20200121162957741_1278470356.png"></p>
<p>1.区域1：在取样器错误后要执行的动作，这个区域的主要作用很明显，在线程内的采样器失败后，接下来做什么。</p>
<pre><code> （1）继续：选择此项，将继续执行接下来的操作。

 （2）Start Next Loop：忽略错误，执行下一个循环。

 （3）停止线程：退出该线程（不再进行此线程的任何操作）。

 （4）停止测试：等待当前执行的采样器结束后，结束整个测试。

 （5）Stop Test Now：直接停止整个测试。（注意与4的“停止测试”进行区分）。</code></pre>
<p>2.区域2：线程属性，这里可以设置线程数（模拟的用户数）和循环次数。含义如下图所示：</p>
<p><img src="_v_images/20200121162957533_2123434422.png"></p>
<p>ramp up:斜坡上升; [动词短语] 加强，加大;</p>
<p> 相当于warm up的一个词,包含准备,热身,加速的意思,可用在生产中小批量的试制中, 也可以指人初入公司的锻炼. 在项目初始阶段要做许多准备工作。</p>
<p>3.区域3：调度器配置（全部都在调度器复选框被选中的前提下，下面的选项才会生效。）</p>
<p><img src="_v_images/20200121162957230_2144403715.png"></p>
<p>最重要的Tcp Sampler:tcp取样器</p>
<h4 id="TCPClient-classname"><a href="#TCPClient-classname" class="headerlink" title="TCPClient classname"></a>TCPClient classname</h4><p>TCP Sampler提供了3个Sampler的实现，分别是</p>
<p>org.apache.jmeter.protocol.tcp.sampler.TCPClientImpl </p>
<p>org.apache.jmeter.protocol.tcp.sampler.BinaryTCPClientImpl和<br>org.apache.jmeter.protocol.tcp.sampler.LengthPrefixedBinaryTCPClientImpl。</p>
<p>其中TCPClientImpl实现了以文本编辑器中所编辑的纯文本为内容进行发送，BinaryTCPClientImpl则以文本编辑器中所编辑的16进制字符（hex）内容为基础转换为二进制的字节内容进行发送，LengthPrefixedBinaryTCPClientImpl则会在BinaryTCPClientImpl基础上默认以发送内容的长度以字节前缀进行填充。</p>
<p>我们可以通过配置jmeter.properties文件中tcp.handler属性来设置默认的TCPClient。</p>
<h2 id="测试基于文本套接字应用"><a href="#测试基于文本套接字应用" class="headerlink" title="测试基于文本套接字应用"></a>测试基于文本套接字应用</h2><p>被测应用的源码请参见<a target="_blank" rel="noopener" href="https://link.jianshu.com/?t=https://github.com/XMeterSaaSService/Blog_sample_project/blob/master/socket_echo/src/main/java/net/xmeter/echo/TextServer.java">这里</a>. 如果想运行该程序，请点击该链接下载socket_echo-0.0.1-SNAPSHOT.jar，并且在命令行下执行:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/XMeterSaaSService/Blog/_sample/_project/tree/master/socket_echo">https://github.com/XMeterSaaSService/Blog\_sample\_project/tree/master/socket_echo</a> </p>
<p>（javac 和java可以去掉包名后再在命令行执行）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -cp socket_echo-0.0.1-SNAPSHOT.jar net.xmeter.echo.TextServer这个程序源码：</span><br></pre></td></tr></table></figure>
<p><img src="_v_images/20200121162957026_1366283370.gif"></p>
<p><a href="javascript:void(0);" title="复制代码"><img src="_v_images/20200121162956724_1452766871.gif" alt="复制代码"></a></p>
<p>import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.io.PrintWriter; import java.net.ServerSocket; import java.net.Socket; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.atomic.AtomicInteger; public class TextServer { public static AtomicInteger sessions = new AtomicInteger(0); public void handleRequest(final Socket socket) {<br>        ExecutorService executor = Executors.newSingleThreadExecutor();</p>
<pre><code>    executor.submit(new Runnable() &#123;
        @Override public void run() &#123; try &#123;
                BufferedReader is = new BufferedReader(new InputStreamReader(socket.getInputStream()));
                PrintWriter os = new PrintWriter(socket.getOutputStream()); while(true) &#123;
                    String line = is.readLine(); if(line == null) &#123;
                        System.out.println(&quot;Probably the client side closed the connection, now close me as well.&quot;);
                        socket.close(); break;
                    &#125;
                    System.out.println(&quot;Received message: &quot; + line);
                    os.println(&quot;Echo: &quot; + line);
                    os.flush(); if(&quot;bye&quot;.equals(line)) &#123; break;
                    &#125;
                &#125;
            &#125; catch(Exception ex) &#123;
                ex.printStackTrace();
            &#125; finally &#123; try &#123;
                    socket.close(); int num = sessions.decrementAndGet();
                    System.out.println(&quot;Now totally has &quot; + num + &quot; of conn.&quot;);
                &#125; catch (IOException e) &#123;
                    e.printStackTrace();
                &#125;
            &#125;
        &#125;

    &#125;);

&#125; public static void main(String\[\] args) &#123; try &#123;
        ServerSocket server = new ServerSocket(4700); while(true) &#123;
            Socket socket = server.accept();
            TextServer srv = new TextServer();
            srv.handleRequest(socket); int num = sessions.incrementAndGet();
            System.out.println(&quot;Received new conn, now totally has &quot; + num + &quot; of conn.&quot;);
        &#125;
    &#125; catch (Exception e) &#123;
        e.printStackTrace();
    &#125;
&#125;</code></pre>
<p>}</p>
<p><a href="javascript:void(0);" title="复制代码"><img src="_v_images/20200121162956522_679224056.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(这个程序测试：</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意几图：hello后面有个换行， ENDof line Byte value 填写的是10.LF (NL line feed, new line) 换行键 ，ascill是10.os.println(&quot;Echo: &quot; + line); 用的是println，服务端返回的最后是一个换行符。如果不填写EOF byte value,那么客户端将会一直阻塞没有返回。</span><br></pre></td></tr></table></figure>
<p>我们发<strong>现EOL原来是与读数据相关的，就是设定来自于服务器数据流的一个结束标识字节。没有设置EOL将会一直读到输入流结束为</strong>止。</p>
<p>这里值得注意的是，这是个十进制的值（千万不要写成hex），比如你可以查询ASCII表，来确认一个表示结束字符的十进制值，我们以$作为案例，改造一下Mock TCP Server，输出结尾为$，如下面代码：</p>
<p>)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>（请确保您的机器上已经安装了Java）。 该程序会在4700端口建立一个ServerSocket，等待来自客户端的请求，客户端如果发送了一个字符串，服务器端返回“Echo: “ + 客户端发送的字符串。如下图所示，如果我们使用telnet连接到服务器端的套接字应用，双方就可以直接进行通信了。</p>
<h5 id="TCPClientImpl"><a href="#TCPClientImpl" class="headerlink" title="TCPClientImpl"></a>TCPClientImpl</h5><p>我们使用TCPClientImpl对Mock TCP Server进行测试，配置参考下图：</p>
<p><img src="_v_images/20200121162956318_161208051.png"></p>
<p>点击运行测试，你会发现测试发生了阻塞，原因是服务器使用了readLine获取客户端的发送数据，需要根据发送数据中的CRLF（\r或\n）判断一行的<strong>结束。而我们制作的发送内容并不包括CRLF标识内容，因此，服务器阻塞在了读数据，测试客户端得不到服务器响应，同样</strong>也阻塞在了读数据，正确的配置需要添加一个“回车”（不能是”\r”或”\n”，因为TCPClientImpl会自动将其转换为对应的两个字符而不是CRLF标识）参考下图</p>
<p>TCP 取样器通过TCP/IP来连接特定服务器，连上服务器之后发送消息，然后等待服务器回复。</p>
<p>如果“Re-use connection”(重复使用连接) 复选框被选中了，在同一个线程中Samplers(取样器)共享连接，包含相同主机名和端口，不同主机/端口合并将会使用不同线程。如果“Re-use connection” 和 “Close connection”(关闭连接)同时被选中，这个套接字在运行完当前Samplers将会关闭。再下一个Sampler将会另外创建一个新套接字。你可能想要在每次线程循环结束之后关闭套接字。</p>
<p>如果一个错误被检测到或者“Re-use connection” 没有被选中，这个套接字将会关闭，另外套接字将会在接下Samplers被再一次打开。</p>
<p>详细看这篇文章：</p>
<h1 id="Apache-JMeter-TCPSampler的使用及自定义"><a href="#Apache-JMeter-TCPSampler的使用及自定义" class="headerlink" title="Apache JMeter TCPSampler的使用及自定义"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/xreztento/article/details/73741697">Apache JMeter TCPSampler的使用及自定义</a></h1><p> 还有这篇文章：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/63e08071075e">https://www.jianshu.com/p/63e08071075e</a></p>
<h1 id="JMeter—–TCP-Sampler（TCP-取样器）"><a href="#JMeter—–TCP-Sampler（TCP-取样器）" class="headerlink" title="JMeter—–TCP Sampler（TCP 取样器）"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_37355951/article/details/74779977">JMeter—–TCP Sampler（TCP 取样器）</a></h1><p>jmeter报告结果中会出现三个时间</p>
<ol>
<li><p>Elapsed time    经过的时间(= Sample time = Load time = Response time ) </p>
<p>   这个时间是我们测试常用的时间，也是整个请求的消耗时间，从发送到接收完成全程消耗的时间</p>
</li>
<li><p>Latency time  延迟时间</p>
<p>  不常用，表示请求发送到刚开始接收响应时，这个时间&lt;Elapsed time</p>
</li>
</ol>
<p>3. Connection time  建立连接时间 （2.13新增参数）</p>
<pre><code>   不常用，请求连接建立的时间，这个时间 &lt; Latency time &lt; Elapsed time</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/tool/typesafe.config/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/tool/typesafe.config/" class="post-title-link" itemprop="url">typesafe.config与HOCON</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tool/" itemprop="url" rel="index"><span itemprop="name">tool</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="typesafe-config"><a href="#typesafe-config" class="headerlink" title="typesafe.config"></a>typesafe.config</h1><h1 id="Typesafe-Config介绍"><a href="#Typesafe-Config介绍" class="headerlink" title="Typesafe Config介绍"></a>Typesafe Config介绍</h1><h3 id="Why-Typesafe-Config"><a href="#Why-Typesafe-Config" class="headerlink" title="Why Typesafe Config"></a>Why Typesafe Config</h3><p><strong>THE config library</strong> 非常好用的API，用过之后不会再想使用其他配置工具</p>
<ul>
<li>纯java实现，无任何依赖</li>
<li>支持各种格式配置的融合: Java properties, JSON, and a human-friendly JSON superset</li>
<li>可以通过文件、urls、classpath加载配置</li>
<li>支持多层嵌套的配置方式：树形配置</li>
<li>识别Java system properties, 如java -Dmyapp.foo.bar=10</li>
<li>可以转换时间，大小等单位。如 “512k”、”10 seconds”</li>
<li>类型转换，比如yes可以转换为true，数字之间也可以在内部做转换</li>
<li>JSON superset features:<ul>
<li>comments</li>
<li>includes</li>
<li>substitutions (“foo” : ${bar}, “foo” : Hello ${who})</li>
<li>properties-like notation (a.b=c)</li>
<li>less noisy, more lenient syntax</li>
<li>substitute environment variables (logdir=${HOME}/logs)</li>
</ul>
</li>
<li>基于不可变对象，不用担心多线程问题</li>
</ul>
<h4 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h4><p>使用gradle</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">compile &#39;com.typesafe:config:1.2.1&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="HOCON-Human-Optimized-Config-Object-Notation"><a href="#HOCON-Human-Optimized-Config-Object-Notation" class="headerlink" title="HOCON (Human-Optimized Config Object Notation)"></a>HOCON (Human-Optimized Config Object Notation)</h3><p>config使用的是HOCON的文件格式，这种文件格式类似于json，很灵活但没有歧义，能引用，能替换，能注释，能兼容老的properties等格式</p>
<p>The following features are desirable, to support human usage:</p>
<ul>
<li>less noisy / less pedantic syntax</li>
<li>ability to refer to another part of the configuration (set a value to another value)</li>
<li>import/include another configuration file into the current file</li>
<li>a mapping to a flat properties list such as Java’s system properties</li>
<li>ability to get values from environment variables</li>
<li>ability to write comments</li>
</ul>
<p>约束：utf8编码</p>
<h4 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 单行注释</span><br><span class="line">a &#x3D; 1 &#x2F;&#x2F; 单行注释</span><br><span class="line">b &#x3D; 2 # 单行注释</span><br><span class="line">c &#x3D; [3, # 行内注释 # 4]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="赋值与嵌套"><a href="#赋值与嵌套" class="headerlink" title="赋值与嵌套"></a>赋值与嵌套</h4><h5 id="普通赋值"><a href="#普通赋值" class="headerlink" title="普通赋值"></a>普通赋值</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a : 1</span><br><span class="line">a &#x3D; 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="（对象）嵌套赋值"><a href="#（对象）嵌套赋值" class="headerlink" title="（对象）嵌套赋值"></a>（对象）嵌套赋值</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;foo&quot; : &#123; &quot;a&quot; : 42 &#125;,</span><br><span class="line">    &quot;foo&quot; : &#123; &quot;b&quot; : 43 &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;foo&quot; : &#123; &quot;a&quot; : 42, &quot;b&quot; : 43 &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo.bar : 42</span><br><span class="line">foo &#123; bar : 42 &#125;</span><br><span class="line"></span><br><span class="line">foo.bar.baz : 42</span><br><span class="line">foo &#123; bar &#123; baz : 42 &#125; &#125;</span><br><span class="line"></span><br><span class="line">a.x : 42, a.y : 43</span><br><span class="line">a &#123; x : 42, y : 43 &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="多种格式"><a href="#多种格式" class="headerlink" title="多种格式"></a>多种格式</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;foo&quot; : &#123;</span><br><span class="line">        &quot;bar&quot; : 10,</span><br><span class="line">        &quot;baz&quot; : 12</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo : &#123;</span><br><span class="line">    bar : 10,</span><br><span class="line">    baz : 12</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo &#123;</span><br><span class="line">    bar &#x3D; 10</span><br><span class="line">    baz &#x3D; 12</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo.bar&#x3D;10</span><br><span class="line">foo.baz&#x3D;12</span><br><span class="line"></span><br><span class="line">foo.bar&#x3D;10, foo.baz&#x3D;12</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="多行赋值"><a href="#多行赋值" class="headerlink" title="多行赋值"></a>多行赋值</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">logo &#x3D; &quot;&quot;&quot;hello</span><br><span class="line">world&quot;&quot;&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="数组与对象合并"><a href="#数组与对象合并" class="headerlink" title="数组与对象合并"></a>数组与对象合并</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; one object</span><br><span class="line">a : &#123; b : 1, c : 2 &#125;</span><br><span class="line">&#x2F;&#x2F; two objects that are merged via concatenation rules</span><br><span class="line">a : &#123; b : 1 &#125; &#123; c : 2 &#125;</span><br><span class="line">&#x2F;&#x2F; two fields that are merged</span><br><span class="line">a : &#123; b : 1 &#125;</span><br><span class="line">a : &#123; c : 2 &#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; one array</span><br><span class="line">a : [ 1, 2, 3, 4 ]</span><br><span class="line">&#x2F;&#x2F; two arrays that are concatenated</span><br><span class="line">a : [ 1, 2 ] [ 3, 4 ]</span><br><span class="line">&#x2F;&#x2F; a later definition referring to an earlier</span><br><span class="line">&#x2F;&#x2F; (see &quot;self-referential substitutions&quot; below)</span><br><span class="line">a : [ 1, 2 ]</span><br><span class="line">a : $&#123;a&#125; [ 3, 4 ]</span><br><span class="line"></span><br><span class="line">path &#x3D; [ &#x2F;bin ]</span><br><span class="line">path &#x3D; $&#123;path&#125; [ &#x2F;usr&#x2F;bin ]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="对象的继承"><a href="#对象的继承" class="headerlink" title="对象的继承"></a>对象的继承</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data-center-generic &#x3D; &#123; cluster-size &#x3D; 6 &#125;</span><br><span class="line">data-center-east &#x3D; $&#123;data-center-generic&#125; &#123; name &#x3D; &quot;east&quot; &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="合并还是覆盖"><a href="#合并还是覆盖" class="headerlink" title="合并还是覆盖"></a>合并还是覆盖</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123; a : &#123; x : 1 &#125; &#125; (first priority)</span><br><span class="line">&#123; a : 42 &#125; (fallback)</span><br><span class="line">&#123; a : &#123; y : 2 &#125; &#125; (another fallback)</span><br><span class="line"># result in &#123; a : &#123; x : 1 &#125; &#125;</span><br><span class="line"></span><br><span class="line">&#123; a : &#123; x : 1 &#125; &#125; (first priority)</span><br><span class="line">&#123; a : &#123; y : 2 &#125; &#125; (fallback)</span><br><span class="line">&#123; a : 42 &#125; (another fallback)</span><br><span class="line"># result in &#123; a : &#123; x : 1, y : 2 &#125; &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h4><p>使用这样的语法 <code>$&#123;pathexpression&#125; or $&#123;?pathexpression&#125;</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">animal.favorite &#x3D; dog</span><br><span class="line">key : $&#123;animal.favorite&#125; is my favorite animal</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>pathexpression</code>是绝对路径，替换是config对象构建的最后一步。</p>
<h4 id="Include"><a href="#Include" class="headerlink" title="Include"></a>Include</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">include &quot;foo&quot;</span><br><span class="line"></span><br><span class="line">include &quot;foo.properties&quot;</span><br><span class="line">include &quot;foo.json&quot;</span><br><span class="line">include &quot;foo.conf&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="内置转换API"><a href="#内置转换API" class="headerlink" title="内置转换API"></a>内置转换API</h4><p>自动转换，<a target="_blank" rel="noopener" href="https://github.com/typesafehub/config/blob/master/HOCON.md#duration-format">时间单位</a>（ns、ms、s、m、h etc），<a target="_blank" rel="noopener" href="https://github.com/typesafehub/config/blob/master/HOCON.md#size-in-bytes-format">文件大小</a>（kB、MB etc）</p>
<h3 id="文件载入顺序"><a href="#文件载入顺序" class="headerlink" title="文件载入顺序"></a>文件载入顺序</h3><p>依次载入合并</p>
<ul>
<li>引用 jar 包中的 reference.conf 库引用配置</li>
<li>引用 jar 包中的 application.{conf,json,properties} 应用配置</li>
<li>本地 reference.conf 库引用配置</li>
<li>本地 application.{conf,json,properties} 应用配置</li>
<li>system properties</li>
</ul>
<h3 id="在java代码中使用"><a href="#在java代码中使用" class="headerlink" title="在java代码中使用"></a>在java代码中使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 配置内容</span><br><span class="line">foo&#x3D;42</span><br><span class="line">dev.foo&#x3D;57</span><br><span class="line">prod.foo&#x3D;10</span><br><span class="line"></span><br><span class="line">import com.typesafe.config.ConfigFactory</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 载入根配置</span><br><span class="line">Config conf &#x3D; ConfigFactory.load();</span><br><span class="line">int foo1 &#x3D; conf.getInt(&quot;dev.foo&quot;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 载入某个对象</span><br><span class="line">Config prod &#x3D; conf.getConfig(&quot;prod&quot;);</span><br><span class="line">int foo2 &#x3D; foo.getInt(&quot;foo&quot;);</span><br><span class="line"></span><br><span class="line">Config devConfig &#x3D; conf</span><br><span class="line">                     .getConfig(&quot;dev&quot;)</span><br><span class="line">                     .withFallback(originalConfig)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; handle default</span><br><span class="line">&#x2F;&#x2F; boolean getBoolean(String path, boolean fallback)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h3><p>使用下面的方法，会把最终所有的配置信息打印出来</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logger.debug(myConfig.root().render())</span><br></pre></td></tr></table></figure>
<p>输出结果中包含所有载入的配置，如果使用了conf文件，会将对应文件的行信息也打印出来：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    # system properties</span><br><span class="line">    &quot;awt&quot; : &#123;</span><br><span class="line">        # system properties</span><br><span class="line">        &quot;toolkit&quot; : &quot;sun.awt.windows.WToolkit&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    # complex1.conf: 2</span><br><span class="line">    # these are our own config values defined by the app</span><br><span class="line">    &quot;complex-app&quot; : &#123;</span><br><span class="line">        # complex1.conf: 3</span><br><span class="line">        &quot;something&quot; : &quot;This value comes from complex-app&#39;s complex1.conf&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/typesafehub/config">https://github.com/typesafehub/config</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/database/MySQL/01.MySQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/database/MySQL/01.MySQL/" class="post-title-link" itemprop="url">MacOS中MySQL密码丢失处理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="01-MySQL"><a href="#01-MySQL" class="headerlink" title="01.MySQL"></a>01.MySQL</h1><h2 id="修改root密码-不成功"><a href="#修改root密码-不成功" class="headerlink" title="修改root密码 不成功"></a>修改root密码 不成功</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Open &amp; Edit /etc/my.cnf or /etc/mysql/my.cnf, depending on your distro.</span><br><span class="line">Add skip-grant-tables under [mysqld]</span><br><span class="line">Restart Mysql</span><br><span class="line">You should be able to login to mysql now using the below command mysql -u root -p</span><br><span class="line">Run mysql&gt; flush privileges;</span><br><span class="line">Set new password by ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;NewPassword&#x27;;</span><br><span class="line">Go back to /etc/my.cnf and remove/comment skip-grant-tables</span><br><span class="line">Restart Mysql</span><br><span class="line">Now you will be able to login with the new password mysql -u root -p</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> drop user root@localhost;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> flush privileges;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> create user root@localhost identified by <span class="string">&#x27;abc.123&#x27;</span>;</span></span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"></span><br><span class="line">grant all privileges on *.* to root@localhost;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<h2 id="mac-brew重装-不成功"><a href="#mac-brew重装-不成功" class="headerlink" title="mac brew重装 不成功"></a>mac brew重装 不成功</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brew uninstall mysql --ignore-dependencies</span><br><span class="line">sudo rm -rf /usr/local/Cellar/mysql</span><br><span class="line">brew cleanup</span><br><span class="line">sudo rm -rf /usr/local/var/mysql</span><br><span class="line">brew install mysql</span><br></pre></td></tr></table></figure>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_zxg_hot_news_result <span class="keyword">add</span> index</span><br><span class="line"> idx_hot_news_cnt (ftype,fcnt,ftime,fnews_id,fmsg_type);</span><br></pre></td></tr></table></figure>
<h3 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_zxg_hot_news_result <span class="keyword">drop</span> index idx_hot_news_cnt ;</span><br></pre></td></tr></table></figure>
<h3 id="查询索引"><a href="#查询索引" class="headerlink" title="查询索引"></a>查询索引</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> index <span class="keyword">from</span> t_zxg_hot_news_result;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">Table</span>                 <span class="operator">|</span> Non_unique <span class="operator">|</span> Key_name         <span class="operator">|</span> Seq_in_index <span class="operator">|</span> Column_name <span class="operator">|</span> <span class="keyword">Collation</span> <span class="operator">|</span> <span class="keyword">Cardinality</span> <span class="operator">|</span> Sub_part <span class="operator">|</span> Packed <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Index_type <span class="operator">|</span> Comment <span class="operator">|</span> Index_comment <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">0</span>          <span class="operator">|</span> <span class="keyword">PRIMARY</span>          <span class="operator">|</span> <span class="number">1</span>            <span class="operator">|</span> fid         <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">765715</span>      <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">1</span>            <span class="operator">|</span> ftype       <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">5</span>           <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">2</span>            <span class="operator">|</span> fcnt        <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">4072</span>        <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">3</span>            <span class="operator">|</span> ftime       <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">49236</span>       <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span> YES  <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">4</span>            <span class="operator">|</span> fnews_id    <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">800020</span>      <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t_zxg_hot_news_result <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> idx_hot_news_cnt <span class="operator">|</span> <span class="number">5</span>            <span class="operator">|</span> fmsg_type   <span class="operator">|</span> A         <span class="operator">|</span> <span class="number">792176</span>      <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span>   <span class="operator">|</span> <span class="operator">&lt;</span><span class="keyword">null</span><span class="operator">&gt;</span> <span class="operator">|</span>      <span class="operator">|</span> BTREE      <span class="operator">|</span>         <span class="operator">|</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span></span><br></pre></td></tr></table></figure>





      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/tool/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/tool/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86/" class="post-title-link" itemprop="url">Java中优雅的加解密</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tool/" itemprop="url" rel="index"><span itemprop="name">tool</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="加密与解密"><a href="#加密与解密" class="headerlink" title="加密与解密"></a>加密与解密</h1><h2 id="AES"><a href="#AES" class="headerlink" title="AES"></a>AES</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.security.InvalidKeyException;</span><br><span class="line"><span class="keyword">import</span> java.security.NoSuchAlgorithmException;</span><br><span class="line"><span class="keyword">import</span> java.security.SecureRandom;</span><br><span class="line"><span class="keyword">import</span> java.util.Base64;</span><br><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.crypto.BadPaddingException;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.Cipher;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.IllegalBlockSizeException;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.KeyGenerator;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.NoSuchPaddingException;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.SecretKey;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.spec.SecretKeySpec;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sun.misc.BASE64Decoder;</span><br><span class="line"><span class="keyword">import</span> sun.misc.BASE64Encoder;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * AES对称加密和解密</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SymmetricEncoder</span> </span>&#123;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * 加密</span></span><br><span class="line"><span class="comment">   * 1.构造密钥生成器</span></span><br><span class="line"><span class="comment">   * 2.根据ecnodeRules规则初始化密钥生成器</span></span><br><span class="line"><span class="comment">   * 3.产生密钥</span></span><br><span class="line"><span class="comment">   * 4.创建和初始化密码器</span></span><br><span class="line"><span class="comment">   * 5.内容加密</span></span><br><span class="line"><span class="comment">   * 6.返回字符串</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">AESEncode</span><span class="params">(String encodeRules,String content)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1.构造密钥生成器，指定为AES算法,不区分大小写</span></span><br><span class="line">            KeyGenerator keygen=KeyGenerator.getInstance(<span class="string">&quot;AES&quot;</span>);</span><br><span class="line">            <span class="comment">//2.根据ecnodeRules规则初始化密钥生成器</span></span><br><span class="line">            <span class="comment">//生成一个128位的随机源,根据传入的字节数组</span></span><br><span class="line">            keygen.init(<span class="number">128</span>, <span class="keyword">new</span> SecureRandom(encodeRules.getBytes()));</span><br><span class="line">              <span class="comment">//3.产生原始对称密钥</span></span><br><span class="line">            SecretKey original_key=keygen.generateKey();</span><br><span class="line">              <span class="comment">//4.获得原始对称密钥的字节数组</span></span><br><span class="line">            <span class="keyword">byte</span> [] raw=original_key.getEncoded();</span><br><span class="line">            <span class="comment">//5.根据字节数组生成AES密钥</span></span><br><span class="line">            SecretKey key=<span class="keyword">new</span> SecretKeySpec(raw, <span class="string">&quot;AES&quot;</span>);</span><br><span class="line">              <span class="comment">//6.根据指定算法AES自成密码器</span></span><br><span class="line">            Cipher cipher=Cipher.getInstance(<span class="string">&quot;AES&quot;</span>);</span><br><span class="line">              <span class="comment">//7.初始化密码器，第一个参数为加密(Encrypt_mode)或者解密解密(Decrypt_mode)操作，第二个参数为使用的KEY</span></span><br><span class="line">            cipher.init(Cipher.ENCRYPT_MODE, key);</span><br><span class="line">            <span class="comment">//8.获取加密内容的字节数组(这里要设置为utf-8)不然内容中如果有中文和英文混合中文就会解密为乱码</span></span><br><span class="line">            <span class="keyword">byte</span> [] byte_encode=content.getBytes(<span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">            <span class="comment">//9.根据密码器的初始化方式--加密：将数据加密</span></span><br><span class="line">            <span class="keyword">byte</span> [] byte_AES=cipher.doFinal(byte_encode);</span><br><span class="line">          <span class="comment">//10.将加密后的数据转换为字符串</span></span><br><span class="line">            <span class="comment">//这里用Base64Encoder中会找不到包</span></span><br><span class="line">            <span class="comment">//解决办法：</span></span><br><span class="line">            <span class="comment">//在项目的Build path中先移除JRE System Library，再添加库JRE System Library，重新编译后就一切正常了。</span></span><br><span class="line">            String AES_encode=<span class="keyword">new</span> String(<span class="keyword">new</span> BASE64Encoder().encode(byte_AES));</span><br><span class="line">          <span class="comment">//11.将字符串返回</span></span><br><span class="line">            <span class="keyword">return</span> AES_encode;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchPaddingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InvalidKeyException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalBlockSizeException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (BadPaddingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果有错就返加nulll</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 解密</span></span><br><span class="line"><span class="comment">     * 解密过程：</span></span><br><span class="line"><span class="comment">     * 1.同加密1-4步</span></span><br><span class="line"><span class="comment">     * 2.将加密后的字符串反纺成byte[]数组</span></span><br><span class="line"><span class="comment">     * 3.将加密内容解密</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">AESDncode</span><span class="params">(String encodeRules,String content)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1.构造密钥生成器，指定为AES算法,不区分大小写</span></span><br><span class="line">            KeyGenerator keygen=KeyGenerator.getInstance(<span class="string">&quot;AES&quot;</span>);</span><br><span class="line">            <span class="comment">//2.根据ecnodeRules规则初始化密钥生成器</span></span><br><span class="line">            <span class="comment">//生成一个128位的随机源,根据传入的字节数组</span></span><br><span class="line">            keygen.init(<span class="number">128</span>, <span class="keyword">new</span> SecureRandom(encodeRules.getBytes()));</span><br><span class="line">              <span class="comment">//3.产生原始对称密钥</span></span><br><span class="line">            SecretKey original_key=keygen.generateKey();</span><br><span class="line">              <span class="comment">//4.获得原始对称密钥的字节数组</span></span><br><span class="line">            <span class="keyword">byte</span> [] raw=original_key.getEncoded();</span><br><span class="line">            <span class="comment">//5.根据字节数组生成AES密钥</span></span><br><span class="line">            SecretKey key=<span class="keyword">new</span> SecretKeySpec(raw, <span class="string">&quot;AES&quot;</span>);</span><br><span class="line">              <span class="comment">//6.根据指定算法AES自成密码器</span></span><br><span class="line">            Cipher cipher=Cipher.getInstance(<span class="string">&quot;AES&quot;</span>);</span><br><span class="line">              <span class="comment">//7.初始化密码器，第一个参数为加密(Encrypt_mode)或者解密(Decrypt_mode)操作，第二个参数为使用的KEY</span></span><br><span class="line">            cipher.init(Cipher.DECRYPT_MODE, key);</span><br><span class="line">            <span class="comment">//8.将加密并编码后的内容解码成字节数组</span></span><br><span class="line">            <span class="keyword">byte</span> [] byte_content= <span class="keyword">new</span> BASE64Decoder().decodeBuffer(content);</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 解密</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">byte</span> [] byte_decode=cipher.doFinal(byte_content);</span><br><span class="line">            String AES_decode=<span class="keyword">new</span> String(byte_decode,<span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> AES_decode;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchPaddingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InvalidKeyException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalBlockSizeException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (BadPaddingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果有错就返加nulll</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SymmetricEncoder se=<span class="keyword">new</span> SymmetricEncoder();</span><br><span class="line">        Scanner scanner=<span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 加密</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        System.out.println(<span class="string">&quot;使用AES对称加密，请输入加密的规则&quot;</span>);</span><br><span class="line">        String encodeRules=scanner.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;请输入要加密的内容:&quot;</span>);</span><br><span class="line">        String content = scanner.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;根据输入的规则&quot;</span>+encodeRules+<span class="string">&quot;加密后的密文是:&quot;</span>+se.AESEncode(encodeRules, content));</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 解密</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        System.out.println(<span class="string">&quot;使用AES对称解密，请输入加密的规则：(须与加密相同)&quot;</span>);</span><br><span class="line">         encodeRules=scanner.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;请输入要解密的内容（密文）:&quot;</span>);</span><br><span class="line">         content = scanner.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;根据输入的规则&quot;</span>+encodeRules+<span class="string">&quot;解密后的明文是:&quot;</span>+se.AESDncode(encodeRules, content));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Apache-commons-codec"><a href="#Apache-commons-codec" class="headerlink" title="Apache commons codec"></a>Apache commons codec</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-codec<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-codec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1、MD5加密</span></span><br><span class="line">String md5Str = DigestUtils.md5Hex(str);</span><br><span class="line">System.out.println(<span class="string">&quot;MD5--&gt;&quot;</span> + md5Str);</span><br><span class="line"></span><br><span class="line"><span class="comment">//SHA1加密</span></span><br><span class="line">String sha1Str = DigestUtils.sha1Hex(str);</span><br><span class="line">System.out.println(<span class="string">&quot;SHA1--&gt;&quot;</span> + sha1Str);</span><br><span class="line"></span><br><span class="line"><span class="comment">//Base64加密</span></span><br><span class="line">String base64Str = Base64.encodeBase64String(str.getBytes());</span><br><span class="line">System.out.println(<span class="string">&quot;base64加密--&gt;&quot;</span> + base64Str);</span><br><span class="line"></span><br><span class="line"><span class="comment">//Base64解密</span></span><br><span class="line">String base64DecodeStr = <span class="keyword">new</span> String(Base64.decodeBase64(base64Str));</span><br><span class="line">System.out.println(<span class="string">&quot;base64解密--&gt;&quot;</span> + base64DecodeStr);</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/database/MySQL/02.InnoDBLocks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/database/MySQL/02.InnoDBLocks/" class="post-title-link" itemprop="url">InnoDB中的锁机制</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="InnoDB中的锁机制"><a href="#InnoDB中的锁机制" class="headerlink" title="InnoDB中的锁机制"></a>InnoDB中的锁机制</h1><p>获取锁争用情况</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mysql root<span class="variable">@localhost</span>:dlock<span class="operator">&gt;</span> <span class="keyword">show</span> status <span class="keyword">like</span> <span class="string">&#x27;innodb_row_lock%&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name                 <span class="operator">|</span> <span class="keyword">Value</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_current_waits <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time          <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time_avg      <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time_max      <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_waits         <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span></span><br><span class="line"><span class="type">Time</span>: <span class="number">0.012</span>s</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Oceanus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Oceanus/" class="post-title-link" itemprop="url">Oceanus: table meta API</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:01" itemprop="dateModified" datetime="2021-04-12T17:35:01+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Oceanus"><a href="#Oceanus" class="headerlink" title="Oceanus"></a>Oceanus</h1><h2 id="拉取库表信息"><a href="#拉取库表信息" class="headerlink" title="拉取库表信息"></a>拉取库表信息</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -o tank_pos_meta.json &#x27;http://&lt;host&gt;:&lt;port&gt;/ec/v1/listTable?pageNum=1&amp;pageSize=999&amp;type=hippo&amp;dbName=bank-pos-info&amp;name=pos_yyyymmdd&#x27;</span><br></pre></td></tr></table></figure>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;result_code&quot;</span>: <span class="string">&quot;0&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;result_msg&quot;</span>: <span class="string">&quot;操作成功&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;result_content&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;tables&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">&quot;id&quot;</span>: <span class="number">2255</span>,</span><br><span class="line">                <span class="attr">&quot;dbName&quot;</span>: <span class="string">&quot;info&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;pos_yyyymmdd&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;hippo&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;principals&quot;</span>: <span class="string">&quot;user_name&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;fields&quot;</span>: <span class="string">&quot;db_name,String,db_name: tb_name,String,tb_name: op_name,String,op_name: exp_time_stample,String,exp_time_stample: exp_time_stample_order,String,exp_time_stample_order: Fbill_no,String,Fbill_no: Fbank_type,Long,Fbank_type: Fbiz_type,Long,Fbiz_type: Fpos_status,Long,Fpos_status: Freverse_status,Long,Freverse_status: Freverse_times,Long,Freverse_times: Ftransaction_id,String,Ftransaction_id: Freal_bill_no,String,Freal_bill_no: Ftrace_no,String,Ftrace_no: Ftx_date,String,Ftx_date: Famount,Long,Famount: Fcur_type,Long,Fcur_type: Fuin,String,Fuin: Fuid,Long,Fuid: Fuser_name,String,Fuser_name: Fuser_id_type,Long,Fuser_id_type: Fuser_id,String,Fuser_id: Fuser_phone,String,Fuser_phone: Fcard_no,String,&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;content&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;银行pos流水&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;attributes&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;table.topic&quot;</span>: <span class="string">&quot;sample_pos&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.bid&quot;</span>: <span class="string">&quot;sample_pos&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;data.encode&quot;</span>: <span class="string">&quot;UTF8&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.hippo.addrlist&quot;</span>: <span class="string">&quot;&lt;hippo_master&gt;&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.package&quot;</span>: <span class="string">&quot;true&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.interfaceId&quot;</span>: <span class="string">&quot;t_sample_pos_yyyymmdd&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;source.data.type&quot;</span>: <span class="string">&quot;data.type.default&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.needwatermark&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.kv&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.field.splitter&quot;</span>: <span class="string">&quot;0x1&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;is.temporal.table&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.field.splitter.other&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.usage&quot;</span>: <span class="string">&quot;table&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.used&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.running.used&quot;</span>: <span class="string">&quot;false&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">&quot;modifier&quot;</span>: <span class="string">&quot;&lt;table_owner&gt;&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modify_time&quot;</span>: <span class="number">1563420065831</span>,</span><br><span class="line">                <span class="attr">&quot;create_time&quot;</span>: <span class="number">1563420065831</span>,</span><br><span class="line">                <span class="attr">&quot;tablesLogs&quot;</span>: <span class="literal">null</span></span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">&quot;total&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;pageNum&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;pageSize&quot;</span>: <span class="number">999</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="flink的优化"><a href="#flink的优化" class="headerlink" title="flink的优化"></a>flink的优化</h2><h3 id="JobManager-failover"><a href="#JobManager-failover" class="headerlink" title="JobManager failover"></a>JobManager failover</h3><p><img src="_v_images/20200601183746039_28243.png"></p>
<p>它的 standby 节点是冷备的，JobManager 的切换会导致它管理的所有 Job 都会被重启恢复，这一行为在我们现网环境中是不可接受的。所以，我们首先定制的第一个大特性就是<br>JobManager 的 failover 优化，让 standby 节点变成热备，这使得 JobManager 的切换对 TaskManager 上已经正在运行的 Job 不产生影响。我们已经对 Standalone 以及 Flink on YARN 这两种部署模式支持了这个特性，Flink on YARN 的支持还处于内部验证阶段。我们以对 Standalone 模式的优化为例来进行分析，它主要包含这么几个步骤：</p>
<ul>
<li>取消 JobManager 跟 TaskManager 因为心跳超时或 Leadership 变动就 cancel task 的行为；</li>
<li>对 ExecutionGraph 核心数据的快照；</li>
<li>通过 ExecutionGraphBuilder 重构空的 ExecutionGraph 加上快照重置来恢复出一个跟原先等价的 ExecutionGraph 对象；</li>
<li>TaskManager 跟新的 JobManager leader 建立连接后以心跳上报自己的状态和必要的信息；<br>新的 JobManager 确认在 reconcile 阶段 Job 的所有 task 是否正常运行。</li>
</ul>
<h3 id="checkpoint失败改进"><a href="#checkpoint失败改进" class="headerlink" title="checkpoint失败改进"></a>checkpoint失败改进</h3><p><img src="_v_images/20200601185553966_3881.png"><br>社区版当前的处理机制。JobMaster 中，每个 Job 会对应一个 Checkpoint Coordinator，它用来管理并协调 Job 检查点的执行。当到达一个检查点的触发周期，Coordinator 会对所有的 Source Task 下发 TriggerCheckpoint 消息，source task 会在自身完成快照后向下游广播 CheckpointBarrier，作为下游 task 触发的通知。其中，如果一个 task 在执行检查点时失败了，这取决于用户是否容忍这个失败（通过一个配置项），如果选择不容忍那么这个失败将变成一个异常导致 task 的失败，与此同时 task 的失败将会通知到 JobMaster，JobMaster 将会通知这个 Job 的其他 task 取消它们的执行。现有的机制存在一些问题：</p>
<ul>
<li>Coordinator 并不能控制 Job 是否容忍检查点失败，因为控制权在 task 端；</li>
<li>Coordinator 当前的失败处理代码逻辑混乱，区分出了触发阶段，却忽略了执行阶段；</li>
<li>无法实现容忍多少个连续的检查点失败则让 Job 失败的逻辑。</li>
</ul>
<p><img src="_v_images/20200601190109255_17290.png"><br>首先，我们对源码中 checkpoint package 下的相关类进行了重构，使得它不再区分触发阶段，引进了更多的检查点失败原因的枚举并重构了相关的代码。然后我们引入了 CheckpointFailureManager 组件，用来统一失败管理，同时为了适配更灵活的容忍失败的能力，我们引入了检查点失败计数器机制。现在，当我们遇到检查点失败后，这个失败信息会直接上报到 Coordinator，而是否要让 Job 失败具体的决策则由 CheckpointFailureManager 作出，这就<strong>使得 Coordinator 具有了完整的检查点控制权，而决策权转让给 CheckpointFailureManager，则充分实现了逻辑解耦</strong>。</p>
<h3 id="AsyncIO超时"><a href="#AsyncIO超时" class="headerlink" title="AsyncIO超时"></a>AsyncIO超时</h3><h3 id="sql-editor"><a href="#sql-editor" class="headerlink" title="sql editor"></a>sql editor</h3><p>ace editor</p>
<h3 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h3><p>[averyzhang@tdw-<ip> /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646]$ ll<br>总用量 32<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 blobStore-b0fe739d-d5e0-4a87-9c34-2a2492fc84a6<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 blobStore-f8cdfc9d-d7d2-4fb6-9836-da65b414b45a<br>drwxr-s—  3 u_teg_tdbank users 4096 6月   5 16:07 container_e03_1542247480019_1646_01_000002<br>drwx–x— 11 u_teg_tdbank users 4096 6月   5 16:07 filecache<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 flink-dist-cache-d55b9eaa-87b9-404e-a015-c4c90c767ac9<br>drwxr-s—  8 u_teg_tdbank users 4096 6月   5 16:07 flink-io-0bd3c6be-79ef-41d6-95ec-f42a949a10f1<br>drwxr-s—  4 u_teg_tdbank users 4096 6月   5 16:07 localState<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 rocksdb-lib-89c57e29c492279dc1e188992c87925e</p>
<p>[averyzhang@tdw-<ip> /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646]$ tree<br>.<br>|– blobStore-b0fe739d-d5e0-4a87-9c34-2a2492fc84a6<br>|– blobStore-f8cdfc9d-d7d2-4fb6-9836-da65b414b45a<br>|– container_e03_1542247480019_1646_01_000002<br>|   |– container_tokens<br>|   |– flink-conf.yaml -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/10/91db3812-bb43-492d-8c32-359b2c21a142-taskmanager-conf.yaml<br>|   |– flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/15/flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar<br>|   |– kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/11/kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar<br>|   |– launch_container.sh<br>|   |– lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/12/lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar<br>|   |– log4j.properties -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/17/log4j.properties<br>|   |– log4j.zip -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/14/log4j.zip<br>|   |– oceanus-common-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/13/oceanus-common-1.1.0-SNAPSHOT.jar<br>|   |– oceanus-core-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/16/oceanus-core-1.1.0-SNAPSHOT.jar<br>|   |– oceanus-ml-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/18/oceanus-ml-1.1.0-SNAPSHOT.jar<br>|   <code>-- tmp |-- filecache [error opening dir] |-- flink-dist-cache-d55b9eaa-87b9-404e-a015-c4c90c767ac9 |-- flink-io-0bd3c6be-79ef-41d6-95ec-f42a949a10f1 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_337adade1e207453ed3502e01d75fd03__1_8__uuid_6d0d5c24-bb66-4793-afa4-7a7e3c3ffd6a |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024751.sst<br>|   |       |– 024753.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_337adade1e207453ed3502e01d75fd03__2_8__uuid_18ea3048-b73d-482d-b6c9-615452280981 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024739.sst<br>|   |       |– 024741.sst<br>|   |       |– 024742.sst<br>|   |       |– 024743.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_be465a1f98956392d0b820196e75d12b__1_8__uuid_efd7a85c-2a15-4d62-9929-60624dd6ea4a |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024741.sst<br>|   |       |– 024743.sst<br>|   |       |– 024744.sst<br>|   |       |– 024745.sst<br>|   |       |– 024746.sst<br>|   |       |– 024747.sst<br>|   |       |– 024748.sst<br>|   |       |– 024749.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_be465a1f98956392d0b820196e75d12b__2_8__uuid_e666a8b1-d26d-4688-b089-0a957e49f947 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024740.sst<br>|   |       |– 024742.sst<br>|   |       |– 024743.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_eaecdab2f3df15db186c08e889659492__1_8__uuid_24efb767-bdf2-4309-a136-302cc4a18399 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024741.sst<br>|   |       |– 024743.sst<br>|   |       |– 024744.sst<br>|   |       |– 024745.sst<br>|   |       |– 024746.sst<br>|   |       |– 024747.sst<br>|   |       |– 024748.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   </code>– job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_eaecdab2f3df15db186c08e889659492__2_8__uuid_776c72fa-68fa-493b-b9ab-03461406816a<br>|       <code>-- db |           |-- 000013.log |           |-- 024740.sst |           |-- 024742.sst |           |-- 024743.sst |           |-- CURRENT |           |-- IDENTITY |           |-- LOCK |           |-- LOG |           |-- MANIFEST-000006 |           |-- OPTIONS-000010 |           </code>– OPTIONS-000012<br>|– localState<br>|   |– aid_AllocationID{e1f41e5a166354d80ad6d6b8d3765fa1}<br>|   <code>-- aid_AllocationID&#123;e6e7f806bb078db66f50eeb3a48f0da9&#125; </code>– rocksdb-lib-89c57e29c492279dc1e188992c87925e<br>    `– librocksdbjni-linux64.so</p>
<p>23 directories, 87 files</p>
<p>[averyzhang@tdw-<ip> /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/container_e03_1542247480019_1646_01_000002]$ ll<br>总用量 52<br>-rw——- 1 u_teg_tdbank users   69 6月   5 16:07 container_tokens<br>lrwxrwxrwx 1 u_teg_tdbank users  154 6月   5 16:07 flink-conf.yaml -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/10/91db3812-bb43-492d-8c32-359b2c21a142-taskmanager-conf.yaml<br>lrwxrwxrwx 1 u_teg_tdbank users  151 6月   5 16:07 flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/15/flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  146 6月   5 16:07 kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/11/kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar<br>-rwx—— 1 u_teg_tdbank users 6328 6月   5 16:07 launch_container.sh<br>lrwxrwxrwx 1 u_teg_tdbank users  164 6月   5 16:07 lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/12/lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  112 6月   5 16:07 log4j.properties -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/17/log4j.properties<br>lrwxrwxrwx 1 u_teg_tdbank users  105 6月   5 16:07 log4j.zip -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/14/log4j.zip<br>lrwxrwxrwx 1 u_teg_tdbank users  129 6月   5 16:07 oceanus-common-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/13/oceanus-common-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  127 6月   5 16:07 oceanus-core-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/16/oceanus-core-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  125 6月   5 16:07 oceanus-ml-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/18/oceanus-ml-1.1.0-SNAPSHOT.jar<br>drwxr-s— 2 u_teg_tdbank users 4096 6月   5 16:07 tmp</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/HBaseConnectors/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/HBaseConnectors/" class="post-title-link" itemprop="url">Flink:HBaseConnectors</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-HBase-connectors"><a href="#Flink-HBase-connectors" class="headerlink" title="Flink HBase connectors"></a>Flink HBase connectors</h1><h2 id="flighting"><a href="#flighting" class="headerlink" title="flighting"></a>flighting</h2><p>奇怪，没有依赖HBase-Client，而是依赖了HBase-server</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-hadoop2-compat<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">type</span>&gt;</span>test-jar<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="添加文件到ClassLoader的classpath"><a href="#添加文件到ClassLoader的classpath" class="headerlink" title="添加文件到ClassLoader的classpath"></a>添加文件到ClassLoader的classpath</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Get the classloader actually used by HBaseConfiguration</span></span><br><span class="line">ClassLoader classLoader = HBaseConfiguration.create().getClassLoader();</span><br><span class="line"><span class="keyword">if</span> (!(classLoader <span class="keyword">instanceof</span> URLClassLoader)) &#123;</span><br><span class="line">	fail(<span class="string">&quot;We should get a URLClassLoader&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Make the addURL method accessible</span></span><br><span class="line">Method method = URLClassLoader.class.getDeclaredMethod(<span class="string">&quot;addURL&quot;</span>, URL.class);</span><br><span class="line">method.setAccessible(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add the directory where we put the hbase-site.xml to the classpath</span></span><br><span class="line">method.invoke(classLoader, directory.toURI().toURL());</span><br></pre></td></tr></table></figure>








      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/%E8%BF%BD%E6%BA%90%E7%B4%A2%E9%AA%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/%E8%BF%BD%E6%BA%90%E7%B4%A2%E9%AA%A5/" class="post-title-link" itemprop="url">【转载】Flink追源索骥</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:01" itemprop="dateModified" datetime="2021-04-12T17:35:01+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="追源索骥：透过源码看懂Flink核心框架的执行流程"><a href="#追源索骥：透过源码看懂Flink核心框架的执行流程" class="headerlink" title="追源索骥：透过源码看懂Flink核心框架的执行流程"></a>追源索骥：透过源码看懂Flink核心框架的执行流程</h1><p>标签（空格分隔）： flink</p>
<hr>
<p>[TOC]</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Flink是大数据处理领域最近很火的一个开源的分布式、高性能的流式处理框架，其对数据的处理可以达到毫秒级别。本文以一个来自官网的WordCount例子为引，全面阐述flink的核心架构及执行流程，希望读者可以借此更加深入的理解Flink逻辑。</p>
<blockquote>
<p>本文跳过了一些基本概念，如果对相关概念感到迷惑，请参考官网文档。另外在本文写作过程中，Flink正式发布了其1.5 RELEASE版本，在其发布之后完成的内容将按照1.5的实现来组织。</p>
</blockquote>
<h2 id="1-从-Hello-World-WordCount开始"><a href="#1-从-Hello-World-WordCount开始" class="headerlink" title="1.从 Hello,World WordCount开始"></a>1.从 <del>Hello,World</del> WordCount开始</h2><p>首先，我们把WordCount的例子再放一遍：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SocketTextStreamWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (args.length != <span class="number">2</span>)&#123;</span><br><span class="line">		System.err.println(<span class="string">&quot;USAGE:\nSocketTextStreamWordCount &lt;hostname&gt; &lt;port&gt;&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	String hostName = args[<span class="number">0</span>];</span><br><span class="line">	Integer port = Integer.parseInt(args[<span class="number">1</span>]);</span><br><span class="line">	<span class="comment">// set up the execution environment</span></span><br><span class="line">	<span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment</span><br><span class="line">			.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// get input data</span></span><br><span class="line">	DataStream&lt;String&gt; text = env.socketTextStream(hostName, port);</span><br><span class="line">	</span><br><span class="line">	text.flatMap(<span class="keyword">new</span> LineSplitter()).setParallelism(<span class="number">1</span>)</span><br><span class="line">	<span class="comment">// group by the tuple field &quot;0&quot; and sum up tuple field &quot;1&quot;</span></span><br><span class="line">			.keyBy(<span class="number">0</span>)</span><br><span class="line">			.sum(<span class="number">1</span>).setParallelism(<span class="number">1</span>)</span><br><span class="line">			.print();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// execute program</span></span><br><span class="line">	env.execute(<span class="string">&quot;Java WordCount from SocketTextStream Example&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Implements the string tokenizer that splits sentences into words as a user-defined</span></span><br><span class="line"><span class="comment">	 * FlatMapFunction. The function takes a line (String) and splits it into</span></span><br><span class="line"><span class="comment">	 * multiple pairs in the form of &quot;(word,1)&quot; (Tuple2&amp;lt;String, Integer&amp;gt;).</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">LineSplitter</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">			<span class="comment">// normalize and split the line</span></span><br><span class="line">			String[] tokens = value.toLowerCase().split(<span class="string">&quot;\\W+&quot;</span>);</span><br><span class="line">			<span class="comment">// emit the pairs</span></span><br><span class="line">			<span class="keyword">for</span> (String token : tokens) &#123;</span><br><span class="line">				<span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">					out.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(token, <span class="number">1</span>));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>首先从命令行中获取socket对端的ip和端口，然后启动一个执行环境，从socket中读取数据，split成单个单词的流，并按单词进行总和的计数，最后打印出来。这个例子相信接触过大数据计算或者函数式编程的人都能看懂，就不过多解释了。</p>
<h3 id="1-1-flink执行环境"><a href="#1-1-flink执行环境" class="headerlink" title="1.1 flink执行环境"></a>1.1 flink执行环境</h3><p>程序的启动，从这句开始：<code> final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()</code>。<br>这行代码会返回一个可用的执行环境。执行环境是整个flink程序执行的上下文，记录了相关配置（如并行度等），并提供了一系列方法，如读取输入流的方法，以及真正开始运行整个代码的execute方法等。对于分布式流处理程序来说，我们在代码中定义的flatMap,keyBy等等操作，事实上可以理解为一种声明，告诉整个程序我们采用了什么样的算子，而真正开启计算的代码不在此处。由于我们是在本地运行flink程序，因此这行代码会返回一个LocalStreamEnvironment，最后我们要调用它的execute方法来开启真正的任务。我们先接着往下看。</p>
<h3 id="1-2-算子（Operator）的注册（声明）"><a href="#1-2-算子（Operator）的注册（声明）" class="headerlink" title="1.2 算子（Operator）的注册（声明）"></a>1.2 算子（Operator）的注册（声明）</h3><p>我们以flatMap为例,<code>text.flatMap(new LineSplitter())</code>这一句话跟踪进去是这样的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">flatMap</span><span class="params">(FlatMapFunction&lt;T, R&gt; flatMapper)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">		TypeInformation&lt;R&gt; outType = TypeExtractor.getFlatMapReturnTypes(clean(flatMapper),</span><br><span class="line">				getType(), Utils.getCallLocationName(), <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> transform(<span class="string">&quot;Flat Map&quot;</span>, outType, <span class="keyword">new</span> StreamFlatMap&lt;&gt;(clean(flatMapper)));</span><br><span class="line"></span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>里面完成了两件事，一是用反射拿到了flatMap算子的输出类型，二是生成了一个Operator。flink流式计算的核心概念，就是将数据从输入流一个个传递给Operator进行链式处理，最后交给输出流的过程。对数据的每一次处理在逻辑上成为一个operator，并且为了本地化处理的效率起见，operator之间也可以串成一个chain一起处理（可以参考责任链模式帮助理解）。下面这张图表明了flink是如何看待用户的处理流程的：抽象化为一系列operator，以source开始，以sink结尾，中间的operator做的操作叫做transform，并且可以把几个操作串在一起执行。<br><img src="http://static.zybuluo.com/bethunebtj/jal2x1y6zqs4jug4ryqnvu3l/image_1cae39t06eoo3ml1be8o0412c69.png" alt="image_1cae39t06eoo3ml1be8o0412c69.png-43.5kB"><br>我们也可以更改flink的设置，要求它不要对某个操作进行chain处理，或者从某个操作开启一个新chain等。<br>上面代码中的最后一行transform方法的作用是返回一个SingleOutputStreamOperator，它继承了Datastream类并且定义了一些辅助方法，方便对流的操作。在返回之前，transform方法还把它注册到了执行环境中（后面生成执行图的时候还会用到它）。其他的操作，包括keyBy，sum和print，都只是不同的算子，在这里出现都是一样的效果，即生成一个operator并注册给执行环境用于生成DAG。</p>
<h3 id="1-3-程序的执行"><a href="#1-3-程序的执行" class="headerlink" title="1.3 程序的执行"></a>1.3 程序的执行</h3><p>程序执行即<code>env.execute(&quot;Java WordCount from SocketTextStream Example&quot;)</code>这行代码。</p>
<h4 id="1-3-1-本地模式下的execute方法"><a href="#1-3-1-本地模式下的execute方法" class="headerlink" title="1.3.1 本地模式下的execute方法"></a>1.3.1 本地模式下的execute方法</h4><p>这行代码主要做了以下事情：</p>
<ul>
<li>生成StreamGraph。代表程序的拓扑结构，是从用户代码直接生成的图。</li>
<li>生成JobGraph。这个图是要交给flink去生成task的图。</li>
<li>生成一系列配置</li>
<li>将JobGraph和配置交给flink集群去运行。如果不是本地运行的话，还会把jar文件通过网络发给其他节点。</li>
<li>以本地模式运行的话，可以看到启动过程，如启动性能度量、web模块、JobManager、ResourceManager、taskManager等等</li>
<li>启动任务。值得一提的是在启动任务之前，先启动了一个用户类加载器，这个类加载器可以用来做一些在运行时动态加载类的工作。</li>
</ul>
<h4 id="1-3-2-远程模式（RemoteEnvironment）的execute方法"><a href="#1-3-2-远程模式（RemoteEnvironment）的execute方法" class="headerlink" title="1.3.2 远程模式（RemoteEnvironment）的execute方法"></a>1.3.2 远程模式（RemoteEnvironment）的execute方法</h4><p>远程模式的程序执行更加有趣一点。第一步仍然是获取StreamGraph，然后调用executeRemotely方法进行远程执行。<br>该方法首先创建一个用户代码加载器</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ClassLoader usercodeClassLoader = JobWithJars.buildUserCodeClassLoader(jarFiles, globalClasspaths,   getClass().getClassLoader());</span><br></pre></td></tr></table></figure>
<p>然后创建一系列配置，交给Client对象。Client这个词有意思，看见它就知道这里绝对是跟远程集群打交道的客户端。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ClusterClient client;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	client = <span class="keyword">new</span> StandaloneClusterClient(configuration);</span><br><span class="line">	client.setPrintStatusDuringExecution(getConfig().isSysoutLoggingEnabled());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> client.run(streamGraph, jarFiles, globalClasspaths, usercodeClassLoader).getJobExecutionResult();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>client的run方法首先生成一个JobGraph，然后将其传递给JobClient。关于Client、JobClient、JobManager到底谁管谁，可以看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/6hhl3e1fumlr0aq78d2m35nt/image_1cae7g15p6k94no1ves121c5pd9.png" alt="image_1cae7g15p6k94no1ves121c5pd9.png-19.7kB"><br>确切的说，JobClient负责以异步的方式和JobManager通信（Actor是scala的异步模块），具体的通信任务由JobClientActor完成。相对应的，JobManager的通信任务也由一个Actor完成。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JobListeningContext jobListeningContext = submitJob(actorSystem, config, highAvailabilityServices, jobGraph, timeout, sysoutLogUpdates,	classLoader);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> awaitJobResult(jobListeningContext);</span><br></pre></td></tr></table></figure>
<p>可以看到，该方法阻塞在awaitJobResult方法上，并最终返回了一个JobListeningContext，透过这个Context可以得到程序运行的状态和结果。</p>
<h4 id="1-3-3-程序启动过程"><a href="#1-3-3-程序启动过程" class="headerlink" title="1.3.3 程序启动过程"></a>1.3.3 程序启动过程</h4><p>上面提到，整个程序真正意义上开始执行，是这里：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.execute(<span class="string">&quot;Java WordCount from SocketTextStream Example&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>远程模式和本地模式有一点不同，我们先按本地模式来调试。<br>我们跟进源码，（在本地调试模式下）会启动一个miniCluster，然后开始执行代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LocalStreamEnvironment.java</span></span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">execute</span><span class="params">(String jobName)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//生成各种图结构</span></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">		    <span class="comment">//启动集群，包括启动JobMaster，进行leader选举等等</span></span><br><span class="line">			miniCluster.start();</span><br><span class="line">			configuration.setInteger(RestOptions.PORT, miniCluster.getRestAddress().getPort());</span><br><span class="line">            </span><br><span class="line">            <span class="comment">//提交任务到JobMaster</span></span><br><span class="line">			<span class="keyword">return</span> miniCluster.executeJobBlocking(jobGraph);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">finally</span> &#123;</span><br><span class="line">			transformations.clear();</span><br><span class="line">			miniCluster.close();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>这个方法里有一部分逻辑是与生成图结构相关的，我们放在第二章里讲；现在我们先接着往里跟：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//MiniCluster.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">executeJobBlocking</span><span class="params">(JobGraph job)</span> <span class="keyword">throws</span> JobExecutionException, InterruptedException </span>&#123;</span><br><span class="line">		checkNotNull(job, <span class="string">&quot;job is null&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//在这里，最终把job提交给了jobMaster</span></span><br><span class="line">		<span class="keyword">final</span> CompletableFuture&lt;JobSubmissionResult&gt; submissionFuture = submitJob(job);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">final</span> CompletableFuture&lt;JobResult&gt; jobResultFuture = submissionFuture.thenCompose(</span><br><span class="line">			(JobSubmissionResult ignored) -&gt; requestJobResult(job.getJobID()));</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>正如我在注释里写的，这一段代码核心逻辑就是调用那个<code>submitJob</code>方法。那么我们再接着看这个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;JobSubmissionResult&gt; <span class="title">submitJob</span><span class="params">(JobGraph jobGraph)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">final</span> DispatcherGateway dispatcherGateway;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		dispatcherGateway = getDispatcherGateway();</span><br><span class="line">	&#125; <span class="keyword">catch</span> (LeaderRetrievalException | InterruptedException e) &#123;</span><br><span class="line">		ExceptionUtils.checkInterrupted(e);</span><br><span class="line">		<span class="keyword">return</span> FutureUtils.completedExceptionally(e);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// we have to allow queued scheduling in Flip-6 mode because we need to request slots</span></span><br><span class="line">	<span class="comment">// from the ResourceManager</span></span><br><span class="line">	jobGraph.setAllowQueuedScheduling(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Void&gt; jarUploadFuture = uploadAndSetJarFiles(dispatcherGateway, jobGraph);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; acknowledgeCompletableFuture = jarUploadFuture.thenCompose(</span><br><span class="line">	</span><br><span class="line">	<span class="comment">//在这里执行了真正的submit操作</span></span><br><span class="line">		(Void ack) -&gt; dispatcherGateway.submitJob(jobGraph, rpcTimeout));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> acknowledgeCompletableFuture.thenApply(</span><br><span class="line">		(Acknowledge ignored) -&gt; <span class="keyword">new</span> JobSubmissionResult(jobGraph.getJobID()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的<code>Dispatcher</code>是一个接收job，然后指派JobMaster去启动任务的类,我们可以看看它的类结构，有两个实现。在本地环境下启动的是<code>MiniDispatcher</code>，在集群上提交任务时，集群上启动的是<code>StandaloneDispatcher</code>。</p>
<p><img src="http://static.zybuluo.com/bethunebtj/y9hjeinc58dqc7wiepv2iim4/image_1cenfj3p9fp110p0a8unn1mrh9.png" alt="image_1cenfj3p9fp110p0a8unn1mrh9.png-27.4kB"></p>
<p>那么这个Dispatcher又做了什么呢？它启动了一个<code>JobManagerRunner</code>（这里我要吐槽Flink的命名，这个东西应该叫做JobMasterRunner才对，flink里的JobMaster和JobManager不是一个东西），委托JobManagerRunner去启动该Job的<code>JobMaster</code>。我们看一下对应的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//jobManagerRunner.java</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">verifyJobSchedulingStatusAndStartJobManager</span><span class="params">(UUID leaderSessionId)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">	    <span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; startFuture = jobMaster.start(<span class="keyword">new</span> JobMasterId(leaderSessionId), rpcTimeout);</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>然后，JobMaster经过了一堆方法嵌套之后，执行到了这里：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">scheduleExecutionGraph</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	checkState(jobStatusListener == <span class="keyword">null</span>);</span><br><span class="line">	<span class="comment">// register self as job status change listener</span></span><br><span class="line">	jobStatusListener = <span class="keyword">new</span> JobManagerJobStatusListener();</span><br><span class="line">	executionGraph.registerJobStatusListener(jobStatusListener);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">	    <span class="comment">//这里调用了ExecutionGraph的启动方法</span></span><br><span class="line">		executionGraph.scheduleForExecution();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">		executionGraph.failGlobal(t);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们知道，flink的框架里有三层图结构，其中ExecutionGraph就是真正被执行的那一层，所以到这里为止，一个任务从提交到真正执行的流程就走完了，我们再回顾一下（顺便提一下远程提交时的流程区别）：</p>
<ul>
<li>客户端代码的execute方法执行；</li>
<li>本地环境下，MiniCluster完成了大部分任务，直接把任务委派给了MiniDispatcher；</li>
<li>远程环境下，启动了一个<code>RestClusterClient</code>，这个类会以HTTP Rest的方式把用户代码提交到集群上；</li>
<li>远程环境下，请求发到集群上之后，必然有个handler去处理，在这里是<code>JobSubmitHandler</code>。这个类接手了请求后，委派StandaloneDispatcher启动job，到这里之后，本地提交和远程提交的逻辑往后又统一了；</li>
<li>Dispatcher接手job之后，会实例化一个<code>JobManagerRunner</code>，然后用这个runner启动job；</li>
<li>JobManagerRunner接下来把job交给了<code>JobMaster</code>去处理；</li>
<li>JobMaster使用<code>ExecutionGraph</code>的方法启动了整个执行图；整个任务就启动起来了。</li>
</ul>
<p>至此，第一部分就讲完了。</p>
<h2 id="2-理解flink的图结构"><a href="#2-理解flink的图结构" class="headerlink" title="2.理解flink的图结构"></a>2.理解flink的图结构</h2><p>第一部分讲到，我们的主函数最后一项任务就是生成StreamGraph，然后生成JobGraph，然后以此开始调度任务运行，所以接下来我们从这里入手，继续探索flink。</p>
<h3 id="2-1-flink的三层图结构"><a href="#2-1-flink的三层图结构" class="headerlink" title="2.1 flink的三层图结构"></a>2.1 flink的三层图结构</h3><p>事实上，flink总共提供了三种图的抽象，我们前面已经提到了StreamGraph和JobGraph，还有一种是ExecutionGraph，是用于调度的基本数据结构。<br><img src="http://static.zybuluo.com/bethunebtj/nseitc0kyuq0n44s7qcp6ij9/image_1caf1oll019fp1odv1bh9idosr79.png" alt="image_1caf1oll019fp1odv1bh9idosr79.png-486.3kB"><br>上面这张图清晰的给出了flink各个图的工作原理和转换过程。其中最后一个物理执行图并非flink的数据结构，而是程序开始执行后，各个task分布在不同的节点上，所形成的物理上的关系表示。</p>
<ul>
<li>从JobGraph的图里可以看到，数据从上一个operator流到下一个operator的过程中，上游作为生产者提供了IntermediateDataSet，而下游作为消费者需要JobEdge。事实上，JobEdge是一个通信管道，连接了上游生产的dataset和下游的JobVertex节点。</li>
<li>在JobGraph转换到ExecutionGraph的过程中，主要发生了以下转变：</li>
<li> 加入了并行度的概念，成为真正可调度的图结构</li>
<li> 生成了与JobVertex对应的ExecutionJobVertex，ExecutionVertex，与IntermediateDataSet对应的IntermediateResult和IntermediateResultPartition等，并行将通过这些类实现</li>
<li>ExecutionGraph已经可以用于调度任务。我们可以看到，flink根据该图生成了一一对应的Task，每个task对应一个ExecutionGraph的一个Execution。Task用InputGate、InputChannel和ResultPartition对应了上面图中的IntermediateResult和ExecutionEdge。</li>
</ul>
<p>那么，flink抽象出这三层图结构，四层执行逻辑的意义是什么呢？<br>StreamGraph是对用户逻辑的映射。JobGraph在此基础上进行了一些优化，比如把一部分操作串成chain以提高效率。ExecutionGraph是为了调度存在的，加入了并行处理的概念。而在此基础上真正执行的是Task及其相关结构。</p>
<h3 id="2-2-StreamGraph的生成"><a href="#2-2-StreamGraph的生成" class="headerlink" title="2.2 StreamGraph的生成"></a>2.2 StreamGraph的生成</h3><p>在第一节的算子注册部分，我们可以看到，flink把每一个算子transform成一个对流的转换（比如上文中返回的SingleOutputStreamOperator是一个DataStream的子类），并且注册到执行环境中，用于生成StreamGraph。实际生成StreamGraph的入口是<code>StreamGraphGenerator.generate(env, transformations)</code> 其中的transformations是一个list，里面记录的就是我们在transform方法中放进来的算子。</p>
<h4 id="2-2-1-StreamTransformation类代表了流的转换"><a href="#2-2-1-StreamTransformation类代表了流的转换" class="headerlink" title="2.2.1 StreamTransformation类代表了流的转换"></a>2.2.1 StreamTransformation类代表了流的转换</h4><p>StreamTransformation代表了从一个或多个DataStream生成新DataStream的操作。顺便，DataStream类在内部组合了一个StreamTransformation类，实际的转换操作均通过该类完成。<br><img src="http://static.zybuluo.com/bethunebtj/69v9syr2p5k5om3c4jox9wh0/image_1caf64b7c1gjnv2eebi1v9e1cvum.png" alt="image_1caf64b7c1gjnv2eebi1v9e1cvum.png-129.4kB"><br>我们可以看到，从source到各种map,union再到sink操作全部被映射成了StreamTransformation。<br>其映射过程如下所示：<br><img src="http://static.zybuluo.com/bethunebtj/a8sjspg8agzl3utnncntds9q/image_1caf6ak4rkqsc1u1hci93fe0d13.png" alt="image_1caf6ak4rkqsc1u1hci93fe0d13.png-36.6kB"></p>
<p>以MapFunction为例：</p>
<ul>
<li><p>首先，用户代码里定义的UDF会被当作其基类对待，然后交给StreamMap这个operator做进一步包装。事实上，每一个Transformation都对应了一个StreamOperator。</p>
</li>
<li><p>由于map这个操作只接受一个输入，所以再被进一步包装为OneInputTransformation。</p>
</li>
<li><p>最后，将该transformation注册到执行环境中，当执行上文提到的generate方法时，生成StreamGraph图结构。</p>
<blockquote>
<p>另外，并不是每一个 StreamTransformation 都会转换成runtime层中的物理操作。有一些只是逻辑概念，比如union、split/select、partition等。如下图所示的转换树，在运行时会优化成下方的操作图。<br><img src="http://static.zybuluo.com/bethunebtj/6zmlsivd9cjdm5nhsacuk3o1/image_1caf71h79s0s3fodem1aeb1j3m1g.png" alt="image_1caf71h79s0s3fodem1aeb1j3m1g.png-83.8kB"></p>
</blockquote>
</li>
</ul>
<h4 id="2-2-2-StreamGraph生成函数分析"><a href="#2-2-2-StreamGraph生成函数分析" class="headerlink" title="2.2.2 StreamGraph生成函数分析"></a>2.2.2 StreamGraph生成函数分析</h4><p>我们从StreamGraphGenerator.generate()方法往下看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">public static StreamGraph generate(StreamExecutionEnvironment env, List&lt;StreamTransformation&lt;?&gt;&gt; transformations) &#123;</span><br><span class="line">	return new StreamGraphGenerator(env).generateInternal(transformations);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">   &#x2F;&#x2F;注意，StreamGraph的生成是从sink开始的</span><br><span class="line">private StreamGraph generateInternal(List&lt;StreamTransformation&lt;?&gt;&gt; transformations) &#123;</span><br><span class="line">	for (StreamTransformation&lt;?&gt; transformation: transformations) &#123;</span><br><span class="line">		transform(transformation);</span><br><span class="line">	&#125;</span><br><span class="line">	return streamGraph;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;这个方法的核心逻辑就是判断传入的steamOperator是哪种类型，并执行相应的操作，详情见下面那一大堆if-else</span><br><span class="line">private Collection&lt;Integer&gt; transform(StreamTransformation&lt;?&gt; transform) &#123;</span><br><span class="line"></span><br><span class="line">	if (alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">		return alreadyTransformed.get(transform);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	LOG.debug(&quot;Transforming &quot; + transform);</span><br><span class="line"></span><br><span class="line">	if (transform.getMaxParallelism() &lt;&#x3D; 0) &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; if the max parallelism hasn&#39;t been set, then first use the job wide max parallelism</span><br><span class="line">		&#x2F;&#x2F; from theExecutionConfig.</span><br><span class="line">		int globalMaxParallelismFromConfig &#x3D; env.getConfig().getMaxParallelism();</span><br><span class="line">		if (globalMaxParallelismFromConfig &gt; 0) &#123;</span><br><span class="line">			transform.setMaxParallelism(globalMaxParallelismFromConfig);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; call at least once to trigger exceptions about MissingTypeInfo</span><br><span class="line">	transform.getOutputType();</span><br><span class="line"></span><br><span class="line">	Collection&lt;Integer&gt; transformedIds;</span><br><span class="line">	&#x2F;&#x2F;这里对操作符的类型进行判断，并以此调用相应的处理逻辑.简而言之，处理的核心无非是递归的将该节点和节点的上游节点加入图</span><br><span class="line">	if (transform instanceof OneInputTransformation&lt;?, ?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformOneInputTransform((OneInputTransformation&lt;?, ?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof TwoInputTransformation&lt;?, ?, ?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformTwoInputTransform((TwoInputTransformation&lt;?, ?, ?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SourceTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSource((SourceTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SinkTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSink((SinkTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof UnionTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformUnion((UnionTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SplitTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSplit((SplitTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SelectTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSelect((SelectTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof FeedbackTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformFeedback((FeedbackTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof CoFeedbackTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformCoFeedback((CoFeedbackTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof PartitionTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformPartition((PartitionTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else if (transform instanceof SideOutputTransformation&lt;?&gt;) &#123;</span><br><span class="line">		transformedIds &#x3D; transformSideOutput((SideOutputTransformation&lt;?&gt;) transform);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		throw new IllegalStateException(&quot;Unknown transformation: &quot; + transform);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F;注意这里和函数开始时的方法相对应，在有向图中要注意避免循环的产生</span><br><span class="line">	&#x2F;&#x2F; need this check because the iterate transformation adds itself before</span><br><span class="line">	&#x2F;&#x2F; transforming the feedback edges</span><br><span class="line">	if (!alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">		alreadyTransformed.put(transform, transformedIds);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (transform.getBufferTimeout() &gt; 0) &#123;</span><br><span class="line">		streamGraph.setBufferTimeout(transform.getId(), transform.getBufferTimeout());</span><br><span class="line">	&#125;</span><br><span class="line">	if (transform.getUid() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setTransformationUID(transform.getId(), transform.getUid());</span><br><span class="line">	&#125;</span><br><span class="line">	if (transform.getUserProvidedNodeHash() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setTransformationUserHash(transform.getId(), transform.getUserProvidedNodeHash());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (transform.getMinResources() !&#x3D; null &amp;&amp; transform.getPreferredResources() !&#x3D; null) &#123;</span><br><span class="line">		streamGraph.setResources(transform.getId(), transform.getMinResources(), transform.getPreferredResources());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return transformedIds;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为map，filter等常用操作都是OneInputStreamOperator,我们就来看看<code>transformOneInputTransform((OneInputTransformation&lt;?, ?&gt;) transform)</code>方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line">private &lt;IN, OUT&gt; Collection&lt;Integer&gt; transformOneInputTransform(OneInputTransformation&lt;IN, OUT&gt; transform) &#123;</span><br><span class="line"></span><br><span class="line">		Collection&lt;Integer&gt; inputIds &#x3D; transform(transform.getInput());</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 在递归处理节点过程中，某个节点可能已经被其他子节点先处理过了，需要跳过</span><br><span class="line">		if (alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">			return alreadyTransformed.get(transform);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;这里是获取slotSharingGroup。这个group用来定义当前我们在处理的这个操作符可以跟什么操作符chain到一个slot里进行操作</span><br><span class="line">        &#x2F;&#x2F;因为有时候我们可能不满意flink替我们做的chain聚合</span><br><span class="line">        &#x2F;&#x2F;一个slot就是一个执行task的基本容器</span><br><span class="line">		String slotSharingGroup &#x3D; determineSlotSharingGroup(transform.getSlotSharingGroup(), inputIds);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;把该operator加入图</span><br><span class="line">		streamGraph.addOperator(transform.getId(),</span><br><span class="line">				slotSharingGroup,</span><br><span class="line">				transform.getOperator(),</span><br><span class="line">				transform.getInputType(),</span><br><span class="line">				transform.getOutputType(),</span><br><span class="line">				transform.getName());</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F;对于keyedStream，我们还要记录它的keySelector方法</span><br><span class="line">        &#x2F;&#x2F;flink并不真正为每个keyedStream保存一个key，而是每次需要用到key的时候都使用keySelector方法进行计算</span><br><span class="line">        &#x2F;&#x2F;因此，我们自定义的keySelector方法需要保证幂等性</span><br><span class="line">        &#x2F;&#x2F;到后面介绍keyGroup的时候我们还会再次提到这一点</span><br><span class="line">		if (transform.getStateKeySelector() !&#x3D; null) &#123;</span><br><span class="line">			TypeSerializer&lt;?&gt; keySerializer &#x3D; transform.getStateKeyType().createSerializer(env.getConfig());</span><br><span class="line">			streamGraph.setOneInputStateKey(transform.getId(), transform.getStateKeySelector(), keySerializer);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		streamGraph.setParallelism(transform.getId(), transform.getParallelism());</span><br><span class="line">		streamGraph.setMaxParallelism(transform.getId(), transform.getMaxParallelism());</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F;为当前节点和它的依赖节点建立边</span><br><span class="line">        &#x2F;&#x2F;这里可以看到之前提到的select union partition等逻辑节点被合并入edge的过程</span><br><span class="line">		for (Integer inputId: inputIds) &#123;</span><br><span class="line">			streamGraph.addEdge(inputId, transform.getId(), 0);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return Collections.singleton(transform.getId());</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	public void addEdge(Integer upStreamVertexID, Integer downStreamVertexID, int typeNumber) &#123;</span><br><span class="line">		addEdgeInternal(upStreamVertexID,</span><br><span class="line">				downStreamVertexID,</span><br><span class="line">				typeNumber,</span><br><span class="line">				null,</span><br><span class="line">				new ArrayList&lt;String&gt;(),</span><br><span class="line">				null);</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">    &#x2F;&#x2F;addEdge的实现，会合并一些逻辑节点</span><br><span class="line">	private void addEdgeInternal(Integer upStreamVertexID,</span><br><span class="line">			Integer downStreamVertexID,</span><br><span class="line">			int typeNumber,</span><br><span class="line">			StreamPartitioner&lt;?&gt; partitioner,</span><br><span class="line">			List&lt;String&gt; outputNames,</span><br><span class="line">			OutputTag outputTag) &#123;</span><br><span class="line">        &#x2F;&#x2F;如果输入边是侧输出节点，则把side的输入边作为本节点的输入边，并递归调用</span><br><span class="line">		if (virtualSideOutputNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualSideOutputNodes.get(virtualId).f0;</span><br><span class="line">			if (outputTag &#x3D;&#x3D; null) &#123;</span><br><span class="line">				outputTag &#x3D; virtualSideOutputNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, null, outputTag);</span><br><span class="line">			&#x2F;&#x2F;如果输入边是select，则把select的输入边作为本节点的输入边</span><br><span class="line">		&#125; else if (virtualSelectNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualSelectNodes.get(virtualId).f0;</span><br><span class="line">			if (outputNames.isEmpty()) &#123;</span><br><span class="line">				&#x2F;&#x2F; selections that happen downstream override earlier selections</span><br><span class="line">				outputNames &#x3D; virtualSelectNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, outputNames, outputTag);</span><br><span class="line">			&#x2F;&#x2F;如果是partition节点</span><br><span class="line">		&#125; else if (virtualPartitionNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId &#x3D; upStreamVertexID;</span><br><span class="line">			upStreamVertexID &#x3D; virtualPartitionNodes.get(virtualId).f0;</span><br><span class="line">			if (partitioner &#x3D;&#x3D; null) &#123;</span><br><span class="line">				partitioner &#x3D; virtualPartitionNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, outputNames, outputTag);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">		&#x2F;&#x2F;正常的edge处理逻辑</span><br><span class="line">			StreamNode upstreamNode &#x3D; getStreamNode(upStreamVertexID);</span><br><span class="line">			StreamNode downstreamNode &#x3D; getStreamNode(downStreamVertexID);</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; If no partitioner was specified and the parallelism of upstream and downstream</span><br><span class="line">			&#x2F;&#x2F; operator matches use forward partitioning, use rebalance otherwise.</span><br><span class="line">			if (partitioner &#x3D;&#x3D; null &amp;&amp; upstreamNode.getParallelism() &#x3D;&#x3D; downstreamNode.getParallelism()) &#123;</span><br><span class="line">				partitioner &#x3D; new ForwardPartitioner&lt;Object&gt;();</span><br><span class="line">			&#125; else if (partitioner &#x3D;&#x3D; null) &#123;</span><br><span class="line">				partitioner &#x3D; new RebalancePartitioner&lt;Object&gt;();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (partitioner instanceof ForwardPartitioner) &#123;</span><br><span class="line">				if (upstreamNode.getParallelism() !&#x3D; downstreamNode.getParallelism()) &#123;</span><br><span class="line">					throw new UnsupportedOperationException(&quot;Forward partitioning does not allow &quot; +</span><br><span class="line">							&quot;change of parallelism. Upstream operation: &quot; + upstreamNode + &quot; parallelism: &quot; + upstreamNode.getParallelism() +</span><br><span class="line">							&quot;, downstream operation: &quot; + downstreamNode + &quot; parallelism: &quot; + downstreamNode.getParallelism() +</span><br><span class="line">							&quot; You must use another partitioning strategy, such as broadcast, rebalance, shuffle or global.&quot;);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			StreamEdge edge &#x3D; new StreamEdge(upstreamNode, downstreamNode, typeNumber, outputNames, partitioner, outputTag);</span><br><span class="line"></span><br><span class="line">			getStreamNode(edge.getSourceId()).addOutEdge(edge);</span><br><span class="line">			getStreamNode(edge.getTargetId()).addInEdge(edge);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-2-3-WordCount函数的StreamGraph"><a href="#2-2-3-WordCount函数的StreamGraph" class="headerlink" title="2.2.3 WordCount函数的StreamGraph"></a>2.2.3 WordCount函数的StreamGraph</h4><p>flink提供了一个StreamGraph可视化显示工具，<a target="_blank" rel="noopener" href="http://flink.apache.org/visualizer/">在这里</a><br>我们可以把我们的程序的执行计划打印出来<code>System.out.println(env.getExecutionPlan());</code> 复制到这个网站上，点击生成，如图所示：<br><img src="http://static.zybuluo.com/bethunebtj/sfckex3xgu33m3srk2bc5hgk/image_1cafgsliu1n2n1uj21p971b0h6m71t.png" alt="image_1cafgsliu1n2n1uj21p971b0h6m71t.png-25.7kB"><br>可以看到，我们源程序被转化成了4个operator。<br>另外，在operator之间的连线上也显示出了flink添加的一些逻辑流程。由于我设定了每个操作符的并行度都是1，所以在每个操作符之间都是直接FORWARD，不存在shuffle的过程。</p>
<h3 id="2-3-JobGraph的生成"><a href="#2-3-JobGraph的生成" class="headerlink" title="2.3 JobGraph的生成"></a>2.3 JobGraph的生成</h3><p>flink会根据上一步生成的StreamGraph生成JobGraph，然后将JobGraph发送到server端进行ExecutionGraph的解析。</p>
<h4 id="2-3-1-JobGraph生成源码"><a href="#2-3-1-JobGraph生成源码" class="headerlink" title="2.3.1 JobGraph生成源码"></a>2.3.1 JobGraph生成源码</h4><p>与StreamGraph类似，JobGraph的入口方法是<code>StreamingJobGraphGenerator.createJobGraph()</code>。我们直接来看源码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">private JobGraph createJobGraph() &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 设置启动模式为所有节点均在一开始就启动</span><br><span class="line">		jobGraph.setScheduleMode(ScheduleMode.EAGER);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 为每个节点生成hash id</span><br><span class="line">		Map&lt;Integer, byte[]&gt; hashes &#x3D; defaultStreamGraphHasher.traverseStreamGraphAndGenerateHashes(streamGraph);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 为了保持兼容性创建的hash</span><br><span class="line">		List&lt;Map&lt;Integer, byte[]&gt;&gt; legacyHashes &#x3D; new ArrayList&lt;&gt;(legacyStreamGraphHashers.size());</span><br><span class="line">		for (StreamGraphHasher hasher : legacyStreamGraphHashers) &#123;</span><br><span class="line">			legacyHashes.add(hasher.traverseStreamGraphAndGenerateHashes(streamGraph));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		Map&lt;Integer, List&lt;Tuple2&lt;byte[], byte[]&gt;&gt;&gt; chainedOperatorHashes &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        &#x2F;&#x2F;生成jobvertex，串成chain等</span><br><span class="line">        &#x2F;&#x2F;这里的逻辑大致可以理解为，挨个遍历节点，如果该节点是一个chain的头节点，就生成一个JobVertex，如果不是头节点，就要把自身配置并入头节点，然后把头节点和自己的出边相连；对于不能chain的节点，当作只有头节点处理即可</span><br><span class="line">		setChaining(hashes, legacyHashes, chainedOperatorHashes);</span><br><span class="line">        &#x2F;&#x2F;设置输入边edge</span><br><span class="line">		setPhysicalEdges();</span><br><span class="line">        &#x2F;&#x2F;设置slot共享group</span><br><span class="line">		setSlotSharing();</span><br><span class="line">        &#x2F;&#x2F;配置检查点</span><br><span class="line">		configureCheckpointing();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 如果有之前的缓存文件的配置的话，重新读入</span><br><span class="line">		for (Tuple2&lt;String, DistributedCache.DistributedCacheEntry&gt; e : streamGraph.getEnvironment().getCachedFiles()) &#123;</span><br><span class="line">			DistributedCache.writeFileInfoToConfig(e.f0, e.f1, jobGraph.getJobConfiguration());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; 传递执行环境配置</span><br><span class="line">		try &#123;</span><br><span class="line">			jobGraph.setExecutionConfig(streamGraph.getExecutionConfig());</span><br><span class="line">		&#125;</span><br><span class="line">		catch (IOException e) &#123;</span><br><span class="line">			throw new IllegalConfigurationException(&quot;Could not serialize the ExecutionConfig.&quot; +</span><br><span class="line">					&quot;This indicates that non-serializable types (like custom serializers) were registered&quot;);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return jobGraph;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-3-2-operator-chain的逻辑"><a href="#2-3-2-operator-chain的逻辑" class="headerlink" title="2.3.2 operator chain的逻辑"></a>2.3.2 operator chain的逻辑</h4><blockquote>
<p>为了更高效地分布式执行，Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。将operators链接成task是非常有效的优化：它能减少线程之间的切换，减少消息的序列化/反序列化，减少数据在缓冲区的交换，减少了延迟的同时提高整体的吞吐量。</p>
</blockquote>
<p><img src="http://static.zybuluo.com/bethunebtj/jcjalvv130ex52vkglkt56r2/image_1cafj7s6bittk5tt0bequlig2a.png" alt="image_1cafj7s6bittk5tt0bequlig2a.png-158.7kB"><br>上图中将KeyAggregation和Sink两个operator进行了合并，因为这两个合并后并不会改变整体的拓扑结构。但是，并不是任意两个 operator 就能 chain 一起的,其条件还是很苛刻的：</p>
<blockquote>
<ul>
<li>上下游的并行度一致</li>
<li>下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）</li>
<li>上下游节点都在同一个 slot group 中（下面会解释 slot group）</li>
<li>下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）</li>
<li>上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）</li>
<li>两个节点间数据分区方式是 forward（参考理解数据流的分区）</li>
<li>用户没有禁用 chain</li>
</ul>
</blockquote>
<p>flink的chain逻辑是一种很常见的设计，比如spring的interceptor也是类似的实现方式。通过把操作符串成一个大操作符，flink避免了把数据序列化后通过网络发送给其他节点的开销，能够大大增强效率。</p>
<h4 id="2-3-3-JobGraph的提交"><a href="#2-3-3-JobGraph的提交" class="headerlink" title="2.3.3 JobGraph的提交"></a>2.3.3 JobGraph的提交</h4><p>前面已经提到，JobGraph的提交依赖于JobClient和JobManager之间的异步通信，如图所示：<br><img src="http://static.zybuluo.com/bethunebtj/dj015uuqpnb4ct7810qfilhe/image_1cafn516r1p68kt31g7r196rcsv2n.png" alt="image_1cafn516r1p68kt31g7r196rcsv2n.png-40.1kB"><br>在submitJobAndWait方法中，其首先会创建一个JobClientActor的ActorRef,然后向其发起一个SubmitJobAndWait消息，该消息将JobGraph的实例提交给JobClientActor。发起模式是ask，它表示需要一个应答消息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Future&lt;Object&gt; future &#x3D; Patterns.ask(jobClientActor, new JobClientMessages.SubmitJobAndWait(jobGraph), new Timeout(AkkaUtils.INF_TIMEOUT()));</span><br><span class="line">answer &#x3D; Await.result(future, AkkaUtils.INF_TIMEOUT());</span><br></pre></td></tr></table></figure>
<p>该SubmitJobAndWait消息被JobClientActor接收后，最终通过调用tryToSubmitJob方法触发真正的提交动作。当JobManager的actor接收到来自client端的请求后，会执行一个submitJob方法，主要做以下事情：</p>
<blockquote>
<ul>
<li>向BlobLibraryCacheManager注册该Job；</li>
<li>构建ExecutionGraph对象；</li>
<li>对JobGraph中的每个顶点进行初始化；</li>
<li>将DAG拓扑中从source开始排序，排序后的顶点集合附加到Exec&gt; - utionGraph对象；</li>
<li>获取检查点相关的配置，并将其设置到ExecutionGraph对象；</li>
<li>向ExecutionGraph注册相关的listener；</li>
<li>执行恢复操作或者将JobGraph信息写入SubmittedJobGraphStore以在后续用于恢复目的；</li>
<li>响应给客户端JobSubmitSuccess消息；</li>
<li>对ExecutionGraph对象进行调度执行；</li>
</ul>
</blockquote>
<p>最后，JobManger会返回消息给JobClient，通知该任务是否提交成功。</p>
<h3 id="2-4-ExecutionGraph的生成"><a href="#2-4-ExecutionGraph的生成" class="headerlink" title="2.4 ExecutionGraph的生成"></a>2.4 ExecutionGraph的生成</h3><p>与StreamGraph和JobGraph不同，ExecutionGraph并不是在我们的客户端程序生成，而是在服务端（JobManager处）生成的，顺便flink只维护一个JobManager。其入口代码是<code>ExecutionGraphBuilder.buildGraph（...）</code><br>该方法长200多行，其中一大半是checkpoiont的相关逻辑，我们暂且略过，直接看核心方法<code>executionGraph.attachJobGraph(sortedTopology)</code><br>因为ExecutionGraph事实上只是改动了JobGraph的每个节点，而没有对整个拓扑结构进行变动，所以代码里只是挨个遍历jobVertex并进行处理：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">for (JobVertex jobVertex : topologiallySorted) &#123;</span><br><span class="line"></span><br><span class="line">			if (jobVertex.isInputVertex() &amp;&amp; !jobVertex.isStoppable()) &#123;</span><br><span class="line">				this.isStoppable &#x3D; false;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F;在这里生成ExecutionGraph的每个节点</span><br><span class="line">			&#x2F;&#x2F;首先是进行了一堆赋值，将任务信息交给要生成的图节点，以及设定并行度等等</span><br><span class="line">			&#x2F;&#x2F;然后是创建本节点的IntermediateResult，根据本节点的下游节点的个数确定创建几份</span><br><span class="line">			&#x2F;&#x2F;最后是根据设定好的并行度创建用于执行task的ExecutionVertex</span><br><span class="line">			&#x2F;&#x2F;如果job有设定inputsplit的话，这里还要指定inputsplits</span><br><span class="line">			ExecutionJobVertex ejv &#x3D; new ExecutionJobVertex(</span><br><span class="line">				this,</span><br><span class="line">				jobVertex,</span><br><span class="line">				1,</span><br><span class="line">				rpcCallTimeout,</span><br><span class="line">				globalModVersion,</span><br><span class="line">				createTimestamp);</span><br><span class="line">            </span><br><span class="line">            &#x2F;&#x2F;这里要处理所有的JobEdge</span><br><span class="line">            &#x2F;&#x2F;对每个edge，获取对应的intermediateResult，并记录到本节点的输入上</span><br><span class="line">            &#x2F;&#x2F;最后，把每个ExecutorVertex和对应的IntermediateResult关联起来</span><br><span class="line">			ejv.connectToPredecessors(this.intermediateResults);</span><br><span class="line"></span><br><span class="line">			ExecutionJobVertex previousTask &#x3D; this.tasks.putIfAbsent(jobVertex.getID(), ejv);</span><br><span class="line">			if (previousTask !&#x3D; null) &#123;</span><br><span class="line">				throw new JobException(String.format(&quot;Encountered two job vertices with ID %s : previous&#x3D;[%s] &#x2F; new&#x3D;[%s]&quot;,</span><br><span class="line">						jobVertex.getID(), ejv, previousTask));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			for (IntermediateResult res : ejv.getProducedDataSets()) &#123;</span><br><span class="line">				IntermediateResult previousDataSet &#x3D; this.intermediateResults.putIfAbsent(res.getId(), res);</span><br><span class="line">				if (previousDataSet !&#x3D; null) &#123;</span><br><span class="line">					throw new JobException(String.format(&quot;Encountered two intermediate data set with ID %s : previous&#x3D;[%s] &#x2F; new&#x3D;[%s]&quot;,</span><br><span class="line">							res.getId(), res, previousDataSet));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			this.verticesInCreationOrder.add(ejv);</span><br><span class="line">			this.numVerticesTotal +&#x3D; ejv.getParallelism();</span><br><span class="line">			newExecJobVertices.add(ejv);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>
<p>至此，ExecutorGraph就创建完成了。</p>
<h2 id="3-任务的调度与执行"><a href="#3-任务的调度与执行" class="headerlink" title="3. 任务的调度与执行"></a>3. 任务的调度与执行</h2><p>关于flink的任务执行架构，官网的这两张图就是最好的说明：<br><img src="http://static.zybuluo.com/bethunebtj/qiv2wip1rok62ljo0tef3qf0/image_1cafnu1pl1d8c15m219b8vkb2334.png" alt="image_1cafnu1pl1d8c15m219b8vkb2334.png-112.9kB"><br>Flink 集群启动后，首先会启动一个 JobManger 和多个的 TaskManager。用户的代码会由JobClient 提交给 JobManager，JobManager 再把来自不同用户的任务发给 不同的TaskManager 去执行，每个TaskManager管理着多个task，task是执行计算的最小结构， TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述除了task外的三者均为独立的 JVM 进程。<br>要注意的是，TaskManager和job并非一一对应的关系。flink调度的最小单元是task而非TaskManager，也就是说，来自不同job的不同task可能运行于同一个TaskManager的不同线程上。<br><img src="http://static.zybuluo.com/bethunebtj/b7cmjn41b1zp5sco34kgvusn/image_1cclle7ui2j41nf611gs1is18m19.png" alt="image_1cclle7ui2j41nf611gs1is18m19.png-127.5kB"><br>一个flink任务所有可能的状态如上图所示。图上画的很明白，就不再赘述了。</p>
<h3 id="3-1-计算资源的调度"><a href="#3-1-计算资源的调度" class="headerlink" title="3.1 计算资源的调度"></a>3.1 计算资源的调度</h3><p>Task slot是一个TaskManager内资源分配的最小载体，代表了一个固定大小的资源子集，每个TaskManager会将其所占有的资源平分给它的slot。<br>通过调整 task slot 的数量，用户可以定义task之间是如何相互隔离的。每个 TaskManager 有一个slot，也就意味着每个task运行在独立的 JVM 中。每个 TaskManager 有多个slot的话，也就是说多个task运行在同一个JVM中。<br>而在同一个JVM进程中的task，可以共享TCP连接（基于多路复用）和心跳消息，可以减少数据的网络传输，也能共享一些数据结构，一定程度上减少了每个task的消耗。<br>每个slot可以接受单个task，也可以接受多个连续task组成的pipeline，如下图所示，FlatMap函数占用一个taskslot，而key Agg函数和sink函数共用一个taskslot：<br><img src="http://static.zybuluo.com/bethunebtj/6ypu9v09z0mit936uk0mcddi/image_1cafpf21c1jh3s5ap1fisu4v23h.png" alt="image_1cafpf21c1jh3s5ap1fisu4v23h.png-44.7kB"><br>为了达到共用slot的目的，除了可以以chain的方式pipeline算子，我们还可以允许SlotSharingGroup，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/tgamd7vw9qcdttvihlmvhie9/image_1cafpko68b3r1lk0dpsnmbj3c3u.png" alt="image_1cafpko68b3r1lk0dpsnmbj3c3u.png-61.2kB"><br>我们可以把不能被chain成一条的两个操作如flatmap和key&amp;sink放在一个TaskSlot里执行，这样做可以获得以下好处：</p>
<ul>
<li>共用slot使得我们不再需要计算每个任务需要的总task数目，直接取最高算子的并行度即可</li>
<li>对计算资源的利用率更高。例如，通常的轻量级操作map和重量级操作Aggregate不再分别需要一个线程，而是可以在同一个线程内执行，而且对于slot有限的场景，我们可以增大每个task的并行度了。<br>接下来我们还是用官网的图来说明flink是如何重用slot的：<br><img src="http://static.zybuluo.com/bethunebtj/l0n9ny2y198x0daucmyo0zb4/image_1cafqroarkjkuje1hfi18gor654b.png" alt="image_1cafqroarkjkuje1hfi18gor654b.png-137kB"></li>
</ul>
<ol>
<li>TaskManager1分配一个SharedSlot0</li>
<li>把source task放入一个SimpleSlot0，再把该slot放入SharedSlot0</li>
<li>把flatmap task放入一个SimpleSlot1，再把该slot放入SharedSlot0</li>
<li>因为我们的flatmap task并行度是2，因此不能再放入SharedSlot0，所以向TaskMange21申请了一个新的SharedSlot0</li>
<li>把第二个flatmap task放进一个新的SimpleSlot，并放进TaskManager2的SharedSlot0</li>
<li>开始处理key&amp;sink task，因为其并行度也是2，所以先把第一个task放进TaskManager1的SharedSlot</li>
<li>把第二个key&amp;sink放进TaskManager2的SharedSlot</li>
</ol>
<h3 id="3-2-JobManager执行job"><a href="#3-2-JobManager执行job" class="headerlink" title="3.2 JobManager执行job"></a>3.2 JobManager执行job</h3><p>JobManager负责接收 flink 的作业，调度 task，收集 job 的状态、管理 TaskManagers。被实现为一个 akka actor。</p>
<h4 id="3-2-1-JobManager的组件"><a href="#3-2-1-JobManager的组件" class="headerlink" title="3.2.1 JobManager的组件"></a>3.2.1 JobManager的组件</h4><ul>
<li>BlobServer 是一个用来管理二进制大文件的服务，比如保存用户上传的jar文件，该服务会将其写到磁盘上。还有一些相关的类，如BlobCache，用于TaskManager向JobManager下载用户的jar文件</li>
<li>InstanceManager 用来管理当前存活的TaskManager的组件，记录了TaskManager的心跳信息等</li>
<li>CompletedCheckpointStore 用于保存已完成的checkpoint相关信息，持久化到内存中或者zookeeper上</li>
<li>MemoryArchivist 保存了已经提交到flink的作业的相关信息，如JobGraph等</li>
</ul>
<h4 id="3-2-2-JobManager的启动过程"><a href="#3-2-2-JobManager的启动过程" class="headerlink" title="3.2.2 JobManager的启动过程"></a>3.2.2 JobManager的启动过程</h4><p>先列出JobManager启动的核心代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">def runJobManager(</span><br><span class="line">      configuration: Configuration,</span><br><span class="line">      executionMode: JobManagerMode,</span><br><span class="line">      listeningAddress: String,</span><br><span class="line">      listeningPort: Int)</span><br><span class="line">    : Unit &#x3D; &#123;</span><br><span class="line"></span><br><span class="line">    val numberProcessors &#x3D; Hardware.getNumberCPUCores()</span><br><span class="line"></span><br><span class="line">    val futureExecutor &#x3D; Executors.newScheduledThreadPool(</span><br><span class="line">      numberProcessors,</span><br><span class="line">      new ExecutorThreadFactory(&quot;jobmanager-future&quot;))</span><br><span class="line"></span><br><span class="line">    val ioExecutor &#x3D; Executors.newFixedThreadPool(</span><br><span class="line">      numberProcessors,</span><br><span class="line">      new ExecutorThreadFactory(&quot;jobmanager-io&quot;))</span><br><span class="line"></span><br><span class="line">    val timeout &#x3D; AkkaUtils.getTimeout(configuration)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; we have to first start the JobManager ActorSystem because this determines the port if 0</span><br><span class="line">    &#x2F;&#x2F; was chosen before. The method startActorSystem will update the configuration correspondingly.</span><br><span class="line">    val jobManagerSystem &#x3D; startActorSystem(</span><br><span class="line">      configuration,</span><br><span class="line">      listeningAddress,</span><br><span class="line">      listeningPort)</span><br><span class="line"></span><br><span class="line">    val highAvailabilityServices &#x3D; HighAvailabilityServicesUtils.createHighAvailabilityServices(</span><br><span class="line">      configuration,</span><br><span class="line">      ioExecutor,</span><br><span class="line">      AddressResolution.NO_ADDRESS_RESOLUTION)</span><br><span class="line"></span><br><span class="line">    val metricRegistry &#x3D; new MetricRegistryImpl(</span><br><span class="line">      MetricRegistryConfiguration.fromConfiguration(configuration))</span><br><span class="line"></span><br><span class="line">    metricRegistry.startQueryService(jobManagerSystem, null)</span><br><span class="line"></span><br><span class="line">    val (_, _, webMonitorOption, _) &#x3D; try &#123;</span><br><span class="line">      startJobManagerActors(</span><br><span class="line">        jobManagerSystem,</span><br><span class="line">        configuration,</span><br><span class="line">        executionMode,</span><br><span class="line">        listeningAddress,</span><br><span class="line">        futureExecutor,</span><br><span class="line">        ioExecutor,</span><br><span class="line">        highAvailabilityServices,</span><br><span class="line">        metricRegistry,</span><br><span class="line">        classOf[JobManager],</span><br><span class="line">        classOf[MemoryArchivist],</span><br><span class="line">        Option(classOf[StandaloneResourceManager])</span><br><span class="line">      )</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case t: Throwable &#x3D;&gt;</span><br><span class="line">        futureExecutor.shutdownNow()</span><br><span class="line">        ioExecutor.shutdownNow()</span><br><span class="line"></span><br><span class="line">        throw t</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; block until everything is shut down</span><br><span class="line">    jobManagerSystem.awaitTermination()</span><br><span class="line">    </span><br><span class="line">    .......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>配置Akka并生成ActorSystem，启动JobManager</li>
<li>启动HA和metric相关服务</li>
<li>在<code>startJobManagerActors()</code>方法中启动JobManagerActors，以及webserver，TaskManagerActor，ResourceManager等等</li>
<li>阻塞等待终止</li>
<li>集群通过LeaderService等选出JobManager的leader</li>
</ul>
<h4 id="3-2-3-JobManager启动Task"><a href="#3-2-3-JobManager启动Task" class="headerlink" title="3.2.3 JobManager启动Task"></a>3.2.3 JobManager启动Task</h4><p>JobManager 是一个Actor，通过各种消息来完成核心逻辑：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">override def handleMessage: Receive &#x3D; &#123;</span><br><span class="line">  case GrantLeadership(newLeaderSessionID) &#x3D;&gt;</span><br><span class="line">    log.info(s&quot;JobManager $getAddress was granted leadership with leader session ID &quot; +</span><br><span class="line">      s&quot;$newLeaderSessionID.&quot;)</span><br><span class="line">    leaderSessionID &#x3D; newLeaderSessionID</span><br><span class="line">    </span><br><span class="line">    .......</span><br></pre></td></tr></table></figure>
<p>有几个比较重要的消息：</p>
<ul>
<li>GrantLeadership 获得leader授权，将自身被分发到的 session id 写到 zookeeper，并恢复所有的 jobs</li>
<li>RevokeLeadership 剥夺leader授权，打断清空所有的 job 信息，但是保留作业缓存，注销所有的 TaskManagers</li>
<li>RegisterTaskManagers 注册 TaskManager，如果之前已经注册过，则只给对应的 Instance 发送消息，否则启动注册逻辑：在 InstanceManager 中注册该 Instance 的信息，并停止 Instance BlobLibraryCacheManager 的端口【供下载 lib 包用】，同时使用 watch 监听 task manager 的存活</li>
<li>SubmitJob 提交 jobGraph<br>最后一项SubmintJob就是我们要关注的，从客户端收到JobGraph，转换为ExecutionGraph并执行的过程。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">private def submitJob(jobGraph: JobGraph, jobInfo: JobInfo, isRecovery: Boolean &#x3D; false): Unit &#x3D; &#123;</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">    executionGraph &#x3D; ExecutionGraphBuilder.buildGraph(</span><br><span class="line">          executionGraph,</span><br><span class="line">          jobGraph,</span><br><span class="line">          flinkConfiguration,</span><br><span class="line">          futureExecutor,</span><br><span class="line">          ioExecutor,</span><br><span class="line">          scheduler,</span><br><span class="line">          userCodeLoader,</span><br><span class="line">          checkpointRecoveryFactory,</span><br><span class="line">          Time.of(timeout.length, timeout.unit),</span><br><span class="line">          restartStrategy,</span><br><span class="line">          jobMetrics,</span><br><span class="line">          numSlots,</span><br><span class="line">          blobServer,</span><br><span class="line">          log.logger)</span><br><span class="line">          </span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">    if (leaderElectionService.hasLeadership) &#123;</span><br><span class="line">            log.info(s&quot;Scheduling job $jobId ($jobName).&quot;)</span><br><span class="line">            </span><br><span class="line">            executionGraph.scheduleForExecution()</span><br><span class="line">            </span><br><span class="line">          &#125; else &#123;</span><br><span class="line">            self ! decorateMessage(RemoveJob(jobId, removeJobFromStateBackend &#x3D; false))</span><br><span class="line"></span><br><span class="line">            log.warn(s&quot;Submitted job $jobId, but not leader. The other leader needs to recover &quot; +</span><br><span class="line">              &quot;this. I am not scheduling the job for execution.&quot;)</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
首先做一些准备工作，然后获取一个ExecutionGraph，判断是否是恢复的job，然后将job保存下来，并且通知客户端本地已经提交成功了，最后如果确认本JobManager是leader，则执行<code>executionGraph.scheduleForExecution()</code>方法，这个方法经过一系列调用，把每个ExecutionVertex传递给了Excution类的deploy方法：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public void deploy() throws JobException &#123;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			&#x2F;&#x2F; good, we are allowed to deploy</span><br><span class="line">			if (!slot.setExecutedVertex(this)) &#123;</span><br><span class="line">				throw new JobException(&quot;Could not assign the ExecutionVertex to the slot &quot; + slot);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; race double check, did we fail&#x2F;cancel and do we need to release the slot?</span><br><span class="line">			if (this.state !&#x3D; DEPLOYING) &#123;</span><br><span class="line">				slot.releaseSlot();</span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (LOG.isInfoEnabled()) &#123;</span><br><span class="line">				LOG.info(String.format(&quot;Deploying %s (attempt #%d) to %s&quot;, vertex.getTaskNameWithSubtaskIndex(),</span><br><span class="line">						attemptNumber, getAssignedResourceLocation().getHostname()));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			final TaskDeploymentDescriptor deployment &#x3D; vertex.createDeploymentDescriptor(</span><br><span class="line">				attemptId,</span><br><span class="line">				slot,</span><br><span class="line">				taskState,</span><br><span class="line">				attemptNumber);</span><br><span class="line"></span><br><span class="line">			final TaskManagerGateway taskManagerGateway &#x3D; slot.getTaskManagerGateway();</span><br><span class="line"></span><br><span class="line">			final CompletableFuture&lt;Acknowledge&gt; submitResultFuture &#x3D; taskManagerGateway.submitTask(deployment, timeout);</span><br><span class="line"></span><br><span class="line">            ......</span><br><span class="line">		&#125;</span><br><span class="line">		catch (Throwable t) &#123;</span><br><span class="line">			markFailed(t);</span><br><span class="line">			ExceptionUtils.rethrow(t);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
我们首先生成了一个TaskDeploymentDescriptor，然后交给了<code>taskManagerGateway.submitTask()</code>方法执行。接下来的部分，就属于TaskManager的范畴了。<h3 id="3-3-TaskManager执行task"><a href="#3-3-TaskManager执行task" class="headerlink" title="3.3 TaskManager执行task"></a>3.3 TaskManager执行task</h3><h4 id="3-3-1-TaskManager的基本组件"><a href="#3-3-1-TaskManager的基本组件" class="headerlink" title="3.3.1 TaskManager的基本组件"></a>3.3.1 TaskManager的基本组件</h4>TaskManager是flink中资源管理的基本组件，是所有执行任务的基本容器，提供了内存管理、IO管理、通信管理等一系列功能，本节对各个模块进行简要介绍。</li>
</ul>
<ol>
<li>MemoryManager flink并没有把所有内存的管理都委托给JVM，因为JVM普遍存在着存储对象密度低、大内存时GC对系统影响大等问题。所以flink自己抽象了一套内存管理机制，将所有对象序列化后放在自己的MemorySegment上进行管理。MemoryManger涉及内容较多，将在后续章节进行继续剖析。</li>
<li>IOManager flink通过IOManager管理磁盘IO的过程，提供了同步和异步两种写模式，又进一步区分了block、buffer和bulk三种读写方式。<br>IOManager提供了两种方式枚举磁盘文件，一种是直接遍历文件夹下所有文件，另一种是计数器方式，对每个文件名以递增顺序访问。<br>在底层，flink将文件IO抽象为FileIOChannle，封装了底层实现。<br><img src="http://static.zybuluo.com/bethunebtj/d3j6qnbjywjzknu6pb3pou6i/image_1cag7idg4vfj1l871n0l1k0e1f7u4o.png" alt="image_1cag7idg4vfj1l871n0l1k0e1f7u4o.png-194.1kB"><br>可以看到，flink在底层实际上都是以异步的方式进行读写。</li>
<li>NetworkEnvironment 是TaskManager的网络 IO 组件，包含了追踪中间结果和数据交换的数据结构。它的构造器会统一将配置的内存先分配出来，抽象成 NetworkBufferPool 统一管理内存的申请和释放。意思是说，在输入和输出数据时，不管是保留在本地内存，等待chain在一起的下个操作符进行处理，还是通过网络把本操作符的计算结果发送出去，都被抽象成了NetworkBufferPool。后续我们还将对这个组件进行详细分析。</li>
</ol>
<h4 id="3-3-2-TaskManager执行Task"><a href="#3-3-2-TaskManager执行Task" class="headerlink" title="3.3.2 TaskManager执行Task"></a>3.3.2 TaskManager执行Task</h4><p>对于TM来说，执行task就是把收到的<code>TaskDeploymentDescriptor</code>对象转换成一个task并执行的过程。TaskDeploymentDescriptor这个类保存了task执行所必须的所有内容，例如序列化的算子，输入的InputGate和输出的ResultPartition的定义，该task要作为几个subtask执行等等。<br>按照正常逻辑思维，很容易想到TM的submitTask方法的行为：首先是确认资源，如寻找JobManager和Blob，而后建立连接，解序列化算子，收集task相关信息，接下来就是创建一个新的<code>Task</code>对象，这个task对象就是真正执行任务的关键所在。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">val task &#x3D; new Task(</span><br><span class="line">        jobInformation,</span><br><span class="line">        taskInformation,</span><br><span class="line">        tdd.getExecutionAttemptId,</span><br><span class="line">        tdd.getAllocationId,</span><br><span class="line">        tdd.getSubtaskIndex,</span><br><span class="line">        tdd.getAttemptNumber,</span><br><span class="line">        tdd.getProducedPartitions,</span><br><span class="line">        tdd.getInputGates,</span><br><span class="line">        tdd.getTargetSlotNumber,</span><br><span class="line">        tdd.getTaskStateHandles,</span><br><span class="line">        memoryManager,</span><br><span class="line">        ioManager,</span><br><span class="line">        network,</span><br><span class="line">        bcVarManager,</span><br><span class="line">        taskManagerConnection,</span><br><span class="line">        inputSplitProvider,</span><br><span class="line">        checkpointResponder,</span><br><span class="line">        blobCache,</span><br><span class="line">        libCache,</span><br><span class="line">        fileCache,</span><br><span class="line">        config,</span><br><span class="line">        taskMetricGroup,</span><br><span class="line">        resultPartitionConsumableNotifier,</span><br><span class="line">        partitionStateChecker,</span><br><span class="line">        context.dispatcher)</span><br></pre></td></tr></table></figure>
<p>如果读者是从头开始看这篇blog，里面有很多对象应该已经比较明确其作用了（除了那个brVarManager，这个是管理广播变量的，广播变量是一类会被分发到每个任务中的共享变量）。接下来的主要任务，就是把这个task启动起来,然后报告说已经启动task了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; all good, we kick off the task, which performs its own initialization</span><br><span class="line">task.startTaskThread()</span><br><span class="line"></span><br><span class="line">sender ! decorateMessage(Acknowledge.get())</span><br></pre></td></tr></table></figure>
<h4 id="3-3-2-1-生成Task对象"><a href="#3-3-2-1-生成Task对象" class="headerlink" title="3.3.2.1 生成Task对象"></a>3.3.2.1 生成Task对象</h4><p>在执行new Task()方法时，第一步是把构造函数里的这些变量赋值给当前task的fields。<br>接下来是初始化ResultPartition和InputGate。这两个类描述了task的输出数据和输入数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">for (ResultPartitionDeploymentDescriptor desc: resultPartitionDeploymentDescriptors) &#123;</span><br><span class="line">	ResultPartitionID partitionId &#x3D; new ResultPartitionID(desc.getPartitionId(), executionId);</span><br><span class="line"></span><br><span class="line">	this.producedPartitions[counter] &#x3D; new ResultPartition(</span><br><span class="line">	    taskNameWithSubtaskAndId,</span><br><span class="line">		this,</span><br><span class="line">		jobId,</span><br><span class="line">		partitionId,</span><br><span class="line">		desc.getPartitionType(),</span><br><span class="line">		desc.getNumberOfSubpartitions(),</span><br><span class="line">		desc.getMaxParallelism(),</span><br><span class="line">		networkEnvironment.getResultPartitionManager(),</span><br><span class="line">		resultPartitionConsumableNotifier,</span><br><span class="line">		ioManager,</span><br><span class="line">		desc.sendScheduleOrUpdateConsumersMessage());		</span><br><span class="line">	&#x2F;&#x2F;为每个partition初始化对应的writer </span><br><span class="line">	writers[counter] &#x3D; new ResultPartitionWriter(producedPartitions[counter]);</span><br><span class="line"></span><br><span class="line">	++counter;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Consumed intermediate result partitions</span><br><span class="line">this.inputGates &#x3D; new SingleInputGate[inputGateDeploymentDescriptors.size()];</span><br><span class="line">this.inputGatesById &#x3D; new HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">counter &#x3D; 0;</span><br><span class="line"></span><br><span class="line">for (InputGateDeploymentDescriptor inputGateDeploymentDescriptor: inputGateDeploymentDescriptors) &#123;</span><br><span class="line">	SingleInputGate gate &#x3D; SingleInputGate.create(</span><br><span class="line">		taskNameWithSubtaskAndId,</span><br><span class="line">		jobId,</span><br><span class="line">		executionId,</span><br><span class="line">		inputGateDeploymentDescriptor,</span><br><span class="line">		networkEnvironment,</span><br><span class="line">		this,</span><br><span class="line">		metricGroup.getIOMetricGroup());</span><br><span class="line"></span><br><span class="line">	inputGates[counter] &#x3D; gate;</span><br><span class="line">	inputGatesById.put(gate.getConsumedResultId(), gate);</span><br><span class="line"></span><br><span class="line">	++counter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后，创建一个Thread对象，并把自己放进该对象，这样在执行时，自己就有了自身的线程的引用。</p>
<h4 id="3-3-2-2-运行Task对象"><a href="#3-3-2-2-运行Task对象" class="headerlink" title="3.3.2.2 运行Task对象"></a>3.3.2.2 运行Task对象</h4><p> Task对象本身就是一个Runable，因此在其run方法里定义了运行逻辑。<br> 第一步是切换Task的状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">      while (true) &#123;</span><br><span class="line">	ExecutionState current &#x3D; this.executionState;</span><br><span class="line">	&#x2F;&#x2F;&#x2F;&#x2F;如果当前的执行状态为CREATED，则将其设置为DEPLOYING状态</span><br><span class="line">	if (current &#x3D;&#x3D; ExecutionState.CREATED) &#123;</span><br><span class="line">		if (transitionState(ExecutionState.CREATED, ExecutionState.DEPLOYING)) &#123;</span><br><span class="line">			&#x2F;&#x2F; success, we can start our work</span><br><span class="line">			break;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;如果当前执行状态为FAILED，则发出通知并退出run方法</span><br><span class="line">	else if (current &#x3D;&#x3D; ExecutionState.FAILED) &#123;</span><br><span class="line">		&#x2F;&#x2F; we were immediately failed. tell the TaskManager that we reached our final state</span><br><span class="line">		notifyFinalState();</span><br><span class="line">		if (metrics !&#x3D; null) &#123;</span><br><span class="line">			metrics.close();</span><br><span class="line">		&#125;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;如果当前执行状态为CANCELING，则将其修改为CANCELED状态，并退出run</span><br><span class="line">	else if (current &#x3D;&#x3D; ExecutionState.CANCELING) &#123;</span><br><span class="line">		if (transitionState(ExecutionState.CANCELING, ExecutionState.CANCELED)) &#123;</span><br><span class="line">			&#x2F;&#x2F; we were immediately canceled. tell the TaskManager that we reached our final state</span><br><span class="line">			notifyFinalState();</span><br><span class="line">			if (metrics !&#x3D; null) &#123;</span><br><span class="line">				metrics.close();</span><br><span class="line">			&#125;</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;否则说明发生了异常</span><br><span class="line">	else &#123;</span><br><span class="line">		if (metrics !&#x3D; null) &#123;</span><br><span class="line">			metrics.close();</span><br><span class="line">		&#125;</span><br><span class="line">		throw new IllegalStateException(&quot;Invalid state for beginning of operation of task &quot; + this + &#39;.&#39;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实这里有个值得关注的点，就是flink里大量使用了这种while(true)的写法来修改和检测状态，emmm…<br>接下来，就是导入用户类加载器并加载用户代码。<br>然后，是向网络管理器注册当前任务（flink的各个算子在运行时进行数据交换需要依赖网络管理器），分配一些缓存以保存数据<br>然后，读入指定的缓存文件。<br>然后，再把task创建时传入的那一大堆变量用于创建一个执行环境Envrionment。<br>再然后，对于那些并不是第一次执行的task（比如失败后重启的）要恢复其状态。<br>接下来最重要的是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">invokable.invoke();</span><br></pre></td></tr></table></figure>
<p>方法。为什么这么说呢，因为这个方法就是用户代码所真正被执行的入口。比如我们写的什么new MapFunction()的逻辑，最终就是在这里被执行的。这里说一下这个invokable，这是一个抽象类，提供了可以被TaskManager执行的对象的基本抽象。<br>这个invokable是在解析JobGraph的时候生成相关信息的，并在此处形成真正可执行的对象</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; now load the task&#39;s invokable code</span><br><span class="line">&#x2F;&#x2F;通过反射生成对象</span><br><span class="line">invokable &#x3D; loadAndInstantiateInvokable(userCodeClassLoader, nameOfInvokableClass);</span><br></pre></td></tr></table></figure>
<p><img src="http://static.zybuluo.com/bethunebtj/9bemw0us5cocnej8lq4x64rk/image_1cbkaa8r9182i18ct1kfu8g829m9.png" alt="image_1cbkaa8r9182i18ct1kfu8g829m9.png-29.9kB"><br>上图显示了flink提供的可被执行的Task类型。从名字上就可以看出各个task的作用，在此不再赘述。<br>接下来就是invoke方法了，因为我们的wordcount例子用了流式api，在此我们以StreamTask的invoke方法为例进行说明。</p>
<h4 id="3-3-2-3-StreamTask的执行逻辑"><a href="#3-3-2-3-StreamTask的执行逻辑" class="headerlink" title="3.3.2.3 StreamTask的执行逻辑"></a>3.3.2.3 StreamTask的执行逻辑</h4><p>先上部分核心代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">public final void invoke() throws Exception &#123;</span><br><span class="line"></span><br><span class="line">	boolean disposed &#x3D; false;</span><br><span class="line">    try &#123;</span><br><span class="line">			&#x2F;&#x2F; -------- Initialize ---------</span><br><span class="line">			&#x2F;&#x2F;先做一些赋值操作</span><br><span class="line">            ......</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; if the clock is not already set, then assign a default TimeServiceProvider</span><br><span class="line">	&#x2F;&#x2F;处理timer</span><br><span class="line">	if (timerService &#x3D;&#x3D; null) &#123;</span><br><span class="line">		ThreadFactory timerThreadFactory &#x3D;</span><br><span class="line">			new DispatcherThreadFactory(TRIGGER_THREAD_GROUP, &quot;Time Trigger for &quot; + getName());</span><br><span class="line"></span><br><span class="line">		timerService &#x3D; new SystemProcessingTimeService(this, getCheckpointLock(), timerThreadFactory);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;把之前JobGraph串起来的chain的信息形成实现</span><br><span class="line">	operatorChain &#x3D; new OperatorChain&lt;&gt;(this);</span><br><span class="line">	headOperator &#x3D; operatorChain.getHeadOperator();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; task specific initialization</span><br><span class="line">	&#x2F;&#x2F;这个init操作的起名非常诡异，因为这里主要是处理算子采用了自定义的checkpoint检查机制的情况，但是起了一个非常大众脸的名字</span><br><span class="line">	init();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; save the work of reloading state, etc, if the task is already canceled</span><br><span class="line">	if (canceled) &#123;</span><br><span class="line">		throw new CancelTaskException();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; -------- Invoke --------</span><br><span class="line">	LOG.debug(&quot;Invoking &#123;&#125;&quot;, getName());</span><br><span class="line">			</span><br><span class="line">	&#x2F;&#x2F; we need to make sure that any triggers scheduled in open() cannot be</span><br><span class="line">	&#x2F;&#x2F; executed before all operators are opened</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; both the following operations are protected by the lock</span><br><span class="line">		&#x2F;&#x2F; so that we avoid race conditions in the case that initializeState()</span><br><span class="line">		&#x2F;&#x2F; registers a timer, that fires before the open() is called.</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;初始化操作符状态，主要是一些state啥的</span><br><span class="line">		initializeState();</span><br><span class="line">		&#x2F;&#x2F;对于富操作符，执行其open操作</span><br><span class="line">		openAllOperators();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; final check to exit early before starting to run</span><br><span class="line">	f (canceled) &#123;</span><br><span class="line">	    throw new CancelTaskException();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; let the task do its work</span><br><span class="line">	&#x2F;&#x2F;真正开始执行的代码</span><br><span class="line">	isRunning &#x3D; true;</span><br><span class="line">	run();</span><br></pre></td></tr></table></figure>
<p>StreamTask.invoke()方法里，第一个值得一说的是<code>TimerService</code>。Flink在2015年决定向StreamTask类加入timer service的时候解释到：</p>
<blockquote>
<p>This integrates the timer as a service in StreamTask that StreamOperators can use by calling a method on the StreamingRuntimeContext. This also ensures that the timer callbacks can not be called concurrently with other methods on the StreamOperator. This behaviour is ensured by an ITCase.</p>
</blockquote>
<p>第二个要注意的是chain操作。前面提到了，flink会出于优化的角度，把一些算子chain成一个整体的算子作为一个task来执行。比如wordcount例子中，Source和FlatMap算子就被chain在了一起。在进行chain操作的时候，会设定头节点，并且指定输出的RecordWriter。</p>
<p>接下来不出所料仍然是初始化，只不过初始化的对象变成了各个operator。如果是有checkpoint的，那就从state信息里恢复，不然就作为全新的算子处理。从源码中可以看到，flink针对keyed算子和普通算子做了不同的处理。keyed算子在初始化时需要计算出一个group区间，这个区间的值在整个生命周期里都不会再变化，后面key就会根据hash的不同结果，分配到特定的group中去计算。顺便提一句，flink的keyed算子保存的是对每个数据的key的计算方法，而非真实的key，用户需要自己保证对每一行数据提供的keySelector的幂等性。至于为什么要用KeyGroup的设计，这就牵扯到扩容的范畴了，将在后面的章节进行讲述。<br>对于<code>openAllOperators()</code>方法，就是对各种RichOperator执行其open方法，通常可用于在执行计算之前加载资源。<br>最后，run方法千呼万唤始出来，该方法经过一系列跳转，最终调用chain上的第一个算子的run方法。在wordcount的例子中，它最终调用了SocketTextStreamFunction的run，建立socket连接并读入文本。</p>
<h3 id="3-4-StreamTask与StreamOperator"><a href="#3-4-StreamTask与StreamOperator" class="headerlink" title="3.4 StreamTask与StreamOperator"></a>3.4 StreamTask与StreamOperator</h3><p>前面提到，Task对象在执行过程中，把执行的任务交给了StreamTask这个类去执行。在我们的wordcount例子中，实际初始化的是OneInputStreamTask的对象（参考上面的类图）。那么这个对象是如何执行用户的代码的呢？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">protected void run() throws Exception &#123;</span><br><span class="line">	&#x2F;&#x2F; cache processor reference on the stack, to make the code more JIT friendly</span><br><span class="line">	final StreamInputProcessor&lt;IN&gt; inputProcessor &#x3D; this.inputProcessor;</span><br><span class="line"></span><br><span class="line">	while (running &amp;&amp; inputProcessor.processInput()) &#123;</span><br><span class="line">		&#x2F;&#x2F; all the work happens in the &quot;processInput&quot; method</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它做的，就是把任务直接交给了InputProcessor去执行processInput方法。这是一个<code>StreamInputProcessor</code>的实例，该processor的任务就是处理输入的数据，包括用户数据、watermark和checkpoint数据等。我们先来看看这个processor是如何产生的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">public void init() throws Exception &#123;</span><br><span class="line">	StreamConfig configuration &#x3D; getConfiguration();</span><br><span class="line"></span><br><span class="line">	TypeSerializer&lt;IN&gt; inSerializer &#x3D; configuration.getTypeSerializerIn1(getUserCodeClassLoader());</span><br><span class="line">	int numberOfInputs &#x3D; configuration.getNumberOfInputs();</span><br><span class="line"></span><br><span class="line">	if (numberOfInputs &gt; 0) &#123;</span><br><span class="line">		InputGate[] inputGates &#x3D; getEnvironment().getAllInputGates();</span><br><span class="line"></span><br><span class="line">		inputProcessor &#x3D; new StreamInputProcessor&lt;&gt;(</span><br><span class="line">				inputGates,</span><br><span class="line">				inSerializer,</span><br><span class="line">				this,</span><br><span class="line">				configuration.getCheckpointMode(),</span><br><span class="line">				getCheckpointLock(),</span><br><span class="line">				getEnvironment().getIOManager(),</span><br><span class="line">				getEnvironment().getTaskManagerInfo().getConfiguration(),</span><br><span class="line">				getStreamStatusMaintainer(),</span><br><span class="line">				this.headOperator);</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; make sure that stream tasks report their I&#x2F;O statistics</span><br><span class="line">		inputProcessor.setMetricGroup(getEnvironment().getMetricGroup().getIOMetricGroup());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是OneInputStreamTask的init方法，从configs里面获取StreamOperator信息，生成自己的inputProcessor。那么inputProcessor是如何处理数据的呢？我们接着跟进源码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">public boolean processInput() throws Exception &#123;</span><br><span class="line">		if (isFinished) &#123;</span><br><span class="line">			return false;</span><br><span class="line">		&#125;</span><br><span class="line">		if (numRecordsIn &#x3D;&#x3D; null) &#123;</span><br><span class="line">			numRecordsIn &#x3D; ((OperatorMetricGroup) streamOperator.getMetricGroup()).getIOMetricGroup().getNumRecordsInCounter();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;这个while是用来处理单个元素的（不要想当然以为是循环处理元素的）</span><br><span class="line">		while (true) &#123;</span><br><span class="line">		    &#x2F;&#x2F;注意 1在下面</span><br><span class="line">		    &#x2F;&#x2F;2.接下来，会利用这个反序列化器得到下一个数据记录，并进行解析（是用户数据还是watermark等等），然后进行对应的操作</span><br><span class="line">			if (currentRecordDeserializer !&#x3D; null) &#123;</span><br><span class="line">				DeserializationResult result &#x3D; currentRecordDeserializer.getNextRecord(deserializationDelegate);</span><br><span class="line"></span><br><span class="line">				if (result.isBufferConsumed()) &#123;</span><br><span class="line">					currentRecordDeserializer.getCurrentBuffer().recycle();</span><br><span class="line">					currentRecordDeserializer &#x3D; null;</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				if (result.isFullRecord()) &#123;</span><br><span class="line">					StreamElement recordOrMark &#x3D; deserializationDelegate.getInstance();</span><br><span class="line"></span><br><span class="line">                    &#x2F;&#x2F;如果元素是watermark，就准备更新当前channel的watermark值（并不是简单赋值，因为有乱序存在），</span><br><span class="line">					if (recordOrMark.isWatermark()) &#123;</span><br><span class="line">						&#x2F;&#x2F; handle watermark</span><br><span class="line">						statusWatermarkValve.inputWatermark(recordOrMark.asWatermark(), currentChannel);</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else if (recordOrMark.isStreamStatus()) &#123;</span><br><span class="line">					&#x2F;&#x2F;如果元素是status，就进行相应处理。可以看作是一个flag，标志着当前stream接下来即将没有元素输入（idle），或者当前即将由空闲状态转为有元素状态（active）。同时，StreamStatus还对如何处理watermark有影响。通过发送status，上游的operator可以很方便的通知下游当前的数据流的状态。</span><br><span class="line">						&#x2F;&#x2F; handle stream status</span><br><span class="line">						statusWatermarkValve.inputStreamStatus(recordOrMark.asStreamStatus(), currentChannel);</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else if (recordOrMark.isLatencyMarker()) &#123;</span><br><span class="line">					&#x2F;&#x2F;LatencyMarker是用来衡量代码执行时间的。在Source处创建，携带创建时的时间戳，流到Sink时就可以知道经过了多长时间</span><br><span class="line">						&#x2F;&#x2F; handle latency marker</span><br><span class="line">						synchronized (lock) &#123;</span><br><span class="line">							streamOperator.processLatencyMarker(recordOrMark.asLatencyMarker());</span><br><span class="line">						&#125;</span><br><span class="line">						continue;</span><br><span class="line">					&#125; else &#123;</span><br><span class="line">					&#x2F;&#x2F;这里就是真正的，用户的代码即将被执行的地方。从章节1到这里足足用了三万字，有点万里长征的感觉</span><br><span class="line">						&#x2F;&#x2F; now we can do the actual processing</span><br><span class="line">						StreamRecord&lt;IN&gt; record &#x3D; recordOrMark.asRecord();</span><br><span class="line">						synchronized (lock) &#123;</span><br><span class="line">							numRecordsIn.inc();</span><br><span class="line">							streamOperator.setKeyContextElement1(record);</span><br><span class="line">							streamOperator.processElement(record);</span><br><span class="line">						&#125;</span><br><span class="line">						return true;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;1.程序首先获取下一个buffer</span><br><span class="line">            &#x2F;&#x2F;这一段代码是服务于flink的FaultTorrent机制的，后面我会讲到，这里只需理解到它会尝试获取buffer，然后赋值给当前的反序列化器</span><br><span class="line">			final BufferOrEvent bufferOrEvent &#x3D; barrierHandler.getNextNonBlocked();</span><br><span class="line">			if (bufferOrEvent !&#x3D; null) &#123;</span><br><span class="line">				if (bufferOrEvent.isBuffer()) &#123;</span><br><span class="line">					currentChannel &#x3D; bufferOrEvent.getChannelIndex();</span><br><span class="line">					currentRecordDeserializer &#x3D; recordDeserializers[currentChannel];</span><br><span class="line">					currentRecordDeserializer.setNextBuffer(bufferOrEvent.getBuffer());</span><br><span class="line">				&#125;</span><br><span class="line">				else &#123;</span><br><span class="line">					&#x2F;&#x2F; Event received</span><br><span class="line">					final AbstractEvent event &#x3D; bufferOrEvent.getEvent();</span><br><span class="line">					if (event.getClass() !&#x3D; EndOfPartitionEvent.class) &#123;</span><br><span class="line">						throw new IOException(&quot;Unexpected event: &quot; + event);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			else &#123;</span><br><span class="line">				isFinished &#x3D; true;</span><br><span class="line">				if (!barrierHandler.isEmpty()) &#123;</span><br><span class="line">					throw new IllegalStateException(&quot;Trailing data in checkpoint barrier handler.&quot;);</span><br><span class="line">				&#125;</span><br><span class="line">				return false;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>到此为止，以上部分就是一个flink程序启动后，到执行用户代码之前，flink框架所做的准备工作。回顾一下：</p>
<ul>
<li>启动一个环境</li>
<li>生成StreamGraph</li>
<li>注册和选举JobManager</li>
<li>在各节点生成TaskManager，并根据JobGraph生成对应的Task</li>
<li>启动各个task，准备执行代码</li>
</ul>
<p>接下来，我们挑几个Operator看看flink是如何抽象这些算子的。</p>
<h2 id="4-StreamOperator的抽象与实现"><a href="#4-StreamOperator的抽象与实现" class="headerlink" title="4. StreamOperator的抽象与实现"></a>4. StreamOperator的抽象与实现</h2><h3 id="4-1-数据源的逻辑——StreamSource与时间模型"><a href="#4-1-数据源的逻辑——StreamSource与时间模型" class="headerlink" title="4.1 数据源的逻辑——StreamSource与时间模型"></a>4.1 数据源的逻辑——StreamSource与时间模型</h3><p>StreamSource抽象了一个数据源，并且指定了一些如何处理数据的模式。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">public class StreamSource&lt;OUT, SRC extends SourceFunction&lt;OUT&gt;&gt;</span><br><span class="line">		extends AbstractUdfStreamOperator&lt;OUT, SRC&gt; implements StreamOperator&lt;OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">	public void run(final Object lockingObject, final StreamStatusMaintainer streamStatusMaintainer) throws Exception &#123;</span><br><span class="line">		run(lockingObject, streamStatusMaintainer, output);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void run(final Object lockingObject,</span><br><span class="line">			final StreamStatusMaintainer streamStatusMaintainer,</span><br><span class="line">			final Output&lt;StreamRecord&lt;OUT&gt;&gt; collector) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">		final TimeCharacteristic timeCharacteristic &#x3D; getOperatorConfig().getTimeCharacteristic();</span><br><span class="line"></span><br><span class="line">		LatencyMarksEmitter latencyEmitter &#x3D; null;</span><br><span class="line">		if (getExecutionConfig().isLatencyTrackingEnabled()) &#123;</span><br><span class="line">			latencyEmitter &#x3D; new LatencyMarksEmitter&lt;&gt;(</span><br><span class="line">				getProcessingTimeService(),</span><br><span class="line">				collector,</span><br><span class="line">				getExecutionConfig().getLatencyTrackingInterval(),</span><br><span class="line">				getOperatorConfig().getVertexID(),</span><br><span class="line">				getRuntimeContext().getIndexOfThisSubtask());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		final long watermarkInterval &#x3D; getRuntimeContext().getExecutionConfig().getAutoWatermarkInterval();</span><br><span class="line"></span><br><span class="line">		this.ctx &#x3D; StreamSourceContexts.getSourceContext(</span><br><span class="line">			timeCharacteristic,</span><br><span class="line">			getProcessingTimeService(),</span><br><span class="line">			lockingObject,</span><br><span class="line">			streamStatusMaintainer,</span><br><span class="line">			collector,</span><br><span class="line">			watermarkInterval,</span><br><span class="line">			-1);</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			userFunction.run(ctx);</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; if we get here, then the user function either exited after being done (finite source)</span><br><span class="line">			&#x2F;&#x2F; or the function was canceled or stopped. For the finite source case, we should emit</span><br><span class="line">			&#x2F;&#x2F; a final watermark that indicates that we reached the end of event-time</span><br><span class="line">			if (!isCanceledOrStopped()) &#123;</span><br><span class="line">				ctx.emitWatermark(Watermark.MAX_WATERMARK);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			&#x2F;&#x2F; make sure that the context is closed in any case</span><br><span class="line">			ctx.close();</span><br><span class="line">			if (latencyEmitter !&#x3D; null) &#123;</span><br><span class="line">				latencyEmitter.close();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">	private static class LatencyMarksEmitter&lt;OUT&gt; &#123;</span><br><span class="line">		private final ScheduledFuture&lt;?&gt; latencyMarkTimer;</span><br><span class="line"></span><br><span class="line">		public LatencyMarksEmitter(</span><br><span class="line">				final ProcessingTimeService processingTimeService,</span><br><span class="line">				final Output&lt;StreamRecord&lt;OUT&gt;&gt; output,</span><br><span class="line">				long latencyTrackingInterval,</span><br><span class="line">				final int vertexID,</span><br><span class="line">				final int subtaskIndex) &#123;</span><br><span class="line"></span><br><span class="line">			latencyMarkTimer &#x3D; processingTimeService.scheduleAtFixedRate(</span><br><span class="line">				new ProcessingTimeCallback() &#123;</span><br><span class="line">					@Override</span><br><span class="line">					public void onProcessingTime(long timestamp) throws Exception &#123;</span><br><span class="line">						try &#123;</span><br><span class="line">							&#x2F;&#x2F; ProcessingTimeService callbacks are executed under the checkpointing lock</span><br><span class="line">							output.emitLatencyMarker(new LatencyMarker(timestamp, vertexID, subtaskIndex));</span><br><span class="line">						&#125; catch (Throwable t) &#123;</span><br><span class="line">							&#x2F;&#x2F; we catch the Throwables here so that we don&#39;t trigger the processing</span><br><span class="line">							&#x2F;&#x2F; timer services async exception handler</span><br><span class="line">							LOG.warn(&quot;Error while emitting latency marker.&quot;, t);</span><br><span class="line">						&#125;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;,</span><br><span class="line">				0L,</span><br><span class="line">				latencyTrackingInterval);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		public void close() &#123;</span><br><span class="line">			latencyMarkTimer.cancel(true);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在StreamSource生成上下文之后，接下来就是把上下文交给SourceFunction去执行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">userFunction.run(ctx);</span><br></pre></td></tr></table></figure>
<p>SourceFunction是对Function的一个抽象，就好像MapFunction，KeyByFunction一样，用户选择实现这些函数，然后flink框架就能利用这些函数进行计算，完成用户逻辑。<br>我们的wordcount程序使用了flink提供的一个<code>SocketTextStreamFunction</code>。我们可以看一下它的实现逻辑，对source如何运行有一个基本的认识：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">public void run(SourceContext&lt;String&gt; ctx) throws Exception &#123;</span><br><span class="line">		final StringBuilder buffer &#x3D; new StringBuilder();</span><br><span class="line">		long attempt &#x3D; 0;</span><br><span class="line"></span><br><span class="line">		while (isRunning) &#123;</span><br><span class="line"></span><br><span class="line">			try (Socket socket &#x3D; new Socket()) &#123;</span><br><span class="line">				currentSocket &#x3D; socket;</span><br><span class="line"></span><br><span class="line">				LOG.info(&quot;Connecting to server socket &quot; + hostname + &#39;:&#39; + port);</span><br><span class="line">				socket.connect(new InetSocketAddress(hostname, port), CONNECTION_TIMEOUT_TIME);</span><br><span class="line">				BufferedReader reader &#x3D; new BufferedReader(new InputStreamReader(socket.getInputStream()));</span><br><span class="line"></span><br><span class="line">				char[] cbuf &#x3D; new char[8192];</span><br><span class="line">				int bytesRead;</span><br><span class="line">				&#x2F;&#x2F;核心逻辑就是一直读inputSocket,然后交给collect方法</span><br><span class="line">				while (isRunning &amp;&amp; (bytesRead &#x3D; reader.read(cbuf)) !&#x3D; -1) &#123;</span><br><span class="line">					buffer.append(cbuf, 0, bytesRead);</span><br><span class="line">					int delimPos;</span><br><span class="line">					while (buffer.length() &gt;&#x3D; delimiter.length() &amp;&amp; (delimPos &#x3D; buffer.indexOf(delimiter)) !&#x3D; -1) &#123;</span><br><span class="line">						String record &#x3D; buffer.substring(0, delimPos);</span><br><span class="line">						&#x2F;&#x2F; truncate trailing carriage return</span><br><span class="line">						if (delimiter.equals(&quot;\n&quot;) &amp;&amp; record.endsWith(&quot;\r&quot;)) &#123;</span><br><span class="line">							record &#x3D; record.substring(0, record.length() - 1);</span><br><span class="line">						&#125;</span><br><span class="line">						&#x2F;&#x2F;读到数据后，把数据交给collect方法，collect方法负责把数据交到合适的位置（如发布为br变量，或者交给下个operator，或者通过网络发出去）</span><br><span class="line">						ctx.collect(record);</span><br><span class="line">						buffer.delete(0, delimPos + delimiter.length());</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			&#x2F;&#x2F; if we dropped out of this loop due to an EOF, sleep and retry</span><br><span class="line">			if (isRunning) &#123;</span><br><span class="line">				attempt++;</span><br><span class="line">				if (maxNumRetries &#x3D;&#x3D; -1 || attempt &lt; maxNumRetries) &#123;</span><br><span class="line">					LOG.warn(&quot;Lost connection to server socket. Retrying in &quot; + delayBetweenRetries + &quot; msecs...&quot;);</span><br><span class="line">					Thread.sleep(delayBetweenRetries);</span><br><span class="line">				&#125;</span><br><span class="line">				else &#123;</span><br><span class="line">					&#x2F;&#x2F; this should probably be here, but some examples expect simple exists of the stream source</span><br><span class="line">					&#x2F;&#x2F; throw new EOFException(&quot;Reached end of stream and reconnects are not enabled.&quot;);</span><br><span class="line">					break;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; collect trailing data</span><br><span class="line">		if (buffer.length() &gt; 0) &#123;</span><br><span class="line">			ctx.collect(buffer.toString());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>整段代码里，只有collect方法有些复杂度，后面我们在讲到flink的对象机制时会结合来讲，此处知道collect方法会收集结果，然后发送给接收者即可。在我们的wordcount里，这个算子的接收者就是被chain在一起的flatmap算子，不记得这个示例程序的话，可以返回第一章去看一下。</p>
<h3 id="4-2-从数据输入到数据处理——OneInputStreamOperator-amp-AbstractUdfStreamOperator"><a href="#4-2-从数据输入到数据处理——OneInputStreamOperator-amp-AbstractUdfStreamOperator" class="headerlink" title="4.2 从数据输入到数据处理——OneInputStreamOperator &amp; AbstractUdfStreamOperator"></a>4.2 从数据输入到数据处理——OneInputStreamOperator &amp; AbstractUdfStreamOperator</h3><p>StreamSource是用来开启整个流的算子，而承接输入数据并进行处理的算子就是OneInputStreamOperator、TwoInputStreamOperator等。<br><img src="http://static.zybuluo.com/bethunebtj/9itne7dj58lkkb4mtrt9c8q5/image_1cdc1tbgs136k1ppf17at14fumjf2d.png" alt="image_1cdc1tbgs136k1ppf17at14fumjf2d.png-126.7kB"><br>整个StreamOperator的继承关系如上图所示（图很大，建议点开放大看）。<br>OneInputStreamOperator这个接口的逻辑很简单：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public interface OneInputStreamOperator&lt;IN, OUT&gt; extends StreamOperator&lt;OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * Processes one element that arrived at this operator.</span><br><span class="line">	 * This method is guaranteed to not be called concurrently with other methods of the operator.</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	void processElement(StreamRecord&lt;IN&gt; element) throws Exception;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * Processes a &#123;@link Watermark&#125;.</span><br><span class="line">	 * This method is guaranteed to not be called concurrently with other methods of the operator.</span><br><span class="line">	 *</span><br><span class="line">	 * @see org.apache.flink.streaming.api.watermark.Watermark</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	void processWatermark(Watermark mark) throws Exception;</span><br><span class="line"></span><br><span class="line">	void processLatencyMarker(LatencyMarker latencyMarker) throws Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而实现了这个接口的StreamFlatMap算子也很简单，没什么可说的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public class StreamFlatMap&lt;IN, OUT&gt;</span><br><span class="line">		extends AbstractUdfStreamOperator&lt;OUT, FlatMapFunction&lt;IN, OUT&gt;&gt;</span><br><span class="line">		implements OneInputStreamOperator&lt;IN, OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">	private static final long serialVersionUID &#x3D; 1L;</span><br><span class="line"></span><br><span class="line">	private transient TimestampedCollector&lt;OUT&gt; collector;</span><br><span class="line"></span><br><span class="line">	public StreamFlatMap(FlatMapFunction&lt;IN, OUT&gt; flatMapper) &#123;</span><br><span class="line">		super(flatMapper);</span><br><span class="line">		chainingStrategy &#x3D; ChainingStrategy.ALWAYS;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void open() throws Exception &#123;</span><br><span class="line">		super.open();</span><br><span class="line">		collector &#x3D; new TimestampedCollector&lt;&gt;(output);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void processElement(StreamRecord&lt;IN&gt; element) throws Exception &#123;</span><br><span class="line">		collector.setTimestamp(element);</span><br><span class="line">		userFunction.flatMap(element.getValue(), collector);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从类图里可以看到，flink为我们封装了一个算子的基类<code>AbstractUdfStreamOperator</code>，提供了一些通用功能，比如把context赋给算子，保存快照等等，其中最为大家了解的应该是这两个：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void open() throws Exception &#123;</span><br><span class="line">	super.open();</span><br><span class="line">	FunctionUtils.openFunction(userFunction, new Configuration());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void close() throws Exception &#123;</span><br><span class="line">	super.close();</span><br><span class="line">	functionsClosed &#x3D; true;</span><br><span class="line">	FunctionUtils.closeFunction(userFunction);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这两个就是flink提供的<code>Rich***Function</code>系列算子的open和close方法被执行的地方。</p>
<h3 id="4-3-StreamSink"><a href="#4-3-StreamSink" class="headerlink" title="4.3 StreamSink"></a>4.3 StreamSink</h3><p>StreamSink着实没什么可说的，逻辑很简单，值得一提的只有两个方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void processElement(StreamRecord&lt;IN&gt; element) throws Exception &#123;</span><br><span class="line">	sinkContext.element &#x3D; element;</span><br><span class="line">	userFunction.invoke(element.getValue(), sinkContext);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">protected void reportOrForwardLatencyMarker(LatencyMarker maker) &#123;</span><br><span class="line">	&#x2F;&#x2F; all operators are tracking latencies</span><br><span class="line">	this.latencyGauge.reportLatency(maker, true);</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; sinks don&#39;t forward latency markers</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>processElement</code> 是继承自StreamOperator的方法。<code>reportOrForwardLatencyMarker</code>是用来计算延迟的，前面提到StreamSource会产生LateMarker，用于记录数据计算时间，就是在这里完成了计算。</p>
<p>算子这部分逻辑相对简单清晰，就讲这么多吧。</p>
<h2 id="5-为执行保驾护航——Fault-Tolerant与保证Exactly-Once语义"><a href="#5-为执行保驾护航——Fault-Tolerant与保证Exactly-Once语义" class="headerlink" title="5. 为执行保驾护航——Fault Tolerant与保证Exactly-Once语义"></a>5. 为执行保驾护航——Fault Tolerant与保证Exactly-Once语义</h2><h3 id="5-1-Fault-Tolerant演进之路"><a href="#5-1-Fault-Tolerant演进之路" class="headerlink" title="5.1 Fault Tolerant演进之路"></a>5.1 Fault Tolerant演进之路</h3><p>对于7×24小时不间断运行的流程序来说，要保证fault tolerant是很难的，这不像是离线任务，如果失败了只需要清空已有结果，重新跑一次就可以了。对于流任务，如果要保证能够重新处理已处理过的数据，就要把数据保存下来；而这就面临着几个问题：比如一是保存多久的数据？二是重复计算的数据应该怎么处理，怎么保证幂等性？<br>对于一个流系统，我们有以下希望：</p>
<ol>
<li>最好能做到exactly-once</li>
<li>处理延迟越低越好</li>
<li>吞吐量越高越好</li>
<li>计算模型应当足够简单易用，又具有足够的表达力</li>
<li>从错误恢复的开销越低越好</li>
<li>足够的流控制能力（背压能力）</li>
</ol>
<h4 id="5-1-1-Storm的Record-acknowledgement模式"><a href="#5-1-1-Storm的Record-acknowledgement模式" class="headerlink" title="5.1.1 Storm的Record acknowledgement模式"></a>5.1.1 Storm的Record acknowledgement模式</h4><p>storm的fault tolerant是这样工作的：每一个被storm的operator处理的数据都会向其上一个operator发送一份应答消息，通知其已被下游处理。storm的源operator保存了所有已发送的消息的每一个下游算子的应答消息，当它收到来自sink的应答时，它就知道该消息已经被完整处理，可以移除了。<br>如果没有收到应答，storm就会重发该消息。显而易见，这是一种at least once的逻辑。另外，这种方式面临着严重的幂等性问题，例如对一个count算子，如果count的下游算子出错，source重发该消息，那么防止该消息被count两遍的逻辑需要程序员自己去实现。最后，这样一种处理方式非常低效，吞吐量很低。</p>
<h4 id="5-1-2-Spark-streaming的micro-batch模式"><a href="#5-1-2-Spark-streaming的micro-batch模式" class="headerlink" title="5.1.2 Spark streaming的micro batch模式"></a>5.1.2 Spark streaming的micro batch模式</h4><p>前面提到，storm的实现方式就注定了与高吞吐量无缘。那么，为了提高吞吐量，把一批数据聚集在一起处理就是很自然的选择。Spark Streaming的实现就是基于这样的思路：<br>我们可以在完全的连续计算与完全的分批计算中间取折中，通过控制每批计算数据的大小来控制延迟与吞吐量的制约，如果想要低延迟，就用小一点的batch，如果想要大吞吐量，就不得不忍受更高的延迟（更久的等待数据到来的时间和更多的计算），如下图所示。<br><img src="http://static.zybuluo.com/bethunebtj/1uwp211uaxpb6nqbztfkh3u1/image_1ceop58ha180p1h3ren58jk15gb9.png" alt="image_1ceop58ha180p1h3ren58jk15gb9.png-105.7kB"><br>以这样的方式，可以在每个batch中做到exactly-once，但是这种方式也有其弊端：<br>首先，batch的方式使得一些需要跨batch的操作变得非常困难，例如session window；用户不得不自己想办法去实现相关逻辑。<br>其次，batch模式很难做好背压。当一个batch因为种种原因处理慢了，那么下一个batch要么不得不容纳更多的新来数据，要么不得不堆积更多的batch，整个任务可能会被拖垮，这是一个非常致命的问题。<br>最后，batch的方式基本意味着其延迟是有比较高的下限的，实时性上不好。</p>
<h4 id="5-1-3-Google-Cloud-Dataflow的事务式模型"><a href="#5-1-3-Google-Cloud-Dataflow的事务式模型" class="headerlink" title="5.1.3 Google Cloud Dataflow的事务式模型"></a>5.1.3 Google Cloud Dataflow的事务式模型</h4><p>我们在传统数据库，如mysql中使用binlog来完成事务，这样的思路也可以被用在实现exactly-once模型中。例如，我们可以log下每个数据元素每一次被处理时的结果和当时所处的操作符的状态。这样，当我们需要fault tolerant时，我们只需要读一下log就可以了。这种模式规避了storm和spark所面临的问题，并且能够很好的实现exactly-once，唯一的弊端是：如何尽可能的减少log的成本？Flink给了我们答案。</p>
<h4 id="5-1-4-Flink的分布式快照机制"><a href="#5-1-4-Flink的分布式快照机制" class="headerlink" title="5.1.4 Flink的分布式快照机制"></a>5.1.4 Flink的分布式快照机制</h4><p> 实现exactly-once的关键是什么？是能够准确的知道和快速记录下来当前的operator的状态、当前正在处理的元素（以及正处在不同算子之间传递的元素）。如果上面这些可以做到，那么fault tolerant无非就是从持久化存储中读取上次记录的这些元信息，并且恢复到程序中。那么Flink是如何实现的呢？</p>
<p>Flink的分布式快照的核心是其轻量级异步分布式快照机制。为了实现这一机制，flink引入了一个概念，叫做Barrier。Barrier是一种标记，它被source产生并且插入到流数据中，被发送到下游节点。当下游节点处理到该barrier标志时，这就意味着在该barrier插入到流数据时，已经进入系统的数据在当前节点已经被处理完毕。<br><img src="http://static.zybuluo.com/bethunebtj/r0h3z9im5o9ijqlvvl7vjgrt/image_1ceos05badva20hb5glen1voqm.png" alt="image_1ceos05badva20hb5glen1voqm.png-15.3kB"></p>
<p>如图所示，每当一个barrier流过一个算子节点时，就说明了在该算子上，可以触发一次检查点，用以保存当前节点的状态和已经处理过的数据，这就是一份快照。（在这里可以联想一下micro-batch，把barrier想象成分割每个batch的逻辑，会好理解一点）这样的方式下，记录快照就像和前面提到的micro-batch一样容易。</p>
<p>与此同时，该算子会向下游发送该barrier。因为数据在算子之间是按顺序发送的，所以当下游节点收到该barrier时，也就意味着同样的一批数据在下游节点上也处理完毕，可以进行一次checkpoint，保存基于该节点的一份快照，快照完成后，会通知JobMananger自己完成了这个快照。这就是分布式快照的基本含义。</p>
<p>再看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/fp1rtm1pjv12lo6nld7bns5j/image_1ceot7q13apu1a04170af7j1jao34.png" alt="image_1ceot7q13apu1a04170af7j1jao34.png-66.6kB"><br>有时，有的算子的上游节点和下游节点都不止一个，应该怎么处理呢？如果有不止一个下游节点，就向每个下游发送barrier。同理，如果有不止一个上游节点，那么就要等到所有上游节点的同一批次的barrier到达之后，才能触发checkpoint。因为每个节点运算速度不同，所以有的上游节点可能已经在发下个barrier周期的数据了，有的上游节点还没发送本次的barrier，这时候，当前算子就要缓存一下提前到来的数据，等比较慢的上游节点发送barrier之后，才能处理下一批数据。</p>
<p>当整个程序的最后一个算子sink都收到了这个barrier，也就意味着这个barrier和上个barrier之间所夹杂的这批元素已经全部落袋为安。这时，最后一个算子通知JobManager整个流程已经完成，而JobManager随后发出通知，要求所有算子删除本次快照内容，以完成清理。这整个部分，就是Flink的<strong>两阶段提交的checkpoint过程</strong>，如下面四幅图所示：<br><img src="http://static.zybuluo.com/bethunebtj/achr7r6gcstodi7m9gc270r5/image_1ceot517e14g31u2u1mnt12o91dkb1g.png" alt="image_1ceot517e14g31u2u1mnt12o91dkb1g.png-175.5kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/sibwkuskxs20xjcqkn872xg5/image_1ceot5kqbnik1f2i1dss1q5c1a1t.png" alt="image_1ceot5kqbnik1f2i1dss1q5c1a1t.png-221.3kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/0ly9zl3w3twknw7ftalv722a/image_1ceot64dppjtojkq3n1jl5j0h2a.png" alt="image_1ceot64dppjtojkq3n1jl5j0h2a.png-297.8kB"></p>
<p><img src="http://static.zybuluo.com/bethunebtj/b5wrovrsrghkxuumgf6rgabc/image_1ceot6kes56sidn1f2u1voo19kf2n.png" alt="image_1ceot6kes56sidn1f2u1voo19kf2n.png-255.5kB"></p>
<p>总之，通过这种方式，flink实现了我们前面提到的六项对流处理框架的要求：exactly-once、低延迟、高吞吐、易用的模型、方便的恢复机制。</p>
<p>最后，贴一个美团做的flink与storm的性能对比：<a target="_blank" rel="noopener" href="https://tech.meituan.com/Flink_Benchmark.html">flink与storm的性能对比</a></p>
<h3 id="5-2-checkpoint的生命周期"><a href="#5-2-checkpoint的生命周期" class="headerlink" title="5.2 checkpoint的生命周期"></a>5.2 checkpoint的生命周期</h3><p>接下来，我们结合源码来看看flink的checkpoint到底是如何实现其生命周期的：</p>
<blockquote>
<p>由于flink提供的SocketSource并不支持checkpoint，所以这里我以<code>FlinkKafkaConsumer010</code>作为sourceFunction。</p>
</blockquote>
<h4 id="5-2-1-触发checkpoint"><a href="#5-2-1-触发checkpoint" class="headerlink" title="5.2.1 触发checkpoint"></a>5.2.1 触发checkpoint</h4><p>要完成一次checkpoint，第一步必然是发起checkpoint请求。那么，这个请求是哪里发出的，怎么发出的，又由谁控制呢？<br>还记得如果我们要设置checkpoint的话，需要指定checkpoint间隔吧？既然是一个指定间隔触发的功能，那应该会有类似于Scheduler的东西存在，flink里，这个负责触发checkpoint的类是<code>CheckpointCoordinator</code>。</p>
<p>flink在提交job时，会启动这个类的<code>startCheckpointScheduler</code>方法，如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public void startCheckpointScheduler() &#123;</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (shutdown) &#123;</span><br><span class="line">			throw new IllegalArgumentException(&quot;Checkpoint coordinator is shut down&quot;);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; make sure all prior timers are cancelled</span><br><span class="line">		stopCheckpointScheduler();</span><br><span class="line"></span><br><span class="line">		periodicScheduling &#x3D; true;</span><br><span class="line">		currentPeriodicTrigger &#x3D; timer.scheduleAtFixedRate(</span><br><span class="line">				new ScheduledTrigger(), </span><br><span class="line">				baseInterval, baseInterval, TimeUnit.MILLISECONDS);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private final class ScheduledTrigger implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void run() &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			triggerCheckpoint(System.currentTimeMillis(), true);</span><br><span class="line">		&#125;</span><br><span class="line">		catch (Exception e) &#123;</span><br><span class="line">			LOG.error(&quot;Exception while triggering checkpoint.&quot;, e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>启动之后，就会以设定好的频率调用<code>triggerCheckPoint()</code>方法。这个方法太长，我大概说一下都做了什么：</p>
<ul>
<li>检查符合触发checkpoint的条件，例如如果禁止了周期性的checkpoint，尚未达到触发checkpoint的最小间隔等等，就直接return</li>
<li>检查是否所有需要checkpoint和需要响应checkpoint的ACK（ack涉及到checkpoint的两阶段提交，后面会讲）的task都处于running状态，否则return</li>
<li>如果都符合，那么执行<code>checkpointID = checkpointIdCounter.getAndIncrement();</code>以生成一个新的id，然后生成一个<code>PendingCheckpoint</code>。PendingCheckpoint是一个启动了的checkpoint，但是还没有被确认。等到所有的task都确认了本次checkpoint，那么这个checkpoint对象将转化为一个<code>CompletedCheckpoint</code>。</li>
<li>定义一个超时callback，如果checkpoint执行了很久还没完成，就把它取消</li>
<li>触发MasterHooks，用户可以定义一些额外的操作，用以增强checkpoint的功能（如准备和清理外部资源）</li>
<li>接下来是核心逻辑：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  &#x2F;&#x2F; send the messages to the tasks that trigger their checkpoint</span><br><span class="line">for (Execution execution: executions) &#123;</span><br><span class="line">	execution.triggerCheckpoint(checkpointID, timestamp, checkpointOptions);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里是调用了Execution的triggerCheckpoint方法，一个execution就是一个executionVertex的实际执行者。我们看一下这个方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public void triggerCheckpoint(long checkpointId, long timestamp, CheckpointOptions checkpointOptions) &#123;</span><br><span class="line">	final LogicalSlot slot &#x3D; assignedResource;</span><br><span class="line"></span><br><span class="line">	if (slot !&#x3D; null) &#123;</span><br><span class="line">	&#x2F;&#x2F;TaskManagerGateway是用来跟taskManager进行通信的组件</span><br><span class="line">		final TaskManagerGateway taskManagerGateway &#x3D; slot.getTaskManagerGateway();</span><br><span class="line"></span><br><span class="line">		taskManagerGateway.triggerCheckpoint(attemptId, getVertex().getJobId(), checkpointId, timestamp, checkpointOptions);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		LOG.debug(&quot;The execution has no slot assigned. This indicates that the execution is &quot; +</span><br><span class="line">			&quot;no longer running.&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再往下跟就进入了<code>Task</code>类的范畴，我们将在下一小节进行解读。本小节主要讲了<code>CheckpointCoordinator</code>类是如何触发一次checkpoint，从其名字也可以看出来其功能：检查点协调器。</p>
<h4 id="5-2-2-Task层面checkpoint的准备工作"><a href="#5-2-2-Task层面checkpoint的准备工作" class="headerlink" title="5.2.2 Task层面checkpoint的准备工作"></a>5.2.2 Task层面checkpoint的准备工作</h4><p>先说Task类中的部分，该类创建了一个<code>CheckpointMetaData</code>的对象，并且生成了一个Runable匿名类用于执行checkpoint，然后以异步的方式触发了该Runable：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">public void triggerCheckpointBarrier(</span><br><span class="line">		final long checkpointID,</span><br><span class="line">		long checkpointTimestamp,</span><br><span class="line">		final CheckpointOptions checkpointOptions) &#123;</span><br><span class="line"></span><br><span class="line">           ......</span><br><span class="line"></span><br><span class="line">		Runnable runnable &#x3D; new Runnable() &#123;</span><br><span class="line">			@Override</span><br><span class="line">			public void run() &#123;</span><br><span class="line">				&#x2F;&#x2F; set safety net from the task&#39;s context for checkpointing thread</span><br><span class="line">				LOG.debug(&quot;Creating FileSystem stream leak safety net for &#123;&#125;&quot;, Thread.currentThread().getName());</span><br><span class="line">				FileSystemSafetyNet.setSafetyNetCloseableRegistryForThread(safetyNetCloseableRegistry);</span><br><span class="line"></span><br><span class="line">				try &#123;</span><br><span class="line">					boolean success &#x3D; invokable.triggerCheckpoint(checkpointMetaData, checkpointOptions);</span><br><span class="line">					if (!success) &#123;</span><br><span class="line">						checkpointResponder.declineCheckpoint(</span><br><span class="line">								getJobID(), getExecutionId(), checkpointID,</span><br><span class="line">								new CheckpointDeclineTaskNotReadyException(taskName));</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">				</span><br><span class="line">                   ......</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;;</span><br><span class="line">		executeAsyncCallRunnable(runnable, String.format(&quot;Checkpoint Trigger for %s (%s).&quot;, taskNameWithSubtask, executionId));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上面代码里的invokable事实上就是我们的StreamTask了。Task类实际上是将checkpoint委托给了更具体的类去执行，而StreamTask也将委托给更具体的类，直到业务代码。<br>StreamTask是这样实现的：</p>
<ul>
<li>如果task还在运行，那就可以进行checkpoint。方法是先向下游所有出口广播一个Barrier，然后触发本task的State保存。</li>
<li>如果task结束了，那我们就要通知下游取消本次checkpoint，方法是发送一个CancelCheckpointMarker，这是类似于Barrier的另一种消息。</li>
<li>注意，从这里开始，整个执行链路上开始出现Barrier，可以和前面讲Fault Tolerant原理的地方结合看一下。 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">private boolean performCheckpoint(</span><br><span class="line">		CheckpointMetaData checkpointMetaData,</span><br><span class="line">		CheckpointOptions checkpointOptions,</span><br><span class="line">		CheckpointMetrics checkpointMetrics) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (isRunning) &#123;</span><br><span class="line">		</span><br><span class="line">			operatorChain.broadcastCheckpointBarrier(</span><br><span class="line">					checkpointMetaData.getCheckpointId(),</span><br><span class="line">					checkpointMetaData.getTimestamp(),</span><br><span class="line">					checkpointOptions);</span><br><span class="line"></span><br><span class="line">			checkpointState(checkpointMetaData, checkpointOptions, checkpointMetrics);</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line"></span><br><span class="line">               ......</span><br><span class="line">               </span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
完成<code>broadcastCheckpointBarrier</code>方法后，在<code>checkpointState()</code>方法中，StreamTask还做了很多别的工作：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public void executeCheckpointing() throws Exception &#123;</span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line"></span><br><span class="line">	try &#123;</span><br><span class="line">	    &#x2F;&#x2F;这里，就是调用StreamOperator进行snapshotState的入口方法</span><br><span class="line">		for (StreamOperator&lt;?&gt; op : allOperators) &#123;</span><br><span class="line">			checkpointStreamOperator(op);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit</span><br><span class="line">		AsyncCheckpointRunnable asyncCheckpointRunnable &#x3D; new AsyncCheckpointRunnable(</span><br><span class="line">			owner,</span><br><span class="line">			operatorSnapshotsInProgress,</span><br><span class="line">			checkpointMetaData,</span><br><span class="line">			checkpointMetrics,</span><br><span class="line">			startAsyncPartNano);</span><br><span class="line"></span><br><span class="line">		owner.cancelables.registerCloseable(asyncCheckpointRunnable);</span><br><span class="line">		&#x2F;&#x2F;这里注册了一个Runnable，在执行完checkpoint之后向JobManager发出CompletedCheckPoint消息，这也是fault tolerant两阶段提交的一部分</span><br><span class="line">		owner.asyncOperationsThreadPool.submit(asyncCheckpointRunnable);</span><br><span class="line">		</span><br><span class="line">		......</span><br><span class="line">	</span><br><span class="line">	&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
说到checkpoint，我们印象里最直观的感受肯定是我们的一些做聚合的操作符的状态保存，比如sum的和以及count的值等等。这些内容就是StreamOperator部分将要触发保存的内容。可以看到，除了我们直观的这些操作符的状态保存外，flink的checkpoint做了大量的其他工作。</li>
</ul>
<p>接下来，我们就把目光转向操作符的checkpoint机制。</p>
<h4 id="5-2-3-操作符的状态保存及barrier传递"><a href="#5-2-3-操作符的状态保存及barrier传递" class="headerlink" title="5.2.3 操作符的状态保存及barrier传递"></a>5.2.3 操作符的状态保存及barrier传递</h4><p>第四章时，我们已经了解了StreamOperator的类关系，这里，我们就直接接着上一节的<code>checkpointStreamOperator(op)</code>方法往下讲。<br>顺便，前面也提到了，在进行checkpoint之前，operator初始化时，会执行一个<code>initializeState</code>方法，在该方法中，如果task是从失败中恢复的话，其保存的state也会被restore进来。</p>
<p>传递barrier是在进行本operator的statesnapshot之前完成的，我们先来看看其逻辑，其实和传递一条数据是类似的，就是生成一个<code>CheckpointBarrier</code>对象，然后向每个streamOutput写进去：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">   public void broadcastCheckpointBarrier(long id, long timestamp, CheckpointOptions checkpointOptions) throws IOException &#123;</span><br><span class="line">	try &#123;</span><br><span class="line">		CheckpointBarrier barrier &#x3D; new CheckpointBarrier(id, timestamp, checkpointOptions);</span><br><span class="line">		for (RecordWriterOutput&lt;?&gt; streamOutput : streamOutputs) &#123;</span><br><span class="line">			streamOutput.broadcastEvent(barrier);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	catch (InterruptedException e) &#123;</span><br><span class="line">		throw new IOException(&quot;Interrupted while broadcasting checkpoint barrier&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下游的operator接收到本barrier，就会触发其自身的checkpoint。</p>
<p>StreamTask在执行完broadcastCheckpointBarrier之后，<br>我们当前的wordcount程序里有两个operator chain，分别是：</p>
<ul>
<li>kafka source -&gt; flatmap</li>
<li>keyed aggregation -&gt; sink</li>
</ul>
<p>我们就按这个顺序来捋一下checkpoint的过程。</p>
<p>1.kafka source的checkpoint过程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">public final void snapshotState(FunctionSnapshotContext context) throws Exception &#123;</span><br><span class="line">	if (!running) &#123;</span><br><span class="line">		LOG.debug(&quot;snapshotState() called on closed source&quot;);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		unionOffsetStates.clear();</span><br><span class="line"></span><br><span class="line">		final AbstractFetcher&lt;?, ?&gt; fetcher &#x3D; this.kafkaFetcher;</span><br><span class="line">		if (fetcher &#x3D;&#x3D; null) &#123;</span><br><span class="line">			&#x2F;&#x2F; the fetcher has not yet been initialized, which means we need to return the</span><br><span class="line">			&#x2F;&#x2F; originally restored offsets or the assigned partitions</span><br><span class="line">			for (Map.Entry&lt;KafkaTopicPartition, Long&gt; subscribedPartition : subscribedPartitionsToStartOffsets.entrySet()) &#123;</span><br><span class="line">				unionOffsetStates.add(Tuple2.of(subscribedPartition.getKey(), subscribedPartition.getValue()));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">				&#x2F;&#x2F; the map cannot be asynchronously updated, because only one checkpoint call can happen</span><br><span class="line">				&#x2F;&#x2F; on this function at a time: either snapshotState() or notifyCheckpointComplete()</span><br><span class="line">				pendingOffsetsToCommit.put(context.getCheckpointId(), restoredState);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			HashMap&lt;KafkaTopicPartition, Long&gt; currentOffsets &#x3D; fetcher.snapshotCurrentState();</span><br><span class="line"></span><br><span class="line">			if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">				&#x2F;&#x2F; the map cannot be asynchronously updated, because only one checkpoint call can happen</span><br><span class="line">				&#x2F;&#x2F; on this function at a time: either snapshotState() or notifyCheckpointComplete()</span><br><span class="line">				pendingOffsetsToCommit.put(context.getCheckpointId(), currentOffsets);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			for (Map.Entry&lt;KafkaTopicPartition, Long&gt; kafkaTopicPartitionLongEntry : currentOffsets.entrySet()) &#123;</span><br><span class="line">				unionOffsetStates.add(</span><br><span class="line">						Tuple2.of(kafkaTopicPartitionLongEntry.getKey(), kafkaTopicPartitionLongEntry.getValue()));</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (offsetCommitMode &#x3D;&#x3D; OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">			&#x2F;&#x2F; truncate the map of pending offsets to commit, to prevent infinite growth</span><br><span class="line">			while (pendingOffsetsToCommit.size() &gt; MAX_NUM_PENDING_CHECKPOINTS) &#123;</span><br><span class="line">				pendingOffsetsToCommit.remove(0);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>kafka的snapshot逻辑就是记录一下当前消费的offsets，然后做成tuple（partitiion，offset）放进一个<code>StateBackend</code>里。StateBackend是flink抽象出来的一个用于保存状态的接口。</p>
<p>2.<strong>FlatMap算子的checkpoint过程</strong><br>没什么可说的，就是调用了snapshotState()方法而已。</p>
<p>3.<strong>本operator chain的state保存过程</strong><br>细心的同学应该注意到了，各个算子的snapshot方法只把自己的状态保存到了StateBackend里，没有写入的持久化操作。这部分操作被放到了<code>AbstractStreamOperator</code>中，由flink统一负责持久化。其实不需要看源码我们也能想出来，持久化无非就是把这些数据用一个流写到磁盘或者别的地方，接下来我们来看看是不是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">         &#x2F;&#x2F;还是AbstractStreamOperator.java的snapshotState方法</span><br><span class="line">if (null !&#x3D; operatorStateBackend) &#123;</span><br><span class="line">	snapshotInProgress.setOperatorStateManagedFuture(</span><br><span class="line">		operatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么这个operatorStateBackend是怎么保存状态的呢？</p>
<ul>
<li>首先把各个算子的state做了一份深拷贝；</li>
<li>然后以异步的方式执行了一个内部类的runnable，该内部类的run方法实现了一个模版方法，首先打开stream，然后写入数据，然后再关闭stream。</li>
</ul>
<p>我们来看看这个写入数据的方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">            public SnapshotResult&lt;OperatorStateHandle&gt; performOperation() throws Exception &#123;</span><br><span class="line">	long asyncStartTime &#x3D; System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line">	CheckpointStreamFactory.CheckpointStateOutputStream localOut &#x3D; this.out;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; get the registered operator state infos ...</span><br><span class="line">	List&lt;RegisteredOperatorBackendStateMetaInfo.Snapshot&lt;?&gt;&gt; operatorMetaInfoSnapshots &#x3D;</span><br><span class="line">		new ArrayList&lt;&gt;(registeredOperatorStatesDeepCopies.size());</span><br><span class="line"></span><br><span class="line">	for (Map.Entry&lt;String, PartitionableListState&lt;?&gt;&gt; entry : registeredOperatorStatesDeepCopies.entrySet()) &#123;</span><br><span class="line">		operatorMetaInfoSnapshots.add(entry.getValue().getStateMetaInfo().snapshot());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; ... write them all in the checkpoint stream ...</span><br><span class="line">	DataOutputView dov &#x3D; new DataOutputViewStreamWrapper(localOut);</span><br><span class="line"></span><br><span class="line">	OperatorBackendSerializationProxy backendSerializationProxy &#x3D;</span><br><span class="line">		new OperatorBackendSerializationProxy(operatorMetaInfoSnapshots, broadcastMetaInfoSnapshots);</span><br><span class="line"></span><br><span class="line">	backendSerializationProxy.write(dov);</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注释写的很清楚，我就不多说了。</p>
<p>4.<strong>后继operatorChain的checkpoint过程</strong><br>前面说到，在flink的流中，barrier流过时会触发checkpoint。在上面第1步中，上游节点已经发出了Barrier，所以在我们的keyed aggregation -&gt; sink 这个operatorchain中，我们将首先捕获这个barrier。</p>
<p>捕获barrier的过程其实就是处理input数据的过程，对应着<code>StreamInputProcessor.processInput()</code>方法，该方法我们在第四章已经讲过，这里我们简单回顾一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">         &#x2F;&#x2F;每个元素都会触发这一段逻辑，如果下一个数据是buffer，则从外围的while循环里进入处理用户数据的逻辑；这个方法里默默的处理了barrier的逻辑</span><br><span class="line">         final BufferOrEvent bufferOrEvent &#x3D; barrierHandler.getNextNonBlocked();</span><br><span class="line">if (bufferOrEvent !&#x3D; null) &#123;</span><br><span class="line">	if (bufferOrEvent.isBuffer()) &#123;</span><br><span class="line">		currentChannel &#x3D; bufferOrEvent.getChannelIndex();</span><br><span class="line">		currentRecordDeserializer &#x3D; recordDeserializers[currentChannel];</span><br><span class="line">		currentRecordDeserializer.setNextBuffer(bufferOrEvent.getBuffer());</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		&#x2F;&#x2F; Event received</span><br><span class="line">		final AbstractEvent event &#x3D; bufferOrEvent.getEvent();</span><br><span class="line">		if (event.getClass() !&#x3D; EndOfPartitionEvent.class) &#123;</span><br><span class="line">			throw new IOException(&quot;Unexpected event: &quot; + event);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>处理barrier的过程在这段代码里没有体现，因为被包含在了<code>getNextNonBlocked()</code>方法中，我们看下这个方法的核心逻辑：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">         &#x2F;&#x2F;BarrierBuffer.getNextNonBlocked方法</span><br><span class="line">else if (bufferOrEvent.getEvent().getClass() &#x3D;&#x3D; CheckpointBarrier.class) &#123;</span><br><span class="line">	if (!endOfStream) &#123;</span><br><span class="line">		&#x2F;&#x2F; process barriers only if there is a chance of the checkpoint completing</span><br><span class="line">		processBarrier((CheckpointBarrier) bufferOrEvent.getEvent(), bufferOrEvent.getChannelIndex());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">else if (bufferOrEvent.getEvent().getClass() &#x3D;&#x3D; CancelCheckpointMarker.class) &#123;</span><br><span class="line">	processCancellationBarrier((CancelCheckpointMarker) bufferOrEvent.getEvent());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先提一嘴，大家还记得之前的部分也提到过CheckpointMarker吧，这里正好也对上了。</p>
<p>处理barrier也是个麻烦事，大家回想一下5.1节提到的屏障的原理图，一个opertor必须收到从每个inputchannel发过来的同一序号的barrier之后才能发起本节点的checkpoint，如果有的channel的数据处理的快了，那该barrier后的数据还需要缓存起来，如果有的inputchannel被关闭了，那它就不会再发送barrier过来了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">private void processBarrier(CheckpointBarrier receivedBarrier, int channelIndex) throws Exception &#123;</span><br><span class="line">		final long barrierId &#x3D; receivedBarrier.getId();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; fast path for single channel cases</span><br><span class="line">		if (totalNumberOfInputChannels &#x3D;&#x3D; 1) &#123;</span><br><span class="line">			if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; new checkpoint</span><br><span class="line">				currentCheckpointId &#x3D; barrierId;</span><br><span class="line">				notifyCheckpoint(receivedBarrier);</span><br><span class="line">			&#125;</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; -- general code path for multiple input channels --</span><br><span class="line"></span><br><span class="line">		if (numBarriersReceived &gt; 0) &#123;</span><br><span class="line">			&#x2F;&#x2F; this is only true if some alignment is already progress and was not canceled</span><br><span class="line"></span><br><span class="line">			if (barrierId &#x3D;&#x3D; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; regular case</span><br><span class="line">				onBarrier(channelIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			else if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">				&#x2F;&#x2F; we did not complete the current checkpoint, another started before</span><br><span class="line">				LOG.warn(&quot;Received checkpoint barrier for checkpoint &#123;&#125; before completing current checkpoint &#123;&#125;. &quot; +</span><br><span class="line">						&quot;Skipping current checkpoint.&quot;, barrierId, currentCheckpointId);</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; let the task know we are not completing this</span><br><span class="line">				notifyAbort(currentCheckpointId, new CheckpointDeclineSubsumedException(barrierId));</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; abort the current checkpoint</span><br><span class="line">				releaseBlocksAndResetBarriers();</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; begin a the new checkpoint</span><br><span class="line">				beginNewAlignment(barrierId, channelIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			else &#123;</span><br><span class="line">				&#x2F;&#x2F; ignore trailing barrier from an earlier checkpoint (obsolete now)</span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		else if (barrierId &gt; currentCheckpointId) &#123;</span><br><span class="line">			&#x2F;&#x2F; first barrier of a new checkpoint</span><br><span class="line">			beginNewAlignment(barrierId, channelIndex);</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line">			&#x2F;&#x2F; either the current checkpoint was canceled (numBarriers &#x3D;&#x3D; 0) or</span><br><span class="line">			&#x2F;&#x2F; this barrier is from an old subsumed checkpoint</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; check if we have all barriers - since canceled checkpoints always have zero barriers</span><br><span class="line">		&#x2F;&#x2F; this can only happen on a non canceled checkpoint</span><br><span class="line">		if (numBarriersReceived + numClosedChannels &#x3D;&#x3D; totalNumberOfInputChannels) &#123;</span><br><span class="line">			&#x2F;&#x2F; actually trigger checkpoint</span><br><span class="line">			if (LOG.isDebugEnabled()) &#123;</span><br><span class="line">				LOG.debug(&quot;Received all barriers, triggering checkpoint &#123;&#125; at &#123;&#125;&quot;,</span><br><span class="line">						receivedBarrier.getId(), receivedBarrier.getTimestamp());</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			releaseBlocksAndResetBarriers();</span><br><span class="line">			notifyCheckpoint(receivedBarrier);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>总之，当收到全部的barrier之后，就会触发<code>notifyCheckpoint()</code>，该方法又会调用StreamTask的<code>triggerCheckpoint</code>，和之前的operator是一样的。</p>
<p>如果还有后续的operator的话，就是完全相同的循环，不再赘述。</p>
<p>5.<strong>报告完成checkpoint事件</strong><br>当一个operator保存完checkpoint数据后，就会启动一个异步对象<code>AsyncCheckpointRunnable</code>，用以报告该检查点已完成，其具体逻辑在reportCompletedSnapshotStates中。这个方法把任务又最终委托给了<code>RpcCheckpointResponder</code>这个类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">checkpointResponder.acknowledgeCheckpoint(</span><br><span class="line">			jobId,</span><br><span class="line">			executionAttemptID,</span><br><span class="line">			checkpointId,</span><br><span class="line">			checkpointMetrics,</span><br><span class="line">			acknowledgedState);</span><br></pre></td></tr></table></figure>
<p>从这个类也可以看出来，它的逻辑是通过rpc的方式远程调JobManager的相关方法完成报告事件，底层也是通过akka实现的。<br>那么，谁响应了这个rpc调用呢？是该任务的JobMaster。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;JobMaster.java</span><br><span class="line">public void acknowledgeCheckpoint(</span><br><span class="line">		final JobID jobID,</span><br><span class="line">		final ExecutionAttemptID executionAttemptID,</span><br><span class="line">		final long checkpointId,</span><br><span class="line">		final CheckpointMetrics checkpointMetrics,</span><br><span class="line">		final TaskStateSnapshot checkpointState) &#123;</span><br><span class="line"></span><br><span class="line">	final CheckpointCoordinator checkpointCoordinator &#x3D; executionGraph.getCheckpointCoordinator();</span><br><span class="line">	final AcknowledgeCheckpoint ackMessage &#x3D; new AcknowledgeCheckpoint(</span><br><span class="line">		jobID,</span><br><span class="line">		executionAttemptID,</span><br><span class="line">		checkpointId,</span><br><span class="line">		checkpointMetrics,</span><br><span class="line">		checkpointState);</span><br><span class="line"></span><br><span class="line">	if (checkpointCoordinator !&#x3D; null) &#123;</span><br><span class="line">		getRpcService().execute(() -&gt; &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				checkpointCoordinator.receiveAcknowledgeMessage(ackMessage);</span><br><span class="line">			&#125; catch (Throwable t) &#123;</span><br><span class="line">				log.warn(&quot;Error while processing checkpoint acknowledgement message&quot;);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		log.error(&quot;Received AcknowledgeCheckpoint message for job &#123;&#125; with no CheckpointCoordinator&quot;,</span><br><span class="line">				jobGraph.getJobID());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>JobMaster反手<del>就是一巴掌</del>就把任务又rpc给了<code>CheckpointCoordinator.receiveAcknowledgeMessage()</code>方法。</p>
<p>之前提到，coordinator在触发checkpoint时，生成了一个<code>PendingCheckpoint</code>，保存了所有operator的id。</p>
<p>当PendingCheckpoint收到一个operator的完成checkpoint的消息时，它就把这个operator从未完成checkpoint的节点集合移动到已完成的集合。当所有的operator都报告完成了checkpoint时，CheckpointCoordinator会触发<code>completePendingCheckpoint()</code>方法，该方法做了以下事情：</p>
<ul>
<li>把pendinCgCheckpoint转换为CompletedCheckpoint</li>
<li>把CompletedCheckpoint加入已完成的检查点集合，并从未完成检查点集合删除该检查点</li>
<li>再度向各个operator发出rpc，通知该检查点已完成</li>
</ul>
<p>本文里，收到这个远程调用的就是那两个operator chain，我们来看看其逻辑:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public void notifyCheckpointComplete(long checkpointId) throws Exception &#123;</span><br><span class="line">	synchronized (lock) &#123;</span><br><span class="line">		if (isRunning) &#123;</span><br><span class="line">			LOG.debug(&quot;Notification of complete checkpoint for task &#123;&#125;&quot;, getName());</span><br><span class="line"></span><br><span class="line">			for (StreamOperator&lt;?&gt; operator : operatorChain.getAllOperators()) &#123;</span><br><span class="line">				if (operator !&#x3D; null) &#123;</span><br><span class="line">					operator.notifyCheckpointComplete(checkpointId);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		else &#123;</span><br><span class="line">			LOG.debug(&quot;Ignoring notification of complete checkpoint for not-running task &#123;&#125;&quot;, getName());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再接下来无非就是层层通知对应的算子做出响应罢了。</p>
<p>至此，flink的两阶段提交的checkpoint逻辑全部完成。</p>
<h3 id="5-3-承载checkpoint数据的抽象：State-amp-StateBackend"><a href="#5-3-承载checkpoint数据的抽象：State-amp-StateBackend" class="headerlink" title="5.3 承载checkpoint数据的抽象：State &amp; StateBackend"></a>5.3 承载checkpoint数据的抽象：State &amp; StateBackend</h3><p>State是快照数据的载体，StateBackend是快照如何被保存的抽象。</p>
<p>State分为 KeyedState和OperatorState，从名字就可以看出来分别对应着keyedStream和其他的oeprator。从State由谁管理上，也可以区分为raw state和Managed state。Flink管理的就是Managed state，用户自己管理的就是raw state。Managed State又分为ValueState、ListState、ReducingState、AggregatingState、FoldingState、MapState这么几种，看名字知用途。</p>
<p>StateBackend目前提供了三个backend，MemoryStateBackend，FsStateBackend，RocksDBStateBackend，都是看名字知用途系列。</p>
<p>State接口、StateBackend接口及其实现都比较简单，代码就不贴了， 尤其State本质上就是一层容器封装。</p>
<p>贴个别人写的状态管理的文章吧：<a target="_blank" rel="noopener" href="https://yq.aliyun.com/articles/225623?spm=a2c4e.11153940.blogcont225624.12.7c797f6bZo3tiM">详解Flink中的状态管理</a></p>
<h2 id="6-数据流转——Flink的数据抽象及数据交换过程"><a href="#6-数据流转——Flink的数据抽象及数据交换过程" class="headerlink" title="6.数据流转——Flink的数据抽象及数据交换过程"></a>6.数据流转——Flink的数据抽象及数据交换过程</h2><p>本章打算讲一下flink底层是如何定义和在操作符之间传递数据的。</p>
<h3 id="6-1-flink的数据抽象"><a href="#6-1-flink的数据抽象" class="headerlink" title="6.1 flink的数据抽象"></a>6.1 flink的数据抽象</h3><h4 id="6-1-1-MemorySegment"><a href="#6-1-1-MemorySegment" class="headerlink" title="6.1.1 MemorySegment"></a>6.1.1 MemorySegment</h4><p>Flink作为一个高效的流框架，为了避免JVM的固有缺陷（java对象存储密度低，FGC影响吞吐和响应等），必然走上自主管理内存的道路。</p>
<p>这个<code>MemorySegment</code>就是Flink的内存抽象。默认情况下，一个MemorySegment可以被看做是一个32kb大的内存块的抽象。这块内存既可以是JVM里的一个byte[]，也可以是堆外内存（DirectByteBuffer）。</p>
<p>如果说byte[]数组和direct memory是最底层的存储，那么memorysegment就是在其上覆盖的一层统一抽象。它定义了一系列抽象方法，用于控制和底层内存的交互，如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public abstract class MemorySegment &#123;</span><br><span class="line"></span><br><span class="line">    public abstract byte get(int index);</span><br><span class="line">    </span><br><span class="line">    public abstract void put(int index, byte b);</span><br><span class="line">    </span><br><span class="line">    public int size() ;</span><br><span class="line">    </span><br><span class="line">    public abstract ByteBuffer wrap(int offset, int length);</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以看到，它在提供了诸多直接操作内存的方法外，还提供了一个<code>wrap()</code>方法，将自己包装成一个ByteBuffer，我们待会儿讲这个ByteBuffer。</p>
<p>Flink为MemorySegment提供了两个实现类：<code>HeapMemorySegment</code>和<code>HybridMemorySegment</code>。他们的区别在于前者只能分配堆内存，而后者能用来分配堆内和堆外内存。事实上，Flink框架里，只使用了后者。这是为什么呢？</p>
<p>如果HybridMemorySegment只能用于分配堆外内存的话，似乎更合常理。但是在JVM的世界中，如果一个方法是一个虚方法，那么每次调用时，JVM都要花时间去确定调用的到底是哪个子类实现的该虚方法（方法重写机制，不明白的去看JVM的invokeVirtual指令），也就意味着每次都要去翻方法表；而如果该方法虽然是个虚方法，但实际上整个JVM里只有一个实现（就是说只加载了一个子类进来），那么JVM会很聪明的把它去虚化处理，这样就不用每次调用方法时去找方法表了，能够大大提升性能。但是只分配堆内或者堆外内存不能满足我们的需要，所以就出现了HybridMemorySegment同时可以分配两种内存的设计。</p>
<p>我们可以看看HybridMemorySegment的构造代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">HybridMemorySegment(ByteBuffer buffer, Object owner) &#123;</span><br><span class="line">	super(checkBufferAndGetAddress(buffer), buffer.capacity(), owner);</span><br><span class="line">	this.offHeapBuffer &#x3D; buffer;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	HybridMemorySegment(byte[] buffer, Object owner) &#123;</span><br><span class="line">	super(buffer, owner);</span><br><span class="line">	this.offHeapBuffer &#x3D; null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，第一个构造函数的<code>checkBufferAndGetAddress()</code>方法能够得到direct buffer的内存地址，因此可以操作堆外内存。</p>
<h4 id="6-1-2-ByteBuffer与NetworkBufferPool"><a href="#6-1-2-ByteBuffer与NetworkBufferPool" class="headerlink" title="6.1.2 ByteBuffer与NetworkBufferPool"></a>6.1.2 ByteBuffer与NetworkBufferPool</h4><p>在<code>MemorySegment</code>这个抽象之上，Flink在数据从operator内的数据对象在向TaskManager上转移，预备被发给下个节点的过程中，使用的抽象或者说内存对象是<code>Buffer</code>。</p>
<p><strong>注意</strong>，这个Buffer是个flink接口，不是java.nio提供的那个Buffer抽象类。Flink在这一层面同时使用了这两个同名概念，用来存储对象，直接看代码时到处都是各种xxxBuffer很容易混淆：</p>
<ul>
<li>java提供的那个Buffer抽象类在这一层主要用于构建<code>HeapByteBuffer</code>，这个主要是当数据从jvm里的一个对象被序列化成字节数组时用的；</li>
<li>Flink的这个Buffer接口主要是一种flink层面用于传输数据和事件的统一抽象，其实现类是<code>NetworkBuffer</code>，是对<code>MemorySegment</code>的包装。Flink在各个TaskManager之间传递数据时，使用的是这一层的抽象。</li>
</ul>
<p>因为Buffer的底层是MemorySegment，这可能不是JVM所管理的，所以为了知道什么时候一个Buffer用完了可以回收，Flink引入了引用计数的概念，当确认这个buffer没有人引用，就可以回收这一片MemorySegment用于别的地方了（JVM的垃圾回收为啥不用引用计数？读者思考一下）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public abstract class AbstractReferenceCountedByteBuf extends AbstractByteBuf &#123;</span><br><span class="line"></span><br><span class="line">    private volatile int refCnt &#x3D; 1;</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了方便管理<code>NetworkBuffer</code>，Flink提供了<code>BufferPoolFactory</code>，并且提供了唯一实现<code>NetworkBufferPool</code>，这是个工厂模式的应用。</p>
<p>NetworkBufferPool在每个TaskManager上只有一个，负责所有子task的内存管理。其实例化时就会尝试获取所有可由它管理的内存（对于堆内存来说，直接获取所有内存并放入老年代，并令用户对象只在新生代存活，可以极大程度的减少Full GC），我们看看其构造方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public NetworkBufferPool(int numberOfSegmentsToAllocate, int segmentSize) &#123;</span><br><span class="line"></span><br><span class="line">		......</span><br><span class="line">		</span><br><span class="line">		try &#123;</span><br><span class="line">			this.availableMemorySegments &#x3D; new ArrayBlockingQueue&lt;&gt;(numberOfSegmentsToAllocate);</span><br><span class="line">		&#125;</span><br><span class="line">		catch (OutOfMemoryError err) &#123;</span><br><span class="line">			throw new OutOfMemoryError(&quot;Could not allocate buffer queue of length &quot;</span><br><span class="line">					+ numberOfSegmentsToAllocate + &quot; - &quot; + err.getMessage());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			for (int i &#x3D; 0; i &lt; numberOfSegmentsToAllocate; i++) &#123;</span><br><span class="line">				ByteBuffer memory &#x3D; ByteBuffer.allocateDirect(segmentSize);</span><br><span class="line">				availableMemorySegments.add(MemorySegmentFactory.wrapPooledOffHeapMemory(memory, null));</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">        </span><br><span class="line">		long allocatedMb &#x3D; (sizeInLong * availableMemorySegments.size()) &gt;&gt; 20;</span><br><span class="line"></span><br><span class="line">		LOG.info(&quot;Allocated &#123;&#125; MB for network buffer pool (number of memory segments: &#123;&#125;, bytes per segment: &#123;&#125;).&quot;,</span><br><span class="line">				allocatedMb, availableMemorySegments.size(), segmentSize);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>由于NetworkBufferPool只是个工厂，实际的内存池是<code>LocalBufferPool</code>。每个TaskManager都只有一个NetworkBufferPool工厂，但是上面运行的每个task都要有一个和其他task隔离的LocalBufferPool池，这从逻辑上很好理解。另外，NetworkBufferPool会计算自己所拥有的所有内存分片数，在分配新的内存池时对每个内存池应该占有的内存分片数重分配，步骤是：</p>
<ul>
<li>首先，从整个工厂管理的内存片中拿出所有的内存池所需要的最少Buffer数目总和</li>
<li>如果正好分配完，就结束</li>
<li>其次，把所有的剩下的没分配的内存片，按照每个LocalBufferPool内存池的剩余想要容量大小进行按比例分配</li>
<li>剩余想要容量大小是这么个东西：如果该内存池至少需要3个buffer，最大需要10个buffer，那么它的剩余想要容量就是7</li>
</ul>
<p>实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">   private void redistributeBuffers() throws IOException &#123;</span><br><span class="line">	assert Thread.holdsLock(factoryLock);</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; All buffers, which are not among the required ones</span><br><span class="line">	final int numAvailableMemorySegment &#x3D; totalNumberOfMemorySegments - numTotalRequiredBuffers;</span><br><span class="line"></span><br><span class="line">	if (numAvailableMemorySegment &#x3D;&#x3D; 0) &#123;</span><br><span class="line">		&#x2F;&#x2F; in this case, we need to redistribute buffers so that every pool gets its minimum</span><br><span class="line">		for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">			bufferPool.setNumBuffers(bufferPool.getNumberOfRequiredMemorySegments());</span><br><span class="line">		&#125;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	long totalCapacity &#x3D; 0; &#x2F;&#x2F; long to avoid int overflow</span><br><span class="line"></span><br><span class="line">	for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">		int excessMax &#x3D; bufferPool.getMaxNumberOfMemorySegments() -</span><br><span class="line">			bufferPool.getNumberOfRequiredMemorySegments();</span><br><span class="line">		totalCapacity +&#x3D; Math.min(numAvailableMemorySegment, excessMax);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; no capacity to receive additional buffers?</span><br><span class="line">	if (totalCapacity &#x3D;&#x3D; 0) &#123;</span><br><span class="line">		return; &#x2F;&#x2F; necessary to avoid div by zero when nothing to re-distribute</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	final int memorySegmentsToDistribute &#x3D; MathUtils.checkedDownCast(</span><br><span class="line">			Math.min(numAvailableMemorySegment, totalCapacity));</span><br><span class="line"></span><br><span class="line">	long totalPartsUsed &#x3D; 0; &#x2F;&#x2F; of totalCapacity</span><br><span class="line">	int numDistributedMemorySegment &#x3D; 0;</span><br><span class="line">	for (LocalBufferPool bufferPool : allBufferPools) &#123;</span><br><span class="line">		int excessMax &#x3D; bufferPool.getMaxNumberOfMemorySegments() -</span><br><span class="line">			bufferPool.getNumberOfRequiredMemorySegments();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; shortcut</span><br><span class="line">		if (excessMax &#x3D;&#x3D; 0) &#123;</span><br><span class="line">			continue;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		totalPartsUsed +&#x3D; Math.min(numAvailableMemorySegment, excessMax);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		final int mySize &#x3D; MathUtils.checkedDownCast(</span><br><span class="line">				memorySegmentsToDistribute * totalPartsUsed &#x2F; totalCapacity - numDistributedMemorySegment);</span><br><span class="line"></span><br><span class="line">		numDistributedMemorySegment +&#x3D; mySize;</span><br><span class="line">		bufferPool.setNumBuffers(bufferPool.getNumberOfRequiredMemorySegments() + mySize);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	assert (totalPartsUsed &#x3D;&#x3D; totalCapacity);</span><br><span class="line">	assert (numDistributedMemorySegment &#x3D;&#x3D; memorySegmentsToDistribute);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来说说这个<code>LocalBufferPool</code>内存池。<br>LocalBufferPool的逻辑想想无非是<del>增删改查</del>，值得说的是其fields：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;** 该内存池需要的最少内存片数目*&#x2F;</span><br><span class="line">private final int numberOfRequiredMemorySegments;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 当前已经获得的内存片中，还没有写入数据的空白内存片</span><br><span class="line"> *&#x2F;</span><br><span class="line">private final ArrayDeque&lt;MemorySegment&gt; availableMemorySegments &#x3D; new ArrayDeque&lt;MemorySegment&gt;();</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 注册的所有监控buffer可用性的监听器</span><br><span class="line"> *&#x2F;</span><br><span class="line">private final ArrayDeque&lt;BufferListener&gt; registeredListeners &#x3D; new ArrayDeque&lt;&gt;();</span><br><span class="line"></span><br><span class="line">&#x2F;** 能给内存池分配的最大分片数*&#x2F;</span><br><span class="line">private final int maxNumberOfMemorySegments;</span><br><span class="line"></span><br><span class="line">&#x2F;** 当前内存池大小 *&#x2F;</span><br><span class="line">private int currentPoolSize;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 所有经由NetworkBufferPool分配的，被本内存池引用到的（非直接获得的）分片数</span><br><span class="line"> *&#x2F;</span><br><span class="line">private int numberOfRequestedMemorySegments;</span><br></pre></td></tr></table></figure>
<p>承接NetworkBufferPool的重分配方法，我们来看看LocalBufferPool的<code>setNumBuffers()</code>方法，代码很短，逻辑也相当简单，就不展开说了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public void setNumBuffers(int numBuffers) throws IOException &#123;</span><br><span class="line">	synchronized (availableMemorySegments) &#123;</span><br><span class="line">		checkArgument(numBuffers &gt;&#x3D; numberOfRequiredMemorySegments,</span><br><span class="line">				&quot;Buffer pool needs at least %s buffers, but tried to set to %s&quot;,</span><br><span class="line">				numberOfRequiredMemorySegments, numBuffers);</span><br><span class="line"></span><br><span class="line">		if (numBuffers &gt; maxNumberOfMemorySegments) &#123;</span><br><span class="line">			currentPoolSize &#x3D; maxNumberOfMemorySegments;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			currentPoolSize &#x3D; numBuffers;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		returnExcessMemorySegments();</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; If there is a registered owner and we have still requested more buffers than our</span><br><span class="line">		&#x2F;&#x2F; size, trigger a recycle via the owner.</span><br><span class="line">		if (owner !&#x3D; null &amp;&amp; numberOfRequestedMemorySegments &gt; currentPoolSize) &#123;</span><br><span class="line">			owner.releaseMemory(numberOfRequestedMemorySegments - numBuffers);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="6-1-3-RecordWriter与Record"><a href="#6-1-3-RecordWriter与Record" class="headerlink" title="6.1.3 RecordWriter与Record"></a>6.1.3 RecordWriter与Record</h4><p>我们接着往高层抽象走，刚刚提到了最底层内存抽象是MemorySegment，用于数据传输的是Buffer，那么，承上启下对接从Java对象转为Buffer的中间对象是什么呢？是<code>StreamRecord</code>。</p>
<p>从<code>StreamRecord&lt;T&gt;</code>这个类名字就可以看出来，这个类就是个wrap，里面保存了原始的Java对象。另外，StreamRecord还保存了一个timestamp。</p>
<p>那么这个对象是怎么变成LocalBufferPool内存池里的一个大号字节数组的呢？借助了<code>StreamWriter</code>这个类。</p>
<p>我们直接来看把数据序列化交出去的方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">private void sendToTarget(T record, int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	RecordSerializer&lt;T&gt; serializer &#x3D; serializers[targetChannel];</span><br><span class="line"></span><br><span class="line">	SerializationResult result &#x3D; serializer.addRecord(record);</span><br><span class="line"></span><br><span class="line">	while (result.isFullBuffer()) &#123;</span><br><span class="line">		if (tryFinishCurrentBufferBuilder(targetChannel, serializer)) &#123;</span><br><span class="line">			&#x2F;&#x2F; If this was a full record, we are done. Not breaking</span><br><span class="line">			&#x2F;&#x2F; out of the loop at this point will lead to another</span><br><span class="line">			&#x2F;&#x2F; buffer request before breaking out (that would not be</span><br><span class="line">			&#x2F;&#x2F; a problem per se, but it can lead to stalls in the</span><br><span class="line">			&#x2F;&#x2F; pipeline).</span><br><span class="line">			if (result.isFullRecord()) &#123;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		BufferBuilder bufferBuilder &#x3D; requestNewBufferBuilder(targetChannel);</span><br><span class="line"></span><br><span class="line">		result &#x3D; serializer.continueWritingWithNextBufferBuilder(bufferBuilder);</span><br><span class="line">	&#125;</span><br><span class="line">	checkState(!serializer.hasSerializedData(), &quot;All data should be written at once&quot;);</span><br><span class="line">       </span><br><span class="line">       </span><br><span class="line">       </span><br><span class="line">	if (flushAlways) &#123;</span><br><span class="line">		targetPartition.flush(targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先说最后一行，如果配置为flushAlways，那么会立刻把元素发送出去，但是这样吞吐量会下降；Flink的默认设置其实也不是一个元素一个元素的发送，是单独起了一个线程，每隔固定时间flush一次所有channel，较真起来也算是mini batch了。</p>
<p>再说序列化那一句:<code>SerializationResult result = serializer.addRecord(record);</code>。在这行代码中，Flink把对象调用该对象所属的序列化器序列化为字节数组。</p>
<h3 id="6-2-数据流转过程"><a href="#6-2-数据流转过程" class="headerlink" title="6.2 数据流转过程"></a>6.2 数据流转过程</h3><p>上一节讲了各层数据的抽象，这一节讲讲数据在各个task之间exchange的过程。</p>
<h4 id="6-2-1-整体过程"><a href="#6-2-1-整体过程" class="headerlink" title="6.2.1 整体过程"></a>6.2.1 整体过程</h4><p>看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/e5m0ggy1t6z8tjgfn52cr31r/image_1cetavukjja42ce1261v5k57i9.png" alt="image_1cetavukjja42ce1261v5k57i9.png-821.8kB"></p>
<ol>
<li>第一步必然是准备一个ResultPartition；</li>
<li>通知JobMaster；</li>
<li>JobMaster通知下游节点；如果下游节点尚未部署，则部署之；</li>
<li>下游节点向上游请求数据</li>
<li>开始传输数据</li>
</ol>
<h4 id="6-2-2-数据跨task传递"><a href="#6-2-2-数据跨task传递" class="headerlink" title="6.2.2 数据跨task传递"></a>6.2.2 数据跨task传递</h4><p>本节讲一下算子之间具体的数据传输过程。也先上一张图：<br><img src="http://static.zybuluo.com/bethunebtj/d9pmni04fg8i11xotv4xqxh7/image_1cfmpba9v15anggtvsba2o1277m.png" alt="image_1cfmpba9v15anggtvsba2o1277m.png-357.5kB"><br>数据在task之间传递有如下几步：</p>
<ol>
<li>数据在本operator处理完后，交给<code>RecordWriter</code>。每条记录都要选择一个下游节点，所以要经过<code>ChannelSelector</code>。</li>
<li>每个channel都有一个serializer（我认为这应该是为了避免多线程写的麻烦），把这条Record序列化为ByteBuffer</li>
<li>接下来数据被写入ResultPartition下的各个subPartition里，此时该数据已经存入DirectBuffer（MemorySegment）</li>
<li>单独的线程控制数据的flush速度，一旦触发flush，则通过Netty的nio通道向对端写入</li>
<li>对端的netty client接收到数据，decode出来，把数据拷贝到buffer里，然后通知<code>InputChannel</code></li>
<li>有可用的数据时，下游算子从阻塞醒来，从InputChannel取出buffer，再解序列化成record，交给算子执行用户代码</li>
</ol>
<p>数据在不同机器的算子之间传递的步骤就是以上这些。</p>
<p>了解了步骤之后，再来看一下部分关键代码：<br>首先是把数据交给recordwriter。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;RecordWriterOutput.java</span><br><span class="line">@Override</span><br><span class="line">public void collect(StreamRecord&lt;OUT&gt; record) &#123;</span><br><span class="line">	if (this.outputTag !&#x3D; null) &#123;</span><br><span class="line">		&#x2F;&#x2F; we are only responsible for emitting to the main input</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">       &#x2F;&#x2F;这里可以看到把记录交给了recordwriter</span><br><span class="line">	pushToRecordWriter(record);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后recordwriter把数据发送到对应的通道。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;RecordWriter.java</span><br><span class="line">public void emit(T record) throws IOException, InterruptedException &#123;</span><br><span class="line">    &#x2F;&#x2F;channelselector登场了</span><br><span class="line">	for (int targetChannel : channelSelector.selectChannels(record, numChannels)) &#123;</span><br><span class="line">		sendToTarget(record, targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	private void sendToTarget(T record, int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	</span><br><span class="line">	&#x2F;&#x2F;选择序列化器并序列化数据</span><br><span class="line">	RecordSerializer&lt;T&gt; serializer &#x3D; serializers[targetChannel];</span><br><span class="line"></span><br><span class="line">	SerializationResult result &#x3D; serializer.addRecord(record);</span><br><span class="line"></span><br><span class="line">	while (result.isFullBuffer()) &#123;</span><br><span class="line">		if (tryFinishCurrentBufferBuilder(targetChannel, serializer)) &#123;</span><br><span class="line">			&#x2F;&#x2F; If this was a full record, we are done. Not breaking</span><br><span class="line">			&#x2F;&#x2F; out of the loop at this point will lead to another</span><br><span class="line">			&#x2F;&#x2F; buffer request before breaking out (that would not be</span><br><span class="line">			&#x2F;&#x2F; a problem per se, but it can lead to stalls in the</span><br><span class="line">			&#x2F;&#x2F; pipeline).</span><br><span class="line">			if (result.isFullRecord()) &#123;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		BufferBuilder bufferBuilder &#x3D; requestNewBufferBuilder(targetChannel);</span><br><span class="line"></span><br><span class="line">           &#x2F;&#x2F;写入channel</span><br><span class="line">		result &#x3D; serializer.continueWritingWithNextBufferBuilder(bufferBuilder);</span><br><span class="line">	&#125;</span><br><span class="line">	checkState(!serializer.hasSerializedData(), &quot;All data should be written at once&quot;);</span><br><span class="line"></span><br><span class="line">	if (flushAlways) &#123;</span><br><span class="line">		targetPartition.flush(targetChannel);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来是把数据推给底层设施（netty）的过程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;ResultPartition.java</span><br><span class="line">@Override</span><br><span class="line">public void flushAll() &#123;</span><br><span class="line">	for (ResultSubpartition subpartition : subpartitions) &#123;</span><br><span class="line">		subpartition.flush();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;PartitionRequestQueue.java</span><br><span class="line">	void notifyReaderNonEmpty(final NetworkSequenceViewReader reader) &#123;</span><br><span class="line">	&#x2F;&#x2F;这里交给了netty server线程去推</span><br><span class="line">	ctx.executor().execute(new Runnable() &#123;</span><br><span class="line">		@Override</span><br><span class="line">		public void run() &#123;</span><br><span class="line">			ctx.pipeline().fireUserEventTriggered(reader);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>netty相关的部分：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;AbstractChannelHandlerContext.java</span><br><span class="line">public ChannelHandlerContext fireUserEventTriggered(final Object event) &#123;</span><br><span class="line">    if (event &#x3D;&#x3D; null) &#123;</span><br><span class="line">        throw new NullPointerException(&quot;event&quot;);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        final AbstractChannelHandlerContext next &#x3D; this.findContextInbound();</span><br><span class="line">        EventExecutor executor &#x3D; next.executor();</span><br><span class="line">        if (executor.inEventLoop()) &#123;</span><br><span class="line">            next.invokeUserEventTriggered(event);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            executor.execute(new OneTimeTask() &#123;</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    next.invokeUserEventTriggered(event);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return this;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后真实的写入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;PartittionRequesetQueue.java</span><br><span class="line">private void enqueueAvailableReader(final NetworkSequenceViewReader reader) throws Exception &#123;</span><br><span class="line">	if (reader.isRegisteredAsAvailable() || !reader.isAvailable()) &#123;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F; Queue an available reader for consumption. If the queue is empty,</span><br><span class="line">	&#x2F;&#x2F; we try trigger the actual write. Otherwise this will be handled by</span><br><span class="line">	&#x2F;&#x2F; the writeAndFlushNextMessageIfPossible calls.</span><br><span class="line">	boolean triggerWrite &#x3D; availableReaders.isEmpty();</span><br><span class="line">	registerAvailableReader(reader);</span><br><span class="line"></span><br><span class="line">	if (triggerWrite) &#123;</span><br><span class="line">		writeAndFlushNextMessageIfPossible(ctx.channel());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void writeAndFlushNextMessageIfPossible(final Channel channel) throws IOException &#123;</span><br><span class="line">	</span><br><span class="line">       ......</span><br><span class="line"></span><br><span class="line">			next &#x3D; reader.getNextBuffer();</span><br><span class="line">			if (next &#x3D;&#x3D; null) &#123;</span><br><span class="line">				if (!reader.isReleased()) &#123;</span><br><span class="line">					continue;</span><br><span class="line">				&#125;</span><br><span class="line">				markAsReleased(reader.getReceiverId());</span><br><span class="line"></span><br><span class="line">				Throwable cause &#x3D; reader.getFailureCause();</span><br><span class="line">				if (cause !&#x3D; null) &#123;</span><br><span class="line">					ErrorResponse msg &#x3D; new ErrorResponse(</span><br><span class="line">						new ProducerFailedException(cause),</span><br><span class="line">						reader.getReceiverId());</span><br><span class="line"></span><br><span class="line">					ctx.writeAndFlush(msg);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				&#x2F;&#x2F; This channel was now removed from the available reader queue.</span><br><span class="line">				&#x2F;&#x2F; We re-add it into the queue if it is still available</span><br><span class="line">				if (next.moreAvailable()) &#123;</span><br><span class="line">					registerAvailableReader(reader);</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				BufferResponse msg &#x3D; new BufferResponse(</span><br><span class="line">					next.buffer(),</span><br><span class="line">					reader.getSequenceNumber(),</span><br><span class="line">					reader.getReceiverId(),</span><br><span class="line">					next.buffersInBacklog());</span><br><span class="line"></span><br><span class="line">				if (isEndOfPartitionEvent(next.buffer())) &#123;</span><br><span class="line">					reader.notifySubpartitionConsumed();</span><br><span class="line">					reader.releaseAllResources();</span><br><span class="line"></span><br><span class="line">					markAsReleased(reader.getReceiverId());</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F; Write and flush and wait until this is done before</span><br><span class="line">				&#x2F;&#x2F; trying to continue with the next buffer.</span><br><span class="line">				channel.writeAndFlush(msg).addListener(writeListener);</span><br><span class="line"></span><br><span class="line">				return;</span><br><span class="line">			&#125;</span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面这段代码里第二个方法中调用的<code>writeAndFlush(msg)</code>就是真正往netty的nio通道里写入的地方了。在这里，写入的是一个RemoteInputChannel，对应的就是下游节点的InputGate的channels。</p>
<p>有写就有读，nio通道的另一端需要读入buffer，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;CreditBasedPartitionRequestClientHandler.java</span><br><span class="line">private void decodeMsg(Object msg) throws Throwable &#123;</span><br><span class="line">	final Class&lt;?&gt; msgClazz &#x3D; msg.getClass();</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; ---- Buffer --------------------------------------------------------</span><br><span class="line">	if (msgClazz &#x3D;&#x3D; NettyMessage.BufferResponse.class) &#123;</span><br><span class="line">		NettyMessage.BufferResponse bufferOrEvent &#x3D; (NettyMessage.BufferResponse) msg;</span><br><span class="line"></span><br><span class="line">		RemoteInputChannel inputChannel &#x3D; inputChannels.get(bufferOrEvent.receiverId);</span><br><span class="line">		if (inputChannel &#x3D;&#x3D; null) &#123;</span><br><span class="line">			bufferOrEvent.releaseBuffer();</span><br><span class="line"></span><br><span class="line">			cancelRequestFor(bufferOrEvent.receiverId);</span><br><span class="line"></span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		decodeBufferOrEvent(inputChannel, bufferOrEvent);</span><br><span class="line"></span><br><span class="line">	&#125; </span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>插一句，Flink其实做阻塞和获取数据的方式非常自然，利用了生产者和消费者模型，当获取不到数据时，消费者自然阻塞；当数据被加入队列，消费者被notify。Flink的背压机制也是借此实现。</p>
<p>然后在这里又反序列化成<code>StreamRecord</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;&#x2F;StreamElementSerializer.java</span><br><span class="line">public StreamElement deserialize(DataInputView source) throws IOException &#123;</span><br><span class="line">	int tag &#x3D; source.readByte();</span><br><span class="line">	if (tag &#x3D;&#x3D; TAG_REC_WITH_TIMESTAMP) &#123;</span><br><span class="line">		long timestamp &#x3D; source.readLong();</span><br><span class="line">		return new StreamRecord&lt;T&gt;(typeSerializer.deserialize(source), timestamp);</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_REC_WITHOUT_TIMESTAMP) &#123;</span><br><span class="line">		return new StreamRecord&lt;T&gt;(typeSerializer.deserialize(source));</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_WATERMARK) &#123;</span><br><span class="line">		return new Watermark(source.readLong());</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_STREAM_STATUS) &#123;</span><br><span class="line">		return new StreamStatus(source.readInt());</span><br><span class="line">	&#125;</span><br><span class="line">	else if (tag &#x3D;&#x3D; TAG_LATENCY_MARKER) &#123;</span><br><span class="line">		return new LatencyMarker(source.readLong(), new OperatorID(source.readLong(), source.readLong()), source.readInt());</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		throw new IOException(&quot;Corrupt stream, found tag: &quot; + tag);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后再次在<code>StreamInputProcessor.processInput()</code>循环中得到处理。</p>
<p>至此，数据在跨jvm的节点之间的流转过程就讲完了。</p>
<h3 id="6-3-Credit漫谈"><a href="#6-3-Credit漫谈" class="headerlink" title="6.3 Credit漫谈"></a>6.3 Credit漫谈</h3><p>在看上一部分的代码时，有一个小细节不知道读者有没有注意到，我们的数据发送端的代码叫做<code>PartittionRequesetQueue.java</code>，而我们的接收端却起了一个完全不相干的名字：<code>CreditBasedPartitionRequestClientHandler.java</code>。为什么前面加了CreditBased的前缀呢？</p>
<h4 id="6-3-1-背压问题"><a href="#6-3-1-背压问题" class="headerlink" title="6.3.1 背压问题"></a>6.3.1 背压问题</h4><p>在流模型中，我们期待数据是像水流一样平滑的流过我们的引擎，但现实生活不会这么美好。数据的上游可能因为各种原因数据量暴增，远远超出了下游的瞬时处理能力（回忆一下98年大洪水），导致系统崩溃。<br>那么框架应该怎么应对呢？和人类处理自然灾害的方式类似，我们修建了三峡大坝，当洪水来临时把大量的水囤积在大坝里；对于Flink来说，就是在数据的接收端和发送端放置了缓存池，用以缓冲数据，并且设置闸门阻止数据向下流。</p>
<p>那么Flink又是如何处理背压的呢？答案也是靠这些缓冲池。<br><img src="http://static.zybuluo.com/bethunebtj/1r40q9nbeuxh4j0omiic5tob/image_1cfksrl5cd4m1lbqqqgvc811349.png" alt="image_1cfksrl5cd4m1lbqqqgvc811349.png-43.1kB"><br>这张图说明了Flink在生产和消费数据时的大致情况。<code>ResultPartition</code>和<code>InputGate</code>在输出和输入数据时，都要向<code>NetworkBufferPool</code>申请一块<code>MemorySegment</code>作为缓存池。<br>接下来的情况和生产者消费者很类似。当数据发送太多，下游处理不过来了，那么首先InputChannel会被填满，然后是InputChannel能申请到的内存达到最大，于是下游停止读取数据，上游负责发送数据的nettyServer会得到响应，停止从ResultSubPartition读取缓存，那么ResultPartition很快也将存满数据不能被消费，从而生产数据的逻辑被阻塞在获取新buffer上，非常自然地形成背压的效果。</p>
<p>Flink自己做了个试验用以说明这个机制的效果：<br><img src="http://static.zybuluo.com/bethunebtj/xxqpmehf1w4un8leyc9itr9y/image_1cfkta54rkdd1od4aau1e3n7nhm.png" alt="image_1cfkta54rkdd1od4aau1e3n7nhm.png-240.6kB"><br>我们首先设置生产者的发送速度为60%，然后下游的算子以同样的速度处理数据。然后我们将下游算子的处理速度降低到30%，可以看到上游的生产者的数据产生曲线几乎与消费者同步下滑。而后当我们解除限速，整个流的速度立刻提高到了100%。</p>
<h4 id="6-3-2-使用Credit实现ATM网络流控"><a href="#6-3-2-使用Credit实现ATM网络流控" class="headerlink" title="6.3.2 使用Credit实现ATM网络流控"></a>6.3.2 使用Credit实现ATM网络流控</h4><p>上文已经提到，对于流量控制，一个朴素的思路就是在<del>长江上建三峡</del>链路上建立一个拦截的dam，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/1wc3o2qo6ozsyxqebnn2xw0j/image_1cfku114lf7hpqf3lmcl0116c13.png" alt="image_1cfku114lf7hpqf3lmcl0116c13.png-22.7kB"><br>基于Credit的流控就是这样一种建立在信用（消费数据的能力)上的，面向每个虚链路（而非端到端的）流模型，如下图所示：<br><img src="http://static.zybuluo.com/bethunebtj/on4kd4bzvoozbo6yk6n2but6/image_1cfku4g4g174d7gb5ecbfcib71g.png" alt="image_1cfku4g4g174d7gb5ecbfcib71g.png-22.5kB"><br>首先，下游会向上游发送一条credit message，用以通知其目前的信用（可联想信用卡的可用额度），然后上游会根据这个信用消息来决定向下游发送多少数据。当上游把数据发送给下游时，它就从下游的信用卡上划走相应的额度（credit balance）：<br><img src="http://static.zybuluo.com/bethunebtj/i8t1qvlib162x1i6lm0qruju/image_1cfkug5sm1v4l15pbgj4jntc7q1t.png" alt="image_1cfkug5sm1v4l15pbgj4jntc7q1t.png-12.9kB"><br>下游总共获得的credit数目是Buf_Alloc，已经消费的数据是Fwd_Cnt，上游发送出来的数据是Tx_Cnt，那么剩下的那部分就是Crd_Bal:<br>Crd_Bal = Buf_Alloc - ( Tx_Cnt - Fwd_Cnt )<br>上面这个式子应该很好理解。</p>
<p>可以看到，Credit Based Flow Control的关键是buffer分配。这种分配可以在数据的发送端完成，也可以在接收端完成。对于下游可能有多个上游节点的情况（比如Flink），使用接收端的credit分配更加合理：<br><img src="http://static.zybuluo.com/bethunebtj/o09mav0lfnk7iqar98iphr7o/image_1cfkvpmlh1gl31ef41cvh1c903a19.png" alt="image_1cfkvpmlh1gl31ef41cvh1c903a19.png-13.1kB"><br>上图中，接收者可以观察到每个上游连接的带宽情况，而上游的节点Snd1却不可能轻易知道发往同一个下游节点的其他Snd2的带宽情况，从而如果在上游控制流量将会很困难，而在下游控制流量将会很方便。</p>
<p>因此，这就是为何Flink在接收端有一个基于Credit的Client，而不是在发送端有一个CreditServer的原因。</p>
<p>最后，再讲一下Credit的面向虚链路的流设计和端到端的流设计的区别：<br><img src="http://static.zybuluo.com/bethunebtj/1mm2eqnuop9rcccap915qrzx/image_1cfl05d2f1ub879c1lc5qsq14n9m.png" alt="image_1cfl05d2f1ub879c1lc5qsq14n9m.png-13.4kB"><br>如上图所示，a是面向连接的流设计，b是端到端的流设计。其中，a的设计使得当下游节点3因某些情况必须缓存数据暂缓处理时，每个上游节点（1和2）都可以利用其缓存保存数据；而端到端的设计b里，只有节点3的缓存才可以用于保存数据（读者可以从如何实现上想想为什么）。</p>
<p>对流控制感兴趣的读者，可以看这篇文章：<a target="_blank" rel="noopener" href="https://www.nap.edu/read/5769/chapter/1">Traffic Management For High-Speed Networks</a>。</p>
<h2 id="7-其他核心概念"><a href="#7-其他核心概念" class="headerlink" title="7.其他核心概念"></a>7.其他核心概念</h2><p>截至第六章，和执行过程相关的部分就全部讲完，告一段落了。第七章主要讲一点杂七杂八的内容，有时间就不定期更新。</p>
<h3 id="7-1-EventTime时间模型"><a href="#7-1-EventTime时间模型" class="headerlink" title="7.1 EventTime时间模型"></a>7.1 EventTime时间模型</h3><p>flink有三种时间模型：ProcessingTime，EventTime和IngestionTime。<br>关于时间模型看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/kcp52h1se5xzocfqcigcv9oh/image_1cdbotdcmoe11q961st5lbn1j4n9.png" alt="image_1cdbotdcmoe11q961st5lbn1j4n9.png-38.4kB"><br>从这张图里可以很清楚的看到三种Time模型的区别。</p>
<ul>
<li>EventTime是数据被生产出来的时间，可以是比如传感器发出信号的时间等（此时数据还没有被传输给flink）。</li>
<li>IngestionTime是数据进入flink的时间，也就是从Source进入flink流的时间（此时数据刚刚被传给flink）</li>
<li>ProcessingTime是针对当前算子的系统时间，是指该数据已经进入某个operator时，operator所在系统的当前时间</li>
</ul>
<p>例如，我在写这段话的时间是2018年5月13日03点47分，但是我引用的这张EventTime的图片，是2015年画出来的，那么这张图的EventTime是2015年，而ProcessingTime是现在。<br>Flink官网对于时间戳的解释非常详细：<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-master/dev/event_time.html">点我</a><br>Flink对于EventTime模型的实现，依赖的是一种叫做<code>watermark</code>的对象。watermark是携带有时间戳的一个对象，会按照程序的要求被插入到数据流中，用以标志某个事件在该时间发生了。<br>我再做一点简短的说明，还是以官网的图为例：<br><img src="http://static.zybuluo.com/bethunebtj/f4k8110qo8arjey5zbp75xz3/image_1cdbt8v5jl2ujn91uu1joh1p4gm.png" alt="image_1cdbt8v5jl2ujn91uu1joh1p4gm.png-11.3kB"><br>对于有序到来的数据，假设我们在timestamp为11的元素后加入一个watermark，时间记录为11，则下个元素收到该watermark时，认为所有早于11的元素均已到达。这是非常理想的情况。<br><img src="http://static.zybuluo.com/bethunebtj/3aqwmrc5hg054b09z47lwsvp/image_1cdbtcc5c1a6i1tuaadb1rd5136913.png" alt="image_1cdbtcc5c1a6i1tuaadb1rd5136913.png-11.6kB"><br>而在现实生活中，经常会遇到乱序的数据。这时，我们虽然在timestamp为7的元素后就收到了11，但是我们一直等到了收到元素12之后，才插入了watermark为11的元素。与上面的图相比，如果我们仍然在11后就插入11的watermark，那么元素9就会被丢弃，造成数据丢失。而我们在12之后插入watermark11，就保证了9仍然会被下一个operator处理。当然，我们不可能无限制的永远等待迟到元素，所以要在哪个元素后插入11需要根据实际场景权衡。</p>
<p>对于来自多个数据源的watermark，可以看这张图：<br><img src="http://static.zybuluo.com/bethunebtj/pu1cr48mq9340g5embaig9b5/image_1cdbufp4a1opmsit5n61mial4520.png" alt="image_1cdbufp4a1opmsit5n61mial4520.png-72kB"><br>可以看到，当一个operator收到多个watermark时，它遵循最小原则（或者说最早），即算子的当前watermark是流经该算子的最小watermark，以容许来自不同的source的乱序数据到来。<br>关于事件时间模型，更多内容可以参考<a target="_blank" rel="noopener" href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101">Stream 101</a> 和谷歌的这篇论文：<a target="_blank" rel="noopener" href="https://research.google.com/pubs/archive/43864.pdf">Dataflow Model paper</a></p>
<h3 id="7-2-FLIP-6-部署及处理模型演进"><a href="#7-2-FLIP-6-部署及处理模型演进" class="headerlink" title="7.2 FLIP-6 部署及处理模型演进"></a>7.2 FLIP-6 部署及处理模型演进</h3><p>就在老白写这篇blog的时候，Flink发布了其1.5 RELEASE版本，号称实现了其部署及处理模型（也就是FLIP-6)，所以打算简略地说一下FLIP-6的主要内容。</p>
<h4 id="7-2-1-现有模型不足"><a href="#7-2-1-现有模型不足" class="headerlink" title="7.2.1 现有模型不足"></a>7.2.1 现有模型不足</h4><p>1.5之前的Flink模型有很多不足，包括：</p>
<ul>
<li>只能静态分配计算资源</li>
<li>在YARN上所有的资源分配都是一碗水端平的</li>
<li>与Docker/k8s的集成非常之蠢，颇有脱裤子放屁的神韵</li>
<li>JobManager没有任务调度逻辑</li>
<li>任务在YARN上执行结束后web dashboard就不可用</li>
<li>集群的session模式和per job模式混淆难以理解</li>
</ul>
<p>就我个人而言，我觉得Flink有一个这里完全没提到的不足才是最应该修改的：针对任务的完全的资源隔离。尤其是如果用Standalone集群，一个用户的task跑挂了TaskManager，然后拖垮了整个集群的情况简直不要太多。</p>
<h4 id="7-2-2-核心变更"><a href="#7-2-2-核心变更" class="headerlink" title="7.2.2 核心变更"></a>7.2.2 核心变更</h4><p><strong>Single Job JobManager</strong><br>最重要的变更是一个JobManager只处理一个job。当我们生成JobGraph时就顺便起一个JobManager，这显然更加自然。</p>
<p><strong>ResourceManager</strong><br>其职责包括获取新的TM和slot，通知失败，释放资源以及缓存TM以用于重用等。重要的是，这个组件要能做到挂掉时不要搞垮正在运行的好好的任务。其职责和与JobManager、TaskManager的交互图如下：<br><img src="http://static.zybuluo.com/bethunebtj/pzuvevivascmk2xky450ll87/image_1cfl9453k1gld4acr1m13j3195sg.png" alt="image_1cfl9453k1gld4acr1m13j3195sg.png-23.9kB"></p>
<p><strong>TaskManager</strong><br>TM要与上面的两个组件交互。与JobManager交互时，要能提供slot，要能与所有给出slot的JM交互。丢失与JM的连接时要能试图把本TM上的slot的情况通告给新JM，如果这一步失败，就要能重新分配slot。<br>与ResourceManager交互时，要通知RM自己的资源和当前的Job分配情况，能按照RM的要求分配资源或者关闭自身。</p>
<p><strong>JobManager Slot Pool</strong><br>这个pool要持有所有分配给当前job的slot资源，并且能在RM挂掉的情况下管理当前已经持有的slot。</p>
<p><strong>Dispatcher</strong><br>需要一个Job的分发器的主要原因是在有的集群环境下我们可能需要一个统一的提交和监控点，以及替代之前的Standalone模式下的JobManager。将来对分发器的期望可能包括权限控制等。<br><img src="http://static.zybuluo.com/bethunebtj/on7x5expzpyvtyqvkjm1si9e/image_1cfl9ju2617bh1s191mar1jsp12vot.png" alt="image_1cfl9ju2617bh1s191mar1jsp12vot.png-31.4kB"></p>
<h4 id="7-2-3-Cluster-Manager的架构"><a href="#7-2-3-Cluster-Manager的架构" class="headerlink" title="7.2.3 Cluster Manager的架构"></a>7.2.3 Cluster Manager的架构</h4><p><strong>YARN</strong><br>新的基于YARN的架构主要包括不再需要先在容器里启动集群，然后提交任务；用户代码不再使用动态ClassLoader加载；不用的资源可以释放；可以按需分配不同大小的容器等。其执行过程如下：<br>无Dispatcher时<br><img src="http://static.zybuluo.com/bethunebtj/w3z5qz98tq5q4jtndka8kdhp/image_1cfla0n7u1lg21n3o36uu0c1o5h1a.png" alt="image_1cfla0n7u1lg21n3o36uu0c1o5h1a.png-46.2kB"><br>有Dispatcher时<br><img src="http://static.zybuluo.com/bethunebtj/ukhd6f3480du2nsx2wnl56g3/image_1cfla15os15i3qcsu6c4p4clk1n.png" alt="image_1cfla15os15i3qcsu6c4p4clk1n.png-50.7kB"></p>
<p><strong>Mesos</strong><br>与基于YARN的模式很像，但是只有带Dispatcher模式，因为只有这样才能在Mesos集群里跑其RM。<br><img src="http://static.zybuluo.com/bethunebtj/k0b95bqzs9crsj2jwk8oy33n/image_1cfla4tka101n18bf1mno4npu9s24.png" alt="image_1cfla4tka101n18bf1mno4npu9s24.png-49.2kB"><br>Mesos的Fault Tolerance是类似这样的：<br><img src="http://static.zybuluo.com/bethunebtj/app8m86al53shk2a83w14x0r/image_1cfla6eka1ph71mu1pll1q0mgqq2h.png" alt="image_1cfla6eka1ph71mu1pll1q0mgqq2h.png-12.1kB"><br>必须用类似Marathon之类的技术保证Dispatcher的HA。</p>
<p><strong>Standalone</strong><br>其实没啥可说的，把以前的JobManager的职责换成现在的Dispatcher就行了。<br><img src="http://static.zybuluo.com/bethunebtj/nn4vbn25yojf3vq80yffr20v/image_1cflaaim2ih2v54umsmq01lqc2u.png" alt="image_1cflaaim2ih2v54umsmq01lqc2u.png-36.8kB"><br>将来可能会实现一个类似于轻量级Yarn的模式。</p>
<p><strong>Docker/k8s</strong><br>用户定义好容器，至少有一个是job specific的（不然怎么启动任务）；还有用于启动TM的，可以不是job specific的。启动过程如下<br><img src="http://static.zybuluo.com/bethunebtj/vcow51koxy17wd3qxj60y4lj/image_1cflafs2o1trgicjmdbndn1bdq3b.png" alt="image_1cflafs2o1trgicjmdbndn1bdq3b.png-24.2kB"></p>
<h4 id="7-2-4-组件设计及细节"><a href="#7-2-4-组件设计及细节" class="headerlink" title="7.2.4 组件设计及细节"></a>7.2.4 组件设计及细节</h4><p><strong>分配slot相关细节</strong><br>从新的TM取slot过程：<br><img src="http://static.zybuluo.com/bethunebtj/r1anoecf2er16nuh3h9r9jb8/image_1cflakoadvjm8pf6nt1k331qj33o.png" alt="image_1cflakoadvjm8pf6nt1k331qj33o.png-77.2kB"></p>
<p>从Cached TM取slot过程：<br><img src="http://static.zybuluo.com/bethunebtj/2uyr1ynvj8ieqi8rth8h8bub/image_1cflambu91ufi5fl1cg9gimdff45.png" alt="image_1cflambu91ufi5fl1cg9gimdff45.png-63.4kB"></p>
<p><strong>失败处理</strong></p>
<ol>
<li><p>TM失败<br>TM失败时，RM要能检测到失败，更新自己的状态，发送消息给JM，重启一份TM；JM要能检测到失败，从状态移除失效slot，标记该TM的task为失败，并在没有足够slot继续任务时调整规模；TM自身则要能从Checkpoint恢复</p>
</li>
<li><p>RM失败<br>此时TM要能检测到失败，并准备向新的RM注册自身，并且向新的RM传递自身的资源情况；JM要能检测到失败并且等待新的RM可用，重新请求需要的资源；丢失的数据要能从Container、TM等处恢复。</p>
</li>
<li><p>JM失败<br>TM释放所有task，向新JM注册资源，并且如果不成功，就向RM报告这些资源可用于重分配；RM坐等；JM丢失的数据从持久化存储中获得，已完成的checkpoints从HA恢复，从最近的checkpoint重启task，并申请资源。</p>
</li>
<li><p>JM &amp; RM 失败<br>TM将在一段时间内试图把资源交给新上任的JM，如果失败，则把资源交给新的RM</p>
</li>
<li><p>TM &amp; RM失败<br>JM如果正在申请资源，则要等到新的RM启动后才能获得；JM可能需要调整其规模，因为损失了TM的slot。</p>
</li>
</ol>
<h2 id="8-后记"><a href="#8-后记" class="headerlink" title="8.后记"></a>8.后记</h2><p>Flink是当前流处理领域的优秀框架，其设计思想和代码实现都蕴含着许多人的智慧结晶。这篇解读花了很多时间，篇幅也写了很长，也仍然不能能覆盖Flink的方方面面，也肯定有很多错误之处，欢迎大家批评指正！Flink生态里中文资料确实不多，对Flink源码有兴趣的读者，可以参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/yanghua_kobe/article/category/6170573/4">VinoYang的专栏</a>，继续学习之旅。</p>
<p>本文至此结束。</p>
<p>最后，欢迎关注我的微信公众号，一起交流技术，或者职业生涯？<br><img src="http://static.zybuluo.com/bethunebtj/daydmugl837tmw92klc6rqxz/image_1cfhqfqgt17r89b4156i1bni1hqq9.png" alt="老白讲互联网"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-time/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-time/" class="post-title-link" itemprop="url">Flink:时间</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-Time"><a href="#Flink-Time" class="headerlink" title="Flink Time"></a>Flink Time</h1><h2 id="Event-Time与Process-Time"><a href="#Event-Time与Process-Time" class="headerlink" title="Event Time与Process Time"></a>Event Time与Process Time</h2><p>如果你对数据的准确性要求比较高的话，采用 <code>Event time</code> 能保障 exactly-once。Processing Time 一般用于实时消费、精准性要求略低的场景，主要是因为时间生成不是 deterministic。</p>
<p>我们可以看下面的关系图， X 轴是 Event time，Y 轴是 Processing time。理想情况下 <code>Event time</code> 和 <code>Processing Time</code> 是相同的，就是说只要有一个事件发生，就可以立刻处理。但是实际场景中，事件发生后往往会经过一定延时才会被处理，这样就会导致我们系统的时间往往会滞后于事件时间。这里它们两个的差 <code>Processing-time lag</code> 表示我们处理事件的延时。</p>
<p><img src="vx_images/1726029789446"></p>
<p>事件时间常用在窗口中，使用 watermark 来确保数据完备性，比如说 watermarker 值大于 window 末尾时间时，我们就可以认为 window 窗口所有数据都已经到达了，就可以触发计算了。</p>
<p><img src="vx_images/1714865841042"></p>
<p>比如上面 <code>[0-10]</code> 的窗口，现在 watermark 走到了 10，已经到达了窗口的结束，触发计算 SUM=21。如果要是想对迟到的数据再进行触发，可以再定义一下后面 late data 的触发，比如说后面来了个 9，我们的 SUM 就等于 30。</p>
<h2 id="北京时间与格林尼治时间"><a href="#北京时间与格林尼治时间" class="headerlink" title="北京时间与格林尼治时间"></a>北京时间与格林尼治时间</h2><p>![北京时间](_v_images/20190731222505723_213254839.png =968x)</p>
<blockquote>
<p>划定时间窗口和时间戳以毫秒为单位</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">eventStream.assignTimestampsAndWatermarks(assigner = <span class="keyword">new</span> <span class="type">AscendingTimestampExtractor</span>[<span class="type">Event</span>]() &#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractAscendingTimestamp</span></span>(t: <span class="type">Event</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">    t.getTime * <span class="number">1000</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="processFunction中的时间"><a href="#processFunction中的时间" class="headerlink" title="processFunction中的时间"></a>processFunction中的时间</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="type">ProcessFunction</span>[<span class="type">Event</span>, (<span class="type">String</span>, <span class="type">Long</span>)] &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(event: <span class="type">Event</span>, context: <span class="type">ProcessFunction</span>[<span class="type">Event</span>,</span><br><span class="line">          (<span class="type">String</span>, <span class="type">Long</span>)]#<span class="type">Context</span>, collector: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Long</span>)]): <span class="type">Unit</span> = &#123;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">context.timestamp=<span class="number">1565064599999</span></span><br><span class="line">context.timerService().currentWatermark()=-<span class="number">9223372036854775808</span></span><br><span class="line">context.timerService().currentProcessingTime()=<span class="number">1565064607343</span></span><br><span class="line"></span><br><span class="line">Event(time=<span class="number">1565064350</span>, count=<span class="number">9</span>, url=/apply/main, channelId=<span class="number">1057</span>)</span><br></pre></td></tr></table></figure>
<p>以事件事件，窗口大小5min</p>
<p>一条消息，事件的时间是 1565064350(2019-08-06 12:05:50)<br><code>Context.timestamp</code>是1565064599999(2019-08-06 12:09:59), 可以理解为窗口结束的时间<br><code>context.timerService().currentWatermark()</code> 莫名其妙，这么大<br><code>context.timerService().currentProcessingTime()</code>是当前处理事件 2019-08-06 12:10:07</p>
<h3 id="Context-timestamp"><a href="#Context-timestamp" class="headerlink" title="Context.timestamp"></a><code>Context.timestamp</code></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Timestamp of the element currently being processed or timestamp of a firing timer.</span><br><span class="line">This might be &#123;<span class="meta">@code</span> <span class="keyword">null</span>&#125;, <span class="keyword">for</span> example <span class="keyword">if</span> the time characteristic of your program</span><br></pre></td></tr></table></figure>
<h2 id="时间戳timestamp与水印watermark"><a href="#时间戳timestamp与水印watermark" class="headerlink" title="时间戳timestamp与水印watermark"></a>时间戳timestamp与水印watermark</h2><p>提取Timestamp与生成Watermark一般步骤</p>
<ol>
<li>设置时间特性为Event Time。<code>StreamExecutionEnvironment#setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</code>。</li>
<li>在Source后Window前用<code>DataStream#assignTimestampsAndWatermarks</code>方法(<code>AssignerWithPeriodicWatermarks</code>或<code>AssignerWithPunctuatedWatermarks</code>)提取时间戳并生成水印。</li>
<li>重写<code>extractTimestamp</code>方法提取Timestamp，重写<code>getCurrentWatermark</code>方法或<code>checkAndGetNextWatermark</code>方法生成水印。</li>
</ol>
<h3 id="数据源中指定"><a href="#数据源中指定" class="headerlink" title="数据源中指定"></a>数据源中指定</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExampleSourceFunction</span> <span class="keyword">implements</span> <span class="title">SourceFunction</span>&lt;<span class="title">Tuple4</span>&lt;<span class="title">String</span>,<span class="title">Long</span>,<span class="title">String</span>,<span class="title">Integer</span>&gt;&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;Tuple4&lt;String,Long,String,Integer&gt;&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (isRunning)&#123;</span><br><span class="line">                <span class="comment">// 构造测试数据</span></span><br><span class="line">                ....</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 发出一条数据以及数据对应的Timestamp</span></span><br><span class="line">                ctx.collectWithTimestamp(record,eventTime);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 发出一条Watermark</span></span><br><span class="line">                ctx.emitWatermark(<span class="keyword">new</span> Watermark(eventTime - maxOutOfOrderness));</span><br><span class="line"></span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            isRunning = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>时间戳和水位线分别通过两个方法实现的</p>
<h3 id="时间戳的抽取方法"><a href="#时间戳的抽取方法" class="headerlink" title="时间戳的抽取方法"></a>时间戳的抽取方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 传入了两个参数，第二个参数是上一个时间戳，元素的当前内部时间戳，如果尚未分配时间戳，则为负值。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element, <span class="keyword">long</span> recordTimestamp)</span></span>;</span><br></pre></td></tr></table></figure>
<h3 id="周期性水印"><a href="#周期性水印" class="headerlink" title="周期性水印"></a>周期性水印</h3><p>分配器为元素分配事件时间时间戳，并生成表示流中事件时间进度的低水位线。这些时间戳和水印由对事件时间进行操作的函数和运算符使用，例如事件时间窗口。</p>
<p>使用此类以周期性间隔生成水印。最多每隔I毫秒(通过<code>ExecutionConfig.getautowerMarkinterval()</code>)配置一次，系统将调用<code>getCurrentWatermark()</code>方法来探测下一个水印值。<br>如果探测到的值为非空，并且时间戳大于前一个水印的时间戳，系统将生成新的水印(以保留升序水印的约定)。 如果自上次调用<code>getCurrentWatermark()</code>方法后没有新元素到达，系统调用该方法的频率可能会低于每I毫秒一次。<br>时间戳和水印被定义为代表自纪元(世界协调时1970年1月1日午夜)以来的毫秒的长度。某个值为t的水印表示不会再出现带有事件时间戳x的元素，其中x小于或等于t。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 返回当前水印。系统定期调用此方法来检索当前水印。该方法可能返回空值，表示没有新的水印可用。</span></span><br><span class="line"><span class="comment">* 只有当返回的水印为非空且其时间戳大于之前发出的水印的时间戳时，才会发出该水印(以保留升序水印的约定)。</span></span><br><span class="line"><span class="comment">* 如果当前水印仍然与前一个相同，则自上一次调用此方法以来，事件时间没有任何进展。如果返回空值，或者返回的水印的时间戳小于上次发出的时间戳，则不会生成新的水印。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">Watermark  AssignerWithPeriodicWatermarks.getCurrentWatermark()</span><br></pre></td></tr></table></figure>
<h3 id="非连续性水印"><a href="#非连续性水印" class="headerlink" title="非连续性水印"></a>非连续性水印</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 询问此实现是否要发出水印。这个方法是在extractTimestamp(对象，长)方法之后调用的。</span></span><br><span class="line"><span class="comment">* 只有当返回的水印为非空且其时间戳大于之前发出的水印的时间戳时，才会发出该水印(以保留升序水印的约定)。</span></span><br><span class="line"><span class="comment">* 如果返回空值，或者返回的水印的时间戳小于上次发出的时间戳，则不会生成新的水印。 有关如何使用此方法的示例，请参见此类的分配器带标点水印的文档。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">Watermark AssignerWithPunctuatedWatermarks.checkAndGetNextWatermark(T lastElement, <span class="keyword">long</span> extractedTimestamp)</span><br></pre></td></tr></table></figure>
<p><img src="_v_images/20201207105022608_1990981860.png"></p>
<h3 id="升序水印-AscendingTimestampExtractor"><a href="#升序水印-AscendingTimestampExtractor" class="headerlink" title="升序水印 AscendingTimestampExtractor"></a>升序水印 AscendingTimestampExtractor</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AscendingTimestampExtractor</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">AssignerWithPeriodicWatermarks</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">	<span class="comment">/** The current timestamp. */</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">long</span> currentTimestamp = Long.MIN_VALUE;</span><br><span class="line">	<span class="comment">/** Handler that is called when timestamp monotony is violated. */</span></span><br><span class="line">	<span class="keyword">private</span> MonotonyViolationHandler violationHandler = <span class="keyword">new</span> LoggingHandler();</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Extracts the timestamp from the given element. The timestamp must be monotonically increasing.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> element The element that the timestamp is extracted from.</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> The new timestamp.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(T element)</span></span>;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Sets the handler for violations to the ascending timestamp order.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> handler The violation handler to use.</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> This extractor.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> AscendingTimestampExtractor&lt;T&gt; <span class="title">withViolationHandler</span><span class="params">(MonotonyViolationHandler handler)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.violationHandler = requireNonNull(handler);</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// ------------------------------------------------------------------------</span></span><br><span class="line">    <span class="comment">// 调用</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element, <span class="keyword">long</span> elementPrevTimestamp)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">final</span> <span class="keyword">long</span> newTimestamp = extractAscendingTimestamp(element);</span><br><span class="line">		<span class="keyword">if</span> (newTimestamp &gt;= <span class="keyword">this</span>.currentTimestamp) &#123;</span><br><span class="line">			<span class="keyword">this</span>.currentTimestamp = newTimestamp;</span><br><span class="line">			<span class="keyword">return</span> newTimestamp;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			violationHandler.handleViolation(newTimestamp, <span class="keyword">this</span>.currentTimestamp);</span><br><span class="line">			<span class="keyword">return</span> newTimestamp;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Watermark <span class="title">getCurrentWatermark</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> Watermark(currentTimestamp == Long.MIN_VALUE ? Long.MIN_VALUE : currentTimestamp - <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AscendingTimestampExtractor抽象类实现了ssignerWithPeriodicWatermarks接口的extractTimestamp及getCurrentWatermark方法，同时声明抽象方法extractAscendingTimestamp供子类实现<br>水印的生产策略为：getCurrentWatermark 方法在currentTimestamp不为Long.MIN_VALUE时返回Watermark(currentTimestamp - 1)</p>
<p>综上：<br>发现AscendingTimestampExtractor适用于elements的时间在每个并行task里面事单调递增的，（timestamp monotony）数据场景。</p>
<h3 id="无序水印-BoundedOutOfOrdernessTimestampExtractor"><a href="#无序水印-BoundedOutOfOrdernessTimestampExtractor" class="headerlink" title="无序水印 BoundedOutOfOrdernessTimestampExtractor"></a>无序水印 BoundedOutOfOrdernessTimestampExtractor</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BoundedOutOfOrdernessTimestampExtractor</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">AssignerWithPeriodicWatermarks</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/** The current maximum timestamp seen so far. */</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">long</span> currentMaxTimestamp;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/** The timestamp of the last emitted watermark. */</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">long</span> lastEmittedWatermark = Long.MIN_VALUE;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * The (fixed) interval between the maximum seen timestamp seen in the records</span></span><br><span class="line"><span class="comment">	 * and that of the watermark to be emitted.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> maxOutOfOrderness;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">BoundedOutOfOrdernessTimestampExtractor</span><span class="params">(Time maxOutOfOrderness)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (maxOutOfOrderness.toMilliseconds() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Tried to set the maximum allowed &quot;</span> +</span><br><span class="line">				<span class="string">&quot;lateness to &quot;</span> + maxOutOfOrderness + <span class="string">&quot;. This parameter cannot be negative.&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">this</span>.maxOutOfOrderness = maxOutOfOrderness.toMilliseconds();</span><br><span class="line">		<span class="keyword">this</span>.currentMaxTimestamp = Long.MIN_VALUE + <span class="keyword">this</span>.maxOutOfOrderness;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getMaxOutOfOrdernessInMillis</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> maxOutOfOrderness;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Extracts the timestamp from the given element.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> element The element that the timestamp is extracted from.</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> The new timestamp.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element)</span></span>;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Watermark <span class="title">getCurrentWatermark</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">// this guarantees that the watermark never goes backwards.</span></span><br><span class="line">		<span class="keyword">long</span> potentialWM = currentMaxTimestamp - maxOutOfOrderness;</span><br><span class="line">		<span class="keyword">if</span> (potentialWM &gt;= lastEmittedWatermark) &#123;</span><br><span class="line">			lastEmittedWatermark = potentialWM;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> Watermark(lastEmittedWatermark);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element, <span class="keyword">long</span> previousElementTimestamp)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">long</span> timestamp = extractTimestamp(element);</span><br><span class="line">		<span class="keyword">if</span> (timestamp &gt; currentMaxTimestamp) &#123;</span><br><span class="line">			currentMaxTimestamp = timestamp;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> timestamp;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>BoundedOutOfOrdernessTimestampExtractor</code> 抽象类实现<code>AssignerWithPeriodicWatermarks</code>接口的<code>extractTimestamp及getCurrentWatermark</code>方法，同时声明抽象方法<code>extractAscendingTimestamp</code>供子类实现<br><code>BoundedOutOfOrdernessTimestampExtractor</code> 的构造器接收<code>maxOutOfOrderness</code>参数用于指定element允许滞后（<code>t</code>~`t_w<code>，</code>t<code>为element的eventTime，</code>t_w<code>为前一次watermark的时间）的最大时间，在计算窗口数据时，如果超过该值则会被忽略。 </code>BoundedOutOfOrdernessTimestampExtractor<code>的</code>extractTimestamp<code>方法会调用子类的</code>extractTimestamp<code>方法抽取时间，如果该时间大于</code>currentMaxTimestamp<code>，则更新</code>currentMaxTimestamp<code>； </code>getCurrentWatermark<code>先计算</code>potentialWM<code>，如果</code>potentialWM<code>大于等于</code>lastEmittedWatermark<code>则更新</code>lastEmittedWatemakr<code>(</code>currentMaxTimestamp - lastEmittedWatermark &gt;= maxOutOfOrderness<code>， 这里表示</code>lastEmittedWatermark<code>太小了，所以差值超过了</code>maxOutOfOrderness<code>，因此会调大</code>lastEmittedWatermark<code>)，最后返回</code>watermark` </p>
<p>具体逻辑参考：就是判断如果新的水印时间大于上次最后一次发出水印时间，选择新的水印时间，否则选择上次最后发送水印时间戳</p>
<h3 id="TimeStamp分配器和Watermark生成器-Timestamp-Assigners-Watermark-Generators"><a href="#TimeStamp分配器和Watermark生成器-Timestamp-Assigners-Watermark-Generators" class="headerlink" title="TimeStamp分配器和Watermark生成器(Timestamp Assigners / Watermark Generators)"></a>TimeStamp分配器和Watermark生成器(Timestamp Assigners / Watermark Generators)</h3><h2 id="数据延迟"><a href="#数据延迟" class="headerlink" title="数据延迟"></a>数据延迟</h2><p>主要的办法是给定一个允许延迟的时间，在该时间范围内仍可以接受处理延迟数据</p>
<p>设置允许延迟的时间是通过<code>allowedLateness(lateness: Time)</code>设置</p>
<p>保存延迟数据则是通过<code>sideOutputLateData(outputTag: OutputTag[T])</code>保存</p>
<p>获取延迟数据是通过<code>DataStream.getSideOutput(tag: OutputTag[X])</code>获取</p>
<h3 id="allowedLateness-lateness-Time"><a href="#allowedLateness-lateness-Time" class="headerlink" title="allowedLateness(lateness: Time)"></a>allowedLateness(lateness: Time)</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">allowedLateness</span></span>(lateness: <span class="type">Time</span>): <span class="type">WindowedStream</span>[<span class="type">T</span>, <span class="type">K</span>, <span class="type">W</span>] = &#123;</span><br><span class="line">    javaStream.allowedLateness(lateness)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法传入一个Time值，设置允许数据迟到的时间，这个时间和waterMark中的时间概念不同。再来回顾一下，</p>
<p>waterMark=数据的事件时间-允许乱序时间值</p>
<p>随着新数据的到来，waterMark的值会更新为最新数据事件时间-允许乱序时间值，但是如果这时候来了一条历史数据，waterMark值则不会更新。总的来说，waterMark是为了能接收到尽可能多的乱序数据。</p>
<p>那这里的Time值呢？主要是为了等待迟到的数据，在一定时间范围内，如果属于该窗口的数据到来，仍会进行计算，后面会对计算方式仔细说明</p>
<p><strong>allowedLateness 是等待数据进入窗口的最大时间，未进入的数据，可以通过偏流导出</strong></p>
<p>注意：该方法只针对于基于event-time的窗口，如果是基于processing-time，并且指定了非零的time值则会抛出异常</p>
<h3 id="sideOutputLateData-outputTag-OutputTag-T"><a href="#sideOutputLateData-outputTag-OutputTag-T" class="headerlink" title="sideOutputLateData(outputTag: OutputTag[T])"></a>sideOutputLateData(outputTag: OutputTag[T])</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sideOutputLateData</span></span>(outputTag: <span class="type">OutputTag</span>[<span class="type">T</span>]): <span class="type">WindowedStream</span>[<span class="type">T</span>, <span class="type">K</span>, <span class="type">W</span>] = &#123;</span><br><span class="line">    javaStream.sideOutputLateData(outputTag)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法是将迟来的数据保存至给定的outputTag参数，而OutputTag则是用来标记延迟数据的一个对象。</p>
<h3 id="DataStream-getSideOutput-tag-OutputTag-X"><a href="#DataStream-getSideOutput-tag-OutputTag-X" class="headerlink" title="DataStream.getSideOutput(tag: OutputTag[X])"></a>DataStream.getSideOutput(tag: OutputTag[X])</h3><p>通过window等操作返回的DataStream调用该方法，传入标记延迟数据的对象来获取延迟的数据</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">waterStream.keyBy(<span class="number">0</span>)</span><br><span class="line">      .window(<span class="type">TumblingEventTimeWindows</span>.of(<span class="type">Time</span>.seconds(<span class="number">5</span>L)))</span><br><span class="line">  </span><br><span class="line">      .allowedLateness(<span class="type">Time</span>.seconds(<span class="number">2</span>L))</span><br><span class="line">      .sideOutputLateData(lateData)</span><br><span class="line">      .apply(<span class="keyword">new</span> <span class="type">WindowFunction</span>[(<span class="type">String</span>, <span class="type">Long</span>), <span class="type">String</span>, <span class="type">Tuple</span>, <span class="type">TimeWindow</span>] &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(key: <span class="type">Tuple</span>, window: <span class="type">TimeWindow</span>, input: <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">Long</span>)], out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">          <span class="keyword">val</span> timeArr = <span class="type">ArrayBuffer</span>[<span class="type">String</span>]()</span><br><span class="line">          <span class="keyword">val</span> iterator = input.iterator</span><br><span class="line">          <span class="keyword">while</span> (iterator.hasNext) &#123;</span><br><span class="line">            <span class="keyword">val</span> tup2 = iterator.next()</span><br><span class="line">            timeArr.append(sdf.format(tup2._2))</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">val</span> outData = <span class="type">String</span>.format(<span class="string">&quot;key: %s    data: %s    startTime:  %s    endTime:  %s&quot;</span>,</span><br><span class="line">            key.toString,</span><br><span class="line">            timeArr.mkString(<span class="string">&quot;-&quot;</span>),</span><br><span class="line">            sdf.format(window.getStart),</span><br><span class="line">            sdf.format(window.getEnd))</span><br><span class="line">          out.collect(outData)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">    result.print(<span class="string">&quot;window计算结果:&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> late = result.getSideOutput(lateData)</span><br><span class="line">    late.print(<span class="string">&quot;迟到的数据:&quot;</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>【参考文献】</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/103519313">Flink时间系列-EventTime下数据延迟处理</a></li>
<li><a target="_blank" rel="noopener" href="https://www.infoq.cn/article/zvc15xotpp5x5brxhwuz">Flink: 时间属性深度解析</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-metrics/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-metrics/" class="post-title-link" itemprop="url">Flink:指标监控</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="flink-metrics"><a href="#flink-metrics" class="headerlink" title="flink-metrics"></a>flink-metrics</h1><p>[参考文献]</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21653785/article/details/79625601">Flink源码系列-指标监控</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/0x12345678/p/10561039.html">自定义metric-report</a></li>
<li><a target="_blank" rel="noopener" href="http://www.mamicode.com/info-detail-2317943.html">深入理解Flink之metrics</a></li>
<li><a target="_blank" rel="noopener" href="https://my.oschina.net/go4it/blog/3023586">聊聊Flink的MertricsQueryServiceGateway</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/e50586fff515">Flink指标</a></li>
</ul>
<p>Flink Metrics是通过引入<code>com.codahale.metrics</code>包实现的，它将收集的metrics分为四大类：<code>Counter</code>，<code>Gauge</code>，<code>Histogram</code>和<code>Meter</code>下面分别说明：</p>
<ul>
<li><code>Counter计数器</code><br>  用来统计一个metrics的总量。<br>  拿flink中的指标来举例，像Task/Operator中的numRecordsIn（此task或者operator接收到的record总量）和numRecordsOut（此task或者operator发送的record总量）就属于Counter。</li>
<li><code>Gauge指标值</code><br>  用来记录一个metrics的瞬间值。<br>  拿flink中的指标举例，像JobManager或者TaskManager中的<code>JVM.Heap.Used</code>就属于<code>Gauge</code>，记录某个时刻JobManager或者TaskManager所在机器的JVM堆使用量。</li>
<li><code>Histogram直方图</code><br>  有的时候我们不满足于只拿到metrics的总量或者瞬时值，当想得到metrics的最大值，最小值，中位数等信息时，我们就能用到Histogram了。<br>  Flink中属于Histogram的指标很少，但是最重要的一个是属于operator的latency。此项指标会记录数据处理的延迟信息，对任务监控起到很重要的作用。</li>
<li><code>Meter平均值</code><br>   用来记录一个metrics某个时间段内平均值。<br>   flink中类似指标有task/operator中的numRecordsInPerSecond，字面意思就可以理解，指的是此task或者operator每秒接收的记录数。</li>
</ul>
<h3 id="com-tencent-oceanus-metastore-metrics-CustomMetricsRegistry"><a href="#com-tencent-oceanus-metastore-metrics-CustomMetricsRegistry" class="headerlink" title="com.tencent.oceanus.metastore.metrics.CustomMetricsRegistry"></a>com.tencent.oceanus.metastore.metrics.CustomMetricsRegistry</h3><h3 id="org-apache-flink-metrics-MeterView"><a href="#org-apache-flink-metrics-MeterView" class="headerlink" title="org.apache.flink.metrics.MeterView"></a>org.apache.flink.metrics.MeterView</h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/8/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/10/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">235</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">126</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
