<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/page/10/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/10/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/HBaseConnectors/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/HBaseConnectors/" class="post-title-link" itemprop="url">Flink:HBaseConnectors</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:05" itemprop="dateModified" datetime="2021-01-18T22:05:05+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-HBase-connectors"><a href="#Flink-HBase-connectors" class="headerlink" title="Flink HBase connectors"></a>Flink HBase connectors</h1><h2 id="flighting"><a href="#flighting" class="headerlink" title="flighting"></a>flighting</h2><p>奇怪，没有依赖HBase-Client，而是依赖了HBase-server</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-hadoop2-compat<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">type</span>&gt;</span>test-jar<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="添加文件到ClassLoader的classpath"><a href="#添加文件到ClassLoader的classpath" class="headerlink" title="添加文件到ClassLoader的classpath"></a>添加文件到ClassLoader的classpath</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Get the classloader actually used by HBaseConfiguration</span></span><br><span class="line">ClassLoader classLoader = HBaseConfiguration.create().getClassLoader();</span><br><span class="line"><span class="keyword">if</span> (!(classLoader <span class="keyword">instanceof</span> URLClassLoader)) &#123;</span><br><span class="line">	fail(<span class="string">&quot;We should get a URLClassLoader&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Make the addURL method accessible</span></span><br><span class="line">Method method = URLClassLoader.class.getDeclaredMethod(<span class="string">&quot;addURL&quot;</span>, URL.class);</span><br><span class="line">method.setAccessible(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add the directory where we put the hbase-site.xml to the classpath</span></span><br><span class="line">method.invoke(classLoader, directory.toURI().toURL());</span><br></pre></td></tr></table></figure>








      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Oceanus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Oceanus/" class="post-title-link" itemprop="url">Oceanus: table meta API</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:05" itemprop="dateModified" datetime="2021-01-18T22:05:05+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Oceanus"><a href="#Oceanus" class="headerlink" title="Oceanus"></a>Oceanus</h1><h2 id="拉取库表信息"><a href="#拉取库表信息" class="headerlink" title="拉取库表信息"></a>拉取库表信息</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -o tank_pos_meta.json &#x27;http://&lt;host&gt;:&lt;port&gt;/ec/v1/listTable?pageNum=1&amp;pageSize=999&amp;type=hippo&amp;dbName=bank-pos-info&amp;name=pos_yyyymmdd&#x27;</span><br></pre></td></tr></table></figure>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;result_code&quot;</span>: <span class="string">&quot;0&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;result_msg&quot;</span>: <span class="string">&quot;操作成功&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;result_content&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;tables&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">&quot;id&quot;</span>: <span class="number">2255</span>,</span><br><span class="line">                <span class="attr">&quot;dbName&quot;</span>: <span class="string">&quot;info&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;pos_yyyymmdd&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;hippo&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;principals&quot;</span>: <span class="string">&quot;user_name&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;fields&quot;</span>: <span class="string">&quot;db_name,String,db_name: tb_name,String,tb_name: op_name,String,op_name: exp_time_stample,String,exp_time_stample: exp_time_stample_order,String,exp_time_stample_order: Fbill_no,String,Fbill_no: Fbank_type,Long,Fbank_type: Fbiz_type,Long,Fbiz_type: Fpos_status,Long,Fpos_status: Freverse_status,Long,Freverse_status: Freverse_times,Long,Freverse_times: Ftransaction_id,String,Ftransaction_id: Freal_bill_no,String,Freal_bill_no: Ftrace_no,String,Ftrace_no: Ftx_date,String,Ftx_date: Famount,Long,Famount: Fcur_type,Long,Fcur_type: Fuin,String,Fuin: Fuid,Long,Fuid: Fuser_name,String,Fuser_name: Fuser_id_type,Long,Fuser_id_type: Fuser_id,String,Fuser_id: Fuser_phone,String,Fuser_phone: Fcard_no,String,&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;content&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;银行pos流水&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;attributes&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;table.topic&quot;</span>: <span class="string">&quot;bank_pos&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.bid&quot;</span>: <span class="string">&quot;bank_pos&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;data.encode&quot;</span>: <span class="string">&quot;UTF8&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.hippo.addrlist&quot;</span>: <span class="string">&quot;&lt;hippo_master&gt;&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.package&quot;</span>: <span class="string">&quot;true&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.interfaceId&quot;</span>: <span class="string">&quot;t_bank_pos_yyyymmdd&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;source.data.type&quot;</span>: <span class="string">&quot;data.type.default&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.needwatermark&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.kv&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.field.splitter&quot;</span>: <span class="string">&quot;0x1&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;is.temporal.table&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.field.splitter.other&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.usage&quot;</span>: <span class="string">&quot;table&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.used&quot;</span>: <span class="string">&quot;false&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;table.running.used&quot;</span>: <span class="string">&quot;false&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">&quot;modifier&quot;</span>: <span class="string">&quot;&lt;table_owner&gt;&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;modify_time&quot;</span>: <span class="number">1563420065831</span>,</span><br><span class="line">                <span class="attr">&quot;create_time&quot;</span>: <span class="number">1563420065831</span>,</span><br><span class="line">                <span class="attr">&quot;tablesLogs&quot;</span>: <span class="literal">null</span></span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">&quot;total&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;pageNum&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;pageSize&quot;</span>: <span class="number">999</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="flink的优化"><a href="#flink的优化" class="headerlink" title="flink的优化"></a>flink的优化</h2><h3 id="JobManager-failover"><a href="#JobManager-failover" class="headerlink" title="JobManager failover"></a>JobManager failover</h3><p><img src="_v_images/20200601183746039_28243.png"></p>
<p>它的 standby 节点是冷备的，JobManager 的切换会导致它管理的所有 Job 都会被重启恢复，这一行为在我们现网环境中是不可接受的。所以，我们首先定制的第一个大特性就是<br>JobManager 的 failover 优化，让 standby 节点变成热备，这使得 JobManager 的切换对 TaskManager 上已经正在运行的 Job 不产生影响。我们已经对 Standalone 以及 Flink on YARN 这两种部署模式支持了这个特性，Flink on YARN 的支持还处于内部验证阶段。我们以对 Standalone 模式的优化为例来进行分析，它主要包含这么几个步骤：</p>
<ul>
<li>取消 JobManager 跟 TaskManager 因为心跳超时或 Leadership 变动就 cancel task 的行为；</li>
<li>对 ExecutionGraph 核心数据的快照；</li>
<li>通过 ExecutionGraphBuilder 重构空的 ExecutionGraph 加上快照重置来恢复出一个跟原先等价的 ExecutionGraph 对象；</li>
<li>TaskManager 跟新的 JobManager leader 建立连接后以心跳上报自己的状态和必要的信息；<br>新的 JobManager 确认在 reconcile 阶段 Job 的所有 task 是否正常运行。</li>
</ul>
<h3 id="checkpoint失败改进"><a href="#checkpoint失败改进" class="headerlink" title="checkpoint失败改进"></a>checkpoint失败改进</h3><p><img src="_v_images/20200601185553966_3881.png"><br>社区版当前的处理机制。JobMaster 中，每个 Job 会对应一个 Checkpoint Coordinator，它用来管理并协调 Job 检查点的执行。当到达一个检查点的触发周期，Coordinator 会对所有的 Source Task 下发 TriggerCheckpoint 消息，source task 会在自身完成快照后向下游广播 CheckpointBarrier，作为下游 task 触发的通知。其中，如果一个 task 在执行检查点时失败了，这取决于用户是否容忍这个失败（通过一个配置项），如果选择不容忍那么这个失败将变成一个异常导致 task 的失败，与此同时 task 的失败将会通知到 JobMaster，JobMaster 将会通知这个 Job 的其他 task 取消它们的执行。现有的机制存在一些问题：</p>
<ul>
<li>Coordinator 并不能控制 Job 是否容忍检查点失败，因为控制权在 task 端；</li>
<li>Coordinator 当前的失败处理代码逻辑混乱，区分出了触发阶段，却忽略了执行阶段；</li>
<li>无法实现容忍多少个连续的检查点失败则让 Job 失败的逻辑。</li>
</ul>
<p><img src="_v_images/20200601190109255_17290.png"><br>首先，我们对源码中 checkpoint package 下的相关类进行了重构，使得它不再区分触发阶段，引进了更多的检查点失败原因的枚举并重构了相关的代码。然后我们引入了 CheckpointFailureManager 组件，用来统一失败管理，同时为了适配更灵活的容忍失败的能力，我们引入了检查点失败计数器机制。现在，当我们遇到检查点失败后，这个失败信息会直接上报到 Coordinator，而是否要让 Job 失败具体的决策则由 CheckpointFailureManager 作出，这就<strong>使得 Coordinator 具有了完整的检查点控制权，而决策权转让给 CheckpointFailureManager，则充分实现了逻辑解耦</strong>。</p>
<h3 id="AsyncIO超时"><a href="#AsyncIO超时" class="headerlink" title="AsyncIO超时"></a>AsyncIO超时</h3><h3 id="sql-editor"><a href="#sql-editor" class="headerlink" title="sql editor"></a>sql editor</h3><p>ace editor</p>
<h3 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h3><p>[averyzhang@tdw-10-121-139-111 /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646]$ ll<br>总用量 32<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 blobStore-b0fe739d-d5e0-4a87-9c34-2a2492fc84a6<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 blobStore-f8cdfc9d-d7d2-4fb6-9836-da65b414b45a<br>drwxr-s—  3 u_teg_tdbank users 4096 6月   5 16:07 container_e03_1542247480019_1646_01_000002<br>drwx–x— 11 u_teg_tdbank users 4096 6月   5 16:07 filecache<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 flink-dist-cache-d55b9eaa-87b9-404e-a015-c4c90c767ac9<br>drwxr-s—  8 u_teg_tdbank users 4096 6月   5 16:07 flink-io-0bd3c6be-79ef-41d6-95ec-f42a949a10f1<br>drwxr-s—  4 u_teg_tdbank users 4096 6月   5 16:07 localState<br>drwxr-s—  2 u_teg_tdbank users 4096 6月   5 16:07 rocksdb-lib-89c57e29c492279dc1e188992c87925e</p>
<p>[averyzhang@tdw-10-121-139-111 /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646]$ tree<br>.<br>|– blobStore-b0fe739d-d5e0-4a87-9c34-2a2492fc84a6<br>|– blobStore-f8cdfc9d-d7d2-4fb6-9836-da65b414b45a<br>|– container_e03_1542247480019_1646_01_000002<br>|   |– container_tokens<br>|   |– flink-conf.yaml -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/10/91db3812-bb43-492d-8c32-359b2c21a142-taskmanager-conf.yaml<br>|   |– flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/15/flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar<br>|   |– kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/11/kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar<br>|   |– launch_container.sh<br>|   |– lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/12/lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar<br>|   |– log4j.properties -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/17/log4j.properties<br>|   |– log4j.zip -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/14/log4j.zip<br>|   |– oceanus-common-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/13/oceanus-common-1.1.0-SNAPSHOT.jar<br>|   |– oceanus-core-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/16/oceanus-core-1.1.0-SNAPSHOT.jar<br>|   |– oceanus-ml-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/18/oceanus-ml-1.1.0-SNAPSHOT.jar<br>|   <code>-- tmp |-- filecache [error opening dir] |-- flink-dist-cache-d55b9eaa-87b9-404e-a015-c4c90c767ac9 |-- flink-io-0bd3c6be-79ef-41d6-95ec-f42a949a10f1 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_337adade1e207453ed3502e01d75fd03__1_8__uuid_6d0d5c24-bb66-4793-afa4-7a7e3c3ffd6a |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024751.sst<br>|   |       |– 024753.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_337adade1e207453ed3502e01d75fd03__2_8__uuid_18ea3048-b73d-482d-b6c9-615452280981 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024739.sst<br>|   |       |– 024741.sst<br>|   |       |– 024742.sst<br>|   |       |– 024743.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_be465a1f98956392d0b820196e75d12b__1_8__uuid_efd7a85c-2a15-4d62-9929-60624dd6ea4a |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024741.sst<br>|   |       |– 024743.sst<br>|   |       |– 024744.sst<br>|   |       |– 024745.sst<br>|   |       |– 024746.sst<br>|   |       |– 024747.sst<br>|   |       |– 024748.sst<br>|   |       |– 024749.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_be465a1f98956392d0b820196e75d12b__2_8__uuid_e666a8b1-d26d-4688-b089-0a957e49f947 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024740.sst<br>|   |       |– 024742.sst<br>|   |       |– 024743.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   |-- job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_eaecdab2f3df15db186c08e889659492__1_8__uuid_24efb767-bdf2-4309-a136-302cc4a18399 |   |   </code>– db<br>|   |       |– 000013.log<br>|   |       |– 024741.sst<br>|   |       |– 024743.sst<br>|   |       |– 024744.sst<br>|   |       |– 024745.sst<br>|   |       |– 024746.sst<br>|   |       |– 024747.sst<br>|   |       |– 024748.sst<br>|   |       |– CURRENT<br>|   |       |– IDENTITY<br>|   |       |– LOCK<br>|   |       |– LOG<br>|   |       |– MANIFEST-000006<br>|   |       |– OPTIONS-000010<br>|   |       <code>-- OPTIONS-000012 |   </code>– job_05606ccf34b1f48ff075d3092d9b81dd_op_WindowOperator_eaecdab2f3df15db186c08e889659492__2_8__uuid_776c72fa-68fa-493b-b9ab-03461406816a<br>|       <code>-- db |           |-- 000013.log |           |-- 024740.sst |           |-- 024742.sst |           |-- 024743.sst |           |-- CURRENT |           |-- IDENTITY |           |-- LOCK |           |-- LOG |           |-- MANIFEST-000006 |           |-- OPTIONS-000010 |           </code>– OPTIONS-000012<br>|– localState<br>|   |– aid_AllocationID{e1f41e5a166354d80ad6d6b8d3765fa1}<br>|   <code>-- aid_AllocationID&#123;e6e7f806bb078db66f50eeb3a48f0da9&#125; </code>– rocksdb-lib-89c57e29c492279dc1e188992c87925e<br>    `– librocksdbjni-linux64.so</p>
<p>23 directories, 87 files</p>
<p>[averyzhang@tdw-10-121-139-111 /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/container_e03_1542247480019_1646_01_000002]$ ll<br>总用量 52<br>-rw——- 1 u_teg_tdbank users   69 6月   5 16:07 container_tokens<br>lrwxrwxrwx 1 u_teg_tdbank users  154 6月   5 16:07 flink-conf.yaml -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/10/91db3812-bb43-492d-8c32-359b2c21a142-taskmanager-conf.yaml<br>lrwxrwxrwx 1 u_teg_tdbank users  151 6月   5 16:07 flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/15/flink-runtime-oceanus-dependency-lib-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  146 6月   5 16:07 kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/11/kafka-connector-0.11-dependency-1.1.0-SNAPSHOT.jar<br>-rwx—— 1 u_teg_tdbank users 6328 6月   5 16:07 launch_container.sh<br>lrwxrwxrwx 1 u_teg_tdbank users  164 6月   5 16:07 lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/12/lct-click-stat-1.0-SNAPSHOT-jar-with-dependencies-20200511152610.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  112 6月   5 16:07 log4j.properties -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/17/log4j.properties<br>lrwxrwxrwx 1 u_teg_tdbank users  105 6月   5 16:07 log4j.zip -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/14/log4j.zip<br>lrwxrwxrwx 1 u_teg_tdbank users  129 6月   5 16:07 oceanus-common-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/13/oceanus-common-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  127 6月   5 16:07 oceanus-core-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/16/oceanus-core-1.1.0-SNAPSHOT.jar<br>lrwxrwxrwx 1 u_teg_tdbank users  125 6月   5 16:07 oceanus-ml-1.1.0-SNAPSHOT.jar -&gt; /data/yarnenv/local/usercache/u_teg_tdbank/appcache/application_1542247480019_1646/filecache/18/oceanus-ml-1.1.0-SNAPSHOT.jar<br>drwxr-s— 2 u_teg_tdbank users 4096 6月   5 16:07 tmp</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Impala/01.Impala/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Impala/01.Impala/" class="post-title-link" itemprop="url">Impala基础与痛点</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:05" itemprop="dateModified" datetime="2021-01-18T22:05:05+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="01-Impala"><a href="#01-Impala" class="headerlink" title="01.Impala"></a>01.Impala</h1><h2 id="components"><a href="#components" class="headerlink" title="components"></a>components</h2><p><a target="_blank" rel="noopener" href="https://impala.apache.org/docs/build/html/topics/impala_components.html">impala components</a></p>
<h3 id="impalad的部署"><a href="#impalad的部署" class="headerlink" title="impalad的部署"></a>impalad的部署</h3><p>Impala daemons can be deployed in one of the following ways:</p>
<ul>
<li>HDFS and Impala are co-located, and each Impala daemon runs on the same host as a DataNode.</li>
<li>Impala is deployed separately in a compute cluster and reads remotely from HDFS, S3, ADLS, etc.</li>
</ul>
<h3 id="hive连接表需要刷新impalad"><a href="#hive连接表需要刷新impalad" class="headerlink" title="hive连接表需要刷新impalad"></a>hive连接表需要刷新impalad</h3><p>The catalog service avoids the need to issue REFRESH and INVALIDATE METADATA statements when the metadata changes are performed by statements issued through Impala. When you create a table, load data, and so on through Hive, you do need to issue REFRESH or INVALIDATE METADATA on an Impala daemon before executing a query there.</p>
<p>impala 自己执行修改元数据的请求时，不需要刷新和重载元数据，当通过hive创建表和加载数据时，在执行查询之前，需要在Impala守护进程上发出REFRESH或INVALIDATE元数据。</p>
<p>The REFRESH and INVALIDATE METADATA statements are not needed when the CREATE TABLE, INSERT, or other table-changing or data-changing operation is performed through Impala. These statements are still needed if such operations are done through Hive or by manipulating data files directly in HDFS, but in those cases the statements only need to be issued on one Impala daemon rather than on all daemons. </p>
<p>当通过Impala执行创建表、插入或其他表更改或数据更改操作时，不需要刷新和无效元数据语句。<br>如果通过Hive或直接在HDFS中操作数据文件，仍然需要，但是在这种情况下，只需要在一个Impala守护进程上发出这些语句，而不是在所有守护进程上。</p>
<h3 id="元数据加载与对查询的影响"><a href="#元数据加载与对查询的影响" class="headerlink" title="元数据加载与对查询的影响"></a>元数据加载与对查询的影响</h3><p><code>‑‑load_catalog_in_background</code> option to control when the metadata of a table is loaded.<br>If set to false, the metadata of a table is loaded when it is referenced for the first time. This means that the first run of a particular query can be slower than subsequent runs. Starting in Impala 2.2, the default for ‑‑load_catalog_in_background is false.</p>
<p>表的元数据在第一次引用时加载。这意味着特定查询的第一次运行可能比后续运行慢</p>
<p>If set to true, the catalog service attempts to load metadata for a table even if no query needed that metadata. So metadata will possibly be already loaded when the first query that would need it is run. However, for the following reasons, we recommend not to set the option to true.</p>
<p>catalogd尝试加载表的元数据，即使没有查询需要该元数据。因此，在运行第一个需要元数据的查询时，元数据可能已经被加载</p>
<p>Background load can interfere with query-specific metadata loading. This can happen on startup or after invalidating metadata, with a duration depending on the amount of metadata, and can lead to a seemingly random long running queries that are difficult to diagnose.</p>
<p>后台加载可能会干扰特定查询的元数据加载。这种情况可能在启动时发生，也可能在元数据失效后发生，持续时间取决于元数据的数量，并可能导致看似随机的长时间运行查询，而这些查询很难诊断。</p>
<p>Impala may load metadata for tables that are possibly never used, potentially increasing catalog size and consequently memory usage for both catalog service and Impala Daemon.</p>
<p>Impala可以为可能从未使用过的表加载元数据，这可能会增加目录大小，从而增加目录服务和Impala守护进程的内存使用量。</p>
<h3 id="元数据刷新耗时"><a href="#元数据刷新耗时" class="headerlink" title="元数据刷新耗时"></a>元数据刷新耗时</h3><p>For tables with a large volume of data and/or many partitions, retrieving all the metadata for a table can be time-consuming, taking minutes in some cases. Thus, each Impala node caches all of this metadata to reuse for future queries against the same table.<br>对于具有大量数据和/或许多分区的表，检索表的所有元数据可能很耗时，在某些情况下会花费几分钟。<br>因此，每个Impala节点都会缓存所有这些元数据，以供将来针对同一表的查询重用。</p>
<p>If the table definition or the data in the table is updated, all other Impala daemons in the cluster must receive the latest metadata, replacing the obsolete cached metadata, before issuing a query against that table</p>
<p>For DDL and DML issued through Hive, or changes made manually to files in HDFS, you still use the REFRESH statement (when new data files are added to existing tables) or the INVALIDATE METADATA statement (for entirely new tables, or after dropping a table, performing an HDFS rebalance operation, or deleting data files). Issuing INVALIDATE METADATA by itself retrieves metadata for all the tables tracked by the metastore. If you know that only specific tables have been changed outside of Impala, you can issue REFRESH table_name for each affected table to only retrieve the latest metadata for those tables.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Spark/Spark-usage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Spark/Spark-usage/" class="post-title-link" itemprop="url">Spark 使用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:06" itemprop="dateModified" datetime="2021-01-18T22:05:06+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Spark-使用"><a href="#Spark-使用" class="headerlink" title="Spark 使用"></a>Spark 使用</h1><h2 id="copy-file"><a href="#copy-file" class="headerlink" title="copy file"></a>copy file</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.&#123;<span class="type">FileAlreadyExistsException</span>, <span class="type">FileSystem</span>, <span class="type">FileUtil</span>, <span class="type">Path</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> srcFileSystem: <span class="type">FileSystem</span> = <span class="type">FileSystemUtil</span></span><br><span class="line">      .apply(spark.sparkContext.hadoopConfiguration)</span><br><span class="line">      .getFileSystem(sourceFile)</span><br><span class="line">    <span class="keyword">val</span> dstFileSystem: <span class="type">FileSystem</span> = <span class="type">FileSystemUtil</span></span><br><span class="line">      .apply(spark.sparkContext.hadoopConfiguration)</span><br><span class="line">      .getFileSystem(sourceFile)</span><br><span class="line"></span><br><span class="line">    <span class="type">FileUtil</span>.copy(</span><br><span class="line">      srcFileSystem,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">Path</span>(<span class="keyword">new</span> <span class="type">URI</span>(sourceFile)),</span><br><span class="line">      dstFileSystem,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">Path</span>(<span class="keyword">new</span> <span class="type">URI</span>(targetFile)),</span><br><span class="line">      <span class="literal">true</span>,</span><br><span class="line">      spark.sparkContext.hadoopConfiguration)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Spark/Spark-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Spark/Spark-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/" class="post-title-link" itemprop="url">Spark开发集锦</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:06" itemprop="dateModified" datetime="2021-01-18T22:05:06+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><p><a target="_blank" rel="noopener" href="https://spark-reference-doc-cn.readthedocs.io/zh_CN/latest/programming-guide/rdd-guide.html">Spark 2.2.x中文文档</a><br>spark两个重要概念</p>
<ul>
<li>RDD</li>
<li>共享变量</li>
</ul>
<h2 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h2><h3 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h3><h3 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h3><h2 id="dev"><a href="#dev" class="headerlink" title="dev"></a>dev</h2><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><p>spark core依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>hdfs client</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>导包</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br></pre></td></tr></table></figure>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>每个JVM进程中，只能有一个活跃（active）的 SparkContext 对象。如果你非要再新建一个，那首先必须将之前那个活跃的 SparkContext 对象stop()掉。</p>
<blockquote>
<p>如何保证SparkContext是单例</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(appName).setMaster(master)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell –help 可以查看完整的选项列表</span><br></pre></td></tr></table></figure>
<h2 id="RDD-弹性分布式数据集"><a href="#RDD-弹性分布式数据集" class="headerlink" title="RDD: 弹性分布式数据集"></a>RDD: 弹性分布式数据集</h2><p>可容错、可并行操作的分布式元素集合</p>
<p>有两种方法可以创建 RDD 对象：由驱动程序中的集合对象通过并行化操作创建，或者从外部存储系统中数据集加载（如：共享文件系统、HDFS、HBase或者其他Hadoop支持的数据源）。</p>
<h3 id="并行集合"><a href="#并行集合" class="headerlink" title="并行集合"></a>并行集合</h3><h2 id="Spark-SQL-partition个数与宽窄依赖"><a href="#Spark-SQL-partition个数与宽窄依赖" class="headerlink" title="Spark SQL partition个数与宽窄依赖"></a>Spark SQL partition个数与宽窄依赖</h2><h3 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey"></a>groupByKey</h3><h4 id="默认值"><a href="#默认值" class="headerlink" title="默认值"></a>默认值</h4><ol>
<li>不指定partition大小</li>
</ol>
<p>默认的 Spark SQL 会使用 <code>spark.sql.shuffle.partitions</code> 的数量来进行 <code>aggregation</code> 和 <code>join</code>，默认值为 200。这会导致 partition 膨胀的问题，200个 partition 都需要执行，无论大小，尽管有些 partition 是没有数据的。</p>
<ol start="2">
<li>通过repartition设定大小后，再groupByKey</li>
</ol>
<p>仍然是200</p>
<ol start="3">
<li><p>Using repartition Operator With Explicit Number of Partitions</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">repartition(numPartitions: <span class="type">Int</span>, partitionExprs: <span class="type">Column</span>*): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure>
<p>指定partitionExprs，则可以实现指定的分区数</p>
</li>
</ol>
<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>rdd的几个基本方法:</p>
<p>getPartitions()</p>
<p>compute()</p>
<h2 id="Hadoop-split-Hadoop分片"><a href="#Hadoop-split-Hadoop分片" class="headerlink" title="Hadoop split: Hadoop分片"></a>Hadoop split: Hadoop分片</h2><p>hdfs dfs blockSize</p>
<p>hdfs-site.xml中修改dfs.blockSize, spark 2.7.x 默认值为128M</p>
<p><img src="_v_images/20200728185752151_2000769439.png"></p>
<h2 id="spark-3-0-读取-orcfile"><a href="#spark-3-0-读取-orcfile" class="headerlink" title="spark 3.0 读取 orcfile"></a>spark 3.0 读取 orcfile</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> path=<span class="string">&quot;/data/sample.orc&quot;</span></span><br><span class="line"><span class="keyword">val</span> orcRdd: <span class="type">RDD</span>[(<span class="type">NullWritable</span>, <span class="type">OrcStruct</span>)] =</span><br><span class="line">  sc.hadoopFile(</span><br><span class="line">    path,</span><br><span class="line">    classOf[<span class="type">OrcInputFormat</span>],</span><br><span class="line">    classOf[<span class="type">NullWritable</span>],</span><br><span class="line">    classOf[<span class="type">OrcStruct</span>],</span><br><span class="line">    <span class="number">10</span>)</span><br><span class="line"><span class="keyword">val</span> result= orcRdd.map((line: (<span class="type">NullWritable</span>, <span class="type">OrcStruct</span>)) =&gt; &#123;</span><br><span class="line">  line._2.getNumFields</span><br><span class="line">&#125;).collect()</span><br></pre></td></tr></table></figure>



<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>toDebugString</p>
<p>参考文献:</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/52328286">Number of Partitions for groupBy Aggregation</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/01_tuner/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/01_tuner/" class="post-title-link" itemprop="url">Java性能调优</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:04" itemprop="dateModified" datetime="2021-01-18T22:05:04+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h1><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>jhat<br>vmstat</p>
<h2 id="测试样例"><a href="#测试样例" class="headerlink" title="测试样例"></a>测试样例</h2><p>新docker container，全新的系统，以纯净的系统Centos为例</p>
<h3 id="安装java"><a href="#安装java" class="headerlink" title="安装java"></a>安装java</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装java8</span></span><br><span class="line">[root@centos ~]# yum install -y java-1.8.0-openjdk*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建deploy用户，用于折腾</span></span><br><span class="line">[root@centos ~]# useradd deploy</span><br><span class="line">[root@centos ~]# su deploy</span><br><span class="line">[root@centos ~]# cd</span><br></pre></td></tr></table></figure>


<h3 id="创建工作目录"><a href="#创建工作目录" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建并切换到工作目录</span></span><br><span class="line">[deploy@centos ~]$ mkdir -p lk-optimization</span><br><span class="line">[deploy@centos ~]$ cd !$</span><br></pre></td></tr></table></figure>
<p>创建package，用于存放java源文件和编译后的class文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[deploy@centos ~]$ mkdir -p src/com/lk/optimization/demo target</span><br><span class="line">[deploy@centos ~]$ vim !$/DemoTest.java</span><br></pre></td></tr></table></figure>
<h3 id="新建Java文件"><a href="#新建Java文件" class="headerlink" title="新建Java文件"></a>新建Java文件</h3><p>//        Thread thread = Thread.currentThread();</p>
<p>//        System.out.println(thread.getName());<br>//        thread.join();<br>        System.out.println(“join over”);</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lk.optimization.demo;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoTest</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] atgs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">		<span class="keyword">new</span> Handler().doHandle();</span><br><span class="line">		Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">				System.out.println(<span class="keyword">this</span>.getName() + <span class="string">&quot; is shutting down ....&quot;</span>);</span><br><span class="line">				&#125;</span><br><span class="line">				&#125;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doHandle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">			String workerName=<span class="string">&quot;worker-&quot;</span>+(i+<span class="number">1</span>);</span><br><span class="line">			<span class="keyword">new</span> Thread(<span class="keyword">new</span> Worker(workerName), <span class="string">&quot;handler-&quot;</span> + i).start();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> String workerName;</span><br><span class="line">	<span class="keyword">private</span> List&lt;String&gt; list;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Worker</span><span class="params">(String workerName)</span></span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.workerName=workerName;</span><br><span class="line">		<span class="keyword">this</span>.list=<span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">1000</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">			System.out.println(workerName+<span class="string">&quot; start!&quot;</span>);</span><br><span class="line">			<span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">				<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">100</span>;i++)&#123;</span><br><span class="line">					list.add(<span class="string">&quot;&quot;</span>+i);</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">if</span>(list.size()&gt;<span class="number">1000</span>)&#123;</span><br><span class="line">					list.clear();</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">try</span> &#123;</span><br><span class="line">					Thread.sleep(<span class="number">100</span>);</span><br><span class="line">					System.out.println(workerName+<span class="string">&quot;: sleep over&quot;</span>);</span><br><span class="line">				&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">					e.printStackTrace();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[deploy@centos ~]$ find src -name &quot;*.java&quot; | xargs javac -d target</span><br><span class="line"></span><br><span class="line">[deploy@centos ~]$ tree</span><br><span class="line">.</span><br><span class="line">├── src</span><br><span class="line">│   └── com</span><br><span class="line">│       └── lk</span><br><span class="line">│           └── optimization</span><br><span class="line">│               └── demo</span><br><span class="line">│                   └── DemoTest.java</span><br><span class="line">└── target</span><br><span class="line">    └── com</span><br><span class="line">        └── lk</span><br><span class="line">            └── optimization</span><br><span class="line">                └── demo</span><br><span class="line">                    ├── DemoTest$1.class</span><br><span class="line">                    ├── DemoTest.class</span><br><span class="line">                    ├── Handler.class</span><br><span class="line">                    └── Worker.class</span><br><span class="line"></span><br><span class="line">10 directories, 5 files</span><br></pre></td></tr></table></figure>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[deploy@centos ~]$ nohup java -cp target  -Xcomp -XX:MaxNewSize=1000000  -XX:MaxHeapSize=2000000 com.lk.optimization.demo.DemoTest &amp;</span><br><span class="line">main</span><br></pre></td></tr></table></figure>


<h2 id="ps-查看进程和线程信息"><a href="#ps-查看进程和线程信息" class="headerlink" title="ps 查看进程和线程信息"></a>ps 查看进程和线程信息</h2><p>ps命令选项:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">********* simple selection *********  ********* selection by list *********</span><br><span class="line">-A all processes                      -C by command name</span><br><span class="line">-N negate selection                   -G by real group ID (supports names)</span><br><span class="line">-a all w/ tty except session leaders  -U by real user ID (supports names)</span><br><span class="line">-d all except session leaders         -g by session OR by effective group name</span><br><span class="line">-e all processes                      -p by process ID</span><br><span class="line">T  all processes on this terminal     -s processes in the sessions given</span><br><span class="line">a  all w/ tty, including other users  -t by tty</span><br><span class="line">g  OBSOLETE -- DO NOT USE             -u by effective user ID (supports names)</span><br><span class="line">r  only running processes             U  processes for specified users</span><br><span class="line">x  processes w/o controlling ttys     t  by tty</span><br><span class="line">*********** output format **********  *********** long options ***********</span><br><span class="line">-o,o user-defined  -f full            --Group --User --pid --cols --ppid</span><br><span class="line">-j,j job control   s  signal          --group --user --sid --rows --info</span><br><span class="line">-O,O preloaded -o  v  virtual memory  --cumulative --format --deselect</span><br><span class="line">-l,l long          u  user-oriented   --sort --tty --forest --version</span><br><span class="line">-F   extra full    X  registers       --heading --no-heading --context</span><br><span class="line">                         ********* misc options *********</span><br><span class="line">-V,V  show version      L  list format codes  f  ASCII art forest</span><br><span class="line">-m,m,-L,-T,H  threads   S  children in sum    -y change -l format</span><br><span class="line">-M,Z  security data     c  true command name  -c scheduling class</span><br><span class="line">-w,w  wide output       n  numeric WCHAN,UID  -H process hierarchy</span><br></pre></td></tr></table></figure>


<p>root用户查看进程信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@centos ~]# ps -ef  | grep -v ps</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 13:16 ?        00:00:00 /usr/sbin/sshd -D</span><br><span class="line">root        14     0  0 13:23 pts/0    00:00:00 /bin/bash</span><br><span class="line">root       421     1  0 13:58 ?        00:00:00 sshd: root@pts/1</span><br><span class="line">root       423   421  0 13:58 pts/1    00:00:00 -bash</span><br><span class="line">root       461     1  0 14:15 ?        00:00:00 sshd: root@pts/2</span><br><span class="line">root       463   461  0 14:15 pts/2    00:00:00 -bash</span><br><span class="line">root       519     1  0 14:16 ?        00:00:00 sshd: root@pts/3</span><br><span class="line">root       521   519  0 14:16 pts/3    00:00:00 -bash</span><br><span class="line">root       785   423  0 14:59 pts/1    00:00:00 su deploy</span><br><span class="line">deploy     786   785  0 14:59 pts/1    00:00:00 bash</span><br><span class="line">deploy    1129   786  0 15:32 pts/1    00:00:02 java -cp target com.lk.optimization.demo.DemoTest</span><br></pre></td></tr></table></figure>
<p>ps 命令</p>
<ul>
<li>-e 显示所有进程信息</li>
<li>-f 显示所有的字段</li>
<li>-l long format</li>
<li>-L 显示NLWP (number of threads) and LWP (thread ID) 显示线程信息</li>
<li>-p 只显示指定的PID</li>
</ul>
<p>字段的解释可以在man页的<code>STANDARD FORMAT SPECIFIERS</code>中查找</p>
<p>默认情况下，ps显示与当前用户相同EUID以及调用了同一个终端的进程。</p>
<ul>
<li>PID是进程ID</li>
<li>TTY为与进程关联的终端名称</li>
<li>TIME为以<code>[dd-]hh:mm:ss</code>格式显示的CPU时间</li>
<li>CMD为执行的名称, 默认不排序</li>
<li>PPID为父进程ID，根据ID可以找到进程的调用关系</li>
</ul>
<p>样例中的进程信息:</p>
<table>
<thead>
<tr>
<th>进程id</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0号进程是根进程</td>
</tr>
<tr>
<td>1</td>
<td>通过sshd发起的ssh连接</td>
</tr>
<tr>
<td>421</td>
<td>ssh连接，用户为root，终端为pts/1，子进程全部这个终端</td>
</tr>
<tr>
<td>423</td>
<td>bash shell</td>
</tr>
<tr>
<td>785</td>
<td>切换deploy账户</td>
</tr>
<tr>
<td>786</td>
<td>deploy账户的bash shell</td>
</tr>
<tr>
<td>1129</td>
<td>java启动进程</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@centos ~]# ps -flL -p 1129</span><br><span class="line">F S UID        PID  PPID   LWP  C NLWP PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD</span><br><span class="line">0 S deploy    1129   786  1129  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">5 S deploy    1129   786  1130  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1131  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1132  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1133  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1134  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1135  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1136  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1137  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1138  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1139  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br><span class="line">1 S deploy    1129   786  1140  0   27  80   0 - 934507 -     15:32 pts/1    00:00:00 java -cp target com.lk.optimization.demo.DemoTest</span><br></pre></td></tr></table></figure>
<h3 id="Process-Format"><a href="#Process-Format" class="headerlink" title="Process Format"></a>Process Format</h3><ol>
<li>F PROCESS FLAGS   1 forked但没有执行 5超级用户权限</li>
<li>S PROCESS STATE CODES<pre><code>D    Uninterruptible sleep (usually IO)
R    Running or runnable (on run queue)
S    Interruptible sleep (waiting for an event to complete)
T    Stopped, either by a job control signal or because it is being traced.
W    paging (not valid since the 2.6.xx kernel)
X    dead (should never be seen)
Z    Defunct (&quot;zombie&quot;) process, terminated but not reaped by its parent.</code></pre>
</li>
<li>lwp (light weight process, or thread) ID 线程ID</li>
<li>C  processor utilization. Currently, this is the integer value of the percent usage over the lifetime of the process.</li>
<li>NLWP 轻量级进程的个数</li>
<li>ni         NI       nice value. This ranges from 19 (nicest) to -20 (not nice to others)</li>
<li>size       SZ       approximate amount of swap space that would be required if the process were to dirty all writable pages and then be swapped out. This number is very rough!</li>
<li>wchan      WCHAN    name of the kernel function in which the process is sleeping, a “-“ if the process is running, or a “*” if the process is multi-threaded and ps is not displaying threads.</li>
</ol>
<h3 id="线程信息"><a href="#线程信息" class="headerlink" title="线程信息"></a>线程信息</h3><p>线程线程的选项:</p>
<ul>
<li>H     Show threads as if they were processes 显示正在处理的线程</li>
<li>-L     Show threads, possibly with LWP and NLWP columns 显示线程</li>
<li>-T     Show threads, possibly with SPID column 显示线程</li>
<li>m     Show threads after processes</li>
<li>-m    Show threads after processes</li>
</ul>
<p>通过上面的例子，可以看出</p>
<p>线程id是1129~1154, 共27个线程<br>实际handler线程和main线程加起来是11个，为什么是27个线程呢</p>
<h2 id="top-查看资源"><a href="#top-查看资源" class="headerlink" title="top 查看资源"></a>top 查看资源</h2><p>以线程模式查看下进程31951的所有线程情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top -Hp 31951</span><br></pre></td></tr></table></figure>
<p>![top-thread](images/20190728100827299_123372753.png =634x)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-H : Threads toggle</span><br><span class="line">            Starts  top with the last remembered ’H’ state reversed.  When this toggle is On, all individual threads will be displayed.  Otherwise, top displays a summation of all threads in a process. 当此开关打开时，将显示所有单个线程。否则，top显示进程中所有线程的总和。</span><br><span class="line"></span><br><span class="line">-p : Monitor PIDs as:  -pN1 -pN2 ...  or  -pN1, N2 [,...]</span><br><span class="line">            Monitor only processes with specified process IDs.  This option can be given up to 20 times, or you can provide a comma delimited list with up  to  20 pids.  Co-mingling both approaches is permitted. This  is  a  command-line  option  only.  And should you wish to return to normal operation, it is not necessary to quit and and restart top  --  just issue the ’&#x3D;’ interactive command.</span><br><span class="line">            打开top后，&#x3D; 可以切换回全部进程</span><br></pre></td></tr></table></figure>


<h2 id="jstack-Java线程栈信息"><a href="#jstack-Java线程栈信息" class="headerlink" title="jstack Java线程栈信息"></a>jstack Java线程栈信息</h2><p>jstack中的线程id为16进制，需要将从top或ps获取的线程id转换为16进制,</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">printf %x &lt;tid&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意:</p>
<ol>
<li>jstack必须和运行的JVM进程是同一个用户</li>
</ol>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">    -F  to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung)</span><br><span class="line">    -m  to print both java and native frames (mixed mode)</span><br><span class="line">    -l  long listing. Prints additional information about locks</span><br><span class="line">    -h or -help to print this help message</span><br></pre></td></tr></table></figure>
<h2 id="虚拟机信息flag"><a href="#虚拟机信息flag" class="headerlink" title="虚拟机信息flag"></a>虚拟机信息flag</h2><p>打印虚拟机所有的参数</p>
<p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html">java 命令文档</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">java -XX:+PrintFlagsFinal -version | grep :</span><br><span class="line">java -XX:+PrintFlagsInitial -version</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">java -XX:+PrintFlagsFinal -version | grep -v :&#x3D;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">The -XX:+PrintFlagsFinal (emphasis on &quot;Final&quot;) option displays what options HotSpot ended up using for running Java code while </span><br><span class="line">-XX:+PrintFlagsInitial (emphasis on &quot;Initial&quot;) displays what options were provided to HotSpot initially, before HotSpot has made its own tweaks.</span><br></pre></td></tr></table></figure>

<h2 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a>jinfo</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">jinfo -flags <span class="variable">$PID</span></span><br><span class="line"></span><br><span class="line">Attaching to process ID 29893, please <span class="built_in">wait</span>...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.  <span class="comment"># 服务器版本的编译器</span></span><br><span class="line">JVM version is 25.232-b09 <span class="comment"># jvm版本</span></span><br><span class="line">Non-default VM flags:</span><br><span class="line">-XX:CICompilerCount=2</span><br><span class="line">-XX:InitialHeapSize=33554432 <span class="comment"># 初始堆大小 33M</span></span><br><span class="line">-XX:MaxHeapSize=524288000 <span class="comment"># 最大堆大小 524M</span></span><br><span class="line">-XX:MaxNewSize=174718976  <span class="comment">#年轻代最大大小 174M</span></span><br><span class="line">-XX:MinHeapDeltaBytes=196608 <span class="comment">#堆自动增加步长最小196K</span></span><br><span class="line">-XX:NewSize=11141120  <span class="comment">#年轻代大小11M</span></span><br><span class="line">-XX:OldSize=22413312 <span class="comment">#老年代大小22M</span></span><br><span class="line">-XX:+UseCompressedClassPointers  <span class="comment">#压缩类指针</span></span><br><span class="line">-XX:+UseCompressedOops <span class="comment">#压缩</span></span><br><span class="line">-XX:+UseParallelGC <span class="comment"># 使用并行回收器</span></span><br><span class="line"></span><br><span class="line">Command line:</span><br></pre></td></tr></table></figure>
<h2 id="jstat查看jvm统计信息和垃圾回收信息"><a href="#jstat查看jvm统计信息和垃圾回收信息" class="headerlink" title="jstat查看jvm统计信息和垃圾回收信息"></a>jstat查看jvm统计信息和垃圾回收信息</h2><p>JVM statistics</p>
<p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jstat.html#BEHHGFAE">jstat docs</a></p>
<p><a target="_blank" rel="noopener" href="https://app.yinxiang.com/shard/s30/nl/6747836/1db66cb0-6a66-4766-84ba-5d5b51df1fd2">jstat 命令使用样例</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">➜ jstat -options</span><br><span class="line">-<span class="class"><span class="keyword">class</span> # <span class="title">classLoader</span>行为的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">compiler</span> #  <span class="title">Java</span> <span class="title">HotSpot</span> <span class="title">VM</span> <span class="title">Just</span>-<span class="title">in</span>-<span class="title">Time</span> <span class="title">compiler</span>行为的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">gc</span> # 垃圾回收堆的统计信息</span></span><br><span class="line"><span class="class">-<span class="title">gccapacity</span> # 每代的大小和容量</span></span><br><span class="line"><span class="class">-<span class="title">gccause</span> # 垃圾收集统计及回收原因</span></span><br><span class="line"><span class="class">-<span class="title">gcmetacapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcnew</span></span></span><br><span class="line"><span class="class">-<span class="title">gcnewcapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcold</span></span></span><br><span class="line"><span class="class">-<span class="title">gcoldcapacity</span></span></span><br><span class="line"><span class="class">-<span class="title">gcutil</span> # <span class="title">gc</span>统计信息汇总，展示<span class="title">gc</span>次数、耗时和各个分区的大小</span></span><br><span class="line"><span class="class">-<span class="title">printcompilation</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line">class: Displays statistics about the behavior of the class loader.</span><br><span class="line">compiler: Displays statistics about the behavior of the Java HotSpot VM Just-in-Time compiler.</span><br><span class="line">gc: Displays statistics about the behavior of the garbage collected heap.</span><br><span class="line">gccapacity: Displays statistics about the capacities of the generations and their corresponding spaces.</span><br><span class="line">gccause: <span class="function">Displays a summary about garbage collection <span class="title">statistics</span> <span class="params">(same as -gcutil)</span>, with the cause of the last and <span class="title">current</span> <span class="params">(when applicable)</span> garbage collection events.</span></span><br><span class="line"><span class="function">gcnew: Displays statistics of the behavior of the new generation.</span></span><br><span class="line"><span class="function">gcnewcapacity: Displays statistics about the sizes of the new generations and its corresponding spaces.</span></span><br><span class="line"><span class="function">gcold: Displays statistics about the behavior of the old generation and metaspace statistics.</span></span><br><span class="line"><span class="function">gcoldcapacity: Displays statistics about the sizes of the old generation.</span></span><br><span class="line"><span class="function">gcmetacapacity: Displays statistics about the sizes of the metaspace.</span></span><br><span class="line"><span class="function">gcutil: Displays a summary about garbage collection statistics.</span></span><br><span class="line"><span class="function">printcompilation: Displays Java HotSpot VM compilation method statistics.</span></span><br></pre></td></tr></table></figure>
<p>GC堆统计</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">jstat -gc <span class="number">12196</span></span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   </span><br><span class="line"><span class="number">512.0</span>  <span class="number">1024.0</span> <span class="number">496.0</span>   <span class="number">0.0</span>   <span class="number">67584.0</span>  <span class="number">38337.9</span>   <span class="number">437248.0</span>   <span class="number">75268.8</span>   <span class="number">83992.0</span> <span class="number">80411.0</span> <span class="number">9496.0</span> <span class="number">8854.4</span>    <span class="number">388</span>    <span class="number">5.643</span>   <span class="number">3</span>      <span class="number">0.390</span>    <span class="number">6.033</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-gc option</span><br><span class="line">Garbage-collected heap statistics.</span><br><span class="line"></span><br><span class="line">S0C: Current survivor space 0 capacity (kB).   #s0区当前容量</span><br><span class="line">S1C: Current survivor space 1 capacity (kB). #s1区当前容量</span><br><span class="line">S0U: Survivor space 0 utilization (kB). #s0区使用量</span><br><span class="line">S1U: Survivor space 1 utilization (kB). #s1区使用量</span><br><span class="line">EC: <span class="function">Current eden space <span class="title">capacity</span> <span class="params">(kB)</span>. #eden区容量</span></span><br><span class="line"><span class="function">EU: Eden space <span class="title">utilization</span> <span class="params">(kB)</span>. #eden区使用量</span></span><br><span class="line"><span class="function">OC: Current old space <span class="title">capacity</span> <span class="params">(kB)</span>. #old区容量</span></span><br><span class="line"><span class="function">OU: Old space <span class="title">utilization</span> <span class="params">(kB)</span>. #old区使用量</span></span><br><span class="line"><span class="function">MC: Metaspace <span class="title">capacity</span> <span class="params">(kB)</span>. #metaspace容量</span></span><br><span class="line"><span class="function">MU: Metacspace <span class="title">utilization</span> <span class="params">(kB)</span>. #metaspace使用量</span></span><br><span class="line"><span class="function">CCSC: Compressed class space <span class="title">capacity</span> <span class="params">(kB)</span>. #压缩类空间容量</span></span><br><span class="line"><span class="function">CCSU: Compressed class space <span class="title">used</span> <span class="params">(kB)</span>. #压缩类空间使用量</span></span><br><span class="line"><span class="function">YGC: Number of young generation garbage collection events.  # YGC次数</span></span><br><span class="line"><span class="function">YGCT: Young generation garbage collection time. #YGC耗时</span></span><br><span class="line"><span class="function">FGC: Number of full GC events. # Full GC次数</span></span><br><span class="line"><span class="function">FGCT: Full garbage collection time. # Full GC耗时</span></span><br><span class="line"><span class="function">GCT: Total garbage collection time. # GC总耗时</span></span><br></pre></td></tr></table></figure>
<p>GC统计</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jstat -gcutil <span class="number">12196</span></span><br><span class="line">  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> <span class="number">96.88</span>   <span class="number">0.00</span>  <span class="number">89.96</span>  <span class="number">17.21</span>  <span class="number">95.74</span>  <span class="number">93.24</span>    <span class="number">388</span>    <span class="number">5.643</span>     <span class="number">3</span>    <span class="number">0.390</span>    <span class="number">6.033</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">-gcutil option</span><br><span class="line">Summary of garbage collection statistics.</span><br><span class="line"></span><br><span class="line">S0: Survivor space <span class="number">0</span> utilization as a percentage of the space<span class="string">&#x27;s current capacity. # s0区使用率</span></span><br><span class="line">S1: Survivor space 1 utilization as a percentage of the space&#x27;s current capacity. # S1区使用率</span><br><span class="line">E: Eden space utilization as a percentage of the space<span class="string">&#x27;s current capacity. # eden区使用率</span></span><br><span class="line">O: Old space utilization as a percentage of the space&#x27;s current capacity. # old区使用率</span><br><span class="line">M: Metaspace utilization as a percentage of the space<span class="string">&#x27;s current capacity. # Metaspace使用率</span></span><br><span class="line"><span class="string">CCS: Compressed class space utilization as a percentage. # 压缩类空间使用率</span></span><br><span class="line"><span class="string">YGC: Number of young generation GC events. # YGC次数</span></span><br><span class="line"><span class="string">YGCT: Young generation garbage collection time. # YGC耗时</span></span><br><span class="line"><span class="string">FGC: Number of full GC events. # Full GC次数</span></span><br><span class="line"><span class="string">FGCT: Full garbage collection time. # Full GC耗时</span></span><br><span class="line"><span class="string">GCT: Total garbage collection time. # GC总耗时</span></span><br></pre></td></tr></table></figure>

<h2 id="堆dump"><a href="#堆dump" class="headerlink" title="堆dump"></a>堆dump</h2><p>full gc前后dump</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -XX:HeapDumpPath=./heap/ -XX:+HeapDumpOnOutOfMemoryError -XX:+HeapDumpAfterFullGC</span><br></pre></td></tr></table></figure>
<p><code>HeapDumpPath</code>: dump path<br><code>HeapDumpOnOutOfMemoryError</code> 内存溢出dump<br><code>HeapDumpAfterFullGC</code>、<code>HeapDumpBeforeFullGC</code> ：Full GC前后dump</p>
<h3 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h3><p>Prints shared object memory maps or heap memory details for a process, core file, or remote debug server. This command is experimental and unsupported.<br>打印进程、核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息</p>
<p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jmap.html#BEHHGFAE">jmap docs</a></p>
<p>jmap -heap <pid></p>
<p>堆的各个分区大小</p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000010648021">堆内存分析-GC日志解读</a></p>
<p>展示堆满的情况下的各个分区大小</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&gt; jmap -heap <span class="number">16186</span></span><br><span class="line">Attaching to process ID <span class="number">16186</span>, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is <span class="number">25.242</span>-b08</span><br><span class="line"></span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Parallel GC with <span class="number">6</span> thread(s)</span><br><span class="line"></span><br><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio         = <span class="number">0</span></span><br><span class="line">   MaxHeapFreeRatio         = <span class="number">100</span></span><br><span class="line">   MaxHeapSize              = <span class="number">522190848</span> (<span class="number">498.</span>0MB)</span><br><span class="line">   NewSize                  = <span class="number">11010048</span> (<span class="number">10.</span>5MB)</span><br><span class="line">   MaxNewSize               = <span class="number">174063616</span> (<span class="number">166.</span>0MB)</span><br><span class="line">   OldSize                  = <span class="number">22544384</span> (<span class="number">21.</span>5MB)</span><br><span class="line">   NewRatio                 = <span class="number">2</span></span><br><span class="line">   SurvivorRatio            = <span class="number">8</span></span><br><span class="line">   MetaspaceSize            = <span class="number">21807104</span> (<span class="number">20.</span>796875MB)</span><br><span class="line">   CompressedClassSpaceSize = <span class="number">1073741824</span> (<span class="number">1024.</span>0MB)</span><br><span class="line">   MaxMetaspaceSize         = <span class="number">17592186044415</span> MB</span><br><span class="line">   G1HeapRegionSize         = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line"></span><br><span class="line">Heap Usage:</span><br><span class="line">PS Young Generation</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity = <span class="number">58720256</span> (<span class="number">56.</span>0MB)</span><br><span class="line">   used     = <span class="number">49193976</span> (<span class="number">46.</span>91503143310547MB)</span><br><span class="line">   free     = <span class="number">9526280</span> (<span class="number">9.</span>084968566894531MB)</span><br><span class="line">   <span class="number">83.7768418448312</span>% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity = <span class="number">57147392</span> (<span class="number">54.</span>5MB)</span><br><span class="line">   used     = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line">   free     = <span class="number">57147392</span> (<span class="number">54.</span>5MB)</span><br><span class="line">   <span class="number">0.0</span>% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity = <span class="number">57671680</span> (<span class="number">55.</span>0MB)</span><br><span class="line">   used     = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line">   free     = <span class="number">57671680</span> (<span class="number">55.</span>0MB)</span><br><span class="line">   <span class="number">0.0</span>% used</span><br><span class="line">PS Old Generation</span><br><span class="line">   capacity = <span class="number">348127232</span> (<span class="number">332.</span>0MB)</span><br><span class="line">   used     = <span class="number">347644232</span> (<span class="number">331.</span>5393753051758MB)</span><br><span class="line">   free     = <span class="number">483000</span> (<span class="number">0.</span>46062469482421875MB)</span><br><span class="line">   <span class="number">99.8612576220409</span>% used</span><br><span class="line"></span><br><span class="line"><span class="number">10381</span> interned Strings occupying <span class="number">935984</span> bytes.</span><br></pre></td></tr></table></figure>

<h2 id="远程监控"><a href="#远程监控" class="headerlink" title="远程监控"></a>远程监控</h2><h3 id="JVM开启远程JMX"><a href="#JVM开启远程JMX" class="headerlink" title="JVM开启远程JMX"></a>JVM开启远程JMX</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启远程调试端口</span></span><br><span class="line">-Dcom.sun.management.jmxremote.port=8777</span><br><span class="line"><span class="comment"># 开启本地调试端口</span></span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port=8777</span><br><span class="line"><span class="comment"># jmx远程服务默认是开启ssl和认证功能功能的，也可以通过jvm选项把这两个功能关闭</span></span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate=<span class="literal">false</span></span><br><span class="line">-Dcom.sun.management.jmxremote.ssl=<span class="literal">false</span></span><br><span class="line"><span class="comment"># jmx默认是通过localhost的ip地址提供RMI服务的，如果要明确指定RMI服务地址或主机名（比如主机有多个接口，想使用非hostname关联的接口）</span></span><br><span class="line">-Djava.rmi.server.hostname=10.242.93.40</span><br></pre></td></tr></table></figure>
<p>例子:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">java \</span><br><span class="line">-Djava.rmi.server.hostname=0.0.0.0 \</span><br><span class="line">-Dcom.sun.management.jmxremote \</span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port=8000 \</span><br><span class="line">-Dcom.sun.management.jmxremote.port=8001 \</span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate=false \</span><br><span class="line">-Dcom.sun.management.jmxremote.ssl=false \</span><br><span class="line">-jar demo-0.0.1-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>
<h3 id="Tomcat-开启远程"><a href="#Tomcat-开启远程" class="headerlink" title="Tomcat 开启远程"></a>Tomcat 开启远程</h3><p>修改<code>catalina.sh</code>,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS&#x3D;&quot;$JAVA_OPTS -Djava.rmi.server.hostname&#x3D;0.0.0.0 </span><br><span class="line">-Dcom.sun.management.jmxremote </span><br><span class="line">-Dcom.sun.management.jmxremote.rmi.port&#x3D;8000 </span><br><span class="line">-Dcom.sun.management.jmxremote.port&#x3D;8001 </span><br><span class="line">-Dcom.sun.management.jmxremote.authenticate&#x3D;false </span><br><span class="line">-Dcom.sun.management.jmxremote.ssl&#x3D;false &quot;</span><br></pre></td></tr></table></figure>
<h3 id="jvisualvm"><a href="#jvisualvm" class="headerlink" title="jvisualvm"></a>jvisualvm</h3><p><a target="_blank" rel="noopener" href="https://visualvm.github.io/pluginscenters.html">插件中心</a></p>
<ul>
<li>新建远程主机0.0.0.0</li>
<li>新建JMX链接: 端口是8001</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://visualvm.github.io/documentation.html">中文文档</a></p>
<h2 id="开启jstatd连接"><a href="#开启jstatd连接" class="headerlink" title="开启jstatd连接"></a>开启jstatd连接</h2><h2 id="BTrace"><a href="#BTrace" class="headerlink" title="BTrace"></a>BTrace</h2><p><a target="_blank" rel="noopener" href="https://github.com/btraceio/btrace">官网</a></p>
<h2 id="JDWP与tomcat远程调试"><a href="#JDWP与tomcat远程调试" class="headerlink" title="JDWP与tomcat远程调试"></a>JDWP与tomcat远程调试</h2><h2 id="Tomcat-监控"><a href="#Tomcat-监控" class="headerlink" title="Tomcat 监控"></a>Tomcat 监控</h2><h3 id="JDWP"><a href="#JDWP" class="headerlink" title="JDWP"></a>JDWP</h3><h3 id="Tomcat-manager"><a href="#Tomcat-manager" class="headerlink" title="Tomcat-manager"></a>Tomcat-manager</h3><h3 id="psi-probe监控"><a href="#psi-probe监控" class="headerlink" title="psi-probe监控"></a>psi-probe监控</h3><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><h3 id="ngx-http-stub-status监控连接信息"><a href="#ngx-http-stub-status监控连接信息" class="headerlink" title="ngx_http_stub_status监控连接信息"></a>ngx_http_stub_status监控连接信息</h3><h3 id="ngxtop监控请求信息"><a href="#ngxtop监控请求信息" class="headerlink" title="ngxtop监控请求信息"></a>ngxtop监控请求信息</h3><h2 id="字节码"><a href="#字节码" class="headerlink" title="字节码"></a>字节码</h2><p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html#jvms-4.4">常量池官方文档</a></p>
<h3 id="深入解析String-intern"><a href="#深入解析String-intern" class="headerlink" title="深入解析String#intern"></a>深入解析String#intern</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/goldenfish1919/article/details/80410349">深入解析String.intern</a><br><a target="_blank" rel="noopener" href="https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html">原文出处: 深入解析String.intern</a></p>
<p>字符串的常量池</p>
<p>常量池在哪里？</p>
<ul>
<li>Jdk1.6及之前： 有永久代, 常量池在方法区</li>
<li>Jdk1.7：       有永久代，但已经逐步“去永久代”，常量池在堆</li>
<li>Jdk1.8及之后： 无永久代，常量池在元空间</li>
</ul>
<h3 id="String去重"><a href="#String去重" class="headerlink" title="String去重"></a>String去重</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/goldenfish1919/article/details/20233263">String Deduplication in G1</a></p>
<p>-XX:+UseStringDeduplication   开启String去重<br>-XX:+PrintStringDeduplicationStatistics 打印详细的去重统计<br>-XX:StringDeduplicationAgeThreshold=15 达到这个年龄的String对象才会去重</p>
<h2 id="重用代码优化方法"><a href="#重用代码优化方法" class="headerlink" title="重用代码优化方法"></a>重用代码优化方法</h2><ul>
<li>尽量重用对象，不要循环创建对象，比如：for循环字符串拼接</li>
<li>容器类初始化的时候指定长度</li>
<li>ArrayList随机遍历快，LinkedList添加删除快</li>
<li>集合遍历尽量减少重复计算  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;collection.size();i++) <span class="comment">// collection.size() 提取成常量</span></span><br></pre></td></tr></table></figure></li>
<li>使用Entry遍历Map  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(Map.Entry&lt;String,String&gt; entry:map.entrySet())&#123;</span><br><span class="line">    String key=entry.getKey();</span><br><span class="line">    String value=entry.getValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>大数组复制用<code>System.arrayCopy()</code></li>
<li>尽量使用基本类型而不是包装类型  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Integer i=<span class="number">100</span>;</span><br><span class="line">System.out.println(i);</span><br></pre></td></tr></table></figure>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack&#x3D;2, locals&#x3D;2, args_size&#x3D;1</span><br><span class="line">     0: bipush        100                 &#x2F;&#x2F; 将100压入栈</span><br><span class="line">     2: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">     5: astore_1</span><br><span class="line">     6: getstatic     #3                  &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;</span><br><span class="line">     9: aload_1</span><br><span class="line">    10: invokevirtual #4                  &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;Object;)V</span><br><span class="line">    13: return</span><br></pre></td></tr></table></figure>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Integer i1=<span class="number">100</span>;</span><br><span class="line">Integer i2=<span class="number">100</span>;</span><br><span class="line">System.out.println(i1==i2); <span class="comment">// true</span></span><br></pre></td></tr></table></figure>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack&#x3D;3, locals&#x3D;3, args_size&#x3D;1</span><br><span class="line">     0: bipush        100</span><br><span class="line">     2: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">     5: astore_1</span><br><span class="line">     6: bipush        100</span><br><span class="line">     8: invokestatic  #2                  &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer;</span><br><span class="line">    11: astore_2</span><br><span class="line">    12: getstatic     #3                  &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;</span><br><span class="line">    15: aload_1</span><br><span class="line">    16: aload_2</span><br><span class="line">    17: if_acmpne     24</span><br><span class="line">    20: iconst_1</span><br><span class="line">    21: goto          25</span><br><span class="line">    24: iconst_0</span><br><span class="line">    25: invokevirtual #5                  &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Z)V</span><br><span class="line">    28: return</span><br></pre></td></tr></table></figure>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Integer i1=<span class="number">1000</span>;</span><br><span class="line">Integer i2=<span class="number">1000</span>;</span><br><span class="line">System.out.println(i1==i2);  <span class="comment">// false</span></span><br></pre></td></tr></table></figure>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Code:</span><br><span class="line">  stack=3, locals=3, args_size=1</span><br><span class="line">     0: sipush        1000</span><br><span class="line">     3: invokestatic  #2                  // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;</span><br><span class="line">     6: astore_1</span><br><span class="line">     7: sipush        1000</span><br><span class="line">    10: invokestatic  #2                  // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;</span><br><span class="line">    13: astore_2</span><br><span class="line">    14: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;</span><br><span class="line">    17: aload_1</span><br><span class="line">    18: aload_2</span><br><span class="line">    19: if_acmpne     26</span><br><span class="line">    22: iconst_1</span><br><span class="line">    23: goto          27</span><br><span class="line">    26: iconst_0</span><br><span class="line">    27: invokevirtual #5                  // Method java/io/PrintStream.println:(Z)V</span><br><span class="line">    30: return</span><br></pre></td></tr></table></figure>
  Integer.valueOf 内部有缓存，如果大于-128且小于<code>java.lang.Integer.IntegerCache.high</code>(默认值是127)，则返回缓存</li>
<li>尽量使用非同步的容器，vector和ArrayList</li>
<li>尽量减少同步作用范围，synchronized方法vs代码块  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">f1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;f1&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">f2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;f4&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">f3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;f3&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">f4</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (TestPrimaryType.class) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;f4&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>使用ThreadLocal缓存线程不安全对象，simpleDateFormat</li>
<li>尽量使用延迟加载，懒惰单例模式  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPrimaryType</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">TestPrimaryType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPrimaryTypeHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> TestPrimaryType instance = <span class="keyword">new</span> TestPrimaryType();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    ** 调用这个方法时，发生对TestPrimaryTypeHolder的引用，才创建instance对象</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> TestPrimaryType <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> TestPrimaryTypeHolder.instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>尽量减少使用反射，加缓存</li>
<li>尽量使用连接池、线程池、对象池、缓存</li>
<li>及时释放资源，I/O流、socket、数据库连接</li>
<li>慎用异常，不要用抛异常来标示正常的业务逻辑</li>
<li>String操作尽量少用正则表达式  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">replace VS replaceAll: 尽量用replace</span><br><span class="line">split</span><br></pre></td></tr></table></figure></li>
<li>日志输出注意使用不同的级别</li>
<li>日志中参数拼接使用占位符  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log.info(“orderId:”+orgerId); &#x2F;&#x2F; 不推荐</span><br><span class="line">log.info(“orderId:&#123;&#125;”,orgerId); &#x2F;&#x2F;推荐</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/02_CMS_GC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/02_CMS_GC/" class="post-title-link" itemprop="url">CMS GC</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:04" itemprop="dateModified" datetime="2021-01-18T22:05:04+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="CMS-GC"><a href="#CMS-GC" class="headerlink" title="CMS GC"></a>CMS GC</h1><h2 id="垃圾回收器组合"><a href="#垃圾回收器组合" class="headerlink" title="垃圾回收器组合"></a>垃圾回收器组合</h2><table>
<thead>
<tr>
<th>Young 年轻代</th>
<th>Tenured 老生代</th>
<th>JVM options</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Serial</td>
<td>Serial</td>
<td>-XX:+UseSerialGC</td>
<td>单线程回收，全程STW</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>Serial</td>
<td>-XX:+UseParallelGC -XX:-UseParallelOldGC</td>
<td>年轻代并行，老年代串行，全程STW</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>Parallel Old</td>
<td>-XX:+UseParallelGC -XX:+UseParallelOldGC</td>
<td>多线程回收，全程STW</td>
</tr>
<tr>
<td>Parallel New或Serial</td>
<td>CMS</td>
<td>-XX:+UseParNewGC -XX:+UseConcMarkSweepGC</td>
<td>年轻代并行或串行，老年代并发，只有某个阶段会STW</td>
</tr>
<tr>
<td>G1</td>
<td>G1</td>
<td>-XX:+UseG1GC</td>
<td>并发回收， 某个阶段会STW</td>
</tr>
</tbody></table>
<p>垃圾回收器从线程运行情况分类有三种：</p>
<ul>
<li><code>串行回收</code>： Serial回收器，单线程回收，全程STW；</li>
<li><code>并行回收</code>： 名称以Parallel开头的回收器，多线程回收，全程STW;</li>
<li><code>并发回收</code>： CMS与G1，多线程分阶段回收，只有某阶段会STW；</li>
</ul>
<p><img src="_v_images/20200716125314502_95470953.png"></p>
<h2 id="Minor-GC、Major-GC与Full-GC"><a href="#Minor-GC、Major-GC与Full-GC" class="headerlink" title="Minor GC、Major GC与Full GC"></a>Minor GC、Major GC与Full GC</h2><p>分代回收中:</p>
<p>Minor GC清理年轻代(Young GC)，除了G1 GC外，都会STW<br>Major GC清理老年代(Tenured GC)<br>Full GC清理整个堆</p>
<p>Minor GC触发条件:</p>
<p>Major GC触发条件:</p>
<p>Full GC触发条件:</p>
<ul>
<li>调用<code>System.gc</code>时，系统建议执行Full GC，不是必然执行</li>
<li>老年代空间不足</li>
<li>方法区空间不足</li>
<li>通过Minor GC后，进入老年代的平均大小 &gt; 老年代的可用内存</li>
<li>由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。即老年代无法存放新年代过度到老年代的对象的时候，会触发Full GC</li>
<li>手动触发Full GC: jmap -histo:live <pid> 或者 jmap -dump:live,file=dump_001.bin PID,然后删掉dump_001.bin文件</li>
</ul>
<h2 id="CMS垃圾收集器-Concurrent-Mark-Sweep-CMS-Collector"><a href="#CMS垃圾收集器-Concurrent-Mark-Sweep-CMS-Collector" class="headerlink" title="CMS垃圾收集器 Concurrent Mark Sweep(CMS) Collector"></a>CMS垃圾收集器 Concurrent Mark Sweep(CMS) Collector</h2><p>并发，低停顿<br>特别是拥有大量长期数据（大老年代），多核心，低停顿</p>
<p>启用<code>-XX:+UseConcMarkSweepGC</code></p>
<p>CMS收集器是分代的。 因此，minor GC和major GC都会发生。 CMS收集器尝试通过使用单独的垃圾收集器线程在执行应用程序线程的同时跟踪可访问对象，来减少由于major GC而导致的暂停时间。 在每个major收集周期中，CMS收集器会在收集开始时暂停所有应用程序线程一小段时间，然后收集中间再暂停一次。 第二次停顿往往是两个停顿中较长的一个。 在两个暂停期间都使用多个线程来执行收集工作。 收集的其余部分（包括大部分活动对象的跟踪和无法访问对象的清除）是通过与应用程序同时运行的一个或多个垃圾收集器线程来完成的。minor GC可以与正在进行的主要周期交错，并在一个 类似于并行收集器的方式（特别是在次要收集期间停止了应用程序线程）。</p>
<p><strong>并发模式失效Concurrent Mode Failure</strong></p>
<ol>
<li>如果CMS收集器在老年代填满之前无法完成回收无法访问的对象，</li>
<li>如果老年代的可用空闲空间块(出现了碎片)无法满足分配，则暂停应用程序，并使所有应用程序线程已停止。 无法同时完成收集的情况称为并发模式失败，代表需要调整CMS收集器参数。</li>
<li>如果并发收集被显式垃圾收集（<code>System.gc()</code>）中断</li>
<li>为提供诊断工具信息所需的垃圾收集中断了，则将报告并发模式中断。</li>
</ol>
<blockquote>
<p>if the CMS collector is unable to finish reclaiming the unreachable objects before the tenured generation fills up, or if an allocation cannot be satisfied with the available free space blocks in the tenured generation, then the application is paused and the collection is completed with all the application threads stopped. The inability to complete a collection concurrently is referred to as concurrent mode failure and indicates the need to adjust the CMS collector parameters. If a concurrent collection is interrupted by an explicit garbage collection (System.gc()) or for a garbage collection needed to provide information for diagnostic tools, then a concurrent mode interruption is reported.</p>
</blockquote>
<p><strong>Excessive GC Time and OutOfMemoryError</strong></p>
<p>太多的时间花在gc上: 如果总时间的98%花在GC上，并且回收不到2%的堆空间，将抛出<code>OutOfMemoryError</code></p>
<p>禁用命令行: <code>-XX:-UseGCOverheadLimit</code></p>
<p><strong>浮动垃圾Floating Garbage</strong></p>
<p>边收集边运行，出现浮动垃圾</p>
<h2 id="CMS垃圾回收特点"><a href="#CMS垃圾回收特点" class="headerlink" title="CMS垃圾回收特点"></a>CMS垃圾回收特点</h2><p>CMS只会回收老年代和永久代（1.8开始为元数据区，需要设置CMSClassUnloadingEnabled），不会收集年轻代；</p>
<p>CMS是一种预处理垃圾回收器，它不能等到老年代内存用尽时回收，需要在内存用尽前，完成回收操作，否则会导致并发回收失败(并发回收降级)；<br>所以CMS垃圾回收器开始执行回收操作，有一个触发阈值(<code>参数名称</code>)，默认是老年代或永久代达到92%；</p>
<h2 id="CMS垃圾收集器步骤"><a href="#CMS垃圾收集器步骤" class="headerlink" title="CMS垃圾收集器步骤"></a>CMS垃圾收集器步骤</h2><p>CMS 处理过程有七个步骤：</p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>是否STW</th>
<th>详情</th>
</tr>
</thead>
<tbody><tr>
<td>初始标记(CMS-initial-mark)</td>
<td>会导致STW</td>
<td>标记GCRoot和被年轻代引用的老年代对象</td>
</tr>
<tr>
<td>并发标记(CMS-concurrent-mark)</td>
<td>与用户线程同时运行；</td>
<td>扫描整个老年代，将引用关系变化的对象置为dirty</td>
</tr>
<tr>
<td>预清理（CMS-concurrent-preclean）</td>
<td>与用户线程同时运行；</td>
<td></td>
</tr>
<tr>
<td>可被终止的预清理（CMS-concurrent-abortable-preclean）</td>
<td>与用户线程同时运行；</td>
<td></td>
</tr>
<tr>
<td>重新标记(CMS-remark)</td>
<td>会导致STW</td>
<td></td>
</tr>
<tr>
<td>并发清除(CMS-concurrent-sweep)</td>
<td>与用户线程同时运行；</td>
<td></td>
</tr>
<tr>
<td>并发重置状态等待下次CMS的触发(CMS-concurrent-reset)</td>
<td>与用户线程同时运行；</td>
<td></td>
</tr>
</tbody></table>
<p>CMS运行流程图如下所示：</p>
<p><img src="_v_images/20200208214054081_1122407096.png"></p>
<h3 id="Phase-1-Initial-Mark（初始化标记）"><a href="#Phase-1-Initial-Mark（初始化标记）" class="headerlink" title="Phase 1: Initial Mark（初始化标记）"></a>Phase 1: Initial Mark（初始化标记）</h3><p>这是CMS中两次stop-the-world事件中的一次。这一步的作用是标记存活的对象，有两部分：</p>
<ol>
<li>从GC Roots遍历可直达的老年代对象，下图中1；</li>
<li>遍历被新生代存活对象所引用的老年代对象，如下图节点2、3；</li>
</ol>
<ul>
<li>支持单线程或并发标记</li>
<li>发生STW</li>
</ul>
<p><img src="_v_images/20200208214053938_762753439.png"></p>
<p>在Java语言里，可作为GC Roots对象的包括如下几种：</p>
<ol>
<li>虚拟机栈(栈桢中的本地变量表)中的引用的对象 ；</li>
<li>方法区中的类静态属性引用的对象 ；</li>
<li>方法区中的常量引用的对象 ；</li>
<li>本地方法栈中JNI的引用的对象；</li>
</ol>
<blockquote>
<p>ps：为了加快此阶段处理速度，减少停顿时间:</p>
<ul>
<li>开启并行化初始标记: <code>-XX:+CMSParallelInitialMarkEnabled</code></li>
<li>同时调大并行标记的线程数，线程数不要超过cpu的核数: <code>-XX:ConcGCThreads=4</code></li>
</ul>
</blockquote>
<h3 id="Phase-2-Concurrent-Mark（并发标记）"><a href="#Phase-2-Concurrent-Mark（并发标记）" class="headerlink" title="Phase 2: Concurrent Mark（并发标记）"></a>Phase 2: Concurrent Mark（并发标记）</h3><p>通过遍历第一个阶段（Initial Mark）标记出来的存活对象，继续递归遍历老年代，并标记可直接或间接到达的所有老年代存活对象。</p>
<p>由于应用线程和GC线程是并发执行的，因此可能产生新的对象或对象关系发生变化，例如：</p>
<ul>
<li>新生代的对象晋升到老年代；</li>
<li>直接在老年代分配对象；</li>
<li>老年代对象的引用关系发生变更；</li>
<li>等等。</li>
</ul>
<p>对于这些对象，需要重新标记以防止被遗漏。为了提高重新标记的效率，本阶段只会把发生变化的对象所在的Card标识为Dirty，这样后续就只需要扫描这些Dirty Card的对象，从而避免扫描整个老年代。</p>
<p>并发标记阶段只负责将引用发生改变的Card标记为Dirty状态，不负责处理；</p>
<p>如下图所示，也就是节点1、2、3，最终找到了节点4和5。并不是老年代的所有存活对象都会被标记，因为标记的同时应用程序会改变一些对象的引用等。</p>
<p><img src="_v_images/20200208214053815_1244593749.png"></p>
<p>这个阶段因为是并发的, 容易导致concurrent mode failure</p>
<h3 id="Phase-3-Concurrent-Preclean（并发预清理）"><a href="#Phase-3-Concurrent-Preclean（并发预清理）" class="headerlink" title="Phase 3: Concurrent Preclean（并发预清理）"></a>Phase 3: Concurrent Preclean（并发预清理）</h3><p>在并发预清洗阶段，将会重新扫描前一个阶段标记的Dirty对象，并标记被Dirty对象直接或间接引用的对象，然后清除Card标识。</p>
<p>前一个阶段已经说明，不能标记出老年代全部的存活对象，是因为标记的同时应用程序会改变一些对象引用，这个阶段就是用来处理前一个阶段因为引用关系改变导致没有标记到的存活对象的，它会扫描所有标记为Direty的Card</p>
<p>如下图所示，在并发清理阶段，节点3的引用指向了6；则会把节点3的card标记为Dirty；</p>
<p><img src="_v_images/20200208214053691_1851185723.png"></p>
<p>最后将6标记为存活,如下图所示：</p>
<p><img src="_v_images/20200208214053551_1708409185.png"></p>
<h3 id="Phase-4-Concurrent-Abortable-Preclean（可中止的并发预清理）"><a href="#Phase-4-Concurrent-Abortable-Preclean（可中止的并发预清理）" class="headerlink" title="Phase 4: Concurrent Abortable Preclean（可中止的并发预清理）"></a>Phase 4: Concurrent Abortable Preclean（可中止的并发预清理）</h3><p>本阶段尽可能承担更多的并发预处理工作，从而减轻在Final Remark阶段的stop-the-world。</p>
<p>这个阶段尝试着去承担下一个阶段Final Remark阶段足够多的工作。这个阶段持续的时间依赖好多的因素，由于这个阶段是重复的做相同的事情直到发生abort的条件（比如：重复的次数、多少量的工作、持续的时间等等）之一才会停止。</p>
<p>ps:此阶段最大持续时间为5秒，之所以可以持续5秒，另外一个原因也是为了期待这5秒内能够发生一次ygc，清理年轻代的引用，是的下个阶段的重新标记阶段，扫描年轻代指向老年代的引用的时间减少；</p>
<p>在该阶段，主要循环的做两件事：</p>
<ul>
<li>处理 From 和 To 区的对象，标记可达的老年代对象；</li>
<li>和上一个阶段一样，扫描处理Dirty Card中的对象。</li>
</ul>
<p>具体执行多久，取决于许多因素，满足其中一个条件将会中止运行：</p>
<ul>
<li>执行循环次数达到了阈值；</li>
<li>执行时间达到了阈值；</li>
<li>新生代Eden区的内存使用率达到了阈值。</li>
</ul>
<h3 id="Phase-5-Final-Remark（重新标记）"><a href="#Phase-5-Final-Remark（重新标记）" class="headerlink" title="Phase 5: Final Remark（重新标记）"></a>Phase 5: Final Remark（重新标记）</h3><p>预清理阶段也是并发执行的，并不一定是所有存活对象都会被标记，因为在并发标记的过程中对象及其引用关系还在不断变化中。</p>
<p>因此，需要有一个stop-the-world的阶段来完成最后的标记工作，这就是重新标记阶段（CMS标记阶段的最后一个阶段）。主要目的是重新扫描之前并发处理阶段的所有残留更新对象。</p>
<p>主要工作：</p>
<p>遍历新生代对象，重新标记；（新生代会被分块，多线程扫描）<br>根据GC Roots，重新标记；<br>遍历老年代的Dirty Card，重新标记。这里的Dirty Card，大部分已经在Preclean阶段被处理过了。</p>
<p>这个阶段会导致第二次stop the world，该阶段的任务是完成标记整个年老代的所有的存活对象。</p>
<p>这个阶段，重新标记的内存范围是整个堆，包含young_gen和old_gen。为什么要扫描新生代呢，因为对于老年代中的对象，如果被新生代中的对象引用，那么就会被视为存活对象，即使新生代的对象已经不可达了，也会使用这些不可达的对象当做CMS的“gc root”，来扫描老年代； 因此对于老年代来说，引用了老年代中对象的新生代的对象，也会被老年代视作“GC ROOTS”:<br>当此阶段耗时较长的时候，可以加入参数<code>-XX:+CMSScavengeBeforeRemark</code>，在重新标记之前，先执行一次ygc，回收掉年轻代的对象无用的对象，并将对象放入survivor区或晋升到老年代，这样再进行年轻代扫描时，只需要扫描幸存区的对象即可，一般survivor区非常小，这大大减少了扫描时间</p>
<p>由于之前的预处理阶段是与用户线程并发执行的，这时候可能年轻代的对象对老年代的引用已经发生了很多改变，这个时候，remark阶段要花很多时间处理这些改变，会导致很长stop the word，所以通常CMS尽量运行Final Remark阶段在年轻代是足够干净的时候。</p>
<p>另外，还可以开启并行收集：<code>-XX:+CMSParallelRemarkEnabled</code></p>
<h3 id="Phase-6-Concurrent-Sweep（并发清理"><a href="#Phase-6-Concurrent-Sweep（并发清理" class="headerlink" title="Phase 6: Concurrent Sweep（并发清理"></a>Phase 6: Concurrent Sweep（并发清理</h3><p>并发清理阶段，主要工作是清理所有未被标记的死亡对象，回收被占用的空间。</p>
<p><img src="_v_images/20200209233712414_1450669107.png"></p>
<p>通过以上5个阶段的标记，老年代所有存活的对象已经被标记并且现在要通过Garbage Collector采用清扫的方式回收那些不能用的对象了。</p>
<p>这个阶段主要是清除那些没有标记的对象并且回收空间；</p>
<p>由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。</p>
<h3 id="步骤7-并发重置"><a href="#步骤7-并发重置" class="headerlink" title="步骤7: 并发重置"></a>步骤7: 并发重置</h3><p>并发重置阶段，将清理并恢复在CMS GC过程中的各种状态，重新初始化CMS相关数据结构，为下一个垃圾收集周期做好准备。</p>
<p>这个阶段并发执行，重新设置CMS算法内部的数据结构，准备下一个CMS生命周期的使用。</p>
<h2 id="CMS日志分析"><a href="#CMS日志分析" class="headerlink" title="CMS日志分析"></a>CMS日志分析</h2><p>下面就是该参数设置打印出来的gc信息，一些非关键的信息已经去掉，如时间：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//第一步 初始标记 这一步会停顿*</span></span><br><span class="line">[GC (CMS Initial Mark) [<span class="number">1</span> CMS-initial-mark: 299570K(307200K)] 323315K(491520K), <span class="number">0.0026208</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.00</span> secs]</span><br><span class="line">vmop [threads: total initially_running wait_to_block] [time: spin block sync cleanup vmop] page_trap_count</span><br><span class="line"><span class="number">0.345</span>: CMS_Initial_Mark [ <span class="number">10</span> <span class="number">0</span> <span class="number">1</span> ] [ <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> ] <span class="number">0</span></span><br><span class="line">Total time <span class="keyword">for</span> which application threads were stopped: <span class="number">0.0028494</span> seconds</span><br><span class="line"></span><br><span class="line"><span class="comment">//第二步 并发标记</span></span><br><span class="line">[CMS-concurrent-mark-start]</span><br><span class="line">[CMS-concurrent-mark: <span class="number">0.012</span>/<span class="number">0.012</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.01</span> secs]</span><br><span class="line"></span><br><span class="line"><span class="comment">//第三步 并发预清理</span></span><br><span class="line">[CMS-concurrent-preclean-start]</span><br><span class="line">[CMS-concurrent-preclean: <span class="number">0.001</span>/<span class="number">0.001</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.00</span> secs]</span><br><span class="line"></span><br><span class="line"><span class="comment">//第四步 可被终止的并发预清理</span></span><br><span class="line">[CMS-concurrent-abortable-preclean-start]</span><br><span class="line">[CMS-concurrent-abortable-preclean: <span class="number">0.000</span>/<span class="number">0.000</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.00</span> secs]</span><br><span class="line"></span><br><span class="line"><span class="comment">//第五步 最终重新标记</span></span><br><span class="line">[GC (CMS Final Remark) [YG occupancy: 72704 K (184320 K)][Rescan (parallel) , 0.0009069 secs][weak refs processing, 0.0000083 secs][class unloading, 0.0002626 secs][scrub symbol table, 0.0003789 secs][scrub string table, 0.0001326 secs][1 CMS-remark: 299570K(307200K)] 372275K(491520K), 0.0017842 secs] [Times: user=0.05 sys=0.00, real=0.00 secs]</span><br><span class="line">vmop [threads: total initially_running wait_to_block] [time: spin block sync cleanup vmop] page_trap_count</span><br><span class="line"><span class="number">0.360</span>: CMS_Final_Remark [ <span class="number">10</span> <span class="number">0</span> <span class="number">1</span> ] [ <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> ] <span class="number">0</span></span><br><span class="line">Total time <span class="keyword">for</span> which application threads were stopped: <span class="number">0.0018800</span> seconds</span><br><span class="line"></span><br><span class="line"><span class="comment">//第六步 并发清理</span></span><br><span class="line">[CMS-concurrent-sweep-start]</span><br><span class="line">[CMS-concurrent-sweep: <span class="number">0.007</span>/<span class="number">0.007</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.01</span> secs]</span><br><span class="line"></span><br><span class="line"><span class="comment">//第七步 并发重置</span></span><br><span class="line">[CMS-concurrent-reset-start]</span><br><span class="line">[CMS-concurrent-reset: <span class="number">0.002</span>/<span class="number">0.002</span> secs] [Times: user=<span class="number">0.00</span> sys=<span class="number">0.00</span>, real=<span class="number">0.00</span> secs]</span><br></pre></td></tr></table></figure>
<p>输出GC详情，需要添加 <code>-verbose:gc</code> 和 <code>-XX:+PrintGCDetails</code> 参数</p>
<p><code>CMS-initial-mark</code>标示着并发收集周期的开始<br><code>CMS-concurrent-mark</code>标示着并发标记阶段的结束<br><code>CMS-concurrent-sweep</code>标志着并发清理阶段的结束<br><code>CMS-concurrent-preclean</code>标志着预清理阶段，预清理代表着在准备CMS-remark阶段可以并发处理的工作<br><code>CMS-concurrent-reset</code>是最后阶段，为下一次并发收集做准备</p>
<blockquote>
<p>CMS-initial-mark indicates the start of the concurrent collection cycle,<br>CMS-concurrent-mark indicates the end of the concurrent marking phase,<br>and CMS-concurrent-sweep marks the end of the concurrent sweeping phase.<br>Not discussed previously is the precleaning phase indicated by CMS-concurrent-preclean.<br>Precleaning represents work that can be done concurrently in preparation for the remark phase CMS-remark.<br>The final phase is indicated by CMS-concurrent-reset and is in preparation for the next concurrent collection.</p>
</blockquote>
<h2 id="调优参数与启用参数"><a href="#调优参数与启用参数" class="headerlink" title="调优参数与启用参数"></a>调优参数与启用参数</h2><p>下面抓取一下gc信息，来进行详细分析，首先将jvm中加入以下运行参数：</p>
<ul>
<li>-XX:+PrintCommandLineFlags [0]</li>
<li>-XX:+UseConcMarkSweepGC [1]</li>
<li>-XX:+UseCMSInitiatingOccupancyOnly [2]</li>
<li>-XX:CMSInitiatingOccupancyFraction=80 [3]</li>
<li>-XX:+CMSClassUnloadingEnabled [4]</li>
<li>-XX:+UseParNewGC [5]</li>
<li>-XX:+CMSParallelRemarkEnabled [6]</li>
<li>-XX:+CMSScavengeBeforeRemark [7]</li>
<li>-XX:+UseCMSCompactAtFullCollection [8]</li>
<li>-XX:CMSFullGCsBeforeCompaction=0 [9]</li>
<li>-XX:+CMSConcurrentMTEnabled [10]</li>
<li>-XX:ConcGCThreads=4 [11]</li>
<li>-XX:+ExplicitGCInvokesConcurrent [12]</li>
<li>-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses [13]</li>
<li>-XX:+CMSParallelInitialMarkEnabled [14]</li>
<li>-XX:+PrintGCDetails [15]</li>
<li>-XX:+PrintGCCause [16]</li>
<li>-XX:+PrintGCTimeStamps [17]</li>
<li>-XX:+PrintGCDateStamps [18]</li>
<li>-Xloggc:../logs/gc.log [19]</li>
<li>-XX:+HeapDumpOnOutOfMemoryError [20]</li>
<li>-XX:HeapDumpPath=../dump [21]</li>
</ul>
<p>先来介绍下下面几个参数的作用：</p>
<p>[0] 打印出启动参数行</p>
<p>[1] 参数指定使用CMS垃圾回收器；</p>
<p>[2]、[3] 参数指定CMS垃圾回收器在老年代达到80%的时候开始工作，如果不指定那么默认的值为92%；</p>
<p>[4] 开启永久代（jdk1.8以下版本）或元数据区（jdk1.8及其以上版本）收集，如果没有设置这个标志，一旦永久代或元数据区间也会尝试进行垃圾回收，但是收集不会是并行的，而再一次进行Full GC；</p>
<p>[5] 使用CMS时默认这个参数就是打开的，不需要配置，CMS只回收老年代，年轻代只能配合Parallel New或Serial回收器；</p>
<p>[6] 减少Remark阶段暂停的时间，启用并行Remark，如果Remark阶段暂停时间长，可以启用这个参数</p>
<p>[7] 如果Remark阶段暂停时间太长，可以启用这个参数，在Remark执行之前，先做一次ygc。因为这个阶段，年轻代也是CMS的gcroot，CMS会扫描年轻代指向老年代对象的引用，如果年轻代有大量引用需要被扫描，会让Remark阶段耗时增加；</p>
<p>[8]、[9]两个参数是针对CMS垃圾回收器碎片做优化的，CMS是不会移动内存的， 运行时间长了，会产生很多内存碎片， 导致没有一段连续区域可以存放大对象，出现”promotion failed”、”concurrent mode failure”, 导致fullgc，启用UseCMSCompactAtFullCollection 在FULL GC的时候， 对年老代的内存进行压缩。-XX:CMSFullGCsBeforeCompaction=0 则是代表多少次FGC后对老年代做压缩操作，默认值为0，代表每次都压缩, 把对象移动到内存的最左边，可能会影响性能,但是可以消除碎片；</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">106.641</span>: [GC <span class="number">106.641</span>: [ParNew (promotion failed): 14784K-&gt;14784K(14784K), <span class="number">0.0370328</span> secs]<span class="number">106.678</span>: [CMS106<span class="number">.715</span>: [CMS-concurrent-mark: <span class="number">0.065</span>/<span class="number">0.103</span> secs] [Times: user=<span class="number">0.17</span> sys=<span class="number">0.00</span>, real=<span class="number">0.11</span> secs]</span><br><span class="line"></span><br><span class="line">(concurrent mode failure): 41568K-&gt;27787K(49152K), <span class="number">0.2128504</span> secs] 52402K-&gt;27787K(63936K), [CMS Perm : 2086K-&gt;2086K(12288K)], <span class="number">0.2499776</span> secs] [Times: user=<span class="number">0.28</span> sys=<span class="number">0.00</span>, real=<span class="number">0.25</span> secs]</span><br></pre></td></tr></table></figure>
<p>[11] 定义并发CMS过程运行时的线程数。比如value=4意味着CMS周期的所有阶段都以4个线程来执行。尽管更多的线程会加快并发CMS过程，但其也会带来额外的同步开销。因此，对于特定的应用程序，应该通过测试来判断增加CMS线程数是否真的能够带来性能的提升。如果未设置这个参数，JVM会根据并行收集器中的-XX:ParallelGCThreads参数的值来计算出默认的并行CMS线程数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ParallelGCThreads = (ncpus &lt;=<span class="number">8</span> ? ncpus : <span class="number">8</span>+(ncpus-<span class="number">8</span>)*<span class="number">5</span>/<span class="number">8</span>) ，ncpus为cpu个数，</span><br><span class="line">ConcGCThreads =(ParallelGCThreads + <span class="number">3</span>)/<span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>这个参数一般不要自己设置，使用默认就好，除非发现默认的参数有调整的必要；<br>[12]、[13]开启foreground CMS GC，CMS gc 有两种模式，background和foreground，正常的CMS gc使用background模式，就是我们平时说的CMS gc；当并发收集失败或者调用了System.gc()的时候，就会导致一次full gc，这个fullgc是不是CMS回收，而是Serial单线程回收器，加入了参数[12]后，执行full gc的时候，就变成了CMS foreground gc，它是并行full gc，只会执行CMS中stop the world阶段的操作，效率比单线程Serial full GC要高；需要注意的是它只会回收old，因为CMS收集器是老年代收集器；而正常的Serial收集是包含整个堆的，加入了参数[13],代表永久代也会被CMS收集；</p>
<p>[14] 开启初始标记过程中的并行化，进一步提升初始化标记效率;</p>
<p>[15]、[16]、[17]、[18] 、[19]是打印gc日志，其中[16]在jdk1.8之后无需设置</p>
<p>[20]、[21]则是内存溢出时dump堆</p>
<h2 id="CMS需要注意的问题"><a href="#CMS需要注意的问题" class="headerlink" title="CMS需要注意的问题"></a>CMS需要注意的问题</h2><h3 id="CMS不是full-GC"><a href="#CMS不是full-GC" class="headerlink" title="CMS不是full GC"></a>CMS不是full GC</h3><p>有一点需要注意的是：CMS并发GC不是“full GC”。HotSpot VM里对concurrent collection和full collection有明确的区分。所有带有“FullCollection”字样的VM参数都是跟真正的full GC相关，而跟CMS并发GC无关的，CMS收集算法只是清理老年代。</p>
<h3 id="减少remark阶段停顿"><a href="#减少remark阶段停顿" class="headerlink" title="减少remark阶段停顿"></a>减少remark阶段停顿</h3><p>一般CMS的GC耗时 80%都在remark阶段，如果发现remark阶段停顿时间很长，可以尝试添加该参数：</p>
<p>-XX:+CMSScavengeBeforeRemark</p>
<p>在执行remark操作之前先做一次ygc，目的在于减少ygen对oldgen的无效引用，降低remark时的开销，如果添加该参数后 ”ygc停顿时间+remark时间&lt;添加该参数之前的remark时间“,说明该参数是有效的；</p>
<h3 id="内存碎片"><a href="#内存碎片" class="headerlink" title="内存碎片"></a>内存碎片</h3><p>CMS是基于标记-清除算法的，只会将标记为为存活的对象删除，并不会移动对象整理内存空间，会造成内存碎片，这时候我们需要用到这个参数;</p>
<p>-XX:CMSFullGCsBeforeCompaction=n</p>
<p>这个参数大部分人的使用方式都是错误的，往往会导致设置后问题更大。</p>
<p>CMSFullGCsBeforeCompaction这个参数在HotSpot VM里是这样声明的：</p>
<p>product(bool, UseCMSCompactAtFullCollection, true, \</p>
<p>“Use mark sweep compact at full collections”) \</p>
<p>\</p>
<p>product(uintx, CMSFullGCsBeforeCompaction, 0, \</p>
<p>“Number of CMS full collection done before compaction if &gt; 0”) \</p>
<p>然后这样使用的：</p>
<p>*should_compact =</p>
<p>UseCMSCompactAtFullCollection &amp;&amp;</p>
<p>((_full_gcs_since_conc_gc &gt;= CMSFullGCsBeforeCompaction) ||</p>
<p>GCCause::is_user_requested_gc(gch-&gt;gc_cause()) ||</p>
<p>gch-&gt;incremental_collection_will_fail(true <em>/\</em> consult_young <em>/</em>));</p>
<p>CMS GC要决定是否在full GC时做压缩，会依赖几个条件。其中，</p>
<ol>
<li><p>UseCMSCompactAtFullCollection 与 CMSFullGCsBeforeCompaction 是搭配使用的；前者目前默认就是true了，也就是关键在后者上。</p>
</li>
<li><p>用户调用了System.gc()，而且DisableExplicitGC没有开启。</p>
</li>
<li><p>young gen报告接下来如果做增量收集会失败；简单来说也就是young gen预计old gen没有足够空间来容纳下次young GC晋升的对象。</p>
</li>
</ol>
<p>上述三种条件的任意一种成立都会让CMS决定这次做full GC时要做压缩。</p>
<p>CMSFullGCsBeforeCompaction 说的是，在上一次CMS并发GC执行过后，到底还要再执行多少次full GC才会做压缩。默认是0，也就是在默认配置下每次CMS GC顶不住了而要转入full GC的时候都会做压缩。 如果把CMSFullGCsBeforeCompaction配置为10，就会让上面说的第一个条件变成每隔10次真正的full GC才做一次压缩（而不是每10次CMS并发GC就做一次压缩，目前VM里没有这样的参数）。这会使full GC更少做压缩，也就更容易使CMS的old gen受碎片化问题的困扰。 本来这个参数就是用来配置降低full GC压缩的频率，以期减少某些full GC的暂停时间。CMS回退到full GC时用的算法是mark-sweep-compact，但compaction是可选的，不做的话碎片化会严重些但这次full GC的暂停时间会短些；这是个取舍。</p>
<h3 id="concurrent-mode-failure"><a href="#concurrent-mode-failure" class="headerlink" title="concurrent mode failure"></a>concurrent mode failure</h3><p>这个异常发生在CMS正在回收的时候。执行CMS GC的过程中，同时业务线程也在运行，当年轻代空间满了，执行ygc时，需要将存活的对象放入到老年代，而此时老年代空间不足，这时CMS还没有机会回收老年带产生的，或者在做Minor GC的时候，新生代救助空间放不下，需要放入老年代，而老年代也放不下而产生的。</p>
<p>设置CMS触发时机有两个参数：</p>
<p>-XX:+UseCMSInitiatingOccupancyOnly</p>
<p>-XX:CMSInitiatingOccupancyFraction=70</p>
<p>-XX:CMSInitiatingOccupancyFraction=70 是指设定CMS在对内存占用率达到70%的时候开始GC。</p>
<p>-XX:+UseCMSInitiatingOccupancyOnly如果不指定, 只是用设定的回收阈值CMSInitiatingOccupancyFraction,则JVM仅在第一次使用设定值,后续则自动调整会导致上面的那个参数不起作用。</p>
<p>为什么要有这两个参数？</p>
<p>由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。</p>
<p>CMS前五个阶段都是标记存活对象的，除了”初始标记”和”重新标记”阶段会stop the word ，其它三个阶段都是与用户线程一起跑的，就会出现这样的情况gc线程正在标记存活对象，用户线程同时向老年代提升新的对象，清理工作还没有开始，old gen已经没有空间容纳更多对象了，这时候就会导致concurrent mode failure， 然后就会使用串行收集器回收老年代的垃圾，导致停顿的时间非常长。</p>
<p>CMSInitiatingOccupancyFraction参数要设置一个合理的值，设置大了，会增加concurrent mode failure发生的频率，设置的小了，又会增加CMS频率，所以要根据应用的运行情况来选取一个合理的值。</p>
<p>如果发现这两个参数设置大了会导致fullgc，设置小了会导致频繁的CMSgc，说明你的老年代空间过小，应该增加老年代空间的大小了；</p>
<h3 id="promotion-failed"><a href="#promotion-failed" class="headerlink" title="promotion failed"></a>promotion failed</h3><p>这个异常发生在年轻代回收的时候；</p>
<p>在进行Minor GC时，Survivor Space放不下，对象只能放入老年代，而此时老年代也放不下造成的，多数是由于老年带有足够的空闲空间，但是由于碎片较多，新生代要转移到老年带的对象比较大,找不到一段连续区域存放这个对象导致的，以下是一段promotion failed的日志：</p>
<p>106.641: [GC 106.641: [ParNew (promotion failed): 14784K-&gt;14784K(14784K), 0.0370328 secs]106.678: [CMS106.715: [CMS-concurrent-mark: 0.065/0.103 secs] [Times: user=0.17 sys=0.00, real=0.11 secs]</p>
<p>(concurrent mode failure): 41568K-&gt;27787K(49152K), 0.2128504 secs] 52402K-&gt;27787K(63936K), [CMS Perm : 2086K-&gt;2086K(12288K)], 0.2499776 secs] [Times: user=0.28 sys=0.00, real=0.25 secs]</p>
<p><strong><em>过早提升与提升失败</em></strong></p>
<p>在 Minor GC 过程中，Survivor Unused 可能不足以容纳 Eden 和另一个 Survivor 中的存活对象， 那么多余的将被移到老年代， 称为过早提升（Premature Promotion）,这会导致老年代中短期存活对象的增长， 可能会引发严重的性能问题。 再进一步， 如果老年代满了， Minor GC 后会进行 Full GC， 这将导致遍历整个堆， 称为提升失败（Promotion Failure）。</p>
<p><strong><em>早提升的原因</em></strong></p>
<ol>
<li><p>Survivor空间太小，容纳不下全部的运行时短生命周期的对象，如果是这个原因，可以尝试将Survivor调大，否则端生命周期的对象提升过快，导致老年代很快就被占满，从而引起频繁的full gc；</p>
</li>
<li><p>对象太大，Survivor和Eden没有足够大的空间来存放这些大象；</p>
</li>
</ol>
<p><strong><em>提升失败原因</em></strong></p>
<p>当提升的时候，发现老年代也没有足够的连续空间来容纳该对象。</p>
<p>为什么是没有足够的连续空间而不是空闲空间呢？</p>
<p>老年代容纳不下提升的对象有两种情况：</p>
<ol>
<li><p>老年代空闲空间不够用了；</p>
</li>
<li><p>老年代虽然空闲空间很多，但是碎片太多，没有连续的空闲空间存放该对象；</p>
</li>
</ol>
<p><strong><em>解决方法</em></strong></p>
<ol>
<li><p>如果是因为内存碎片导致的大对象提升失败，CMS需要进行空间整理压缩；</p>
</li>
<li><p>如果是因为提升过快导致的，说明Survivor 空闲空间不足，那么可以尝试调大 Survivor；</p>
</li>
<li><p>如果是因为老年代空间不够导致的，尝试将CMS触发的阈值调低；</p>
</li>
</ol>
<h2 id="其它导致回收停顿时间变长原因"><a href="#其它导致回收停顿时间变长原因" class="headerlink" title="其它导致回收停顿时间变长原因"></a>其它导致回收停顿时间变长原因</h2><p>linux使用了swap，内存换入换出（vmstat），尤其是开启了大内存页的时候，因为swap只支持4k的内存页，大内存页的大小为2M，大内存页在swap的交换的时候需要先将swap中4k内存页合并成一个大内存页再放入内存或将大内存页切分为4k的内存页放入swap，合并和切分的操作会导致操作系统占用cup飙高，用户cpu占用反而很低；</p>
<p>除了swap交换外，网络io（netstat）、磁盘I/O （iostat）在 GC 过程中发生会使 GC 时间变长。</p>
<p>如果是以上原因，就要去查看gc日志中的Times耗时：</p>
<p>[Times: user=0.00 sys=0.00, real=0.00 secs]</p>
<p>user是用户线程占用的时间，sys是系统线程占用的时间，如果是io导致的问题，会有两种情况</p>
<ol>
<li>user与sys时间都非常小，但是real却很长，如下：</li>
</ol>
<p>[ Times: user=0.51 sys=0.10, real=5.00 secs ]</p>
<p>user+sys的时间远远小于real的值，这种情况说明停顿的时间并不是消耗在cup执行上了，不是cup肯定就是io导致的了，所以这时候要去检查系统的io情况。</p>
<p>sys时间很长，user时间很短，real几乎等于sys的时间，如下：</p>
<p>[ Times: user=0.11 sys=31.10, real=33.12 secs ]</p>
<p>这时候其中一种原因是开启了大内存页，还开启了swap，大内存进行swap交换时会有这种现象；</p>
<h2 id="增加线程数"><a href="#增加线程数" class="headerlink" title="增加线程数"></a>增加线程数</h2><p>CMS默认启动的回收线程数目是 (ParallelGCThreads + 3)/4) ，这里的ParallelGCThreads是年轻代的并行收集线程数，感觉有点怪怪的；</p>
<p>年轻代的并行收集线程数默认是(ncpus &lt;= 8) ? ncpus : 3 + ((ncpus * 5) / 8)，可以通过-XX:ParallelGCThreads= N 来调整；</p>
<p>如果要直接设定CMS回收线程数，可以通过-XX:ParallelCMSThreads=n，注意这个n不能超过cpu线程数，需要注意的是增加gc线程数，就会和应用争抢资源；</p>
<p>参考</p>
<p><a target="_blank" rel="noopener" href="https://plumbr.eu/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep">https://plumbr.eu/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep</a></p>
<p><a target="_blank" rel="noopener" href="http://www.infoq.com/cn/presentations/a-long-period-of-atypical-jvm-gc-caused-by-os/">http://www.infoq.com/cn/presentations/a-long-period-of-atypical-jvm-gc-caused-by-os/</a></p>
<p>GC Cause</p>
<p>Heap Inspection Initiated GC</p>
<p>因为执行了jmap -histo:live 触发的gc</p>
<p>![](_v_images/20200621105321510_162455977.png =546x)</p>
<p>![](_v_images/20200621105825309_1900989220.png =541x)</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/">Java 8 document</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html">Java 8 CMS collector</a></li>
<li><a target="_blank" rel="noopener" href="https://www.iteye.com/blog/zhanjia-2435266">Java之CMS GC的7个阶段</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E8%B0%83%E4%BC%98%E8%AF%A6%E8%A7%A3%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E8%B0%83%E4%BC%98%E8%AF%A6%E8%A7%A3%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">【转载】Java生产环境下性能监控与调优详解笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:04" itemprop="dateModified" datetime="2021-01-18T22:05:04+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Java生产环境下性能监控与调优详解笔记"><a href="#Java生产环境下性能监控与调优详解笔记" class="headerlink" title="Java生产环境下性能监控与调优详解笔记"></a>Java生产环境下性能监控与调优详解笔记</h1><p>另一个整理<a target="_blank" rel="noopener" href="http://alanhou.org/java-optimization/">http://alanhou.org/java-optimization/</a></p>
<h2 id="1：JVM字节码指令与-javap"><a href="#1：JVM字节码指令与-javap" class="headerlink" title="1：JVM字节码指令与 javap"></a>1：JVM字节码指令与 javap</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">javap &lt;options&gt; &lt;classes&gt;</span><br><span class="line"><span class="built_in">cd</span> monitor\_tuning/target/classes/org/alanhou/monitor\_tuning/chapter8/</span><br><span class="line">javap -verbose Test1.class &gt; Test1.txt</span><br></pre></td></tr></table></figure>
<p>即可保存字节码文件<br>会有三个部分组成<br>操作数栈<br>LineNumberTable<br>LocalVariableTable</p>
<p>i++和++i 的执行效果完全相同 多了一个压入栈顶操作<br>for(int i=0;i&lt;10;i++) {}<br>for(int i=0;i&lt;10;++i) {} 执行效果一样</p>
<p>2：</p>
<p>public static void f1() {<br>String src = “”;<br>for(int i=0;i&lt;10;i++) {<br>//每一次循环都会new一个StringBuilder 然后在src.append(“A”);<br>src = src + “A”;<br>}<br>System.out.println(src);<br>}<br>public static void f2() {<br>//只要一个StringBuilder<br>StringBuilder src = new StringBuilder();<br>for(int i=0;i&lt;10;i++) {<br>src.append(“A”);<br>}<br>System.out.println(src);<br>}</p>
<p>3：</p>
<p>public static String f1() {<br>String str = “hello”;<br>try{<br>return str;<br>}<br>finally{<br>str = “imooc”;<br>}<br>} 返回 hello 但会执行finally 中的代码</p>
<p>4：字符串拼接都会在编译阶段转换成stringbuilder</p>
<p>5:字符串去重</p>
<p>字符串在任何应用中都占用了大量的内存。尤其数包含独立UTF-16字符的char[]数组对JVM内存的消耗贡献最多——因为每个字符占用2位。</p>
<p>内存的30%被字符串消耗其实是很常见的，不仅是因为字符串是与我们互动的最好的格式，而且是由于流行的HTTP API使用了大量的字符串。使用Java 8 Update 20，我们现在可以接触到一个新特性，叫做字符串去重，该特性需要G1垃圾回收器，该垃圾回收器默认是被关闭的。</p>
<p>字符串去重利用了字符串内部实际是char数组，并且是final的特性，所以JVM可以任意的操纵他们。</p>
<p>对于字符串去重，开发者考虑了大量的策略，但最终的实现采用了下面的方式：</p>
<p>无论何时垃圾回收器访问了String对象，它会对char数组进行一个标记。它获取char数组的hash value并把它和一个对数组的弱引用存在一起。只要垃圾回收器发现另一个字符串，而这个字符串和char数组具有相同的hash code，那么就会对两者进行一个字符一个字符的比对。</p>
<p>如果他们恰好匹配，那么一个字符串就会被修改，指向第二个字符串的char数组。第一个char数组就不再被引用，也就可以被回收了。</p>
<p>这整个过程当然带来了一些开销，但是被很紧实的上限控制了。例如，如果一个字符未发现有重复，那么一段时间之内，它会不再被检查。</p>
<p>那么该特性实际上是怎么工作的呢？首先，你需要刚刚发布的Java 8 Update 20，然后按照这个配置: -Xmx256m -XX:+UseG1GC 去运行下列的代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LotsOfStrings</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> LinkedList LOTS_OF_STRINGS = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> iteration = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">1000</span>; j++) &#123;</span><br><span class="line">                    LOTS_OF_STRINGS.add(<span class="keyword">new</span> String(<span class="string">&quot;String &quot;</span> + j));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            iteration++;</span><br><span class="line">            System.out.println(<span class="string">&quot;Survived Iteration: &quot;</span> + iteration);</span><br><span class="line">            Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码会执行30个迭代之后报OutOfMemoryError。</p>
<p>现在，开启字符串去重，使用如下配置去跑上述代码：</p>
<p>-Xmx256m -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintStringDeduplicationStatistics</p>
<p>此时它已经可以运行更长的时间，而且在50个迭代之后才终止。</p>
<p>6:</p>
<p>ArrayLIst  底层是数组  扩容会拷贝<br>hashmap   底层也是数组+ 链表 扩容 重新计算key 负载因子是 0.75  </p>
<p>linklist底层是双向链表<br>1. 尽量重用对象，不要循环创建对象，比如:for 循环字符串拼接(不在 for中使用+拼接，先new 一个StringBuilder再在 for 里 append)  </p>
<p>2. 容器类初始化的地时候指定长度  </p>
<p>List<String> collection = new ArrayLIst<String>(5);  </p>
<p>Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(32);  </p>
<p>3. ArrayList（底层数组）随机遍历快，LinkedList（底层双向链表）添加删除快  </p>
<p>4. 集合遍历尽量减少重复计算  </p>
<p>5. 使用 Entry 遍历 Map可以同时取出key和value  </p>
<p>6. 大数组复制使用System.arraycopy 底层是native实现的  </p>
<p>7. 尽量使用基本类型而不是包装类型  </p>
<p>public class Test03 {  </p>
<p>  public static void main(String[] args) {<br>  Integer f1 = 100, f2 = 100, f3 = 150, f4 = 150;  </p>
<p>  System.out.println(f1 == f2);<br>  System.out.println(f3 == f4);<br>}<br>}  </p>
<p>如果不明就里很容易认为两个输出要么都是true要么都是false。首先需要注意的是f1、f2、f3、f4四个变量都是Integer对象引用，所以下面的==运算比较的不是值而是引用。装箱的本质是什么呢？当我们给一个Integer对象赋一个int值的时候，会调用Integer类的静态方法valueOf，如果看看valueOf的源代码就知道发生了什么。<br>public static Integer valueOf(int i) {<br>  if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)<br>    return IntegerCache.cache[i + (-IntegerCache.low)];<br>  return new Integer(i);<br>}<br>简单的说，如果整型字面量的值在-128到127之间，那么不会new新的Integer对象，而是直接引用常量池中的Integer对象，所以上面的面试题中f1==f2的结果是true，而f3==f4的结果是false。<br>8. 不要手动调用 System.gc()  </p>
<p>9. 及时消除过期对象的引用，防止内存泄漏<br>public string pop()<br>{<br>  string currentValue=object[size];<br>  //object[size]=null;如果不添加这句话就会造成内存泄漏<br>  size–;<br>  return currentValue;<br>}  </p>
<p>10. 尽量使用局部变量，减小变量的作用域 方便出了作用域尽快垃圾回收  </p>
<p>11. 尽量使用非同步的容器ArraryList vs. Vector  </p>
<p>12. 尽量减小同步作用范围, synchronized 方法 vs. 代码块  </p>
<p>public class SynchronizedTest {<br>  public static void main(String[] args) {<br>}<br>public synchronized void f1() {//在this對象上加鎖<br>  System.out.println(“f1”);<br>}<br>public  void f2() {//在this對象上加鎖<br>  synchronized(this) {<br>    System.out.println(“f2”);<br>  }<br>}<br>public static synchronized void f3() {//在类上加鎖<br>  System.out.println(“f3”);<br>}<br>public static void f4() {//在类上加鎖<br>  synchronized(SynchronizedTest.class) {<br>    System.out.println(“f4”);<br>  }<br>}<br>}  </p>
<p>13. 用ThreadLocal 缓存线程不安全的对象，SimpleDateFormat 缓存重量的对象避免重新构造<br>@SuppressWarnings(“rawtypes”)<br>    private static ThreadLocal threadLocal = new ThreadLocal() {<br>        protected synchronized Object initialValue() {<br>            return new SimpleDateFormat(DATE_FORMAT);<br>        }<br>    };  </p>
<p>14. 尽量使用延迟加载  </p>
<p>15. 尽量减少使用反射，必须用加缓存，反射比较影响性能  </p>
<p>16. 尽量使用连接池、线程池、对象池、缓存  </p>
<p>17. 及时释放资源， I/O 流、Socket、数据库连接  </p>
<p>18. 慎用异常，不要用抛异常来表示正常的业务逻辑，异常也是比较重的对象要记录堆栈信息  </p>
<p>19. String 操作尽量少用正则表达式 比如replaceAll是用正则 比较耗费性能 replace就不是用正则  </p>
<p>20. 日志输出注意使用不同的级别  </p>
<p>21. 日志中参数拼接使用占位符<br>log.info(“orderId:” + orderId); 不推荐 会用字符串拼接<br>log.info(“orderId:{}”, orderId); 推荐 用占位符 不会进行字符串拼接  </p>
<p>7：JVM的参数类型</p>
<p>标准参数（各版本中保持稳定）</p>
<p>-help</p>
<p>-server -client</p>
<p>-version -showversion</p>
<p>-cp -classpath</p>
<p>X 参数（非标准化参数）</p>
<p>-Xint：解释执行</p>
<p>-Xcomp：第一次使用就编译成本地代码</p>
<p>-Xmixed：混合模式，JVM 自己决定是否编译成本地代码</p>
<p>示例：</p>
<p>java -version（默认是混合模式）</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, mixed mode)</p>
<p>java -Xint -version</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, interpreted mode)</p>
<p>XX 参数（非标准化参数）</p>
<p>主要用于 JVM调优和 debug</p>
<ul>
<li>Boolean类型</li>
</ul>
<p>格式：-XX:[+-]<name>表示启用或禁用 name 属性<br>如：-XX:+UseConcMarkSweepGC<br>-XX:+UseG1GC</p>
<ul>
<li>非Boolean类型</li>
</ul>
<p>格式：-XX:<name>=<value>表示 name 属性的值是 value<br>如：-XX:MaxGCPauseMillis=500<br>-xx:GCTimeRatio=19<br>-Xmx -Xms属于 XX 参数<br>-Xms 等价于-XX:InitialHeapSize<br>-Xmx 等价于-XX:MaxHeapSize<br>-xss 等价于-XX:ThreadStackSize</p>
<h3 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h3><p>-XX:+PrintFlagsInitial 查看jvm初始值</p>
<p>-XX:+PrintFlagsFinal 查看jvm最终值</p>
<p>-XX:+UnlockExperimentalVMOptions 解锁实验参数</p>
<p>-XX:+UnlockDiagnosticVMOptions 解锁诊断参数</p>
<p>-XX:+PrintCommandLineFlags 打印命令行参数</p>
<p>输出结果中=表示默认值，:=表示被用户或 JVM 修改后的值</p>
<p>示例：java -XX:+PrintFlagsFinal -version</p>
<p>补充：测试中需要用到 Tomcat，CentOS 7安装示例如下</p>
<p><code>sudo </code>yum -y ``install java-1.8.0-openjdk*<br>wget  <a target="_blank" rel="noopener" href="http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz">http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz</a><br>tar -zxvf apache-tomcat-8.5.32.tar.gz<br>mv apache-tomcat-8.5.32 tomcat<br>cd tomcat/bin/sh startup.sh</p>
<p>pid 可通过类似 ps -ef|grep tomcat或 jps来进行查看</p>
<h3 id="jps"><a href="#jps" class="headerlink" title="jps"></a>jps</h3><p>查看java进程 -l 可以知道完全类名</p>
<h3 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a>jinfo</h3><p>jinfo -flag MaxHeapSize <pid></p>
<p>jinfo -flags <pid>  手动赋过值的参数</p>
<h3 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h3><p>可以查看jvm的统计信息 如类加载。垃圾回收信息，jit编译信息</p>
<p>详情参考 <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html">jstat 官方文档</a></p>
<p><img src="_v_images/20200117100110226_7723.jpg" alt="jstat 使用示例"></p>
<p>类加载</p>
<h1 id="以下1000表每隔1000ms-即1秒，共输出10次"><a href="#以下1000表每隔1000ms-即1秒，共输出10次" class="headerlink" title="以下1000表每隔1000ms 即1秒，共输出10次"></a>以下1000表每隔1000ms 即1秒，共输出10次</h1><p>jstat -class <pid> 1000 10</p>
<p>垃圾收集</p>
<p>-gc, -gcutil, -gccause, -gcnew, -gcold</p>
<p>jstat -gc <pid> 1000 10</p>
<p>以下大小的单位均为 KB</p>
<p>![](_v_images/20200117100110111_28215.png =800x600)</p>
<p>S0C, S1C, S0U, S1U: S0和 S1的总量和使用量</p>
<p>EC, EU: Eden区总量与使用量</p>
<p>OC, OU: Old区总量与使用量</p>
<p>MC, MU: Metacspace区(jdk1.8前为 PermGen)总量与使用量</p>
<p>CCSC, CCSU: 压缩类区总量与使用量</p>
<p>YGC, YGCT: YoungGC 的次数与时间</p>
<p>FGC, FGCT: FullGC 的次数与时间</p>
<p>GCT: 总的 GC 时间</p>
<p>JIT 编译</p>
<p>-compiler, -printcompilation</p>
<p>一个对象默认分配在堆上面 但是有个指针指向class默认是64位长指针，可以设置为用32位存储在压缩类空间</p>
<p>非堆区 即对应于虚拟机规范中的方法区 是操作系统本地内存 独立于jvm堆区之外 jdk8后面叫metaspace jdk8前面叫performancespace</p>
<p>codecache 存储的是jit即时编译的代码 以及native代码</p>
<h3 id="jmap-MAT"><a href="#jmap-MAT" class="headerlink" title="jmap+MAT"></a>jmap+MAT</h3><p>详情参考<a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jmap.html">jmap 官方文档</a></p>
<p>内存溢出演示：</p>
<p><a target="_blank" rel="noopener" href="https://start.spring.io/%E7%94%9F%E6%88%90%E5%88%9D%E5%A7%8B%E4%BB%A3%E7%A0%81">https://start.spring.io/生成初始代码</a></p>
<p>最终代码：<a target="_blank" rel="noopener" href="https://github.com/alanhou7/java-codes/tree/master/monitor_tuning">monitor_tuning</a></p>
<p>为快速产生内存溢出，右击 Run As&gt;Run Configurations, Arguments 标签VM arguments 中填入</p>
<p>-Xmx32M -Xms32M</p>
<p><img src="_v_images/20200117100109881_9995.png"></p>
<p>访问 <a target="_blank" rel="noopener" href="http://localhost:8080/heap">http://localhost:8080/heap</a></p>
<p>Exception in thread “http-nio-8080-exec-2” Exception in thread “http-nio-8080-exec-1” java.lang.OutOfMemoryError: Java heap space<br>java.lang.OutOfMemoryError: Java heap space</p>
<p>-XX:MetaspaceSize=32M -XX:MaxMetaspaceSize=32M（同时在 pom.xml 中加入 asm 的依赖）</p>
<p><img src="_v_images/20200117100109670_1795.png"></p>
<p>访问 <a target="_blank" rel="noopener" href="http://localhost:8080/nonheap">http://localhost:8080/nonheap</a></p>
<p>Exception in thread “main” java.lang.OutOfMemoryError: Metaspace<br>Exception in thread “ContainerBackgroundProcessor[StandardEngine[Tomcat]]“ java.lang.OutOfMemoryError: Metaspace</p>
<p>内存溢出自动导出</p>
<p>-XX:+HeapDumpOnOutOfMemoryError</p>
<p>-XX:HeapDumpPath=./</p>
<p>右击 Run As&gt;Run Configurations, Arguments 标签VM arguments 中填入</p>
<p>-Xmx32M -Xms32M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./</p>
<p>可以看到自动在当前目录中生成了一个java_pid660.hprof文件</p>
<p>java.lang.OutOfMemoryError: GC overhead limit exceeded<br>Dumping heap to ./java_pid660.hprof …</p>
<p>另一种导出溢出也更推荐的方式是jmap</p>
<p>option: -heap, -clstats, -dump:<dump-options>, -F</p>
<p>jmap -dump:format=b,file=heap.hprof <pid></p>
<p><img src="_v_images/20200117100109462_23769.jpg" alt="jmap 导出溢出文件"></p>
<p>MAT下载地址：<a target="_blank" rel="noopener" href="http://www.eclipse.org/mat/">http://www.eclipse.org/mat/</a></p>
<p>找开上述导出的内存溢出文件即可进行分析，如下图的溢出源头分析：</p>
<p><img src="_v_images/20200117100109352_8610.jpg" alt="Memory Analyzer 内存溢出分析"></p>
<ol>
<li>Histogram可以列出内存中的对象，对象的个数以及大小。</li>
<li>Dominator Tree可以列出那个线程，以及线程下面的那些对象占用的空间。</li>
</ol>
<p>Histogram</p>
<pre><code>[![](_v_images/20200117100109236_4753.png)](http://static.oschina.net/uploads/space/2014/0702/120039_qSi5_1767531.png)</code></pre>
<ul>
<li><p>Class Name ： 类名称，java类名</p>
</li>
<li><p>Objects ： 类的对象的数量，这个对象被创建了多少个</p>
</li>
<li><p>Shallow Heap ：一个对象内存的消耗大小，不包含对其他对象的引用</p>
</li>
</ul>
<ul>
<li>Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收到内存的总和</li>
</ul>
<p>Dominator Tree</p>
<p><a target="_blank" rel="noopener" href="http://static.oschina.net/uploads/space/2014/0702/145926_K3ET_1767531.png"><img src="_v_images/20200117100109129_22861.png"></a></p>
<p>我们可以看到ibatis占了较多内存</p>
<p>快速找出某个实例没被释放的原因，可以右健 Path to GC Roots–&gt;exclue all phantom/weak/soft etc. reference :</p>
<p> <img src="_v_images/20200117100108918_9987.png"></p>
<p>得到的结果是：</p>
<p><img src="_v_images/20200117100108703_17828.png"></p>
<p>从表中可以看出 PreferenceManager -&gt; … -&gt;HomePage这条线路就引用着这个 HomePage实例。用这个方法可以快速找到某个对象的 <strong>GC Root</strong>,一个存在 GC Root的对象是不会被 GC回收掉的.</p>
<h3 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h3><p>详情参考 <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstack.html">jstack 官方文档</a></p>
<p>jstack <pid>  打印jvm内部所有的线程</p>
<p> <em>jstack 15672 &gt;15673.txt  导出当前进程文件</em></p>
<p>可查看其中包含java.lang.Thread.State: WAITING (parking)，JAVA 线程包含的状态有：</p>
<p>NEW：线程尚未启动</p>
<p>RUNNABLE：线程正在 JVM 中执行</p>
<p>BLOCKED：线程在等待监控锁(monitor lock)</p>
<p>WAITING：线程在等待另一个线程进行特定操作（时间不确定）</p>
<p>TIMED_WAITING：线程等待另一个线程进行限时操作</p>
<p>TERMINATED：线程已退出</p>
<p>此时会生成一个monitor_tuning-0.0.1-SNAPSHOT.jar的 jar包，为避免本地的 CPU 消耗过多导致死机，建议上传上传到虚拟机进行测试</p>
<p>nohup java -jar monitor_tuning-0.0.1-SNAPSHOT.jar &amp;</p>
<p>访问 <a target="_blank" rel="noopener" href="http://xx.xx.xx.xx:12345/loop(%E7%AB%AF%E5%8F%A312345%E5%9C%A8application.properties%E6%96%87%E4%BB%B6%E4%B8%AD%E5%AE%9A%E4%B9%89)">http://xx.xx.xx.xx:12345/loop(端口12345在application.properties文件中定义)</a></p>
<p>top 是查询所有进程的cpu 占用率<br>top还可以用来显示一个进程中各个线程CPU的占用率：top -p <pid> -H<br>top命令如下  </p>
<p><img src="_v_images/20200117100108489_10785.png"></p>
<p>top -p <pid>  -H 命令如下 看的是7930的进程</p>
<p><img src="_v_images/20200117100108169_20096.png"></p>
<p>使用 jstack <pid>可以导出追踪文件，文件中 PID 在 jstack 中显示的对应 nid 为十六进制(命令行可执行 print ‘%x’ <pid>可以进行转化，如1640对应的十六进制为668)</p>
<p>“http-nio-12345-exec-3” #18 daemon prio=5 os_prio=0 tid=0x00007f10003fb000 nid=0x668 runnable [0x00007f0fcf8f9000]<br>   java.lang.Thread.State: RUNNABLE<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.getPartneridsFromJson(CpuController.java:77)<br>…</p>
<p>访问<a target="_blank" rel="noopener" href="http://xx.xx.xx.xx:12345/deadlock">http://xx.xx.xx.xx:12345/deadlock</a>(如上jstack <pid>导出追踪记录会发现如下这样的记录)</p>
<p> ![](_v_images/20200117100107951_17762.png =800x500)</p>
<h1 id="Java-stack-information-for-the-threads-listed-above"><a href="#Java-stack-information-for-the-threads-listed-above" class="headerlink" title="Java stack information for the threads listed above:"></a>Java stack information for the threads listed above:</h1><p>“Thread-5”:<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.lambda$deadlock$1(CpuController.java:41)<br>    - waiting to lock &lt;0x00000000edcf3470&gt; (a java.lang.Object)<br>    - locked &lt;0x00000000edcf3480&gt; (a java.lang.Object)<br>    at org.alanhou.monitor_tuning.chapter2.CpuController$$Lambda$337/547045985.run(Unknown Source)<br>    at java.lang.Thread.run(Thread.java:748)<br>“Thread-4”:<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.lambda$deadlock$0(CpuController.java:33)<br>    - waiting to lock &lt;0x00000000edcf3480&gt; (a java.lang.Object)<br>    - locked &lt;0x00000000edcf3470&gt; (a java.lang.Object)<br>    at org.alanhou.monitor_tuning.chapter2.CpuController$$Lambda$336/1704575158.run(Unknown Source)<br>    at java.lang.Thread.run(Thread.java:748)</p>
<p>Found 1 deadlock.</p>
<p>查看后台日志，都是使用tail -f catalina.out命令来查看  </p>
<p>jvisualvm 图形化工具<br>插件安装Tools&gt;Plugins&gt;Settings根据自身版本(java -version)更新插件中心地址，各版本查询地址：<br><a target="_blank" rel="noopener" href="http://visualvm.github.io/pluginscenters.html">http://visualvm.github.io/pluginscenters.html</a><br> 建议安装：Visual GC, BTrace Workbench<br>概述 监控可以堆dump 线程可以线程dump 抽样器可以对cpu和内存进行抽样调查</p>
<p>以上是本地的JAVA进程监控，还可以进行远程的监控，在上图左侧导航的 Applications 下的 Remote 处右击Add Remote Host…，输入主机 IP 即可添加，在 IP 上右击会发现有两种连接 JAVA 进程进行监控的方式:JMX, jstatd</p>
<p>bin/catalina.sh(以192.168.0.5为例)</p>
<p>JAVA_OPTS=”$JAVA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9004 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.net.preferIPv4Stack=true -Djava.rmi.server.hostname=192.168.0.5”</p>
<p>启动tomcat，</p>
<p>启动tomcat服务<br>方式一：直接启动 ./startup.sh<br>方式二：作为服务启动 nohup ./startup.sh &amp;<br>查看tomcat运行日志<br>tail -f catalina.out</p>
<p>tomcat设置jvm参数<br>修改文件 apache-tomcat-9.0.10/bin下catalina.bat文件</p>
<p>以 JMX 为例，在 IP 上右击点击Add JMX Connection…，输入 IP:PORT</p>
<p><img src="_v_images/20200117100107732_2132.jpg" alt="Add JMX Connection"></p>
<p>以上为 Tomcat，其它 JAVA 进程也是类似的，如：</p>
<p>nohup java -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9005 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.net.preferIPv4Stack=true -Djava.rmi.server.hostname=192.168.0.5 -jar monitor_tuning-0.0.1-SNAPSHOT.jar &amp;</p>
<h3 id="BTrace"><a href="#BTrace" class="headerlink" title="BTrace"></a>BTrace</h3><p><a target="_blank" rel="noopener" href="https://github.com/jbachorik/btrace/releases/latest">BTrace</a> 可以动态地向目标应用程序的字节码注入追踪代码，使用的技术有 JavaCompilerApi, JVMTI, Agent, Instrumentation+ASM</p>
<p>使用方法：JVisualVM中添加 BTrace 插件</p>
<p>方法二：btrace <pid> <trace_script></p>
<p>btrace只能调试本地进程<br>btrace修改后的字节码不能被还原</p>
<p>pom.xml 中添加 btrace-agent, btrace-boot, btrace-client的依赖</p>
<p><img src="_v_images/20200117100107618_23079.png"></p>
<p><img src="_v_images/20200117100107506_24487.png"></p>
<p>拦截构造方法</p>
<p><img src="_v_images/20200117100107296_11386.png"></p>
<p>拦截同名方法  </p>
<p><img src="_v_images/20200117100107084_31796.png"></p>
<p>拦截返回值  </p>
<p><img src="_v_images/20200117100106870_26027.png"></p>
<p>拦截行号</p>
<p><img src="_v_images/20200117100106659_4260.png"></p>
<p>拦截异常信息</p>
<p><img src="_v_images/20200117100106449_4493.png"></p>
<p>拦截复杂类型</p>
<p><img src="_v_images/20200117100106216_21011.png"></p>
<p>拦截正则表达式</p>
<p><img src="_v_images/20200117100105902_16999.png"></p>
<p>拦截环境参数信息  </p>
<p><img src="_v_images/20200117100105692_8879.png">  </p>
<p>常用参数：  </p>
<p>-Xms -Xmx  </p>
<p>-XX:NewSize -XX:MaxNewSize  </p>
<p>-XX:NewRatio -XX:SurvivorRatio  </p>
<p>-XX:MetaspaceSize -XX:MaxMetaspaceSize 以下几个参数通常这样只设置这个值即可  </p>
<p>-XX:+UseCompressedClassPointers  </p>
<p>-XX:CompressedClassSpaceSize  </p>
<p>-XX:InitialCodeCacheSize  </p>
<p>-XX:ReservedCodeCacheSize</p>
<p>Tomcat 远程 Debug</p>
<p>JDWP</p>
<p>bin/startup.sh 修改最后一行(添加 jpda)</p>
<p>exec “$PRGDIR”/“$EXECUTABLE” jpda start “$@”</p>
<p>bin/catalina.sh 为便于远程调试进行如下修改</p>
<p>JPDA_ADDRESS=”localhost:8000”</p>
<h1 id="修改为"><a href="#修改为" class="headerlink" title="修改为"></a>修改为</h1><p>JPDA_ADDRESS=”54321”</p>
<p>若发现54321端口启动存在问题可尝试bin/catalina.sh jpda start</p>
<p>使用 Eclipse 远程调试，右击 Debug As &gt; Debug Configurations… &gt; Remote Java Application &gt; 右击 New 新建</p>
<p>普通java进程可以这样配置<br>java -jar -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=10001 access-10000.jar</p>
<p>tomcat-manager 监控</p>
<p>1.conf/tomcat-users.xml添加用户</p>
  <role rolename="tomcat"/>
  <role rolename="manager-status"/>
  <role rolename="manager-gui"/>
  <user username="tomcat" password="123456" roles="tomcat,manager-gui,manager-status"/>

<p>2.conf/Catalina/localhost/manager.xml配置允许的远程连接</p>
<?xml version="1.0" encoding="UTF-8"?>
<p><Context privileged="true" antiResourceLocking="false"
        docBase="$(catalina.home)/webapps/manager"><br>  <Valve className="org.apache.catalina.valves.RemoteAddrValve"
        allow="127\\.0\\.0\\.1" /><br></Context></p>
<p>远程连接将allow=”127\.0\.0\.1”修改为allow=”^.*$”，浏览器中输入<a target="_blank" rel="noopener" href="http://127.0.0.1:8080/manage%E6%88%96%E5%AF%B9%E5%BA%94%E7%9A%84">http://127.0.0.1:8080/manage或对应的</a> IP，用户名密码为tomcat-users.xml中所设置的</p>
<p>3.重启 Tomcat 服务</p>
<p><img src="_v_images/20200117100105380_4818.jpg" alt="Tomcat Manager"></p>
<p>psi-probe 监控</p>
<p>下载地址：<a target="_blank" rel="noopener" href="https://github.com/psi-probe/psi-probe%EF%BC%8C">https://github.com/psi-probe/psi-probe，</a></p>
<p>下载后进入psi-probe-master目录，执行：</p>
<p>mvn clean package -Dmaven.test.skip</p>
<p>将 web/target/probe.war放到 Tomcat 的 webapps 目录下，同样需要conf/tomcat-users.xml和conf/Catalina/localhost/manager.xml中的配置（可保持不变），启动 Tomcat 服务</p>
<p>浏览器中输入<a target="_blank" rel="noopener" href="http://127.0.0.1:8080/probe%E6%88%96%E5%AF%B9%E5%BA%94%E7%9A%84">http://127.0.0.1:8080/probe或对应的</a> IP，用户名密码为tomcat-users.xml中所设置的</p>
<p><img src="_v_images/20200117100105268_9524.jpg" alt="PSI Probe演示"></p>
<p>Tomcat 调优</p>
<p>线程优化（webapps/docs/config/http.html）：</p>
<p>maxConnections</p>
<p>acceptCount</p>
<p>maxThreads</p>
<p>minSpareThreads</p>
<p>配置优化（webapps/docs/config/host.html）：</p>
<p>autoDeploy</p>
<p>enableLookups（http.html）</p>
<p>reloadable（context.html）</p>
<p>protocol=”org.apache.coyote.http11.Http11AprProtocol”</p>
<p>Session 优化：</p>
<p>如果是 JSP, 可以禁用 Session</p>
<h3 id="Nginx-性能监控与调优"><a href="#Nginx-性能监控与调优" class="headerlink" title="Nginx 性能监控与调优"></a>Nginx 性能监控与调优</h3><p>Nginx 安装</p>
<p>添加 yum 源（/etc/yum.repos.d/nginx.repo）</p>
<p>[nginx]<br>name=nginx repo<br>baseurl=<a target="_blank" rel="noopener" href="http://nginx.org/packages/centos/7/$basesearch/">http://nginx.org/packages/centos/7/$basesearch/</a><br>gpgcheck=0<br>enabled=1</p>
<p>安装及常用命令</p>
<p>yum install -y nginx</p>
<p>systemctl status|start|stop|reload|restart nginx<br>nginx -s stop|reload|quit|reopen  nginx  启动nginx<br>cat default.conf | grep -v “#’ &gt; default2.conf  移除配置文件中的注释 并生成新的配置文件<br>nginx -V<br>nginx -t</p>
<p>配置反向代理 setenforce 0</p>
<p>ngx_http_stub_status 监控连接信息</p>
<p>location = /nginx_status {<br>    stub_status on;<br>    access_log off;<br>    allow 127.0.0.1;<br>    deny all;<br>}</p>
<p>可通过curl <a target="_blank" rel="noopener" href="http://127.0.0.1/nginx_status">http://127.0.0.1/nginx_status</a> 进行查看或注释掉 allow 和 deny 两行使用 IP 进行访问</p>
<p>ngxtop监控请求信息</p>
<p>查看官方使用方法：<a target="_blank" rel="noopener" href="https://github.com/lebinh/ngxtop">https://github.com/lebinh/ngxtop</a></p>
<h1 id="安装-python-pip"><a href="#安装-python-pip" class="headerlink" title="安装 python-pip"></a>安装 python-pip</h1><p>yum install epel-release<br>yum install python-pip</p>
<h1 id="安装-ngxtop"><a href="#安装-ngxtop" class="headerlink" title="安装 ngxtop"></a>安装 ngxtop</h1><p>pip install ngxtop</p>
<p>使用示例</p>
<p>指定配置文件：ngxtop -c /etc/nginx/nginx.conf</p>
<p>查询状态是200：ngxtop -c /etc/nginx/nginx.conf -i ‘status == 200’</p>
<p>查询访问最多 ip：ngxtop -c /etc/nginx/nginx.conf -g remote_addr</p>
<p><img src="_v_images/20200117100103032_6684.jpg" alt="ngxtop查询访问最多 ip"></p>
<p>Nginx 优化</p>
<p>增加工作线程数和并发连接数</p>
<p>worker_processes  4; # 一般CPU 是几核就设置为几<br>events {<br>    worker_connections  1024; # 每个进程打开的最大连接数，包含了 Nginx 与客户端和 Nginx 与 upstream 之间的连接<br>    multi_accept on; # 可以一次建立多个连接<br>    use epoll;<br>}</p>
<p>启用长连接</p>
<p>upstream server_pool{<br>    server localhost:8080 weight=1 max_fails=2 fail_timeout=30s;<br>    server localhost:8081 weight=1 max_fails=2 fail_timeout=30s;<br>    keepalive 300; # 300个长连接<br>}<br>location / {<br>    proxy_http_version 1.1;<br>    proxy_set_header Upgrade $http_upgrade;<br>    proxy_set_header Connection “upgrade”;<br>    proxy_pass <a target="_blank" rel="noopener" href="http://server/_pool">http://server\_pool</a>;<br>}</p>
<p>启用缓存压缩</p>
<p>gzip on;<br>gzip_http_version 1.1;<br>gzip_disable “MSIE [1-6]\.(?!.*SV1)”;<br>gzip_proxied any;<br>gzip_types text/plain text/css application/javascript application/x-javascript application/json application/xml application/vnd.ms-fontobject application/x-font-ttf application/svg+xml application/x-icon;<br>gzip_vary on;<br>gzip_static on;</p>
<p>操作系统优化</p>
<h1 id="配置文件-etc-sysctl-conf"><a href="#配置文件-etc-sysctl-conf" class="headerlink" title="配置文件/etc/sysctl.conf"></a>配置文件/etc/sysctl.conf</h1><p>sysctl -w net.ipv4.tcp_syncookies=1 # 防止一个套接字在有过多试图连接到时引起过载<br>sysctl -w net.core.somaxconn=1024 # 默认128，连接队列<br>sysctl -w net.ipv4.tcp_fin_timeout=10 # timewait 的超时时间<br>sysctl -w net.ipv4.tcp_tw_reuse=1 # os 直接使用 timewait的连接<br>sysctl -w net.ipv4.tcp_tw_recycle=0 # 回收禁用</p>
<h1 id="etc-security-limits-conf"><a href="#etc-security-limits-conf" class="headerlink" title="/etc/security/limits.conf"></a>/etc/security/limits.conf</h1><ul>
<li><pre><code>          hard    nofile            204800</code></pre>
</li>
<li><pre><code>          soft    nofile             204800</code></pre>
</li>
<li><pre><code>          soft    core             unlimited</code></pre>
</li>
<li><pre><code>          soft    stack             204800</code></pre>
</li>
</ul>
<p>其它优化</p>
<p>sendfile    on; # 减少文件在应用和内核之间拷贝<br>tcp_nopush    on; # 当数据包达到一定大小再发送<br>tcp_nodelay    off; # 有数据随时发送</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-backpress-ext/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-backpress-ext/" class="post-title-link" itemprop="url">【转发】咱们从头到尾讲一次 Flink 网络流控和反压剖析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:05" itemprop="dateModified" datetime="2021-01-18T22:05:05+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本文根据 Apache Flink 系列直播整理而成，由 Apache Flink Contributor、OPPO 大数据平台研发负责人张俊老师分享。主要内容如下：</p>
<ul>
<li><p>网络流控的概念与背景</p>
</li>
<li><p>TCP的流控机制</p>
</li>
<li><p>Flink TCP-based 反压机制（before V1.5）</p>
</li>
<li><p>Flink Credit-based 反压机制 （since V1.5）</p>
</li>
<li><p>总结与思考</p>
</li>
</ul>
<h2 id="网络流控的概念与背景"><a href="#网络流控的概念与背景" class="headerlink" title="网络流控的概念与背景"></a>网络流控的概念与背景</h2><h3 id="为什么需要网络流控"><a href="#为什么需要网络流控" class="headerlink" title="为什么需要网络流控"></a>为什么需要网络流控</h3><p><img src="_v_images/20200714171454820_132283117"></p>
<p>首先我们可以看下这张最精简的网络流控的图，Producer 的吞吐率是 2MB/s，Consumer 是 1MB/s，这个时候我们就会发现在网络通信的时候我们的 Producer 的速度是比 Consumer 要快的，有 1MB/s 的这样的速度差，假定我们两端都有一个 Buffer，Producer 端有一个发送用的 Send Buffer，Consumer 端有一个接收用的 Receive Buffer，在网络端的吞吐率是 2MB/s，过了 5s 后我们的 Receive Buffer 可能就撑不住了，这时候会面临两种情况：</p>
<ul>
<li><p>1.如果 Receive Buffer 是有界的，这时候新到达的数据就只能被丢弃掉了。</p>
</li>
<li><p>2.如果 Receive Buffer 是无界的，Receive Buffer 会持续的扩张，最终会导致 Consumer 的内存耗尽。</p>
</li>
</ul>
<h3 id="网络流控的实现：静态限速"><a href="#网络流控的实现：静态限速" class="headerlink" title="网络流控的实现：静态限速"></a>网络流控的实现：静态限速</h3><p><img src="_v_images/20200714171454414_685240728"></p>
<p>为了解决这个问题，我们就需要网络流控来解决上下游速度差的问题，传统的做法可以在 Producer 端实现一个类似 Rate Limiter 这样的静态限流，Producer 的发送速率是 2MB/s，但是经过限流这一层后，往 Send Buffer 去传数据的时候就会降到 1MB/s 了，这样的话 Producer 端的发送速率跟 Consumer 端的处理速率就可以匹配起来了，就不会导致上述问题。但是这个解决方案有两点限制：</p>
<ul>
<li><p>1、事先无法预估 Consumer 到底能承受多大的速率</p>
</li>
<li><p>2、 Consumer 的承受能力通常会动态地波动</p>
</li>
</ul>
<h3 id="网络流控的实现：动态反馈-自动反压"><a href="#网络流控的实现：动态反馈-自动反压" class="headerlink" title="网络流控的实现：动态反馈/自动反压"></a>网络流控的实现：动态反馈/自动反压</h3><p><img src="_v_images/20200714171454209_1020595047"></p>
<p>针对静态限速的问题我们就演进到了动态反馈（自动反压）的机制，我们需要 Consumer 能够及时的给 Producer 做一个 feedback，即告知 Producer 能够承受的速率是多少。动态反馈分为两种：</p>
<ul>
<li><p>1、负反馈：接受速率小于发送速率时发生，告知 Producer 降低发送速率</p>
</li>
<li><p>2、正反馈：发送速率小于接收速率时发生，告知 Producer 可以把发送速率提上来</p>
</li>
</ul>
<p>让我们来看几个经典案例</p>
<h3 id="案例一：Storm-反压实现"><a href="#案例一：Storm-反压实现" class="headerlink" title="案例一：Storm 反压实现"></a>案例一：Storm 反压实现</h3><p><img src="_v_images/20200714171454004_1684651238"></p>
<p>上图就是 Storm 里实现的反压机制，可以看到 Storm 在每一个 Bolt 都会有一个监测反压的线程（Backpressure Thread），这个线程一但检测到 Bolt 里的接收队列（recv queue）出现了严重阻塞就会把这个情况写到 ZooKeeper 里，ZooKeeper 会一直被 Spout 监听，监听到有反压的情况就会停止发送，通过这样的方式匹配上下游的发送接收速率。</p>
<h3 id="案例二：Spark-Streaming-反压实现"><a href="#案例二：Spark-Streaming-反压实现" class="headerlink" title="案例二：Spark Streaming 反压实现"></a>案例二：Spark Streaming 反压实现</h3><p><img src="_v_images/20200714171453699_1486221085"></p>
<p>Spark Streaming 里也有做类似这样的 feedback 机制，上图 Fecher 会实时的从 Buffer、Processing 这样的节点收集一些指标然后通过 Controller 把速度接收的情况再反馈到 Receiver，实现速率的匹配。</p>
<h3 id="疑问：为什么-Flink（before-V1-5）里没有用类似的方式实现-feedback-机制？"><a href="#疑问：为什么-Flink（before-V1-5）里没有用类似的方式实现-feedback-机制？" class="headerlink" title="疑问：为什么 Flink（before V1.5）里没有用类似的方式实现 feedback 机制？"></a>疑问：为什么 Flink（before V1.5）里没有用类似的方式实现 feedback 机制？</h3><p>首先在解决这个疑问之前我们需要先了解一下 Flink 的网络传输是一个什么样的架构。</p>
<p><img src="_v_images/20200714171453393_758272414"></p>
<p>这张图就体现了 Flink 在做网络传输的时候基本的数据的流向，发送端在发送网络数据前要经历自己内部的一个流程，会有一个自己的 Network Buffer，在底层用 Netty 去做通信，Netty 这一层又有属于自己的 ChannelOutbound Buffer，因为最终是要通过 Socket 做网络请求的发送，所以在 Socket 也有自己的 Send Buffer，同样在接收端也有对应的三级 Buffer。学过计算机网络的时候我们应该了解到，TCP 是自带流量控制的。实际上 Flink （before V1.5）就是通过 TCP 的流控机制来实现 feedback 的。</p>
<h2 id="TCP-流控机制"><a href="#TCP-流控机制" class="headerlink" title="TCP 流控机制"></a>TCP 流控机制</h2><p>根据下图我们来简单的回顾一下 TCP 包的格式结构。首先，他有 Sequence number 这样一个机制给每个数据包做一个编号，还有 ACK number 这样一个机制来确保 TCP 的数据传输是可靠的，除此之外还有一个很重要的部分就是 Window Size，接收端在回复消息的时候会通过 Window Size 告诉发送端还可以发送多少数据。</p>
<p><img src="_v_images/20200714171452987_650184722"></p>
<p>接下来我们来简单看一下这个过程。</p>
<h3 id="TCP-流控：滑动窗口"><a href="#TCP-流控：滑动窗口" class="headerlink" title="TCP 流控：滑动窗口"></a>TCP 流控：滑动窗口</h3><p><img src="_v_images/20200714171452683_1953611527"></p>
<p>TCP 的流控就是基于滑动窗口的机制，现在我们有一个 Socket 的发送端和一个 Socket 的接收端，目前我们的发送端的速率是我们接收端的 3 倍，这样会发生什么样的一个情况呢？假定初始的时候我们发送的 window 大小是 3，然后我们接收端的 window 大小是固定的，就是接收端的 Buffer 大小为 5。</p>
<p><img src="_v_images/20200714171452278_1991948370"></p>
<p>首先，发送端会一次性发 3 个 packets，将 1，2，3 发送给接收端，接收端接收到后会将这 3 个 packets 放到 Buffer 里去。</p>
<p><img src="_v_images/20200714171452072_41416741"></p>
<p>接收端一次消费 1 个 packet，这时候 1 就已经被消费了，然后我们看到接收端的滑动窗口会往前滑动一格，这时候 2，3 还在 Buffer 当中 而 4，5，6 是空出来的，所以接收端会给发送端发送 ACK = 4 ，代表发送端可以从 4 开始发送，同时会将 window 设置为 3 （Buffer 的大小 5 减去已经存下的 2 和 3），发送端接收到回应后也会将他的滑动窗口向前移动到 4，5，6。</p>
<p><img src="_v_images/20200714171451767_719493078"></p>
<p>这时候发送端将 4，5，6 发送，接收端也能成功的接收到 Buffer 中去。</p>
<p><img src="_v_images/20200714171451562_313469730"></p>
<p>到这一阶段后，接收端就消费到 2 了，同样他的窗口也会向前滑动一个，这时候他的 Buffer 就只剩一个了，于是向发送端发送 ACK = 7、window = 1。发送端收到之后滑动窗口也向前移，但是这个时候就不能移动 3 格了，虽然发送端的速度允许发 3 个 packets 但是 window 传值已经告知只能接收一个，所以他的滑动窗口就只能往前移一格到 7 ，这样就达到了限流的效果，发送端的发送速度从 3 降到 1。</p>
<p><img src="_v_images/20200714171451057_482639053"></p>
<p><img src="_v_images/20200714171450752_1192910727"></p>
<p>我们再看一下这种情况，这时候发送端将 7 发送后，接收端接收到，但是由于接收端的消费出现问题，一直没有从 Buffer 中去取，这时候接收端向发送端发送 ACK = 8、window = 0 ，由于这个时候 window = 0，发送端是不能发送任何数据，也就会使发送端的发送速度降为 0。这个时候发送端不发送任何数据了，接收端也不进行任何的反馈了，那么如何知道消费端又开始消费了呢？</p>
<p><img src="_v_images/20200714171450147_1390602232"></p>
<p><img src="_v_images/20200714171449642_832142513"></p>
<p><img src="_v_images/20200714171449037_394744327"></p>
<p>TCP 当中有一个 ZeroWindowProbe 的机制，发送端会定期的发送 1 个字节的探测消息，这时候接收端就会把 window 的大小进行反馈。当接收端的消费恢复了之后，接收到探测消息就可以将 window 反馈给发送端端了从而恢复整个流程。TCP 就是通过这样一个滑动窗口的机制实现 feedback。</p>
<h2 id="Flink-TCP-based-反压机制（before-V1-5）"><a href="#Flink-TCP-based-反压机制（before-V1-5）" class="headerlink" title="Flink TCP-based 反压机制（before V1.5）"></a>Flink TCP-based 反压机制（before V1.5）</h2><h3 id="示例：WindowWordCount"><a href="#示例：WindowWordCount" class="headerlink" title="示例：WindowWordCount"></a>示例：WindowWordCount</h3><p><img src="_v_images/20200714171448732_1736435542"></p>
<p>大体的逻辑就是从 Socket 里去接收数据，每 5s 去进行一次 WordCount，将这个代码提交后就进入到了编译阶段。</p>
<h3 id="编译阶段：生成-JobGraph"><a href="#编译阶段：生成-JobGraph" class="headerlink" title="编译阶段：生成 JobGraph"></a>编译阶段：生成 JobGraph</h3><p><img src="_v_images/20200714171448227_116055159"></p>
<p>这时候还没有向集群去提交任务，在 Client 端会将 StreamGraph 生成 JobGraph，JobGraph 就是做为向集群提交的最基本的单元。在生成 JobGrap 的时候会做一些优化，将一些没有 Shuffle 机制的节点进行合并。有了 JobGraph 后就会向集群进行提交，进入运行阶段。</p>
<h3 id="运行阶段：调度-ExecutionGraph"><a href="#运行阶段：调度-ExecutionGraph" class="headerlink" title="运行阶段：调度 ExecutionGraph"></a>运行阶段：调度 ExecutionGraph</h3><p><img src="_v_images/20200714171447922_1674684296"></p>
<p>JobGraph 提交到集群后会生成 ExecutionGraph ，这时候就已经具备基本的执行任务的雏形了，把每个任务拆解成了不同的 SubTask，上图 ExecutionGraph 中的 Intermediate Result Partition 就是用于发送数据的模块，最终会将 ExecutionGraph 交给 JobManager 的调度器，将整个 ExecutionGraph 调度起来。然后我们概念化这样一张物理执行图，可以看到每个 Task 在接收数据时都会通过这样一个 InputGate 可以认为是负责接收数据的，再往前有这样一个 ResultPartition 负责发送数据，在 ResultPartition 又会去做分区跟下游的 Task 保持一致，就形成了 ResultSubPartition 和 InputChannel 的对应关系。这就是从逻辑层上来看的网络传输的通道，基于这么一个概念我们可以将反压的问题进行拆解。</p>
<h3 id="问题拆解：反压传播两个阶段"><a href="#问题拆解：反压传播两个阶段" class="headerlink" title="问题拆解：反压传播两个阶段"></a>问题拆解：反压传播两个阶段</h3><p><img src="_v_images/20200714171447717_722983245"></p>
<p>反压的传播实际上是分为两个阶段的，对应着上面的执行图，我们一共涉及 3 个 TaskManager，在每个 TaskManager 里面都有相应的 Task 在执行，还有负责接收数据的 InputGate，发送数据的 ResultPartition，这就是一个最基本的数据传输的通道。在这时候假设最下游的 Task （Sink）出现了问题，处理速度降了下来这时候是如何将这个压力反向传播回去呢？这时候就分为两种情况：</p>
<ul>
<li><p>跨 TaskManager ，反压如何从 InputGate 传播到 ResultPartition</p>
</li>
<li><p>TaskManager 内，反压如何从 ResultPartition 传播到 InputGate</p>
</li>
</ul>
<h3 id="跨-TaskManager-数据传输"><a href="#跨-TaskManager-数据传输" class="headerlink" title="跨 TaskManager 数据传输"></a>跨 TaskManager 数据传输</h3><p><img src="_v_images/20200714171447411_1651413338"></p>
<p>前面提到，发送数据需要 ResultPartition，在每个 ResultPartition 里面会有分区 ResultSubPartition，中间还会有一些关于内存管理的 Buffer。 对于一个 TaskManager 来说会有一个统一的 Network BufferPool 被所有的 Task 共享，在初始化时会从 Off-heap Memory 中申请内存，申请到内存的后续内存管理就是同步 Network BufferPool 来进行的，不需要依赖 JVM GC 的机制去释放。有了 Network BufferPool 之后可以为每一个 ResultSubPartition 创建 Local BufferPool 。 如上图左边的 TaskManager 的 Record Writer 写了 &lt;1，2&gt; 这个两个数据进来，因为 ResultSubPartition 初始化的时候为空，没有 Buffer 用来接收，就会向 Local BufferPool 申请内存，这时 Local BufferPool 也没有足够的内存于是将请求转到 Network BufferPool，最终将申请到的 Buffer 按原链路返还给 ResultSubPartition，&lt;1，2&gt; 这个两个数据就可以被写入了。之后会将 ResultSubPartition 的 Buffer 拷贝到 Netty 的 Buffer 当中最终拷贝到 Socket 的 Buffer 将消息发送出去。然后接收端按照类似的机制去处理将消息消费掉。 接下来我们来模拟上下游处理速度不匹配的场景，发送端的速率为 2，接收端的速率为 1，看一下反压的过程是怎样的。</p>
<h3 id="跨-TaskManager-反压过程"><a href="#跨-TaskManager-反压过程" class="headerlink" title="跨 TaskManager 反压过程"></a>跨 TaskManager 反压过程</h3><p><img src="_v_images/20200714171447006_680735181"></p>
<p>因为速度不匹配就会导致一段时间后 InputChannel 的 Buffer 被用尽，于是他会向 Local BufferPool 申请新的 Buffer ，这时候可以看到 Local BufferPool 中的一个 Buffer 就会被标记为 Used。</p>
<p><img src="_v_images/20200714171446799_1194236091"></p>
<p>发送端还在持续以不匹配的速度发送数据，然后就会导致 InputChannel 向 Local BufferPool 申请 Buffer 的时候发现没有可用的 Buffer 了，这时候就只能向 Network BufferPool 去申请，当然每个 Local BufferPool 都有最大的可用的 Buffer，防止一个 Local BufferPool 把 Network BufferPool 耗尽。这时候看到 Network BufferPool 还是有可用的 Buffer 可以向其申请。</p>
<p><img src="_v_images/20200714171445992_941635712"></p>
<p>一段时间后，发现 Network BufferPool 没有可用的 Buffer，或是 Local BufferPool 的最大可用 Buffer 到了上限无法向 Network BufferPool 申请，没有办法去读取新的数据，这时 Netty AutoRead 就会被禁掉，Netty 就不会从 Socket 的 Buffer 中读取数据了。</p>
<p><img src="_v_images/20200714171444186_160162504"></p>
<p>显然，再过不久 Socket 的 Buffer 也被用尽，这时就会将 Window = 0 发送给发送端（前文提到的 TCP 滑动窗口的机制）。这时发送端的 Socket 就会停止发送。</p>
<p><img src="_v_images/20200714171443780_1304730499"></p>
<p>很快发送端的 Socket 的 Buffer 也被用尽，Netty 检测到 Socket 无法写了之后就会停止向 Socket 写数据。</p>
<p><img src="_v_images/20200714171443573_720011262"></p>
<p>Netty 停止写了之后，所有的数据就会阻塞在 Netty 的 Buffer 当中了，但是 Netty 的 Buffer 是无界的，可以通过 Netty 的水位机制中的 high watermark 控制他的上界。当超过了 high watermark，Netty 就会将其 channel 置为不可写，ResultSubPartition 在写之前都会检测 Netty 是否可写，发现不可写就会停止向 Netty 写数据。</p>
<p><img src="_v_images/20200714171443267_566801867"></p>
<p>这时候所有的压力都来到了 ResultSubPartition，和接收端一样他会不断的向 Local BufferPool 和 Network BufferPool 申请内存。</p>
<p><img src="_v_images/20200714171442761_1041985779"></p>
<p>Local BufferPool 和 Network BufferPool 都用尽后整个 Operator 就会停止写数据，达到跨 TaskManager 的反压。</p>
<h3 id="TaskManager-内反压过程"><a href="#TaskManager-内反压过程" class="headerlink" title="TaskManager 内反压过程"></a>TaskManager 内反压过程</h3><p>了解了跨 TaskManager 反压过程后再来看 TaskManager 内反压过程就更好理解了，下游的 TaskManager 反压导致本 TaskManager 的 ResultSubPartition 无法继续写入数据，于是 Record Writer 的写也被阻塞住了，因为 Operator 需要有输入才能有计算后的输出，输入跟输出都是在同一线程执行， Record Writer 阻塞了，Record Reader 也停止从 InputChannel 读数据，这时上游的 TaskManager 还在不断地发送数据，最终将这个 TaskManager 的 Buffer 耗尽。具体流程可以参考下图，这就是 TaskManager 内的反压过程。</p>
<p><img src="_v_images/20200714171442455_926070537"></p>
<p><img src="_v_images/20200714171442149_493428448"></p>
<p><img src="_v_images/20200714171441744_1291490922"></p>
<p><img src="_v_images/20200714171441439_2105575637"></p>
<h2 id="Flink-Credit-based-反压机制（since-V1-5）"><a href="#Flink-Credit-based-反压机制（since-V1-5）" class="headerlink" title="Flink Credit-based 反压机制（since V1.5）"></a>Flink Credit-based 反压机制（since V1.5）</h2><h3 id="TCP-based-反压的弊端"><a href="#TCP-based-反压的弊端" class="headerlink" title="TCP-based 反压的弊端"></a>TCP-based 反压的弊端</h3><p><img src="_v_images/20200714171441134_1354461165"></p>
<p>在介绍 Credit-based 反压机制之前，先分析下 TCP 反压有哪些弊端。</p>
<ul>
<li><p>在一个 TaskManager 中可能要执行多个 Task，如果多个 Task 的数据最终都要传输到下游的同一个 TaskManager 就会复用同一个 Socket 进行传输，这个时候如果单个 Task 产生反压，就会导致复用的 Socket 阻塞，其余的 Task 也无法使用传输，checkpoint barrier 也无法发出导致下游执行 checkpoint 的延迟增大。</p>
</li>
<li><p>依赖最底层的 TCP 去做流控，会导致反压传播路径太长，导致生效的延迟比较大。</p>
</li>
</ul>
<h3 id="引入-Credit-based-反压"><a href="#引入-Credit-based-反压" class="headerlink" title="引入 Credit-based 反压"></a>引入 Credit-based 反压</h3><p>这个机制简单的理解起来就是在 Flink 层面实现类似 TCP 流控的反压机制来解决上述的弊端，Credit 可以类比为 TCP 的 Window 机制。</p>
<h3 id="Credit-based-反压过程"><a href="#Credit-based-反压过程" class="headerlink" title="Credit-based 反压过程"></a>Credit-based 反压过程</h3><p><img src="_v_images/20200714171440828_629774125"></p>
<p>如图所示在 Flink 层面实现反压机制，就是每一次 ResultSubPartition 向 InputChannel 发送消息的时候都会发送一个 backlog size 告诉下游准备发送多少消息，下游就会去计算有多少的 Buffer 去接收消息，算完之后如果有充足的 Buffer 就会返还给上游一个 Credit 告知他可以发送消息（图上两个 ResultSubPartition 和 InputChannel 之间是虚线是因为最终还是要通过 Netty 和 Socket 去通信），下面我们看一个具体示例。</p>
<p><img src="_v_images/20200714171440422_2073806088"></p>
<p>假设我们上下游的速度不匹配，上游发送速率为 2，下游接收速率为 1，可以看到图上在 ResultSubPartition 中累积了两条消息，10 和 11， backlog 就为 2，这时就会将发送的数据 &lt;8,9&gt; 和 backlog = 2 一同发送给下游。下游收到了之后就会去计算是否有 2 个 Buffer 去接收，可以看到 InputChannel 中已经不足了这时就会从 Local BufferPool 和 Network BufferPool 申请，好在这个时候 Buffer 还是可以申请到的。</p>
<p><img src="_v_images/20200714171440216_190878629"></p>
<p>过了一段时间后由于上游的发送速率要大于下游的接受速率，下游的 TaskManager 的 Buffer 已经到达了申请上限，这时候下游就会向上游返回 Credit = 0，ResultSubPartition 接收到之后就不会向 Netty 去传输数据，上游 TaskManager 的 Buffer 也很快耗尽，达到反压的效果，这样在 ResultSubPartition 层就能感知到反压，不用通过 Socket 和 Netty 一层层地向上反馈，降低了反压生效的延迟。同时也不会将 Socket 去阻塞，解决了由于一个 Task 反压导致 TaskManager 和 TaskManager 之间的 Socket 阻塞的问题。</p>
<h2 id="总结与思考"><a href="#总结与思考" class="headerlink" title="总结与思考"></a>总结与思考</h2><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><p>网络流控是为了在上下游速度不匹配的情况下，防止下游出现过载</p>
</li>
<li><p>网络流控有静态限速和动态反压两种手段</p>
</li>
<li><p>Flink 1.5 之前是基于 TCP 流控 + bounded buffer 实现反压</p>
</li>
<li><p>Flink 1.5 之后实现了自己托管的 credit - based 流控机制，在应用层模拟 TCP 的流控机制</p>
</li>
</ul>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>有了动态反压，静态限速是不是完全没有作用了？</p>
<p><img src="_v_images/20200714171439509_423419298"></p>
<p>实际上动态反压不是万能的，我们流计算的结果最终是要输出到一个外部的存储（Storage），外部数据存储到 Sink 端的反压是不一定会触发的，这要取决于外部存储的实现，像 Kafka 这样是实现了限流限速的消息中间件可以通过协议将反压反馈给 Sink 端，但是像 ES 无法将反压进行传播反馈给 Sink 端，这种情况下为了防止外部存储在大的数据量下被打爆，我们就可以通过静态限速的方式在 Source 端去做限流。所以说动态反压并不能完全替代静态限速的，需要根据合适的场景去选择处理方案。</p>
<p>作者：阿里云云栖号<br>链接：<a target="_blank" rel="noopener" href="https://juejin.im/post/5dce4b265188254a2b1faddf">https://juejin.im/post/5dce4b265188254a2b1faddf</a><br>来源：掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-checkpoint-savepoint-2pc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-checkpoint-savepoint-2pc/" class="post-title-link" itemprop="url">Flink-checkpoint与数据一致性</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-18 22:05:05" itemprop="dateModified" datetime="2021-01-18T22:05:05+08:00">2021-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="1-Flink-checkpoint-与-高可用"><a href="#1-Flink-checkpoint-与-高可用" class="headerlink" title="1. Flink checkpoint 与 高可用"></a>1. Flink checkpoint 与 高可用</h1><p>Flink Checkpoint 受 Chandy-Lamport 分布式快照启发，可以保证数据的高可用。但是有些情况下，不见得一定有效:</p>
<p>Flink On Yarn 模式，某个 Container 发生 OOM 异常，这种情况程序直接变成失败状态，此时 Flink 程序虽然开启 Checkpoint 也无法恢复，因为程序已经变成失败状态，所以此时可以借助外部参与启动程序，比如外部程序检测到实时任务失败时，从新对实时任务进行拉起。</p>
<h2 id="1-1-2PC"><a href="#1-1-2PC" class="headerlink" title="1.1. 2PC"></a>1.1. 2PC</h2><h3 id="1-1-1-Exactly-once-VS-At-least-once"><a href="#1-1-1-Exactly-once-VS-At-least-once" class="headerlink" title="1.1.1. Exactly-once VS At-least-once"></a>1.1.1. Exactly-once VS At-least-once</h3><p>算子做快照时，如果等所有输入端的barrier都到了才开始做快照，可保证算子的exactly-once；如果为了降低延时而跳过对齐，从而继续处理数据，那么等barrier都到齐后做快照就是at-least-once了，因为这次的快照掺杂了下一次快照的数据，当作业失败恢复的时候，这些数据会重复作用系统，就好像这些数据被消费了两遍。</p>
<p>注：对齐只会发生在算子的上端是join操作以及上游存在partition或者shuffle的情况，对于直连操作类似map、flatMap、filter等还是会保证exactly-once的语义。</p>
<h3 id="1-1-2-端到端的Exactly-once实现"><a href="#1-1-2-端到端的Exactly-once实现" class="headerlink" title="1.1.2. 端到端的Exactly once实现"></a>1.1.2. 端到端的Exactly once实现</h3><p>2PC分为几个阶段: 开始事务-&gt;预提交-&gt;提交(或回滚)</p>
<p>为了保证Exactly once, source和sink必须支持flink的2PC</p>
<p>当状态涉及到外部系统时，需要外部系统支持事务操作来配合flink实现2PC协议，从而保证数据的exatly-once。<br>这个时候，sink算子除了将自己的state写到后段，还必须准备好事务提交。</p>
<ul>
<li>一旦所有的算子完成了它们的pre-commit，它们会要求一个commit。</li>
<li>如果存在一个算子pre-commit失败了，本次事务失败，我们回滚到上次的checkpoint。</li>
<li>一旦master做出了commit的决定，那么这个commit必须得到执行，就算宕机恢复也有继续执行。</li>
</ul>
<h4 id="1-1-2-1-pre-commit"><a href="#1-1-2-1-pre-commit" class="headerlink" title="1.1.2.1. pre-commit"></a>1.1.2.1. pre-commit</h4><p>pre-commit阶段起始于一次快照的开始，即master节点将checkpoint的barrier注入source端，barrier随着数据向下流动直到sink端。barrier每到一个算子，都会出发算子做本地快照。</p>
<p><img src="_v_images/20200710154629243_751269158.png" alt="precommit"></p>
<p>当所有的算子都做完了本地快照并且回复到master节点时，pre-commit阶段才算结束。这个时候，checkpoint已经成功，并且包含了外部系统的状态。如果作业失败，可以进行恢复。</p>
<p><img src="_v_images/20200710154750060_1524377793.png" alt="precommit-success"></p>
<h4 id="1-1-2-2-commit"><a href="#1-1-2-2-commit" class="headerlink" title="1.1.2.2. commit"></a>1.1.2.2. commit</h4><p>通知所有的算子这次checkpoint成功了，即2PC的commit阶段。source节点和window节点没有外部状态，所以这时它们不需要做任何操作。<br>而对于sink节点，需要commit这次事务，将数据写到外部系统。</p>
<p><img src="_v_images/20200710154844838_737658241.png" alt="commit"></p>
<h4 id="1-1-2-3-rollback"><a href="#1-1-2-3-rollback" class="headerlink" title="1.1.2.3. rollback"></a>1.1.2.3. rollback</h4><p>一旦任何一个算子的快照保存失败，则触发回滚，同样的sink算子也需要取消写入外部的数据</p>
<h3 id="1-1-3-TwoPhaseCommitSinkFunction"><a href="#1-1-3-TwoPhaseCommitSinkFunction" class="headerlink" title="1.1.3. TwoPhaseCommitSinkFunction"></a>1.1.3. TwoPhaseCommitSinkFunction</h3><p>为了简化2PC的实现成本，flink抽象了TwoPhaseCommitSinkFunction</p>
<ul>
<li>beginTransaction。开始一次事务，在目的文件系统创建一个临时文件。接下来我们就可以将数据写到这个文件。</li>
<li>preCommit。在这个阶段，将文件flush掉，同时重起一个文件写入，作为下一次事务的开始。</li>
<li>commit。这个阶段，将文件写到真正的目的目录。值得注意的是，这会增加数据可视的延时。</li>
<li>abort。如果回滚，那么删除临时文件。</li>
</ul>
<p>如果pre-commit成功了，但是commit没有到达算子旧宕机了，flink会将算子恢复到pre-commit时的状态，然后继续commit。</p>
<p>我们需要做的还有就是保证commit的幂等性，这可以通过检查临时文件是否还在来实现。</p>
<h2 id="1-2-checkpoint"><a href="#1-2-checkpoint" class="headerlink" title="1.2. checkpoint"></a>1.2. checkpoint</h2><p><strong>保留策略</strong>:</p>
<ul>
<li>DELETE_ON_CANCELLATION 表示当程序取消时，删除 Checkpoint 存储文件。</li>
<li>RETAIN_ON_CANCELLATION 表示当程序取消时，保存之前的 Checkpoint 存储文件</li>
</ul>
<p>默认情况下，Flink不会触发一次 Checkpoint 当系统有其他 Checkpoint 在进行时，也就是说 Checkpoint 默认的并发为1。</p>
<p><strong>CheckpointCoordinator</strong> :</p>
<p>针对 Flink DataStream 任务，程序需要经历从 StreamGraph -&gt; JobGraph -&gt; ExecutionGraph -&gt; 物理执行图四个步骤，其中在 ExecutionGraph 构建时，会初始化 CheckpointCoordinator。ExecutionGraph通过ExecutionGraphBuilder.buildGraph方法构建，在构建完时，会调用 ExecutionGraph 的enableCheckpointing方法创建CheckpointCoordinator</p>
<p><strong>Flink Checkpoint 参数配置及建议</strong>:</p>
<ul>
<li>当 Checkpoint 时间比设置的 Checkpoint 间隔时间要长时，可以设置 Checkpoint 间最小时间间隔 。这样在上次 Checkpoint 完成时，不会立马进行下一次 Checkpoint，而是会等待一个最小时间间隔，然后在进行该次 Checkpoint。否则，每次 Checkpoint 完成时，就会立马开始下一次 Checkpoint，系统会有很多资源消耗 Checkpoint。</li>
<li>如果Flink状态很大，在进行恢复时，需要从远程存储读取状态恢复，此时可能导致任务恢复很慢，可以设置 Flink Task 本地状态恢复。任务状态本地恢复默认没有开启，可以设置参数state.backend.local-recovery值为true进行激活。</li>
<li>Checkpoint保存数，Checkpoint 保存数默认是1，也就是保存最新的 Checkpoint 文件，当进行状态恢复时，如果最新的Checkpoint文件不可用时(比如HDFS文件所有副本都损坏或者其他原因)，那么状态恢复就会失败，如果设置 Checkpoint 保存数2，即使最新的Checkpoint恢复失败，那么Flink 会回滚到之前那一次Checkpoint进行恢复。考虑到这种情况，用户可以增加 Checkpoint 保存数。</li>
<li>建议设置的 Checkpoint 的间隔时间最好大于 Checkpoint 的完成时间。</li>
</ul>
<p>下图是不设置 Checkpoint 最小时间间隔示例图，可以看到，系统一致在进行 Checkpoint，可能对运行的任务产生一定影响：<br><img src="_v_images/20200714095846469_121820659.png"></p>
<h2 id="1-3-savepoint"><a href="#1-3-savepoint" class="headerlink" title="1.3. savepoint"></a>1.3. savepoint</h2><blockquote>
<p>注意:<br>使用DataStream进行开发，建议为每个算子定义一个 uid，这样我们在修改作业时，即使导致程序拓扑图改变，由于相关算子 uid 没有变，那么这些算子还能够继续使用之前的状态，如果用户没有定义 uid ， Flink 会为每个算子自动生成 uid，如果用户修改了程序，可能导致之前的状态程序不能再进行复用。</p>
</blockquote>
<p>Flink 在触发Savepoint 或者 Checkpoint时，会根据这次触发的类型计算出在HDFS上面的目录:</p>
<p>如果类型是 Savepoint，那么 其 HDFS 上面的目录为：Savepoint 根目录+savepoint-jobid前六位+随机数字，具体如下格式：</p>
<p><img src="_v_images/20200714100459823_887900222.png"></p>
<p>Checkpoint 目录为 chk-checkpoint ID,具体格式如下：</p>
<p><img src="_v_images/20200714100516223_630729421.png"></p>
<ul>
<li>使用 flink cancel -s 命令取消作业同时触发 Savepoint 时，会有一个问题，可能存在触发 Savepoint 失败。比如实时程序处于异常状态(比如 Checkpoint失败)，而此时你停止作业，同时触发 Savepoint,这次 Savepoint 就会失败，这种情况会导致，在实时平台上面看到任务已经停止，但是实际实时作业在 Yarn 还在运行。针对这种情况，需要捕获触发 Savepoint 失败的异常，当抛出异常时，可以直接在 Yarn 上面 Kill 掉该任务。</li>
<li>使用 DataStream 程序开发时，最好为每个算子分配 uid,这样即使作业拓扑图变了，相关算子还是能够从之前的状态进行恢复，默认情况下，Flink 会为每个算子分配 uid,这种情况下，当你改变了程序的某些逻辑时，可能导致算子的 uid 发生改变，那么之前的状态数据，就不能进行复用，程序在启动的时候，就会报错。</li>
<li>由于 Savepoint 是程序的全局状态，对于某些状态很大的实时任务，当我们触发 Savepoint，可能会对运行着的实时任务产生影响，个人建议如果对于状态过大的实时任务，触发 Savepoint 的时间，不要太过频繁。根据状态的大小，适当的设置触发时间。</li>
<li>当我们从 Savepoint 进行恢复时，需要检查这次 Savepoint 目录文件是否可用。可能存在你上次触发 Savepoint 没有成功，导致 HDFS 目录上面 Savepoint 文件不可用或者缺少数据文件等，这种情况下，如果在指定损坏的 Savepoint 的状态目录进行状态恢复，任务会启动不起来。</li>
</ul>
<h2 id="1-4-snapshot保存到哪里-应该需要汇总到jobManager？"><a href="#1-4-snapshot保存到哪里-应该需要汇总到jobManager？" class="headerlink" title="1.4. snapshot保存到哪里? 应该需要汇总到jobManager？"></a>1.4. snapshot保存到哪里? 应该需要汇总到jobManager？</h2><h2 id="1-5-state-backend"><a href="#1-5-state-backend" class="headerlink" title="1.5. state backend"></a>1.5. state backend</h2><p><img src="_v_images/20200713183839429_2053265091.png"></p>
<h3 id="FsStateBackend"><a href="#FsStateBackend" class="headerlink" title="FsStateBackend"></a>FsStateBackend</h3><p>构造方法:<br><code>FsStateBackend(URI checkpointDataUri,boolean asynchronousSnapshots)</code></p>
<p>1 基于文件系统的状态管理器<br>2 如果使用，默认是异步<br>3 比较稳定，3个副本，比较安全。不会出现任务无法恢复等问题<br>4 状态大小受磁盘容量限制</p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager内存</li>
<li>checkpoint: 外部文件系统(本地或HDFS)</li>
</ul>
<p>容量限制:</p>
<ul>
<li>单TaskManager上State总量不超过它的内存</li>
<li>总大小不超过配置的文件系统容量</li>
</ul>
<p>推荐使用场景:</p>
<ul>
<li>常规使用状态的作业，例如分钟级窗口聚合、join、窗口比较长、kv状态大；需要开启HA的作业</li>
<li>可以用于生产场景</li>
</ul>
<h3 id="RocksDBStateBackend"><a href="#RocksDBStateBackend" class="headerlink" title="RocksDBStateBackend"></a>RocksDBStateBackend</h3><p>状态数据先写入RocksDB，然后异步的将状态数据写入文件系统。正在进行计算的热数据存储在RocksDB，长时间才更新的数据写入磁盘中（文件系统）存储，体量比较小的元数据状态写入JobManager内存中（将工作state保存在RocksDB中，并且默认将checkpoint数据存在文件系统中）</p>
<p>目前唯一支持incremental的checkpoints的策略</p>
<p>构造方法:<br><code>RocksDBStateBackend(URI checkpointDataUri,boolean enableIncrementalCheckpointing)</code></p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager上的KV数据库(实际使用内存+硬盘)</li>
<li>Checkpoint: 外部文件系统(本地或HDFS)</li>
</ul>
<p>容量限制:</p>
<ul>
<li>单TaskManager上的State总量不超过他的内存+磁盘</li>
<li>单key最大2G</li>
<li>总大小不超过配置的文件系统容量</li>
</ul>
<p>推荐使用的场景:</p>
<ul>
<li>超大状态的作业，例如天级别窗口聚合；需要开启HA的作业；对状态读写性能要求不高的作业</li>
<li>可以在生产环境使用</li>
</ul>
<h3 id="MemoryStateBackend"><a href="#MemoryStateBackend" class="headerlink" title="MemoryStateBackend"></a>MemoryStateBackend</h3><p>构造方法:<br><code>MemoryStateBackend(int maxStateSize, boolean asynchronousSnapshots)</code></p>
<p>主机内存中的数据可能会丢失，任务可能无法恢复</p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager内存</li>
<li>Checkpoint: JobManager内存</li>
</ul>
<p>容量限制</p>
<ul>
<li>单个State maxStateSize默认5M</li>
<li>maxStateSize &lt;= akka.frameSize 默认10M</li>
<li>总大小不超过JobManager的内存</li>
</ul>
<p>推荐使用场景：</p>
<ul>
<li>本地测试；几乎无状态的作业，比如ETL；JobManager不容易挂，或挂掉影响不大的情况</li>
<li>不推荐在生产环境使用</li>
</ul>
<h2 id="1-6-checkpoint-与-savepoint"><a href="#1-6-checkpoint-与-savepoint" class="headerlink" title="1.6. checkpoint 与 savepoint"></a>1.6. checkpoint 与 savepoint</h2><p>Checkpoint指定触发生成时间间隔后，每当需要触发Checkpoint时，会向Flink程序运行时的多个分布式的Stream Source中插入一个Barrier标记，这些Barrier会根据Stream中的数据记录一起流向下游的各个Operator。<br>当一个Operator接收到一个Barrier时，它会暂停处理Steam中新接收到的数据记录。<br>因为一个Operator可能存在多个输入的Stream，而每个Stream中都会存在对应的Barrier，该Operator要等到所有的输入Stream中的Barrier都到达。(<strong>对齐</strong>)<br>当所有Stream中的Barrier都已经到达该Operator，这时所有的Barrier在时间上看来是同一个时刻点（表示已经对齐），在等待所有Barrier到达的过程中，<br>Operator的Buffer中可能已经缓存了一些比Barrier早到达Operator的数据记录（Outgoing Records），这时该Operator会将数据记录（Outgoing Records）发射（Emit）出去，作为下游Operator的输入，<br>最后将Barrier对应Snapshot发射（Emit）出去作为此次Checkpoint的结果数据。</p>
<p>Checkpoint 是增量做的，每次的时间较短，数据量较小，只要在程序里面启用后会自动触发，用户无须感知；Checkpoint 是作业 failover 的时候自动使用，不需要用户指定。</p>
<p>Savepoint 是全量做的，每次的时间较长，数据量较大，需要用户主动去触发。Savepoint 一般用于程序的版本更新（详见文档），Bug 修复，A/B Test 等场景，需要用户指定。</p>
<p><strong>保存的内容</strong></p>
<ul>
<li>首先，Savepoint 包含了一个目录，其中包含（通常很大的）二进制文件，这些文件表示了整个流应用在 Checkpoint/Savepoint 时的状态。</li>
<li>以及一个（相对较小的）元数据文件，包含了指向 Savapoint 各个文件的指针，并存储在所选的分布式文件系统或数据存储中。</li>
</ul>
<p><strong>目标</strong></p>
<p>Savepoint 和 Checkpoint 的不同之处很像传统数据库中备份与恢复日志之间的区别。Checkpoint 的主要目标是充当 Flink 中的恢复机制，确保能从潜在的故障中恢复。相反，Savepoint 的主要目标是充当手动备份、恢复暂停作业的方法。</p>
<p><strong>实现</strong></p>
<p>Checkpoint 被设计成轻量和快速的机制。它们可能（但不一定必须）利用底层状态后端的不同功能尽可能快速地恢复数据。例如，基于 RocksDB 状态后端的增量检查点，能够加速 RocksDB 的 checkpoint 过程，这使得 checkpoint 机制变得更加轻量。相反，Savepoint 旨在更多地关注数据的可移植性，并支持对作业做任何更改而状态能保持兼容，这使得生成和恢复的成本更高</p>
<p><strong>状态文件保留策略</strong></p>
<p>Checkpoint默认程序删除，可以设置CheckpointConfig中的参数进行保留 。Savepoint会一直保存，除非用户删除 。</p>
<p><strong>应用</strong></p>
<ul>
<li>部署流应用的一个新版本，包括新功能、BUG 修复、或者一个更好的机器学习模型</li>
<li>引入 A/B 测试，使用相同的源数据测试程序的不同版本，从同一时间点开始测试而不牺牲先前的状态</li>
<li>在需要更多资源时扩容应用程序</li>
<li>迁移流应用程序到 Flink 的新版本上，或者迁移到另一个集群</li>
</ul>
<h1 id="Flink数据一致性"><a href="#Flink数据一致性" class="headerlink" title="Flink数据一致性"></a>Flink数据一致性</h1><h2 id="一、综述"><a href="#一、综述" class="headerlink" title="一、综述"></a>一、综述</h2><p><strong>flink 通过内部依赖checkpoint 并且可以通过设置其参数exactly-once 实现其内部的一致性</strong>。但要实现其端到端的一致性，还必须保证<br>1、source 外部数据源可重设数据的读取位置<br>2、sink端 需要保证数据从故障恢复时，数据不会重复写入外部系统（或者可以逻辑实现写入多次，但只有一次生效的数据sink端）</p>
<h2 id="二、sink-端到端实现方式"><a href="#二、sink-端到端实现方式" class="headerlink" title="二、sink 端到端实现方式"></a>二、sink 端到端实现方式</h2><p><strong>幂等操作：</strong><br>一个操作，可以重复执行多次，但只导致一次结果更改，豁免重复操作执行就不起作用了，他的瑕疵 （在系统恢复的过程中，如果这段时间内多个更新或者插入导致状态不一致，但当数据追上就可以了）<br>（逻辑与、逻辑或等）具体理解参照自己以前写的文章。<br><strong>事务写入：</strong><br>事务应该具有四个属性：原子性、一致性、隔离性、持久性等。其具体的实现方式有两种<br><strong>（1）、预写日志</strong><br>简单易于实现，由于数据提前在状态后端中做了缓存，所以无论什么sink系统，都能用这种方式一批搞定，DataStream API提供了一个模板类：GenericWriteAheadSink，来实现这种事务性sink；<br>缺点：<br>1）、sink系统没说他支持事务。有可能出现一部分写入集群了。一部分没有写进去（如果实表，再写一次就写重复了）<br>2）、checkpoint做完了sink才去真正的写入（但其实得等sink都写完checkpoint才能生效，所以WAL这个机制jobmanager确定它写完还不算真正写完，还得有一个外部系统已经确认 完成的checkpoint）<br>（<strong>2）、两阶段提交。 flink 真正实现exactle-once</strong><br>对于每个checkpoint,sink 任务会启动一个事务，并将接下来所有接收的数据添加到事务中，然后将这些数据写入外部sink系统，但不提交他们（这里是预提交）。当checkpoint完成时的通知，它才正式提交事务，实现结果的真正写入；这种方式真正实现了exactly-once,它需要一个提供事务支持的外部sink系统，Flink提供了其具体实现（TwoPhaseCommitSinkFunction接口）</p>
<h2 id="三、-2pc-对外部-sink的要求"><a href="#三、-2pc-对外部-sink的要求" class="headerlink" title="三、 2pc 对外部 sink的要求"></a>三、 2pc 对外部 sink的要求</h2><p>1、外部sink系统必须事务支持，或者sink任务必须能够模拟外部系统上的事务；<br>2、在checkpoint的间隔期间里，必须能够开启一个事务，并接受数据写入。<br>3、在收到checkpoint完成通知之前，事务必须是“等待提交”的状态，在故障恢复的情况线，这可能需要一些时间。如果个时候sink系统关闭事务（例如超时了），那么未提交的数据就会丢失；<br>4、四年任务必选能够在进程失败后恢复事务<br>5、提交事务必须是幂等操作；</p>
<p>四、综上不同Source和sink的一致性保证：<br><img src="_v_images/20201208154240979_1471214802.png" alt="在这里插入图片描述"></p>
<h2 id="五、应用（flinK-kafka-端到端一致性保证）"><a href="#五、应用（flinK-kafka-端到端一致性保证）" class="headerlink" title="五、应用（flinK+kafka 端到端一致性保证）"></a>五、应用（flinK+kafka 端到端一致性保证）</h2><p>flink 和kafka 端到端一致性(kafka(source+flink+kafka(sink)))<br>1、内部 – 利用checkpoint机制，把状态存盘，发生故障的时候可以恢复，保证内部的状态一致性<br>2、source – kafka consumer作为source，可以将偏移量保存下来，如果后续任务出现了故障，恢复的时候可以由连接器重置偏移量，重新消费数据，保证一致性；</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">kafka</span> 0.8 和<span class="selector-tag">kafka</span> 0.11 之后 通过以下配置将偏移量保存，恢复时候重新消费</span><br><span class="line"> <span class="selector-tag">kafka</span><span class="selector-class">.setStartFromLatest</span>();</span><br><span class="line"> <span class="selector-tag">kafka</span><span class="selector-class">.setCommitOffsetsOnCheckpoints</span>(<span class="selector-tag">false</span>);</span><br><span class="line"> <span class="selector-tag">kafka</span> 0.9 和<span class="selector-tag">kafka0</span>.10 未验证是否支持这两个参数(<span class="selector-tag">todo</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>3、sink FlinkkafkaProducer作为Sink，采用两阶段提交的sink，由下图可以看出flink 0.11 已经默认继承了TwoPhaseCommitSinkFunction<br><img src="_v_images/20201208154240548_914126344.png" alt="在这里插入图片描述"><br>但我们需要在参数种传入指定语义，它默认时还是at-least-once<br>此外我们还需要进行一些producer的容错配置：<br>（1）除了启用Flink的检查点之外，还可以通过将适当的semantic参数传递给FlinkKafkaProducer011（FlinkKafkaProducer对于Kafka&gt; = 1.0.0版本）<br>（2）来选择三种不同的操作模式<br>1）、Semantic.NONE 代表at-mostly-once语义<br>2）、Semantic.AT_LEAST_ONCE（Flink默认设置<br>3）、Semantic.EXACTLY_ONCE 使用Kafka事务提供一次精确的语义，每当您使用事务写入Kafka时<br>（3）、请不要忘记消费kafka记录任何应用程序设置所需的设置isolation.leva（read_committed 或者read_uncommitted-后者是默认）<br>read_committed，只是读取已经提交的数据。</p>
<p>应用；<br>Semantic.EXACTLY_ONCE依赖与下游系统能支持事务操作.以0.11kafka为例.<br>transaction.max.timeout.ms 最大超市时长，默认15分钟，如果需要用exactly语义，需要增加这个值。（因为它小于transaction.timeout.ms ）<br>isolation.level 如果需要用到exactly语义，需要在下级consumerConfig中设置read-commited [read-uncommited(默认值)]<br>transaction.timeout.ms 默认为1hour</p>
<p><strong>其参数对应关系为 和一些报错问题<br>checkpoint间隔&lt;transaction.timeout.ms&lt;transaction.max.timeout.ms</strong></p>
<p><strong>参考：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/createweb/p/11971846.html">https://www.cnblogs.com/createweb/p/11971846.html</a></strong></p>
<p>注意：<br>1、Semantic.EXACTLY_ONCE 模式每个FlinkKafkaProducer011实例使用一个固定大小的KafkaProducers池。每个检查点使用这些生产者中的每一个。如果并发检查点的数量超过池大小，FlinkKafkaProducer011 将引发异常，并使整个应用程序失败。请相应地配置最大池大小和最大并发检查点数。</p>
<p>2、Semantic.EXACTLY_ONCE采取所有可能的措施，不要留下任何挥之不去的数据，否则这将有碍于消费者更多地阅读Kafka主题。但是，如果flink应用程序在第一个检查点之前失败，则在重新启动此类应用程序后，系统种将没有有关先前池大小信息，因此，在第一个检查点完成前按比例缩小Flink应用程序的FlinkKafkaProducer011.SAFE_SCALE_DOWN_FACTOR</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//1。设置最大允许的并行<span class="selector-tag">checkpoint</span>数，防止超过<span class="selector-tag">producer</span>池的个数发生异常</span><br><span class="line"><span class="selector-tag">env</span><span class="selector-class">.getCheckpointConfig</span><span class="selector-class">.setMaxConcurrentCheckpoints</span>(5) </span><br><span class="line">//2。设置<span class="selector-tag">producer</span>的<span class="selector-tag">ack</span>传输配置</span><br><span class="line">// 设置超市时长，默认15分钟，建议1个小时以上</span><br><span class="line"><span class="selector-tag">producerConfig</span><span class="selector-class">.put</span>(<span class="selector-tag">ProducerConfig</span><span class="selector-class">.ACKS_CONFIG</span>, 1) </span><br><span class="line"><span class="selector-tag">producerConfig</span><span class="selector-class">.put</span>(<span class="selector-tag">ProducerConfig</span><span class="selector-class">.TRANSACTION_TIMEOUT_CONFIG</span>, 15000) </span><br><span class="line"></span><br><span class="line">//3。在下一个<span class="selector-tag">kafka</span> <span class="selector-tag">consumer</span>的配置文件，或者代码中设置<span class="selector-tag">ISOLATION_LEVEL_CONFIG-read-commited</span></span><br><span class="line">//<span class="selector-tag">Note</span>:必须在下一个<span class="selector-tag">consumer</span>中指定，当前指定是没用用的</span><br><span class="line"><span class="selector-tag">kafkaonfigs</span><span class="selector-class">.setProperty</span>(<span class="selector-tag">ConsumerConfig</span><span class="selector-class">.ISOLATION_LEVEL_CONFIG</span>,&quot;<span class="selector-tag">read_commited</span>&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>完整应用代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shufang.flink.connectors</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.TimeCharacteristic</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.Semantic</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line"></span><br><span class="line">object KafkaSource01 &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这是checkpoint的超时时间</span></span><br><span class="line">    <span class="comment">//env.getCheckpointConfig.setCheckpointTimeout()</span></span><br><span class="line">    <span class="comment">//设置最大并行的chekpoint</span></span><br><span class="line">    env.getCheckpointConfig.setMaxConcurrentCheckpoints(<span class="number">5</span>)</span><br><span class="line">    env.getCheckpointConfig.setCheckpointInterval(<span class="number">1000</span>) <span class="comment">//增加checkpoint的中间时长，保证可靠性</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 为了保证数据的一致性，我们开启Flink的checkpoint一致性检查点机制，保证容错</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    env.enableCheckpointing(<span class="number">60000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从kafka获取数据，一定要记得添加checkpoint，能保证offset的状态可以重置，从数据源保证数据的一致性</span></span><br><span class="line"><span class="comment">     * 保证kafka代理的offset与checkpoint备份中保持状态一致</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    val kafkaonfigs = <span class="keyword">new</span> Properties()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka的启动集群</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">    <span class="comment">//指定消费者组</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;flinkConsumer&quot;</span>)</span><br><span class="line">    <span class="comment">//指定key的反序列化类型</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer].getName)</span><br><span class="line">    <span class="comment">//指定value的反序列化类型</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer].getName)</span><br><span class="line">    <span class="comment">//指定自动消费offset的起点配置</span></span><br><span class="line">    <span class="comment">//    kafkaonfigs.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义kafkaConsumer，同时可以指定从哪里开始消费</span></span><br><span class="line"><span class="comment">     * 开启了Flink的检查点之后，我们还要开启kafka-offset的检查点，通过kafkaConsumer.setCommitOffsetsOnCheckpoints(true)开启，</span></span><br><span class="line"><span class="comment">     * 一旦这个检查点开启，那么之前配置的 auto-commit-enable = true的配置就会自动失效</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    val kafkaConsumer = <span class="keyword">new</span> FlinkKafkaConsumer[String](</span><br><span class="line">      <span class="string">&quot;console-topic&quot;</span>,</span><br><span class="line">      <span class="keyword">new</span> SimpleStringSchema(), <span class="comment">// 这个schema是将kafka的数据应设成Flink中的String类型</span></span><br><span class="line">      kafkaonfigs</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 开启kafka-offset检查点状态保存机制</span></span><br><span class="line">    kafkaConsumer.setCommitOffsetsOnCheckpoints(<span class="keyword">true</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromEarliest()//</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromTimestamp(1010003794)</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromLatest()</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromSpecificOffsets(Map[KafkaTopicPartition,Long]()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加source数据源</span></span><br><span class="line">    val kafkaStream: DataStream[String] = env.addSource(kafkaConsumer)</span><br><span class="line"></span><br><span class="line">    kafkaStream.print()</span><br><span class="line"></span><br><span class="line">    val sinkStream: DataStream[String] = kafkaStream.assignTimestampsAndWatermarks(<span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor[String](Time.seconds(<span class="number">5</span>)) &#123;</span><br><span class="line">      <span class="function">override def <span class="title">extractTimestamp</span><span class="params">(element: String)</span>: Long </span>= &#123;</span><br><span class="line">        element.split(<span class="string">&quot;,&quot;</span>)(<span class="number">1</span>).toLong</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过FlinkkafkaProduccer API将stream的数据写入到kafka的&#x27;sink-topic&#x27;中</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//    val brokerList = &quot;localhost:9092&quot;</span></span><br><span class="line">    val topic = <span class="string">&quot;sink-topic&quot;</span></span><br><span class="line">    val producerConfig = <span class="keyword">new</span> Properties()</span><br><span class="line">    producerConfig.put(ProducerConfig.ACKS_CONFIG, <span class="keyword">new</span> Integer(<span class="number">1</span>)) <span class="comment">// 设置producer的ack传输配置</span></span><br><span class="line">    producerConfig.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, Time.hours(<span class="number">2</span>)) <span class="comment">//设置超市时长，默认1小时，建议1个小时以上</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义producer，可以通过不同的构造器创建</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    val producer: FlinkKafkaProducer[String] = <span class="keyword">new</span> FlinkKafkaProducer[String](</span><br><span class="line">      topic,</span><br><span class="line">      <span class="keyword">new</span> KeyedSerializationSchemaWrapper[String](SimpleStringSchema),</span><br><span class="line">      producerConfig,</span><br><span class="line">      Semantic.EXACTLY_ONCE</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    FlinkKafkaProducer.SAFE_SCALE_DOWN_FACTOR</span></span><br><span class="line">    <span class="comment">/** *****************************************************************************************************************</span></span><br><span class="line"><span class="comment">     * * 出了要开启flink的checkpoint功能，同时还要设置相关配置功能。</span></span><br><span class="line"><span class="comment">     * * 因在0.9或者0.10，默认的FlinkKafkaProducer只能保证at-least-once语义，假如需要满足at-least-once语义，我们还需要设置</span></span><br><span class="line"><span class="comment">     * * setLogFailuresOnly(boolean)    默认false</span></span><br><span class="line"><span class="comment">     * * setFlushOnCheckpoint(boolean)  默认true</span></span><br><span class="line"><span class="comment">     * * come from 官网 below：</span></span><br><span class="line"><span class="comment">     * * Besides enabling Flink’s checkpointing，you should also configure the setter methods setLogFailuresOnly(boolean)</span></span><br><span class="line"><span class="comment">     * * and setFlushOnCheckpoint(boolean) appropriately.</span></span><br><span class="line"><span class="comment">     * ******************************************************************************************************************/</span></span><br><span class="line"></span><br><span class="line">    producer.setLogFailuresOnly(<span class="keyword">false</span>) <span class="comment">//默认是false</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 除了启用Flink的检查点之外，还可以通过将适当的semantic参数传递给FlinkKafkaProducer011（FlinkKafkaProducer对于Kafka&gt; = 1.0.0版本）</span></span><br><span class="line"><span class="comment">     * 来选择三种不同的操作模式：</span></span><br><span class="line"><span class="comment">     * Semantic.NONE  代表at-mostly-once语义</span></span><br><span class="line"><span class="comment">     * Semantic.AT_LEAST_ONCE（Flink默认设置）</span></span><br><span class="line"><span class="comment">     * Semantic.EXACTLY_ONCE：使用Kafka事务提供一次精确的语义，每当您使用事务写入Kafka时，</span></span><br><span class="line"><span class="comment">     * 请不要忘记为使用Kafka记录的任何应用程序设置所需的设置isolation.level（read_committed 或read_uncommitted-后者是默认值)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    sinkStream.addSink(producer)</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">&quot;kafka source &amp; sink&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a target="_blank" rel="noopener" href="http://shiyanjun.cn/archives/1855.html">Flink Checkpoint、Savepoint配置与实践</a></li>
<li><a target="_blank" rel="noopener" href="http://wuchong.me/blog/2018/11/04/how-apache-flink-manages-kafka-consumer-offsets/">Flink 小贴士 (2)：Flink 如何管理 Kafka 消费位点</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4bcbcda0e2f4">Flink实时计算-深入理解Checkpoint和Savepoint</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.08603">Lightweight Asynchronous Snapshots for Distributed Dataflows: 分布式数据流轻量级异步快照</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">223</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">106</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
