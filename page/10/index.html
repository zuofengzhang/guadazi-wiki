<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/page/10/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/10/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-distributed-snapshot/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-distributed-snapshot/" class="post-title-link" itemprop="url">Flink-分布式快照机制</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-distributed-snapshot"><a href="#Flink-distributed-snapshot" class="headerlink" title="Flink-distributed-snapshot"></a>Flink-distributed-snapshot</h1><p>Flink 的快照机制主要是为了保障作业 failover 时不丢失状态. Flink 提供了一种轻量级的快照机制，不需要停止作业就可以帮助用户持久化内存中的状态数据. </p>
<p><img src="vx_images/121103515291"> </p>
<p>上图中的 <code>markers</code>（与 <code>barrier</code> 语义相同）通过流动来触发快照的制作，每一个编号都代表了一次快照，比如编号为 n 的 <code>markers</code> 从最上游流动到最下游就代表了一次快照的制作过程. 简述如下：</p>
<ul>
<li>系统发送编号为 n 的 <code>markers</code> 到最上游的算子，<code>markers</code> 随着数据往下游流动；</li>
<li>当下游算子收到 <code>marker</code> 后，就开始将自身的状态保存到共享存储中；</li>
<li>当所有最下游的算子接收到 <code>marker</code> 并完成算子快照后，本次作业的快照制作完成. </li>
</ul>
<p>一旦作业失败，重启时就可以从快照恢复. </p>
<p>下面为一个简单的 demo 说明（<code>barrier</code> 等同于 <code>marker</code>）. </p>
<p><img src="vx_images/108294726199"></p>
<ul>
<li><code>barrier</code> 到达 Source，将状态 offset=7 存储到共享存储；</li>
<li><code>barrier</code> 到达 Task，将状态 sum=21 存储到共享存储；</li>
<li><code>barrier</code> 到达 Sink，commit 本次快照，标志着快照的成功制作. </li>
</ul>
<p><img src="vx_images/96412168676"></p>
<p>这时候突然间作业也挂掉， 重启时 Flink 会通过快照恢复各个状态. Source 会将自身的 offset 置为 7，Task 会将自身的 sum 置为 21.<br>现在我们可以认为 1、2、3、4、5、6 这 6 个数字的加和结果并没有丢失. 这个时候，offset 从 7 开始消费，跟作业失败前完全对接了起来，确保了 exactly-once</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/GraalVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/GraalVM/" class="post-title-link" itemprop="url">GraalVM: run programs faster anywhere</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="GraalVM-run-programs-faster-anywhere"><a href="#GraalVM-run-programs-faster-anywhere" class="headerlink" title="GraalVM: run programs faster anywhere"></a>GraalVM: run programs faster anywhere</h1><p>Yudi Zheng 郑雨迪</p>
<p>Graal Compiler Team， Oracle Labs</p>
<p>为什么快？</p>
<p>支持哪些程序</p>
<p>跑在哪里？</p>
<p>compiler optimization ， performace tuning， X64 backend</p>
<p>ahead-of-time<br>experimental java-based JIT Compiler</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-VS-Spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-VS-Spark/" class="post-title-link" itemprop="url">Flink VS Spark</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-VS-Spark"><a href="#Flink-VS-Spark" class="headerlink" title="Flink VS Spark"></a>Flink VS Spark</h1><p>Spark Structure Streaming 是什么？</p>
<h3 id="1、抽象-Abstraction"><a href="#1、抽象-Abstraction" class="headerlink" title="1、抽象 Abstraction"></a>1、抽象 Abstraction</h3><p>　　Spark中，对于批处理我们有RDD,对于流式，我们有DStream，不过内部实际还是RDD.所以所有的数据表示本质上还是RDD抽象。在Flink中，对于批处理有DataSet，对于流式我们有DataStreams。看起来和Spark类似，他们的不同点在于：</p>
<p>　　<strong>（一）DataSet在运行时是表现为运行计划(runtime plans)的</strong></p>
<p>　　在Spark中，RDD在运行时是表现为java objects的。通过引入Tungsten，这块有了些许的改变。但是在Flink中是被表现为logical plan(逻辑计划)的, 就是类似于Spark中的dataframes。所以在Flink中你使用的类Dataframe api是被作为第一优先级来优化的。但是相对来说在Spark RDD中就没有了这块的优化了。<br>　　Flink中的Dataset，对标Spark中的Dataframe，在运行前会经过优化。在Spark 1.6，dataset API已经被引入Spark了，也许最终会取代RDD 抽象。</p>
<p>　　<strong>(二）Dataset和DataStream是独立的API</strong></p>
<p>　　在Spark中，所有不同的API，例如DStream，Dataframe都是基于RDD抽象的。但是在Flink中，Dataset和DataStream是同一个公用的引擎之上两个独立的抽象。所以你不能把这两者的行为合并在一起操作，当然，Flink社区目前在朝这个方向努力(<code>https://issues.apache.org/jira/browse/Flink-2320</code>)，但是目前还不能轻易断言最后的结果。</p>
<h3 id="2、内存管理"><a href="#2、内存管理" class="headerlink" title="2、内存管理"></a>2、内存管理</h3><p>　　一直到1.5版本，Spark都是试用java的内存管理来做数据缓存，明显很容易导致OOM或者gc。所以从1.5开始，Spark开始转向精确的控制内存的使用，这就是tungsten项目了。</p>
<p>　　而Flink从第一天开始就坚持自己控制内存试用。这个也是启发了Spark走这条路的原因之一。Flink除了把数据存在自己管理的内存以外，还直接操作二进制数据。在Spark中，从1.5开始，所有的dataframe操作都是直接作用在tungsten的二进制数据上。</p>
<h3 id="3、语言实现"><a href="#3、语言实现" class="headerlink" title="3、语言实现"></a>3、语言实现</h3><ul>
<li><p>实现语言</p>
<p>Spark和Flink均有Scala/Java混合编程实现，Spark的核心逻辑由Scala完成，Flink的主要核心逻辑由Java完成</p>
</li>
<li><p>支持应用语言<br> Flink主要支持Scala，和Java编程，部分API支持python应用<br> Spark主要支持Scala，Java，Python,R语言编程，部分API暂不支持Python和R</p>
</li>
</ul>
<h3 id="4、API"><a href="#4、API" class="headerlink" title="4、API"></a>4、API</h3><table>
<thead>
<tr>
<th>API对比</th>
<th>Flink</th>
<th></th>
<th>Spark</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>应用类型</td>
<td>Batch</td>
<td>Streaming</td>
<td>Batch</td>
<td>Structed Streaming</td>
<td>SparkStreaming</td>
</tr>
<tr>
<td>数据表示</td>
<td>Dataset</td>
<td>datastream</td>
<td>RDD,Dataset</td>
<td>Dataset</td>
<td>Dtream</td>
</tr>
<tr>
<td>主要支持API</td>
<td>map,filter,flatMap等</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>转换后数据类型</td>
<td>Dataset</td>
<td>datastream</td>
<td>RDD,Dataset</td>
<td>Dataset</td>
<td>Dtream</td>
</tr>
</tbody></table>
<h4 id="批处理："><a href="#批处理：" class="headerlink" title="批处理："></a>批处理：</h4><p>Spark批处理的数据表示经历了从<code>RDD -&gt; DataFrame -&gt; Dataset</code>的变化，均具有不可变，lazy执行，可分区等特性，是Spark框架的核心，rdd经过map等函数操作后，并没有改变而是生成新的RDD，Spark的Dataset（DataFrame是一种特殊的Dataset，已经不推荐使用）还包含数据类型信息</p>
<p>Flink批处理的API是Dataset,同样具有不可变，lazy执行，可分区等特性，是Flink框架的核心，Dataset经过map等函数操作后，并没有改变而是生成新的Dataset</p>
<h4 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h4><ul>
<li><p>Spark Streaming</p>
<p>Spark在1.*版本引入的spark streaming作为流处理模块，抽象出Dstream的API来进行流数据处理，同时抽象出通过receiver获取消息数据，然后启动task处理的模式，以及直接启动task消费处理两种方式的流式数据处理。receiver模式由于稳定性不足被遗弃，推荐使用的是直接消费模式；然而本质上讲，Sparkstreaming的流处理是micro-batch的处理模式，将一定时间的流数据作为一个block/RDD，然后使用批处理的rdd的api来完成数据的处理。</p>
</li>
<li><p>Structed streaming</p>
<p>随着Spark在2.*版本的Structed streaming的推出，Spark streaming模块进入了维护模式，从Spark2.*版本以来没有已经没有更新，当前社区主推使用Structed streaming进行流处理。Structed streaming在流处理中有两种流处理模式，一种是microbatch模式；一种是continuous模式；</p>
<ul>
<li><p>microbatch模式与spark streaming的microbatch模式大致相当，分批处理消息，但可通过设置连续的批次处理，即一个批次执行完之后立即进入下一个批次的处理</p>
</li>
<li><p>continuous模式，可以实现真正的流数据处理，端到端的毫秒级，当前处于Experiment状态，也只能支持简单的map,filter操作，当前不支持聚合，<code>current_timestamp</code>，<code>current_date</code>等操作</p>
</li>
<li><p>PS : microbatch &lt;—-&gt; continuous 两种模式可以相互切换且无需改动代码</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>Flink Streaming</p>
<p>Flink Streaming以流的方式处理流数据，可以实现简单map,fliter等操作，也可以实现复杂的聚合，关联操作，以完善的处理模型及high throughout得到了广泛的应用。</p>
</li>
</ul>
<p>　　Spark和Flink都在模仿scala的collection API.所以从表面看起来，两者都很类似。下面是分别用RDD和DataSet API实现的word count</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Spark wordcount</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="keyword">new</span> <span class="type">SparkContext</span>(<span class="string">&quot;local&quot;</span>,<span class="string">&quot;wordCount&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> data = <span class="type">List</span>(<span class="string">&quot;hi&quot;</span>,<span class="string">&quot;how are you&quot;</span>,<span class="string">&quot;hi&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> dataSet = env.parallelize(data)</span><br><span class="line">    <span class="keyword">val</span> words = dataSet.flatMap(value =&gt; value.split(<span class="string">&quot;\\s+&quot;</span>))</span><br><span class="line">    <span class="keyword">val</span> mappedWords = words.map(value =&gt; (value,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">val</span> sum = mappedWords.reduceByKey(_+_)</span><br><span class="line">    println(sum.collect())</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// Flink wordcount</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">　　<span class="keyword">val</span> env = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">　　<span class="keyword">val</span> data = <span class="type">List</span>(<span class="string">&quot;hi&quot;</span>,<span class="string">&quot;how are you&quot;</span>,<span class="string">&quot;hi&quot;</span>)</span><br><span class="line">　　<span class="keyword">val</span> dataSet = env.fromCollection(data)</span><br><span class="line">　　<span class="keyword">val</span> words = dataSet.flatMap(value =&gt; value.split(<span class="string">&quot;\\s+&quot;</span>))</span><br><span class="line">　　<span class="keyword">val</span> mappedWords = words.map(value =&gt; (value,<span class="number">1</span>))</span><br><span class="line">　　<span class="keyword">val</span> grouped = mappedWords.groupBy(<span class="number">0</span>)</span><br><span class="line">　　<span class="keyword">val</span> sum = grouped.sum(<span class="number">1</span>)</span><br><span class="line">　　println(sum.collect())</span><br><span class="line">　&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>　　不知道是偶然还是故意的，API都长得很像，这样很方便开发者从一个引擎切换到另外一个引擎。我感觉以后这种Collection API会成为写data pipeline的标配。</p>
<h3 id="5、Steaming"><a href="#5、Steaming" class="headerlink" title="5、Steaming"></a>5、Steaming</h3><p>　　Spark把streaming看成是更快的批处理，而Flink把批处理看成streaming的special case。这里面的思路决定了各自的方向，其中两者的差异点有如下这些：</p>
<p><strong>实时 vs 近实时的角度</strong></p>
<p>　　Flink提供了基于每个事件的流式处理机制，所以可以被认为是一个真正的流式计算。它非常像storm的model。而Spark，不是基于事件的粒度，而是用小批量来模拟流式，也就是多个事件的集合。所以Spark被认为是近实时的处理系统。</p>
<p>　　Spark streaming 是更快的批处理，而Flink Batch是有限数据的流式计算。虽然大部分应用对准实时是可以接受的，但是也还是有很多应用需要event level的流式计算。这些应用更愿意选择storm而非Spark streaming，现在，Flink也许是一个更好的选择。</p>
<p><strong>流式计算和批处理计算的表示</strong></p>
<p>　　Spark对于批处理和流式计算，都是用的相同的抽象：RDD，这样很方便这两种计算合并起来表示。而Flink这两者分为了DataSet和DataStream，相比Spark，这个设计算是一个糟糕的设计。</p>
<p><strong>对 windowing 的支持</strong></p>
<p>　　因为Spark的小批量机制，Spark对于windowing的支持非常有限。只能基于process time，且只能对batches来做window。而Flink对window的支持非常到位，且Flink对windowing API的支持是相当给力的，允许基于process time,data time,record 来做windowing。我不太确定Spark是否能引入这些API，不过到目前为止，Flink的windowing支持是要比Spark好的。Steaming这部分Flink胜</p>
<table>
<thead>
<tr>
<th>Window 类型</th>
<th>Window 含义</th>
<th>Flink Streaming</th>
<th>SparkStreaming</th>
<th>Structed Streaming</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>tumblingWindow</td>
<td>一个滚动的window</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>Sliding window</td>
<td>滑动的window</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>Global window</td>
<td>全局window</td>
<td>支持</td>
<td>间接实现</td>
<td>间接支持</td>
<td>间接支持的含义是可以时间类似功能，但没有抽象出该window</td>
</tr>
<tr>
<td>Session window</td>
<td>以接收到数据开始，一定时间没有接收到数据，则结束</td>
<td>支持</td>
<td>不支持</td>
<td>不支持</td>
<td></td>
</tr>
</tbody></table>
<p><strong>流join分析：</strong></p>
<p>由于Spark streaming中不支持event time的概念，其只能支持window不同Dstream的RDD的join，不同window间无法join</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>event-time</th>
<th>流join</th>
<th>join实现方式</th>
<th>处理方式</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Spark streaming</td>
<td>不支持</td>
<td>支持</td>
<td>window内</td>
<td>processingTime</td>
<td>micro-batch处理</td>
</tr>
<tr>
<td>FLink1.5之前</td>
<td>支持</td>
<td>支持</td>
<td>window内</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime ／ element Number</td>
</tr>
<tr>
<td>FLink1.6之后</td>
<td>支持</td>
<td>支持</td>
<td>window内，跨window</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime ／ element Number</td>
</tr>
<tr>
<td>Structed Streaming 2.2</td>
<td>支持</td>
<td>不支持</td>
<td>仅支持流数据和静态数据的join</td>
<td>native处理，join时(window触发)，watermark灵活</td>
<td>Processing Time／ EventTime</td>
</tr>
<tr>
<td>Structed Streaming 2.3+</td>
<td>支持</td>
<td>支持</td>
<td>跨window</td>
<td>native处理，join时（proocessingTime（interval）触发）</td>
<td>Processing Time／ EventTime</td>
</tr>
</tbody></table>
<p>PS:</p>
<ul>
<li>Flink／structed streaming开发难度相当，FLink略复杂，但灵活度更高</li>
<li>Flink的inteval join</li>
<li>Structed Streaming支持数据去重（同个imsi的数据的多个不同join结果的去重）</li>
<li>FLink的窗口操作相当于structed streaming的update模式</li>
<li>Flink的单流的watermark更新时实时的，有专门线程处理</li>
<li>Structed streaming的watermark更新时间基于批的，每个批次共用同一个watermark，如果有多个流，多个流共用一个watermark</li>
<li>structed Streaming的watermark更新方法：<br> 基于每个流找出该流的watermark：Max_event_time - lateness<br> 找出所有流中最小/最大的watermark设置为batch的watermark</li>
<li>Flink专门抽象了类以便不同场景下使用自定义的eventTime的waterMark获取/设置方法,且提供了一般场景下的的类以便使用</li>
<li>Flink抽象了trigger和evictor来实现触发计算和清理数据的逻辑，以便自定义相关逻辑</li>
<li>FLink 支持sideoutput输出，如迟到的数据可以单独输出</li>
</ul>
<h3 id="6、SQL-interface"><a href="#6、SQL-interface" class="headerlink" title="6、SQL interface"></a>6、SQL interface</h3><p>　　目前Spark-sql是Spark里面最活跃的组件之一，Spark提供了类似Hive的sql和Dataframe这种DSL来查询结构化数据，API很成熟，在流式计算中使用很广，预计在流式计算中也会发展得很快。至于Flink，到目前为止，Flink Table API只支持类似DataFrame这种DSL，并且还是处于beta状态，社区有计划增加SQL 的interface，但是目前还不确定什么时候才能在框架中用上。所以这个部分，Spark胜出。目前Flink已经支持SQL API</p>
<h3 id="7、外部数据源的整合"><a href="#7、外部数据源的整合" class="headerlink" title="7、外部数据源的整合"></a>7、外部数据源的整合</h3><p>　　Spark的数据源 API是整个框架中最好的，支持的数据源包括NoSql db,parquet,ORC等，并且支持一些高级的操作，例如predicate push down。Flink目前还依赖map/reduce InputFormat来做数据源聚合。这一场Spark胜，目前已经提供 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">env.readTextFile(path_i)</span><br><span class="line">env.writeTextFile(path_i)</span><br></pre></td></tr></table></figure>


<h3 id="8、Iterative-processing"><a href="#8、Iterative-processing" class="headerlink" title="8、Iterative processing"></a>8、Iterative processing</h3><p>![Flink 迭代处理](_v_images/20190723102241286_1833770582.png =519x)<br>![Spark迭代处理](_v_images/20190723102318593_811318029.png =519x)<br>　　Spark对机器学习的支持较好，因为利用内存cache来加速机器学习算法。然而大部分机器学习算法其实是一个有环的数据流，但是在Spark中，实际是用无环图来表示的，一般的分布式处理引擎都是不鼓励试用有环图的。但是Flink这里又有点不一样，Flink支持在runtime中的有环数据流，这样表示机器学习算法更有效而且更有效率。这一点Flink胜出。</p>
<h3 id="9、Stream-as-platform-vs-Batch-as-Platform"><a href="#9、Stream-as-platform-vs-Batch-as-Platform" class="headerlink" title="9、Stream as platform vs Batch as Platform"></a>9、Stream as platform vs Batch as Platform</h3><ul>
<li><p>Spark诞生在Map/Reduce的时代，数据都是以文件的形式保存在磁盘中，这样非常方便做容错处理。</p>
</li>
<li><p>Flink把纯流式数据计算引入大数据时代，无疑给业界带来了一股清新的空气。这个idea非常类似akka-streams这种。</p>
</li>
</ul>
<p>【参考文献】</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://www.iteblog.com/archives/1624.html">Apache Flink vs Apache Spark</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/da1910535f73">Flink vs Spark</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E8%B0%83%E4%BC%98%E8%AF%A6%E8%A7%A3%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/Java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E8%B0%83%E4%BC%98%E8%AF%A6%E8%A7%A3%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">【转载】Java生产环境下性能监控与调优详解笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Java生产环境下性能监控与调优详解笔记"><a href="#Java生产环境下性能监控与调优详解笔记" class="headerlink" title="Java生产环境下性能监控与调优详解笔记"></a>Java生产环境下性能监控与调优详解笔记</h1><p>另一个整理<a target="_blank" rel="noopener" href="http://alanhou.org/java-optimization/">http://alanhou.org/java-optimization/</a></p>
<h2 id="1：JVM字节码指令与-javap"><a href="#1：JVM字节码指令与-javap" class="headerlink" title="1：JVM字节码指令与 javap"></a>1：JVM字节码指令与 javap</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">javap &lt;options&gt; &lt;classes&gt;</span><br><span class="line"><span class="built_in">cd</span> monitor\_tuning/target/classes/org/alanhou/monitor\_tuning/chapter8/</span><br><span class="line">javap -verbose Test1.class &gt; Test1.txt</span><br></pre></td></tr></table></figure>
<p>即可保存字节码文件<br>会有三个部分组成<br>操作数栈<br>LineNumberTable<br>LocalVariableTable</p>
<p>i++和++i 的执行效果完全相同 多了一个压入栈顶操作<br>for(int i=0;i&lt;10;i++) {}<br>for(int i=0;i&lt;10;++i) {} 执行效果一样</p>
<p>2：</p>
<p>public static void f1() {<br>String src = “”;<br>for(int i=0;i&lt;10;i++) {<br>//每一次循环都会new一个StringBuilder 然后在src.append(“A”);<br>src = src + “A”;<br>}<br>System.out.println(src);<br>}<br>public static void f2() {<br>//只要一个StringBuilder<br>StringBuilder src = new StringBuilder();<br>for(int i=0;i&lt;10;i++) {<br>src.append(“A”);<br>}<br>System.out.println(src);<br>}</p>
<p>3：</p>
<p>public static String f1() {<br>String str = “hello”;<br>try{<br>return str;<br>}<br>finally{<br>str = “imooc”;<br>}<br>} 返回 hello 但会执行finally 中的代码</p>
<p>4：字符串拼接都会在编译阶段转换成stringbuilder</p>
<p>5:字符串去重</p>
<p>字符串在任何应用中都占用了大量的内存。尤其数包含独立UTF-16字符的char[]数组对JVM内存的消耗贡献最多——因为每个字符占用2位。</p>
<p>内存的30%被字符串消耗其实是很常见的，不仅是因为字符串是与我们互动的最好的格式，而且是由于流行的HTTP API使用了大量的字符串。使用Java 8 Update 20，我们现在可以接触到一个新特性，叫做字符串去重，该特性需要G1垃圾回收器，该垃圾回收器默认是被关闭的。</p>
<p>字符串去重利用了字符串内部实际是char数组，并且是final的特性，所以JVM可以任意的操纵他们。</p>
<p>对于字符串去重，开发者考虑了大量的策略，但最终的实现采用了下面的方式：</p>
<p>无论何时垃圾回收器访问了String对象，它会对char数组进行一个标记。它获取char数组的hash value并把它和一个对数组的弱引用存在一起。只要垃圾回收器发现另一个字符串，而这个字符串和char数组具有相同的hash code，那么就会对两者进行一个字符一个字符的比对。</p>
<p>如果他们恰好匹配，那么一个字符串就会被修改，指向第二个字符串的char数组。第一个char数组就不再被引用，也就可以被回收了。</p>
<p>这整个过程当然带来了一些开销，但是被很紧实的上限控制了。例如，如果一个字符未发现有重复，那么一段时间之内，它会不再被检查。</p>
<p>那么该特性实际上是怎么工作的呢？首先，你需要刚刚发布的Java 8 Update 20，然后按照这个配置: -Xmx256m -XX:+UseG1GC 去运行下列的代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LotsOfStrings</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> LinkedList LOTS_OF_STRINGS = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> iteration = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">1000</span>; j++) &#123;</span><br><span class="line">                    LOTS_OF_STRINGS.add(<span class="keyword">new</span> String(<span class="string">&quot;String &quot;</span> + j));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            iteration++;</span><br><span class="line">            System.out.println(<span class="string">&quot;Survived Iteration: &quot;</span> + iteration);</span><br><span class="line">            Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码会执行30个迭代之后报OutOfMemoryError。</p>
<p>现在，开启字符串去重，使用如下配置去跑上述代码：</p>
<p>-Xmx256m -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintStringDeduplicationStatistics</p>
<p>此时它已经可以运行更长的时间，而且在50个迭代之后才终止。</p>
<p>6:</p>
<p>ArrayLIst  底层是数组  扩容会拷贝<br>hashmap   底层也是数组+ 链表 扩容 重新计算key 负载因子是 0.75  </p>
<p>linklist底层是双向链表<br>1. 尽量重用对象，不要循环创建对象，比如:for 循环字符串拼接(不在 for中使用+拼接，先new 一个StringBuilder再在 for 里 append)  </p>
<p>2. 容器类初始化的地时候指定长度  </p>
<p>List<String> collection = new ArrayLIst<String>(5);  </p>
<p>Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(32);  </p>
<p>3. ArrayList（底层数组）随机遍历快，LinkedList（底层双向链表）添加删除快  </p>
<p>4. 集合遍历尽量减少重复计算  </p>
<p>5. 使用 Entry 遍历 Map可以同时取出key和value  </p>
<p>6. 大数组复制使用System.arraycopy 底层是native实现的  </p>
<p>7. 尽量使用基本类型而不是包装类型  </p>
<p>public class Test03 {  </p>
<p>  public static void main(String[] args) {<br>  Integer f1 = 100, f2 = 100, f3 = 150, f4 = 150;  </p>
<p>  System.out.println(f1 == f2);<br>  System.out.println(f3 == f4);<br>}<br>}  </p>
<p>如果不明就里很容易认为两个输出要么都是true要么都是false。首先需要注意的是f1、f2、f3、f4四个变量都是Integer对象引用，所以下面的==运算比较的不是值而是引用。装箱的本质是什么呢？当我们给一个Integer对象赋一个int值的时候，会调用Integer类的静态方法valueOf，如果看看valueOf的源代码就知道发生了什么。<br>public static Integer valueOf(int i) {<br>  if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)<br>    return IntegerCache.cache[i + (-IntegerCache.low)];<br>  return new Integer(i);<br>}<br>简单的说，如果整型字面量的值在-128到127之间，那么不会new新的Integer对象，而是直接引用常量池中的Integer对象，所以上面的面试题中f1==f2的结果是true，而f3==f4的结果是false。<br>8. 不要手动调用 System.gc()  </p>
<p>9. 及时消除过期对象的引用，防止内存泄漏<br>public string pop()<br>{<br>  string currentValue=object[size];<br>  //object[size]=null;如果不添加这句话就会造成内存泄漏<br>  size–;<br>  return currentValue;<br>}  </p>
<p>10. 尽量使用局部变量，减小变量的作用域 方便出了作用域尽快垃圾回收  </p>
<p>11. 尽量使用非同步的容器ArraryList vs. Vector  </p>
<p>12. 尽量减小同步作用范围, synchronized 方法 vs. 代码块  </p>
<p>public class SynchronizedTest {<br>  public static void main(String[] args) {<br>}<br>public synchronized void f1() {//在this對象上加鎖<br>  System.out.println(“f1”);<br>}<br>public  void f2() {//在this對象上加鎖<br>  synchronized(this) {<br>    System.out.println(“f2”);<br>  }<br>}<br>public static synchronized void f3() {//在类上加鎖<br>  System.out.println(“f3”);<br>}<br>public static void f4() {//在类上加鎖<br>  synchronized(SynchronizedTest.class) {<br>    System.out.println(“f4”);<br>  }<br>}<br>}  </p>
<p>13. 用ThreadLocal 缓存线程不安全的对象，SimpleDateFormat 缓存重量的对象避免重新构造<br>@SuppressWarnings(“rawtypes”)<br>    private static ThreadLocal threadLocal = new ThreadLocal() {<br>        protected synchronized Object initialValue() {<br>            return new SimpleDateFormat(DATE_FORMAT);<br>        }<br>    };  </p>
<p>14. 尽量使用延迟加载  </p>
<p>15. 尽量减少使用反射，必须用加缓存，反射比较影响性能  </p>
<p>16. 尽量使用连接池、线程池、对象池、缓存  </p>
<p>17. 及时释放资源， I/O 流、Socket、数据库连接  </p>
<p>18. 慎用异常，不要用抛异常来表示正常的业务逻辑，异常也是比较重的对象要记录堆栈信息  </p>
<p>19. String 操作尽量少用正则表达式 比如replaceAll是用正则 比较耗费性能 replace就不是用正则  </p>
<p>20. 日志输出注意使用不同的级别  </p>
<p>21. 日志中参数拼接使用占位符<br>log.info(“orderId:” + orderId); 不推荐 会用字符串拼接<br>log.info(“orderId:{}”, orderId); 推荐 用占位符 不会进行字符串拼接  </p>
<p>7：JVM的参数类型</p>
<p>标准参数（各版本中保持稳定）</p>
<p>-help</p>
<p>-server -client</p>
<p>-version -showversion</p>
<p>-cp -classpath</p>
<p>X 参数（非标准化参数）</p>
<p>-Xint：解释执行</p>
<p>-Xcomp：第一次使用就编译成本地代码</p>
<p>-Xmixed：混合模式，JVM 自己决定是否编译成本地代码</p>
<p>示例：</p>
<p>java -version（默认是混合模式）</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, mixed mode)</p>
<p>java -Xint -version</p>
<p>Java HotSpot(TM) 64-Bit Server VM (build 25.40-b25, interpreted mode)</p>
<p>XX 参数（非标准化参数）</p>
<p>主要用于 JVM调优和 debug</p>
<ul>
<li>Boolean类型</li>
</ul>
<p>格式：-XX:[+-]<name>表示启用或禁用 name 属性<br>如：-XX:+UseConcMarkSweepGC<br>-XX:+UseG1GC</p>
<ul>
<li>非Boolean类型</li>
</ul>
<p>格式：-XX:<name>=<value>表示 name 属性的值是 value<br>如：-XX:MaxGCPauseMillis=500<br>-xx:GCTimeRatio=19<br>-Xmx -Xms属于 XX 参数<br>-Xms 等价于-XX:InitialHeapSize<br>-Xmx 等价于-XX:MaxHeapSize<br>-xss 等价于-XX:ThreadStackSize</p>
<h3 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h3><p>-XX:+PrintFlagsInitial 查看jvm初始值</p>
<p>-XX:+PrintFlagsFinal 查看jvm最终值</p>
<p>-XX:+UnlockExperimentalVMOptions 解锁实验参数</p>
<p>-XX:+UnlockDiagnosticVMOptions 解锁诊断参数</p>
<p>-XX:+PrintCommandLineFlags 打印命令行参数</p>
<p>输出结果中=表示默认值，:=表示被用户或 JVM 修改后的值</p>
<p>示例：java -XX:+PrintFlagsFinal -version</p>
<p>补充：测试中需要用到 Tomcat，CentOS 7安装示例如下</p>
<p><code>sudo </code>yum -y ``install java-1.8.0-openjdk*<br>wget  <a target="_blank" rel="noopener" href="http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz">http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz</a><br>tar -zxvf apache-tomcat-8.5.32.tar.gz<br>mv apache-tomcat-8.5.32 tomcat<br>cd tomcat/bin/sh startup.sh</p>
<p>pid 可通过类似 ps -ef|grep tomcat或 jps来进行查看</p>
<h3 id="jps"><a href="#jps" class="headerlink" title="jps"></a>jps</h3><p>查看java进程 -l 可以知道完全类名</p>
<h3 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a>jinfo</h3><p>jinfo -flag MaxHeapSize <pid></p>
<p>jinfo -flags <pid>  手动赋过值的参数</p>
<h3 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h3><p>可以查看jvm的统计信息 如类加载。垃圾回收信息，jit编译信息</p>
<p>详情参考 <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html">jstat 官方文档</a></p>
<p><img src="_v_images/20200117100110226_7723.jpg" alt="jstat 使用示例"></p>
<p>类加载</p>
<h1 id="以下1000表每隔1000ms-即1秒，共输出10次"><a href="#以下1000表每隔1000ms-即1秒，共输出10次" class="headerlink" title="以下1000表每隔1000ms 即1秒，共输出10次"></a>以下1000表每隔1000ms 即1秒，共输出10次</h1><p>jstat -class <pid> 1000 10</p>
<p>垃圾收集</p>
<p>-gc, -gcutil, -gccause, -gcnew, -gcold</p>
<p>jstat -gc <pid> 1000 10</p>
<p>以下大小的单位均为 KB</p>
<p>![](_v_images/20200117100110111_28215.png =800x600)</p>
<p>S0C, S1C, S0U, S1U: S0和 S1的总量和使用量</p>
<p>EC, EU: Eden区总量与使用量</p>
<p>OC, OU: Old区总量与使用量</p>
<p>MC, MU: Metacspace区(jdk1.8前为 PermGen)总量与使用量</p>
<p>CCSC, CCSU: 压缩类区总量与使用量</p>
<p>YGC, YGCT: YoungGC 的次数与时间</p>
<p>FGC, FGCT: FullGC 的次数与时间</p>
<p>GCT: 总的 GC 时间</p>
<p>JIT 编译</p>
<p>-compiler, -printcompilation</p>
<p>一个对象默认分配在堆上面 但是有个指针指向class默认是64位长指针，可以设置为用32位存储在压缩类空间</p>
<p>非堆区 即对应于虚拟机规范中的方法区 是操作系统本地内存 独立于jvm堆区之外 jdk8后面叫metaspace jdk8前面叫performancespace</p>
<p>codecache 存储的是jit即时编译的代码 以及native代码</p>
<h3 id="jmap-MAT"><a href="#jmap-MAT" class="headerlink" title="jmap+MAT"></a>jmap+MAT</h3><p>详情参考<a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jmap.html">jmap 官方文档</a></p>
<p>内存溢出演示：</p>
<p><a target="_blank" rel="noopener" href="https://start.spring.io/%E7%94%9F%E6%88%90%E5%88%9D%E5%A7%8B%E4%BB%A3%E7%A0%81">https://start.spring.io/生成初始代码</a></p>
<p>最终代码：<a target="_blank" rel="noopener" href="https://github.com/alanhou7/java-codes/tree/master/monitor_tuning">monitor_tuning</a></p>
<p>为快速产生内存溢出，右击 Run As&gt;Run Configurations, Arguments 标签VM arguments 中填入</p>
<p>-Xmx32M -Xms32M</p>
<p><img src="_v_images/20200117100109881_9995.png"></p>
<p>访问 <a target="_blank" rel="noopener" href="http://localhost:8080/heap">http://localhost:8080/heap</a></p>
<p>Exception in thread “http-nio-8080-exec-2” Exception in thread “http-nio-8080-exec-1” java.lang.OutOfMemoryError: Java heap space<br>java.lang.OutOfMemoryError: Java heap space</p>
<p>-XX:MetaspaceSize=32M -XX:MaxMetaspaceSize=32M（同时在 pom.xml 中加入 asm 的依赖）</p>
<p><img src="_v_images/20200117100109670_1795.png"></p>
<p>访问 <a target="_blank" rel="noopener" href="http://localhost:8080/nonheap">http://localhost:8080/nonheap</a></p>
<p>Exception in thread “main” java.lang.OutOfMemoryError: Metaspace<br>Exception in thread “ContainerBackgroundProcessor[StandardEngine[Tomcat]]“ java.lang.OutOfMemoryError: Metaspace</p>
<p>内存溢出自动导出</p>
<p>-XX:+HeapDumpOnOutOfMemoryError</p>
<p>-XX:HeapDumpPath=./</p>
<p>右击 Run As&gt;Run Configurations, Arguments 标签VM arguments 中填入</p>
<p>-Xmx32M -Xms32M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./</p>
<p>可以看到自动在当前目录中生成了一个java_pid660.hprof文件</p>
<p>java.lang.OutOfMemoryError: GC overhead limit exceeded<br>Dumping heap to ./java_pid660.hprof …</p>
<p>另一种导出溢出也更推荐的方式是jmap</p>
<p>option: -heap, -clstats, -dump:<dump-options>, -F</p>
<p>jmap -dump:format=b,file=heap.hprof <pid></p>
<p><img src="_v_images/20200117100109462_23769.jpg" alt="jmap 导出溢出文件"></p>
<p>MAT下载地址：<a target="_blank" rel="noopener" href="http://www.eclipse.org/mat/">http://www.eclipse.org/mat/</a></p>
<p>找开上述导出的内存溢出文件即可进行分析，如下图的溢出源头分析：</p>
<p><img src="_v_images/20200117100109352_8610.jpg" alt="Memory Analyzer 内存溢出分析"></p>
<ol>
<li>Histogram可以列出内存中的对象，对象的个数以及大小。</li>
<li>Dominator Tree可以列出那个线程，以及线程下面的那些对象占用的空间。</li>
</ol>
<p>Histogram</p>
<pre><code>[![](_v_images/20200117100109236_4753.png)](http://static.oschina.net/uploads/space/2014/0702/120039_qSi5_1767531.png)</code></pre>
<ul>
<li><p>Class Name ： 类名称，java类名</p>
</li>
<li><p>Objects ： 类的对象的数量，这个对象被创建了多少个</p>
</li>
<li><p>Shallow Heap ：一个对象内存的消耗大小，不包含对其他对象的引用</p>
</li>
</ul>
<ul>
<li>Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收到内存的总和</li>
</ul>
<p>Dominator Tree</p>
<p><a target="_blank" rel="noopener" href="http://static.oschina.net/uploads/space/2014/0702/145926_K3ET_1767531.png"><img src="_v_images/20200117100109129_22861.png"></a></p>
<p>我们可以看到ibatis占了较多内存</p>
<p>快速找出某个实例没被释放的原因，可以右健 Path to GC Roots–&gt;exclue all phantom/weak/soft etc. reference :</p>
<p> <img src="_v_images/20200117100108918_9987.png"></p>
<p>得到的结果是：</p>
<p><img src="_v_images/20200117100108703_17828.png"></p>
<p>从表中可以看出 PreferenceManager -&gt; … -&gt;HomePage这条线路就引用着这个 HomePage实例。用这个方法可以快速找到某个对象的 <strong>GC Root</strong>,一个存在 GC Root的对象是不会被 GC回收掉的.</p>
<h3 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h3><p>详情参考 <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstack.html">jstack 官方文档</a></p>
<p>jstack <pid>  打印jvm内部所有的线程</p>
<p> <em>jstack 15672 &gt;15673.txt  导出当前进程文件</em></p>
<p>可查看其中包含java.lang.Thread.State: WAITING (parking)，JAVA 线程包含的状态有：</p>
<p>NEW：线程尚未启动</p>
<p>RUNNABLE：线程正在 JVM 中执行</p>
<p>BLOCKED：线程在等待监控锁(monitor lock)</p>
<p>WAITING：线程在等待另一个线程进行特定操作（时间不确定）</p>
<p>TIMED_WAITING：线程等待另一个线程进行限时操作</p>
<p>TERMINATED：线程已退出</p>
<p>此时会生成一个monitor_tuning-0.0.1-SNAPSHOT.jar的 jar包，为避免本地的 CPU 消耗过多导致死机，建议上传上传到虚拟机进行测试</p>
<p>nohup java -jar monitor_tuning-0.0.1-SNAPSHOT.jar &amp;</p>
<p>访问 <a target="_blank" rel="noopener" href="http://xx.xx.xx.xx:12345/loop(%E7%AB%AF%E5%8F%A312345%E5%9C%A8application.properties%E6%96%87%E4%BB%B6%E4%B8%AD%E5%AE%9A%E4%B9%89)">http://xx.xx.xx.xx:12345/loop(端口12345在application.properties文件中定义)</a></p>
<p>top 是查询所有进程的cpu 占用率<br>top还可以用来显示一个进程中各个线程CPU的占用率：top -p <pid> -H<br>top命令如下  </p>
<p><img src="_v_images/20200117100108489_10785.png"></p>
<p>top -p <pid>  -H 命令如下 看的是7930的进程</p>
<p><img src="_v_images/20200117100108169_20096.png"></p>
<p>使用 jstack <pid>可以导出追踪文件，文件中 PID 在 jstack 中显示的对应 nid 为十六进制(命令行可执行 print ‘%x’ <pid>可以进行转化，如1640对应的十六进制为668)</p>
<p>“http-nio-12345-exec-3” #18 daemon prio=5 os_prio=0 tid=0x00007f10003fb000 nid=0x668 runnable [0x00007f0fcf8f9000]<br>   java.lang.Thread.State: RUNNABLE<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.getPartneridsFromJson(CpuController.java:77)<br>…</p>
<p>访问<a target="_blank" rel="noopener" href="http://xx.xx.xx.xx:12345/deadlock">http://xx.xx.xx.xx:12345/deadlock</a>(如上jstack <pid>导出追踪记录会发现如下这样的记录)</p>
<p> ![](_v_images/20200117100107951_17762.png =800x500)</p>
<h1 id="Java-stack-information-for-the-threads-listed-above"><a href="#Java-stack-information-for-the-threads-listed-above" class="headerlink" title="Java stack information for the threads listed above:"></a>Java stack information for the threads listed above:</h1><p>“Thread-5”:<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.lambda$deadlock$1(CpuController.java:41)<br>    - waiting to lock &lt;0x00000000edcf3470&gt; (a java.lang.Object)<br>    - locked &lt;0x00000000edcf3480&gt; (a java.lang.Object)<br>    at org.alanhou.monitor_tuning.chapter2.CpuController$$Lambda$337/547045985.run(Unknown Source)<br>    at java.lang.Thread.run(Thread.java:748)<br>“Thread-4”:<br>    at org.alanhou.monitor_tuning.chapter2.CpuController.lambda$deadlock$0(CpuController.java:33)<br>    - waiting to lock &lt;0x00000000edcf3480&gt; (a java.lang.Object)<br>    - locked &lt;0x00000000edcf3470&gt; (a java.lang.Object)<br>    at org.alanhou.monitor_tuning.chapter2.CpuController$$Lambda$336/1704575158.run(Unknown Source)<br>    at java.lang.Thread.run(Thread.java:748)</p>
<p>Found 1 deadlock.</p>
<p>查看后台日志，都是使用tail -f catalina.out命令来查看  </p>
<p>jvisualvm 图形化工具<br>插件安装Tools&gt;Plugins&gt;Settings根据自身版本(java -version)更新插件中心地址，各版本查询地址：<br><a target="_blank" rel="noopener" href="http://visualvm.github.io/pluginscenters.html">http://visualvm.github.io/pluginscenters.html</a><br> 建议安装：Visual GC, BTrace Workbench<br>概述 监控可以堆dump 线程可以线程dump 抽样器可以对cpu和内存进行抽样调查</p>
<p>以上是本地的JAVA进程监控，还可以进行远程的监控，在上图左侧导航的 Applications 下的 Remote 处右击Add Remote Host…，输入主机 IP 即可添加，在 IP 上右击会发现有两种连接 JAVA 进程进行监控的方式:JMX, jstatd</p>
<p>bin/catalina.sh(以192.168.0.5为例)</p>
<p>JAVA_OPTS=”$JAVA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9004 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.net.preferIPv4Stack=true -Djava.rmi.server.hostname=192.168.0.5”</p>
<p>启动tomcat，</p>
<p>启动tomcat服务<br>方式一：直接启动 ./startup.sh<br>方式二：作为服务启动 nohup ./startup.sh &amp;<br>查看tomcat运行日志<br>tail -f catalina.out</p>
<p>tomcat设置jvm参数<br>修改文件 apache-tomcat-9.0.10/bin下catalina.bat文件</p>
<p>以 JMX 为例，在 IP 上右击点击Add JMX Connection…，输入 IP:PORT</p>
<p><img src="_v_images/20200117100107732_2132.jpg" alt="Add JMX Connection"></p>
<p>以上为 Tomcat，其它 JAVA 进程也是类似的，如：</p>
<p>nohup java -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9005 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.net.preferIPv4Stack=true -Djava.rmi.server.hostname=192.168.0.5 -jar monitor_tuning-0.0.1-SNAPSHOT.jar &amp;</p>
<h3 id="BTrace"><a href="#BTrace" class="headerlink" title="BTrace"></a>BTrace</h3><p><a target="_blank" rel="noopener" href="https://github.com/jbachorik/btrace/releases/latest">BTrace</a> 可以动态地向目标应用程序的字节码注入追踪代码，使用的技术有 JavaCompilerApi, JVMTI, Agent, Instrumentation+ASM</p>
<p>使用方法：JVisualVM中添加 BTrace 插件</p>
<p>方法二：btrace <pid> <trace_script></p>
<p>btrace只能调试本地进程<br>btrace修改后的字节码不能被还原</p>
<p>pom.xml 中添加 btrace-agent, btrace-boot, btrace-client的依赖</p>
<p><img src="_v_images/20200117100107618_23079.png"></p>
<p><img src="_v_images/20200117100107506_24487.png"></p>
<p>拦截构造方法</p>
<p><img src="_v_images/20200117100107296_11386.png"></p>
<p>拦截同名方法  </p>
<p><img src="_v_images/20200117100107084_31796.png"></p>
<p>拦截返回值  </p>
<p><img src="_v_images/20200117100106870_26027.png"></p>
<p>拦截行号</p>
<p><img src="_v_images/20200117100106659_4260.png"></p>
<p>拦截异常信息</p>
<p><img src="_v_images/20200117100106449_4493.png"></p>
<p>拦截复杂类型</p>
<p><img src="_v_images/20200117100106216_21011.png"></p>
<p>拦截正则表达式</p>
<p><img src="_v_images/20200117100105902_16999.png"></p>
<p>拦截环境参数信息  </p>
<p><img src="_v_images/20200117100105692_8879.png">  </p>
<p>常用参数：  </p>
<p>-Xms -Xmx  </p>
<p>-XX:NewSize -XX:MaxNewSize  </p>
<p>-XX:NewRatio -XX:SurvivorRatio  </p>
<p>-XX:MetaspaceSize -XX:MaxMetaspaceSize 以下几个参数通常这样只设置这个值即可  </p>
<p>-XX:+UseCompressedClassPointers  </p>
<p>-XX:CompressedClassSpaceSize  </p>
<p>-XX:InitialCodeCacheSize  </p>
<p>-XX:ReservedCodeCacheSize</p>
<p>Tomcat 远程 Debug</p>
<p>JDWP</p>
<p>bin/startup.sh 修改最后一行(添加 jpda)</p>
<p>exec “$PRGDIR”/“$EXECUTABLE” jpda start “$@”</p>
<p>bin/catalina.sh 为便于远程调试进行如下修改</p>
<p>JPDA_ADDRESS=”localhost:8000”</p>
<h1 id="修改为"><a href="#修改为" class="headerlink" title="修改为"></a>修改为</h1><p>JPDA_ADDRESS=”54321”</p>
<p>若发现54321端口启动存在问题可尝试bin/catalina.sh jpda start</p>
<p>使用 Eclipse 远程调试，右击 Debug As &gt; Debug Configurations… &gt; Remote Java Application &gt; 右击 New 新建</p>
<p>普通java进程可以这样配置<br>java -jar -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=10001 access-10000.jar</p>
<p>tomcat-manager 监控</p>
<p>1.conf/tomcat-users.xml添加用户</p>
  <role rolename="tomcat"/>
  <role rolename="manager-status"/>
  <role rolename="manager-gui"/>
  <user username="tomcat" password="123456" roles="tomcat,manager-gui,manager-status"/>

<p>2.conf/Catalina/localhost/manager.xml配置允许的远程连接</p>
<?xml version="1.0" encoding="UTF-8"?>
<p><Context privileged="true" antiResourceLocking="false"
        docBase="$(catalina.home)/webapps/manager"><br>  <Valve className="org.apache.catalina.valves.RemoteAddrValve"
        allow="127\\.0\\.0\\.1" /><br></Context></p>
<p>远程连接将allow=”127\.0\.0\.1”修改为allow=”^.*$”，浏览器中输入<a target="_blank" rel="noopener" href="http://127.0.0.1:8080/manage%E6%88%96%E5%AF%B9%E5%BA%94%E7%9A%84">http://127.0.0.1:8080/manage或对应的</a> IP，用户名密码为tomcat-users.xml中所设置的</p>
<p>3.重启 Tomcat 服务</p>
<p><img src="_v_images/20200117100105380_4818.jpg" alt="Tomcat Manager"></p>
<p>psi-probe 监控</p>
<p>下载地址：<a target="_blank" rel="noopener" href="https://github.com/psi-probe/psi-probe%EF%BC%8C">https://github.com/psi-probe/psi-probe，</a></p>
<p>下载后进入psi-probe-master目录，执行：</p>
<p>mvn clean package -Dmaven.test.skip</p>
<p>将 web/target/probe.war放到 Tomcat 的 webapps 目录下，同样需要conf/tomcat-users.xml和conf/Catalina/localhost/manager.xml中的配置（可保持不变），启动 Tomcat 服务</p>
<p>浏览器中输入<a target="_blank" rel="noopener" href="http://127.0.0.1:8080/probe%E6%88%96%E5%AF%B9%E5%BA%94%E7%9A%84">http://127.0.0.1:8080/probe或对应的</a> IP，用户名密码为tomcat-users.xml中所设置的</p>
<p><img src="_v_images/20200117100105268_9524.jpg" alt="PSI Probe演示"></p>
<p>Tomcat 调优</p>
<p>线程优化（webapps/docs/config/http.html）：</p>
<p>maxConnections</p>
<p>acceptCount</p>
<p>maxThreads</p>
<p>minSpareThreads</p>
<p>配置优化（webapps/docs/config/host.html）：</p>
<p>autoDeploy</p>
<p>enableLookups（http.html）</p>
<p>reloadable（context.html）</p>
<p>protocol=”org.apache.coyote.http11.Http11AprProtocol”</p>
<p>Session 优化：</p>
<p>如果是 JSP, 可以禁用 Session</p>
<h3 id="Nginx-性能监控与调优"><a href="#Nginx-性能监控与调优" class="headerlink" title="Nginx 性能监控与调优"></a>Nginx 性能监控与调优</h3><p>Nginx 安装</p>
<p>添加 yum 源（/etc/yum.repos.d/nginx.repo）</p>
<p>[nginx]<br>name=nginx repo<br>baseurl=<a target="_blank" rel="noopener" href="http://nginx.org/packages/centos/7/$basesearch/">http://nginx.org/packages/centos/7/$basesearch/</a><br>gpgcheck=0<br>enabled=1</p>
<p>安装及常用命令</p>
<p>yum install -y nginx</p>
<p>systemctl status|start|stop|reload|restart nginx<br>nginx -s stop|reload|quit|reopen  nginx  启动nginx<br>cat default.conf | grep -v “#’ &gt; default2.conf  移除配置文件中的注释 并生成新的配置文件<br>nginx -V<br>nginx -t</p>
<p>配置反向代理 setenforce 0</p>
<p>ngx_http_stub_status 监控连接信息</p>
<p>location = /nginx_status {<br>    stub_status on;<br>    access_log off;<br>    allow 127.0.0.1;<br>    deny all;<br>}</p>
<p>可通过curl <a target="_blank" rel="noopener" href="http://127.0.0.1/nginx_status">http://127.0.0.1/nginx_status</a> 进行查看或注释掉 allow 和 deny 两行使用 IP 进行访问</p>
<p>ngxtop监控请求信息</p>
<p>查看官方使用方法：<a target="_blank" rel="noopener" href="https://github.com/lebinh/ngxtop">https://github.com/lebinh/ngxtop</a></p>
<h1 id="安装-python-pip"><a href="#安装-python-pip" class="headerlink" title="安装 python-pip"></a>安装 python-pip</h1><p>yum install epel-release<br>yum install python-pip</p>
<h1 id="安装-ngxtop"><a href="#安装-ngxtop" class="headerlink" title="安装 ngxtop"></a>安装 ngxtop</h1><p>pip install ngxtop</p>
<p>使用示例</p>
<p>指定配置文件：ngxtop -c /etc/nginx/nginx.conf</p>
<p>查询状态是200：ngxtop -c /etc/nginx/nginx.conf -i ‘status == 200’</p>
<p>查询访问最多 ip：ngxtop -c /etc/nginx/nginx.conf -g remote_addr</p>
<p><img src="_v_images/20200117100103032_6684.jpg" alt="ngxtop查询访问最多 ip"></p>
<p>Nginx 优化</p>
<p>增加工作线程数和并发连接数</p>
<p>worker_processes  4; # 一般CPU 是几核就设置为几<br>events {<br>    worker_connections  1024; # 每个进程打开的最大连接数，包含了 Nginx 与客户端和 Nginx 与 upstream 之间的连接<br>    multi_accept on; # 可以一次建立多个连接<br>    use epoll;<br>}</p>
<p>启用长连接</p>
<p>upstream server_pool{<br>    server localhost:8080 weight=1 max_fails=2 fail_timeout=30s;<br>    server localhost:8081 weight=1 max_fails=2 fail_timeout=30s;<br>    keepalive 300; # 300个长连接<br>}<br>location / {<br>    proxy_http_version 1.1;<br>    proxy_set_header Upgrade $http_upgrade;<br>    proxy_set_header Connection “upgrade”;<br>    proxy_pass <a target="_blank" rel="noopener" href="http://server/_pool">http://server\_pool</a>;<br>}</p>
<p>启用缓存压缩</p>
<p>gzip on;<br>gzip_http_version 1.1;<br>gzip_disable “MSIE [1-6]\.(?!.*SV1)”;<br>gzip_proxied any;<br>gzip_types text/plain text/css application/javascript application/x-javascript application/json application/xml application/vnd.ms-fontobject application/x-font-ttf application/svg+xml application/x-icon;<br>gzip_vary on;<br>gzip_static on;</p>
<p>操作系统优化</p>
<h1 id="配置文件-etc-sysctl-conf"><a href="#配置文件-etc-sysctl-conf" class="headerlink" title="配置文件/etc/sysctl.conf"></a>配置文件/etc/sysctl.conf</h1><p>sysctl -w net.ipv4.tcp_syncookies=1 # 防止一个套接字在有过多试图连接到时引起过载<br>sysctl -w net.core.somaxconn=1024 # 默认128，连接队列<br>sysctl -w net.ipv4.tcp_fin_timeout=10 # timewait 的超时时间<br>sysctl -w net.ipv4.tcp_tw_reuse=1 # os 直接使用 timewait的连接<br>sysctl -w net.ipv4.tcp_tw_recycle=0 # 回收禁用</p>
<h1 id="etc-security-limits-conf"><a href="#etc-security-limits-conf" class="headerlink" title="/etc/security/limits.conf"></a>/etc/security/limits.conf</h1><ul>
<li><pre><code>          hard    nofile            204800</code></pre>
</li>
<li><pre><code>          soft    nofile             204800</code></pre>
</li>
<li><pre><code>          soft    core             unlimited</code></pre>
</li>
<li><pre><code>          soft    stack             204800</code></pre>
</li>
</ul>
<p>其它优化</p>
<p>sendfile    on; # 减少文件在应用和内核之间拷贝<br>tcp_nopush    on; # 当数据包达到一定大小再发送<br>tcp_nodelay    off; # 有数据随时发送</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/03.%E5%A4%A7%E5%A0%86%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/03.%E5%A4%A7%E5%A0%86%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/" class="post-title-link" itemprop="url">大堆问题定位</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="03-大堆问题定位"><a href="#03-大堆问题定位" class="headerlink" title="03.大堆问题定位"></a>03.大堆问题定位</h1><ol>
<li>首先确定是内存问题，还是内存泄露。如果是内存问题，则可以通过JVM监控等手段，判断内存持续增长的区域；假设确定了是内存泄露，也可能是堆内或者堆外</li>
<li>堆内内存泄露的情况，最有效的手段莫过于Heap Dump，使用<code>jmap -heap $PID</code>、<code>jcmd</code>或者<code>HeapDumpOnOutOfMemoryError</code>等等手段都可以获取，使用MAT找超级powerful的机器分析；MAT 其实提供了分析脚本可以在不用 IDE 加载整个 HEAP 获取到需要的信息, 也就是通过脚本解析 HEAP 逐步分析, 具体可参考 <a target="_blank" rel="noopener" href="https://www.techpaste.com/2015/07/how-to-analyse-large-heap-dumps">How to Analyse Large Heap Dumps</a>. PS: 曾经分析过 108G 的堆</li>
<li>实际生产中，这么大的堆，不管是dump对生产系统的影响，还是dump本身的难度，都往往不切实际，相对低成本的手段：</li>
<li><code>jmap -histo $PID</code>或<code>jmap -histo:live $PID</code>获得当前堆内对象的个数统计，并采样多次，查看一下里面object的分布，看哪类对象比较多，一般来说200G的堆，做一次<code>jmap -histo</code>可能要几十秒到一分钟，可能会触发full gc，如果使用 <code>CMS</code> 或 <code>G1</code> 的话, 可加入 <code>-XX:+ExplicitGCInvokesConcurrent</code> 使用并发收集器显式；如果不能探明的话, 只能使用 jmap 将整个堆 dump 下来。<br>所以如果有类似timeout killer的守护线程，要注意不要让它把进程kill掉</li>
<li>详细的GC日志等，比如判断引用堆积情况等，看看没有没什么异常， 比如有没有因为metaspace 满了而导致的GC。这种情况，可以看看是不是打开XX:+TraceClassLoading -XX:+TraceClassUnloading 分析下类加载情况。</li>
<li>使用Tencent JDK，可以利用old object sampling技术，不做Heap dump定位相当一部分memory leak</li>
<li>堆外内存： 确认下是否是 Java 的 direct bytebuffer 泄露, 由于采用 reference 机制回收, 如果一直没有触发 JVM GC 或回收线程偏少也会导致堆外内存回收缓慢导致泄露<br>如果是 Native 或者使用 Unsafe 方式直接向 OS 申请内存, 可通过 NMT以及 pmap 等查看, JDK 团队分享的 <a target="_blank" rel="noopener" href="http://km.oa.com/group/42239/articles/show/404478?ts=1574932416">http://km.oa.com/group/42239/articles/show/404478?ts=1574932416</a> 可谓是面面俱到.</li>
</ol>
<h2 id="使用MAT命令行分析"><a href="#使用MAT命令行分析" class="headerlink" title="使用MAT命令行分析"></a>使用MAT命令行分析</h2><p><a target="_blank" rel="noopener" href="https://www.techpaste.com/2015/07/how-to-analyse-large-heap-dumps">How to Analyse Large Heap Dumps</a></p>
<ol>
<li><p>下载MAT</p>
</li>
<li><p>到MAT的安装目录下，打开<code>MemoryAnalyzer.ini</code>，调整MAT的启动jvm参数</p>
 <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">-Xms6144m</span></span><br><span class="line"><span class="attr">-Xmx8192m</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+UseConcMarkSweepGC</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+UseParNewGC</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+CMSParallelRemarkEnabled</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+CMSClassUnloadingEnabled</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+UseCMSInitiatingOccupancyOnly</span></span><br></pre></td></tr></table></figure>
<p> 堆最大大小调整为机器内存大小</p>
</li>
<li><p>dump文件所在文件夹，确保有dump文件两倍的空间</p>
</li>
<li><p>到MAT的安装目录下，使用root账户运行命令<br> For UNIX:</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./ParseHeapDump.sh /opt/heap_dump/jvm.hprof org.eclipse.mat.api:suspects</span><br><span class="line">./ParseHeapDump.sh /opt/heap_dump/jvm.hprof org.eclipse.mat.api:overview</span><br><span class="line">./ParseHeapDump.sh /opt/heap_dump/jvm.hprof org.eclipse.mat.api:top_components</span><br></pre></td></tr></table></figure>
<p> For Windows:</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ParseHeapDump.bat D:\heap_dump\jvm.hprof org.eclipse.mat.api:suspects</span><br><span class="line">ParseHeapDump.bat D:\heap_dump\jvm.hprof org.eclipse.mat.api:overview</span><br><span class="line">ParseHeapDump.bat D:\heap_dump\jvm.hprof org.eclipse.mat.api:top_components</span><br></pre></td></tr></table></figure></li>
<li><p>使用MAT打开生成的分析结果文件</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-StreamingAPI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-StreamingAPI/" class="post-title-link" itemprop="url">Flink-streaming API</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-Streaming-API"><a href="#Flink-Streaming-API" class="headerlink" title="Flink Streaming API"></a>Flink Streaming API</h1><h2 id="org-apache-flink-streaming-api-functions-source-SourceFunction"><a href="#org-apache-flink-streaming-api-functions-source-SourceFunction" class="headerlink" title="org.apache.flink.streaming.api.functions.source.SourceFunction"></a>org.apache.flink.streaming.api.functions.source.SourceFunction</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-StateManagement/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-StateManagement/" class="post-title-link" itemprop="url">Flink状态管理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="state-management"><a href="#state-management" class="headerlink" title="state-management"></a>state-management</h1><h2 id="org-apache-flink-streaming-api-checkpoint-CheckpointedFunction"><a href="#org-apache-flink-streaming-api-checkpoint-CheckpointedFunction" class="headerlink" title="org.apache.flink.streaming.api.checkpoint.CheckpointedFunction"></a>org.apache.flink.streaming.api.checkpoint.CheckpointedFunction</h2><ul>
<li>CheckpointedFunction是stateful transformation functions的核心接口，用于跨stream维护state<ul>
<li>snapshotState 在checkpoint的时候会被调用，用于snapshot state，通常用于flush、commit、synchronize外部系统</li>
<li>initializeState 在parallel function初始化的时候(<strong>第一次初始化或者从前一次checkpoint recover的时候</strong>)被调用，通常用来初始化state，以及处理state recovery的逻辑</li>
</ul>
</li>
</ul>
<p>从checkpoint中恢复数据时，需要判断snapshot当前的情况，</p>
<p>FunctionSnapshotContext实现了ManagedSnapshotContext, 父类中的方法: <code>getCheckpointId</code>,<code>getCheckpointTimestamp</code><br>FunctionInitializationContext实现了ManagedInitializationContext接口, 实现了<code>isRestored</code>、<code>getOperatorStateStore</code>、<code>getKeyedStateStore</code>方法</p>
<p>在初始化容器之后，我们使用上下文的<code>isrestore()</code>方法检查失败后是否正在恢复。如果是true，即正在恢复，则应用恢复逻辑。</p>
<blockquote>
<p>样例: HBase写入OutPutFormat</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">PortraitOutputFormat</span> <span class="keyword">extends</span> <span class="title">RichOutputFormat</span>&lt;<span class="title">EventItem</span>&gt; <span class="keyword">implements</span> <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 输出阈值，批量写入的条数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> threshold;</span><br><span class="line">    <span class="comment">// 维护在状态中的数据</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> ListState&lt;EventItem&gt; checkpointState;</span><br><span class="line">    <span class="comment">// 内存中的数据</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;EventItem&gt; bufferedEventItem;</span><br><span class="line">    <span class="comment">// HBase客户端</span></span><br><span class="line">    <span class="keyword">private</span> HBaseClient hbaseClient;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PortraitOutputFormat</span><span class="params">(HBaseClient hbaseClient)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.hbaseClient = hbaseClient;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * checkpoint时调用</span></span><br><span class="line"><span class="comment">    * 执行snapshot操作，将内存中的数据写入到内存</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext functionSnapshotContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        checkpointState.clear();</span><br><span class="line">        <span class="keyword">for</span> (EventItem eventItem : bufferedEventItem) &#123;</span><br><span class="line">            checkpointState.add(eventItem);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 创建state，判断是否存在需要恢复的状态，如果有则需要恢复到bufferedEventItem</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ListStateDescriptor&lt;EventItem&gt; descriptor = <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(<span class="string">&quot;buf-p&quot;</span>, EventItem.class);</span><br><span class="line">        checkpointState = context.getOperatorStateStore().getListState(descriptor);</span><br><span class="line">        <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (EventItem eventItem : checkpointState.get()) &#123;</span><br><span class="line">                bufferedEventItem.add(eventItem);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Configuration configuration)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(<span class="keyword">int</span> taskNumber, <span class="keyword">int</span> numTasks)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 将新消息写入到缓存bufferedEventItem，缓存个数大约threshold,则执行sink写入，然后清空bufferedEventItem</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeRecord</span><span class="params">(EventItem value)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (value.getAttachUserId() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        bufferedEventItem.add(value);</span><br><span class="line">        <span class="keyword">int</span> size = bufferedEventItem.size();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (size &gt;= threshold) &#123;</span><br><span class="line">            List&lt;Put&gt; puts = bufferedEventItem</span><br><span class="line">                    .stream()</span><br><span class="line">                    .map(eventItem -&gt; &#123;</span><br><span class="line">                        String rowKey1 = portraitDataGenerator.rowKey(eventItem);</span><br><span class="line">                        Map&lt;String, String&gt; data = portraitDataGenerator.data(eventItem);</span><br><span class="line">                        Put put = <span class="keyword">new</span> Put(rowKey1.getBytes());</span><br><span class="line">                        <span class="keyword">for</span> (String cfc : data.keySet()) &#123;</span><br><span class="line">                            String[] cfcs = cfc.split(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">                            String cf = cfcs[<span class="number">0</span>];</span><br><span class="line">                            String c = cfcs[<span class="number">1</span>];</span><br><span class="line">                            String dataOne = data.get(cfc);</span><br><span class="line">                            put.addColumn(cf.getBytes(), c.getBytes(), dataOne.getBytes());</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> put;</span><br><span class="line">                    &#125;)</span><br><span class="line">                    .collect(Collectors.toList());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                hbaseClient.putAndFlush(puts);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            bufferedEventItem.clear();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hTable != <span class="keyword">null</span>) &#123;</span><br><span class="line">            hTable.flushCommits();</span><br><span class="line">            hTable.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




<h2 id="org-apache-flink-runtime-state-CheckpointListener"><a href="#org-apache-flink-runtime-state-CheckpointListener" class="headerlink" title="org.apache.flink.runtime.state.CheckpointListener"></a>org.apache.flink.runtime.state.CheckpointListener</h2><p>一旦所有checkpoint参与者确认完全，该接口必须由想要接收提交通知的功能/操作来实现。</p>
<h1 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h1><p>1.8 自动清理原理</p>
<p>Apache Flink的1.6.0版本引入了State TTL功能。它使流处理应用程序的开发人员配置过期时间，并在定义时间超时（Time to Live）之后进行清理。在Flink 1.8.0中，该功能得到了扩展，包括对RocksDB和堆状态后端（FSStateBackend和MemoryStateBackend）的历史数据进行持续清理，从而实现旧条目的连续清理过程（根据TTL设置）。</p>
<p>RocksDB后台压缩可以过滤掉过期状态<br>如果你的Flink应用程序使用RocksDB作为状态后端存储，则可以启用另一个基于Flink特定压缩过滤器的清理策略。RocksDB定期运行异步压缩以合并状态更新并减少存储。Flink压缩过滤器使用TTL检查状态条目的到期时间戳，并丢弃所有过期值。</p>
<p>激活此功能的第一步是通过设置以下Flink配置选项来配置RocksDB状态后端：</p>
<p>state.backend.rocksdb.ttl.compaction.filter.enabled</p>
<p>配置RocksDB状态后端后，将为状态启用压缩清理策略，如以下代码示例所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">StateTtlConfig ttlConfig &#x3D; StateTtlConfig</span><br><span class="line">    .newBuilder(Time.days(7))</span><br><span class="line">    .cleanupInRocksdbCompactFilter()</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure>


<h2 id="backend-状态后端"><a href="#backend-状态后端" class="headerlink" title="backend 状态后端"></a>backend 状态后端</h2><table>
<thead>
<tr>
<th>state</th>
<th>保存</th>
<th>snapshot与restore</th>
<th>大小</th>
</tr>
</thead>
<tbody><tr>
<td>keyed state</td>
<td>堆内或堆外(RocksDB)</td>
<td>backend自行实现，用户不关心</td>
<td>大</td>
</tr>
<tr>
<td>operator state</td>
<td>堆内</td>
<td>用户自行实现</td>
<td>小</td>
</tr>
</tbody></table>
<p><img src="_v_images/20201208101748835_1926021392.png"></p>
<p>Flink 的 keyed state 本质上来说就是一个键值对，所以与 RocksDB 的数据模型是吻合的。下图分别是 “window state” 和 “value state” 在 RocksDB 中的存储格式，所有存储的 key，value 均被序列化成 bytes 进行存储。</p>
<p><img src="_v_images/20201208113819762_751391291.png"></p>
<p>在 RocksDB 中，每个 state 独享一个 Column Family，而每个 Column family 使用各自独享的 write buffer 和 block cache，上图中的 window state 和 value state实际上分属不同的 column family。</p>
<h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="operator-state"><a href="#operator-state" class="headerlink" title="operator state"></a>operator state</h4><h5 id="慎重使用长-list"><a href="#慎重使用长-list" class="headerlink" title="慎重使用长 list"></a>慎重使用长 list</h5><p>下图展示的是目前 task 端 operator state 在执行完 checkpoint 返回给 job master 端的 StateMetaInfo 的代码片段。</p>
<p><img src="_v_images/20201208113527702_980726558.png"></p>
<p>由于 operator state 没有 key group 的概念，所以为了实现改并发恢复的功能，需要对 operator state 中的每一个序列化后的元素存储一个位置偏移 offset，也就是构成了上图红框中的 offset 数组。  </p>
<p>那么如果你的 operator state 中的 list 长度达到一定规模时，这个 offset 数组就可能会有几十 MB 的规模，关键这个数组是会返回给 job master，当 operator 的并发数目很大时，很容易触发 job master 的内存超用问题。我们遇到过用户把 operator state 当做黑名单存储，结果这个黑名单规模很大，导致一旦开始执行 checkpoint，job master 就会因为收到 task 发来的“巨大”的 offset 数组，而内存不断增长直到超用无法正常响应。</p>
<h5 id="正确使用-UnionListState"><a href="#正确使用-UnionListState" class="headerlink" title="正确使用 UnionListState"></a>正确使用 UnionListState</h5><p>union list state 目前被广泛使用在 kafka connector 中，不过可能用户日常开发中较少遇到，他的语义是从检查点恢复之后每个并发 task 内拿到的是原先所有operator 上的 state，如下图所示：</p>
<p><img src="_v_images/20201208113559017_2066750174.png"></p>
<p>kafka connector 使用该功能，为的是从检查点恢复时，可以拿到之前的全局信息，如果用户需要使用该功能，需要切记恢复的 task 只取其中的一部分进行处理和用于下一次 snapshot，否则有可能随着作业不断的重启而导致 state 规模不断增长。</p>
<h4 id="Keyed-state-使用建议"><a href="#Keyed-state-使用建议" class="headerlink" title="Keyed state 使用建议"></a>Keyed state 使用建议</h4><h5 id="如何正确清空当前的-state"><a href="#如何正确清空当前的-state" class="headerlink" title="如何正确清空当前的 state"></a>如何正确清空当前的 state</h5><p>state.clear() 实际上只能清理当前 key 对应的 value 值，如果想要清空整个 state，需要借助于 applyToAllKeys 方法，具体代码片段如下：</p>
<p><img src="_v_images/20201208113620034_1338097160.png"></p>
<p>如果你的需求中只是对 state 有过期需求，借助于 state TTL 功能来清理会是一个性能更好的方案。</p>
<h5 id="RocksDB-中考虑-value-值很大的极限场景"><a href="#RocksDB-中考虑-value-值很大的极限场景" class="headerlink" title="RocksDB 中考虑 value 值很大的极限场景"></a>RocksDB 中考虑 value 值很大的极限场景</h5><p>受限于 JNI bridge API 的限制，单个 value 只支持 2^31 bytes 大小，如果存在很极限的情况，可以考虑使用 MapState 来替代 ListState 或者 ValueState，因为RocksDB 的 map state 并不是将整个 map 作为 value 进行存储，而是将 map 中的一个条目作为键值对进行存储。</p>
<h5 id="如何知道当前-RocksDB-的运行情况"><a href="#如何知道当前-RocksDB-的运行情况" class="headerlink" title="如何知道当前 RocksDB 的运行情况"></a>如何知道当前 RocksDB 的运行情况</h5><p>比较直观的方式是打开 RocksDB 的 native metrics ，在默认使用 Flink managed memory 方式的情况下，state.backend.rocksdb.metrics.block-cache-usage ，state.backend.rocksdb.metrics.mem-table-flush-pending，state.backend.rocksdb.metrics.num-running-compactions 以及 state.backend.rocksdb.metrics.num-running-flushes 是比较重要的相关 metrics。</p>
<h4 id="使用-checkpoint-的使用建议"><a href="#使用-checkpoint-的使用建议" class="headerlink" title="使用 checkpoint 的使用建议"></a>使用 checkpoint 的使用建议</h4><h5 id="Checkpoint-间隔不要太短"><a href="#Checkpoint-间隔不要太短" class="headerlink" title="Checkpoint 间隔不要太短"></a>Checkpoint 间隔不要太短</h5><p>虽然理论上 Flink 支持很短的 checkpoint 间隔，但是在实际生产中，过短的间隔对于底层分布式文件系统而言，会带来很大的压力。另一方面，由于检查点的语义，所以实际上 Flink 作业处理 record 与执行 checkpoint 存在互斥锁，过于频繁的 checkpoint，可能会影响整体的性能。当然，这个建议的出发点是底层分布式文件系统的压力考虑。 </p>
<h5 id="合理设置超时时间"><a href="#合理设置超时时间" class="headerlink" title="合理设置超时时间"></a>合理设置超时时间</h5><p>默认的超时时间是 10min，如果 state 规模大，则需要合理配置。最坏情况是分布式地创建速度大于单点（job master 端）的删除速度，导致整体存储集群可用空间压力较大。建议当检查点频繁因为超时而失败时，增大超时时间。</p>
<p>【参考文献】</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6ed0ef5e2b74">Flink Streaming状态处理（Working with State）</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-SQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-SQL/" class="post-title-link" itemprop="url">FlinkSQL与动态表</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h1><h2 id="Retract-mode-和-Append-mode"><a href="#Retract-mode-和-Append-mode" class="headerlink" title="Retract mode 和 Append mode"></a>Retract mode 和 Append mode</h2><p>toAppendStream  只支持insert<br>toRetractStream  其余模式都可以</p>
<p>如果动态表仅只有Insert操作，即之前输出的结果不会被更新，则使用该模式。如果更新或删除操作使用追加模式会失败报错，始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回。</p>
<p>使用flinkSQL处理实时数据当我们把表转化成流的时候，需要用toAppendStream与toRetractStream这两个方法。稍不注意可能直接选择了toAppendStream。</p>
<p>始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回。</p>
<p>当我们使用的sql语句包含：count() group by时，必须使用缩进模式</p>
<p><img src="_v_images/20201111111954370_1165111473.png"><br><img src="_v_images/20201111112036578_1272633365.png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取StreamTableEnvironment.</span></span><br><span class="line">StreamTableEnvironment tableEnv = ...;</span><br><span class="line"><span class="comment">// 包含两个字段的表(String name, Integer age)</span></span><br><span class="line">Table table = ...</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用Append Mode追加模式，数据类型为Row</span></span><br><span class="line">DataStream&lt;Row&gt; dsRow = tableEnv.toAppendStream(table, Row.class);</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用Append Mode追加模式，数据类型为定义好的TypeInformation</span></span><br><span class="line">TupleTypeInfo&lt;Tuple2&lt;String, Integer&gt;&gt; tupleType = <span class="keyword">new</span> TupleTypeInfo&lt;&gt;(</span><br><span class="line">  Types.STRING(),</span><br><span class="line">  Types.INT());</span><br><span class="line">  DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dsTuple =</span><br><span class="line">  tableEnv.toAppendStream(table, tupleType);</span><br><span class="line"><span class="comment">// 将表转为DataStream，使用的模式为Retract Mode撤回模式，类型为Row</span></span><br><span class="line"><span class="comment">// 对于转换后的DataStream&lt;Tuple2&lt;Boolean, X&gt;&gt;，X表示流的数据类型，</span></span><br><span class="line"><span class="comment">// boolean值表示数据改变的类型，其中INSERT返回true，DELETE返回的是false</span></span><br><span class="line">DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; retractStream</span><br><span class="line">  tableEnv.toRetractStream(table, Row.class);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="如何实现回退更新"><a href="#如何实现回退更新" class="headerlink" title="如何实现回退更新?"></a>如何实现回退更新?</h3><p>flink-connector-jdbc 最终使用的是SQL引擎的upsert语法:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tbl() <span class="keyword">values</span> ( ),( ) <span class="keyword">on</span> duplicate key <span class="keyword">update</span></span><br></pre></td></tr></table></figure>
<p>可以看下 MySQL/upsert 一节</p>
<p>对应flink 源码</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.flink.connector.jdbc.dialect.MySQLDialect#getUpsertStatement</span><br></pre></td></tr></table></figure>



<h2 id="keyedBy与group-by区别"><a href="#keyedBy与group-by区别" class="headerlink" title="keyedBy与group by区别"></a>keyedBy与group by区别</h2><h2 id="SQL解析工具"><a href="#SQL解析工具" class="headerlink" title="SQL解析工具"></a>SQL解析工具</h2><p>hive使用了antlr3实现了自己的HQL,<br>Flink使用Apache Calcite,<br>而Calcite的解析器是使用JavaCC实现的,<br>Spark2.x以后采用了antlr4实现自己的解析器,<br>Presto也是使用antlr4。</p>
<h2 id="通过Table-api创建表"><a href="#通过Table-api创建表" class="headerlink" title="通过Table api创建表"></a>通过Table api创建表</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># create a <span class="type">Table</span> from a <span class="type">Table</span> <span class="type">API</span> query</span><br><span class="line">tapi_result = table_env.from_path(<span class="string">&quot;table1&quot;</span>).select(...)</span><br></pre></td></tr></table></figure>
<h2 id="视图-view"><a href="#视图-view" class="headerlink" title="视图 view"></a>视图 view</h2><h2 id="window-aggregate与group-aggregate区别"><a href="#window-aggregate与group-aggregate区别" class="headerlink" title="window aggregate与group aggregate区别"></a>window aggregate与group aggregate区别</h2><p>参考自<a target="_blank" rel="noopener" href="https://ververica.cn/developers/flink-sql-programming-practice/">Apache Flink 零基础入门（九）：Flink SQL 编程实践</a></p>
<h3 id="Group-Aggregate的例子"><a href="#Group-Aggregate的例子" class="headerlink" title="Group Aggregate的例子"></a>Group Aggregate的例子</h3><p>这是一个group aggregate, 内存中累计每个分类的数据，有变化时，update sink</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> psgCnt, <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> cnt </span><br><span class="line"><span class="keyword">FROM</span> Rides </span><br><span class="line"><span class="keyword">WHERE</span> isInNYC(lon, lat)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> psgCnt;</span><br></pre></td></tr></table></figure>
<h3 id="Window-Aggregate"><a href="#Window-Aggregate" class="headerlink" title="Window Aggregate"></a>Window Aggregate</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">  toAreaId(lon, lat) <span class="keyword">AS</span> area, <span class="comment">-- toAreaId为UDF</span></span><br><span class="line">  TUMBLE_END(rideTime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> window_end, </span><br><span class="line">  <span class="comment">--滚动窗口的结束时间: </span></span><br><span class="line">  <span class="comment">-- ① 可以时间不同吗?</span></span><br><span class="line">  <span class="comment">-- ② 窗口可以别名吗?</span></span><br><span class="line">  <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> cnt </span><br><span class="line"><span class="keyword">FROM</span> Rides </span><br><span class="line"><span class="keyword">WHERE</span> isInNYC(lon, lat) <span class="keyword">and</span> isStart</span><br><span class="line"><span class="comment">-- isStart 为boolean</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> </span><br><span class="line">  toAreaId(lon, lat), </span><br><span class="line">  TUMBLE(rideTime, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">MINUTE</span>) </span><br><span class="line">  <span class="comment">-- 定义窗口</span></span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="operator">&gt;=</span> <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 5分钟超过5次才输出</span></span><br></pre></td></tr></table></figure>
<h3 id="Window-Aggregate-与-Group-Aggregate-的区别"><a href="#Window-Aggregate-与-Group-Aggregate-的区别" class="headerlink" title="Window Aggregate 与 Group Aggregate 的区别"></a>Window Aggregate 与 Group Aggregate 的区别</h3><p>Window Aggregate 是当window结束时才输出，其输出的结果是最终值，不会再进行修改，其输出流是一个 Append 流。而 Group Aggregate 是每处理一条数据，就输出最新的结果，其结果是在不断更新的，就好像数据库中的数据一样，其输出流是一个 Update 流。</p>
<p>window 由于有 watermark ，可以精确知道哪些窗口已经过期了，所以可以及时清理过期状态，保证状态维持在稳定的大小。而 Group Aggregate 因为不知道哪些数据是过期的，所以状态会无限增长，这对于生产作业来说不是很稳定，所以建议对 Group Aggregate 的作业配上 State TTL 的配置。</p>
<p><img src="_v_images/20210410180758564_1166368853.png"></p>
<p>例如统计每个店铺每天的实时PV，那么就可以将 TTL 配置成 24+ 小时，因为一天前的状态一般来说就用不到了。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  DATE_FORMAT(ts, <span class="string">&#x27;yyyy-MM-dd&#x27;</span>), shop_id, <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">as</span> pv</span><br><span class="line"><span class="keyword">FROM</span> T</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> DATE_FORMAT(ts, <span class="string">&#x27;yyyy-MM-dd&#x27;</span>), shop_id</span><br></pre></td></tr></table></figure>
<p>当然，如果 TTL 配置地太小，可能会清除掉一些有用的状态和数据，从而导致数据精确性地问题。这也是用户需要权衡地一个参数。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><p><a target="_blank" rel="noopener" href="http://www.10tiao.com/html/157/201707/2653162664/1.html">在数据流中使用SQL查询：Apache Flink中的动态表的持续查询</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://jiamaoxiang.top/2020/05/25/Flink-Table-API-SQL%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/">Flink Table API &amp; SQL编程指南(1)</a></p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/00_docker%E6%9E%84%E5%BB%BAJava%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/00_docker%E6%9E%84%E5%BB%BAJava%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/" class="post-title-link" itemprop="url">Docker构建Java调试环境</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Docker构建Java调试环境"><a href="#Docker构建Java调试环境" class="headerlink" title="Docker构建Java调试环境"></a>Docker构建Java调试环境</h1><p><a target="_blank" rel="noopener" href="https://c.163yun.com/hub#/home">网易镜像仓库</a></p>
<p>Docker动态给容器Container暴露端口</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lsziri/article/details/69396990">https://blog.csdn.net/lsziri/article/details/69396990</a></p>
<h2 id="Docker-container"><a href="#Docker-container" class="headerlink" title="Docker container"></a>Docker container</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">docker pull hub.c.163.com/public/centos:6.7-tools</span><br><span class="line">docker tag hub.c.163.com/public/centos:6.7-tools  centos</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 增加参数解决不能获取ptrace的问题</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> https://blog.csdn.net/russle/article/details/99708261</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这种不可用 docker run --name centos-one --cap-add=SYS_PTRACE  -d -P centos</span></span><br><span class="line">docker run --cap-add=SYS_PTRACE --security-opt seccomp:unconfined --name centos-two  -d -P centos</span><br><span class="line">➜  ~ docker container ls -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS                   NAMES</span><br><span class="line">3ae403bf463c        centos              &quot;/usr/bin/supervisord&quot;   About a minute ago   Up About a minute   0.0.0.0:32772-&gt;22/tcp   centos-one</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入容器</span></span><br><span class="line">➜  ~ docker exec -it centos-one su deploy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="Java环境"><a href="#Java环境" class="headerlink" title="Java环境"></a>Java环境</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装全部 yum install -y java-1.8.0-openjdk*</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 只安装需要的</span></span><br><span class="line">yum install -y java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel.x86_64</span><br></pre></td></tr></table></figure>
<p> install git</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">yum install gcc gcc-c++ autoconf make automake -y</span><br><span class="line">yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel -y</span><br><span class="line">yum install perl docbook2X texinfo sgml2xml openjade perl-ExtUtils-MakeMaker -y</span><br><span class="line">yum install asciidoc xmlto cpio expat-devel gettext-devel  -y</span><br><span class="line">yum install perl-ExtUtils-MakeMaker</span><br><span class="line"></span><br><span class="line">yum install -y tk zlib-devel openssl-devel perl cpio expat-devel gettext-devel  asciidoc xmlto autoconf gcc</span><br><span class="line">wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.9.5.tar.gz</span><br><span class="line"></span><br><span class="line">tar zxvf git-2.9.5.tar.gz</span><br><span class="line">cd git-2.9.5</span><br><span class="line"></span><br><span class="line">make configure</span><br><span class="line">./configure --prefix=/usr/local/git --with-iconv=/usr/local/libiconv</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置安装路径</span></span><br><span class="line">make all doc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 编译</span></span><br><span class="line">make install install-doc install-html</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装</span></span><br><span class="line"></span><br><span class="line">修改环境变量</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> -e <span class="string">&quot;# git\nexport PATH=/usr/local/git/bin:\$PATH&quot;</span>&gt; /etc/profile.d/git.sh</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cat /etc/profile.d/git.sh</span></span><br><span class="line">\# git        // 文件内容</span><br><span class="line">export PATH=/usr/local/git/bin:$PATH</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">source</span> /etc/profile</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>安装oh-my-zsh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">yum install -y zsh</span><br><span class="line">chsh -s /bin/zsh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>编辑~/.zshrc文件</p>
<p>找到plugins=(git)这一行，然后再添加autosuggestions，最后为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plugins&#x3D;(git zsh-autosuggestions)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker container cp target/demo-0.0.1-SNAPSHOT.jar centos-one:/home/deploy/</span><br></pre></td></tr></table></figure>



<h3 id="增加端口，做远程debug"><a href="#增加端口，做远程debug" class="headerlink" title="增加端口，做远程debug"></a>增加端口，做远程debug</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker commit 95c6d4eed5f0 jdk8-debug</span><br><span class="line"></span><br><span class="line">docker run --cap-add=SYS_PTRACE --security-opt seccomp:unconfined --name centos-jdk8-debug  -d -p 8000:8000 -p  8001:8001 -p 8002:8002  -P jdk8-debug</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker exec -it centos-jdk8-debug zsh</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-SQL-active/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-SQL-active/" class="post-title-link" itemprop="url">Flink-SQL实践</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-12 17:35:00" itemprop="dateModified" datetime="2021-04-12T17:35:00+08:00">2021-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-SQL-active"><a href="#Flink-SQL-active" class="headerlink" title="Flink-SQL-active"></a>Flink-SQL-active</h1><p>维表同步脚本:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span></span><br><span class="line"><span class="keyword">into</span></span><br><span class="line">    dim_result_lct_activy_config</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        Fact_id,</span><br><span class="line">        <span class="built_in">LAST_VALUE</span>(Fact_name),</span><br><span class="line">        FROM_UNIXTIME(UNIX_TIMESTAMP(<span class="built_in">LAST_VALUE</span>(Fact_start_time)),</span><br><span class="line">        <span class="string">&#x27;yyyyMMddHHmmss&#x27;</span>) <span class="keyword">as</span> startTime,</span><br><span class="line">        FROM_UNIXTIME(UNIX_TIMESTAMP(<span class="built_in">LAST_VALUE</span>(Fact_end_time)),</span><br><span class="line">        <span class="string">&#x27;yyyyMMddHHmmss&#x27;</span>) <span class="keyword">as</span> endTime,</span><br><span class="line">        <span class="built_in">LAST_VALUE</span>(Fstate)</span><br><span class="line">    <span class="keyword">from</span></span><br><span class="line">        db_act_config_t_act_logic_config</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">        Fact_id</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://apache-flink.147419.n8.nabble.com/FlinkSQL-Upsert-Retraction-MySQL-td2785.html">FlinkSQL Upsert/Retraction 写入 MySQL 的问题 </a></p>
<p> retract流是算子的特性，不同的算子不同，比如group by聚合算子天生就是会发retract流的，比如你之前算出来的是a, 1, 后面变化了，变成了a,2，所以group by算子会发-a,1, +a,2.</p>
<p>像join的话也是有retract流的，比如outer join</p>
<p>当然如果下游sink支持upsert, 这块也会有优化，会优化为update。</p>
<blockquote>
<p>INSERT INTO  mysql_sink SELECT  f1, count(*) FROM kafka_src GROUP BY f1<br>每从 kafka 过来一条新的记录，会生成两条记录 Tuple2&lt;Row, Boolean&gt;, 旧的被删除，新的会添加上。这是query是会一个会产生retract stream的query，可以简单理解成每条kafka的数据过来会产生两条记录，但是最终写入下游的系统。需要看下游的系统支持和实现的sink(现在有三种sink AppendStreamSink, UpsertStreamSink, RetractStreamSink)</p>
</blockquote>
<blockquote>
<p>我看 <a target="_blank" rel="noopener" href="https://github.com/apache/flink/tree/master/flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc">https://github.com/apache/flink/tree/master/flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc</a> 没有 Retract 方式<br>实际上使用了 JDBCUpsertTableSink.java 的代码写入 MySQL 吗？<br>现有的sink中，kafka是实现的AppendStreamSink，所以只支持insert 的记录，不支持retract.<br>你用DDL声明的mysql表，对应的jdbc sink 是JDBCUpsertTableSink，所以会按照Upsert的逻辑处理, 也不支持retract。</p>
</blockquote>
<blockquote>
<p>如若不带 group by 直接：<br>INSERT INTO  mysql_sink SELECT  f1,  f2 FROM kafka_src<br>主键冲突写入 mysql 是会出错的，怎么可以用 Upsert 的方式直接覆盖呢？</p>
</blockquote>
<p>不带 group by时无法推导出query的 unique key，没法做按照unique key的更新，<br>只需要将 query的 key （你这里是group by 后的字段）和db中主键保持一致即可</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">235</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">126</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
