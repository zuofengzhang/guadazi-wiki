<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/page/7/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/7/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Kafka/kafka-base/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Kafka/kafka-base/" class="post-title-link" itemprop="url">kafka</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-12 00:00:00" itemprop="dateCreated datePublished" datetime="2020-08-12T00:00:00+08:00">2020-08-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:52" itemprop="dateModified" datetime="2021-04-24T12:58:52+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h1><h2 id="ACK机制"><a href="#ACK机制" class="headerlink" title="ACK机制"></a>ACK机制</h2><p>Kafka producer有三种ack机制  初始化producer时在config中进行配置</p>
<table>
<thead>
<tr>
<th>ACK</th>
<th>同步</th>
<th>延迟</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>producer不等待broker同步完成就发送下一条(批)信息</td>
<td>低的延迟最弱的持久性，当服务器发生故障时，就很可能发生数据丢失。例如leader已经死亡，producer不知情，还会继续发送消息broker接收不到数据就会数据丢失</td>
</tr>
<tr>
<td>1</td>
<td>producer要等待leader成功收到数据并得到确认，才发送下一条message</td>
<td>较好的持久性较低的延迟性：Partition的Leader死亡，follwer尚未复制，数据就会丢失</td>
</tr>
<tr>
<td>-1</td>
<td>producer得到follwer确认，才发送下一条数据</td>
<td>持久性最好，延时性最差</td>
</tr>
</tbody></table>
<p>三种机制性能递减，可靠性递增。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/multithread/12.google-guava-concurrency/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/multithread/12.google-guava-concurrency/" class="post-title-link" itemprop="url">Guava并发库</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-06 14:58:00" itemprop="dateCreated datePublished" datetime="2020-05-06T14:58:00+08:00">2020-05-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:51" itemprop="dateModified" datetime="2021-04-24T12:58:51+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="disruptor"><a href="#disruptor" class="headerlink" title="disruptor"></a>disruptor</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/02_GC_tuning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/02_GC_tuning/" class="post-title-link" itemprop="url">GC调优</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-05 14:58:00" itemprop="dateCreated datePublished" datetime="2020-02-05T14:58:00+08:00">2020-02-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:51" itemprop="dateModified" datetime="2021-04-24T12:58:51+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="GC调优"><a href="#GC调优" class="headerlink" title="GC调优"></a>GC调优</h1><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>内容：</p>
<ol>
<li>教程</li>
<li>压测+调优</li>
<li>实际样例</li>
</ol>
<p>tip:</p>
<ul>
<li>collector</li>
<li>gc logs</li>
<li>gc viewer</li>
<li>jmeter</li>
<li>压测与调优</li>
</ul>
<h2 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40368860/article/details/84447085">jvm整体架构图文详解</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jls/se8/html/index.html">Java8 语言规范</a><br><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se8/html/index.html">Java8 JVM规范</a><br><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5">Java8 JVM规范-内存结构</a></p>
<p>运行时数据区</p>
<p>![](_v_images/20200205234634496_2051245788.png =526x)</p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><h3 id="虚拟机栈JVM-Stacks"><a href="#虚拟机栈JVM-Stacks" class="headerlink" title="虚拟机栈JVM Stacks"></a>虚拟机栈JVM Stacks</h3><p>栈帧分为哪些快？每块又保存什么内容？</p>
<h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p>非堆</p>
<ul>
<li>JDK6 perm区</li>
<li>JDK7 perm区</li>
<li>JDK8 metaspace</li>
</ul>
<h3 id="常量池Run-Time-Constant-Pool-方法区中"><a href="#常量池Run-Time-Constant-Pool-方法区中" class="headerlink" title="常量池Run-Time Constant Pool (方法区中)"></a>常量池Run-Time Constant Pool (方法区中)</h3><h3 id="本地方法栈Native-Method-Stacks"><a href="#本地方法栈Native-Method-Stacks" class="headerlink" title="本地方法栈Native Method Stacks"></a>本地方法栈Native Method Stacks</h3><h3 id="JVM的内存结构"><a href="#JVM的内存结构" class="headerlink" title="JVM的内存结构"></a>JVM的内存结构</h3><p>![](_v_images/20200205235938340_210349887.png =500x)</p>
<ul>
<li>CCS：只有启用了短指针的时候，才存在</li>
<li>CodeCache：只有启用了JIT和有JNI调用Native代码的时候，才存在<ul>
<li><code>-Xcomp</code>：JIT完全编译执行</li>
<li><code>-Xint</code>完全解释执行</li>
<li><code>-Xmixed</code>编译和解释混合</li>
</ul>
</li>
</ul>
<h3 id="非堆区"><a href="#非堆区" class="headerlink" title="非堆区"></a>非堆区</h3><p>![](_v_images/20200206000408818_592467847.png =516x)</p>
<h3 id="标准参数"><a href="#标准参数" class="headerlink" title="标准参数"></a>标准参数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-version -showversion</span><br><span class="line">-help</span><br><span class="line">-cp -classpath</span><br><span class="line">-server -client</span><br></pre></td></tr></table></figure>




<h3 id="X"><a href="#X" class="headerlink" title="-X"></a>-X</h3><p>-Xint: 解释执行模式<br>-Xcomp: 编译执行模式, 第一次使用就编译成本地代码, 编译结果保存在metaspace的code cache空间<br>-Xmixed: 混合执行模式, JVM决定是否编译成本地代码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; java -Xint -version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_232&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (build 1.8.0_232-b09)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 25.232-b09, interpreted mode)</span><br><span class="line"></span><br><span class="line">&gt; java -Xcomp -version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_232&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (build 1.8.0_232-b09)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 25.232-b09, compiled mode)</span><br></pre></td></tr></table></figure>
<h3 id="XX"><a href="#XX" class="headerlink" title="-XX"></a>-XX</h3><table>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>-Xms</td>
<td>最小堆内存</td>
</tr>
<tr>
<td>-Xmx</td>
<td>最大堆内存</td>
</tr>
<tr>
<td>-XX:NewSize</td>
<td>新生代大小</td>
</tr>
<tr>
<td>-XX:MaxNewSize</td>
<td>最大新生代大小</td>
</tr>
<tr>
<td>-XX:NewRatio</td>
<td>new区和old区的比例</td>
</tr>
<tr>
<td>-XX:SurvivorRatio</td>
<td>eden区与survivor区大小比例</td>
</tr>
<tr>
<td>-XX:MetaspaceSize</td>
<td>Metaspace大小</td>
</tr>
<tr>
<td>-XX:MaxMetaspaceSize</td>
<td>Metaspace最大大小</td>
</tr>
<tr>
<td>-XX:+UseCompressedClassPointers</td>
<td>压缩类指针</td>
</tr>
<tr>
<td>-XX:CompressedClassSpaceSize</td>
<td>压缩类空间(<code>CCS</code>)的大小,默认1G</td>
</tr>
<tr>
<td>-XX:InitialCodeCacheSize</td>
<td>code cache的初始大小</td>
</tr>
<tr>
<td>-XX:ReservedCodeCacheSize</td>
<td>code cache的最大的大小</td>
</tr>
<tr>
<td>-XX:PretenureSizeThreshold</td>
<td>大对象直接进入老年代，大对象的大小阈值</td>
</tr>
<tr>
<td>-XX:MaxTenuringThreshold</td>
<td>长期存活的对象进入老年代，晋升年龄阈值</td>
</tr>
<tr>
<td>-XX:+PrintTrnuringDistuibution</td>
<td>youngGC时打印年龄分布情况</td>
</tr>
<tr>
<td>-XX:TargetSurvivorRatio</td>
<td>survivor垃圾回收存活的比例，超过值将直接晋升</td>
</tr>
</tbody></table>
<h3 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h3><p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc.html">gc调优官方指南</a></p>
<p>GC Root：</p>
<ul>
<li>类加载器：由类加载器生成的对象，都持有指针</li>
<li>Thread：线程运行会持有很多对象</li>
<li>虚拟机栈的本地变量表</li>
<li>static成员</li>
<li>常量引用</li>
<li>本地方法栈的变量</li>
</ul>
<h4 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h4><p>缺点：<br>无法处理循环引用</p>
<h4 id="标记清除"><a href="#标记清除" class="headerlink" title="标记清除"></a>标记清除</h4><p>先标记需要回收的对象，在统一回收所有对象</p>
<p><strong>缺点：</strong></p>
<p>效率不高:标记和清除两个过程效率都不高；碎片：导致提前GC</p>
<h4 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h4><p>内存划分为大小相同的两块，每次只使用其中一块，一块用完复制存活的对象到另一块，然后再把已使用的内存空间一次清理掉</p>
<p><strong>缺点：</strong></p>
<p>使用简单，效率高，空间利用率不高</p>
<h4 id="标记整理"><a href="#标记整理" class="headerlink" title="标记整理"></a>标记整理</h4><p>先标记需要回收的对象，让所有存活的对象都向一端移动，然后清理掉端边界外的内存</p>
<p><strong>缺点：</strong><br>无内存碎片，比较耗时</p>
<h3 id="分带垃圾回收"><a href="#分带垃圾回收" class="headerlink" title="分带垃圾回收"></a>分带垃圾回收</h3><p>young区朝生夕死，生命周期端，用复制算法：效率高<br>Old区生命周期长，用标记清除或标记整理</p>
<ul>
<li>对象优先分配在eden区</li>
<li>大对象直接进入老年代：<code>-XX:PretenureSizeThreshold</code></li>
<li>长期存活的对象进入老年代：<ul>
<li><code>-XX:MaxTenuringThreshold</code>: 晋升年龄代数阈值</li>
<li><code>-XX:+PrintTenuringDistribution</code>：ygc打印存活对象的分布情况</li>
<li><code>-XX:TargetSurvivorRatio</code>：Survivor区存活对象比例，动态调整，取存活对象的平均值与晋升年龄阈值间的最小值</li>
</ul>
</li>
</ul>
<h3 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h3><p>枚举根节点，做可达性分析<br>根节点: 类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量</p>
<ul>
<li>串行收集器Serial: Serial、 Serial old</li>
<li>并行收集器Parallel: Parallel Scavenge、Parallel old，吞吐量优先</li>
<li>并发收集器Concurrent: CMS、G1,停顿时间优先</li>
</ul>
<h4 id="并行-vs-并发"><a href="#并行-vs-并发" class="headerlink" title="并行 vs 并发"></a>并行 vs 并发</h4><p>并行(Parallel): 多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互的场景</p>
<p>并发(Concurrent): 用户线程和垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），垃圾收集线程在执行的时候不会停顿用户程序的运行。适合对响应时间有要求的场景，如web。</p>
<h4 id="停顿时间-vs-吞吐量"><a href="#停顿时间-vs-吞吐量" class="headerlink" title="停顿时间 vs 吞吐量"></a>停顿时间 vs 吞吐量</h4><p>停顿时间：垃圾收集器做垃圾回收中断应用执行的时间。<code>-XX:MaxGCPauseMillis</code></p>
<p>吞吐量：花在垃圾收集的时间和花在应用时间的占比。 <code>-XX:GCTimeRatio=&lt;n&gt;</code>, 垃圾收集时间占: <code>1/(1+n)</code></p>
<h3 id="串行收集器"><a href="#串行收集器" class="headerlink" title="串行收集器"></a>串行收集器</h3><p>-XX:+UseSerialGC<br>-XX:+UseSerialOldGC</p>
<p>采用串行收集器，默认old区采用串行收集器</p>
<h3 id="并行收集器-ParallelCollector"><a href="#并行收集器-ParallelCollector" class="headerlink" title="并行收集器 ParallelCollector"></a>并行收集器 ParallelCollector</h3><p>吞吐量优先</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-XX:+UseParallelGC</span><br><span class="line">-XX:+UseParallelOldGC</span><br><span class="line"></span><br><span class="line">Server模式下的默认收集器</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-XX:ParallelGCThreads&#x3D;&lt;N&gt; 多少个GC线程</span><br><span class="line"></span><br><span class="line">CPU&gt;8 N&#x3D;5&#x2F;8</span><br><span class="line">CPU&lt;8 N&#x3D;CPU</span><br></pre></td></tr></table></figure>
<h3 id="并发收集器"><a href="#并发收集器" class="headerlink" title="并发收集器"></a>并发收集器</h3><p>响应时间优先</p>
<p>CMS:  -XX:+UseConcMarkSweepGC  -XX:+UseParNewGC<br>G1:  -XX:+UseG1GC</p>
<h3 id="如何选择垃圾收集器"><a href="#如何选择垃圾收集器" class="headerlink" title="如何选择垃圾收集器"></a>如何选择垃圾收集器</h3><p><a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/collectors.html#sthref27">如何选择垃圾收集器</a></p>
<ul>
<li>优先调整堆的大小让服务器自己选择</li>
<li>如果内存小于100M，使用串行收集器</li>
<li>如果是单核，并且没有停顿时间的要求，串行或者jvm自己选</li>
<li>如果允许停顿时间超过1s，选择并行或者jvm自己选</li>
<li>如果响应时间最重要，并且不能超过1s，则使用并发收集器</li>
</ul>
<table>
<thead>
<tr>
<th>young</th>
<th>Tenured</th>
<th>JVM options</th>
</tr>
</thead>
<tbody><tr>
<td>Serial</td>
<td>Serial</td>
<td>-XX:+UseSerialGC</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>Serial</td>
<td>-XX:+UseParallelGC -XX:-UseParallelOldGC</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>Parallel Old</td>
<td>-XX:+UseParallelGC -XX:+UseParallelOldGC</td>
</tr>
<tr>
<td>Parallel New或Serial</td>
<td>CMS</td>
<td>-XX:+UseParNewGC -XX:+UseConcMarkSweepGC</td>
</tr>
<tr>
<td>G1</td>
<td>G1</td>
<td>-XX:+UseG1GC</td>
</tr>
</tbody></table>
<p>![](_v_images/20200202130338468_927467357.png =500x)</p>
<p>垃圾回收器从线程运行情况分类有三种</p>
<p>串行回收: Serial回收器，单线程回收，全程stw；<br>并行回收: 名称以Parallel开头的回收器，多线程回收，全程stw；<br>并发回收: cms与G1，多线程分阶段回收，只有某阶段会stw；</p>
<h2 id="并行收集器-Parallel-Collector"><a href="#并行收集器-Parallel-Collector" class="headerlink" title="并行收集器 Parallel Collector"></a>并行收集器 Parallel Collector</h2><p>暂停应用程序，开启多个垃圾收集线程开始垃圾回收</p>
<ul>
<li><code>-XX:+UseParallelGC</code> 手动开启，Server默认开启</li>
<li><code>-XX:ParallelGCThreads=&lt;N&gt;</code>多少个GC线程<ul>
<li><code>CPU&gt;8 N=5/8</code></li>
<li><code>CPU&lt;8 N=CPU</code></li>
</ul>
</li>
</ul>
<p>查找使用ParallelGC的进程<br><code>jps -v  | grep -v grep | awk &#39;&#123;print $1&#125;&#39;   | xargs -L 1 -t jinfo -flag UseParallelGC</code></p>
<h3 id="Parallel-Collector-Ergonomics自适应"><a href="#Parallel-Collector-Ergonomics自适应" class="headerlink" title="Parallel Collector Ergonomics自适应"></a>Parallel Collector Ergonomics自适应</h3><ul>
<li><code>-XX:MaxGCPauseMillis=&lt;N&gt;</code>：最大停顿时间</li>
<li><code>-XX:GCTimeRatio=&lt;N&gt;</code>: GC时间占比，代表吞吐量</li>
<li><code>-Xmx&lt;N&gt;</code>: 堆最大大小</li>
</ul>
<p>优先满足停顿时间，再满足吞吐量的要求，最后再调整满足堆最大大小</p>
<p>动态调整每个分区的大小</p>
<h3 id="动态内存调整"><a href="#动态内存调整" class="headerlink" title="动态内存调整"></a>动态内存调整</h3><ul>
<li><code>-XX:YoungGenerationSizeIncrement=&lt;Y&gt;</code> 年轻代大小调整增量，默认值20%</li>
<li><code>-XX:TenuredGenerationSizeIncrement=&lt;T&gt;</code> 老年代大小调整增量，默认值</li>
<li><code>-XX:AdaptiveSizeDecrementScaleFactor=&lt;D&gt;</code> 减少增量，默认值4%</li>
</ul>
<h2 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -XX:+UseConcMarkSweepGC  -jar -server console.jar</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">jps -l | grep buried | awk &#x27;&#123;print $1&#125;&#x27; | xargs -L 1 -t /usr/local/soft/jdk1.8.0_191/bin/jinfo  -flags</span><br><span class="line">/usr/local/soft/jdk1.8.0_191/bin/jinfo -flags 4893</span><br><span class="line">Attaching to process ID 4893, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.191-b12</span><br><span class="line">Non-default VM flags: </span><br><span class="line">-XX:CICompilerCount=3 </span><br><span class="line">-XX:InitialHeapSize=524288000 </span><br><span class="line">-XX:MaxHeapSize=8363442176 </span><br><span class="line">-XX:MaxNewSize=348913664 </span><br><span class="line">-XX:MaxTenuringThreshold=6 </span><br><span class="line">-XX:MinHeapDeltaBytes=196608 </span><br><span class="line">-XX:NewSize=174718976 </span><br><span class="line">-XX:OldPLABSize=16 </span><br><span class="line">-XX:OldSize=349569024 </span><br><span class="line">-XX:+UseCompressedClassPointers </span><br><span class="line">-XX:+UseCompressedOops </span><br><span class="line">-XX:+UseConcMarkSweepGC </span><br><span class="line">-XX:+UseFastUnorderedTimeStamps </span><br><span class="line">-XX:+UseParNewGC</span><br><span class="line">Command line:  -XX:+UseConcMarkSweepGC </span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jps -l | grep buried | awk &#x27;&#123;print $1&#125;&#x27; | xargs -L 1 -t /usr/local/soft/jdk1.8.0_191/bin/jinfo  -flag CMSInitiatingOccupancyFraction</span><br><span class="line">/usr/local/soft/jdk1.8.0_191/bin/jinfo -flag CMSInitiatingOccupancyFraction 4893</span><br><span class="line">-XX:CMSInitiatingOccupancyFraction=-1</span><br></pre></td></tr></table></figure>
<p>cms是一种预处理垃圾回收器，它不能等到old内存用尽时回收，需要在内存用尽前，完成回收操作，否则会导致并发回收失败；所以cms垃圾回收器开始执行回收操作，有一个触发阈值，默认是老年代或永久带达到92%</p>
<ul>
<li>并发收集</li>
<li>低停顿 低延迟</li>
<li>老年代收集器</li>
</ul>
<p><strong>CMS垃圾收集过程</strong></p>
<ol>
<li>CMS inital mark: 初始标记Root  STW</li>
<li>CMS concurrent mark：并发标记</li>
<li>CMS-concurrent-preclean: 并发预清理</li>
<li>CMS remark: 重新标记 STW</li>
<li>CMS concurrent sweep：并发清除</li>
<li>CMS-concurrent-reset：并发重置</li>
</ol>
<p><strong>缺点</strong></p>
<ul>
<li>低停顿 低延迟</li>
<li>CPU敏感</li>
<li>浮动垃圾：边运行应用程序，边回收</li>
<li>空间碎片</li>
</ul>
<p><strong>调优参数</strong></p>
<table>
<thead>
<tr>
<th>参数</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>-XX:ConcGCThreads</td>
<td>并发的GC线程数</td>
</tr>
<tr>
<td>-XX:+UseCMSCompactAtFullCollection</td>
<td>FullGC之后做压缩</td>
</tr>
<tr>
<td>-XX:CMSFullGCsBeforeCompaction</td>
<td>多少次FullGC之后压缩一次</td>
</tr>
<tr>
<td>-XX:CMSInitiatingOccupancyFraction</td>
<td>触发FullGC  92%</td>
</tr>
<tr>
<td>-XX:+UseCMSInitiatingOccupancyOnly</td>
<td>是否动态调</td>
</tr>
<tr>
<td>-XX:+CMSScavengeBeforeRemark</td>
<td>FullGC之前先做YGC</td>
</tr>
<tr>
<td>-XX:+CMSClassUnloadingEnabled</td>
<td>启用回收Perm区</td>
</tr>
</tbody></table>
<h2 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h2><p>大内存(大于6G)，优先延迟(小于0.5s)</p>
<p>![](_v_images/20200206210747611_907596705.png =421x)</p>
<p>H区：大对象，如果对象超过了region的一半大小</p>
<p>Region</p>
<p>SATB：snapshot-at-the-beginning, 通过Root tracing得到的，GC开始时候存活对象的快照。垃圾回收以此为基础回收</p>
<p>RSet：记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）</p>
<p><strong>YoungGC</strong></p>
<ul>
<li>新独享进入Eden区</li>
<li>存活对象拷贝到s区</li>
<li>存活时间达到年龄阈值时，对象晋升到old区</li>
</ul>
<p><strong>mixedGC</strong></p>
<p>没有full gc</p>
<ul>
<li>不是FullGC，回收所有的Young和部分Old</li>
<li>global concurrent marking</li>
</ul>
<p><strong>global concurrent marking</strong></p>
<ol>
<li>Initial marking phase：标记GC Root ，STW</li>
<li>Root region scanning phase：标记存活Region</li>
<li>Concurrent marking phase：标记存活的对象</li>
<li>Remark phase：重新标记 STW</li>
<li>Cleanup phase：部分STW</li>
</ol>
<p><strong>MixedGC时机</strong></p>
<ul>
<li>InitiatingHeapOccupancyPercent: 堆占有率达到这个数值则触发global concurrent marking，默认45%</li>
<li>G1HeapWastePercent：在gloabl concurrent marking结束之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生MixedGC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生MixedGC</li>
<li>G1MixedGCLiveThresholdPercent: Old区的region被回收时候的存活对象占比</li>
<li>G1MixedGCCountTarget：一次global concurrent marking之后，最多执行MixedGC的次数<br>![](_v_images/20200206214458093_401476294.png =473x)</li>
</ul>
<p>![](_v_images/20200206215456237_1513279165.png =412x)</p>
<p>![](_v_images/20200206215646888_1034094734.png =400x)</p>
<h3 id="调优最佳实践"><a href="#调优最佳实践" class="headerlink" title="调优最佳实践"></a>调优最佳实践</h3><p>![](_v_images/20200206220804596_445039167.png =408x)</p>
<p>![](_v_images/20200206220825238_87737268.png =427x)</p>
<p>![](_v_images/20200206221006981_1426481434.png =384x)</p>
<h2 id="可视化GC日志分析工具"><a href="#可视化GC日志分析工具" class="headerlink" title="可视化GC日志分析工具"></a>可视化GC日志分析工具</h2><p>![](_v_images/20200206222823823_366026130.png =490x)</p>
<p>吞吐量与延迟时间的权衡</p>
<h2 id="Tomcat调优实例"><a href="#Tomcat调优实例" class="headerlink" title="Tomcat调优实例"></a>Tomcat调优实例</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zqz_zqz/article/details/70568819">CMS垃圾回收器详解</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/multithread/Atomic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/multithread/Atomic/" class="post-title-link" itemprop="url">Atomic原子变量</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-11 14:58:00" itemprop="dateCreated datePublished" datetime="2019-09-11T14:58:00+08:00">2019-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:51" itemprop="dateModified" datetime="2021-04-24T12:58:51+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>转载自<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34871626/article/details/81411815">Java并发编程之原子性-Atomic详解</a></p>
</blockquote>
<h1 id="Atomic"><a href="#Atomic" class="headerlink" title="Atomic"></a>Atomic</h1><h2 id="atomic包"><a href="#atomic包" class="headerlink" title="atomic包"></a>atomic包</h2><p>JUC中的Atomic包详解：</p>
<p>Atomic包中提供了很多Atomicxxx的类：</p>
<p><img src="images/20191201183741334_611136175.png"></p>
<p>它们都是CAS（compareAndSwap）来实现原子性。</p>
<h2 id="AtomicInteger样例"><a href="#AtomicInteger样例" class="headerlink" title="AtomicInteger样例"></a>AtomicInteger样例</h2><p>先写一个简单示例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicExample1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 请求总数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> clientTotal = <span class="number">5000</span>;</span><br><span class="line">    <span class="comment">// 同时并发执行的线程数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> threadTotal = <span class="number">200</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> AtomicInteger count = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ExecutorService executorService = Executors.newCachedThreadPool();</span><br><span class="line">        <span class="keyword">final</span> Semaphore semaphore = <span class="keyword">new</span> Semaphore(threadTotal);</span><br><span class="line">        <span class="keyword">final</span> CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(clientTotal);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; clientTotal ; i++) &#123;</span><br><span class="line">            executorService.execute(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    semaphore.acquire();</span><br><span class="line">                    add();</span><br><span class="line">                    semaphore.release();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;exception&quot;</span>, e);</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        executorService.shutdown();</span><br><span class="line">        log.info(<span class="string">&quot;count:&#123;&#125;&quot;</span>, count.get());</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        count.incrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以发下每次的运行结果总是我们想要的预期结果5000。<br>说明该计数方法是线程安全的。</p>
<h2 id="AtomicInteger实现原理"><a href="#AtomicInteger实现原理" class="headerlink" title="AtomicInteger实现原理"></a>AtomicInteger实现原理</h2><p>我们查看下<code>count.incrementAndGet()</code>方法，它的第一个参数为对象本身，第二个参数为valueOffset是用来记录value本身在内存的编译地址的，这个记录，也主要是为了在更新操作在内存中找到value的位置，方便比较，第三个参数为常量1。：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicInteger</span> <span class="keyword">extends</span> <span class="title">Number</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">6214790243416807050L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// setup to use Unsafe.compareAndSwapInt for updates</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> valueOffset;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            valueOffset = unsafe.objectFieldOffset</span><br><span class="line">                (AtomicInteger.class.getDeclaredField(<span class="string">&quot;value&quot;</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123; <span class="keyword">throw</span> <span class="keyword">new</span> Error(ex); &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> value;</span><br><span class="line">    ... 此处省略多个方法...</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Atomically increments by one the current value.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> the updated value</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">incrementAndGet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> unsafe.getAndAddInt(<span class="keyword">this</span>, valueOffset, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AtomicInteger源码里使用了一个Unsafe的类,它提供了一个<strong>getAndAddInt</strong>的方法，我们继续点看查看它的源码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Unsafe</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe theUnsafe;</span><br><span class="line"></span><br><span class="line">    ....此处省略很多方法及成员变量....</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndAddInt</span><span class="params">(Object var1, <span class="keyword">long</span> var2, <span class="keyword">int</span> var4)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> var5;</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            var5 = <span class="keyword">this</span>.getIntVolatile(var1, var2);</span><br><span class="line">        &#125; <span class="keyword">while</span>(!<span class="keyword">this</span>.compareAndSwapInt(var1, var2, var5, var5 + var4));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> var5;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">compareAndSwapInt</span><span class="params">(Object var1, <span class="keyword">long</span> var2, <span class="keyword">int</span> var4, <span class="keyword">int</span> var5)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">int</span> <span class="title">getIntVolatile</span><span class="params">(Object var1, <span class="keyword">long</span> var2)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到这里使用了一个do while语句来做主体实现的。而在while语句里它的核心是调用了一个<code>compareAndSwapInt()</code>的方法。它是一个native方法，它是一个底层的方法，不是使用Java来实现的。</p>
<p>假设我们要执行0+1=0的操作，下面是单线程情况下各参数的值：</p>
<p><img src="images/20191201180435146_205936933.png"><br><img src="images/20191201180445132_1585877614.png"><br>更新后：</p>
<p><img src="images/20191201180454442_1425515581.png"></p>
<p>compareAndSwapInt()方法的第一个参数（var1）是当前的对象，就是代码示例中的count。此时它的值为0（期望值）。<br>第二个值（var2）是传递的valueOffset值，它的值为12。<br>第三个参数（var4）就为常量1。方法中的变量参数（var5）是根据参数一和参数二valueOffset，调用底层getIntVolatile方法得到的值，此时它的值为0 。<br>compareAndSwapInt()想要达到的目标是对于count这个对象，如果当前的期望值var1里的value跟底层的返回的值（var5）相同的话，那么把它更新成var5+var4这个值。<br>不同的话重新循环取期望值（var5）直至当前值与期望值相同才做更新。compareAndSwap方法的核心也就是我们通常所说的CAS。</p>
<p>Atomic包下其他的类如AtomicLong等的实现原理基本与上述一样。</p>
<h3 id="AtomicInteger的代码"><a href="#AtomicInteger的代码" class="headerlink" title="AtomicInteger的代码"></a>AtomicInteger的代码</h3><p><img src="images/20191201191519348_1356001936" title="image.png"></p>
<p>他的值是存在一个volatile的int里面。volatile只能保证这个变量的可见性。不能保证他的原子性。</p>
<p>可以看看getAndIncrement这个类似i++的函数，可以发现，是调用了UnSafe中的getAndAddInt。  </p>
<p><img src="images/20191201191518930_1459996071" title="image.png"></p>
<h3 id="UnSafe"><a href="#UnSafe" class="headerlink" title="UnSafe"></a>UnSafe</h3><p>UnSafe是何方神圣？UnSafe提供了java可以直接操作底层的能力。</p>
<p>进一步，我们可以发现实现方式：  </p>
<p><img src="images/20191201191518602_784980377" title="image.png"></p>
<p>如何保证原子性：<strong>自旋 + <a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&mid=2650121285&idx=1&sn=7cf9b5badd6d38b57ccfbfed63d3aad1&chksm=f36bb964c41c307218914cab6c1592f649281460e4ec1f85627c1311441c8a43ee1854440552&scene=21#wechat_redirect">CAS</a>（乐观锁）</strong>。在这个过程中，通过compareAndSwapInt比较更新value值，如果更新失败，重新获取旧值，然后更新。</p>
<p><strong>优缺点</strong></p>
<p>CAS相对于其他锁，不会进行内核态操作，有着一些性能的提升。但同时引入自旋，<strong>当锁竞争较大的时候，自旋次数会增多。cpu资源会消耗很高</strong>。  </p>
<p>换句话说，CAS+自旋适合使用在低并发有同步数据的应用场景。</p>
<h3 id="Java-8做出的改进和努力"><a href="#Java-8做出的改进和努力" class="headerlink" title="Java 8做出的改进和努力"></a>Java 8做出的改进和努力</h3><p>在Java 8中引入了4个新的计数器类型，<code>LongAdder</code>、<code>LongAccumulator</code>、<code>DoubleAdder</code>、<code>DoubleAccumulator</code>。他们都是继承于<code>Striped64</code></p>
<h4 id="在LongAdder-与AtomicLong有什么区别"><a href="#在LongAdder-与AtomicLong有什么区别" class="headerlink" title="在LongAdder 与AtomicLong有什么区别?"></a>在LongAdder 与AtomicLong有什么区别?</h4><p>这里再介绍下LongAdder这个类，通过上述的分析，我们已经知道了AtomicLong使用CAS：<br><strong>在一个死循环内不断尝试修改目标值直到修改成功。如果在竞争不激烈的情况下，它修改成功概率很高。反之，如果在竞争激烈的情况下，修改失败的概率会很高，它就会进行多次的循环尝试，因此性能会受到一些影响。</strong><br>对于普通类型的long和double变量，jvm允许将64位的读操作或写操作拆成两个32位的操作。</p>
<p>LongAdder的核心思想是将热点数据分离，它可以将AtomicLong内部核心数据value分离成一个数组，每个线程访问时通过hash等算法映射到其中一个数字进行计数。而最终的计数结果则为这个数组的求和累加，其中热点数据value，它会被分离成多个单元的cell，每个cell独自维护内部的值,当前对象的实际值由所有的cell累计合成。这样,热点就进行了有效的分离,提高了并行度。LongAdder相当于在AtomicLong的基础上将单点的更新压力分散到各个节点上，在低并发的时候对base的直接更新可以很好的保障跟Atomic的性能基本一致。而在高并发的时候，通过分散提高了性能。但是如果在统计的时候有并发更新，可能会导致统计的数据有误差。</p>
<p>在实际高并发计数的时候，可以优先使用LongAdder。在低并行度或者需要准确数值的时候可以优先使用AtomicLong，这样反而效率更高。</p>
<p>下面简单的演示下Atomic包下AtomicReference简单的用法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicExample4</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AtomicReference&lt;Integer&gt; count = <span class="keyword">new</span> AtomicReference&lt;&gt;(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        count.compareAndSet(<span class="number">0</span>, <span class="number">2</span>);</span><br><span class="line">        count.compareAndSet(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">        log.info(<span class="string">&quot;count:&#123;&#125;&quot;</span>, count.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>compareAndSet()分别传入的是预期值跟更新值，只有当预期值跟当前值相等时，才会将值更新为更新值；</p>
<p>上面的第一个方法可以将值更新为2，而第二个步中无法将值更新为1。</p>
<p>Atomic*遇到的问题是，只能运用于低并发场景。因此LongAddr在这基础上引入了<strong>分段锁</strong>的概念。可以参考《JDK8系列之LongAdder解析》一起看看做了什么。</p>
<p>**大概就是当竞争不激烈的时候，所有线程都是通过CAS对同一个变量（Base）进行修改，当竞争激烈的时候，会将根据当前线程哈希到对于Cell上进行修改（多段锁）。  **</p>
<p><img src="images/20191201191517305_1368784593" title="image.png"></p>
<p>可以看到大概实现原理是：通过<strong>CAS乐观锁</strong>保证原子性，通过<strong>自旋</strong>保证当次修改的最终修改成功，通过<strong>降低锁粒度（多段锁）</strong>增加并发性能。</p>
<h2 id="AtomicIntegerFieldUpdater"><a href="#AtomicIntegerFieldUpdater" class="headerlink" title="AtomicIntegerFieldUpdater"></a>AtomicIntegerFieldUpdater</h2><p>下面简单介绍下AtomicIntegerFieldUpdater 用法（利用原子性去更新某个类的实例）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicExample5</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AtomicIntegerFieldUpdater&lt;AtomicExample5&gt; updater =</span><br><span class="line">            AtomicIntegerFieldUpdater.newUpdater(AtomicExample5.class, <span class="string">&quot;count&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> count = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        AtomicExample5 example5 = <span class="keyword">new</span> AtomicExample5();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (updater.compareAndSet(example5, <span class="number">100</span>, <span class="number">120</span>)) &#123;</span><br><span class="line">            log.info(<span class="string">&quot;update success 1, &#123;&#125;&quot;</span>, example5.getCount());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (updater.compareAndSet(example5, <span class="number">100</span>, <span class="number">120</span>)) &#123;</span><br><span class="line">            log.info(<span class="string">&quot;update success 2, &#123;&#125;&quot;</span>, example5.getCount());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            log.info(<span class="string">&quot;update failed, &#123;&#125;&quot;</span>, example5.getCount());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它可以更新某个类中指定成员变量的值。注意：修改的成员变量需要用volatile关键字来修饰，并且不能是static描述的字段。</p>
<h2 id="AtomicStampReference"><a href="#AtomicStampReference" class="headerlink" title="AtomicStampReference"></a>AtomicStampReference</h2><p>AtomicStampReference 这个类它的核心是要解决CAS的ABA问题（CAS操作的时候，其他线程将变量的值A改成了B，接着又改回了A，等线程使用期望值A与当前变量进行比较的时候，发现A变量没有变，于是CAS就将A值进行了交换操作。实际上该值已经被其他线程改变过）。ABA问题的解决思路就是每次变量变更的时候，就将版本号加一。看一下它的一个核心方法compareAndSet()：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicStampedReference</span>&lt;<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> T reference;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> stamp;</span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="title">Pair</span><span class="params">(T reference, <span class="keyword">int</span> stamp)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.reference = reference;</span><br><span class="line">            <span class="keyword">this</span>.stamp = stamp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">static</span> &lt;T&gt; <span class="function">Pair&lt;T&gt; <span class="title">of</span><span class="params">(T reference, <span class="keyword">int</span> stamp)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Pair&lt;T&gt;(reference, stamp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">   ... 此处省略多个方法 ....</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(V   expectedReference,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 V   newReference,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">int</span> expectedStamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">int</span> newStamp)</span> </span>&#123;</span><br><span class="line">        Pair&lt;V&gt; current = pair;</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">            expectedReference == current.reference &amp;&amp;</span><br><span class="line">            expectedStamp == current.stamp &amp;&amp;</span><br><span class="line">            ((newReference == current.reference &amp;&amp;</span><br><span class="line">              newStamp == current.stamp) ||</span><br><span class="line">             casPair(current, Pair.of(newReference, newStamp)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到它多了一个stamp的比较，stamp的值是由每次更新的时候进行维护的。</p>
<h2 id="AtomicLongArray"><a href="#AtomicLongArray" class="headerlink" title="AtomicLongArray"></a>AtomicLongArray</h2><p>再介绍下 AtomicLongArray ， 它维护了一个数组。在该数组下，我们可以选择性的已原子性操作更新某个索引对应的值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicLongArray</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">2308431214976778248L</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class="line"> </span><br><span class="line">    ...此处省略....</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Atomically sets the element at position &#123;<span class="doctag">@code</span> i&#125; to the given value</span></span><br><span class="line"><span class="comment">     * and returns the old value.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> i the index</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> newValue the new value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> the previous value</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">getAndSet</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">long</span> newValue)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> unsafe.getAndSetLong(array, checkedByteOffset(i), newValue);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Atomically sets the element at position &#123;<span class="doctag">@code</span> i&#125; to the given</span></span><br><span class="line"><span class="comment">     * updated value if the current value &#123;<span class="doctag">@code</span> ==&#125; the expected value.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> i the index</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> expect the expected value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> update the new value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> &#123;<span class="doctag">@code</span> true&#125; if successful. False return indicates that</span></span><br><span class="line"><span class="comment">     * the actual value was not equal to the expected value.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">long</span> expect, <span class="keyword">long</span> update)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> compareAndSetRaw(checkedByteOffset(i), expect, update);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="AtomcBoolean"><a href="#AtomcBoolean" class="headerlink" title="AtomcBoolean"></a>AtomcBoolean</h2><p>最后再写一个AtomcBoolean的简单使用：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicExample6</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AtomicBoolean isHappened = <span class="keyword">new</span> AtomicBoolean(<span class="keyword">false</span>);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 请求总数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> clientTotal = <span class="number">5000</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 同时并发执行的线程数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> threadTotal = <span class="number">200</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ExecutorService executorService = Executors.newCachedThreadPool();</span><br><span class="line">        <span class="keyword">final</span> Semaphore semaphore = <span class="keyword">new</span> Semaphore(threadTotal);</span><br><span class="line">        <span class="keyword">final</span> CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(clientTotal);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; clientTotal ; i++) &#123;</span><br><span class="line">            executorService.execute(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    semaphore.acquire();</span><br><span class="line">                    test();</span><br><span class="line">                    semaphore.release();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;exception&quot;</span>, e);</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        executorService.shutdown();</span><br><span class="line">        log.info(<span class="string">&quot;isHappened:&#123;&#125;&quot;</span>, isHappened.get());</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (isHappened.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">            log.info(<span class="string">&quot;execute&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>总结：以上就是Atomic包的基本原理及主要的使用方法。它是使用CAS来保证原子性操作，从而达到线程安全的目的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.Semaphore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RunningInTurn</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="title">extendsThread</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Semaphore thisSemaphore;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Semaphore nextSemaphore;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> value;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Worker</span><span class="params">(String name, Semaphore thisSemaphore, Semaphore nextSemaphore, <span class="keyword">int</span> initialValue)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.name= name;</span><br><span class="line"><span class="keyword">this</span>.thisSemaphore= thisSemaphore;</span><br><span class="line"><span class="keyword">this</span>.nextSemaphore= nextSemaphore;</span><br><span class="line"><span class="keyword">this</span>.value= initialValue;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">while</span>(value &lt;= <span class="number">100</span>) &#123;</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">thisSemaphore.acquire();</span><br><span class="line">System.out.println(name + <span class="string">&quot;:\t&quot;</span>+ value);</span><br><span class="line">value += <span class="number">2</span>;</span><br><span class="line">nextSemaphore.release();</span><br><span class="line">&#125; <span class="keyword">catch</span>(InterruptedExceptione) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException</span>&#123;</span><br><span class="line"></span><br><span class="line">Semaphorea Semaphore = newSemaphore(<span class="number">1</span>);</span><br><span class="line">Semaphore bSemaphore = newSemaphore(<span class="number">1</span>);</span><br><span class="line">Worker workerA = newWorker(<span class="string">&quot;a&quot;</span>, aSemaphore, bSemaphore, <span class="number">1</span>);</span><br><span class="line">Worker workerB = newWorker(<span class="string">&quot;b&quot;</span>, bSemaphore, aSemaphore, <span class="number">2</span>);</span><br><span class="line">bSemaphore.acquire();</span><br><span class="line">workerA.start();</span><br><span class="line">workerB.start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrimeNumberWithRoll</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> rowNum = <span class="number">21</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> colNum = <span class="number">10000_0000</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">byte</span>[][] bytes = newbyte[rowNum][colNum];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">init();</span><br><span class="line">start();</span><br><span class="line">print();</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">intcount = <span class="number">0</span>;</span><br><span class="line">longi;</span><br><span class="line"><span class="keyword">for</span>(i = <span class="number">1</span>; count &lt;= <span class="number">10000_0000</span>&amp;&amp; i &lt;= rowNum * colNum; i++) &#123;</span><br><span class="line"><span class="keyword">if</span>(getValue(i)) &#123;</span><br><span class="line">count++;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(count - <span class="number">1</span>+ <span class="string">&quot;\t&quot;</span>+ i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">byte</span>[] aByte :bytes) &#123;</span><br><span class="line">Arrays.fill(aByte, (<span class="keyword">byte</span>) <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">longindex = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">while</span>(index * index &lt; (<span class="keyword">long</span>) rowNum * colNum) &#123;</span><br><span class="line"><span class="keyword">boolean</span> prime = getValue(index);</span><br><span class="line">System.out.println(index + <span class="string">&quot;\t&quot;</span>+ prime);</span><br><span class="line"><span class="keyword">if</span>(prime) &#123;</span><br><span class="line">setPrimeRoll(index, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line">index++;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setPrimeRoll</span><span class="params">(longindex, booleanpri)</span> </span>&#123;</span><br><span class="line"><span class="keyword">for</span>(longi = index + index; i &lt; bytes.length* bytes[<span class="number">0</span>].length; i += index) &#123;</span><br><span class="line">setValue(i, pri);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setValue</span><span class="params">(longindex, booleanpri)</span> </span>&#123;</span><br><span class="line"><span class="keyword">long</span> localIndex = index - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">long</span> rowNo = localIndex / colNum;</span><br><span class="line"><span class="keyword">long</span> colNo = localIndex % colNum;</span><br><span class="line">bytes[(<span class="keyword">int</span>) rowNo][(<span class="keyword">int</span>) colNo] = pri ?(<span class="keyword">byte</span>) <span class="number">1</span>:(<span class="keyword">byte</span>) <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">getValue</span><span class="params">(longindex)</span> </span>&#123;</span><br><span class="line"><span class="keyword">long</span> localIndex = index - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span>(localIndex == <span class="number">1</span>|| localIndex == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">long</span> rowNo = localIndex / colNum;</span><br><span class="line"><span class="keyword">long</span> colNo = localIndex % colNum;</span><br><span class="line"><span class="keyword">return</span> bytes[(<span class="keyword">int</span>) rowNo][(<span class="keyword">int</span>) colNo] == <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/distributed/03.%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81%E6%9C%BA%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/distributed/03.%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81%E6%9C%BA%E5%88%B6/" class="post-title-link" itemprop="url">分布式理论：隔离机制【转载】</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-09-10T14:58:00+08:00">2019-09-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:51" itemprop="dateModified" datetime="2021-04-24T12:58:51+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转载自 <a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000020791119">微服务容错 - 隔离熔断限流</a></p>
<p>在高并发访问下，系统所依赖的服务的稳定性对系统的影响非常大，依赖有很多不可控的因素，比如网络连接变慢，资源突然繁忙，暂时不可用，服务脱机等。我们要构建稳定、可靠的分布式系统，就必须要有这样一套容错机制。常用的的容错技术如：隔离，降级，熔断，限流等策略，本文将详细的介绍微服务中的容错机制。</p>
<h2 id="隔离机制"><a href="#隔离机制" class="headerlink" title="隔离机制"></a>隔离机制</h2><p>为什么要隔离? 比如我们现在某个接口所在的服务A需要调用服务B，而服务B同时需要调用C服务，此时服务C突然宕机同时此时流量暴涨，调用全部打到服务B上，此时B服务调用C超时大量的线程资源被该接口所占全部hang住，慢慢服务B中的线程数量则会持续增加直致CPU资源耗尽到100%，整个服务对外不可用渐渐蔓延到B服务集群中的其他节点，导致服务级联故障。</p>
<p><img src="_v_images/20191130225057895_2045824433" alt="1570592685522.png" title="1570592685522.png"></p>
<p>此时我们就需要对服务出现异常的情况进行隔离，防止级联故障效应，常用的隔离策略有线程池隔离和信号量隔离</p>
<h3 id="线程池隔离"><a href="#线程池隔离" class="headerlink" title="线程池隔离"></a>线程池隔离</h3><p>线程池隔离顾名思义就是通过Java的线程池进行隔离，B服务调用C服务给予固定的线程数量比如10个线程，如果此时C服务宕机了就算大量的请求过来，调用C服务的接口只会占用10个线程不会占用其他工作线程资源，因此B服务就不会出现级联故障</p>
<p><img src="_v_images/20191130225057490_1596748749" alt="1570593867373.png" title="1570593867373.png"></p>
<h3 id="信号量隔离"><a href="#信号量隔离" class="headerlink" title="信号量隔离"></a>信号量隔离</h3><p>另一种隔离信号量隔离是使用<code>JUC</code>下的Semaphore来实现的，当拿不到信号量的时候直接拒接因此不会出现超时占用其他工作线程的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Semaphore semaphore &#x3D; new Semaphore(10,true);</span><br><span class="line">&#x2F;&#x2F;获取信号量</span><br><span class="line">semaphore.acquire();</span><br><span class="line">&#x2F;&#x2F;do something here</span><br><span class="line">&#x2F;&#x2F;释放信号量</span><br><span class="line">semaphore.release();</span><br></pre></td></tr></table></figure>
<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>​线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。而信号量隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。</p>
<table>
<thead>
<tr>
<th>比较项</th>
<th>线程池隔离</th>
<th>信号量隔离</th>
</tr>
</thead>
<tbody><tr>
<td>线程</td>
<td>与调用线程不同，使用的是线程池创建的线程</td>
<td>与调用线程相同</td>
</tr>
<tr>
<td>开销</td>
<td>排队，切换，调度等开销</td>
<td>无线程切换性能更高</td>
</tr>
<tr>
<td>是否支持异步</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>是否支持超时</td>
<td>支持超时</td>
<td><strong>支持超时(<a target="_blank" rel="noopener" href="https://www.codercto.com/a/77154.html">新版本支持</a>)</strong></td>
</tr>
<tr>
<td>并发支持</td>
<td>支持通过线程池大小控制</td>
<td>支持通过最大信号量控制</td>
</tr>
</tbody></table>
<h2 id="降级熔断机制"><a href="#降级熔断机制" class="headerlink" title="降级熔断机制"></a>降级熔断机制</h2><p>​ 什么是降级和熔断？降级和熔断有什么区别？虽然很多人把降级熔断当着一个词来说的，但是降级和熔断是完全不同的概念的，看看下面几种场景：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">场景一：比如我们每天上班坐公交，1路和2路公交都能到公司，但是2路公交需要下车走点路，所以平时都是坐1路公交，</span><br><span class="line">突然有一天等了1路公交好久都没来，于是就坐了2路公交作为替代方案总不能迟到吧！下次再等1路车。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">场景二：第二天，第三天 ... 已经一个星期了都没看到1路公交，心里觉得可能是1路公交改路线了，</span><br><span class="line">于是直接坐2路公交了，在接下来的日子里都是直接忽略1路车直接坐2路车</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">场景三：突然有一天在等2路车的时候看到了1路车，是不是1路车现在恢复了，于是天天开心的坐着1路车上班去了，领导再也不担心我迟到了</span><br></pre></td></tr></table></figure>
<p>场景一 在1路车没等到的情况下采取降级方案坐2路车，这就是降级策略，<br>场景二 如果多次都没有等到1路车就直接不等了下次直接坐2路车，这就是熔断策略，<br>场景三 如果过段时间1路车恢复了就使用2路车，这就是熔断恢复！</p>
<h3 id="降级机制"><a href="#降级机制" class="headerlink" title="降级机制"></a>降级机制</h3><p>常用的降级策略如：熔断器降级，限流降级，超时降级，异常降级，平均响应时间降级等</p>
<p><img src="_v_images/20191130225057086_638012610" alt="1570591437265.png" title="1570591437265.png"></p>
<ul>
<li><strong>熔断器降级：</strong>即熔断器开启的时间直接熔断走降级的策略</li>
<li><strong>限流降级：</strong>对流量进行限制达到降级的效果，如：<code>Hystrix</code>中的线程池，信号量都能达到限流的效果</li>
<li><strong>超时降级：</strong>课时设置对应的超时时间如果服务调用超时了就执行降级策略，如：<code>Hystrix</code>中默认为1s</li>
<li><strong>异常降级：</strong>异常降级很简单就是服务出现异常了执行降级策略</li>
<li><strong>平均响应时间降级：</strong>服务响应时间持续飙高的时候实现降级策略，如Sentinel中默认的RT 上限是 4900 ms</li>
</ul>
<h3 id="熔断机制"><a href="#熔断机制" class="headerlink" title="熔断机制"></a>熔断机制</h3><p>​ 熔断其实是一个框架级的处理，那么这套熔断机制的设计，基本上业内用的是<code>Martin Fowler</code>提出的断路器模式，断路器的基本原理非常简单。<br>您将受保护的函数调用包装在断路器对象中，该对象将监视故障。一旦故障达到某个阈值，断路器将跳闸，并且所有进一步的断路器调用都会返回错误，而根本不会进行受保护的调用。常见的断路器模式有基本模式和扩展模式。</p>
<p><strong>基本模式：</strong></p>
<ul>
<li>如果断路器状态为close，则调用断路器将调用supplier服务模块；</li>
<li>如果断路器状态为open则直接返回错误；</li>
<li>如果超时，我们将增加失败计数器，成功的调用会将其重置为零；</li>
<li>通过比较故障计数和阈值来确定断路器的状态；</li>
</ul>
<p><img src="_v_images/20191130225056679_1480988248" alt="20191024163112.png" title="20191024163112.png"></p>
<p><strong>扩展模式：</strong></p>
<p>基础模式的断路器避免了在电路断开时发出受保护的呼叫，但是当情况恢复正常时，将需要外部干预才能将其重置。对于建筑物中的电路断路器，这是一种合理的方法，但是对于软件断路器，我们可以让断路器本身检测基础调用是否再次正常工作。我们可以通过在适当的时间间隔后再次尝试受保护的调用来实现这种自我重置行为，并在成功后重置断路器。于是就出现了扩展模式：</p>
<p><img src="_v_images/20191130225056272_406198049" alt="20191024163133.png" title="20191024163133.png"></p>
<ul>
<li>最开始处于<code>closed</code>状态，一旦检测到错误到达一定阈值，便转为<code>open</code>状态；</li>
<li>这时候会有个 reset timeout，到了这个时间了，会转移到<code>half open</code>状态；</li>
<li>尝试放行一部分请求到后端，一旦检测成功便回归到<code>closed</code>状态，即恢复服务；</li>
</ul>
<h3 id="熔断策略"><a href="#熔断策略" class="headerlink" title="熔断策略"></a>熔断策略</h3><p>我们通常用以下几种方式来衡量资源是否处于稳定的状态：</p>
<ul>
<li>平均响应时间：如<code>Sentinel</code>中的熔断就使用了平均响应时间，当 1s 内持续进入 5 个请求，对应时刻的平均响应时间（秒级）均超过阈值（<code>count</code>，以 ms 为单位），那么在接下的时间窗口之内，对这个方法的调用都会自动地熔断。</li>
<li>异常比例 ：主流的容错框架<code>Hystrix</code>和<code>sentinel</code>中都使用了异常比例熔断策略，比如当资源的每秒请求量 &gt;= 5，并且每秒异常总数占通过量的比值超过阈值之后，资源进入熔断状态，即在接下的时间窗口之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 <code>[0.0, 1.0]</code>，代表 0% - 100%。</li>
<li>异常数：如<code>Sentinel</code>中的熔断就使用了异常数熔断策略，当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 <code>timeWindow</code> 小于 60s，则结束熔断状态后仍可能再进入熔断状态。</li>
</ul>
<h2 id="限流机制"><a href="#限流机制" class="headerlink" title="限流机制"></a>限流机制</h2><p>​ 限流也是提高系统的容错性的一种方案，不同的场景对“流”的定义也是不同的，可以是网络流量，带宽，每秒处理的事务数 (<code>TPS</code>)，每秒请求数 (<code>hits per second</code>)，并发请求数，甚至还可能是业务上的某个指标，比如用户在某段时间内允许的最多请求短信验证码次数。我们常说的限流都是限制每秒请求数，从分布式角度来看，限流可分为 <code>分布式限流</code> （比如基于<code>Sentinel</code>或者<code>Redis</code>的集群限流）和 <code>单机限流</code> 。从算法实现角度来看，限流算法可分为 <code>漏桶算法</code>、 <code>令牌桶算法</code> 和 <code>滑动时间窗口算法</code> 。</p>
<h3 id="单机限流"><a href="#单机限流" class="headerlink" title="单机限流"></a>单机限流</h3><p><strong>漏桶算法</strong></p>
<p><img src="_v_images/20191130225055766_1808623677" alt="1570701032430.png" title="1570701032430.png"></p>
<ul>
<li>一个固定容量的漏桶，按照常量固定速率流出水滴；</li>
<li>如果桶是空的，则不需流出水滴；</li>
<li>可以以任意速率流入水滴到漏桶；</li>
<li>如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。</li>
</ul>
<p><strong>令牌桶算法</strong></p>
<p><img src="_v_images/20191130225055360_839601664" alt="1570700342271.png" title="1570700342271.png"></p>
<ul>
<li>假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌；</li>
<li>桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝；</li>
<li>当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上；</li>
<li>如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。</li>
</ul>
<p><strong>固定时间窗口算法</strong><br><img src="_v_images/20191130225054755_1892726461" alt="20191024163948.png" title="20191024163948.png"></p>
<p>这种实现计数器限流方式由于是在一个时间间隔内进行限制，如果用户在上个时间间隔结束前请求（但没有超过限制），同时在当前时间间隔刚开始请求（同样没超过限制），在各自的时间间隔内，这些请求都是正常的，但是将间隔临界的一段时间内的请求就会超过系统限制，可能导致系统被压垮。</p>
<p><strong>滑动时间窗口算法</strong></p>
<p><img src="_v_images/20191130225054050_1038055339" alt="1571219763433.png" title="1571219763433.png"></p>
<ul>
<li>0、初始化，设置时间窗口，设置时间窗口时间点间隔长度；</li>
<li>1、判断请求时间点是否在时间窗口中，在进入步骤2，否则进入步骤3；</li>
<li>2、判断是否超过时间窗口限流值，是-&gt;进行限流，否-&gt;对应时间窗口计数器+1；</li>
<li>3、移动当时时间窗口，移动方式是：起始时间点变为时间列表中的第二时间点，结束时间增加一个时间点。重新步骤一的判断 。</li>
</ul>
<h3 id="分布式限流"><a href="#分布式限流" class="headerlink" title="分布式限流"></a>分布式限流</h3><p>当应用为单点应用时，只要应用进行了限流，那么应用所依赖的各种服务也都得到了保护。 但线上业务出于各种原因考虑，多是分布式系统，单节点的限流仅能保护自身节点，但无法保护应用依赖的各种服务，并且在进行节点扩容、缩容时也无法准确控制整个服务的请求限制。</p>
<p><img src="_v_images/20191130225053543_420645799" alt="1571903140149.png" title="1571903140149.png"></p>
<p>如果实现了分布式限流，那么就可以方便地控制整个服务集群的请求限制，且由于整个集群的请求数量得到了限制，因此服务依赖的各种资源也得到了限流的保护。</p>
<p><img src="_v_images/20191130225052943_1592738452" alt="1571904304647.png" title="1571904304647.png"></p>
<p><strong>分布式限流方案</strong></p>
<p>分布式限流的思想我列举下面三个方案：</p>
<p><strong>1，<code>Redis</code>令牌桶</strong></p>
<p>这种方案是最简单的一种集群限流思想。在本地限流中，我们使用Long的原子类作令牌桶，当实例数量超过1，我们就考虑将<code>Redis</code>用作公共内存区域，进行读写。涉及到的并发控制，也可以使用<code>Redis</code>实现分布式锁。</p>
<p><strong>缺点：</strong>每取一次令牌都会进行一次网络开销，而网络开销起码是毫秒级，所以这种方案支持的并发量是非常有限的。</p>
<p><strong>2，<code>QPS</code>统一分配</strong></p>
<p>这种方案的思想是将集群限流最大程度的本地化。</p>
<p>举个例子，我们有两台服务器实例，对应的是同一个应用程序（<code>Application.name</code>相同），程序中设置的<code>QPS</code>为100，将应用程序与同一个控制台程序进行连接，控制台端依据应用的实例数量将<code>QPS</code>进行均分，动态设置每个实例的<code>QPS</code>为50，若是遇到两个服务器的配置并不相同，在负载均衡层的就已经根据服务器的优劣对流量进行分配，例如一台分配70%流量，另一台分配30%的流量。面对这种情况，控制台也可以对其实行加权分配<code>QPS</code>的策略。</p>
<p><strong>缺点：</strong></p>
<p>这也算一种集群限流的实现方案，但依旧存在不小的问题。该模式的分配比例是建立在大数据流量下的趋势进行分配，实际情况中可能并不是严格的五五分或三七分，误差不可控，极容易出现用户连续访问某一台服务器遇到请求驳回而另一台服务器此刻空闲流量充足的尴尬情况。</p>
<p><strong>3，发票服务器</strong></p>
<p>这种方案的思想是建立在<code>Redis</code>令牌桶方案的基础之上的。如何解决每次取令牌都伴随一次网络开销，该方案的解决方法是建立一层控制端，利用该控制端与<code>Redis</code>令牌桶进行交互，只有当客户端的剩余令牌数不足时，客户端才向该控制层取令牌并且每次取一批。</p>
<p><strong>缺点：</strong><br>这种思想类似于Java集合框架的数组扩容，设置一个阈值，只有当超过该临界值时，才会触发异步调用。其余存取令牌的操作与本地限流无二。虽然该方案依旧存在误差，但误差最大也就一批次令牌数而已。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1，<a target="_blank" rel="noopener" href="https://www.cnblogs.com/rjzheng/p/10340176.html">https://www.cnblogs.com/rjzhe…</a><br>2，<a target="_blank" rel="noopener" href="https://www.martinfowler.com/bliki/CircuitBreaker.html">https://www.martinfowler.com/…</a><br>3，<a target="_blank" rel="noopener" href="https://www.cnblogs.com/babycomeon/p/11216538.html">https://www.cnblogs.com/babyc…</a><br>4，<a target="_blank" rel="noopener" href="https://github.com/alibaba/Sentinel/wiki/Sentinel-%E4%B8%8E-Hystrix-%E7%9A%84%E5%AF%B9%E6%AF%94">https://github.com/alibaba/Se…</a><br>5，<a target="_blank" rel="noopener" href="https://www.jishuwen.com/d/2TX1">https://www.jishuwen.com/d/2TX1</a><br>6，<a target="_blank" rel="noopener" href="https://juejin.im/post/5c74a2e2f265da2dea053355">https://juejin.im/post/5c74a2…</a><br>7，<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/2596e559db5c">https://www.jianshu.com/p/259…</a><br>8，<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/48965194">https://zhuanlan.zhihu.com/p/…</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/distributed/03.%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81%E6%9C%BA%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/distributed/03.%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81%E6%9C%BA%E5%88%B6/" class="post-title-link" itemprop="url">分布式理论：隔离机制【转载】</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-09-10T14:58:00+08:00">2019-09-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:52" itemprop="dateModified" datetime="2021-04-24T12:58:52+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转载自 <a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000020791119">微服务容错 - 隔离熔断限流</a></p>
<p>在高并发访问下，系统所依赖的服务的稳定性对系统的影响非常大，依赖有很多不可控的因素，比如网络连接变慢，资源突然繁忙，暂时不可用，服务脱机等。我们要构建稳定、可靠的分布式系统，就必须要有这样一套容错机制。常用的的容错技术如：隔离，降级，熔断，限流等策略，本文将详细的介绍微服务中的容错机制。</p>
<h2 id="隔离机制"><a href="#隔离机制" class="headerlink" title="隔离机制"></a>隔离机制</h2><p>为什么要隔离? 比如我们现在某个接口所在的服务A需要调用服务B，而服务B同时需要调用C服务，此时服务C突然宕机同时此时流量暴涨，调用全部打到服务B上，此时B服务调用C超时大量的线程资源被该接口所占全部hang住，慢慢服务B中的线程数量则会持续增加直致CPU资源耗尽到100%，整个服务对外不可用渐渐蔓延到B服务集群中的其他节点，导致服务级联故障。</p>
<p><img src="_v_images/20191130225057895_2045824433" alt="1570592685522.png" title="1570592685522.png"></p>
<p>此时我们就需要对服务出现异常的情况进行隔离，防止级联故障效应，常用的隔离策略有线程池隔离和信号量隔离</p>
<h3 id="线程池隔离"><a href="#线程池隔离" class="headerlink" title="线程池隔离"></a>线程池隔离</h3><p>线程池隔离顾名思义就是通过Java的线程池进行隔离，B服务调用C服务给予固定的线程数量比如10个线程，如果此时C服务宕机了就算大量的请求过来，调用C服务的接口只会占用10个线程不会占用其他工作线程资源，因此B服务就不会出现级联故障</p>
<p><img src="_v_images/20191130225057490_1596748749" alt="1570593867373.png" title="1570593867373.png"></p>
<h3 id="信号量隔离"><a href="#信号量隔离" class="headerlink" title="信号量隔离"></a>信号量隔离</h3><p>另一种隔离信号量隔离是使用<code>JUC</code>下的Semaphore来实现的，当拿不到信号量的时候直接拒接因此不会出现超时占用其他工作线程的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Semaphore semaphore &#x3D; new Semaphore(10,true);</span><br><span class="line">&#x2F;&#x2F;获取信号量</span><br><span class="line">semaphore.acquire();</span><br><span class="line">&#x2F;&#x2F;do something here</span><br><span class="line">&#x2F;&#x2F;释放信号量</span><br><span class="line">semaphore.release();</span><br></pre></td></tr></table></figure>
<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>​线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。而信号量隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。</p>
<table>
<thead>
<tr>
<th>比较项</th>
<th>线程池隔离</th>
<th>信号量隔离</th>
</tr>
</thead>
<tbody><tr>
<td>线程</td>
<td>与调用线程不同，使用的是线程池创建的线程</td>
<td>与调用线程相同</td>
</tr>
<tr>
<td>开销</td>
<td>排队，切换，调度等开销</td>
<td>无线程切换性能更高</td>
</tr>
<tr>
<td>是否支持异步</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>是否支持超时</td>
<td>支持超时</td>
<td><strong>支持超时(<a target="_blank" rel="noopener" href="https://www.codercto.com/a/77154.html">新版本支持</a>)</strong></td>
</tr>
<tr>
<td>并发支持</td>
<td>支持通过线程池大小控制</td>
<td>支持通过最大信号量控制</td>
</tr>
</tbody></table>
<h2 id="降级熔断机制"><a href="#降级熔断机制" class="headerlink" title="降级熔断机制"></a>降级熔断机制</h2><p>​ 什么是降级和熔断？降级和熔断有什么区别？虽然很多人把降级熔断当着一个词来说的，但是降级和熔断是完全不同的概念的，看看下面几种场景：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">场景一：比如我们每天上班坐公交，1路和2路公交都能到公司，但是2路公交需要下车走点路，所以平时都是坐1路公交，</span><br><span class="line">突然有一天等了1路公交好久都没来，于是就坐了2路公交作为替代方案总不能迟到吧！下次再等1路车。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">场景二：第二天，第三天 ... 已经一个星期了都没看到1路公交，心里觉得可能是1路公交改路线了，</span><br><span class="line">于是直接坐2路公交了，在接下来的日子里都是直接忽略1路车直接坐2路车</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">场景三：突然有一天在等2路车的时候看到了1路车，是不是1路车现在恢复了，于是天天开心的坐着1路车上班去了，领导再也不担心我迟到了</span><br></pre></td></tr></table></figure>
<p>场景一 在1路车没等到的情况下采取降级方案坐2路车，这就是降级策略，<br>场景二 如果多次都没有等到1路车就直接不等了下次直接坐2路车，这就是熔断策略，<br>场景三 如果过段时间1路车恢复了就使用2路车，这就是熔断恢复！</p>
<h3 id="降级机制"><a href="#降级机制" class="headerlink" title="降级机制"></a>降级机制</h3><p>常用的降级策略如：熔断器降级，限流降级，超时降级，异常降级，平均响应时间降级等</p>
<p><img src="_v_images/20191130225057086_638012610" alt="1570591437265.png" title="1570591437265.png"></p>
<ul>
<li><strong>熔断器降级：</strong>即熔断器开启的时间直接熔断走降级的策略</li>
<li><strong>限流降级：</strong>对流量进行限制达到降级的效果，如：<code>Hystrix</code>中的线程池，信号量都能达到限流的效果</li>
<li><strong>超时降级：</strong>课时设置对应的超时时间如果服务调用超时了就执行降级策略，如：<code>Hystrix</code>中默认为1s</li>
<li><strong>异常降级：</strong>异常降级很简单就是服务出现异常了执行降级策略</li>
<li><strong>平均响应时间降级：</strong>服务响应时间持续飙高的时候实现降级策略，如Sentinel中默认的RT 上限是 4900 ms</li>
</ul>
<h3 id="熔断机制"><a href="#熔断机制" class="headerlink" title="熔断机制"></a>熔断机制</h3><p>​ 熔断其实是一个框架级的处理，那么这套熔断机制的设计，基本上业内用的是<code>Martin Fowler</code>提出的断路器模式，断路器的基本原理非常简单。<br>您将受保护的函数调用包装在断路器对象中，该对象将监视故障。一旦故障达到某个阈值，断路器将跳闸，并且所有进一步的断路器调用都会返回错误，而根本不会进行受保护的调用。常见的断路器模式有基本模式和扩展模式。</p>
<p><strong>基本模式：</strong></p>
<ul>
<li>如果断路器状态为close，则调用断路器将调用supplier服务模块；</li>
<li>如果断路器状态为open则直接返回错误；</li>
<li>如果超时，我们将增加失败计数器，成功的调用会将其重置为零；</li>
<li>通过比较故障计数和阈值来确定断路器的状态；</li>
</ul>
<p><img src="_v_images/20191130225056679_1480988248" alt="20191024163112.png" title="20191024163112.png"></p>
<p><strong>扩展模式：</strong></p>
<p>基础模式的断路器避免了在电路断开时发出受保护的呼叫，但是当情况恢复正常时，将需要外部干预才能将其重置。对于建筑物中的电路断路器，这是一种合理的方法，但是对于软件断路器，我们可以让断路器本身检测基础调用是否再次正常工作。我们可以通过在适当的时间间隔后再次尝试受保护的调用来实现这种自我重置行为，并在成功后重置断路器。于是就出现了扩展模式：</p>
<p><img src="_v_images/20191130225056272_406198049" alt="20191024163133.png" title="20191024163133.png"></p>
<ul>
<li>最开始处于<code>closed</code>状态，一旦检测到错误到达一定阈值，便转为<code>open</code>状态；</li>
<li>这时候会有个 reset timeout，到了这个时间了，会转移到<code>half open</code>状态；</li>
<li>尝试放行一部分请求到后端，一旦检测成功便回归到<code>closed</code>状态，即恢复服务；</li>
</ul>
<h3 id="熔断策略"><a href="#熔断策略" class="headerlink" title="熔断策略"></a>熔断策略</h3><p>我们通常用以下几种方式来衡量资源是否处于稳定的状态：</p>
<ul>
<li>平均响应时间：如<code>Sentinel</code>中的熔断就使用了平均响应时间，当 1s 内持续进入 5 个请求，对应时刻的平均响应时间（秒级）均超过阈值（<code>count</code>，以 ms 为单位），那么在接下的时间窗口之内，对这个方法的调用都会自动地熔断。</li>
<li>异常比例 ：主流的容错框架<code>Hystrix</code>和<code>sentinel</code>中都使用了异常比例熔断策略，比如当资源的每秒请求量 &gt;= 5，并且每秒异常总数占通过量的比值超过阈值之后，资源进入熔断状态，即在接下的时间窗口之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 <code>[0.0, 1.0]</code>，代表 0% - 100%。</li>
<li>异常数：如<code>Sentinel</code>中的熔断就使用了异常数熔断策略，当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 <code>timeWindow</code> 小于 60s，则结束熔断状态后仍可能再进入熔断状态。</li>
</ul>
<h2 id="限流机制"><a href="#限流机制" class="headerlink" title="限流机制"></a>限流机制</h2><p>​ 限流也是提高系统的容错性的一种方案，不同的场景对“流”的定义也是不同的，可以是网络流量，带宽，每秒处理的事务数 (<code>TPS</code>)，每秒请求数 (<code>hits per second</code>)，并发请求数，甚至还可能是业务上的某个指标，比如用户在某段时间内允许的最多请求短信验证码次数。我们常说的限流都是限制每秒请求数，从分布式角度来看，限流可分为 <code>分布式限流</code> （比如基于<code>Sentinel</code>或者<code>Redis</code>的集群限流）和 <code>单机限流</code> 。从算法实现角度来看，限流算法可分为 <code>漏桶算法</code>、 <code>令牌桶算法</code> 和 <code>滑动时间窗口算法</code> 。</p>
<h3 id="单机限流"><a href="#单机限流" class="headerlink" title="单机限流"></a>单机限流</h3><p><strong>漏桶算法</strong></p>
<p><img src="_v_images/20191130225055766_1808623677" alt="1570701032430.png" title="1570701032430.png"></p>
<ul>
<li>一个固定容量的漏桶，按照常量固定速率流出水滴；</li>
<li>如果桶是空的，则不需流出水滴；</li>
<li>可以以任意速率流入水滴到漏桶；</li>
<li>如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。</li>
</ul>
<p><strong>令牌桶算法</strong></p>
<p><img src="_v_images/20191130225055360_839601664" alt="1570700342271.png" title="1570700342271.png"></p>
<ul>
<li>假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌；</li>
<li>桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝；</li>
<li>当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上；</li>
<li>如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。</li>
</ul>
<p><strong>固定时间窗口算法</strong><br><img src="_v_images/20191130225054755_1892726461" alt="20191024163948.png" title="20191024163948.png"></p>
<p>这种实现计数器限流方式由于是在一个时间间隔内进行限制，如果用户在上个时间间隔结束前请求（但没有超过限制），同时在当前时间间隔刚开始请求（同样没超过限制），在各自的时间间隔内，这些请求都是正常的，但是将间隔临界的一段时间内的请求就会超过系统限制，可能导致系统被压垮。</p>
<p><strong>滑动时间窗口算法</strong></p>
<p><img src="_v_images/20191130225054050_1038055339" alt="1571219763433.png" title="1571219763433.png"></p>
<ul>
<li>0、初始化，设置时间窗口，设置时间窗口时间点间隔长度；</li>
<li>1、判断请求时间点是否在时间窗口中，在进入步骤2，否则进入步骤3；</li>
<li>2、判断是否超过时间窗口限流值，是-&gt;进行限流，否-&gt;对应时间窗口计数器+1；</li>
<li>3、移动当时时间窗口，移动方式是：起始时间点变为时间列表中的第二时间点，结束时间增加一个时间点。重新步骤一的判断 。</li>
</ul>
<h3 id="分布式限流"><a href="#分布式限流" class="headerlink" title="分布式限流"></a>分布式限流</h3><p>当应用为单点应用时，只要应用进行了限流，那么应用所依赖的各种服务也都得到了保护。 但线上业务出于各种原因考虑，多是分布式系统，单节点的限流仅能保护自身节点，但无法保护应用依赖的各种服务，并且在进行节点扩容、缩容时也无法准确控制整个服务的请求限制。</p>
<p><img src="_v_images/20191130225053543_420645799" alt="1571903140149.png" title="1571903140149.png"></p>
<p>如果实现了分布式限流，那么就可以方便地控制整个服务集群的请求限制，且由于整个集群的请求数量得到了限制，因此服务依赖的各种资源也得到了限流的保护。</p>
<p><img src="_v_images/20191130225052943_1592738452" alt="1571904304647.png" title="1571904304647.png"></p>
<p><strong>分布式限流方案</strong></p>
<p>分布式限流的思想我列举下面三个方案：</p>
<p><strong>1，<code>Redis</code>令牌桶</strong></p>
<p>这种方案是最简单的一种集群限流思想。在本地限流中，我们使用Long的原子类作令牌桶，当实例数量超过1，我们就考虑将<code>Redis</code>用作公共内存区域，进行读写。涉及到的并发控制，也可以使用<code>Redis</code>实现分布式锁。</p>
<p><strong>缺点：</strong>每取一次令牌都会进行一次网络开销，而网络开销起码是毫秒级，所以这种方案支持的并发量是非常有限的。</p>
<p><strong>2，<code>QPS</code>统一分配</strong></p>
<p>这种方案的思想是将集群限流最大程度的本地化。</p>
<p>举个例子，我们有两台服务器实例，对应的是同一个应用程序（<code>Application.name</code>相同），程序中设置的<code>QPS</code>为100，将应用程序与同一个控制台程序进行连接，控制台端依据应用的实例数量将<code>QPS</code>进行均分，动态设置每个实例的<code>QPS</code>为50，若是遇到两个服务器的配置并不相同，在负载均衡层的就已经根据服务器的优劣对流量进行分配，例如一台分配70%流量，另一台分配30%的流量。面对这种情况，控制台也可以对其实行加权分配<code>QPS</code>的策略。</p>
<p><strong>缺点：</strong></p>
<p>这也算一种集群限流的实现方案，但依旧存在不小的问题。该模式的分配比例是建立在大数据流量下的趋势进行分配，实际情况中可能并不是严格的五五分或三七分，误差不可控，极容易出现用户连续访问某一台服务器遇到请求驳回而另一台服务器此刻空闲流量充足的尴尬情况。</p>
<p><strong>3，发票服务器</strong></p>
<p>这种方案的思想是建立在<code>Redis</code>令牌桶方案的基础之上的。如何解决每次取令牌都伴随一次网络开销，该方案的解决方法是建立一层控制端，利用该控制端与<code>Redis</code>令牌桶进行交互，只有当客户端的剩余令牌数不足时，客户端才向该控制层取令牌并且每次取一批。</p>
<p><strong>缺点：</strong><br>这种思想类似于Java集合框架的数组扩容，设置一个阈值，只有当超过该临界值时，才会触发异步调用。其余存取令牌的操作与本地限流无二。虽然该方案依旧存在误差，但误差最大也就一批次令牌数而已。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1，<a target="_blank" rel="noopener" href="https://www.cnblogs.com/rjzheng/p/10340176.html">https://www.cnblogs.com/rjzhe…</a><br>2，<a target="_blank" rel="noopener" href="https://www.martinfowler.com/bliki/CircuitBreaker.html">https://www.martinfowler.com/…</a><br>3，<a target="_blank" rel="noopener" href="https://www.cnblogs.com/babycomeon/p/11216538.html">https://www.cnblogs.com/babyc…</a><br>4，<a target="_blank" rel="noopener" href="https://github.com/alibaba/Sentinel/wiki/Sentinel-%E4%B8%8E-Hystrix-%E7%9A%84%E5%AF%B9%E6%AF%94">https://github.com/alibaba/Se…</a><br>5，<a target="_blank" rel="noopener" href="https://www.jishuwen.com/d/2TX1">https://www.jishuwen.com/d/2TX1</a><br>6，<a target="_blank" rel="noopener" href="https://juejin.im/post/5c74a2e2f265da2dea053355">https://juejin.im/post/5c74a2…</a><br>7，<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/2596e559db5c">https://www.jianshu.com/p/259…</a><br>8，<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/48965194">https://zhuanlan.zhihu.com/p/…</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/DataTypesAndSerialization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/DataTypesAndSerialization/" class="post-title-link" itemprop="url">Flink:数据类型与序列化</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:52" itemprop="dateModified" datetime="2021-04-24T12:58:52+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-Data-Types-amp-Serialization"><a href="#Flink-Data-Types-amp-Serialization" class="headerlink" title="Flink Data Types &amp; Serialization"></a>Flink Data Types &amp; Serialization</h1><h2 id="使用case-class的坑"><a href="#使用case-class的坑" class="headerlink" title="使用case class的坑"></a>使用case class的坑</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">id: <span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> lb = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">13:00:43,342 INFO  org.apache.flink.api.java.typeutils.TypeExtractor             - class org.myorg.quickstart.Event does not contain a setter for field id</span><br><span class="line">13:00:43,343 INFO  org.apache.flink.api.java.typeutils.TypeExtractor             - Class class org.myorg.quickstart.Event cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on &quot;Data Types &amp; Serialization&quot; for details of the effect on performance.</span><br></pre></td></tr></table></figure>
<p><strong>提示信息：找不到setter，对于POJO类型必须所有的字段必须要有setter和getter</strong><br>命名是case class啊</p>
<p>再看生产环境的例子： 折腾了一下午</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">uin: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 sPid: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 applyId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 bankType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 transactionId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 amount: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 createTime: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 bizType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 modifyTime: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 equ: <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span></span></span><br><span class="line"><span class="class"><span class="params">                </span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(uin: <span class="type">String</span>,</span><br><span class="line">           sPid: <span class="type">String</span>,</span><br><span class="line">           applyId: <span class="type">String</span>,</span><br><span class="line">           bankType: <span class="type">Long</span>,</span><br><span class="line">           transactionId: <span class="type">String</span>,</span><br><span class="line">           amount: <span class="type">Long</span>,</span><br><span class="line">           createTime: <span class="type">Long</span>,</span><br><span class="line">           bizType: <span class="type">Long</span>,</span><br><span class="line">           modifyTime: <span class="type">String</span>,</span><br><span class="line">           equ: <span class="type">List</span>[<span class="type">Int</span>]</span><br><span class="line">          ) = &#123;</span><br><span class="line">    <span class="keyword">this</span>(uin, sPid, applyId, bankType, transactionId, amount, createTime, bizType, modifyTime)</span><br><span class="line">    <span class="keyword">if</span> (equ != <span class="literal">null</span>) &#123;</span><br><span class="line">      equities.appendAll(equ)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> _active = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">val</span> equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addEquity</span></span>(id: <span class="type">Int</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    equities.append(id)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">equityString</span></span>(separator: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    equities.mkString(separator)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(active: <span class="type">String</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="string">&quot;1&quot;</span>.equals(active)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isActive</span></span>() = &#123;</span><br><span class="line">    _active</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用的是flink 1.6版本的，case class识别出来了，但是equities没有传递到下一个算子中，始终没有值</p>
<p>老老实实的修改成普通类</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">_uin: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _sPid: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _applyId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _bankType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _transactionId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _amount: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _createTime: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _bizType: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">            _modifyTime: <span class="type">String</span></span></span></span><br><span class="line"><span class="class"><span class="params">           </span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> uin: <span class="type">String</span> = _uin</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> sPid: <span class="type">String</span> = _sPid</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> applyId: <span class="type">String</span> = _applyId</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> bankType: <span class="type">Long</span> = _bankType</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> transactionId: <span class="type">String</span> = _transactionId</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> amount: <span class="type">Long</span> = _amount</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> createTime: <span class="type">Long</span> = _createTime</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> bizType: <span class="type">Long</span> = _bizType</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> modifyTime: <span class="type">String</span> = _modifyTime</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> _active = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(uin: <span class="type">String</span>,</span><br><span class="line">           sPid: <span class="type">String</span>,</span><br><span class="line">           applyId: <span class="type">String</span>,</span><br><span class="line">           bankType: <span class="type">Long</span>,</span><br><span class="line">           transactionId: <span class="type">String</span>,</span><br><span class="line">           amount: <span class="type">Long</span>,</span><br><span class="line">           createTime: <span class="type">Long</span>,</span><br><span class="line">           bizType: <span class="type">Long</span>,</span><br><span class="line">           modifyTime: <span class="type">String</span>,</span><br><span class="line">           equ: <span class="type">List</span>[<span class="type">Int</span>]</span><br><span class="line">          ) = &#123;</span><br><span class="line">    <span class="keyword">this</span>(uin, sPid, applyId, bankType, transactionId, amount, createTime, bizType, modifyTime)</span><br><span class="line">    <span class="keyword">if</span> (equ != <span class="literal">null</span>) &#123;</span><br><span class="line">      equities.appendAll(equ)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getUin</span></span>: <span class="type">String</span> = uin</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setUin</span></span>(<span class="type">Uin</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.uin = <span class="type">Uin</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getSPid</span></span>: <span class="type">String</span> = sPid</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setSPid</span></span>(<span class="type">SPid</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.sPid = <span class="type">SPid</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getApplyId</span></span>: <span class="type">String</span> = applyId</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setApplyId</span></span>(<span class="type">ApplyId</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.applyId = <span class="type">ApplyId</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getBankType</span></span>: <span class="type">Long</span> = bankType</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setBankType</span></span>(<span class="type">BankType</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.bankType = <span class="type">BankType</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getTransactionId</span></span>: <span class="type">String</span> = transactionId</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setTransactionId</span></span>(<span class="type">TransactionId</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.transactionId = <span class="type">TransactionId</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getAmount</span></span>: <span class="type">Long</span> = amount</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setAmount</span></span>(<span class="type">Amount</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.amount = <span class="type">Amount</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getCreateTime</span></span>: <span class="type">Long</span> = createTime</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setCreateTime</span></span>(<span class="type">CreateTime</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.createTime = <span class="type">CreateTime</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getBizType</span></span>: <span class="type">Long</span> = bizType</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setBizType</span></span>(<span class="type">BizType</span>: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.bizType = <span class="type">BizType</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getModifyTime</span></span>: <span class="type">String</span> = modifyTime</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setModifyTime</span></span>(<span class="type">ModifyTime</span>: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">this</span>.modifyTime = <span class="type">ModifyTime</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addEquity</span></span>(id: <span class="type">Int</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    equities.append(id)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">equityString</span></span>(separator: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    equities.mkString(separator)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setActive</span></span>(active: <span class="type">String</span>): <span class="type">Event</span> = &#123;</span><br><span class="line">    _active = <span class="string">&quot;1&quot;</span>.equals(active)</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isActive</span></span>() = &#123;</span><br><span class="line">    _active</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rights</span></span>(split: <span class="type">String</span>) = &#123;</span><br><span class="line">    <span class="type">RightEvent</span>(<span class="keyword">this</span>, equities.mkString(split))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getEquities</span> </span>= equities</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setEquities</span></span>(equities: <span class="type">ListBuffer</span>[<span class="type">Int</span>]) = &#123;</span><br><span class="line">    <span class="keyword">this</span>.equities = equities</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以了</p>
<p>初步估计，序列化除了问题</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-TableAPI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-TableAPI/" class="post-title-link" itemprop="url">Flink:Table API</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:51" itemprop="dateModified" datetime="2021-04-24T12:58:51+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="flink-table-api"><a href="#flink-table-api" class="headerlink" title="flink-table-api"></a>flink-table-api</h1><p><a target="_blank" rel="noopener" href="https://github.com/crestofwave1/oneFlink/blob/master/doc/table/Concept%20%26%20Common%20API.md">官方文档翻译</a></p>
<h2 id="Concept-amp-Common-API"><a href="#Concept-amp-Common-API" class="headerlink" title="Concept  &amp; Common API"></a>Concept  &amp; Common API</h2><p>Table API和SQL集成在一个联合的API中。这个API核心概念是Table，<br>Table可以作为查询的输入和输出。这篇文章展示了使用Table API和SQL查询的通用结构，<br>如何去进行表的注册，如何去进行表的查询，并且展示如何去进行表的输出。</p>
<h2 id="1-Structure-of-Table-API-and-SQL-Programs"><a href="#1-Structure-of-Table-API-and-SQL-Programs" class="headerlink" title="1. Structure of Table API and SQL Programs"></a>1. Structure of Table API and SQL Programs</h2><p>​    所有使用批量和流式相关的Table API和SQL的程序都有以下相同模式。下面的代码实例展示了Table API和SQL程序的通用结构。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在批处理程序中使用ExecutionEnvironment代替StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册表</span></span><br><span class="line">tableEnv.registerTable(<span class="string">&quot;table1&quot;</span>, ...)           <span class="comment">// or</span></span><br><span class="line">tableEnv.registerTableSource(<span class="string">&quot;table2&quot;</span>, ...)     <span class="comment">// or</span></span><br><span class="line">tableEnv.registerExternalCatalog(<span class="string">&quot;extCat&quot;</span>, ...) </span><br><span class="line"></span><br><span class="line"><span class="comment">// 基于Table API的查询创建表</span></span><br><span class="line"><span class="keyword">val</span> tapiResult = tableEnv.scan(<span class="string">&quot;table1&quot;</span>).select(...)</span><br><span class="line"><span class="comment">// 从SQL查询创建表</span></span><br><span class="line"><span class="keyword">val</span> sqlResult  = tableEnv.sqlQuery(<span class="string">&quot;SELECT ... FROM table2 ...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表操作API查询到的结果表输出到TableSink，SQL查询到的结果一样如此</span></span><br><span class="line">tapiResult.writeToSink(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行</span></span><br><span class="line">env.execute()</span><br></pre></td></tr></table></figure>
<p>注意：Table API和SQL查询很容易集成并被嵌入到DataStream或者DataSet程序中。查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-datastream-and-dataset-api">将DataStream和DataSet API进行整合</a>章节<br>学习DataSteams和DataSets是如何转换成Table以及Table是如何转换为DataStream或DataSet</p>
<h2 id="2-Create-a-TableEnvironment"><a href="#2-Create-a-TableEnvironment" class="headerlink" title="2. Create a TableEnvironment"></a>2. Create a TableEnvironment</h2><p>TableEnvironment是Table API与SQL整合的核心概念之一，它主要有如下功能：</p>
<ul>
<li>在internal catalog注册表</li>
<li>注册external catalog</li>
<li>执行SQL查询</li>
<li>注册UDF函数（user-defined function)，例如 标量, 表或聚合</li>
<li>将DataStream或者DataSet转换为表</li>
<li>保持ExecutionEnvironment或者StreamExecutionEnvironment的引用指向</li>
</ul>
<p>一个表总是与一个特定的TableEnvironment绑定在一块，<br>相同的查询不同的TableEnvironment是无法通过join、union合并在一起。</p>
<p>创建TableEnvironment的方法通常是通过StreamExecutionEnvironment，ExecutionEnvironment对象调用其中的静态方法TableEnvironment.getTableEnvironment()，或者是TableConfig来创建。<br>TableConfig可以用作配置TableEnvironment或是对自定义查询优化器或者是编译过程进行优化(详情查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#query-optimization">查询优化</a>)</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ***************</span></span><br><span class="line"><span class="comment">// 流式查询</span></span><br><span class="line"><span class="comment">// ***************</span></span><br><span class="line"><span class="keyword">val</span> sEnv = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="comment">// 为流式查询创建一个TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> sTableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(sEnv)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ***********</span></span><br><span class="line"><span class="comment">// 批量查询</span></span><br><span class="line"><span class="comment">// ***********</span></span><br><span class="line"><span class="keyword">val</span> bEnv = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="comment">// 为批量查询创建一个TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> bTableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(bEnv)</span><br></pre></td></tr></table></figure>
<h2 id="Register-Tables-in-the-Catalog"><a href="#Register-Tables-in-the-Catalog" class="headerlink" title="Register Tables in the Catalog"></a>Register Tables in the Catalog</h2><p>TableEnvironment包含了通过名称注册表时的表的catalog信息。通常情况下有两种表，一种为输入表，<br>一种为输出表。输入表主要是在使用Table API和SQL查询时提供输入数据，输出表主要是将Table API和<br>SQL查询的结果作为输出结果对接到外部系统。</p>
<p>输入表有多种不同的输入源进行注册：</p>
<ul>
<li>已经存在的Table对象，通常是是作为Table API和SQL查询的结果</li>
<li>TableSource，可以访问外部数据如文件，数据库或者是消息系统</li>
<li>来自DataStream或是DataSet程序中的DataStream或DataSet，讨论DataStream或是DataSet<br>可以<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-datastream-and-dataset-api">整合DataStream和DataSet API</a>了解到</li>
</ul>
<p>输出表可使用TableSink进行注册</p>
<h2 id="Register-a-Table"><a href="#Register-a-Table" class="headerlink" title="Register a Table"></a>Register a Table</h2><p>Table是如何注册到TableEnvironment中如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从简单的查询结果中作为表</span></span><br><span class="line"><span class="keyword">val</span> projTable: <span class="type">Table</span> = tableEnv.scan(<span class="string">&quot;X&quot;</span>).select(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的表projTable命名为projectedTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTable(<span class="string">&quot;projectedTable&quot;</span>, projTable)</span><br></pre></td></tr></table></figure>
<p>注意：一张注册过的Table就跟关系型数据库中的视图性质相同，定义表的查询未进行优化，但在另一个查询引用已注册的表时将进行内联。<br>如果多表查询引用了相同的Table，它就会将每一个引用进行内联并且多次执行，已注册的Table的结果之间不会进行共享。</p>
<h2 id="Register-a-TableSource"><a href="#Register-a-TableSource" class="headerlink" title="Register a TableSource"></a>Register a TableSource</h2><p>TableSource可以访问外部系统存储例如数据库（Mysql,HBase），特殊格式编码的文件(CSV, Apache [Parquet, Avro, ORC], …)<br>或者是消息系统 (Apache Kafka, RabbitMQ, …)中的数据。</p>
<p>Flink旨在为通用数据格式和存储系统提供TableSource。请查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">此处</a><br>了解支持的TableSource类型与如何去自定义TableSour。</p>
<p>TableSource是如何注册到TableEnvironment中如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableSource对象</span></span><br><span class="line"><span class="keyword">val</span> csvSource: <span class="type">TableSource</span> = <span class="keyword">new</span> <span class="type">CsvTableSource</span>(<span class="string">&quot;/path/to/file&quot;</span>, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的TableSource作为表并命名为csvTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTableSource(<span class="string">&quot;CsvTable&quot;</span>, csvSource)</span><br></pre></td></tr></table></figure>
<h2 id="Register-a-TableSink"><a href="#Register-a-TableSink" class="headerlink" title="Register a TableSink"></a>Register a TableSink</h2><p>注册过的TableSink可以将SQL查询的结果以表的形式输出到外部的存储系统，例如关系型数据库，<br>Key-Value数据库(Nosql)，消息队列，或者是其他文件系统(使用不同的编码, 例如CSV, Apache [Parquet, Avro, ORC], …)</p>
<p>Flink使用TableSink的目的是为了将常用的数据进行清洗转换然后存储到不同的存储介质中。详情请查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">此处</a><br>去深入了解哪些sinks是可用的，并且如何去自定义TableSink。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建TableSink对象</span></span><br><span class="line"><span class="keyword">val</span> csvSink: <span class="type">TableSink</span> = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">&quot;/path/to/file&quot;</span>, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义字段的名称和类型</span></span><br><span class="line"><span class="keyword">val</span> fieldNames: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> fieldTypes: <span class="type">Array</span>[<span class="type">TypeInformation</span>[_]] = <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">INT</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将创建的TableSink作为表并命名为CsvSinkTable注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerTableSink(<span class="string">&quot;CsvSinkTable&quot;</span>, fieldNames, fieldTypes, csvSink)</span><br></pre></td></tr></table></figure>
<h2 id="Register-an-External-Catalog"><a href="#Register-an-External-Catalog" class="headerlink" title="Register an External Catalog"></a>Register an External Catalog</h2><p>外部目录可以提供有关外部数据库和表的信息，<br>例如其名称，模式，统计以及有关如何访问存储在外部数据库，表或文件中的数据的信息。</p>
<p>外部目录的创建方式可以通过实现ExternalCatalog接口，并且注册到TableEnvironment中，详情如下所示:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个External Catalog目录对象</span></span><br><span class="line"><span class="keyword">val</span> catalog: <span class="type">ExternalCatalog</span> = <span class="keyword">new</span> <span class="type">InMemoryExternalCatalog</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将ExternalCatalog注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerExternalCatalog(<span class="string">&quot;InMemCatalog&quot;</span>, catalog)</span><br></pre></td></tr></table></figure>
<p>一旦将External Catalog注册到TableEnvironment中，所有在ExternalCatalog中<br>定义的表可以通过完整的路径如catalog.database.table进行Table API和SQL的查询操作 </p>
<p>目前，Flink提供InMemoryExternalCatalog对象用来做demo和测试，然而，<br>ExternalCatalog对象还可用作Table API来连接catalogs，例如HCatalog 或 Metastore</p>
<h2 id="Query-a-Table"><a href="#Query-a-Table" class="headerlink" title="Query a Table"></a>Query a Table</h2><h3 id="Table-API"><a href="#Table-API" class="headerlink" title="Table API"></a>Table API</h3><p>Table API是Scala和Java语言集成查询的API，与SQL查询不同之处在于，它的查询不是像<br>SQL一样使用字符串进行查询，而是在语言中使用语法进行逐步组合使用</p>
<p>Table API是基于展示表（流或批处理）的Table类，它提供一些列操作应用相关的操作。<br>这些方法返回一个新的Table对象，该对象表示在输入表上关系运算的结果。一些关系运算是<br>由多个方法组合而成的，例如 table.groupBy(…).select()，其中groupBy()指定<br>表的分组，select()表示在分组的结果上进行查询。</p>
<p><a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/tableApi.html">Table API</a><br>描述了所有支持表的流式或者批处理相关的操作。</p>
<p>下面给出一个简单的实例去说明如何去使用Table API进行聚合查询：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册Orders表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 扫描注册过的Orders表</span></span><br><span class="line"><span class="keyword">val</span> orders = tableEnv.scan(<span class="string">&quot;Orders&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入</span></span><br><span class="line"><span class="keyword">val</span> revenue = orders</span><br><span class="line">  .filter(<span class="symbol">&#x27;cCountry</span> === <span class="string">&quot;FRANCE&quot;</span>)</span><br><span class="line">  .groupBy(<span class="symbol">&#x27;cID</span>, <span class="symbol">&#x27;cName</span>)</span><br><span class="line">  .select(<span class="symbol">&#x27;cID</span>, <span class="symbol">&#x27;cName</span>, <span class="symbol">&#x27;revenue</span>.sum <span class="type">AS</span> <span class="symbol">&#x27;revSum</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出成一张表或者是转换表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<p>注意：Scala的Table API使用Scala符号，它使用单引号加字段(‘cID)来表示表的属性的引用，<br>如果使用Scala的隐式转换的话，确保引入了org.apache.flink.api.scala._ 和 org.apache.flink.table.api.scala._<br>来确保它们之间的转换。</p>
<h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><p>Flink的SQL操作基于实现了SQL标准的<a target="_blank" rel="noopener" href="https://calcite.apache.org/">Apache Calcite</a>，SQL查询通常是使用特殊且有规律的字符串。<br><a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sql.html">SQL</a><br>描述了所有支持表的流式或者批处理相关的SQL操作。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册Orders表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入</span></span><br><span class="line"><span class="keyword">val</span> revenue = tableEnv.sqlQuery(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  |SELECT cID, cName, SUM(revenue) AS revSum</span></span><br><span class="line"><span class="string">  |FROM Orders</span></span><br><span class="line"><span class="string">  |WHERE cCountry = &#x27;FRANCE&#x27;</span></span><br><span class="line"><span class="string">  |GROUP BY cID, cName</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出成一张表或者是转换表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<p>下面的例子展示了如何去使用更新查询去插入数据到已注册的表中</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册&quot;Orders&quot;表</span></span><br><span class="line"><span class="comment">// 注册&quot;RevenueFrance&quot;输出表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算表中所有来自法国的客户的收入并且将结果作为结果输出到&quot;RevenueFrance&quot;中</span></span><br><span class="line">tableEnv.sqlUpdate(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  |INSERT INTO RevenueFrance</span></span><br><span class="line"><span class="string">  |SELECT cID, cName, SUM(revenue) AS revSum</span></span><br><span class="line"><span class="string">  |FROM Orders</span></span><br><span class="line"><span class="string">  |WHERE cCountry = &#x27;FRANCE&#x27;</span></span><br><span class="line"><span class="string">  |GROUP BY cID, cName</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行查询</span></span><br></pre></td></tr></table></figure>
<h2 id="Mixing-Table-API-and-SQL"><a href="#Mixing-Table-API-and-SQL" class="headerlink" title="Mixing Table API and SQL"></a>Mixing Table API and SQL</h2><p>Table API和SQL可以很轻松的混合使用因为他们两者返回的结果都为Table对象：</p>
<ul>
<li>可以在SQL查询返回的Table对象上定义Table API查询</li>
<li>通过在TableEnvironment中注册结果表并在SQL查询的FROM子句中引用它，<br>可以在Table API查询的结果上定义SQL查询。</li>
</ul>
<h2 id="Emit-a-Table"><a href="#Emit-a-Table" class="headerlink" title="Emit a Table"></a>Emit a Table</h2><p>通过将Table写入到TableSink来作为一张表的输出，TableSink是做为多种文件类型 (CSV, Apache Parquet, Apache Avro),<br>存储系统(JDBC, Apache HBase, Apache Cassandra, Elasticsearch), 或者是消息系统 (Apache Kafka, RabbitMQ).输出的通用接口，</p>
<p>Batch Table只能通过BatchTableSink来进行数据写入，而Streaming Table可以<br>选择AppendStreamTableSink，RetractStreamTableSink，UpsertStreamTableSink<br>中的任意一个来进行。</p>
<p>请查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/sourceSinks.html">Table Source &amp; Sinks</a><br>来更详细的了解支持的Sinks并且如何去实现自定义的TableSink。</p>
<p>可以使用两种方式来输出一张表：</p>
<ul>
<li>Table.writeToSink(TableSink sink)方法使用提供的TableSink自动配置的表的schema来<br>进行表的输出</li>
<li>Table.insertInto（String sinkTable）方法查找在TableEnvironment目录中提供的名称下使用特定模式注册的TableSink。<br>将输出表的模式将根据已注册的TableSink的模式进行验证</li>
</ul>
<p>下面的例子展示了如何去查询结果作为一张表输出</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用Table API或者SQL 查询来查找结果</span></span><br><span class="line"><span class="keyword">val</span> result: <span class="type">Table</span> = ...</span><br><span class="line"><span class="comment">// 创建TableSink对象</span></span><br><span class="line"><span class="keyword">val</span> sink: <span class="type">TableSink</span> = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">&quot;/path/to/file&quot;</span>, fieldDelim = <span class="string">&quot;|&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法1: 使用TableSink的writeToSink()方法来将结果输出为一张表</span></span><br><span class="line">result.writeToSink(sink)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法2: 注册特殊schema的TableSink</span></span><br><span class="line"><span class="keyword">val</span> fieldNames: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> fieldTypes: <span class="type">Array</span>[<span class="type">TypeInformation</span>] = <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">INT</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>)</span><br><span class="line">tableEnv.registerTableSink(<span class="string">&quot;CsvSinkTable&quot;</span>, fieldNames, fieldTypes, sink)</span><br><span class="line"><span class="comment">// 调用注册过的TableSink中insertInto() 方法来将结果输出为一张表</span></span><br><span class="line">result.insertInto(<span class="string">&quot;CsvSinkTable&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行</span></span><br></pre></td></tr></table></figure>
<h2 id="Translate-and-Execute-a-Query"><a href="#Translate-and-Execute-a-Query" class="headerlink" title="Translate and Execute a Query"></a>Translate and Execute a Query</h2><p>Table API和SQL查询的结果转换为<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/datastream_api.html">DataStream</a><br>或是<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/">DataSet</a><br>取决于它的输入是流式输入还是批处理输入。查询逻辑在内部表示为逻辑执行计划，并分为两个阶段进行转换：</p>
<ul>
<li>优化逻辑执行计划</li>
<li>转换为DataStream或DataSet</li>
</ul>
<p>Table API或SQL查询在下面请看下进行转换：</p>
<ul>
<li>当调用Table.writeToSink() 或 Table.insertInto()进行查询结果表输出的时候</li>
<li>当调用TableEnvironment.sqlUpdate()进行SQL更新查询时</li>
<li>当表转换为DataSteam或DataSet时，详情查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#integration-with-dataStream-and-dataSet-api">Integration with DataStream and DataSet API</a></li>
</ul>
<p>一旦进行转换后，Table API或SQL查询的结果就会在StreamExecutionEnvironment.execute() 或 ExecutionEnvironment.execute()<br>被调用时被当做DataStream或DataSet一样被进行处理</p>
<h2 id="Integration-with-DataStream-and-DataSet-API"><a href="#Integration-with-DataStream-and-DataSet-API" class="headerlink" title="Integration with DataStream and DataSet API"></a>Integration with DataStream and DataSet API</h2><p>Table API或SQL查询的结果很容易被<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/datastream_api.html">DataStream</a><br>或是<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/batch/">DataSet</a>内嵌整合。举个例子，<br>我们会进行外部表的查询(像关系型数据库)，然后做像过滤，映射，聚合或者是元数据关联的一些预处理。<br>然后使用DataStream或是DataSet API(或者是基于这些基础库开发的上层API库, 例如CEP或Gelly)进一步对数据进行处理。<br>同样，Table API或SQL查询也可以应用于DataStream或DataSet程序的结果。</p>
<p>##implicit Conversion for Scala<br>Scala Table API具有DataSet，DataStream和Table Class之间的隐式转换，流式操作API中只要引入org.apache.flink.table.api.scala._<br>和 org.apache.flink.api.scala._ 便可以进行相应的隐式转换</p>
<h2 id="Register-a-DataStream-or-DataSet-as-Table"><a href="#Register-a-DataStream-or-DataSet-as-Table" class="headerlink" title="Register a DataStream or DataSet as Table"></a>Register a DataStream or DataSet as Table</h2><p>DataStream或DataSet也可以作为Table注册到TableEnvironment中。结果表的模式取决于已注册的DataStream或DataSet的数据类型，<br>详情请查看<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/common.html#mapping-of-data-types-to-table-schema">mapping of data types to table schema</a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream作为具有&quot;f0&quot;, &quot;f1&quot;字段的&quot;myTable&quot;表注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerDataStream(<span class="string">&quot;myTable&quot;</span>, stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream作为具有&quot;myLong&quot;, &quot;myString&quot;字段的&quot;myTable2&quot;表注册到TableEnvironment中</span></span><br><span class="line">tableEnv.registerDataStream(<span class="string">&quot;myTable2&quot;</span>, stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br></pre></td></tr></table></figure>
<p>注意：DataStream表的名称必须与^ <em>DataStreamTable</em> [0-9] +模式不匹配，<br>并且DataSet表的名称必须与^ <em>DataSetTable</em> [0-9] +模式不匹配。<br>这些模式仅供内部使用。</p>
<h2 id="Convert-a-DataStream-or-DataSet-into-a-Table"><a href="#Convert-a-DataStream-or-DataSet-into-a-Table" class="headerlink" title="Convert a DataStream or DataSet into a Table"></a>Convert a DataStream or DataSet into a Table</h2><p>如果你使用Table API或是SQL查询，你可以直接将DataStream或DataSet直接转换为表而不需要<br>再将它们注册到TableEnvironment中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1, &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table1: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;myLong, &#x27;myString将DataStram转换为Table</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> table2: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Convert-a-Table-into-a-DataStream-or-DataSet"><a href="#Convert-a-Table-into-a-DataStream-or-DataSet" class="headerlink" title="Convert a Table into a DataStream or DataSet"></a>Convert a Table into a DataStream or DataSet</h2><p>表可以转换为DataStream或DataSet，通过这种方式，自定义DataStream或DataSet<br>同样也可以作为Table API或SQL查询结果的结果。<br>当把表转换为DataStream或DataSet时，你需要指定生成的DataStream或DataSet的数据类型。<br>例如，表格行所需转换的数据类型，通常最方便的转换类型也最常用的是Row。<br>以下列表概述了不同选项的功能：</p>
<ul>
<li>Row：字段按位置，任意数量的字段映射，支持空值，无类型安全访问。</li>
<li>POJO：字段按名称(POJO字段必须与Table字段保持一致)，任意数量的字段映射，支持空值，类型安全访问。</li>
<li>Case Class：字段按位置，任意数量的字段映射，不支持空值，类型安全访问。</li>
<li>Tuple：字段按位置，Scala支持22个字段，Java 25个字段映射，不支持空值，类型安全访问。</li>
<li>Atomic Type：表必须具有单个字段，不支持空值，类型安全访问。<h3 id="Convert-a-Table-into-a-DataStream"><a href="#Convert-a-Table-into-a-DataStream" class="headerlink" title="Convert a Table into a DataStream"></a>Convert a Table into a DataStream</h3>作为流式查询结果的表将动态更新，它随着新记录到达查询的输入流而改变，于是，转换到这样的动态查询DataStream<br>需要对表的更新进行编码。<br>将表转换为DataStream有两种模式：</li>
<li>Append Mode：这种模式仅用于动态表仅仅通过INSERT来进行表的更新，它是仅可追加模式，<br>并且之前输出的表不会进行更改</li>
<li>Retract Mode：这种模式经常用到。它使用布尔值的变量来对INSERT和DELETE对表的更新做标记<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表中有两个字段(String name, Integet age)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为列的 append DataStream</span></span><br><span class="line"><span class="keyword">val</span> dsRow: <span class="type">DataStream</span>[<span class="type">Row</span>] = tableEnv.toAppendStream[<span class="type">Row</span>](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为Tubple2[String,Int]的 append DataStream</span></span><br><span class="line"><span class="comment">// convert the Table into an append DataStream of Tuple2[String, Int]</span></span><br><span class="line"><span class="keyword">val</span> dsTuple: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] dsTuple = </span><br><span class="line">  tableEnv.toAppendStream[(<span class="type">String</span>, <span class="type">Int</span>)](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// convert the Table into a retract DataStream of Row.</span></span><br><span class="line"><span class="comment">// Retract Mode下将表转换为列的 append DataStream</span></span><br><span class="line"><span class="comment">// 判断A retract stream X是否为DataStream[(Boolean, X)]</span></span><br><span class="line"><span class="comment">//  布尔只表示数据类型的变化,True代表为INSERT，false表示为删除</span></span><br><span class="line"><span class="keyword">val</span> retractStream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, <span class="type">Row</span>)] = tableEnv.toRetractStream[<span class="type">Row</span>](table)</span><br></pre></td></tr></table></figure>
注意：关于动态表和它的属性详情参考<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/table/streaming.html">Streaming Queries</a></li>
</ul>
<h3 id="Convert-a-Table-into-a-DataSet"><a href="#Convert-a-Table-into-a-DataSet" class="headerlink" title="Convert a Table into a DataSet"></a>Convert a Table into a DataSet</h3><p>表转换为DataSet如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="comment">// 注册如表一样的DataSet</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表中有两个字段(String name, Integet age)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为列的DataSet</span></span><br><span class="line"><span class="keyword">val</span> dsRow: <span class="type">DataSet</span>[<span class="type">Row</span>] = tableEnv.toDataSet[<span class="type">Row</span>](table)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将表转换为Tubple2[String,Int]的DataSet</span></span><br><span class="line"><span class="keyword">val</span> dsTuple: <span class="type">DataSet</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = tableEnv.toDataSet[(<span class="type">String</span>, <span class="type">Int</span>)](table)</span><br></pre></td></tr></table></figure>
<h3 id="Mapping-of-Data-Types-to-Table-Schema"><a href="#Mapping-of-Data-Types-to-Table-Schema" class="headerlink" title="Mapping of Data Types to Table Schema"></a>Mapping of Data Types to Table Schema</h3><p>Flink的DataStream和DataSet API支持多种类型。组合类型像Tuple(内置Scala元组和Flink Java元组)，<br>POJOs，Scala case classes和Flink中具有可在表表达式中访问的多个字段允许嵌套数据结构的Row类型，<br>其他类型都被视为原子类型。接下来，我们将会描述Table API是如何将这些类型转换为内部的列展现并且<br>举例说明如何将DataStream转换为Table</p>
<h4 id="Position-based-Mapping"><a href="#Position-based-Mapping" class="headerlink" title="Position-based Mapping"></a>Position-based Mapping</h4><p>基于位置的映射通常在保持顺序的情况下给字段一个更有意义的名称，这种映射可用于有固定顺序的组合数据类型，<br>也可用于原子类型。复合数据类型（如元组，行和Case Class）具有此类字段顺序.然而，POJO的字段必须与映射的<br>表的字段名相同。</p>
<p>当定义基于位置的映射，输入的数据类型不得存在指定的名称，不然API会认为这些映射应该按名称来进行映射。<br>如果未指定字段名称，则使用复合类型的默认字段名称和字段顺序，或者使用f0作为原子类型。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1, &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table1: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;myLong, &#x27;myInt将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span> <span class="symbol">&#x27;myInt</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Name-based-Mapping"><a href="#Name-based-Mapping" class="headerlink" title="Name-based Mapping"></a>Name-based Mapping</h4><p>基于名称的映射可用于一切数据类型包括POJOs，它是定义表模式映射最灵活的一种方式。虽然查询结果的字段可能会使用别名，但<br>这种模式下所有的字段都是使用名称进行映射的。使用别名的情况下会进行重排序。<br>如果未指定字段名称，则使用复合类型的默认字段名称和字段顺序，或者使用f0作为原子类型。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认的字段&#x27;_1 和 &#x27;_2将DataStram转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只使用&#x27;_2字段将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换字段将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>, <span class="symbol">&#x27;_1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换后的字段给予别名&#x27;myInt, &#x27;myLong将DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span> as <span class="symbol">&#x27;myInt</span>, <span class="symbol">&#x27;_1</span> as <span class="symbol">&#x27;myLong</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Atomic-Types"><a href="#Atomic-Types" class="headerlink" title="Atomic Types"></a>Atomic Types</h4><p>Flink将基础类型(Integer, Double, String)和通用类型(不能被分析和拆分的类型)视为原子类型。<br>原子类型的DataStream或DataSet转换为只有单个属性的表。从原子类型推断属性的类型，并且可以指定属性的名称。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Long</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为带默认字段&quot;f0&quot;的表</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为带字段&quot;myLong&quot;的表</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Tuples-Scala-and-Java-and-Case-Classes-Scala-only"><a href="#Tuples-Scala-and-Java-and-Case-Classes-Scala-only" class="headerlink" title="Tuples (Scala and Java) and Case Classes (Scala only)"></a>Tuples (Scala and Java) and Case Classes (Scala only)</h4><p>Flink支持内建的Tuples并且提供了自己的Tuple类给Java进行使用。DataStreams和DataSet这两种<br>Tuple都可以转换为表。提供所有字段的名称(基于位置的映射)字段可以被重命名。如果没有指定字段的名称，<br>就使用默认的字段名称。如果原始字段名(f0, f1, … for Flink Tuples and _1, _2, … for Scala Tuples)被引用了的话，<br>API就会使用基于名称的映射来代替位置的映射。基于名称的映射可以起别名并且会进行重排序。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象 </span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将默认的字段重命名为&#x27;_1，&#x27;_2的DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字段名为&#x27;myLong，&#x27;myString的DataStream转换为Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myLong</span>, <span class="symbol">&#x27;myString</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将重排序后字段为&#x27;_2，&#x27;_1 的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>, <span class="symbol">&#x27;_1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将映射字段&#x27;_2的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将重排序后字段为&#x27;_2给出别名&#x27;myString，&#x27;_1给出别名&#x27;myLong 的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;_2</span> as <span class="symbol">&#x27;myString</span>, <span class="symbol">&#x27;_1</span> as <span class="symbol">&#x27;myLong</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义 case class</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">streamCC</span></span>: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将默认字段&#x27;name, &#x27;age的DataStream转换为Table</span></span><br><span class="line"><span class="keyword">val</span> table = tableEnv.fromDataStream(streamCC)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字段名为&#x27;myName，&#x27;myAge的DataStream转换为Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table = tableEnv.fromDataStream(streamCC, <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line">将重排序后字段为<span class="symbol">&#x27;_age</span>给出别名<span class="symbol">&#x27;myAge</span>，<span class="symbol">&#x27;_name</span>给出别名<span class="symbol">&#x27;myName</span> 的<span class="type">DataStream</span>转换为<span class="type">Table</span>(基于名称)</span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="POJO-Java-and-Scala"><a href="#POJO-Java-and-Scala" class="headerlink" title="POJO (Java and Scala)"></a>POJO (Java and Scala)</h4><p>Flink支持POJO作为符合类型。决定POJO规则的文档请参考<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/dev/api_concepts.html#pojos">这里</a></p>
<p>当将一个POJO类型的DataStream或者DataSet转换为Table而不指定字段名称时，Table的字段名称将采用JOPO原生的字段名称作为字段名称。<br>重命名原始的POJO字段需要关键字AS，因为POJO没有固定的顺序，名称映射需要原始名称并且不能通过位置来完成。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Person 是一个有两个字段&quot;name&quot;和&quot;age&quot;的POJO</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为带字段 &quot;age&quot;, &quot;name&quot; 的Table(字段通过名称进行排序)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将DataStream转换为重命名为&quot;myAge&quot;, &quot;myName&quot;的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将带映射字段&#x27;name的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将带映射字段&#x27;name并重命名为&#x27;myName的DataStream转换为Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Row"><a href="#Row" class="headerlink" title="Row"></a>Row</h4><p>Row数据类型可以支持任意数量的字段，并且这些字段支持null值。当进行Row DataStream或Row DataSet<br>转换为Table时可以通过RowTypeInfo来指定字段的名称。Row Type支持基于位置和名称的两种映射方式。<br>通过提供所有字段的名称可以进行字段的重命名(基于位置)，或者是单独选择列来进行映射/重排序/重命名(基于名称)</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取(创建)TableEnvironment对象</span></span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在`RowTypeInfo`中指定字段&quot;name&quot; 和 &quot;age&quot;的Row类型DataStream</span></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Row</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为带默认字段 &quot;age&quot;, &quot;name&quot; 的Table</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为重命名字段 &#x27;myName, &#x27;myAge 的Table(基于位置)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为重命名字段 &#x27;myName, &#x27;myAge 的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>, <span class="symbol">&#x27;age</span> as <span class="symbol">&#x27;myAge</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为映射字段 &#x27;name的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream 转换为映射字段 &#x27;name并重命名为&#x27;myName的Table(基于名称)</span></span><br><span class="line"><span class="keyword">val</span> table: <span class="type">Table</span> = tableEnv.fromDataStream(stream, <span class="symbol">&#x27;name</span> as <span class="symbol">&#x27;myName</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Query-Optimization"><a href="#Query-Optimization" class="headerlink" title="Query Optimization"></a>Query Optimization</h4><p>Apache Flink 基于 Apache Calcite 来做转换和查询优化。当前的查询优化包括投影、过滤下推、<br>相关子查询和各种相关的查询重写。Flink不去做join优化，但是会让他们去顺序执行(FROM子句中表的顺序或者WHERE子句中连接谓词的顺序)</p>
<p>可以通过提供一个CalciteConfig对象来调整在不同阶段应用的优化规则集，<br>这个可以通过调用CalciteConfig.createBuilder())获得的builder来创建，<br>并且可以通过调用tableEnv.getConfig.setCalciteConfig(calciteConfig)来提供给TableEnvironment。</p>
<h4 id="Explaining-a-Table"><a href="#Explaining-a-Table" class="headerlink" title="Explaining a Table"></a>Explaining a Table</h4><p>Table API为计算Table提供了一个机制来解析逻辑和优化查询计划，这个可以通过TableEnvironment.explain(table)<br>来完成。它返回描述三个计划的字符串信息：</p>
<ul>
<li>关联查询抽象语法树，即未优化过的逻辑执行计划</li>
<li>优化过的逻辑执行计划</li>
<li>物理执行计划</li>
</ul>
<p>下面的实例展示了相应的输出：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> tEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> table1 = env.fromElements((<span class="number">1</span>, <span class="string">&quot;hello&quot;</span>)).toTable(tEnv, <span class="symbol">&#x27;count</span>, <span class="symbol">&#x27;word</span>)</span><br><span class="line"><span class="keyword">val</span> table2 = env.fromElements((<span class="number">1</span>, <span class="string">&quot;hello&quot;</span>)).toTable(tEnv, <span class="symbol">&#x27;count</span>, <span class="symbol">&#x27;word</span>)</span><br><span class="line"><span class="keyword">val</span> table = table1</span><br><span class="line">  .where(<span class="symbol">&#x27;word</span>.like(<span class="string">&quot;F%&quot;</span>))</span><br><span class="line">  .unionAll(table2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> explanation: <span class="type">String</span> = tEnv.explain(table)</span><br><span class="line">println(explanation)</span><br></pre></td></tr></table></figure>
<p>对应的输出如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#x3D;&#x3D; 抽象语法树 &#x3D;&#x3D;</span><br><span class="line">LogicalUnion(all&#x3D;[true])</span><br><span class="line">  LogicalFilter(condition&#x3D;[LIKE($1, &#39;F%&#39;)])</span><br><span class="line">    LogicalTableScan(table&#x3D;[[_DataStreamTable_0]])</span><br><span class="line">  LogicalTableScan(table&#x3D;[[_DataStreamTable_1]])</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D; 优化后的逻辑执行计划 &#x3D;&#x3D;</span><br><span class="line">DataStreamUnion(union&#x3D;[count, word])</span><br><span class="line">  DataStreamCalc(select&#x3D;[count, word], where&#x3D;[LIKE(word, &#39;F%&#39;)])</span><br><span class="line">    DataStreamScan(table&#x3D;[[_DataStreamTable_0]])</span><br><span class="line">  DataStreamScan(table&#x3D;[[_DataStreamTable_1]])</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D; 物理执行计划 &#x3D;&#x3D;</span><br><span class="line">Stage 1 : Data Source</span><br><span class="line">  content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">Stage 2 : Data Source</span><br><span class="line">  content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">  Stage 3 : Operator</span><br><span class="line">    content : from: (count, word)</span><br><span class="line">    ship_strategy : REBALANCE</span><br><span class="line"></span><br><span class="line">    Stage 4 : Operator</span><br><span class="line">      content : where: (LIKE(word, &#39;F%&#39;)), select: (count, word)</span><br><span class="line">      ship_strategy : FORWARD</span><br><span class="line"></span><br><span class="line">      Stage 5 : Operator</span><br><span class="line">        content : from: (count, word)</span><br><span class="line">        ship_strategy : REBALANCE</span><br></pre></td></tr></table></figure>

<h1 id="Flink用户自定义函数"><a href="#Flink用户自定义函数" class="headerlink" title="Flink用户自定义函数"></a>Flink用户自定义函数</h1><p>用户自定义函数是非常重要的一个特征，因为他极大地扩展了查询的表达能力。</p>
<p>在大多数场景下，用户自定义函数在使用之前是必须要注册的。对于Scala的Table API，udf是不需要注册的。<br>调用TableEnvironment的registerFunction()方法来实现注册。Udf注册成功之后，会被插入TableEnvironment的function catalog，这样table API和sql就能解析他了。<br>本文会主要讲三种udf：</p>
<ul>
<li>ScalarFunction</li>
<li>TableFunction</li>
<li>AggregateFunction</li>
</ul>
<h2 id="1-Scalar-Functions-标量函数"><a href="#1-Scalar-Functions-标量函数" class="headerlink" title="1. Scalar Functions 标量函数"></a>1. Scalar Functions 标量函数</h2><p>标量函数，是指指返回一个值的函数。标量函数是实现讲0，1，或者多个标量值转化为一个新值。</p>
<p>实现一个标量函数需要继承ScalarFunction，并且实现一个或者多个evaluation方法。标量函数的行为就是通过evaluation方法来实现的。evaluation方法必须定义为public，命名为eval。evaluation方法的输入参数类型和返回值类型决定着标量函数的输入参数类型和返回值类型。evaluation方法也可以被重载实现多个eval。同时evaluation方法支持变参数，例如：eval(String… strs)。</p>
<p>下面给出一个标量函数的例子。例子实现的事一个hashcode方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">12</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">HashCode</span><span class="params">(<span class="keyword">int</span> factor)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.factor = factor;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the function</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> HashCode(<span class="number">10</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in Java Table API</span></span><br><span class="line">myTable.select(<span class="string">&quot;string, string.hashCode(), hashCode(string)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in SQL API</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;</span>);</span><br><span class="line"></span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">默认情况下evaluation方法的返回值类型是由flink类型抽取工具决定。对于基础类型，简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载</span><br><span class="line">ScalarFunction#getResultType()。</span><br><span class="line"></span><br><span class="line">下面给一个例子，通过复写ScalarFunction#getResultType()，将long型的返回值在代码生成的时候翻译成Types.TIMESTAMP。</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TimestampModifier</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">eval</span><span class="params">(<span class="keyword">long</span> t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> t % <span class="number">1000</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> TypeInformation&lt;?&gt; getResultType(signature: Class&lt;?&gt;[]) &#123;</span><br><span class="line">    <span class="keyword">return</span> Types.TIMESTAMP;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-Table-Functions-表函数"><a href="#2-Table-Functions-表函数" class="headerlink" title="2. Table Functions 表函数"></a>2. Table Functions 表函数</h2><p>与标量函数相似之处是输入可以0，1，或者多个参数，但是不同之处可以输出任意数目的行数。返回的行也可以包含一个或者多个列。</p>
<p>为了自定义表函数，需要继承TableFunction，实现一个或者多个evaluation方法。表函数的行为定义在这些evaluation方法内部，函数名为eval并且必须是public。TableFunction可以重载多个eval方法。Evaluation方法的输入参数类型，决定着表函数的输入类型。Evaluation方法也支持变参，例如：eval(String… strs)。返回表的类型取决于TableFunction的基本类型。Evaluation方法使用collect(T)发射输出的rows。</p>
<p>在Table API中，表函数在scala语言中使用方法如下：.join(Expression) 或者 .leftOuterJoin(Expression)，在java语言中使用方法如下：.join(String) 或者.leftOuterJoin(String)。</p>
<p>Join操作算子会使用表值函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行。</p>
<p>leftOuterJoin操作算子会使用表值函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行，并且在表函数返回一个空表的情况下会保留所有的outer rows。</p>
<p>在sql语法中稍微有点区别：<br>cross join用法是LATERAL TABLE(<TableFunction>)。<br>LEFT JOIN用法是在join条件中加入ON TRUE。</p>
<p>下面的理智讲的是如何使用表值函数。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The generic type &quot;Tuple2&lt;String, Integer&gt;&quot; determines the schema of the returned table as (String, Integer).</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Split</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String separator = <span class="string">&quot; &quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Split</span><span class="params">(String separator)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.separator = separator;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String s : str.split(separator)) &#123;</span><br><span class="line">            <span class="comment">// use collect(...) to emit a row</span></span><br><span class="line">            collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(s, s.length()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line">Table myTable = ...         <span class="comment">// table schema: [a: String]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Register the function.</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;split&quot;</span>, <span class="keyword">new</span> Split(<span class="string">&quot;#&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use the table function in the Java Table API. &quot;as&quot; specifies the field names of the table.</span></span><br><span class="line">myTable.join(<span class="string">&quot;split(a) as (word, length)&quot;</span>).select(<span class="string">&quot;a, word, length&quot;</span>);</span><br><span class="line">myTable.leftOuterJoin(<span class="string">&quot;split(a) as (word, length)&quot;</span>).select(<span class="string">&quot;a, word, length&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use the table function in SQL with LATERAL and TABLE keywords.</span></span><br><span class="line">join.md</span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT a, word, length FROM MyTable, LATERAL TABLE(split(a)) as T(word, length)&quot;</span>);</span><br><span class="line"><span class="comment">// LEFT JOIN a table function (equivalent to &quot;leftOuterJoin&quot; in Table API).</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT a, word, length FROM MyTable LEFT JOIN LATERAL TABLE(split(a)) as T(word, length) ON TRUE&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>需要注意的是PROJO类型不需要一个确定的字段顺序。意味着你不能使用as修改表函数返回的pojo的字段的名字。</p>
<p>默认情况下TableFunction返回值类型是由flink类型抽取工具决定。对于基础类型，简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载<br>TableFunction#getResultType()。</p>
<p>下面的例子，我们通过复写TableFunction#getResultType()方法使得表返回类型是RowTypeInfo(String, Integer)。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomTypeSplit</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Row</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String s : str.split(<span class="string">&quot; &quot;</span>)) &#123;</span><br><span class="line">            Row row = <span class="keyword">new</span> Row(<span class="number">2</span>);</span><br><span class="line">            row.setField(<span class="number">0</span>, s);</span><br><span class="line">            row.setField(<span class="number">1</span>, s.length);</span><br><span class="line">            collect(row);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TypeInformation&lt;Row&gt; <span class="title">getResultType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Types.ROW(Types.STRING(), Types.INT());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-Aggregation-Functions-聚合函数"><a href="#3-Aggregation-Functions-聚合函数" class="headerlink" title="3. Aggregation Functions 聚合函数"></a>3. Aggregation Functions 聚合函数</h2><p>用户自定义聚合函数聚合一张表(一行或者多行，一行有一个或者多个属性)为一个标量的值。</p>
<p>上图中是讲的一张饮料的表这个表有是那个字段五行数据，现在要做的事求出所有饮料的最高价。</p>
<p>聚合函数需要继承AggregateFunction。聚合函数工作方式如下：<br>首先，需要一个accumulator，这个是保存聚合中间结果的数据结构。调用AggregateFunction函数的createAccumulator()方法来创建一个空的accumulator.<br>随后，每个输入行都会调用accumulate()方法来更新accumulator。一旦所有的行被处理了，getValue()方法就会被调用，计算和返回最终的结果。</p>
<p>对于每个AggregateFunction，下面三个方法都是比不可少的：<br>createAccumulator()<br>accumulate()<br>getValue()</p>
<p>flink的类型抽取机制不能识别复杂的数据类型，比如，数据类型不是基础类型或者简单的pojos类型。所以，类似于ScalarFunction 和TableFunction，AggregateFunction提供了方法去指定返回结果类型的TypeInformation，用的是AggregateFunction#getResultType()。Accumulator类型用的是AggregateFunction#getAccumulatorType()。</p>
<p>除了上面的方法，这里有一些可选的方法。尽管有些方法是让系统更加高效的执行查询，另外的一些在特定的场景下是必须的。例如，merge()方法在会话组窗口上下文中是必须的。当一行数据是被视为跟两个回话窗口相关的时候，两个会话窗口的accumulators需要被join。</p>
<p>AggregateFunction的下面几个方法，根据使用场景的不同需要被实现：<br>retract()：在bounded OVER窗口的聚合方法中是需要实现的。<br>merge()：在很多batch 聚合和会话窗口聚合是必须的。<br>resetAccumulator(): 在大多数batch聚合是必须的。</p>
<p>AggregateFunction的所有方法都是需要被声明为public，而不是static。定义聚合函数需要实现org.apache.flink.table.functions.AggregateFunction同时需要实现一个或者多个accumulate方法。该方法可以被重载为不同的数据类型，并且支持变参。</p>
<p>在这里就不贴出来AggregateFunction的源码了。</p>
<p>下面举个求加权平均的栗子<br>为了计算加权平均值，累加器需要存储已累积的所有数据的加权和及计数。在栗子中定义一个WeightedAvgAccum类作为accumulator。尽管，retract(), merge(), 和resetAccumulator()方法在很多聚合类型是不需要的，这里也给出了栗子。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Accumulator for WeightedAvg.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvgAccum</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Weighted Average user-defined aggregate function.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvg</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>&lt;<span class="title">Long</span>, <span class="title">WeightedAvgAccum</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> WeightedAvgAccum <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> WeightedAvgAccum();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Long <span class="title">getValue</span><span class="params">(WeightedAvgAccum acc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (acc.count == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> acc.sum / acc.count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accumulate</span><span class="params">(WeightedAvgAccum acc, <span class="keyword">long</span> iValue, <span class="keyword">int</span> iWeight)</span> </span>&#123;</span><br><span class="line">        acc.sum += iValue * iWeight;</span><br><span class="line">        acc.count += iWeight;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">retract</span><span class="params">(WeightedAvgAccum acc, <span class="keyword">long</span> iValue, <span class="keyword">int</span> iWeight)</span> </span>&#123;</span><br><span class="line">        acc.sum -= iValue * iWeight;</span><br><span class="line">        acc.count -= iWeight;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(WeightedAvgAccum acc, Iterable&lt;WeightedAvgAccum&gt; it)</span> </span>&#123;</span><br><span class="line">        Iterator&lt;WeightedAvgAccum&gt; iter = it.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            WeightedAvgAccum a = iter.next();</span><br><span class="line">            acc.count += a.count;</span><br><span class="line">            acc.sum += a.sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resetAccumulator</span><span class="params">(WeightedAvgAccum acc)</span> </span>&#123;</span><br><span class="line">        acc.count = <span class="number">0</span>;</span><br><span class="line">        acc.sum = <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// register function</span></span><br><span class="line">StreamTableEnvironment tEnv = ...</span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;wAvg&quot;</span>, <span class="keyword">new</span> WeightedAvg());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use function</span></span><br><span class="line">tEnv.sqlQuery(<span class="string">&quot;SELECT user, wAvg(points, level) AS avgPoints FROM userScores GROUP BY user&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="4-实现udf的最佳实践经验"><a href="#4-实现udf的最佳实践经验" class="headerlink" title="4. 实现udf的最佳实践经验"></a>4. 实现udf的最佳实践经验</h2><p>Table API和SQL 代码生成器内部会尽可能多的尝试使用原生值。用户定义的函数可能通过对象创建、强制转换(casting)和拆装箱((un)boxing)引入大量开销。因此，强烈推荐参数和返回值的类型定义为原生类型而不是他们包装类型(boxing class)。Types.DATE 和Types.TIME可以用int代替。Types.TIMESTAMP可以用long代替。</p>
<p>我们建议用户自定义函数使用java编写而不是scala编写，因为scala的类型可能会有不被flink类型抽取器兼容。</p>
<p>用Runtime集成UDFs</p>
<p>有时候udf需要获取全局runtime信息或者在进行实际工作之前做一些设置和清除工作。Udf提供了open()和close()方法，可以被复写，功能类似Dataset和DataStream API的RichFunction方法。</p>
<p>Open()方法是在evaluation方法调用前调用一次。Close()是在evaluation方法最后一次调用后调用。</p>
<p>Open()方法提共一个FunctionContext，FunctionContext包含了udf执行环境的上下文，比如，metric group，分布式缓存文件，全局的job参数。</p>
<p>通过调用FunctionContext的相关方法，可以获取到相关的信息：</p>
<p>方法描述</p>
<ul>
<li>getMetricGroup() - 并行子任务的指标组</li>
<li>getCachedFile(name) -分布式缓存文件的本地副本</li>
<li>getJobParameter(name, defaultValue) - 给定key全局job参数。</li>
</ul>
<p>下面，给出的例子就是通过FunctionContext在一个标量函数中获取全局job的参数。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(FunctionContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// access &quot;hashcode_factor&quot; parameter</span></span><br><span class="line">        <span class="comment">// &quot;12&quot; would be the default value if parameter does not exist</span></span><br><span class="line">        factor = Integer.valueOf(context.getJobParameter(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;12&quot;</span>)); </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// set job parameter</span></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.setString(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;31&quot;</span>);</span><br><span class="line">env.getConfig().setGlobalJobParameters(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// register the function</span></span><br><span class="line">tableEnv.registerFunction(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> HashCode());</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in Java Table API</span></span><br><span class="line">myTable.select(<span class="string">&quot;string, string.hashCode(), hashCode(string)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// use the function in SQL</span></span><br><span class="line">tableEnv.sqlQuery(<span class="string">&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;</span>);</span><br></pre></td></tr></table></figure>
<h1 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h1><h2 id="scala"><a href="#scala" class="headerlink" title="scala"></a>scala</h2><h3 id="三元运算符"><a href="#三元运算符" class="headerlink" title="三元运算符"></a>三元运算符</h3><p>sql或者table API筛选数据，必须保证每个字段不为空，<br>Flink内部，中间结果都是通过case class传递，而case class的字段必须保证不能为空</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">BOOLEAN</span>.?(<span class="type">VALUE1</span>, <span class="type">VALUE2</span>)</span><br><span class="line"><span class="symbol">&#x27;is_active_user</span>.isNull.?(<span class="string">&quot;0&quot;</span>, <span class="string">&quot;1&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="等值判断"><a href="#等值判断" class="headerlink" title="等值判断"></a>等值判断</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&#x27;Fuin</span> === <span class="symbol">&#x27;active_user</span></span><br></pre></td></tr></table></figure>
<p>scala中的<code>===</code>是运算符重构</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/Springmoon-venn/p/11826359.html">Flink Table Api &amp; SQL 翻译目录</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-SQL-active/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-SQL-active/" class="post-title-link" itemprop="url">Flink-SQL实践</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:51" itemprop="dateModified" datetime="2021-04-24T12:58:51+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink-SQL-active"><a href="#Flink-SQL-active" class="headerlink" title="Flink-SQL-active"></a>Flink-SQL-active</h1><p>维表同步脚本:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span></span><br><span class="line"><span class="keyword">into</span></span><br><span class="line">    dim_result_lct_activy_config</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        Fact_id,</span><br><span class="line">        <span class="built_in">LAST_VALUE</span>(Fact_name),</span><br><span class="line">        FROM_UNIXTIME(UNIX_TIMESTAMP(<span class="built_in">LAST_VALUE</span>(Fact_start_time)),</span><br><span class="line">        <span class="string">&#x27;yyyyMMddHHmmss&#x27;</span>) <span class="keyword">as</span> startTime,</span><br><span class="line">        FROM_UNIXTIME(UNIX_TIMESTAMP(<span class="built_in">LAST_VALUE</span>(Fact_end_time)),</span><br><span class="line">        <span class="string">&#x27;yyyyMMddHHmmss&#x27;</span>) <span class="keyword">as</span> endTime,</span><br><span class="line">        <span class="built_in">LAST_VALUE</span>(Fstate)</span><br><span class="line">    <span class="keyword">from</span></span><br><span class="line">        db_act_config_t_act_logic_config</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">        Fact_id</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://apache-flink.147419.n8.nabble.com/FlinkSQL-Upsert-Retraction-MySQL-td2785.html">FlinkSQL Upsert/Retraction 写入 MySQL 的问题 </a></p>
<p> retract流是算子的特性，不同的算子不同，比如group by聚合算子天生就是会发retract流的，比如你之前算出来的是a, 1, 后面变化了，变成了a,2，所以group by算子会发-a,1, +a,2.</p>
<p>像join的话也是有retract流的，比如outer join</p>
<p>当然如果下游sink支持upsert, 这块也会有优化，会优化为update。</p>
<blockquote>
<p>INSERT INTO  mysql_sink SELECT  f1, count(*) FROM kafka_src GROUP BY f1<br>每从 kafka 过来一条新的记录，会生成两条记录 Tuple2&lt;Row, Boolean&gt;, 旧的被删除，新的会添加上。这是query是会一个会产生retract stream的query，可以简单理解成每条kafka的数据过来会产生两条记录，但是最终写入下游的系统。需要看下游的系统支持和实现的sink(现在有三种sink AppendStreamSink, UpsertStreamSink, RetractStreamSink)</p>
</blockquote>
<blockquote>
<p>我看 <a target="_blank" rel="noopener" href="https://github.com/apache/flink/tree/master/flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc">https://github.com/apache/flink/tree/master/flink-connectors/flink-jdbc/src/main/java/org/apache/flink/api/java/io/jdbc</a> 没有 Retract 方式<br>实际上使用了 JDBCUpsertTableSink.java 的代码写入 MySQL 吗？<br>现有的sink中，kafka是实现的AppendStreamSink，所以只支持insert 的记录，不支持retract.<br>你用DDL声明的mysql表，对应的jdbc sink 是JDBCUpsertTableSink，所以会按照Upsert的逻辑处理, 也不支持retract。</p>
</blockquote>
<blockquote>
<p>如若不带 group by 直接：<br>INSERT INTO  mysql_sink SELECT  f1,  f2 FROM kafka_src<br>主键冲突写入 mysql 是会出错的，怎么可以用 Upsert 的方式直接覆盖呢？</p>
</blockquote>
<p>不带 group by时无法推导出query的 unique key，没法做按照unique key的更新，<br>只需要将 query的 key （你这里是group by 后的字段）和db中主键保持一致即可</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-checkpoint-savepoint-2pc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-checkpoint-savepoint-2pc/" class="post-title-link" itemprop="url">Flink-checkpoint与高可用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-10 14:58:00" itemprop="dateCreated datePublished" datetime="2019-08-10T14:58:00+08:00">2019-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-24 12:58:51" itemprop="dateModified" datetime="2021-04-24T12:58:51+08:00">2021-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Flink Checkpoint 受 Chandy-Lamport 分布式快照启发，可以保证数据的高可用。但是有些情况下，不见得一定有效:</p>
<p>Flink On Yarn 模式，某个 Container 发生 OOM 异常，这种情况程序直接变成失败状态，此时 Flink 程序虽然开启 Checkpoint 也无法恢复，因为程序已经变成失败状态，所以此时可以借助外部参与启动程序，比如外部程序检测到实时任务失败时，从新对实时任务进行拉起。</p>
<h2 id="1-1-2PC"><a href="#1-1-2PC" class="headerlink" title="1.1. 2PC"></a>1.1. 2PC</h2><h3 id="1-1-1-Exactly-once-VS-At-least-once"><a href="#1-1-1-Exactly-once-VS-At-least-once" class="headerlink" title="1.1.1. Exactly-once VS At-least-once"></a>1.1.1. Exactly-once VS At-least-once</h3><p>算子做快照时，如果等所有输入端的barrier都到了才开始做快照，可保证算子的exactly-once；如果为了降低延时而跳过对齐，从而继续处理数据，那么等barrier都到齐后做快照就是at-least-once了，因为这次的快照掺杂了下一次快照的数据，当作业失败恢复的时候，这些数据会重复作用系统，就好像这些数据被消费了两遍。</p>
<p>注：对齐只会发生在算子的上端是join操作以及上游存在partition或者shuffle的情况，对于直连操作类似map、flatMap、filter等还是会保证exactly-once的语义。</p>
<h3 id="1-1-2-端到端的Exactly-once实现"><a href="#1-1-2-端到端的Exactly-once实现" class="headerlink" title="1.1.2. 端到端的Exactly once实现"></a>1.1.2. 端到端的Exactly once实现</h3><p>2PC分为几个阶段: 开始事务-&gt;预提交-&gt;提交(或回滚)</p>
<p>为了保证Exactly once, source和sink必须支持flink的2PC</p>
<p>当状态涉及到外部系统时，需要外部系统支持事务操作来配合flink实现2PC协议，从而保证数据的exatly-once。<br>这个时候，sink算子除了将自己的state写到后段，还必须准备好事务提交。</p>
<ul>
<li>一旦所有的算子完成了它们的pre-commit，它们会要求一个commit。</li>
<li>如果存在一个算子pre-commit失败了，本次事务失败，我们回滚到上次的checkpoint。</li>
<li>一旦master做出了commit的决定，那么这个commit必须得到执行，就算宕机恢复也有继续执行。</li>
</ul>
<h4 id="1-1-2-1-pre-commit"><a href="#1-1-2-1-pre-commit" class="headerlink" title="1.1.2.1. pre-commit"></a>1.1.2.1. pre-commit</h4><p>pre-commit阶段起始于一次快照的开始，即master节点将checkpoint的barrier注入source端，barrier随着数据向下流动直到sink端。barrier每到一个算子，都会出发算子做本地快照。</p>
<p><img src="_v_images/20200710154629243_751269158.png" alt="precommit"></p>
<p>当所有的算子都做完了本地快照并且回复到master节点时，pre-commit阶段才算结束。这个时候，checkpoint已经成功，并且包含了外部系统的状态。如果作业失败，可以进行恢复。</p>
<p><img src="_v_images/20200710154750060_1524377793.png" alt="precommit-success"></p>
<h4 id="1-1-2-2-commit"><a href="#1-1-2-2-commit" class="headerlink" title="1.1.2.2. commit"></a>1.1.2.2. commit</h4><p>通知所有的算子这次checkpoint成功了，即2PC的commit阶段。source节点和window节点没有外部状态，所以这时它们不需要做任何操作。<br>而对于sink节点，需要commit这次事务，将数据写到外部系统。</p>
<p><img src="_v_images/20200710154844838_737658241.png" alt="commit"></p>
<h4 id="1-1-2-3-rollback"><a href="#1-1-2-3-rollback" class="headerlink" title="1.1.2.3. rollback"></a>1.1.2.3. rollback</h4><p>一旦任何一个算子的快照保存失败，则触发回滚，同样的sink算子也需要取消写入外部的数据</p>
<h3 id="1-1-3-TwoPhaseCommitSinkFunction"><a href="#1-1-3-TwoPhaseCommitSinkFunction" class="headerlink" title="1.1.3. TwoPhaseCommitSinkFunction"></a>1.1.3. TwoPhaseCommitSinkFunction</h3><p>为了简化2PC的实现成本，flink抽象了TwoPhaseCommitSinkFunction</p>
<ul>
<li>beginTransaction。开始一次事务，在目的文件系统创建一个临时文件。接下来我们就可以将数据写到这个文件。</li>
<li>preCommit。在这个阶段，将文件flush掉，同时重起一个文件写入，作为下一次事务的开始。</li>
<li>commit。这个阶段，将文件写到真正的目的目录。值得注意的是，这会增加数据可视的延时。</li>
<li>abort。如果回滚，那么删除临时文件。</li>
</ul>
<p>如果pre-commit成功了，但是commit没有到达算子旧宕机了，flink会将算子恢复到pre-commit时的状态，然后继续commit。</p>
<p>我们需要做的还有就是保证commit的幂等性，这可以通过检查临时文件是否还在来实现。</p>
<h2 id="1-2-checkpoint"><a href="#1-2-checkpoint" class="headerlink" title="1.2. checkpoint"></a>1.2. checkpoint</h2><p><strong>保留策略</strong>:</p>
<ul>
<li>DELETE_ON_CANCELLATION 表示当程序取消时，删除 Checkpoint 存储文件。</li>
<li>RETAIN_ON_CANCELLATION 表示当程序取消时，保存之前的 Checkpoint 存储文件</li>
</ul>
<p>默认情况下，Flink不会触发一次 Checkpoint 当系统有其他 Checkpoint 在进行时，也就是说 Checkpoint 默认的并发为1。</p>
<p><strong>CheckpointCoordinator</strong> :</p>
<p>针对 Flink DataStream 任务，程序需要经历从 StreamGraph -&gt; JobGraph -&gt; ExecutionGraph -&gt; 物理执行图四个步骤，其中在 ExecutionGraph 构建时，会初始化 CheckpointCoordinator。ExecutionGraph通过ExecutionGraphBuilder.buildGraph方法构建，在构建完时，会调用 ExecutionGraph 的enableCheckpointing方法创建CheckpointCoordinator</p>
<p><strong>Flink Checkpoint 参数配置及建议</strong>:</p>
<ul>
<li>当 Checkpoint 时间比设置的 Checkpoint 间隔时间要长时，可以设置 Checkpoint 间最小时间间隔 。这样在上次 Checkpoint 完成时，不会立马进行下一次 Checkpoint，而是会等待一个最小时间间隔，然后在进行该次 Checkpoint。否则，每次 Checkpoint 完成时，就会立马开始下一次 Checkpoint，系统会有很多资源消耗 Checkpoint。</li>
<li>如果Flink状态很大，在进行恢复时，需要从远程存储读取状态恢复，此时可能导致任务恢复很慢，可以设置 Flink Task 本地状态恢复。任务状态本地恢复默认没有开启，可以设置参数state.backend.local-recovery值为true进行激活。</li>
<li>Checkpoint保存数，Checkpoint 保存数默认是1，也就是保存最新的 Checkpoint 文件，当进行状态恢复时，如果最新的Checkpoint文件不可用时(比如HDFS文件所有副本都损坏或者其他原因)，那么状态恢复就会失败，如果设置 Checkpoint 保存数2，即使最新的Checkpoint恢复失败，那么Flink 会回滚到之前那一次Checkpoint进行恢复。考虑到这种情况，用户可以增加 Checkpoint 保存数。</li>
<li>建议设置的 Checkpoint 的间隔时间最好大于 Checkpoint 的完成时间。</li>
</ul>
<p>下图是不设置 Checkpoint 最小时间间隔示例图，可以看到，系统一致在进行 Checkpoint，可能对运行的任务产生一定影响：<br><img src="_v_images/20200714095846469_121820659.png"></p>
<h2 id="1-3-savepoint"><a href="#1-3-savepoint" class="headerlink" title="1.3. savepoint"></a>1.3. savepoint</h2><blockquote>
<p>注意:<br>使用DataStream进行开发，建议为每个算子定义一个 uid，这样我们在修改作业时，即使导致程序拓扑图改变，由于相关算子 uid 没有变，那么这些算子还能够继续使用之前的状态，如果用户没有定义 uid ， Flink 会为每个算子自动生成 uid，如果用户修改了程序，可能导致之前的状态程序不能再进行复用。</p>
</blockquote>
<p>Flink 在触发Savepoint 或者 Checkpoint时，会根据这次触发的类型计算出在HDFS上面的目录:</p>
<p>如果类型是 Savepoint，那么 其 HDFS 上面的目录为：Savepoint 根目录+savepoint-jobid前六位+随机数字，具体如下格式：</p>
<p><img src="_v_images/20200714100459823_887900222.png"></p>
<p>Checkpoint 目录为 chk-checkpoint ID,具体格式如下：</p>
<p><img src="_v_images/20200714100516223_630729421.png"></p>
<ul>
<li>使用 flink cancel -s 命令取消作业同时触发 Savepoint 时，会有一个问题，可能存在触发 Savepoint 失败。比如实时程序处于异常状态(比如 Checkpoint失败)，而此时你停止作业，同时触发 Savepoint,这次 Savepoint 就会失败，这种情况会导致，在实时平台上面看到任务已经停止，但是实际实时作业在 Yarn 还在运行。针对这种情况，需要捕获触发 Savepoint 失败的异常，当抛出异常时，可以直接在 Yarn 上面 Kill 掉该任务。</li>
<li>使用 DataStream 程序开发时，最好为每个算子分配 uid,这样即使作业拓扑图变了，相关算子还是能够从之前的状态进行恢复，默认情况下，Flink 会为每个算子分配 uid,这种情况下，当你改变了程序的某些逻辑时，可能导致算子的 uid 发生改变，那么之前的状态数据，就不能进行复用，程序在启动的时候，就会报错。</li>
<li>由于 Savepoint 是程序的全局状态，对于某些状态很大的实时任务，当我们触发 Savepoint，可能会对运行着的实时任务产生影响，个人建议如果对于状态过大的实时任务，触发 Savepoint 的时间，不要太过频繁。根据状态的大小，适当的设置触发时间。</li>
<li>当我们从 Savepoint 进行恢复时，需要检查这次 Savepoint 目录文件是否可用。可能存在你上次触发 Savepoint 没有成功，导致 HDFS 目录上面 Savepoint 文件不可用或者缺少数据文件等，这种情况下，如果在指定损坏的 Savepoint 的状态目录进行状态恢复，任务会启动不起来。</li>
</ul>
<h2 id="1-4-snapshot保存到哪里-应该需要汇总到jobManager？"><a href="#1-4-snapshot保存到哪里-应该需要汇总到jobManager？" class="headerlink" title="1.4. snapshot保存到哪里? 应该需要汇总到jobManager？"></a>1.4. snapshot保存到哪里? 应该需要汇总到jobManager？</h2><h2 id="1-5-state-backend"><a href="#1-5-state-backend" class="headerlink" title="1.5. state backend"></a>1.5. state backend</h2><p><img src="_v_images/20200713183839429_2053265091.png"></p>
<h3 id="FsStateBackend"><a href="#FsStateBackend" class="headerlink" title="FsStateBackend"></a>FsStateBackend</h3><p>构造方法:<br><code>FsStateBackend(URI checkpointDataUri,boolean asynchronousSnapshots)</code></p>
<p>1 基于文件系统的状态管理器<br>2 如果使用，默认是异步<br>3 比较稳定，3个副本，比较安全。不会出现任务无法恢复等问题<br>4 状态大小受磁盘容量限制</p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager内存</li>
<li>checkpoint: 外部文件系统(本地或HDFS)</li>
</ul>
<p>容量限制:</p>
<ul>
<li>单TaskManager上State总量不超过它的内存</li>
<li>总大小不超过配置的文件系统容量</li>
</ul>
<p>推荐使用场景:</p>
<ul>
<li>常规使用状态的作业，例如分钟级窗口聚合、join、窗口比较长、kv状态大；需要开启HA的作业</li>
<li>可以用于生产场景</li>
</ul>
<h3 id="RocksDBStateBackend"><a href="#RocksDBStateBackend" class="headerlink" title="RocksDBStateBackend"></a>RocksDBStateBackend</h3><p>状态数据先写入RocksDB，然后异步的将状态数据写入文件系统。正在进行计算的热数据存储在RocksDB，长时间才更新的数据写入磁盘中（文件系统）存储，体量比较小的元数据状态写入JobManager内存中（将工作state保存在RocksDB中，并且默认将checkpoint数据存在文件系统中）</p>
<p>目前唯一支持incremental的checkpoints的策略</p>
<p>构造方法:<br><code>RocksDBStateBackend(URI checkpointDataUri,boolean enableIncrementalCheckpointing)</code></p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager上的KV数据库(实际使用内存+硬盘)</li>
<li>Checkpoint: 外部文件系统(本地或HDFS)</li>
</ul>
<p>容量限制:</p>
<ul>
<li>单TaskManager上的State总量不超过他的内存+磁盘</li>
<li>单key最大2G</li>
<li>总大小不超过配置的文件系统容量</li>
</ul>
<p>推荐使用的场景:</p>
<ul>
<li>超大状态的作业，例如天级别窗口聚合；需要开启HA的作业；对状态读写性能要求不高的作业</li>
<li>可以在生产环境使用</li>
</ul>
<h3 id="MemoryStateBackend"><a href="#MemoryStateBackend" class="headerlink" title="MemoryStateBackend"></a>MemoryStateBackend</h3><p>构造方法:<br><code>MemoryStateBackend(int maxStateSize, boolean asynchronousSnapshots)</code></p>
<p>主机内存中的数据可能会丢失，任务可能无法恢复</p>
<p>存储方式:</p>
<ul>
<li>State: TaskManager内存</li>
<li>Checkpoint: JobManager内存</li>
</ul>
<p>容量限制</p>
<ul>
<li>单个State maxStateSize默认5M</li>
<li>maxStateSize &lt;= akka.frameSize 默认10M</li>
<li>总大小不超过JobManager的内存</li>
</ul>
<p>推荐使用场景：</p>
<ul>
<li>本地测试；几乎无状态的作业，比如ETL；JobManager不容易挂，或挂掉影响不大的情况</li>
<li>不推荐在生产环境使用</li>
</ul>
<h2 id="1-6-checkpoint-与-savepoint"><a href="#1-6-checkpoint-与-savepoint" class="headerlink" title="1.6. checkpoint 与 savepoint"></a>1.6. checkpoint 与 savepoint</h2><p>Checkpoint指定触发生成时间间隔后，每当需要触发Checkpoint时，会向Flink程序运行时的多个分布式的Stream Source中插入一个Barrier标记，这些Barrier会根据Stream中的数据记录一起流向下游的各个Operator。<br>当一个Operator接收到一个Barrier时，它会暂停处理Steam中新接收到的数据记录。<br>因为一个Operator可能存在多个输入的Stream，而每个Stream中都会存在对应的Barrier，该Operator要等到所有的输入Stream中的Barrier都到达。(<strong>对齐</strong>)<br>当所有Stream中的Barrier都已经到达该Operator，这时所有的Barrier在时间上看来是同一个时刻点（表示已经对齐），在等待所有Barrier到达的过程中，<br>Operator的Buffer中可能已经缓存了一些比Barrier早到达Operator的数据记录（Outgoing Records），这时该Operator会将数据记录（Outgoing Records）发射（Emit）出去，作为下游Operator的输入，<br>最后将Barrier对应Snapshot发射（Emit）出去作为此次Checkpoint的结果数据。</p>
<p>Checkpoint 是增量做的，每次的时间较短，数据量较小，只要在程序里面启用后会自动触发，用户无须感知；Checkpoint 是作业 failover 的时候自动使用，不需要用户指定。</p>
<p>Savepoint 是全量做的，每次的时间较长，数据量较大，需要用户主动去触发。Savepoint 一般用于程序的版本更新（详见文档），Bug 修复，A/B Test 等场景，需要用户指定。</p>
<p><strong>保存的内容</strong></p>
<ul>
<li>首先，Savepoint 包含了一个目录，其中包含（通常很大的）二进制文件，这些文件表示了整个流应用在 Checkpoint/Savepoint 时的状态。</li>
<li>以及一个（相对较小的）元数据文件，包含了指向 Savapoint 各个文件的指针，并存储在所选的分布式文件系统或数据存储中。</li>
</ul>
<p><strong>目标</strong></p>
<p>Savepoint 和 Checkpoint 的不同之处很像传统数据库中备份与恢复日志之间的区别。Checkpoint 的主要目标是充当 Flink 中的恢复机制，确保能从潜在的故障中恢复。相反，Savepoint 的主要目标是充当手动备份、恢复暂停作业的方法。</p>
<p><strong>实现</strong></p>
<p>Checkpoint 被设计成轻量和快速的机制。它们可能（但不一定必须）利用底层状态后端的不同功能尽可能快速地恢复数据。例如，基于 RocksDB 状态后端的增量检查点，能够加速 RocksDB 的 checkpoint 过程，这使得 checkpoint 机制变得更加轻量。相反，Savepoint 旨在更多地关注数据的可移植性，并支持对作业做任何更改而状态能保持兼容，这使得生成和恢复的成本更高</p>
<p><strong>状态文件保留策略</strong></p>
<p>Checkpoint默认程序删除，可以设置CheckpointConfig中的参数进行保留 。Savepoint会一直保存，除非用户删除 。</p>
<p><strong>应用</strong></p>
<ul>
<li>部署流应用的一个新版本，包括新功能、BUG 修复、或者一个更好的机器学习模型</li>
<li>引入 A/B 测试，使用相同的源数据测试程序的不同版本，从同一时间点开始测试而不牺牲先前的状态</li>
<li>在需要更多资源时扩容应用程序</li>
<li>迁移流应用程序到 Flink 的新版本上，或者迁移到另一个集群</li>
</ul>
<h1 id="Flink数据一致性"><a href="#Flink数据一致性" class="headerlink" title="Flink数据一致性"></a>Flink数据一致性</h1><h2 id="一、综述"><a href="#一、综述" class="headerlink" title="一、综述"></a>一、综述</h2><p><strong>flink 通过内部依赖checkpoint 并且可以通过设置其参数exactly-once 实现其内部的一致性</strong>。但要实现其端到端的一致性，还必须保证<br>1、source 外部数据源可重设数据的读取位置<br>2、sink端 需要保证数据从故障恢复时，数据不会重复写入外部系统（或者可以逻辑实现写入多次，但只有一次生效的数据sink端）</p>
<h2 id="二、sink-端到端实现方式"><a href="#二、sink-端到端实现方式" class="headerlink" title="二、sink 端到端实现方式"></a>二、sink 端到端实现方式</h2><p><strong>幂等操作：</strong><br>一个操作，可以重复执行多次，但只导致一次结果更改，豁免重复操作执行就不起作用了，他的瑕疵 （在系统恢复的过程中，如果这段时间内多个更新或者插入导致状态不一致，但当数据追上就可以了）<br>（逻辑与、逻辑或等）具体理解参照自己以前写的文章。<br><strong>事务写入：</strong><br>事务应该具有四个属性：原子性、一致性、隔离性、持久性等。其具体的实现方式有两种<br><strong>（1）、预写日志</strong><br>简单易于实现，由于数据提前在状态后端中做了缓存，所以无论什么sink系统，都能用这种方式一批搞定，DataStream API提供了一个模板类：GenericWriteAheadSink，来实现这种事务性sink；<br>缺点：<br>1）、sink系统没说他支持事务。有可能出现一部分写入集群了。一部分没有写进去（如果实表，再写一次就写重复了）<br>2）、checkpoint做完了sink才去真正的写入（但其实得等sink都写完checkpoint才能生效，所以WAL这个机制jobmanager确定它写完还不算真正写完，还得有一个外部系统已经确认 完成的checkpoint）<br>（<strong>2）、两阶段提交。 flink 真正实现exactle-once</strong><br>对于每个checkpoint,sink 任务会启动一个事务，并将接下来所有接收的数据添加到事务中，然后将这些数据写入外部sink系统，但不提交他们（这里是预提交）。当checkpoint完成时的通知，它才正式提交事务，实现结果的真正写入；这种方式真正实现了exactly-once,它需要一个提供事务支持的外部sink系统，Flink提供了其具体实现（TwoPhaseCommitSinkFunction接口）</p>
<h2 id="三、-2pc-对外部-sink的要求"><a href="#三、-2pc-对外部-sink的要求" class="headerlink" title="三、 2pc 对外部 sink的要求"></a>三、 2pc 对外部 sink的要求</h2><p>1、外部sink系统必须事务支持，或者sink任务必须能够模拟外部系统上的事务；<br>2、在checkpoint的间隔期间里，必须能够开启一个事务，并接受数据写入。<br>3、在收到checkpoint完成通知之前，事务必须是“等待提交”的状态，在故障恢复的情况线，这可能需要一些时间。如果个时候sink系统关闭事务（例如超时了），那么未提交的数据就会丢失；<br>4、四年任务必选能够在进程失败后恢复事务<br>5、提交事务必须是幂等操作；</p>
<p>四、综上不同Source和sink的一致性保证：<br><img src="_v_images/20201208154240979_1471214802.png" alt="在这里插入图片描述"></p>
<h2 id="五、应用（flinK-kafka-端到端一致性保证）"><a href="#五、应用（flinK-kafka-端到端一致性保证）" class="headerlink" title="五、应用（flinK+kafka 端到端一致性保证）"></a>五、应用（flinK+kafka 端到端一致性保证）</h2><p>flink 和kafka 端到端一致性(kafka(source+flink+kafka(sink)))<br>1、内部 – 利用checkpoint机制，把状态存盘，发生故障的时候可以恢复，保证内部的状态一致性<br>2、source – kafka consumer作为source，可以将偏移量保存下来，如果后续任务出现了故障，恢复的时候可以由连接器重置偏移量，重新消费数据，保证一致性；</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">kafka</span> 0.8 和<span class="selector-tag">kafka</span> 0.11 之后 通过以下配置将偏移量保存，恢复时候重新消费</span><br><span class="line"> <span class="selector-tag">kafka</span><span class="selector-class">.setStartFromLatest</span>();</span><br><span class="line"> <span class="selector-tag">kafka</span><span class="selector-class">.setCommitOffsetsOnCheckpoints</span>(<span class="selector-tag">false</span>);</span><br><span class="line"> <span class="selector-tag">kafka</span> 0.9 和<span class="selector-tag">kafka0</span>.10 未验证是否支持这两个参数(<span class="selector-tag">todo</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>3、sink FlinkkafkaProducer作为Sink，采用两阶段提交的sink，由下图可以看出flink 0.11 已经默认继承了TwoPhaseCommitSinkFunction<br><img src="_v_images/20201208154240548_914126344.png" alt="在这里插入图片描述"><br>但我们需要在参数种传入指定语义，它默认时还是at-least-once<br>此外我们还需要进行一些producer的容错配置：<br>（1）除了启用Flink的检查点之外，还可以通过将适当的semantic参数传递给FlinkKafkaProducer011（FlinkKafkaProducer对于Kafka&gt; = 1.0.0版本）<br>（2）来选择三种不同的操作模式<br>1）、Semantic.NONE 代表at-mostly-once语义<br>2）、Semantic.AT_LEAST_ONCE（Flink默认设置<br>3）、Semantic.EXACTLY_ONCE 使用Kafka事务提供一次精确的语义，每当您使用事务写入Kafka时<br>（3）、请不要忘记消费kafka记录任何应用程序设置所需的设置isolation.leva（read_committed 或者read_uncommitted-后者是默认）<br>read_committed，只是读取已经提交的数据。</p>
<p>应用；<br>Semantic.EXACTLY_ONCE依赖与下游系统能支持事务操作.以0.11kafka为例.<br>transaction.max.timeout.ms 最大超市时长，默认15分钟，如果需要用exactly语义，需要增加这个值。（因为它小于transaction.timeout.ms ）<br>isolation.level 如果需要用到exactly语义，需要在下级consumerConfig中设置read-commited [read-uncommited(默认值)]<br>transaction.timeout.ms 默认为1hour</p>
<p><strong>其参数对应关系为 和一些报错问题<br>checkpoint间隔&lt;transaction.timeout.ms&lt;transaction.max.timeout.ms</strong></p>
<p><strong>参考：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/createweb/p/11971846.html">https://www.cnblogs.com/createweb/p/11971846.html</a></strong></p>
<p>注意：<br>1、Semantic.EXACTLY_ONCE 模式每个FlinkKafkaProducer011实例使用一个固定大小的KafkaProducers池。每个检查点使用这些生产者中的每一个。如果并发检查点的数量超过池大小，FlinkKafkaProducer011 将引发异常，并使整个应用程序失败。请相应地配置最大池大小和最大并发检查点数。</p>
<p>2、Semantic.EXACTLY_ONCE采取所有可能的措施，不要留下任何挥之不去的数据，否则这将有碍于消费者更多地阅读Kafka主题。但是，如果flink应用程序在第一个检查点之前失败，则在重新启动此类应用程序后，系统种将没有有关先前池大小信息，因此，在第一个检查点完成前按比例缩小Flink应用程序的FlinkKafkaProducer011.SAFE_SCALE_DOWN_FACTOR</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//1。设置最大允许的并行<span class="selector-tag">checkpoint</span>数，防止超过<span class="selector-tag">producer</span>池的个数发生异常</span><br><span class="line"><span class="selector-tag">env</span><span class="selector-class">.getCheckpointConfig</span><span class="selector-class">.setMaxConcurrentCheckpoints</span>(5) </span><br><span class="line">//2。设置<span class="selector-tag">producer</span>的<span class="selector-tag">ack</span>传输配置</span><br><span class="line">// 设置超市时长，默认15分钟，建议1个小时以上</span><br><span class="line"><span class="selector-tag">producerConfig</span><span class="selector-class">.put</span>(<span class="selector-tag">ProducerConfig</span><span class="selector-class">.ACKS_CONFIG</span>, 1) </span><br><span class="line"><span class="selector-tag">producerConfig</span><span class="selector-class">.put</span>(<span class="selector-tag">ProducerConfig</span><span class="selector-class">.TRANSACTION_TIMEOUT_CONFIG</span>, 15000) </span><br><span class="line"></span><br><span class="line">//3。在下一个<span class="selector-tag">kafka</span> <span class="selector-tag">consumer</span>的配置文件，或者代码中设置<span class="selector-tag">ISOLATION_LEVEL_CONFIG-read-commited</span></span><br><span class="line">//<span class="selector-tag">Note</span>:必须在下一个<span class="selector-tag">consumer</span>中指定，当前指定是没用用的</span><br><span class="line"><span class="selector-tag">kafkaonfigs</span><span class="selector-class">.setProperty</span>(<span class="selector-tag">ConsumerConfig</span><span class="selector-class">.ISOLATION_LEVEL_CONFIG</span>,&quot;<span class="selector-tag">read_commited</span>&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>完整应用代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shufang.flink.connectors</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.TimeCharacteristic</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.Semantic</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line"></span><br><span class="line">object KafkaSource01 &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这是checkpoint的超时时间</span></span><br><span class="line">    <span class="comment">//env.getCheckpointConfig.setCheckpointTimeout()</span></span><br><span class="line">    <span class="comment">//设置最大并行的chekpoint</span></span><br><span class="line">    env.getCheckpointConfig.setMaxConcurrentCheckpoints(<span class="number">5</span>)</span><br><span class="line">    env.getCheckpointConfig.setCheckpointInterval(<span class="number">1000</span>) <span class="comment">//增加checkpoint的中间时长，保证可靠性</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 为了保证数据的一致性，我们开启Flink的checkpoint一致性检查点机制，保证容错</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    env.enableCheckpointing(<span class="number">60000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从kafka获取数据，一定要记得添加checkpoint，能保证offset的状态可以重置，从数据源保证数据的一致性</span></span><br><span class="line"><span class="comment">     * 保证kafka代理的offset与checkpoint备份中保持状态一致</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    val kafkaonfigs = <span class="keyword">new</span> Properties()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka的启动集群</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">    <span class="comment">//指定消费者组</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;flinkConsumer&quot;</span>)</span><br><span class="line">    <span class="comment">//指定key的反序列化类型</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer].getName)</span><br><span class="line">    <span class="comment">//指定value的反序列化类型</span></span><br><span class="line">    kafkaonfigs.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer].getName)</span><br><span class="line">    <span class="comment">//指定自动消费offset的起点配置</span></span><br><span class="line">    <span class="comment">//    kafkaonfigs.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义kafkaConsumer，同时可以指定从哪里开始消费</span></span><br><span class="line"><span class="comment">     * 开启了Flink的检查点之后，我们还要开启kafka-offset的检查点，通过kafkaConsumer.setCommitOffsetsOnCheckpoints(true)开启，</span></span><br><span class="line"><span class="comment">     * 一旦这个检查点开启，那么之前配置的 auto-commit-enable = true的配置就会自动失效</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    val kafkaConsumer = <span class="keyword">new</span> FlinkKafkaConsumer[String](</span><br><span class="line">      <span class="string">&quot;console-topic&quot;</span>,</span><br><span class="line">      <span class="keyword">new</span> SimpleStringSchema(), <span class="comment">// 这个schema是将kafka的数据应设成Flink中的String类型</span></span><br><span class="line">      kafkaonfigs</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 开启kafka-offset检查点状态保存机制</span></span><br><span class="line">    kafkaConsumer.setCommitOffsetsOnCheckpoints(<span class="keyword">true</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromEarliest()//</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromTimestamp(1010003794)</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromLatest()</span></span><br><span class="line">    <span class="comment">//    kafkaConsumer.setStartFromSpecificOffsets(Map[KafkaTopicPartition,Long]()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加source数据源</span></span><br><span class="line">    val kafkaStream: DataStream[String] = env.addSource(kafkaConsumer)</span><br><span class="line"></span><br><span class="line">    kafkaStream.print()</span><br><span class="line"></span><br><span class="line">    val sinkStream: DataStream[String] = kafkaStream.assignTimestampsAndWatermarks(<span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor[String](Time.seconds(<span class="number">5</span>)) &#123;</span><br><span class="line">      <span class="function">override def <span class="title">extractTimestamp</span><span class="params">(element: String)</span>: Long </span>= &#123;</span><br><span class="line">        element.split(<span class="string">&quot;,&quot;</span>)(<span class="number">1</span>).toLong</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过FlinkkafkaProduccer API将stream的数据写入到kafka的&#x27;sink-topic&#x27;中</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//    val brokerList = &quot;localhost:9092&quot;</span></span><br><span class="line">    val topic = <span class="string">&quot;sink-topic&quot;</span></span><br><span class="line">    val producerConfig = <span class="keyword">new</span> Properties()</span><br><span class="line">    producerConfig.put(ProducerConfig.ACKS_CONFIG, <span class="keyword">new</span> Integer(<span class="number">1</span>)) <span class="comment">// 设置producer的ack传输配置</span></span><br><span class="line">    producerConfig.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, Time.hours(<span class="number">2</span>)) <span class="comment">//设置超市时长，默认1小时，建议1个小时以上</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义producer，可以通过不同的构造器创建</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    val producer: FlinkKafkaProducer[String] = <span class="keyword">new</span> FlinkKafkaProducer[String](</span><br><span class="line">      topic,</span><br><span class="line">      <span class="keyword">new</span> KeyedSerializationSchemaWrapper[String](SimpleStringSchema),</span><br><span class="line">      producerConfig,</span><br><span class="line">      Semantic.EXACTLY_ONCE</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    FlinkKafkaProducer.SAFE_SCALE_DOWN_FACTOR</span></span><br><span class="line">    <span class="comment">/** *****************************************************************************************************************</span></span><br><span class="line"><span class="comment">     * * 出了要开启flink的checkpoint功能，同时还要设置相关配置功能。</span></span><br><span class="line"><span class="comment">     * * 因在0.9或者0.10，默认的FlinkKafkaProducer只能保证at-least-once语义，假如需要满足at-least-once语义，我们还需要设置</span></span><br><span class="line"><span class="comment">     * * setLogFailuresOnly(boolean)    默认false</span></span><br><span class="line"><span class="comment">     * * setFlushOnCheckpoint(boolean)  默认true</span></span><br><span class="line"><span class="comment">     * * come from 官网 below：</span></span><br><span class="line"><span class="comment">     * * Besides enabling Flink’s checkpointing，you should also configure the setter methods setLogFailuresOnly(boolean)</span></span><br><span class="line"><span class="comment">     * * and setFlushOnCheckpoint(boolean) appropriately.</span></span><br><span class="line"><span class="comment">     * ******************************************************************************************************************/</span></span><br><span class="line"></span><br><span class="line">    producer.setLogFailuresOnly(<span class="keyword">false</span>) <span class="comment">//默认是false</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 除了启用Flink的检查点之外，还可以通过将适当的semantic参数传递给FlinkKafkaProducer011（FlinkKafkaProducer对于Kafka&gt; = 1.0.0版本）</span></span><br><span class="line"><span class="comment">     * 来选择三种不同的操作模式：</span></span><br><span class="line"><span class="comment">     * Semantic.NONE  代表at-mostly-once语义</span></span><br><span class="line"><span class="comment">     * Semantic.AT_LEAST_ONCE（Flink默认设置）</span></span><br><span class="line"><span class="comment">     * Semantic.EXACTLY_ONCE：使用Kafka事务提供一次精确的语义，每当您使用事务写入Kafka时，</span></span><br><span class="line"><span class="comment">     * 请不要忘记为使用Kafka记录的任何应用程序设置所需的设置isolation.level（read_committed 或read_uncommitted-后者是默认值)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    sinkStream.addSink(producer)</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">&quot;kafka source &amp; sink&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a target="_blank" rel="noopener" href="http://shiyanjun.cn/archives/1855.html">Flink Checkpoint、Savepoint配置与实践</a></li>
<li><a target="_blank" rel="noopener" href="http://wuchong.me/blog/2018/11/04/how-apache-flink-manages-kafka-consumer-offsets/">Flink 小贴士 (2)：Flink 如何管理 Kafka 消费位点</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4bcbcda0e2f4">Flink实时计算-深入理解Checkpoint和Savepoint</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.08603">Lightweight Asynchronous Snapshots for Distributed Dataflows: 分布式数据流轻量级异步快照</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">239</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">128</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
