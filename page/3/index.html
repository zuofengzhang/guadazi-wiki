<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/FFA-2020/FFA-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/FFA-2020/FFA-2020/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="FFA-2020"><a href="#FFA-2020" class="headerlink" title="FFA-2020"></a>FFA-2020</h1><p>主要包括：流计算引擎内核，流批一体，Flink + AI 融合，云原生这四个方向</p>
<h3 id="1）Unaligned-Checkpoint"><a href="#1）Unaligned-Checkpoint" class="headerlink" title="1）Unaligned Checkpoint"></a>1）Unaligned Checkpoint</h3><p>我们知道 Flink 的一个最核心的部分是通过分布式全局轻量快照算法 [2, vldb17] 做 checkpoint 来保证强一致性 exactly once 语义。这个算法通过 task 之间 barrier 的传递使得每一个 task 只需要对自己的状态进行快照；当 barrier 最终达到 sink 的时候，我们就会得到一个完整的全局快照（checkpoint）。但在数据反压的情况下，barrier 无法流到 sink，会造成 checkpoint 始终无法完成。Unaligned Checkpoint 解决了反压状态下，checkpoint 无法完成的问题。在 unaligned checkpoint 的模式下，Flink 可以对每个 task 的 channel state 和 output buffer 也进行快照，这样 barrier 可以快速传递到 sink，使得 checkpoint 不受反压影响。Unaligned checkpoint 和 aligned checkpoint（现有的 checkpoint 模式）可以通过 alignment timeout 自动智能的切换，下图给出了示意图。</p>
<p><img src="vx_images/1103143188373.jpg"></p>
<h3 id="流批一体数据生态"><a href="#流批一体数据生态" class="headerlink" title="流批一体数据生态"></a>流批一体数据生态</h3><p>莫问老师指出，流批一体不仅仅只是一个技术问题，它也对业界数据生态的演化也起到了深远的作用，比较典型的场景包括数据同步集成（数据库里的数据同步到数仓中）和基于 Flink 流批一体的数仓架构/数据湖架构。传统的数据同步集成采用全量增量定时合并的模式，而 Flink 流批一体混合 connector 可以实现全量增量一体化数据集成（读取数据库全量数据后，可以自动切换到增量模式，通过 CDC 读取 binlog 进行增量同步），全量和增量之间无缝自动切换，如下图所示。</p>
<p><img src="vx_images/5331630745896.jpg"></p>
<p>传统的数仓架构分别维护一套实时数仓和离线数仓链路，这样会造成开发流程冗余（实时离线两套开发流程），数据链路冗余（两遍对数据的清洗补齐过滤），数据口径不一致（实时和离线计算结果不一致）等问题。而 Flink 的流批一体数仓架构将实时离线链路合二为一，可以完全的解决上述这三个问题。不仅于此，Flink 的流批一体架构和数据湖所要解决的问题（流批一体存储问题）也完美契合。现在比较主流的数据湖解决方案 Iceberg，Hudi 和 Flink 都有集成。其中，Flink + Iceberg 已有完整的集成方案；而 Flink + Hudi 的整合也在积极对接中。</p>
<p>从 Flink-1.10 版本开始，Flink 经过三个版本的迭代，到 Flink-1.12，Flink 已经可以原生地运行在 Kubernetes 之上，对接 K8S 的 HA 方案，并不再依赖 ZooKeeper，达到生产可用级别。同时，Flink 的 JobManager 可以和 K8S Master 直接通信，实现动态扩缩容，并支持对 GPU 的资源调度。</p>
<p><img src="vx_images/3116544534988.jpg"></p>
<p>2020 年，Flink 已经成为事实上的全球实时计算标准。目前各大云厂商（阿里云，AWS）和大数据厂商（Cloudera）等均已将 Flink 内置作为标准的云产品。到今年双十一，Flink 已包揽阿里内部所有集团（包括蚂蚁，钉钉，菜鸟等）的全链路实时化解决方案，规模达到百万级 CPU Core。并且在资源没有增长的情况下，提高了一倍业务能力。今年双十一的实时数据处理峰值更是达到 40 亿条记录/秒的新高。</p>
<p><img src="vx_images/4419468860739.jpg"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/%E7%BD%91%E6%96%87-%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/%E7%9F%A5%E4%B9%8E%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/%E7%BD%91%E6%96%87-%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/%E7%9F%A5%E4%B9%8E%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="知乎实时数仓架构演进"><a href="#知乎实时数仓架构演进" class="headerlink" title="知乎实时数仓架构演进"></a>知乎实时数仓架构演进</h1><p>(1.0) Spark Streaming –&gt; (2.0) Flink Streaming –&gt; (未来) Streaming SQL</p>
<ul>
<li>数据采集，由三端 SDK 采集数据并通过 Log Collector Server 发送到 Kafka。</li>
<li>数据 ETL，主要完成对原始数据的清洗和加工并分实时和离线导入 Druid。</li>
<li>数据可视化，由 Druid 负责计算指标并通过 Web Server 配合前端完成数据可视化。</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/FFA-2019/Flink%E5%9C%A8%E5%BF%AB%E6%89%8B%E5%AE%9E%E6%97%B6%E5%A4%9A%E7%BB%B4%E5%88%86%E6%9E%90%E5%9C%BA%E6%99%AF%E7%9A%84%E5%BA%94%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/FFA-2019/Flink%E5%9C%A8%E5%BF%AB%E6%89%8B%E5%AE%9E%E6%97%B6%E5%A4%9A%E7%BB%B4%E5%88%86%E6%9E%90%E5%9C%BA%E6%99%AF%E7%9A%84%E5%BA%94%E7%94%A8/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink在快手实时多维分析场景的应用"><a href="#Flink在快手实时多维分析场景的应用" class="headerlink" title="Flink在快手实时多维分析场景的应用"></a>Flink在快手实时多维分析场景的应用</h1><p><img src="vx_images/3309049613978" alt="图片">  </p>
<p>分享嘉宾：董亭亭、徐明 快手</p>
<p>编辑整理：王洪达</p>
<p>内容来源：Flink Forward Asia</p>
<p>出品平台：Flink中文社区、DataFunTalk</p>
<p><strong>导读：</strong>作为短视频分享跟直播的平台，快手有诸多业务场景应用了 Flink，包括短视频、直播的质量监控、用户增长分析、实时数据处理、直播 CDN 调度等。此次主要介绍在快手使用 Flink 在实时多维分析场景的应用与优化。</p>
<p><strong>主要内容包括：</strong></p>
<ul>
<li><p>  Flink 在快手应用场景及规模</p>
</li>
<li><p>  快手实时多维分析平台</p>
</li>
<li><p>  SlimBase-更省 IO、嵌入式共享 state 存储</p>
</li>
</ul>
<p><strong>01</strong></p>
<p><strong>Flink 在快手应用场景及规模</strong></p>
<p>首先看 Flink 在快手的应用场景和规模。</p>
<p><strong>1. 快手应用场景</strong></p>
<p><img src="vx_images/3248644693883" alt="图片">  </p>
<p>快手计算链路是从 DB/Binlog 以及 WebService Log 实时入到 Kafka 中，然后接入 Flink 做实时计算，其中包括实时数仓、实时分析以及实时训练，最后的结果存到 Druid、Kudu、HBase 或者 ClickHouse 里面；同时 Kafka 数据实时 Dump 一份到 Hadoop 集群，然后通过 Hive、MapReduce 或者 Spark 来做离线计算；最终实时计算和离线计算的结果数据会用内部自研 BI 工具 KwaiBI 来展现出来。</p>
<p><img src="vx_images/3186855898433" alt="图片"></p>
<p>Flink 在快手典型的应用场景主要分为三大类：</p>
<ul>
<li><p>  80% 统计监控：实时统计，包括各项数据的指标，监控项报警，用于辅助业务进行实时分析和监控；</p>
</li>
<li><p>  15% 数据处理：对数据的清洗、拆分、Join 等逻辑处理，例如大 Topic 的数据拆分、清洗；</p>
</li>
<li><p>  5% 数据处理：实时业务处理，针对特定业务逻辑的实时处理，例如实时调度。</p>
</li>
</ul>
<p><img src="vx_images/3138367056731" alt="图片"></p>
<p>Flink 在快手应用的典型场景案例包括：</p>
<ul>
<li><p>  快手是分享短视频跟直播的平台，快手短视频、直播的质量监控是通过 Flink 进行实时统计，比如直播观众端、主播端的播放量、卡顿率、开播失败率等跟直播质量相关的多种监控指标；</p>
</li>
<li><p>  用户增长分析，实时统计各投放渠道拉新情况，根据效果实时调整各渠道的投放量；</p>
</li>
<li><p>  实时数据处理，广告展现流、点击流实时 Join，客户端日志的拆分等；</p>
</li>
<li><p>  直播 CDN 调度，实时监控各 CDN 厂商质量，通过 Flink 实时训练调整各个 CDN 厂商流量配比。</p>
</li>
</ul>
<p><strong>2. Flink 集群规模</strong></p>
<p><img src="vx_images/3087838210240" alt="图片"></p>
<p>快手目前集群规模有 1500 台左右，日处理条目数总共有3万亿，峰值处理条目数大约是 3亿/s 左右。集群部署都是 On Yarn 模式，实时集群和离线集群混合部署，通过 Yarn 标签进行物理隔离，实时集群是 Flink 专用集群，针对隔离性、稳定性要求极高的业务部署。注：本文所涉及数据仅代表嘉宾分享时的数据。</p>
<p><strong>02</strong></p>
<p><strong>快手实时多维分析平台</strong></p>
<p>此处重点和大家分享下快手的实时多维分析平台。</p>
<p><strong>1. 快手实时多维分析场景</strong></p>
<p><img src="vx_images/3017004484190" alt="图片"></p>
<p>快手内部有这样的应用场景，每天的数据量在百亿级别，业务方需要在数据中任选五个以内的维度组合进行全维的建模进而计算累计的 PV ( Page View 访问量 )、UV ( Unique Visitor 独立访客 )、新增或者留存等这样的指标，然后指标的计算结果要实时进行图形化报表展示供给业务分析人员进行分析。</p>
<p><strong>2. 方案选型</strong></p>
<p><img src="vx_images/2947233836683" alt="图片"></p>
<p>现在社区已经有一些 OLAP 实时分析的工具，像 Druid 和 ClickHouse；目前快手采用的是 Flink+Kudu 的方案，在前期调研阶段对这三种方案从计算能力、分组聚合能力、查询并发以及查询延迟四个方面结合实时多维查询业务场景进行对比分析：</p>
<ul>
<li><p>  计算能力方面：多维查询这种业务场景需要支持 Sum、Count 和 count distinct 等能力，而 Druid 社区版本不支持 count distinct，快手内部版本支持数值类型、但不支持字符类型的 count distinct；ClickHouse 本身全都支持这些计算能力；Flink 是一个实时计算引擎，这些能力也都具备。</p>
</li>
<li><p>  分组聚合能力方面：Druid 的分组聚合能力一般，ClickHouse 和 Flink 都支持较强的分组聚合能力。</p>
</li>
<li><p>  查询并发方面：ClickHouse 的索引比较弱，不能支持较高的查询并发，Druid 和 Flink 都支持较高的并发度，存储系统 Kudu，它也支持强索引以及很高的并发。</p>
</li>
<li><p>  查询延迟方面：Druid 和 ClickHouse 都是在查询时进行现计算，而 Flink+Kudu 方案，通过 Flink 实时计算后将指标结果直接存储到 Kudu 中，查询直接从 Kudu 中查询结果而不需要进行计算，所以查询延迟比较低。</p>
</li>
</ul>
<p><img src="vx_images/2895917117288" alt="图片"></p>
<p>采用 Flink+Kudu 的方案主要思想是借鉴了 Kylin 的思路，Kylin 可以指定很多维度和指标进行离线的预计算然后将预计算结果存储到 HBase 中；快手的方案是通过 Flink 实时计算指标，再实时地写到 Kudu 里面。</p>
<p><strong>3. 方案设计</strong></p>
<p><img src="vx_images/2845440202475" alt="图片"></p>
<p>实时多维分析的整体的流程为：用户在快手自研的 BI 分析工具 KwaiBI 上配置 Cube 数据立方体模型，指定维度列和指标列以及基于指标做什么样的计算；配置过程中选择的数据表是经过处理过后存储在实时数仓平台中的数据表；然后根据配置的计算规则通过 Flink 任务进行建模指标的预计算，结果存储到 Kudu 中；最后 KwaiBI 从 Kudu 中查询数据进行实时看板展示。</p>
<p>接下来详细介绍一下实时多维分析的主要模块。</p>
<p><strong>① 数据预处理</strong></p>
<p><img src="vx_images/2786477962198" alt="图片"></p>
<p>KwaiBI 配置维度建模时选择的数据表，是经过提前预处理的：</p>
<ul>
<li><p>  首先内部有一个元信息系统，在元信息系统中提供统一的 schema 服务，所有的信息都被抽象为逻辑表；</p>
</li>
<li><p>  例如 Kafka 的 topic、Redis、HBase 表等元数据信息都抽取成 schema 存储起来；</p>
</li>
<li><p>  快手 Kafka 的物理数据格式大部分是 Protobuf 和 Json 格式，schema 服务平台也支持将其映射为逻辑表；</p>
</li>
<li><p>  用户只需要将逻辑表建好之后，就可以在实时数仓对数据进行清洗和过滤。</p>
</li>
</ul>
<p><strong>② 建模计算指标</strong></p>
<p><img src="vx_images/2715761707926" alt="图片"></p>
<p>数据预处理完成后，最重要的步骤是进行建模指标计算，此处支持 Cube、GroupingSet 方式维度组合来计算小时或者天累计的 UV ( Unique Visitor )、新增和留存等指标，可以根据用户配置按固定时间间隔定期输出结果；维度聚合逻辑中，通过逐层降维计算的方式会让 DAG 作业图十分复杂，如上图右上角模型所示；因此快手设计了两层降维计算模型，分为全维度层和剩余维度层，这样既利用了全维度层的聚合结果又简化了 DAG 作业图。</p>
<p><img src="vx_images/2665939107897" alt="图片"></p>
<p>以 UV 类指标计算举例，两个黄色虚线框分别对应两层计算模块：全维计算和降维计算。</p>
<ul>
<li><p>  全维计算分为两个步骤，为避免数据倾斜问题，首先是维度打散预聚合，将相同的维度值先哈希打散一下。因为 UV 指标需要做到精确去重，所以采用 Bitmap 进行去重操作，每分钟一个窗口计算出增量窗口内数据的 Bitmap 发送给第二步按维度全量聚合；在全量聚合中，将增量的 Bitmap 合并到全量 Bitmap 中最终得出准确的 UV 值。然而有人会有问题，针对用户 id 这种的数值类型的可以采用此种方案，但是对于 deviceid 这种字符类型的数据应该如何处理？实际上在源头，数据进行维度聚合之前，会通过字典服务将字符类型的变量转换为唯一的 Long 类型值，进而通过 Bitmap 进行去重计算 UV。</p>
</li>
<li><p>  降维计算中，通过全维计算得出的结果进行预聚合然后进行全量聚合，最终将结果进行输出。</p>
</li>
</ul>
<p><img src="vx_images/2615384737072" alt="图片"></p>
<p>再重点介绍下，建模指标计算中的几个关键点。在建模指标计算中，为了避免维度数据倾斜问题，通过预聚合 ( 相同维度 hash 打散 ) 和全量聚合 ( 相同维度打散后聚合 ) 两种方式来解决；为了解决 UV 精确去重问题，前文有提到，使用 Bitmap 进行精确去重，通过字典服务将 String 类型数据转换成 Long 类型数据进而便于存储到 Bitmap 中，因为统计 UV 要统计历史的数据，比如说按天累计，随着时间的推移，Bitmap 会越来越大，在 Rocksdb 状态存储下，读写过大的 KV 会比较耗性能，所以内部自定义了一个 BitmapState，将 Bitmap 进行分块存储，一个 blockid 对应一个局部的 bitmap，这样在 RocksDB 中存储时，一个 KV 会比较小，更新的时候也只需要根据 blockid 更新局部的 bitmap 就可以而不需要全量更新。</p>
<p><img src="vx_images/2554301074442" alt="图片"></p>
<p>接下来，看新增类的指标计算，和刚刚 UV 的不同点是需要判断是否为新增用户，通过异步地访问外部的历史用户服务进行新增用户判断，再根据新增用户流计算新增 UV，这块计算逻辑和 UV 计算一致。</p>
<p><img src="vx_images/2504273316016" alt="图片"></p>
<p>然后，再来看留存类指标计算，与 UV 计算不同的时候，不仅需要当天的数据还需要前一天的历史数据，这样才能计算出留存率，内部实现的时候是采用双 buffer state 存储，在计算的时候将双 buffer 数据相除就可以计算出留存率。</p>
<p><strong>③ Kudu 存储</strong></p>
<p><img src="vx_images/2404440711252" alt="图片"></p>
<p>最后经过上面的计算逻辑后，会将结果存储到 Kudu 里面，其本身具有低延迟随机读写以及快速列扫描等特点，很适合实时交互分析场景；在存储方式上，首先对维度进行编码，然后按时间+维度组合+维度值组合作为主键，最终按维度组合、维度值组合、时间进行分区，这样有利于提高查询的效率快速获取到数据。</p>
<p><strong>4. KwaiBI 展示</strong></p>
<p><img src="vx_images/2353652508850" alt="图片"></p>
<p>界面为配置 Cube 模型的截图，配置一些列并指定类型，再通过一个 SQL 语句来描述指标计算的逻辑，最终结果也会通过 KwaiBI 展示出来。</p>
<p><strong>03</strong></p>
<p><strong>SlimBase</strong></p>
<p>更省 IO、嵌入式共享 state 存储</p>
<p>接下来介绍一种比 RocksDB 更省 IO、嵌入式的共享 state 存储引擎：SlimBase。</p>
<p><strong>1. 面临的挑战</strong></p>
<p><img src="vx_images/2303205608310" alt="图片"></p>
<p>首先看一下 Flink 使用 RocksDB 遇到的问题，先阐述一下快手的应用场景、广告展现点击流实时 Join 场景：打开快手 App 可能会收到广告服务推荐的广告视频，用户可能会点击展现的广告视频。这样的行为在后端会形成两份数据流，一份是广告展现日志，一份是客户端点击日志。这两份数据进行实时 Join，并将 Join 结果作为样本数据用于模型训练，训练出的模型会被推送到线上的广告服务。该场景下展现以后20分钟的点击被认为是有效点击，实时 Join 逻辑则是点击数据 Join 过去20分钟内的展现。其中，展现流的数据量相对比较大，20分钟数据在 1TB 以上。检查点设置为五分钟，Backend 选择 RocksDB。</p>
<p><img src="vx_images/2251794482474" alt="图片"></p>
<p>在这样的场景下，面临着磁盘 IO 开销70%，其中50%开销来自于 Compaction；在 Checkpoint 期间，磁盘 IO 开销达到了100%，耗时在1~5分钟，甚至会长于 Checkpoint 间隔，业务能明显感觉到反压。经过分析找出问题：</p>
<ul>
<li><p>  首先，在 Checkpoint 期间会产生四倍的大规模数据拷贝，即：从 RocksDB 中全量读取出来然后以三副本形式写入到 HDFS 中；</p>
</li>
<li><p>  其次，对于大规模数据写入，RocksDB 的默认 Level Compaction 会有严重的 IO 放大开销。</p>
</li>
</ul>
<p><strong>2. 解决方案</strong></p>
<p><img src="vx_images/2192798860934" alt="图片"></p>
<p>由于出现上文阐述的问题，开始寻找解决方案，整体思路是在数据写入时直接落地到共享存储中，避免 Checkpoint 带来的数据拷贝问题。手段是尝试使用更省 IO 的 Compaction，例如使用 SizeTieredCompation 方式，或者利用时序数据的特点使用并改造 FIFOCompaction。综合比较共享存储、SizeTieredCompation、基于事件时间的 FIFOCompaction 以及技术栈四个方面得出共识：HBase 代替 RocksDB 方案。</p>
<ul>
<li><p>  共享存储方面，HBase 支持， RocksDB 不支持</p>
</li>
<li><p>  SizeTieredCompation 方面，RocksDB 默认不支持，但 HBase 默认支持，开发起来比较简单</p>
</li>
<li><p>  基于事件时间下推的 FIFOCompaction 方面，RocksDB 不支持，但 HBase 开发起来比较简单</p>
</li>
<li><p>  技术栈方面，RocksDB 使用 C++，HBase 使用 java，HBase 改造起来更方便</p>
</li>
</ul>
<p><img src="vx_images/2141566766794" alt="图片"></p>
<p>但是 HBase 有些方面相比 RocksDB 较差：</p>
<ul>
<li><p>  HBase 是一个依赖 zookeeper、包含 Master 和 RegionServer 的重量级分布式系统；而 RocksDB 仅是一个嵌入式的 Lib 库，很轻量级。</p>
</li>
<li><p>  在资源隔离方面，HBase 比较困难，内存和 cpu 被多个 Container 共享；而 RocksDB 比较容易，内存和 cpu 伴随 Container 天生隔离。</p>
</li>
<li><p>  网络开销方面，因为 HBase 是分布式的，所有比嵌入式的 RocksDB 开销要大很多。</p>
</li>
</ul>
<p>综合上面几点原因，快手达成了第二个共识，将 HBase 瘦身，改造为嵌入式共享存储系统。</p>
<p><strong>3. 实现方案</strong></p>
<p><img src="vx_images/2091556896608" alt="图片"></p>
<p>接下来介绍一下将 HBase 改造成 SlimBase 的实现方案，主要是分为两层：</p>
<ul>
<li><p>  一层是 SlimBase 本身，包含三层结构：Slim HBase、适配器以及接口层；</p>
</li>
<li><p>  另一层是 SlimBaseStateBackend，主要包含 ListState、MapState、ValueState 和 ReduceState。</p>
</li>
</ul>
<p>后面将从 HBase 瘦身、适配并实现操作接口以及实现 SlimBaseStateBackend 三个步骤分别进行详细介绍。</p>
<p><strong>① HBase 瘦身</strong>  </p>
<p><img src="vx_images/2041508082264" alt="图片"></p>
<p>先讲 HBase 瘦身，主要从减肥和增瘦两个步骤，在减肥方面：</p>
<ul>
<li><p>  先对 HBase 进行减裁，去除 client、zookeeper 和 master，仅保留 RegionServer</p>
</li>
<li><p>  再对 RegionServer 进行剪裁，去除 ZK Listener、Master Tracker、Rpc、WAL 和 MetaTable</p>
</li>
<li><p>  仅保留 RegionServer 中的 Cache、Memstore、Compaction、Fluster 和 Fs</p>
</li>
</ul>
<p>在增瘦方面：</p>
<ul>
<li><p>  将原来 Master 上用于清理 Hfile 的 HFileCleaner 迁移到 RegionServer 上</p>
</li>
<li><p>  RocksDB 支持读放大写的 merge 接口，但是 SlimBase 是不支持的，所以要实现 merge 的接口</p>
</li>
</ul>
<p><img src="vx_images/1990409535786" alt="图片"></p>
<p>接口层主要有以下三点实现：</p>
<ul>
<li><p>  仿照 RocksDB，逻辑视图分为两级：DB 和 ColumnFamily</p>
</li>
<li><p>  支持一些基本的接口：put/get/delete/merge 和 snapshot</p>
</li>
<li><p>  额外支持了 restore 接口，用于从 snapshot 中恢复</p>
</li>
</ul>
<p>适配层主要有以下两个概念：</p>
<ul>
<li><p>  一个 SlimBase 适配为 Hbase 的 namespace</p>
</li>
<li><p>  一个 SlimBase 的 ColumnFamily 适配为 HBase 的 table</p>
</li>
</ul>
<p><img src="vx_images/1941680849144" alt="图片"></p>
<p>SlimBaseStateBackend 实现上主要体现在两个方面：</p>
<ul>
<li><p>  一是多种 States 实现，支持多种数据结构，ListState、MapState、ValueState 和 ReduceState</p>
</li>
<li><p>  二是改造 Snapshot 和 Restore 的流程，从下面的两幅图可以看出，SlimBase 在磁盘 IO 上节省了大量的资源，避免了多次的 IO 的问题。</p>
</li>
</ul>
<p><strong>4. 测试结论</strong></p>
<p><img src="vx_images/1891216900740" alt="图片"></p>
<p>上线对比测试后，得出测试结论：</p>
<ul>
<li><p>  Checkpoint 和 Restore 的时延从分钟级别降到秒级。</p>
</li>
<li><p>  磁盘 IO 下降了66%</p>
</li>
<li><p>  磁盘写吞吐下降50%</p>
</li>
<li><p>  CPU 开销下降了33%</p>
</li>
</ul>
<p><strong>5. 后期优化</strong></p>
<p><img src="vx_images/1840293574989" alt="图片"></p>
<p>目前用的 Compaction 策略是 SizeTieredCompaction，后期要实现基于 OldestUnexpiredTime 的 FiFOCompaction 策略，目标是做到无磁盘 IO 开销。</p>
<p><strong>FiFOCompaction</strong> 是一种基于 TTL 的无 IO 的 Compaction 策略；<strong>OldestUnexpiredTime</strong> 是指例如设置 OldestUnexpiredTime=t2，表示 t2 时刻前的数据全部过期，可以被 Compaction 清理，基于时间点的 FIFOCompaction 理论上可以做到无磁盘 IO 开销。</p>
<p><img src="vx_images/1768984785897" alt="图片"></p>
<p>后续还有四点优化，前三点是基于 HBase 的优化，最后是针对 HDFS 做的优化：</p>
<ul>
<li><p>  SlimBase 使用 InMemoryCompaction，降低内存 Flush 和 Compaction 开销</p>
</li>
<li><p>  SlimBase 支持 prefixBloomFilter，提高 Scan 性能</p>
</li>
<li><p>  SlimBase 支持短路读</p>
</li>
<li><p>  HDFS 副本落盘改造：非本地副本使用 DirectIO 直接落盘，提高本地读 pagecache 命中率；此条主要是在测试使用时发现单副本比多副本读写效率高这一问题</p>
</li>
</ul>
<p><strong>6. 未来规划</strong></p>
<p><img src="vx_images/1650802228374" alt="图片"></p>
<p>从语言、存储、压缩策略、事件事件下推、垃圾回收、检查点时间、重加载时间七个方面来看，SlimBase 都比 RocksDB 更适合快手实时计算任务的开发，未来的规划是对 SlimBase 的性能做进一步优化，愿景是将快手 Flink 上的所有业务场景全部用 SlimBase 替代掉 RocksDB。</p>
<p><strong>分享嘉宾：</strong></p>
<p>董亭亭，快手实时计算引擎团队负责人。  </p>
<p>徐明，快手大数据架构研发工程师。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/FFA-2019/bilibili%E5%AE%9E%E6%97%B6%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%9E%B6%E6%9E%84%E5%92%8C%E5%AE%9E%E8%B7%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/FFA-2019/bilibili%E5%AE%9E%E6%97%B6%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%9E%B6%E6%9E%84%E5%92%8C%E5%AE%9E%E8%B7%B5/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="bilibili实时平台的架构和实践"><a href="#bilibili实时平台的架构和实践" class="headerlink" title="bilibili实时平台的架构和实践"></a>bilibili实时平台的架构和实践</h1><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/745196">文章地址</a></p>
<p>Saber实时计算平台</p>
<h2 id="实时计算的痛点"><a href="#实时计算的痛点" class="headerlink" title="实时计算的痛点"></a>实时计算的痛点</h2><h3 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h3><ul>
<li>各个部门语言种类和体系不通，管理维护非常困难</li>
<li>用户增长、渠道投放的分析等 BI 分析任务 需要对实时数仓的实时数据进行清洗</li>
<li>AI 推荐场景下的实时计算需求也比较强烈</li>
</ul>
<h3 id="痛点共性"><a href="#痛点共性" class="headerlink" title="痛点共性"></a>痛点共性</h3><ul>
<li>开发门槛高<br>  环境配置、语言基础、编码可靠性、代码质量，引擎多</li>
<li>运维成本<br>  统一的监控告警体系: 计算延时、断流、波动、故障切换</li>
<li>AI实时工程<br>  AI团队承担更多工程的工作</li>
</ul>
<h3 id="Saber-基于Flink的流式计算平台"><a href="#Saber-基于Flink的流式计算平台" class="headerlink" title="Saber-基于Flink的流式计算平台"></a>Saber-基于Flink的流式计算平台</h3><p>目标:</p>
<ul>
<li>对 SQL 进行了扩展，称为 BSQL。BSQL 扩展了 Flink 底层 SQL 的上层，即 SQL 语法层。</li>
<li>DAG 拖拽编程,一方面用户可以通过画板来构建自己的 Pipeline，另一方面用户也可以使用原生 Jar 方式进行编码。</li>
<li>作业的一体化托管运维</li>
</ul>
<p>场景:</p>
<ul>
<li>流式Joiner和维表Joiner: AI工程方向，解决了广告、搜索、推荐</li>
<li>实时计算的特征支持，支持 Player 以及 CDN 的质量监控。包括直播、PCU、卡顿率、CDN 质量等；</li>
<li>用户增长，即如何借助实时计算进行渠道分析、调整渠道投放效果；</li>
<li>实时 ETL，包括 Boss 实时播报、实时大屏、看板等。</li>
</ul>
<h2 id="Saber的平台演进"><a href="#Saber的平台演进" class="headerlink" title="Saber的平台演进"></a>Saber的平台演进</h2><h3 id="平台架构"><a href="#平台架构" class="headerlink" title="平台架构"></a>平台架构</h3><p>实时传输 + 实时计算<br>统一管理元数据、血缘、权限和作业运维<br>基于BSQL</p>
<p><img src="vx_images/3126005169499.png"></p>
<p>实时传输有 APP 日志、数据库 Binlog、服务端日志或系统日志。bilibili 内部的 Lancer 系统解决数据落地到 Kafka 或 HDFS。<br>计算体系主要围绕 Saber 构建一套 BSQL，底层基于 YARN 进行调度管理。</p>
<p>多种维表-MySQL、Redis、HBase<br>Flink的状态在RocksDB基础上，扩展了MapDB、Redis</p>
<p>Flink 需要 IO 密集是很麻烦的问题，因为 Flink 的资源调度体系内有内存和 CPU，但 IO 单位未做统一管理。当某一个作业对 IO 有强烈的需求时，需要分配很多以 CPU 或内存为单位的资源，且未必能够很好的满足 IO 的扩展。所以本质上 bilibili 现阶段是将 IO 密集的资源的 State 转移到 Redis 上做缓解。数据经过 BSQL 计算完成之后传输到实时数仓，如 Kafka、HBase、ES 或 MySQL、TiDB。最终到 AI 或 BI、报表以及日志中心。</p>
<h3 id="开发架构"><a href="#开发架构" class="headerlink" title="开发架构"></a>开发架构</h3><h4 id="开发结构图"><a href="#开发结构图" class="headerlink" title="开发结构图"></a>开发结构图</h4><p><img src="vx_images/4025499727022.png"></p>
<ul>
<li>Saber-Streamer: 作业提交和API管理</li>
<li>BSQL: SQL的扩展和解释，包括自定义算子和个性算子</li>
<li>运行时: Spark Streaming –&gt; Flink</li>
</ul>
<h4 id="平台设计"><a href="#平台设计" class="headerlink" title="平台设计"></a>平台设计</h4><ul>
<li>对streaming workflows进行抽象</li>
<li>数据规范化，保证schema完整</li>
<li>BSQL解析层</li>
<li>工厂效率</li>
</ul>
<p><strong>Streaming workflows</strong></p>
<p>大数据计算引擎的本质是数据输入经过一个 function 得到输出，所以 function 本质是一个能够做 DAG 转换的 Transform。Saber 平台期望的流计算抽象形态是提供相应的 Source，计算过程中是一个 Transform 的 DAG，最后有一个 Sink 的输出。</p>
<p><img src="vx_images/307515516114.png"></p>
<p><strong>让数据说话</strong></p>
<p>数据抽象化。计算过程中的数据源于数据集成的上报。用户首先需要在平台上构建一个输入的数据源。用户选择了一个对应的数据源，平台可以将其分发到 Kafka、 HBase、 Hive 等，并且在分发过程中要求用户定义 Schema。所以在数据集成过程中，可以轻松地管理输入语言的 Schema。计算过程中，用户选择 Input Source，比如选择一个 HBase 的表或 Kafka 的表，此时 Schema 已是强约束的。用户通过平台提供的 BSQL 或者 DAG 的方式进行结果表或者指标的输出。</p>
<p><strong>BSQL通用设计</strong></p>
<p>BSQL 更多是在 Source 和 Sink 上进行分装，支持 DDL 的分装。此处 DDL 参照阿里云对外资料进行了扩展。另外，BSQL 针对计算过程进行了优化，如针对算子计算的数据倾斜问题采取分桶 + hash 策略进行打扫。针对 distinct 类 count，非精准计算采用 Redis 的 HyperLogLog。</p>
<p><strong>BSQL解析模型</strong></p>
<p>将 SQL 转化成树。之后可以获取 SqlNode 节点。SqlNode 节点中有很多元数据信息。在 SqlNode 树的情况下实现 Table 解析器，将不同的 SqlNode 节点转化成 Flink 相应的 Streamer 进行映射。</p>
<p><img src="vx_images/1638852841865.jpeg" alt="640-11.jpeg"></p>
<p><strong>BSQL 执行流程</strong></p>
<ul>
<li>进行验证并构建 SQL 树。验证与构建主要是提取表名、字段信息，从元数据库中提取 schema 验证 SQL 的规范性、完整性和合法性</li>
<li>将输入表和结果表注册到 Flink 的运行时态，其中还包括 UDF 和 watermark 信息的完善。</li>
</ul>
<p>另外，平台对 SQL 有一些扩展。第三块是扩展的核心工作，将 SQL 树中扩展的子树转换为新的节点，然后将 SQL 的 DAG 提交到 Flink 上运<br>行。</p>
<p><strong>作业测试</strong></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/rtc/%E5%AE%9E%E6%97%B6OLAP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/rtc/%E5%AE%9E%E6%97%B6OLAP/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="实时OLAP"><a href="#实时OLAP" class="headerlink" title="实时OLAP"></a>实时OLAP</h1><h2 id="Apache-Pinot-Uber"><a href="#Apache-Pinot-Uber" class="headerlink" title="Apache Pinot (Uber)"></a>Apache Pinot (Uber)</h2><p>Pinot 是一个实时分布式的 OLAP 数据存储和分析系统。使用它实现低延迟可伸缩的实时分析。Pinot 从脱机数据源（包括 Hadoop 和各类文件）和在线数据源（如 Kafka）中获取数据进行分析。Pinot 被设计成可进行水平扩展。Pinot 特别适合这样的数据分析场景：查询具有大量维度和指标的时间序列数据、分析模型固定、数据只追加以及低延迟，以及分析结果可查询。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/rtc/%E5%AE%9E%E6%97%B6%E5%BC%80%E5%8F%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/rtc/%E5%AE%9E%E6%97%B6%E5%BC%80%E5%8F%91/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="实时开发"><a href="#实时开发" class="headerlink" title="实时开发"></a>实时开发</h1><p>开源项目:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/DTStack/flinkx">https://github.com/DTStack/flinkx</a></p>
<p>公司内资源:</p>
<p>ETL</p>
<p><a target="_blank" rel="noopener" href="https://git.code.oa.com/xone/bigdata/XoneFlinkPlugin">https://git.code.oa.com/xone/bigdata/XoneFlinkPlugin</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/rtc/2020%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/rtc/2020%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="2020实时计算技术前瞻"><a href="#2020实时计算技术前瞻" class="headerlink" title="2020实时计算技术前瞻"></a>2020实时计算技术前瞻</h1><ul>
<li><p>开发/管控</p>
</li>
<li><p>ETL</p>
</li>
<li><p>湖/仓</p>
</li>
<li><p>HSAP(湖、仓、流、批、OLTP、OLAP)</p>
</li>
</ul>
<p>[TOC]</p>
<p><strong>现状:</strong></p>
<p>阿里内部离线实时比例为2:1，腾讯不到10:1, FiT不到100:1</p>
<h2 id="开发-管控"><a href="#开发-管控" class="headerlink" title="开发/管控"></a>开发/管控</h2><p>元数据管理<br>可视化开发、SQL、<br>结果验证与开放查询<br>监控</p>
<p>下半年，除了微信外，全部迁移到Oceanus</p>
<p>系统难点:</p>
<p>元数据</p>
<h3 id="技术方案"><a href="#技术方案" class="headerlink" title="技术方案"></a>技术方案</h3><ul>
<li>Standalone flink session</li>
<li>flink on yarn session</li>
<li>flink on yarn perjob</li>
<li>standalone flink session on k8s</li>
<li>native flink session on k8s</li>
</ul>
<h4 id="AthenaX-Oceanus方案"><a href="#AthenaX-Oceanus方案" class="headerlink" title="AthenaX(Oceanus方案)"></a>AthenaX(Oceanus方案)</h4><h4 id="Zeppelin"><a href="#Zeppelin" class="headerlink" title="Zeppelin"></a>Zeppelin</h4><p><img src="_v_images/20201026123822607_16171.png"></p>
<h4 id="Flink-sql-gateway-ververica官方"><a href="#Flink-sql-gateway-ververica官方" class="headerlink" title="Flink-sql-gateway(ververica官方)"></a>Flink-sql-gateway(ververica官方)</h4><h4 id="beam"><a href="#beam" class="headerlink" title="beam"></a>beam</h4><h4 id="Google-dataflow"><a href="#Google-dataflow" class="headerlink" title="Google dataflow"></a>Google dataflow</h4><h3 id="建议方案"><a href="#建议方案" class="headerlink" title="建议方案"></a>建议方案</h3><p>基于Oceanus:</p>
<p>2021年，除了微信外，腾讯的实时集群将全部迁移到Oceanus</p>
<p><img src="_v_images/20201025201758792_1563726055.png"></p>
<h2 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h2><p>指标数据存储可以大体分为点查询和分析查询:</p>
<p>点查询: 以kv存储或支持个性索引方式的存储: 如HBase、Redis、LevelDB、Tair(腾讯的TDE、美团的Cellar)<br>分析查询:  ES/Impala/Kudu/Druid/</p>
<p>业界难点与解决方案：</p>
<ul>
<li>动态CEP: 基于session方案</li>
<li>巨大状态以及离线数据与状态打通：阿里方案</li>
<li>实时在线分析: 启动引起延迟: 基于kafka-streaming或采样方案(头条)</li>
<li>大流join: 与数据湖结合方案</li>
<li>TaskManager快速失败(失心跳、OOM、)自动诊断系统</li>
<li>Hive+Flink: </li>
<li>Flink+机器学习: Alink</li>
</ul>
<h2 id="实时数仓-实时多维分析"><a href="#实时数仓-实时多维分析" class="headerlink" title="实时数仓/实时多维分析"></a>实时数仓/实时多维分析</h2><p>流式引擎-&gt;分析引擎-&gt;可视化层(大屏、报表)</p>
<p>$$<br>实时数仓 = 实时ETL + 分层<br>$$</p>
<p><img src="_v_images/20201025195812116_131156870.png"></p>
<p>业务痛点: 实时性、避免重复计算、避免报表高峰期</p>
<p>技术无难点: 重在olap引擎, 百花齐放难统一</p>
<h3 id="业内"><a href="#业内" class="headerlink" title="业内"></a>业内</h3><h4 id="菜鸟"><a href="#菜鸟" class="headerlink" title="菜鸟"></a>菜鸟</h4><p><img src="_v_images/20201024082719245_54033306.png"></p>
<p>天工 – API网关，隐藏存储引擎</p>
<h4 id="知乎"><a href="#知乎" class="headerlink" title="知乎"></a>知乎</h4><p><img src="_v_images/20201025192726642_972956146.png"></p>
<p>olap选择的是Druid</p>
<h4 id="美团"><a href="#美团" class="headerlink" title="美团"></a>美团</h4><p><img src="_v_images/20201025192931947_870030501.png"></p>
<p>OLAP引擎选择的是Druid</p>
<h4 id="网易"><a href="#网易" class="headerlink" title="网易"></a>网易</h4><p><img src="_v_images/20201025192953009_386477884.png"></p>
<p><img src="_v_images/20201025193155868_1543247860.png"></p>
<p>Doris</p>
<h2 id="HSAP-湖、仓、流、批、OLTP、OLAP"><a href="#HSAP-湖、仓、流、批、OLTP、OLAP" class="headerlink" title="HSAP(湖、仓、流、批、OLTP、OLAP)"></a>HSAP(湖、仓、流、批、OLTP、OLAP)</h2><h3 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h3><h4 id="Druid"><a href="#Druid" class="headerlink" title="Druid"></a>Druid</h4><p><img src="_v_images/20201025210003428_897401023" alt="在这里插入图片描述"><br>Druid 整体架构</p>
<p>Druid是一个高效的数据查询系统，主要解决的是对于大量的基于时序的数据进行聚合查询。数据可以实时摄入，进入到Druid后立即可查，同时数据是几乎是不可变。通常是基于时序的事实事件，事实发生后进入Druid，外部系统就可以对该事实进行查询。 Druid采用的架构:</p>
<ul>
<li>shared-nothing架构与lambda架构</li>
</ul>
<p>Druid设计的三个原则:</p>
<ul>
<li>快速查询：部分数据聚合（Partial Aggregate） + 内存化（In-Memory） + 索引（Index）</li>
<li>水平拓展能力：分布式数据（Distributed data）+并行化查询（Parallelizable Query）</li>
<li>实时分析：Immutable Past , Append-Only Future</li>
</ul>
<p>如果你对Druid不了解，请参考这里：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/35146892">https://zhuanlan.zhihu.com/p/35146892</a></p>
<h3 id="HSAP"><a href="#HSAP" class="headerlink" title="HSAP"></a>HSAP</h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/rtc/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/rtc/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="数据中台"><a href="#数据中台" class="headerlink" title="数据中台"></a>数据中台</h1><ol>
<li>pcg datahub</li>
<li>venas</li>
<li>superSet</li>
<li>各个bg的实时开发平台</li>
<li>标签萃取</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/rtc/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/rtc/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h1><p>解决了什么问题<br>优劣势</p>
<h2 id="TEG-基于Iceberg打造T-0实时数仓"><a href="#TEG-基于Iceberg打造T-0实时数仓" class="headerlink" title="TEG 基于Iceberg打造T+0实时数仓"></a>TEG 基于Iceberg打造T+0实时数仓</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/00.prospect/rtc/OLAP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/00.prospect/rtc/OLAP/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 11:49:08" itemprop="dateCreated datePublished" datetime="2021-01-16T11:49:08+08:00">2021-01-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">227</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">107</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
