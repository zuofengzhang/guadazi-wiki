<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/page/11/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/11/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink-local-demo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink-local-demo/" class="post-title-link" itemprop="url">flink local deploy</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-06-06 00:00:00" itemprop="dateCreated datePublished" datetime="2019-06-06T00:00:00+08:00">2019-06-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:15" itemprop="dateModified" datetime="2021-02-09T09:52:15+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink本地部署"><a href="#Flink本地部署" class="headerlink" title="Flink本地部署"></a>Flink本地部署</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-cep/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-cep/" class="post-title-link" itemprop="url">flink cep</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-06-06 00:00:00" itemprop="dateCreated datePublished" datetime="2019-06-06T00:00:00+08:00">2019-06-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:15" itemprop="dateModified" datetime="2021-02-09T09:52:15+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Flink cep</p>
<p>CEP的处理范例引起了人们的极大兴趣，并在各种用例中得到了应用。 最值得注意的是，CEP现在用于诸如股票市场趋势和信用卡欺诈检测等金融应用</p>
<p>模式，从流中查找符合某个pattern的个体事件。<br>可以将一个pattern sequence视为pattern组成的图, 基于用户定义的条件，从一个pattern传递到下一个pattern<br>一个match是事件必须流过复杂pattern图的所有的pattern。</p>
<p><strong>注意</strong></p>
<ul>
<li>每一个pattern必须具有唯一的名称，用于标示符合条件的事件</li>
<li>pattern名称不能包含:</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/failover-recovery/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/failover-recovery/" class="post-title-link" itemprop="url">大规模分布式系统故障恢复和容错架构探究</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-26 00:00:00" itemprop="dateCreated datePublished" datetime="2019-05-26T00:00:00+08:00">2019-05-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:15" itemprop="dateModified" datetime="2021-02-09T09:52:15+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在大规模数据处理的分布式系统中，如何保障数据的高可用、数据的一致性和幂等性(exactly once)是系统的一大难题!<br>使用廉价机器构建集群成为大数据平台的标配，故障恢复和容错（failover recovery）机制成为防止消息丢失和快速恢复服务必不可少的组成部分; 在通用的大数据架构中，也是保障数据高可用、一致性和幂等性的基础。</p>
<p>分布式系统故障恢复需要解决的问题:</p>
<ol>
<li>吞吐量大的场景，当出现了失败时，需要保证失败的数据可以重放，且状态可恢复。</li>
<li>某一个时刻，多个计算节点存在处理速度不一致的问题，一条数据可能经过多个计算节点才能完成计算。如何保存多个计算节点的状态，且保证数据对齐？</li>
<li>如何保证数据经过各个计算节点的顺序性和不重复？</li>
<li>如何回放数据？</li>
</ol>
<p>虽然大规模分布式系统的侧重各不相同，但是failover recovery的机制却如出一辙, 主要有ack模式、异步checkpoint模式、CL模式、补偿模式等，接下来就这四种模式分别总结。</p>
<h1 id="Ack模式"><a href="#Ack模式" class="headerlink" title="Ack模式"></a>Ack模式</h1><p>在分布式系统中，为了确保一条(批)数据被正确处理，且当出现任何故障，保障数据不丢。ack机制是最简单的方式，每一条(批)数据正确处理完后，发送一条确认标示。</p>
<h2 id="TCP-ack"><a href="#TCP-ack" class="headerlink" title="TCP ack"></a>TCP ack</h2><p>在TCP握手时，当收到客户端发起的握手报文时, 返回一个Acknowledgement Number, 标示客户端的请求已经收到，并返回给客户端。<br>而后客户端返回Acknowledgement Number以确保服务端请求正确接受。<br>当网络抖动或者服务器和客户端故障时，报文可能丢失。此时就要依赖于与ack机制相配合的faiover-recovery机制。</p>
<p>如果服务器没有收到客户端的最终ACK确认报文，会一直处于<code>SYN_RECV</code>状态，将客户端IP加入等待列表，<br>并重发<code>SYN+ACK</code>报文。<br>重发一般进行3-5次，大约间隔30秒左右轮询一次等待列表重试所有客户端。<br>另一方面，服务器在自己发出了<code>SYN+ACK</code>报文后，会预分配资源为即将建立的TCP连接储存信息做准备，<br>这个资源在等待重试期间一直保留。更为重要的是，服务器资源有限，可以维护的<code>SYN_RECV</code>状态超过极限后就不再接受新的SYN报文，<br>也就是拒绝新的TCP连接建立。</p>
<p>然而著名的<code>SYNC Flood</code>的DDos攻击正式利用上述的<code>failover-recovery</code>机制。<br>攻击者伪装大量的IP地址给服务器发送SYN报文，由于伪造的IP地址几乎不可能存在，也就几乎没有设备会给服务器返回任何应答了。<br>因此，服务器将会维持一个庞大的等待列表，不停地重试发送SYN+ACK报文，同时占用着大量的资源无法释放。<br>更为关键的是，被攻击服务器的<code>SYN_RECV</code>队列被恶意的数据包占满，不再接受新的SYN请求，合法用户无法完成三次握手建立起TCP连接。<br>也就是说，这个服务器被SYN Flood拒绝服务了。</p>
<p>SYN Flood攻击大量消耗服务器的CPU、内存资源，并占满SYN等待队列。相应的，我们修改内核参数即可有效缓解。主要参数如下：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">net.ipv4.tcp_syncookies</span> = <span class="string">1</span></span><br><span class="line"><span class="meta">net.ipv4.tcp_max_syn_backlog</span> = <span class="string">8192</span></span><br><span class="line"><span class="meta">net.ipv4.tcp_synack_retries</span> = <span class="string">2</span></span><br></pre></td></tr></table></figure>
<p>分别为启用SYN Cookie、设置SYN最大队列长度以及设置SYN+ACK最大重试次数。<br>SYNC Cookie主要是在服务端缓冲基于时间种子的SYN号，只有客户端发送的SYN+ACK与缓冲完全匹配才完成握手，否则直接丢弃。<br><code>tcp_max_syn_backlog</code>则是增加等待队列的长度。</p>
<h2 id="Apache-storm中的ack机制"><a href="#Apache-storm中的ack机制" class="headerlink" title="Apache storm中的ack机制"></a>Apache storm中的ack机制</h2><p>Apache storm是首个真正意义上的流式处理引擎，在spark/Flink出现之前，是实时计算领域的一枝独秀。</p>
<p>storm中是没有checkpoint机制的，但storm以大名鼎鼎的ack算法来保证at least once语义，(在<a target="_blank" rel="noopener" href="http://storm.apache.org/releases/2.0.0-SNAPSHOT/Trident-tutorial.html">Trident</a>出现之前，storm是没有办法保证exactly once语义的)。ack需要spout节点保存每条数据，当所有的计算节点处理完毕，再发送给spout节点，因此与Chandy-Lamport算法相比，每条数据都需要保存和反复发送，而状态和数据回滚需要用户来保证。</p>
<p>实时大数据处理，数据源源不断的流入系统。无法在一个线程中串行的处理并确认一条或一批数据。<br>strom采用的是异步并行处理的模式(这里以JStorm的实现分析),<br>当excutor节点（executor节点是storm的进程，spout和bolt都是executor启动的task线程）收到消息时，首先将消息压入disruptor队列，disruptor的消费者从队列中获取数据，执行转发或者计算。</p>
<p><img src="/images/bigdata/storm/strom-queue.png"></p>
<p>strom引入ack机制来确保数据不丢，但是对系统整体架构也带来了很大的影响，那么问题来了：</p>
<ul>
<li>消息量大，如何保存消息？</li>
<li>消息可能流过多个节点，如何保证每个节点都正确处理？</li>
<li>spout节点重启，如何确保消息不丢失？</li>
<li>消息堆积，如何确保集群的稳定？</li>
</ul>
<p>ack机制是如何巧妙解决这写问题的呢？</p>
<p><img src="https://images2015.cnblogs.com/blog/639357/201612/639357-20161207181349866-1482908747.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A xor A &#x3D; 0.</span><br><span class="line">A xor B … xor B xor A &#x3D; 0，</span><br></pre></td></tr></table></figure>
<p>其中每一个操作数出现且仅出现两次。</p>
<p>strom的ack机制，巧妙的利用了两个相同的值异或为0的原理.</p>
<p>理解下整个大体节奏分为几部分:</p>
<ul>
<li><p>步骤1和2 spout把一条信息同时发送给了bolt1和bolt2，步骤3表示spout emit成功后去 acker bolt里注册本次根消息，ack值设定为本次发送的消息对应的64位id的异或运算值，上图对应的是T1^T2。</p>
</li>
<li><p>步骤4表示bolt1收到T1后，单条tuple被拆成了三条消息T3T4T5发送给bolt3。步骤6 bolt1在ack()方法调用时会向acker bolt提交T1^T3^T4^T5的ack值。</p>
</li>
<li><p>步骤5和7的bolt都没有产生新消息，所以ack()的时候分别向acker bolt提交了T2 和T3^T4^T5的ack值。综上所述，本次spout产生的tuple树对应的ack值经过的运算为 T1^T2^T1^T3^T4^T5^T2^T3^T4^T5按照异或运算的规则，ack值最终正好归零。</p>
</li>
<li><p>步骤8为acker bolt发现根spout最终对应的的ack是0以后认为所有衍生出来的数据都已经处理成功，它会通知对应的spout，spout会调用相应的ack方法。</p>
</li>
</ul>
<p>storm这个机制的实现方式保证了无论一个tuple树有多少个节点，一个根消息对应的追踪ack值所占用的空间大小是固定的，极大地节约了内存空间。</p>
<p>通过ack机制，spout发出的每一条消息，都可以确定是被成功或失败处理。但是，需要备份每条消息，来确认消息是否处理完成，如果消息流过的每个节点都备份数据，总数据量将翻几倍。spout作为消息流入到topology的起点，在这里备份数据既可以节省内存，又可以验证整条链路。此外，Ack机制还常用于<strong>限流</strong>作用： 为了避免spout发送数据太快，而bolt处理太慢，常常设置pending数，当spout有等于或超过pending数的tuple没有收到ack或fail响应时，跳过执行nextTuple， 从而限制spout发送数据。</p>
<p>strom逐条发送逐条处理逐条ack，这也是吞吐量不及spark和flink。</p>
<h1 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>通俗来讲:  就是在分布式系统中，通过状态的checkpoint来确保数据的高可用。</p>
<p>checkpoint俗称检查点，是指定时将数据快照保存到持久化存储介质中，来提供数据的可靠性和与增量文件结合快速恢复数据。</p>
<h2 id="Hadoop-NameNode-的checkpoint"><a href="#Hadoop-NameNode-的checkpoint" class="headerlink" title="Hadoop NameNode 的checkpoint"></a>Hadoop NameNode 的checkpoint</h2><p>NameNode负责管理Hadoop的元数据(workspace信息、blockMap信息、network topology等)信息，是HDFS的心脏。<br>checkpoint机制是NameNode数据故障恢复的方案。</p>
<p><img src="/images/bigdata/hdfs/nameNode_1.x.png" alt="HDFS namenode 1.x"></p>
<p>HDFS 2.x 引入了HA来解决NameNode的单点问题，社区也涌现了多种共享内存方案来保存editlog，而namenode的元数据的数据结构几乎没有变化。</p>
<p><img src="/images/bigdata/hdfs/namenode-workspace-memory.png" alt="name node workspace 内存结构"></p>
<p>workspace信息常驻内存，并定时checkpoint成fsimage文件, 当HDFS-Client发起修改文件目录的请求时，直接修改内存中的数据， 并将修改记录写到editlog文件中。可以将name node的workspace的维护过程简单理解为分布式系统中消息处理的过程，</p>
<h1 id="Chandy-Lamport算法"><a href="#Chandy-Lamport算法" class="headerlink" title="Chandy-Lamport算法"></a>Chandy-Lamport算法</h1><p>在实时流式处理中，简单的使用checkpoint没办法保证exactly once语义，主要是由于在某一个时刻：</p>
<ol>
<li>消息还在处理(没有合并到状态中)，source接收数据的偏移量不能准确的与状态做到数据一致性。</li>
<li>每个子任务处理进度也难以统一。</li>
</ol>
<p>理想情况下，停止接收新数据并排干整个流处理系统，再做checkpoint，才能保证数据一致性和exactly once。停机显然是不可能的！Chandy-Lamport算法使用巧妙的方法，在不停止流处理的前提下拿到每个子任务的状态并checkpoint下来。</p>
<p>著名的一致性算法 Paxos 的作者Leslie Lamport与Chandy合作发表了算法论文: <a target="_blank" rel="noopener" href="https://dl.acm.org/ft_gateway.cfm?id=214456&ftid=20679&dwn=1&CFID=72171565&CFTOKEN=2bfe026b198b5dc8-AEFB79E7-EF87-025C-C01DC78635F21DF8">Distributed snapshots: determining global states of distributed systems</a>, 在该论文中提出了分布式快照算法: <strong>Chandy-Lamport</strong></p>
<blockquote>
<p>A <strong>snapshot algorithm</strong> is used to create a consistent snapshot of the global state of a <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Distributed_system">distributed system</a>. Due to the lack of globally shared memory and a global clock, this isn’t trivially possible.</p>
</blockquote>
<p>Chandy-Lamport算法用于在缺乏全局共享内存和全局时钟的分布式系统中创建一致性的全局分布式快照。而这个算法正是1978年提出的<a target="_blank" rel="noopener" href="http://lamport.azurewebsites.net/pubs/pubs.html?spm=a2c4e.11153940.blogcont688764.10.4f964568O0SyIm#time-clocks"><strong>Time, Clocks and the Ordering of Events in a Distributed System</strong></a>的直接应用。在分布式系统中，为了确保数据在不同计算节点的有序性，引入barrier机制，当相同的barrier到达每一个计算节点时，认为全局节点处理结束。</p>
<p>Chandy-Lamport算法将全局的状态简化为有限个节点以及节点与节点之间的channel组成，也就是有向图。节点是进程，边是channel；分布式系统中，进程运行在不同的物理机器上，一个分布式的系统中的全局状态由进程的状态和channel中的message组成，这些都是分布式快照要保存的内容。</p>
<p>因为是有向图，一个节点的channel包含了input channel和output channel，流经channel的数据源源不断，假设channel是FIFO队列，保证不重复，那么只需要保存每个节点的局部状态和input message的偏移量，合并起来就是全局的分布式快照。</p>
<h2 id="Flink中的Chandy-Lamport算法"><a href="#Flink中的Chandy-Lamport算法" class="headerlink" title="Flink中的Chandy-Lamport算法"></a>Flink中的Chandy-Lamport算法</h2><p>Chandy-Lamport算法在flink中用于实现at least once语义。具体工作流程如下:</p>
<ol>
<li><p>在checkpoint触发时刻，Job Manager会往所有Source的流中放入一个barrier（图中三角形）。barrier包含当前checkpoint的ID<br><img src="https://upload-images.jianshu.io/upload_images/1431048-f1583d01e8fad051.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/521"></p>
</li>
<li><p>当barrier经过一个subtask时，即表示当前这个subtask处于checkpoint触发的“时刻”，他就会立即将barrier法往下游，并执行checkpoint方法将当前的state存入backend storage。图中Source1和Source2就是完成了checkpoint动作。<br><img src="https://upload-images.jianshu.io/upload_images/1431048-29b12d52fb1ccf05.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/523"></p>
</li>
<li><p>如果一个subtask有多个上游节点，这个subtask就需要等待所有上游发来的barrier都接收到，才能表示这个subtask到达了checkpoint触发“时刻”。但所有节点的barrier不一定一起到达，这时候就会面临“是否要对齐barrier”的问题（Barrier Alignment）。如图中的Task1.1，他有2个上游节点，Source1和Source2。假设Source1的barrier先到，这时候Task1.1就有2个选择：</p>
</li>
</ol>
<ul>
<li>是马上把这个barrier发往下游并等待Source2的barrier来了再做checkpoint</li>
<li>还是把Source1这边后续的event全都cache起来，等Source2的barrier来了，在做checkpoint，完了再继续处理Source1和Source2的event，当前Source1这边需要先处理cache里的event。</li>
</ul>
<h1 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h1><p>WAL是一种常见的故障恢复方式，如NameNode的元数据、HBase WAL、kafka消息中间件、SQLite WAL等。</p>
<blockquote>
<p>“In computer science, write-ahead logging (WAL) is a family of techniques for providing atomicity and durability (two of the ACID properties) in database systems.”——维基百科</p>
</blockquote>
<h2 id="HBase中的WAL"><a href="#HBase中的WAL" class="headerlink" title="HBase中的WAL"></a>HBase中的WAL</h2><p>这里介绍一下HBase WAL(write ahead log)机制，Hbase的RegionServer在处理数据插入和删除的过程中用来记录操作内容的一种日志。在每次Put、Delete等一条记录时，首先将其数据写入到RegionServer对应的HLog文件中去。</p>
<p>客户端向RegionServer端提交数据的时候，会先写入WAL日志，只有当WAL日志写入成功的时候，客户端才会被告诉提交数据成功。如果写WAL失败会告知客户端提交失败，这其实就是数据落地的过程。</p>
<p>在一个RegionServer上的所有Region都共享一个HLog，一次数据的提交先写入WAL，写入成功后，再写入menstore之中。当menstore的值达到一定的时候，就会形成一个个StoreFile。<br><img src="https://img-blog.csdn.net/20180419134053354"></p>
<p>WAL记载了每一个RegionServer对应的HLog。RegionServer1或者RegionServer1上某一个regiong挂掉了，都会迁移到其它的机器上处理，重新操作，进行恢复。</p>
<p>当RegionServer意外终止的时候，Master会通过Zookeeper感知到，Master首先会处理遗留下来的HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应的Region目录下，然后再将实效的Region重新分配，领取到这些Regio你的RegionMaster发现有历史的HLog需要处理，因此会Replay HLog的数据到Memstore之中，然后flush数据到StoreFiles，完成数据的恢复。</p>
<p>飞行日志+补偿机制，也是常用的方法，如基于消息的分布式事务是保证最终一致性的方式之一、Quartz中的恢复执行等。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a target="_blank" rel="noopener" href="https://elf8848.iteye.com/blog/2067774">深入浅出DDoS攻击防御</a></li>
<li><a href="">《Storm源码分析》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9b10313fde10">Flink Checkpoint</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hzmark/p/wal.html">什么是WAL</a></li>
<li><a target="_blank" rel="noopener" href="https://www.sqlite.org/wal.html">Write-Ahead Logging in SQLite</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/docker/yarn-docker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/docker/yarn-docker/" class="post-title-link" itemprop="url">在Docker上搭建Yarn集群和HDFS集群</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-23 00:00:00" itemprop="dateCreated datePublished" datetime="2019-05-23T00:00:00+08:00">2019-05-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:14" itemprop="dateModified" datetime="2021-02-09T09:52:14+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>yarn作为目前最流行的分布式计算资源管理平台，为Hadoop MR、spark、Flink等提供了资源容器</p>
<h2 id="Docker-File"><a href="#Docker-File" class="headerlink" title="Docker File"></a>Docker File</h2><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基础镜像</span></span><br><span class="line"><span class="keyword">FROM</span> hub.c.<span class="number">163</span>.com/public/centos</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum clean all</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y yum-plugin-ovl || <span class="literal">true</span></span></span><br><span class="line"><span class="comment"># 安装基础的工具包</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y vim tar wget curl rsync bzip2 iptables tcpdump less telnet net-tools lsof sysstat cronie python-setuptools</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum clean all</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">22</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /etc/supervisor/conf.d/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> [include] &gt;&gt; /etc/supervisord.conf</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&#x27;files = /etc/supervisor/conf.d/*.conf&#x27;</span> &gt;&gt; /etc/supervisord.conf</span></span><br><span class="line"><span class="comment">#COPY sshd.conf /etc/supervisor/conf.d/sshd.conf</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/usr/bin/supervisord&quot;</span>]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像的作者  </span></span><br><span class="line"><span class="keyword">MAINTAINER</span> averyzhang</span><br><span class="line"><span class="comment"># 安装openssh-server和sudo软件包，并且将sshd的UsePAM参数设置成no  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y openssh-server sudo  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">&#x27;s/UsePAM yes/UsePAM no/g&#x27;</span> /etc/ssh/sshd_config  </span></span><br><span class="line"><span class="comment">#安装openssh-clients</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum  install -y openssh-clients</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加测试用户root，密码abc.123，并且将此用户添加到sudoers里  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;root:abc.123&quot;</span> | chpasswd  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;root   ALL=(ALL)       ALL&quot;</span> &gt;&gt; /etc/sudoers  </span></span><br><span class="line"><span class="comment"># 下面这两句比较特殊，</span></span><br><span class="line"><span class="comment"># 在centos6上必须要有，否则创建出来的容器sshd不能登录  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了避免文件已存在报错，首先删掉私钥文件</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /etc/ssh/ssh_host_rsa_key</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /etc/ssh/ssh_host_dsa_key</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动sshd服务并且暴露22端口  </span></span><br><span class="line"><span class="comment"># RUN mkdir /var/run/sshd  </span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">22</span>  </span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/usr/sbin/sshd&quot;</span>, <span class="string">&quot;-D&quot;</span>]</span></span><br><span class="line"><span class="comment">###### 以上建立centos-ssh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装java</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel.x86_64</span></span><br><span class="line"><span class="comment">## 添加环境变量</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME /usr/lib/jvm/jre-openjdk/</span><br><span class="line"><span class="keyword">ENV</span> JRE_HOME $&#123;JAVA_HOME&#125;</span><br><span class="line"><span class="keyword">ENV</span> PATH $JAVA_HOME/bin:$PATH</span><br><span class="line"><span class="keyword">ENV</span> CLASSPATH $CLASSPATH:.:$JAVA_HOME/lib</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export JAVA_HOME=/usr/lib/jvm/jre-openjdk/&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export JRE_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span>&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span>&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export CLASSPATH=<span class="variable">$CLASSPATH</span>:.:<span class="variable">$JAVA_HOME</span>/lib&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装scala</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /data/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://downloads.lightbend.com/scala/2.10.7/scala-2.10.7.rpm</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y scala-2.10.7.rpm</span></span><br><span class="line"><span class="keyword">ENV</span> SCALA_HOME /usr/share/java</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export SCALA_HOME=/usr/share/java&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装Hadoop</span></span><br><span class="line"><span class="comment">## RUN wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> hadoop-2.7.7.tar /data/hadoop</span></span><br><span class="line"><span class="comment"># RUN tar zxvf /data/hadoop-2.7.7.tar -C /data/hadoop</span></span><br><span class="line"><span class="comment"># RUN ln -s /data/hadoop-2.7.7 /data/hadoop</span></span><br><span class="line"><span class="keyword">ENV</span> HADOOP_HOME /data/hadoop</span><br><span class="line"><span class="keyword">ENV</span> HADOOP_CONF_DIR $&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line"><span class="keyword">ENV</span> YARN_HOME $&#123;HADOOP_HOME&#125;</span><br><span class="line"><span class="keyword">ENV</span> YARN_CONF_DIR $&#123;YARN_HOME&#125;/etc/hadoop</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export HADOOP_HOME=/data/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export YARN_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export YARN_CONF_DIR=<span class="variable">$&#123;YARN_HOME&#125;</span>/etc/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br></pre></td></tr></table></figure>
<h2 id="制作image"><a href="#制作image" class="headerlink" title="制作image"></a>制作image</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t=&quot;avery/centos-yarn&quot; .</span><br></pre></td></tr></table></figure>
<h2 id="创建yarn节点"><a href="#创建yarn节点" class="headerlink" title="创建yarn节点"></a>创建yarn节点</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run --name yarn0 --hostname yarn0 -d -P -p 50070:50070 -p 8088:8088 avery/centos-yarn</span><br><span class="line">docker run --name yarn1 --hostname yarn1 -d -P avery/centos-yarn</span><br><span class="line">docker run --name yarn2 --hostname yarn2 -d -P avery/centos-yarn</span><br><span class="line">docker run --name yarn3 --hostname yarn3 -d -P avery/centos-yarn</span><br></pre></td></tr></table></figure>
<p>查看三个container的ip:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn0</span></span><br><span class="line">172.17.0.2</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn1</span></span><br><span class="line">172.17.0.3</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn2</span></span><br><span class="line">172.17.0.4</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn3</span></span><br><span class="line">172.17.0.5</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>节点</th>
<th>备注</th>
<th>ip</th>
</tr>
</thead>
<tbody><tr>
<td>yarn0</td>
<td>master</td>
<td>172.17.0.2</td>
</tr>
<tr>
<td>yarn1</td>
<td>slaver</td>
<td>172.17.0.3</td>
</tr>
<tr>
<td>yarn2</td>
<td>slaver</td>
<td>172.17.0.4</td>
</tr>
<tr>
<td>yarn3</td>
<td>slaver</td>
<td>172.17.0.5</td>
</tr>
</tbody></table>
<p>查看端口</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker container ls -a                                        </span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS                                                                     NAMES</span><br><span class="line">e150f9141cbd        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32771-&gt;22/tcp                                                     yarn3</span><br><span class="line">9fe0eb86b3e9        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32770-&gt;22/tcp                                                     yarn2</span><br><span class="line">1d5c0ea3d3b3        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32769-&gt;22/tcp                                                     yarn1</span><br><span class="line">60a9cb47ff0c        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:8088-&gt;8088/tcp, 0.0.0.0:50070-&gt;50070/tcp, 0.0.0.0:32768-&gt;22/tcp   yarn0</span><br></pre></td></tr></table></figure>


<h2 id="连接container"><a href="#连接container" class="headerlink" title="连接container"></a>连接container</h2><p>验证ssh连接</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> ssh root@localhost -p 32774</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入密码 abc.123</span></span><br></pre></td></tr></table></figure>
<p>使用exec</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it yarn0 /bin/bash</span><br></pre></td></tr></table></figure>

<h2 id="修改container的主机名"><a href="#修改container的主机名" class="headerlink" title="修改container的主机名"></a>修改container的主机名</h2><p>分别修改三个container的hosts</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hosts </span><br></pre></td></tr></table></figure>
<p>添加下面配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">172.17.0.2      yarn0</span><br><span class="line">172.17.0.3      yarn1</span><br><span class="line">172.17.0.4      yarn2</span><br><span class="line">172.17.0.5      yarn3</span><br></pre></td></tr></table></figure>
<h2 id="ssh-免密"><a href="#ssh-免密" class="headerlink" title="ssh 免密"></a>ssh 免密</h2><p>设置ssh免密码登录<br>在yarn0上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">mkdir .ssh</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn0</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>在yarn1上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>在yarn2上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn0</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>至此，Docker搭建Hadoop集群的准备工作</p>
<h2 id="Hadoop-安装"><a href="#Hadoop-安装" class="headerlink" title="Hadoop 安装"></a>Hadoop 安装</h2><p>登录yarn0，修改Hadoop配置</p>
<p>配置 Hadoop，cd  ~/hadoop-2.7.2/etc/hadoop进入hadoop配置目录，需要配置有以下7个文件：hadoop-env.sh，yarn-env.sh，slaves，core-site.xml，hdfs-site.xml，maprd-site.xml，yarn-site.xml。</p>
<p>在hadoop-env.sh中配置JAVA_HOME</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The java implementation to use.</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_77</span><br></pre></td></tr></table></figure>
<p>在yarn-env.sh中配置JAVA_HOME</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> some Java parameters</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_77</span><br></pre></td></tr></table></figure>
<p>在slaves中配置slave节点的ip或者host，</p>
<p>yarn1<br>yarn2<br>yarn3</p>
<p>修改core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://yarn0:9000/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang//hadoop-2.7.2/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn0:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang/hadoop-2.7.2/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang/hadoop-2.7.2/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改yarn-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8032&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8030&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8035&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8033&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8088&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>将配置好的hadoop-2.7.2文件夹分发给所有slaves节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r hadoop/* root@yarn1:/data/hadoop</span><br><span class="line">scp -r hadoop/* root@yarn2:/data/hadoop</span><br><span class="line">scp -r hadoop/* root@yarn3:/data/hadoop</span><br></pre></td></tr></table></figure>
<h2 id="启动HDFS和yarn"><a href="#启动HDFS和yarn" class="headerlink" title="启动HDFS和yarn"></a>启动HDFS和yarn</h2><p>格式化HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop namenode -format    #格式化namenode</span><br><span class="line">注：若格式化之后重新修改了配置文件，重新格式化之前需要删除tmp，dfs，logs文件夹。</span><br><span class="line">sbin/start-dfs.sh              #启动dfs </span><br><span class="line">sbin/start-yarn.sh              #启动yarn</span><br></pre></td></tr></table></figure>
<p>检查</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@yarn0 hadoop]# jps</span><br><span class="line">709 ResourceManager</span><br><span class="line">984 Jps</span><br><span class="line">346 NameNode</span><br><span class="line">543 SecondaryNameNode</span><br><span class="line">[root@yarn0 hadoop]# ssh yarn1</span><br><span class="line">Last login: Sun Jun  2 23:21:51 2019 from yarn0</span><br><span class="line">[root@yarn1 ~]# jps</span><br><span class="line">305 NodeManager</span><br><span class="line">449 Jps</span><br><span class="line">200 DataNode</span><br><span class="line">[root@yarn1 ~]# ssh yarn2</span><br><span class="line">Last login: Sun Jun  2 23:22:18 2019 from yarn0</span><br><span class="line">[root@yarn2 ~]# jps</span><br><span class="line">193 DataNode</span><br><span class="line">442 Jps</span><br><span class="line">298 NodeManager</span><br><span class="line">[root@yarn2 ~]# ssh yarn3</span><br><span class="line">Last login: Sun Jun  2 23:22:25 2019 from yarn0</span><br><span class="line">[root@yarn3 ~]# jps</span><br><span class="line">178 DataNode</span><br><span class="line">283 NodeManager</span><br><span class="line">427 Jps</span><br></pre></td></tr></table></figure>
<p>yarn web</p>
<p>浏览器打开 <a target="_blank" rel="noopener" href="http://localhost:8088/">http://localhost:8088</a></p>
<p><img src="/images/distributed/docker/docker-yarn-web.png"></p>
<p>搞定收工</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Hadoop/HDFS-NameNode-2.x-HA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Hadoop/HDFS-NameNode-2.x-HA/" class="post-title-link" itemprop="url">Hadoop NameNode 高可用 (High Availability) 实现解析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-23 00:00:00" itemprop="dateCreated datePublished" datetime="2019-05-23T00:00:00+08:00">2019-05-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:15" itemprop="dateModified" datetime="2021-02-09T09:52:15+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="NameNode-高可用整体架构概述"><a href="#NameNode-高可用整体架构概述" class="headerlink" title="NameNode 高可用整体架构概述"></a>NameNode 高可用整体架构概述</h2><p>在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，包括 MapReduce、Hive、Pig 以及 HBase 等也都无法正常工作，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。</p>
<p>所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger(JobTracker 在 2.0 中已经被整合到 YARN ResourceManger 之中) 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。HDFS NameNode 和 YARN ResourceManger 的高可用 (High Availability，HA) 方案基本类似，两者也复用了部分代码，但是由于 HDFS NameNode 对于数据存储和数据一致性的要求比 YARN ResourceManger 高得多，所以 HDFS NameNode 的高可用实现更为复杂一些，本文从内部实现的角度对 HDFS NameNode 的高可用机制进行详细的分析。</p>
<p>HDFS NameNode 的高可用整体架构如图 1 所示 (图片来源于参考文献 [1])：</p>
<p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img001.png" alt="img"></p>
<p>从上图中，我们可以看出 NameNode 的高可用架构主要分为下面几个部分：</p>
<p>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。</p>
<p>主备切换控制器 ZKFailoverController：</p>
<p>ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。<strong>检测NameNode和主从切换  healthMonitor和ActiveStandbyElector</strong></p>
<p>Zookeeper 集群：为主备切换控制器提供主备选举支持。</p>
<p>共享存储系统：</p>
<p>共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。(会不会没有同步完，新的选举就开始了)</p>
<p>DataNode 节点：</p>
<p>除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 <strong>HDFS 的数据块和 DataNode 之间的映射关系</strong>。<strong>DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。</strong> name node包含的元数据信息</p>
<p>下面开始分别介绍 NameNode 的主备切换实现和共享存储系统的实现，在文章的最后会结合笔者的实践介绍一下在 NameNode 的高可用运维中的一些注意事项。</p>
<h2 id="NameNode-的主备切换实现"><a href="#NameNode-的主备切换实现" class="headerlink" title="NameNode 的主备切换实现"></a>NameNode 的主备切换实现</h2><p>NameNode 主备切换主要由 <strong>ZKFailoverController</strong>、<strong>HealthMonitor</strong> 和 <strong>ActiveStandbyElector</strong> 这 3 个组件来协同实现：</p>
<p><strong>HealthMonitor负责监听NameNode的状态，而ActiveStandbyElector负责主备切换</strong></p>
<p>ZKFailoverController 作为 NameNode 机器上一个独立的进程启动 (在 hdfs 启动脚本之中的进程名为 zkfc)，启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 <strong>HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。</strong> 回调方法分别用于几个场景：</p>
<ul>
<li>强制fench NameNode</li>
<li></li>
</ul>
<p>HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调ZKFailoverController 的相应方法进行自动的主备选举。</p>
<p>ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</p>
<p>NameNode 实现主备切换的流程如图 2 所示，有以下几步：</p>
<p><strong>HAServiceProtocol RPC与Hadoop RPC的异同</strong></p>
<ol>
<li>HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。</li>
<li>HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会<strong>回调 ZKFailoverController 注册的相应方法进行处理</strong>。</li>
<li>如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。</li>
<li>ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。</li>
<li>ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。</li>
<li>ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。</li>
</ol>
<h5 id="图-2-NameNode-的主备切换流程"><a href="#图-2-NameNode-的主备切换流程" class="headerlink" title="图 2.NameNode 的主备切换流程"></a>图 2.NameNode 的主备切换流程</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img002.png" alt="img"></p>
<p>下面分别对 HealthMonitor、ActiveStandbyElector 和 ZKFailoverController 的实现细节进行分析：</p>
<h3 id="HealthMonitor-实现分析"><a href="#HealthMonitor-实现分析" class="headerlink" title="HealthMonitor 实现分析"></a>HealthMonitor 实现分析</h3><p>ZKFailoverController 在初始化的时候会创建 HealthMonitor，HealthMonitor 在内部会启动一个线程来循环调用 NameNode 的 HAServiceProtocol RPC 接口的方法来检测 NameNode 的状态，并将状态的变化通过回调的方式来通知 ZKFailoverController。</p>
<p>HealthMonitor 主要检测 NameNode 的两类状态，分别是 HealthMonitor.State 和 HAServiceStatus。HealthMonitor.State 是通过 HAServiceProtocol RPC 接口的 monitorHealth 方法来获取的，反映了 NameNode 节点的健康状况，主要是磁盘存储资源是否充足。HealthMonitor.State 包括下面几种状态：</p>
<ul>
<li>•INITIALIZING：HealthMonitor 在初始化过程中，还没有开始进行健康状况检测；</li>
<li>•SERVICE_HEALTHY：NameNode 状态正常；</li>
<li>•SERVICE_NOT_RESPONDING：调用 NameNode 的 monitorHealth 方法调用无响应或响应超时；</li>
<li>•SERVICE_UNHEALTHY：NameNode 还在运行，但是 monitorHealth 方法返回状态不正常，磁盘存储资源不足；</li>
<li>•HEALTH_MONITOR_FAILED：HealthMonitor 自己在运行过程中发生了异常，不能继续检测 NameNode 的健康状况，会导致 ZKFailoverController 进程退出；</li>
</ul>
<p>HealthMonitor.State 在状态检测之中起主要的作用，在 HealthMonitor.State 发生变化的时候，HealthMonitor 会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。</p>
<p>而 HAServiceStatus 则是通过 HAServiceProtocol RPC 接口的 getServiceStatus 方法来获取的，主要反映的是 NameNode 的 HA 状态，包括：</p>
<ul>
<li>•INITIALIZING：NameNode 在初始化过程中；</li>
<li>•ACTIVE：当前 NameNode 为主 NameNode；</li>
<li>•STANDBY：当前 NameNode 为备 NameNode；</li>
<li>•STOPPING：当前 NameNode 已停止；</li>
</ul>
<p>HAServiceStatus 在状态检测之中只是起辅助的作用，在 HAServiceStatus 发生变化时，HealthMonitor 也会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。</p>
<h3 id="ActiveStandbyElector-实现分析"><a href="#ActiveStandbyElector-实现分析" class="headerlink" title="ActiveStandbyElector 实现分析"></a>ActiveStandbyElector 实现分析</h3><p>Namenode(包括 YARN ResourceManager) 的主备选举是通过 ActiveStandbyElector 来完成的，ActiveStandbyElector 主要是利用了 Zookeeper 的写一致性和临时节点机制，具体的主备选举实现如下：</p>
<p><strong>创建锁节点</strong></p>
<p>如果 HealthMonitor 检测到对应的 NameNode 的状态正常，那么表示这个 NameNode 有资格参加 Zookeeper 的主备选举。如果目前还没有进行过主备选举的话，那么相应的 ActiveStandbyElector 就会发起一次主备选举，尝试在 Zookeeper 上创建一个路径为/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 的临时节点 (${dfs.nameservices} 为 Hadoop 的配置参数 dfs.nameservices 的值，下同)，Zookeeper 的写一致性会保证最终只会有一个 ActiveStandbyElector 创建成功，那么创建成功的 ActiveStandbyElector 对应的 NameNode 就会成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Active 状态。而创建失败的 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Standby 状态。</p>
<p><strong>注册 Watcher 监听</strong></p>
<p>不管创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点是否成功，ActiveStandbyElector 随后都会向 Zookeeper 注册一个 Watcher 来监听这个节点的状态变化事件，ActiveStandbyElector 主要关注这个节点的 NodeDeleted 事件。</p>
<p><strong>自动触发主备选举</strong></p>
<p>如果 Active NameNode 对应的 HealthMonitor 检测到 NameNode 的状态异常时， ZKFailoverController 会主动删除当前在 Zookeeper 上建立的临时节点<code>/hadoop-ha/$&#123;dfs.nameservices&#125;/ActiveStandbyElectorLock</code>， 这样处于 Standby 状态的 NameNode 的 ActiveStandbyElector 注册的监听器就会收到这个节点的 NodeDeleted 事件。收到这个事件之后，会马上再次进入到创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点的流程，如果创建成功，这个本来处于 Standby 状态的 NameNode 就选举为主 NameNode 并随后开始切换为 Active 状态。</p>
<p>当然，如果是 Active 状态的 NameNode 所在的机器整个宕掉的话，那么根据 Zookeeper 的临时节点特性，/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点会自动被删除，从而也会自动进行一次主备切换。</p>
<p><strong>防止脑裂</strong></p>
<p>Zookeeper 在工程实践的过程中经常会发生的一个现象就是 Zookeeper 客户端“假死”，所谓的“假死”是指如果 Zookeeper 客户端机器负载过高或者正在进行 JVM Full GC，那么可能会导致 Zookeeper 客户端到 Zookeeper 服务端的心跳不能正常发出，一旦这个时间持续较长，超过了配置的 Zookeeper Session Timeout 参数的话，Zookeeper 服务端就会认为客户端的 session 已经过期从而将客户端的 Session 关闭。“假死”有可能引起分布式系统常说的双主或脑裂 (brain-split) 现象。具体到本文所述的 NameNode，假设 NameNode1 当前为 Active 状态，NameNode2 当前为 Standby 状态。如果某一时刻 NameNode1 对应的 ZKFailoverController 进程发生了“假死”现象，那么 Zookeeper 服务端会认为 NameNode1 挂掉了，根据前面的主备切换逻辑，NameNode2 会替代 NameNode1 进入 Active 状态。但是此时 NameNode1 可能仍然处于 Active 状态正常运行，即使随后 NameNode1 对应的 ZKFailoverController 因为负载下降或者 Full GC 结束而恢复了正常，感知到自己和 Zookeeper 的 Session 已经关闭，但是由于网络的延迟以及 CPU 线程调度的不确定性，仍然有可能会在接下来的一段时间窗口内 NameNode1 认为自己还是处于 Active 状态。这样 NameNode1 和 NameNode2 都处于 Active 状态，都可以对外提供服务。这种情况对于 NameNode 这类对数据一致性要求非常高的系统来说是灾难性的，数据会发生错乱且无法恢复。Zookeeper 社区对这种问题的解决方法叫做 fencing，中文翻译为隔离，也就是想办法把旧的 Active NameNode 隔离起来，使它不能正常对外提供服务。</p>
<p>ActiveStandbyElector 为了实现 fencing，会在成功创建 Zookeeper 节点 hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 从而成为 Active NameNode 之后，创建另外一个路径为/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 的持久节点，这个节点里面保存了这个 Active NameNode 的地址信息。Active NameNode 的 ActiveStandbyElector 在正常的状态下关闭 Zookeeper Session 的时候 (注意由于/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 是临时节点，也会随之删除)，会一起删除节点/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb。但是如果 ActiveStandbyElector 在异常的状态下 Zookeeper Session 关闭 (比如前述的 Zookeeper 假死)，那么由于/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 是持久节点，会一直保留下来。后面当另一个 NameNode 选主成功之后，会注意到上一个 Active NameNode 遗留下来的这个节点，从而会回调 ZKFailoverController 的方法对旧的 Active NameNode 进行 fencing，具体处理见后文 ZKFailoverController 部分所述。</p>
<h3 id="ZKFailoverController-实现分析"><a href="#ZKFailoverController-实现分析" class="headerlink" title="ZKFailoverController 实现分析"></a>ZKFailoverController 实现分析</h3><p>ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调函数，ZKFailoverController 的处理逻辑主要靠 HealthMonitor 和 ActiveStandbyElector 的回调函数来驱动。</p>
<p><strong>对 HealthMonitor 状态变化的处理</strong></p>
<p>如前所述，HealthMonitor 会检测 NameNode 的两类状态，HealthMonitor.State 在状态检测之中起主要的作用，ZKFailoverController 注册到 HealthMonitor 上的处理 HealthMonitor.State 状态变化的回调函数主要关注 SERVICE_HEALTHY、SERVICE_NOT_RESPONDING 和 SERVICE_UNHEALTHY 这 3 种状态：</p>
<ul>
<li>•如果检测到状态为 SERVICE_HEALTHY，表示当前的 NameNode 有资格参加 Zookeeper 的主备选举，如果目前还没有进行过主备选举的话，ZKFailoverController 会调用 ActiveStandbyElector 的 joinElection 方法发起一次主备选举。</li>
<li>•如果检测到状态为 SERVICE_NOT_RESPONDING 或者是 SERVICE_UNHEALTHY，就表示当前的 NameNode 出现问题了，ZKFailoverController 会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举，这样其它的 NameNode 就有机会成为主 NameNode。</li>
</ul>
<p>而 HAServiceStatus 在状态检测之中仅起辅助的作用，在 HAServiceStatus 发生变化时，ZKFailoverController 注册到 HealthMonitor 上的处理 HAServiceStatus 状态变化的回调函数会判断 NameNode 返回的 HAServiceStatus 和 ZKFailoverController 所期望的是否一致，如果不一致的话，ZKFailoverController 也会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举。</p>
<p><strong>对 ActiveStandbyElector 主备选举状态变化的处理</strong></p>
<p>在 ActiveStandbyElector 的主备选举状态发生变化时，会回调 ZKFailoverController 注册的回调函数来进行相应的处理：</p>
<ul>
<li>•如果 ActiveStandbyElector 选主成功，那么 ActiveStandbyElector 对应的 NameNode 成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeActive 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToActive 方法，将 NameNode 转换为 Active 状态。</li>
<li>•如果 ActiveStandbyElector 选主失败，那么 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeStandby 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，将 NameNode 转换为 Standby 状态。</li>
<li>•如果 ActiveStandbyElector 选主成功之后，发现了上一个 Active NameNode 遗留下来的/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 节点 (见“ActiveStandbyElector 实现分析”一节“防止脑裂”部分所述)，那么 ActiveStandbyElector 会首先回调 ZKFailoverController 注册的 fenceOldActive 方法，尝试对旧的 Active NameNode 进行 fencing，在进行 fencing 的时候，会执行以下的操作：</li>
</ul>
<ol>
<li>1.首先尝试调用这个旧 Active NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，看能不能把它转换为 Standby 状态。</li>
<li>2.如果 transitionToStandby 方法调用失败，那么就执行 Hadoop 配置文件之中预定义的隔离措施，Hadoop 目前主要提供两种隔离措施，通常会选择 sshfence：</li>
</ol>
<ul>
<li>•sshfence：通过 SSH 登录到目标机器上，执行命令 fuser 将对应的进程杀死；</li>
<li>•shellfence：执行一个用户自定义的 shell 脚本来将对应的进程隔离；</li>
</ul>
<p>只有在成功地执行完成 fencing 之后，选主成功的 ActiveStandbyElector 才会回调 ZKFailoverController 的 becomeActive 方法将对应的 NameNode 转换为 Active 状态，开始对外提供服务。</p>
<h2 id="NameNode-的共享存储实现"><a href="#NameNode-的共享存储实现" class="headerlink" title="NameNode 的共享存储实现"></a>NameNode 的共享存储实现</h2><p>过去几年中 Hadoop 社区涌现过很多的 NameNode 共享存储方案，比如 shared NAS+NFS、BookKeeper、BackupNode 和 QJM(Quorum Journal Manager) 等等。目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案合并到 HDFS 的 trunk 之中并且作为默认的共享存储实现，本部分只针对基于 QJM 的共享存储方案的内部实现原理进行分析。为了理解 QJM 的设计和实现，首先要对 NameNode 的元数据存储结构有所了解。</p>
<h3 id="NameNode-的元数据存储概述"><a href="#NameNode-的元数据存储概述" class="headerlink" title="NameNode 的元数据存储概述"></a>NameNode 的元数据存储概述</h3><p>一个典型的 NameNode 的元数据存储目录结构如图 3 所示 (图片来源于参考文献 [4])，这里主要关注其中的 EditLog 文件和 FSImage 文件：</p>
<h5 id="图-3-NameNode-的元数据存储目录结构"><a href="#图-3-NameNode-的元数据存储目录结构" class="headerlink" title="图 3 .NameNode 的元数据存储目录结构"></a>图 3 .NameNode 的元数据存储目录结构</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img003.png" alt="img"></p>
<p>NameNode 在执行 HDFS 客户端提交的创建文件或者移动文件这样的写操作的时候，会首先把这些操作记录在 EditLog 文件之中，然后再更新内存中的文件系统镜像。内存中的文件系统镜像用于 NameNode 向客户端提供读服务，而 EditLog 仅仅只是在数据恢复的时候起作用。记录在 EditLog 之中的每一个操作又称为一个事务，每个事务有一个整数形式的事务 id 作为编号。EditLog 会被切割为很多段，每一段称为一个 Segment。正在写入的 EditLog Segment 处于 in-progress 状态，其文件名形如 edits_inprogress_${start_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，例如上图中的 edits_inprogress_0000000000000000020。而已经写入完成的 EditLog Segment 处于 finalized 状态，其文件名形如 edits_${start_txid}-${end_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，${end_txid} 表示这个 segment 的结束事务 id，例如上图中的 edits_0000000000000000001-0000000000000000019。</p>
<p>NameNode 会定期对内存中的文件系统镜像进行 checkpoint 操作，在磁盘上生成 FSImage 文件，FSImage 文件的文件名形如 fsimage_${end_txid}，其中${end_txid} 表示这个 fsimage 文件的结束事务 id，例如上图中的 fsimage_0000000000000000020。在 NameNode 启动的时候会进行数据恢复，首先把 FSImage 文件加载到内存中形成文件系统镜像，然后再把 EditLog 之中 FsImage 的结束事务 id 之后的 EditLog 回放到这个文件系统镜像上。</p>
<h3 id="基于-QJM-的共享存储系统的总体架构"><a href="#基于-QJM-的共享存储系统的总体架构" class="headerlink" title="基于 QJM 的共享存储系统的总体架构"></a>基于 QJM 的共享存储系统的总体架构</h3><p><strong>基于 QJM 的共享存储系统主要用于保存 EditLog，并不保存 FSImage 文件</strong>。FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法 (参见参考文献 [3])，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉。</p>
<p>基于 QJM 的共享存储系统的内部实现架构图如图 4 所示，主要包含下面几个主要的组件：</p>
<h5 id="图-4-基于-QJM-的共享存储系统的内部实现架构图"><a href="#图-4-基于-QJM-的共享存储系统的内部实现架构图" class="headerlink" title="图 4 . 基于 QJM 的共享存储系统的内部实现架构图"></a>图 4 . 基于 QJM 的共享存储系统的内部实现架构图</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img004.png" alt="img"></p>
<p>FSEditLog：这个类封装了对 EditLog 的所有操作，是 NameNode 对 EditLog 的所有操作的入口。</p>
<p>JournalSet： 这个类封装了对本地磁盘和 JournalNode 集群上的 EditLog 的操作，内部包含了两类 JournalManager，一类为 FileJournalManager，用于实现对本地磁盘上 EditLog 的操作。一类为 QuorumJournalManager，用于实现对 JournalNode 集群上共享目录的 EditLog 的操作。FSEditLog 只会调用 JournalSet 的相关方法，而不会直接使用 FileJournalManager 和 QuorumJournalManager。</p>
<p>FileJournalManager：封装了对本地磁盘上的 EditLog 文件的操作，不仅 NameNode 在向本地磁盘上写入 EditLog 的时候使用 FileJournalManager，JournalNode 在向本地磁盘写入 EditLog 的时候也复用了 FileJournalManager 的代码和逻辑。</p>
<p>QuorumJournalManager：封装了对 JournalNode 集群上的 EditLog 的操作，它会根据 JournalNode 集群的 URI 创建负责与 JournalNode 集群通信的类 AsyncLoggerSet， QuorumJournalManager 通过 AsyncLoggerSet 来实现对 JournalNode 集群上的 EditLog 的写操作，对于读操作，QuorumJournalManager 则是通过 Http 接口从 JournalNode 上的 JournalNodeHttpServer 读取 EditLog 的数据。</p>
<p>AsyncLoggerSet：内部包含了与 JournalNode 集群进行通信的 AsyncLogger 列表，每一个 AsyncLogger 对应于一个 JournalNode 节点，另外 AsyncLoggerSet 也包含了用于等待大多数 JournalNode 返回结果的工具类方法给 QuorumJournalManager 使用。</p>
<p>AsyncLogger：具体的实现类是 IPCLoggerChannel，IPCLoggerChannel 在执行方法调用的时候，会把调用提交到一个单线程的线程池之中，由线程池线程来负责向对应的 JournalNode 的 JournalNodeRpcServer 发送 RPC 请求。</p>
<p>JournalNodeRpcServer：运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求。</p>
<p>JournalNodeHttpServer：运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby 状态的 NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求。</p>
<p>下面对基于 QJM 的共享存储系统的两个关键性问题同步数据和恢复数据进行详细分析。</p>
<h3 id="基于-QJM-的共享存储系统的数据同步机制分析"><a href="#基于-QJM-的共享存储系统的数据同步机制分析" class="headerlink" title="基于 QJM 的共享存储系统的数据同步机制分析"></a>基于 QJM 的共享存储系统的数据同步机制分析</h3><p>Active NameNode 和 StandbyNameNode 使用 JouranlNode 集群来进行数据同步的过程如图 5 所示，Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog：</p>
<h5 id="图-5-基于-QJM-的共享存储的数据同步机制"><a href="#图-5-基于-QJM-的共享存储的数据同步机制" class="headerlink" title="图 5 . 基于 QJM 的共享存储的数据同步机制"></a>图 5 . 基于 QJM 的共享存储的数据同步机制</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img005.png" alt="img"></p>
<p><strong>Active NameNode 提交 EditLog 到 JournalNode 集群</strong></p>
<p>当处于 Active 状态的 NameNode 调用 FSEditLog 类的 logSync 方法来提交 EditLog 的时候，会通过 JournalSet 同时向本地磁盘目录和 JournalNode 集群上的共享存储目录写入 EditLog。写入 JournalNode 集群是通过并行调用每一个 JournalNode 的 QJournalProtocol RPC 接口的 journal 方法实现的，如果对大多数 JournalNode 的 journal 方法调用成功，那么就认为提交 EditLog 成功，否则 NameNode 就会认为这次提交 EditLog 失败。提交 EditLog 失败会导致 Active NameNode 关闭 JournalSet 之后退出进程，留待处于 Standby 状态的 NameNode 接管之后进行数据恢复。</p>
<p>从上面的叙述可以看出，Active NameNode 提交 EditLog 到 JournalNode 集群的过程实际上是同步阻塞的，但是并不需要所有的 JournalNode 都调用成功，只要大多数 JournalNode 调用成功就可以了。如果无法形成大多数，那么就认为提交 EditLog 失败，NameNode 停止服务退出进程。如果对应到分布式系统的 CAP 理论的话，虽然采用了 Paxos 的“大多数”思想对 C(consistency，一致性) 和 A(availability，可用性) 进行了折衷，但还是可以认为 NameNode 选择了 C 而放弃了 A，这也符合 NameNode 对数据一致性的要求。</p>
<p><strong>Standby NameNode 从 JournalNode 集群同步 EditLog</strong></p>
<p>当 NameNode 进入 Standby 状态之后，会启动一个 EditLogTailer 线程。这个线程会定期调用 EditLogTailer 类的 doTailEdits 方法从 JournalNode 集群上同步 EditLog，然后把同步的 EditLog 回放到内存之中的文件系统镜像上 (并不会同时把 EditLog 写入到本地磁盘上)。</p>
<p>这里需要关注的是：从 JournalNode 集群上同步的 EditLog 都是处于 finalized 状态的 EditLog Segment。“NameNode 的元数据存储概述”一节说过 EditLog Segment 实际上有两种状态，处于 in-progress 状态的 Edit Log 当前正在被写入，被认为是处于不稳定的中间态，有可能会在后续的过程之中发生修改，比如被截断。Active NameNode 在完成一个 EditLog Segment 的写入之后，就会向 JournalNode 集群发送 finalizeLogSegment RPC 请求，将完成写入的 EditLog Segment finalized，然后开始下一个新的 EditLog Segment。一旦 finalizeLogSegment 方法在大多数的 JournalNode 上调用成功，表明这个 EditLog Segment 已经在大多数的 JournalNode 上达成一致。一个 EditLog Segment 处于 finalized 状态之后，可以保证它再也不会变化。</p>
<p>从上面描述的过程可以看出，虽然 Active NameNode 向 JournalNode 集群提交 EditLog 是同步的，但 Standby NameNode 采用的是定时从 JournalNode 集群上同步 EditLog 的方式，那么 Standby NameNode 内存中文件系统镜像有很大的可能是落后于 Active NameNode 的，所以 Standby NameNode 在转换为 Active NameNode 的时候需要把落后的 EditLog 补上来。</p>
<h3 id="基于-QJM-的共享存储系统的数据恢复机制分析"><a href="#基于-QJM-的共享存储系统的数据恢复机制分析" class="headerlink" title="基于 QJM 的共享存储系统的数据恢复机制分析"></a>基于 QJM 的共享存储系统的数据恢复机制分析</h3><p>处于 Standby 状态的 NameNode 转换为 Active 状态的时候，有可能上一个 Active NameNode 发生了异常退出，那么 JournalNode 集群中各个 JournalNode 上的 EditLog 就可能会处于不一致的状态，所以首先要做的事情就是让 JournalNode 集群中各个节点上的 EditLog 恢复为一致。另外如前所述，当前处于 Standby 状态的 NameNode 的内存中的文件系统镜像有很大的可能是落后于旧的 Active NameNode 的，所以在 JournalNode 集群中各个节点上的 EditLog 达成一致之后，接下来要做的事情就是从 JournalNode 集群上补齐落后的 EditLog。只有在这两步完成之后，当前新的 Active NameNode 才能安全地对外提供服务。</p>
<p>补齐落后的 EditLog 的过程复用了前面描述的 Standby NameNode 从 JournalNode 集群同步 EditLog 的逻辑和代码，最终调用 EditLogTailer 类的 doTailEdits 方法来完成 EditLog 的补齐。使 JournalNode 集群上的 EditLog 达成一致的过程是一致性算法 Paxos 的典型应用场景，QJM 对这部分的处理可以看做是 Single Instance Paxos(参见参考文献 [3]) 算法的一个实现，在达成一致的过程中，Active NameNode 和 JournalNode 集群之间的交互流程如图 6 所示，具体描述如下：</p>
<h5 id="图-6-Active-NameNode-和-JournalNode-集群的交互流程图"><a href="#图-6-Active-NameNode-和-JournalNode-集群的交互流程图" class="headerlink" title="图 6.Active NameNode 和 JournalNode 集群的交互流程图"></a>图 6.Active NameNode 和 JournalNode 集群的交互流程图</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img006.png" alt="img"></p>
<p><strong>生成一个新的 Epoch</strong></p>
<p>Epoch 是一个单调递增的整数，用来标识每一次 Active NameNode 的生命周期，每发生一次 NameNode 的主备切换，Epoch 就会加 1。这实际上是一种 fencing 机制，为什么需要 fencing 已经在前面“ActiveStandbyElector 实现分析”一节的“防止脑裂”部分进行了说明。产生新 Epoch 的流程与 Zookeeper 的 ZAB(Zookeeper Atomic Broadcast) 协议在进行数据恢复之前产生新 Epoch 的过程完全类似：</p>
<ol>
<li><p>1.</p>
<p>Active NameNode 首先向 JournalNode 集群发送 getJournalState RPC 请求，每个 JournalNode 会返回自己保存的最近的那个 Epoch(代码中叫 lastPromisedEpoch)。</p>
</li>
<li><p>2.</p>
<p>NameNode 收到大多数的 JournalNode 返回的 Epoch 之后，在其中选择最大的一个加 1 作为当前的新 Epoch，然后向各个 JournalNode 发送 newEpoch RPC 请求，把这个新的 Epoch 发给各个 JournalNode。</p>
</li>
<li><p>3.</p>
<p>每一个 JournalNode 在收到新的 Epoch 之后，首先检查这个新的 Epoch 是否比它本地保存的 lastPromisedEpoch 大，如果大的话就把 lastPromisedEpoch 更新为这个新的 Epoch，并且向 NameNode 返回它自己的本地磁盘上最新的一个 EditLogSegment 的起始事务 id，为后面的数据恢复过程做好准备。如果小于或等于的话就向 NameNode 返回错误。</p>
</li>
<li><p>4.</p>
<p>NameNode 收到大多数 JournalNode 对 newEpoch 的成功响应之后，就会认为生成新的 Epoch 成功。</p>
</li>
</ol>
<p>在生成新的 Epoch 之后，每次 NameNode 在向 JournalNode 集群提交 EditLog 的时候，都会把这个 Epoch 作为参数传递过去。每个 JournalNode 会比较传过来的 Epoch 和它自己保存的 lastPromisedEpoch 的大小，如果传过来的 epoch 的值比它自己保存的 lastPromisedEpoch 小的话，那么这次写相关操作会被拒绝。一旦大多数 JournalNode 都拒绝了这次写操作，那么这次写操作就失败了。如果原来的 Active NameNode 恢复正常之后再向 JournalNode 写 EditLog，那么因为它的 Epoch 肯定比新生成的 Epoch 小，并且大多数的 JournalNode 都接受了这个新生成的 Epoch，所以拒绝写入的 JournalNode 数目至少是大多数，这样原来的 Active NameNode 写 EditLog 就肯定会失败，失败之后这个 NameNode 进程会直接退出，这样就实现了对原来的 Active NameNode 的隔离了。</p>
<p><strong>选择需要数据恢复的 EditLog Segment 的 id</strong></p>
<p>需要恢复的 Edit Log 只可能是各个 JournalNode 上的最后一个 Edit Log Segment，如前所述，JournalNode 在处理完 newEpoch RPC 请求之后，会向 NameNode 返回它自己的本地磁盘上最新的一个 EditLog Segment 的起始事务 id，这个起始事务 id 实际上也作为这个 EditLog Segment 的 id。NameNode 会在所有这些 id 之中选择一个最大的 id 作为要进行数据恢复的 EditLog Segment 的 id。</p>
<p><strong>向 JournalNode 集群发送 prepareRecovery RPC 请求</strong></p>
<p>NameNode 接下来向 JournalNode 集群发送 prepareRecovery RPC 请求，请求的参数就是选出的 EditLog Segment 的 id。JournalNode 收到请求后返回本地磁盘上这个 Segment 的起始事务 id、结束事务 id 和状态 (in-progress 或 finalized)。</p>
<p>这一步对应于 Paxos 算法的 Phase 1a 和 Phase 1b(参见参考文献 [3]) 两步。Paxos 算法的 Phase1 是 prepare 阶段，这也与方法名 prepareRecovery 相对应。并且这里以前面产生的新的 Epoch 作为 Paxos 算法中的提案编号 (proposal number)。只要大多数的 JournalNode 的 prepareRecovery RPC 调用成功返回，NameNode 就认为成功。</p>
<p>选择进行同步的基准数据源，向 JournalNode 集群发送 acceptRecovery RPC 请求 NameNode 根据 prepareRecovery 的返回结果，选择一个 JournalNode 上的 EditLog Segment 作为同步的基准数据源。选择基准数据源的原则大致是：在 in-progress 状态和 finalized 状态的 Segment 之间优先选择 finalized 状态的 Segment。如果都是 in-progress 状态的话，那么优先选择 Epoch 比较高的 Segment(也就是优先选择更新的)，如果 Epoch 也一样，那么优先选择包含的事务数更多的 Segment。</p>
<p>在选定了同步的基准数据源之后，NameNode 向 JournalNode 集群发送 acceptRecovery RPC 请求，将选定的基准数据源作为参数。JournalNode 接收到 acceptRecovery RPC 请求之后，从基准数据源 JournalNode 的 JournalNodeHttpServer 上下载 EditLog Segment，将本地的 EditLog Segment 替换为下载的 EditLog Segment。</p>
<p>这一步对应于 Paxos 算法的 Phase 2a 和 Phase 2b(参见参考文献 [3]) 两步。Paxos 算法的 Phase2 是 accept 阶段，这也与方法名 acceptRecovery 相对应。只要大多数 JournalNode 的 acceptRecovery RPC 调用成功返回，NameNode 就认为成功。</p>
<p><strong>向 JournalNode 集群发送 finalizeLogSegment RPC 请求，数据恢复完成</strong></p>
<p>上一步执行完成之后，NameNode 确认大多数 JournalNode 上的 EditLog Segment 已经从基准数据源进行了同步。接下来，NameNode 向 JournalNode 集群发送 finalizeLogSegment RPC 请求，JournalNode 接收到请求之后，将对应的 EditLog Segment 从 in-progress 状态转换为 finalized 状态，实际上就是将文件名从 edits_inprogress_${startTxid} 重命名为 edits_${startTxid}-${endTxid}，见“NameNode 的元数据存储概述”一节的描述。</p>
<p>只要大多数 JournalNode 的 finalizeLogSegment RPC 调用成功返回，NameNode 就认为成功。此时可以保证 JournalNode 集群的大多数节点上的 EditLog 已经处于一致的状态，这样 NameNode 才能安全地从 JournalNode 集群上补齐落后的 EditLog 数据。</p>
<p>需要注意的是，尽管基于 QJM 的共享存储方案看起来理论完备，设计精巧，但是仍然无法保证数据的绝对强一致，下面选取参考文献 [2] 中的一个例子来说明：</p>
<p>假设有 3 个 JournalNode：JN1、JN2 和 JN3，Active NameNode 发送了事务 id 为 151、152 和 153 的 3 个事务到 JournalNode 集群，这 3 个事务成功地写入了 JN2，但是在还没能写入 JN1 和 JN3 之前，Active NameNode 就宕机了。同时，JN3 在整个写入的过程中延迟较大，落后于 JN1 和 JN2。最终成功写入 JN1 的事务 id 为 150，成功写入 JN2 的事务 id 为 153，而写入到 JN3 的事务 id 仅为 125，如图 7 所示 (图片来源于参考文献 [2])。按照前面描述的只有成功地写入了大多数的 JournalNode 才认为写入成功的原则，显然事务 id 为 151、152 和 153 的这 3 个事务只能算作写入失败。在进行数据恢复的过程中，会发生下面两种情况：</p>
<h5 id="图-7-JournalNode-集群写入的事务-id-情况"><a href="#图-7-JournalNode-集群写入的事务-id-情况" class="headerlink" title="图 7.JournalNode 集群写入的事务 id 情况"></a>图 7.JournalNode 集群写入的事务 id 情况</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img007.png" alt="img"></p>
<ul>
<li>•如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段收到了 JN2 的回复，那么肯定会以 JN2 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 153。从恢复的结果来看，实际上可以认为前面宕机的 Active NameNode 对事务 id 为 151、152 和 153 的这 3 个事务的写入成功了。但是如果从 NameNode 自身的角度来看，这显然就发生了数据不一致的情况。</li>
<li>•如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段没有收到 JN2 的回复，那么肯定会以 JN1 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 150。在这种情况下，如果从 NameNode 自身的角度来看的话，数据就是一致的了。</li>
</ul>
<p>事实上不光本文描述的基于 QJM 的共享存储方案无法保证数据的绝对一致，大家通常认为的一致性程度非常高的 Zookeeper 也会发生类似的情况，这也从侧面说明了要实现一个数据绝对一致的分布式存储系统的确非常困难。</p>
<h3 id="NameNode-在进行状态转换时对共享存储的处理"><a href="#NameNode-在进行状态转换时对共享存储的处理" class="headerlink" title="NameNode 在进行状态转换时对共享存储的处理"></a>NameNode 在进行状态转换时对共享存储的处理</h3><p>下面对 NameNode 在进行状态转换的过程中对共享存储的处理进行描述，使得大家对基于 QJM 的共享存储方案有一个完整的了解，同时也作为本部分的总结。</p>
<p><strong>NameNode 初始化启动，进入 Standby 状态</strong></p>
<p>在 NameNode 以 HA 模式启动的时候，NameNode 会认为自己处于 Standby 模式，在 NameNode 的构造函数中会加载 FSImage 文件和 EditLog Segment 文件来恢复自己的内存文件系统镜像。在加载 EditLog Segment 的时候，调用 FSEditLog 类的 initSharedJournalsForRead 方法来创建只包含了在 JournalNode 集群上的共享目录的 JournalSet，也就是说，这个时候只会从 JournalNode 集群之中加载 EditLog，而不会加载本地磁盘上的 EditLog。另外值得注意的是，加载的 EditLog Segment 只是处于 finalized 状态的 EditLog Segment，而处于 in-progress 状态的 Segment 需要后续在切换为 Active 状态的时候，进行一次数据恢复过程，将 in-progress 状态的 Segment 转换为 finalized 状态的 Segment 之后再进行读取。</p>
<p>加载完 FSImage 文件和共享目录上的 EditLog Segment 文件之后，NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式。如前所述，EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog。而 StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点。</p>
<p><strong>NameNode 从 Standby 状态切换为 Active 状态</strong></p>
<p>当 NameNode 从 Standby 状态切换为 Active 状态的时候，首先需要做的就是停止它在 Standby 状态的时候启动的线程和相关的服务，包括上面提到的 EditLogTailer 线程和 StandbyCheckpointer 线程，然后关闭用于读取 JournalNode 集群的共享目录上的 EditLog 的 JournalSet，接下来会调用 FSEditLog 的 initJournalSetForWrite 方法重新打开 JournalSet。不同的是，这个 JournalSet 内部同时包含了本地磁盘目录和 JournalNode 集群上的共享目录。这些工作完成之后，就开始执行“基于 QJM 的共享存储系统的数据恢复机制分析”一节所描述的流程，调用 FSEditLog 类的 recoverUnclosedStreams 方法让 JournalNode 集群中各个节点上的 EditLog 达成一致。然后调用 EditLogTailer 类的 catchupDuringFailover 方法从 JournalNode 集群上补齐落后的 EditLog。最后打开一个新的 EditLog Segment 用于新写入数据，同时启动 Active NameNode 所需要的线程和服务。</p>
<p><strong>NameNode 从 Active 状态切换为 Standby 状态</strong></p>
<p>当 NameNode 从 Active 状态切换为 Standby 状态的时候，首先需要做的就是停止它在 Active 状态的时候启动的线程和服务，然后关闭用于读取本地磁盘目录和 JournalNode 集群上的共享目录的 EditLog 的 JournalSet。接下来会调用 FSEditLog 的 initSharedJournalsForRead 方法重新打开用于读取 JournalNode 集群上的共享目录的 JournalSet。这些工作完成之后，就会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，EditLogTailer 线程会定时从 JournalNode 集群上同步 Edit Log。</p>
<h2 id="NameNode-高可用运维中的注意事项"><a href="#NameNode-高可用运维中的注意事项" class="headerlink" title="NameNode 高可用运维中的注意事项"></a>NameNode 高可用运维中的注意事项</h2><p>本节结合笔者的实践，从初始化部署和日常运维两个方面介绍一些在 NameNode 高可用运维中的注意事项。</p>
<h3 id="初始化部署"><a href="#初始化部署" class="headerlink" title="初始化部署"></a>初始化部署</h3><p>如果在开始部署 Hadoop 集群的时候就启用 NameNode 的高可用的话，那么相对会比较容易。但是如果在采用传统的单 NameNode 的架构运行了一段时间之后，升级为 NameNode 的高可用架构的话，就要特别注意在升级的时候需要按照以下的步骤进行操作：</p>
<ol>
<li>1.对 Zookeeper 进行初始化，创建 Zookeeper 上的/hadoop-ha/${dfs.nameservices} 节点。创建节点是为随后通过 Zookeeper 进行主备选举做好准备，在进行主备选举的时候会在这个节点下面创建子节点 (具体可参照“ActiveStandbyElector 实现分析”一节的叙述)。这一步通过在原有的 NameNode 上执行命令 hdfs zkfc -formatZK 来完成。</li>
<li>2.启动所有的 JournalNode，这通过脚本命令 hadoop-daemon.sh start journalnode 来完成。</li>
<li>3.对 JouranlNode 集群的共享存储目录进行格式化，并且将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件 (具体可参照“NameNode 的元数据存储概述”一节的叙述) 之后的 EditLog 拷贝到 JournalNode 集群上的共享目录之中，这通过在原有的 NameNode 上执行命令 hdfs namenode -initializeSharedEdits 来完成。</li>
<li>4.启动原有的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。</li>
<li>5.对新增的 NameNode 节点进行初始化，将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件拷贝到这个新增的 NameNode 的本地磁盘上，同时需要验证 JournalNode 集群的共享存储目录上已经具有了这个 FSImage 文件之后的 EditLog(已经在第 3 步完成了)。这一步通过在新增的 NameNode 上执行命令 hdfs namenode -bootstrapStandby 来完成。</li>
<li>6.启动新增的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。</li>
<li>7.在这两个 NameNode 上启动 zkfc(ZKFailoverController) 进程，谁通过 Zookeeper 选主成功，谁就是主 NameNode，另一个为备 NameNode。这通过脚本命令 hadoop-daemon.sh start zkfc 完成。</li>
</ol>
<h3 id="日常维护"><a href="#日常维护" class="headerlink" title="日常维护"></a>日常维护</h3><p>笔者在日常的维护之中主要遇到过下面两种问题：</p>
<p>Zookeeper 过于敏感：Hadoop 的配置项中 Zookeeper 的 session timeout 的配置参数 ha.zookeeper.session-timeout.ms 的默认值为 5000，也就是 5s，这个值比较小，会导致 Zookeeper 比较敏感，可以把这个值尽量设置得大一些，避免因为网络抖动等原因引起 NameNode 进行无谓的主备切换。</p>
<p>单台 JouranlNode 故障时会导致主备无法切换：在理论上，如果有 3 台或者更多的 JournalNode，那么挂掉一台 JouranlNode 应该仍然可以进行正常的主备切换。但是笔者在某次 NameNode 重启的时候，正好赶上一台 JournalNode 挂掉宕机了，这个时候虽然某一台 NameNode 通过 Zookeeper 选主成功，但是这台被选为主的 NameNode 无法成功地从 Standby 状态切换为 Active 状态。事后追查原因发现，被选为主的 NameNode 卡在退出 Standby 状态的最后一步，这个时候它需要等待到 JournalNode 的请求全部完成之后才能退出。但是由于有一台 JouranlNode 宕机，到这台 JournalNode 的请求都积压在一起并且在不断地进行重试，同时在 Hadoop 的配置项中重试次数的默认值非常大，所以就会导致被选为主的 NameNode 无法及时退出 Standby 状态。这个问题主要是 Hadoop 内部的 RPC 通信框架的设计缺陷引起的，Hadoop HA 的源代码 IPCLoggerChannel 类中有关于这个问题的 TODO，但是截止到社区发布的 2.7.1 版本这个问题仍然存在。</p>
<h4 id="相关主题"><a href="#相关主题" class="headerlink" title="相关主题"></a>相关主题</h4><ul>
<li>•[<a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HDFS-1623">1]Sanjay Radia, Suresh Srinivas. High Availability for the HDFS Namenode.</a></li>
<li>•[<a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HDFS-3077">2]Todd Lipcon . Quorum-Journal Design.</a></li>
<li>•[<a target="_blank" rel="noopener" href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">3]L Lamport. Paxos Made Simple. ACM SIGACT News,2001</a></li>
<li>•[<a target="_blank" rel="noopener" href="http://shop.oreilly.com/product/0636920033448.do">4]Tom White.Hadoop: The Definitive Guide 4th Edition. O’Reilly Media, Inc., 2015</a></li>
<li>•<a target="_blank" rel="noopener" href="http://www.ibm.com/developerworks/cn/opensource/">developerWorks 开源技术主题</a>：查找丰富的操作信息、工具和项目更新，帮助您掌握开源技术并将其用于 IBM 产品。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/database/MySQL/information_schema/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/database/MySQL/information_schema/" class="post-title-link" itemprop="url">MySQL information_schema数据库</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-25 11:00:00" itemprop="dateCreated datePublished" datetime="2019-03-25T11:00:00+08:00">2019-03-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:14" itemprop="dateModified" datetime="2021-02-09T09:52:14+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DataBase/" itemprop="url" rel="index"><span itemprop="name">DataBase</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>information_schema这这个数据库中保存了MySQL服务器所有数据库的信息。<br>如数据库名，数据库的表，表栏的数据类型与访问权限等。<br>再简单点，这台MySQL服务器上，到底有哪些数据库、各个数据库有哪些表，<br>每张表的字段类型是什么，各个数据库要什么权限才能访问，等等信息都保存在information_schema里面。</p>
<p>选用MySQL版本 5.6.25</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> version();</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="operator">|</span> version()  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5.6</span><span class="number">.25</span><span class="operator">-</span>log <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">use information_schema;</span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Tables_in_information_schema          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> CHARACTER_SETS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLLATIONS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLLATION_CHARACTER_SET_APPLICABILITY <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLUMNS                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLUMN_PRIVILEGES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ENGINES                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> EVENTS                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> FILES                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> GLOBAL_STATUS                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> GLOBAL_VARIABLES                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> KEY_COLUMN_USAGE                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OPTIMIZER_TRACE                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PARAMETERS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PARTITIONS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PLUGINS                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PROCESSLIST                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PROFILING                             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> REFERENTIAL_CONSTRAINTS               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ROUTINES                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SCHEMATA                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SCHEMA_PRIVILEGES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SESSION_STATUS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SESSION_VARIABLES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> STATISTICS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLES                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLESPACES                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLE_CONSTRAINTS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLE_PRIVILEGES                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TRIGGERS                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> USER_PRIVILEGES                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> VIEWS                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_LOCKS                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_TRX                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_DATAFILES                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_LOCK_WAITS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLESTATS                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_METRICS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_RESET                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_PER_INDEX                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMPMEM_RESET                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_DELETED                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_PAGE_LRU                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FOREIGN                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_COLUMNS                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_INDEXES                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_DEFAULT_STOPWORD            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FIELDS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_PER_INDEX_RESET            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_PAGE                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMPMEM                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_INDEX_TABLE                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_BEING_DELETED               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLESPACES                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_INDEX_CACHE                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FOREIGN_COLS               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_POOL_STATS              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_CONFIG                      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="number">59</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure>
<p>information_schema 数据库中有59张表， 分别存储了如下的信息:<br><a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.6/en/information-schema.html">参考官方文档</a></p>
<table>
<thead>
<tr>
<th>SCHEMATA</th>
<th>提供了当前mysql实例中所有数据库的信息，show databases的结果取之此表。</th>
</tr>
</thead>
<tbody><tr>
<td>TABLES</td>
<td>提供了关于数据库中的表的信息（包括视图），详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息，show tables from schemaname的结果取之此表。</td>
</tr>
<tr>
<td>COLUMNS</td>
<td>提供了表中的列信息，详细表述了某张表的所有列以及每个列的信息，show columns from  schemaname.tablename的结果取之此表。</td>
</tr>
<tr>
<td>STATISTICS</td>
<td>提供了关于表索引的信息，show index from schemaname.tablename的结果取之此表。</td>
</tr>
<tr>
<td>USER_PRIVILEGES（用户权限）</td>
<td>给出了关于全程权限的信息，该信息源自mysql.user授权表，是非标准表。</td>
</tr>
<tr>
<td>SCHEMA_PRIVILEGES（方案权限）</td>
<td>给出了关于方案（数据库）权限的信息，该信息来自mysql.db授权表，是非标准表。</td>
</tr>
<tr>
<td>TABLE_PRIVILEGES（表权限）</td>
<td>给出了关于表权限的信息，该信息源自mysql.tables_priv授权表，是非标准表。</td>
</tr>
<tr>
<td>COLUMN_PRIVILEGES（列权限）</td>
<td>给出了关于列权限的信息，该信息源自mysql.columns_priv授权表，是非标准表。</td>
</tr>
<tr>
<td>CHARACTER_SETS（字符集）</td>
<td>提供了mysql实例可用字符集的信息，SHOW CHARACTER SET结果集取之此表。</td>
</tr>
<tr>
<td>COLLATIONS</td>
<td>提供了关于各字符集的对照信息。</td>
</tr>
<tr>
<td>COLLATION_CHARACTER_SET_APPLICABILITY</td>
<td>指明了可用于校对的字符集，这些列等效于SHOW COLLATION的前两个显示字段。</td>
</tr>
<tr>
<td>TABLE_CONSTRAINTS</td>
<td>描述了存在约束的表，以及表的约束类型。</td>
</tr>
<tr>
<td>KEY_COLUMN_USAGE</td>
<td>描述了具有约束的键列。</td>
</tr>
<tr>
<td>ROUTINES</td>
<td>提供了关于存储子程序（存储程序和函数）的信息，此时，ROUTINES表不包含自定义函数（UDF），名为</td>
</tr>
<tr>
<td>VIEWS</td>
<td>给出了关于数据库中的视图的信息，需要有show views权限，否则无法查看视图信息。</td>
</tr>
<tr>
<td>TRIGGERS</td>
<td>提供了关于触发程序的信息，必须有super权限才能查看该表。</td>
</tr>
</tbody></table>
<p>information_schema的表schemata中的列schema_name记录了所有数据库的名字<br>information_schema的表tables中的列table_schema记录了所有数据库的名字<br>information_schema的表tables中的列table_name记录了所有数据库的表的名字<br>information_schema的表columns中的列table_schema记录了所有数据库的名字<br>information_schema的表columns中的列table_name记录了所有数据库的表的名字<br>information_schema的表columns中的列column_name记录了所有数据库的表的列的名字</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/performance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/performance/" class="post-title-link" itemprop="url">Java性能指标与调优</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-25 08:58:00" itemprop="dateCreated datePublished" datetime="2019-03-25T08:58:00+08:00">2019-03-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:14" itemprop="dateModified" datetime="2021-02-09T09:52:14+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>无论是web服务、集群应用还是单机应用，涉及的性能相关的内容很多:</p>
<p>接下来分别从上层到底层介绍所涉及的点:</p>
<p>webpage–&gt;nginx–&gt;io–&gt;cpu–&gt;memory–&gt;JVM–&gt;Java</p>
<h2 id="webpage"><a href="#webpage" class="headerlink" title="webpage"></a>webpage</h2><h2 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h2><h2 id="io"><a href="#io" class="headerlink" title="io"></a>io</h2><h2 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h2><h2 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h2><h2 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h2><h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/multithread/lockless-disruptor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/multithread/lockless-disruptor/" class="post-title-link" itemprop="url">无锁队列与Disruptor</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-20 00:00:00" itemprop="dateCreated datePublished" datetime="2019-03-20T00:00:00+08:00">2019-03-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:14" itemprop="dateModified" datetime="2021-02-09T09:52:14+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自<a target="_blank" rel="noopener" href="http://www.importnew.com/19877.html">剖析Disruptor为什么会这么快</a></p>
<p><strong>Disruptor如何解决这些问题。</strong></p>
<p>首先，Disruptor根本就不用锁。</p>
<p>取而代之的是，在需要确保操作是线程安全的（特别是，在<a target="_blank" rel="noopener" href="http://mechanitis.blogspot.com/2011/07/dissecting-disruptor-writing-to-ring.html">多生产者</a>的环境下，更新下一个可用的序列号）地方，我们使用<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Compare-and-swap">CAS</a>（Compare And Swap/Set）操作。这是一个CPU级别的指令，在我的意识中，它的工作方式有点像乐观锁——CPU去更新一个值，但如果想改的值不再是原来的值，操作就失败，因为很明显，有其它操作先改变了这个值。</p>
<p><a target="_blank" rel="noopener" href="http://ifeve.com/wp-content/uploads/2013/01/ConcurrencyCAS.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/ConcurrencyCAS.png" alt="img"></a></p>
<p>注意，这可以是CPU的两个不同的核心，但不会是两个独立的CPU。</p>
<p>CAS操作比锁消耗资源少的多，因为它们不牵涉操作系统，它们直接在CPU上操作。但它们并非没有代价——在上面的试验中，单线程无锁耗时300ms，单线程有锁耗时10000ms，单线程使用CAS耗时5700ms。所以它比使用锁耗时少，但比不需要考虑竞争的单线程耗时多。</p>
<p>回到Disruptor，在我<a target="_blank" rel="noopener" href="http://ifeve.com/disruptor-writing-ringbuffer/">讲生产者</a>时讲过<a target="_blank" rel="noopener" href="https://github.com/LMAX-Exchange/disruptor/blob/version-2.x/code/src/main/com/lmax/disruptor/ClaimStrategy.java">ClaimStrategy</a>。在这些代码中，你可以看见两个策略，一个是SingleThreadedStrategy（单线程策略）另一个是MultiThreadedStrategy（多线程策略）。你可能会有疑问，为什么在只有单个生产者时不用多线程的那个策略？它是否能够处理这种场景？当然可以。但多线程的那个使用了<a target="_blank" rel="noopener" href="http://download.oracle.com/javase/6/docs/api/java/util/concurrent/atomic/AtomicLong.html">AtomicLong</a>（Java提供的CAS操作），而单线程的使用long，没有锁也没有CAS。这意味着单线程版本会非常快，因为它只有一个生产者，不会产生序号上的冲突。</p>
<p>我知道，你可能在想：把一个数字转成AtomicLong不可能是Disruptor速度快的唯一秘密。当然，它不是，否则它不可能称为“为什么这么快（第一部分）”。</p>
<p>但这是非常重要的一点</p>
<p>——在整个复杂的框架中，只有这一个地方出现多线程竞争修改同一个变量值。这就是秘密。还记得所有的访问对象都拥有序号吗？如果只有一个生产者，那么系统中的每一个序列号只会由一个线程写入。这意味着没有竞争、不需要锁、甚至不需要CAS。在ClaimStrategy中，如果存在多个生产者，唯一会被多线程竞争写入的序号就是 ClaimStrategy 对象里的那个。</p>
<p>这也是为什么Entry中的每一个变量都<a target="_blank" rel="noopener" href="http://ifeve.com/dissecting-disruptor-wiring-up/">只能被一个消费者写</a>。它确保了没有写竞争，因此不需要锁或者CAS。</p>
<p><strong>回到为什么队列不能胜任这个工作</strong></p>
<p>因此你可能会有疑问，为什么队列底层用RingBuffer来实现，仍然在性能上无法与 Disruptor 相比。队列和<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Circular_buffer">最简单的ring buffer</a>只有两个指针——一个指向队列的头，一个指向队尾：</p>
<p><a target="_blank" rel="noopener" href="http://ifeve.com/wp-content/uploads/2013/01/QueueMultiple.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueMultiple.png" alt="img"></a></p>
<p>如果有超过一个生产者想要往队列里放东西，尾指针就将成为一个冲突点，因为有多个线程要更新它。如果有多个消费者，那么头指针就会产生竞争，因为元素被消费之后，需要更新指针，所以不仅有读操作还有写操作了。</p>
<p>等等，我听到你喊冤了！因为我们已经知道这些了，所以队列常常是单生产者和单消费者（或者至少在我们的测试里是）。<br>队列的目的就是为生产者和消费者提供一个地方存放要交互的数据，帮助缓冲它们之间传递的消息。这意味着缓冲常常是满的（生产者比消费者快）或者空的（消费者比生产者快）。生产者和消费者能够步调一致的情况非常少见。</p>
<p>所以，这就是事情的真面目。一个空的队列：</p>
<p><a target="_blank" rel="noopener" href="http://ifeve.com/wp-content/uploads/2013/01/QueueEmpty.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueEmpty.png" alt="img"></a></p>
<p>…</p>
<p>一个满的队列：</p>
<p><a target="_blank" rel="noopener" href="http://ifeve.com/wp-content/uploads/2013/01/QueueFull.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueFull.png" alt="img"></a></p>
<p><em>(校对注：这应该是一个双向队列)</em></p>
<p>队列需要保存一个关于大小的变量，以便区分队列是空还是满。否则，它需要根据队列中的元素的内容来判断，这样的话，消费一个节点（Entry）后需要做一次写入来清除标记，或者标记节点已经被消费过了。无论采用何种方式实现，在头、尾和大小变量上总是会有很多竞争，或者如果消费操作移除元素时需要使用一个写操作，那元素本身也包含竞争。</p>
<p>基于以上，这三个变量常常在一个<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/CPU_cache">cache line</a>里面，有可能导致伪分享<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/False_sharing">false sharing</a>。因此，不仅要担心生产者和消费者同时写size变量（或者元素），还要注意由于头指针尾指针在同一位置，当头指针更新时，更新尾指针会导致缓存不命中。这篇文章已经很长了，所以我就不再详述细节了。</p>
<p>这就是我们所说的“分离竞争点问题”或者队列的“合并竞争点问题”。通过将所有的东西都赋予私有的序列号，并且只允许一个消费者写Entry对象中的变量来消除竞争，Disruptor 唯一需要处理访问冲突的地方，是多个生产者写入 Ring Buffer 的场景。</p>
<p><strong>总结</strong></p>
<p>Disruptor相对于传统方式的优点：</p>
<ol>
<li>没有竞争=没有锁=非常快。</li>
<li>所有访问者都记录自己的序号的实现方式，允许多个生产者与多个消费者共享相同的数据结构。</li>
<li>在每个对象中都能跟踪序列号（ring buffer，claim Strategy，生产者和消费者），加上神奇的<a target="_blank" rel="noopener" href="http://code.google.com/p/disruptor/source/browse/trunk/code/src/main/com/lmax/disruptor/RingBuffer.java">cache line padding</a>，就意味着没有为伪共享和非预期的竞争。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/multithread/01.1.monitor-synchronized/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/multithread/01.1.monitor-synchronized/" class="post-title-link" itemprop="url">monitor和synchronized</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-20 00:00:00" itemprop="dateCreated datePublished" datetime="2019-03-20T00:00:00+08:00">2019-03-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:14" itemprop="dateModified" datetime="2021-02-09T09:52:14+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转载自<a target="_blank" rel="noopener" href="https://blog.csdn.net/javazejian/article/details/72828483#synchronized%E6%96%B9%E6%B3%95%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86">深入理解Java并发之synchronized实现原理</a></p>
<p>线程安全是并发编程中的重要关注点，应该注意到的是，造成线程安全问题的主要诱因有两点:</p>
<p>一是存在共享数据(也称临界资源)，二是存在多条线程共同操作共享数据。</p>
<p>因此为了解决这个问题，我们可能需要这样一个方案，当存在多个线程操作共享数据时，需要保证同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再进行，这种方式有个高尚的名称叫<strong>互斥锁</strong>，即能达到互斥访问目的的锁，也就是说当一个共享数据被当前正在访问的线程加上互斥锁后，在同一个时刻，其他线程只能处于等待的状态，直到当前线程处理完毕释放该锁。</p>
<p>在 Java 中，关键字 synchronized可以保证在同一个时刻，只有一个线程可以执行某个方法或者某个代码块(主要是对方法或者代码块中存在共享数据的操作)，同时我们还应该注意到synchronized另外一个重要的作用，synchronized可保证一个线程的变化(主要是共享数据的变化)被其他线程所看到（保证可见性，完全可以替代Volatile功能），这点确实也是很重要的。</p>
<h1 id="synchronized底层语义原理"><a href="#synchronized底层语义原理" class="headerlink" title="synchronized底层语义原理"></a>synchronized底层语义原理</h1><p>Java 虚拟机中的同步(Synchronization)基于进入和退出管程(Monitor)对象实现， 无论是显式同步(有明确的 <code>monitorenter</code> 和 <code>monitorexit</code> 指令,即同步代码块)还是隐式同步都是如此。同步用的最多的地方可能是被 <code>synchronized</code> 修饰的同步方法。同步方法 并不是由 <code>monitorenter</code> 和 <code>monitorexit</code> 指令来实现同步的，而是由方法调用指令读取运行时常量池中方法的 <code>ACC_SYNCHRONIZED</code> 标志来隐式实现的，先来了解一个概念Java对象头，这对深入理解synchronized实现原理非常关键。</p>
<h2 id="理解Java对象头与Monitor"><a href="#理解Java对象头与Monitor" class="headerlink" title="理解Java对象头与Monitor"></a>理解Java对象头与Monitor</h2><p>在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。如下：</p>
<p><img src="/images/java/multithread/monitor/object_struct_in_heap.png"></p>
<p>实例变量：存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。</p>
<p>填充数据：由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。</p>
<p>而对于顶部，则是Java对象头，它实现<code>synchronized</code>的锁对象的基础，这点我们重点分析它，一般而言，<code>synchronized</code>使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由<code>Mark Word</code> 和 <code>Class Metadata Address</code> 组成，其结构说明如下表：</p>
<table>
<thead>
<tr>
<th>虚拟机位数</th>
<th>头对象结构</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>32/64bit</td>
<td>Mark Word</td>
<td>存储对象的hashCode、锁信息或分代年龄或GC标志等信息</td>
</tr>
<tr>
<td>32/64bit</td>
<td>Class Metadata Address</td>
<td>类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的实例。</td>
</tr>
</tbody></table>
<p>其中Mark Word在默认情况下存储着对象的HashCode、分代年龄、锁标记位等</p>
<p>以下是32位JVM的Mark Word默认存储结构</p>
<table>
<thead>
<tr>
<th>锁状态</th>
<th>25bit</th>
<th>4bit</th>
<th>1bit是否是偏向锁</th>
<th>2bit 锁标志位</th>
</tr>
</thead>
<tbody><tr>
<td>无锁状态</td>
<td>对象HashCode</td>
<td>对象分代年龄</td>
<td>0</td>
<td>01</td>
</tr>
</tbody></table>
<p>由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间，如32位JVM下，除了上述列出的Mark Word默认存储结构外，还有如下可能变化的结构：</p>
<p><img src="/images/java/multithread/monitor/object_mark_word.png"></p>
<p>其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的，重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ObjectMonitor() &#123;</span><br><span class="line">    _header       = <span class="literal">NULL</span>;</span><br><span class="line">    _count        = <span class="number">0</span>; <span class="comment">//记录个数</span></span><br><span class="line">    _waiters      = <span class="number">0</span>,</span><br><span class="line">    _recursions   = <span class="number">0</span>;</span><br><span class="line">    _object       = <span class="literal">NULL</span>;</span><br><span class="line">    _owner        = <span class="literal">NULL</span>;</span><br><span class="line">    _WaitSet      = <span class="literal">NULL</span>; <span class="comment">//处于wait状态的线程，会被加入到_WaitSet</span></span><br><span class="line">    _WaitSetLock  = <span class="number">0</span> ;</span><br><span class="line">    _Responsible  = <span class="literal">NULL</span> ;</span><br><span class="line">    _succ         = <span class="literal">NULL</span> ;</span><br><span class="line">    _cxq          = <span class="literal">NULL</span> ;</span><br><span class="line">    FreeNext      = <span class="literal">NULL</span> ;</span><br><span class="line">    _EntryList    = <span class="literal">NULL</span> ; <span class="comment">//处于等待锁block状态的线程，会被加入到该列表</span></span><br><span class="line">    _SpinFreq     = <span class="number">0</span> ;</span><br><span class="line">    _SpinClock    = <span class="number">0</span> ;</span><br><span class="line">    OwnerIsThread = <span class="number">0</span> ;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>ObjectMonitor中有两个队列，<code>_WaitSet</code> 和 <code>_EntryList</code>，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，<code>_owner</code>指向持有ObjectMonitor对象的线程</p>
<ul>
<li>当多个线程同时访问一段同步代码时，首先会进入 <code>_EntryList</code> 集合</li>
<li>当线程获取到对象的<code>monitor</code> 后进入 <code>_Owner</code> 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1</li>
<li>若线程调用 <code>wait()</code> 方法，将释放当前持有的<code>monitor</code>，owner变量恢复为null，count自减1，同时该线程进入 <code>WaitSet</code>集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。</li>
</ul>
<p><img src="/images/java/multithread/monitor/monitor_lock.png"></p>
<p>monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，<strong>synchronized锁便是通过这种方式获取锁的</strong>，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因</p>
<h2 id="synchronized代码块底层原理"><a href="#synchronized代码块底层原理" class="headerlink" title="synchronized代码块底层原理"></a>synchronized代码块底层原理</h2><p>现在我们重新定义一个synchronized修饰的同步代码块，在代码块中操作共享变量i，如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SyncCodeBlock</span> </span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">int</span> i;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">syncTask</span><span class="params">()</span></span>&#123;</span><br><span class="line">       <span class="comment">//同步代码库</span></span><br><span class="line">       <span class="keyword">synchronized</span> (<span class="keyword">this</span>)&#123;</span><br><span class="line">           i++;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译上述代码并使用javap反编译后得到字节码如下(这里我们省略一部分没有必要的信息)：</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">Classfile</span> /Users/zejian/Downloads/Java8_Action/src/main/java/com/zejian/concurrencys/SyncCodeBlock.class</span><br><span class="line">  Last modified <span class="number">2017</span>-<span class="number">6</span>-<span class="number">2</span><span class="comment">; size 426 bytes</span></span><br><span class="line">  MD5 checksum c80bc322c87b312de760942820b4fed5</span><br><span class="line">  Compiled from <span class="string">&quot;SyncCodeBlock.java&quot;</span></span><br><span class="line"><span class="symbol">public</span> class com.zejian.concurrencys.SyncCodeBlock</span><br><span class="line">  minor version: <span class="number">0</span></span><br><span class="line">  major version: <span class="number">52</span></span><br><span class="line"><span class="symbol">  flags:</span> ACC_PUBLIC, ACC_SUPER</span><br><span class="line"><span class="symbol">Constant</span> pool:</span><br><span class="line">  <span class="comment">//........省略常量池中数据</span></span><br><span class="line">  <span class="comment">//构造函数</span></span><br><span class="line">  public com.zejian.concurrencys.SyncCodeBlock()<span class="comment">;</span></span><br><span class="line"><span class="symbol">    descriptor:</span> ()V</span><br><span class="line"><span class="symbol">    flags:</span> ACC_PUBLIC</span><br><span class="line"><span class="symbol">    Code:</span></span><br><span class="line">      stack<span class="number">=1</span>, locals<span class="number">=1</span>, args_size<span class="number">=1</span></span><br><span class="line">         <span class="number">0</span>: aload_0</span><br><span class="line">         <span class="number">1</span>: invokespecial <span class="number">#1</span>                  <span class="comment">// Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span></span><br><span class="line">         <span class="number">4</span>: return</span><br><span class="line"><span class="symbol">      LineNumberTable:</span></span><br><span class="line">        line <span class="number">7</span>: <span class="number">0</span></span><br><span class="line">  <span class="comment">//===========主要看看syncTask方法实现================</span></span><br><span class="line">  public void syncTask()<span class="comment">;</span></span><br><span class="line"><span class="symbol">    descriptor:</span> ()V</span><br><span class="line"><span class="symbol">    flags:</span> ACC_PUBLIC</span><br><span class="line"><span class="symbol">    Code:</span></span><br><span class="line">      stack<span class="number">=3</span>, locals<span class="number">=3</span>, args_size<span class="number">=1</span></span><br><span class="line">         <span class="number">0</span>: aload_0</span><br><span class="line">         <span class="number">1</span>: dup</span><br><span class="line">         <span class="number">2</span>: astore_1</span><br><span class="line">         <span class="number">3</span>: monitorenter  <span class="comment">//注意此处，进入同步方法</span></span><br><span class="line">         <span class="number">4</span>: aload_0</span><br><span class="line">         <span class="number">5</span>: dup</span><br><span class="line">         <span class="number">6</span>: getfield      <span class="number">#2</span>             <span class="comment">// Field i:I</span></span><br><span class="line">         <span class="number">9</span>: iconst_1</span><br><span class="line">        <span class="number">10</span>: iadd</span><br><span class="line">        <span class="number">11</span>: putfield      <span class="number">#2</span>            <span class="comment">// Field i:I</span></span><br><span class="line">        <span class="number">14</span>: aload_1</span><br><span class="line">        <span class="number">15</span>: monitorexit   <span class="comment">//注意此处，退出同步方法</span></span><br><span class="line">        <span class="number">16</span>: goto          <span class="number">24</span></span><br><span class="line">        <span class="number">19</span>: astore_2</span><br><span class="line">        <span class="number">20</span>: aload_1</span><br><span class="line">        <span class="number">21</span>: monitorexit <span class="comment">//注意此处，退出同步方法</span></span><br><span class="line">        <span class="number">22</span>: aload_2</span><br><span class="line">        <span class="number">23</span>: athrow</span><br><span class="line">        <span class="number">24</span>: return</span><br><span class="line">      Exception table:</span><br><span class="line">      <span class="comment">//省略其他字节码.......</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="symbol">SourceFile:</span> <span class="string">&quot;SyncCodeBlock.java&quot;</span></span><br></pre></td></tr></table></figure>
<p>我们主要关注字节码中的如下代码</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3</span>: monitorenter  <span class="comment">//进入同步方法</span></span><br><span class="line"><span class="comment">//..........省略其他  </span></span><br><span class="line"><span class="number">15</span>: monitorexit   <span class="comment">//退出同步方法</span></span><br><span class="line"><span class="number">16</span>: goto          <span class="number">24</span></span><br><span class="line"><span class="comment">//省略其他.......</span></span><br><span class="line"><span class="number">21</span>: monitorexit <span class="comment">//退出同步方法</span></span><br></pre></td></tr></table></figure>
<p>从字节码中可知同步语句块的实现使用的是<code>monitorenter</code> 和 <code>monitorexit</code> 指令，其中<code>monitorenter</code>指令指向同步代码块的开始位置，<code>monitorexit</code>指令则指明同步代码块的结束位置，当执行<code>monitorenter</code>指令时，当前线程将试图获取 <code>objectref</code>(即对象锁) 所对应的 <code>monitor</code> 的持有权，当 <code>objectref</code> 的 <code>monitor</code> 的进入计数器为 0，那线程可以成功取得 <code>monitor</code>，并将计数器值设置为 1，取锁成功。如果当前线程已经拥有 <code>objectref</code> 的 <code>monitor</code> 的持有权，那它可以重入这个 <code>monitor</code> (关于重入性稍后会分析)，重入时计数器的值也会加 1。倘若其他线程已经拥有 <code>objectref</code> 的 <code>monitor</code> 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即<code>monitorexit</code>指令被执行，执行线程将释放 <code>monitor</code>(锁)并设置计数器值为0 ，其他线程将有机会持有 <code>monitor</code> 。</p>
<p>值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 <code>monitorenter</code> 指令都有执行其对应 <code>monitorexit</code> 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 <code>monitorenter</code> 和 <code>monitorexit</code> 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 <code>monitorexit</code> 指令。从字节码中也可以看出多了一个<code>monitorexit</code>指令，它就是异常结束时被执行的释放monitor 的指令。</p>
<h2 id="synchronized方法底层原理"><a href="#synchronized方法底层原理" class="headerlink" title="synchronized方法底层原理"></a>synchronized方法底层原理</h2><p>方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的<code>方法表结构</code>(method_info Structure) 中的 <code>ACC_SYNCHRONIZED</code> 访问标志区分一个方法是否同步方法。当方法调用时，调用指令将会 检查方法的 <code>ACC_SYNCHRONIZED</code> 访问标志是否被设置，如果设置了，执行线程将先持有 <code>monitor</code> （虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放 <code>monitor</code> 。在方法执行期间，执行线程持有了 <code>monitor</code> ，其他任何线程都无法再获得同一个 <code>monitor</code> 。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的 <code>monitor</code> 将在异常抛到同步方法之外时自动释放。下面我们看看字节码层面如何实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SyncMethod</span> </span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">int</span> i;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">syncTask</span><span class="params">()</span></span>&#123;</span><br><span class="line">           i++;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用javap反编译后的字节码如下：</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">Classfile</span> /Users/zejian/Downloads/Java8_Action/src/main/java/com/zejian/concurrencys/SyncMethod.class</span><br><span class="line">  Last modified <span class="number">2017</span>-<span class="number">6</span>-<span class="number">2</span><span class="comment">; size 308 bytes</span></span><br><span class="line">  MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94</span><br><span class="line">  Compiled from <span class="string">&quot;SyncMethod.java&quot;</span></span><br><span class="line"><span class="symbol">public</span> class com.zejian.concurrencys.SyncMethod</span><br><span class="line">  minor version: <span class="number">0</span></span><br><span class="line">  major version: <span class="number">52</span></span><br><span class="line"><span class="symbol">  flags:</span> ACC_PUBLIC, ACC_SUPER</span><br><span class="line"><span class="symbol">Constant</span> pool<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">//省略没必要的字节码</span></span><br><span class="line">  <span class="comment">//==================syncTask方法======================</span></span><br><span class="line">  public synchronized void syncTask()<span class="comment">;</span></span><br><span class="line"><span class="symbol">    descriptor:</span> ()V</span><br><span class="line">    <span class="comment">//方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法</span></span><br><span class="line"><span class="symbol">    flags:</span> ACC_PUBLIC, ACC_SYNCHRONIZED</span><br><span class="line"><span class="symbol">    Code:</span></span><br><span class="line">      stack<span class="number">=3</span>, locals<span class="number">=1</span>, args_size<span class="number">=1</span></span><br><span class="line">         <span class="number">0</span>: aload_0</span><br><span class="line">         <span class="number">1</span>: dup</span><br><span class="line">         <span class="number">2</span>: getfield      <span class="number">#2</span>                  <span class="comment">// Field i:I</span></span><br><span class="line">         <span class="number">5</span>: iconst_1</span><br><span class="line">         <span class="number">6</span>: iadd</span><br><span class="line">         <span class="number">7</span>: putfield      <span class="number">#2</span>                  <span class="comment">// Field i:I</span></span><br><span class="line">        <span class="number">10</span>: return</span><br><span class="line"><span class="symbol">      LineNumberTable:</span></span><br><span class="line">        line <span class="number">12</span>: <span class="number">0</span></span><br><span class="line">        line <span class="number">13</span>: <span class="number">10</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="symbol">SourceFile:</span> <span class="string">&quot;SyncMethod.java&quot;</span></span><br></pre></td></tr></table></figure>
<p>从字节码中可以看出，synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。这便是synchronized锁在同步代码块和同步方法上实现的基本原理。</p>
<p>同时我们还必须注意到的是在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁，接下来我们将简单了解一下Java官方在JVM层面对synchronized锁的优化。</p>
<h2 id="Java虚拟机对synchronized的优化"><a href="#Java虚拟机对synchronized的优化" class="headerlink" title="Java虚拟机对synchronized的优化"></a>Java虚拟机对synchronized的优化</h2><p>锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。<br>随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级，下面我们将介绍偏向锁和轻量级锁以及JVM的其他优化手段，阐述Java虚拟机所提供的每个锁的核心优化思想，毕竟涉及到具体过程比较繁琐，如需了解详细过程可以查阅《深入理解Java虚拟机原理》。</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，<strong>在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得</strong>，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，<strong>如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提高了程序的性能</strong>。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果。但对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>倘若偏向锁失败，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“<strong>对绝大部分的锁，在整个同步周期内都不存在竞争</strong>”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。</p>
<h4 id="加锁过程"><a href="#加锁过程" class="headerlink" title="加锁过程"></a>加锁过程</h4><p>锁升级为轻量级锁之后，对象的 <code>Mark word</code> 也会进行相应的的变化。升级为轻量级锁的过程：</p>
<ul>
<li>线程在自己的栈桢中创建锁记录 LockRecord。</li>
<li>将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。</li>
<li>将锁记录中的 Owner 指针指向锁对象。</li>
<li>将锁对象的对象头的 MarkWord替换为指向锁记录的指针。</li>
</ul>
<h4 id="通过自旋锁加锁"><a href="#通过自旋锁加锁" class="headerlink" title="通过自旋锁加锁"></a>通过自旋锁加锁</h4><p>轻量级锁失败后，<strong>虚拟机为了避免线程真实地在操作系统层面挂起</strong>，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，<strong>线程持有锁的时间都不会太长</strong>，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。</p>
<p>轻量级锁在加锁过程中，用到了自旋锁所谓自旋，就是指当有另外一个线程来竞争锁时，这个线程会在原地循环等待，而不是把该线程给阻塞，直到那个获得锁的线程释放锁之后，这个线程就可以马上获得锁的。注意，锁在原地循环的时候，是会消耗 cpu 的，就相当于在执行一个啥也没有的 for 循环。所以，轻量级锁适用于那些同步代码块执行的很快的场景，这样，线程原地等待很短的时间就能够获得锁了。自旋锁的使用，其实也是有一定的概率背景，在大部分同步代码块执行的时间都是很短的。所以通过看似无异议的循环反而能提升锁的性能。但是自旋必要有一定的条件控制，否则如果一个线程执行同步代码块的时间很长，那么这个线程不断的循环反而会消耗 CPU 资源。默认情况下自旋的次数是 10 次，可以通过 preBlockSpin 来修改在 JDK1.6 之后，引入了自适应自旋锁，自适应意味着自旋的次数不是固定不变的，而是根据前一次在同一个锁上自旋的时间以及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。</p>
<h3 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h3><p>消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by zejian on 2017/6/4.</span></span><br><span class="line"><span class="comment"> * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创]</span></span><br><span class="line"><span class="comment"> * 消除StringBuffer同步锁</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringBufferRemoveSync</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(String str1, String str2)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//StringBuffer是线程安全,由于sb只会在append方法中使用,不可能被其他线程引用</span></span><br><span class="line">        <span class="comment">//因此sb属于不可能共享的资源,JVM会自动消除内部的锁</span></span><br><span class="line">        StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        sb.append(str1).append(str2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        StringBufferRemoveSync rmsync = <span class="keyword">new</span> StringBufferRemoveSync();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000000</span>; i++) &#123;</span><br><span class="line">            rmsync.add(<span class="string">&quot;abc&quot;</span>, <span class="string">&quot;123&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="关于synchronized-可能需要了解的关键点"><a href="#关于synchronized-可能需要了解的关键点" class="headerlink" title="关于synchronized 可能需要了解的关键点"></a>关于synchronized 可能需要了解的关键点</h2><h3 id="synchronized的可重入性"><a href="#synchronized的可重入性" class="headerlink" title="synchronized的可重入性"></a>synchronized的可重入性</h3><p>从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AccountingSync</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> AccountingSync instance=<span class="keyword">new</span> AccountingSync();</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> j=<span class="number">0</span>;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">1000000</span>;j++)&#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//this,当前实例对象锁</span></span><br><span class="line">            <span class="keyword">synchronized</span>(<span class="keyword">this</span>)&#123;</span><br><span class="line">                i++;</span><br><span class="line">                increase();<span class="comment">//synchronized的可重入性</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span></span>&#123;</span><br><span class="line">        j++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread t1=<span class="keyword">new</span> Thread(instance);</span><br><span class="line">        Thread t2=<span class="keyword">new</span> Thread(instance);</span><br><span class="line">        t1.start();t2.start();</span><br><span class="line">        t1.join();t2.join();</span><br><span class="line">        System.out.println(i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在获取当前实例对象锁后进入synchronized代码块执行同步代码，并在代码块中调用了当前实例对象的另外一个synchronized方法，再次请求当前实例锁时，将被允许，进而执行方法体代码，这就是重入锁最直接的体现，需要特别注意另外一种情况，<strong>当子类继承父类时，子类也是可以通过可重入锁调用父类的同步方法</strong>。注意由于synchronized是基于monitor实现的，因此每次重入，monitor中的计数器仍会加1。</p>
<h3 id="三种锁的对比"><a href="#三种锁的对比" class="headerlink" title="三种锁的对比"></a>三种锁的对比</h3><p><img src="/images/java/multithread/monitor/synchronized-3-locks.png" alt="三种锁对比"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/io/high-performance-network-programming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/io/high-performance-network-programming/" class="post-title-link" itemprop="url">高性能网络编程IO模型与线程模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-19 17:28:00" itemprop="dateCreated datePublished" datetime="2019-03-19T17:28:00+08:00">2019-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:52:14" itemprop="dateModified" datetime="2021-02-09T09:52:14+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="C10K问题"><a href="#C10K问题" class="headerlink" title="C10K问题"></a>C10K问题</h2><p><a target="_blank" rel="noopener" href="http://www.kegel.com/c10k.html">C10K问题</a>: 一万个客户端同时连接</p>
<h3 id="常识一：文件句柄限制"><a href="#常识一：文件句柄限制" class="headerlink" title="常识一：文件句柄限制"></a>常识一：文件句柄限制</h3><p>在linux下每一个tcp连接都要占一个文件描述符，一旦文件描述符使用完了，新的连接到来返回给我们的错误是“Socket/File:Can’t open so many files”。</p>
<p>操作系统可以打开的最大文件数的限制。</p>
<h4 id="1-进程限制"><a href="#1-进程限制" class="headerlink" title="1 进程限制"></a>1 进程限制</h4><p>执行 <code>ulimit -n</code> 输出 <code>1024</code>，说明对于一个进程而言最多只能打开1024个文件，所以采用此配置最多可以并发上千个TCP连接。<br>临时修改：ulimit -n 1000000，但是这种临时修改只对当前登录用户目前的使用环境有效，系统重启或用户退出后就会失效。</p>
<p>重启后失效的修改: （CentOS 6.5下测试，重启后未发现失效），编辑 <code>/etc/security/limits.conf</code> 文件， 修改后内容为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">soft nofile 1000000</span><br><span class="line">hard nofile 1000000</span><br></pre></td></tr></table></figure>
<p>永久修改：编辑/etc/rc.local，在其后添加如下内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ulimit -SHn 1000000</span><br></pre></td></tr></table></figure>
<h4 id="2-全局限制"><a href="#2-全局限制" class="headerlink" title="2 全局限制"></a>2 全局限制</h4><p>执行<code>cat /proc/sys/fs/file-nr</code>输出<code>9344 0 592026</code>，分别为：</p>
<ol>
<li>已经分配的文件句柄数，</li>
<li>已经分配但没有使用的文件句柄数，</li>
<li>最大文件句柄数。</li>
</ol>
<p>但在kernel 2.6版本中第二项的值总为0，这并不是一个错误，它实际上意味着已经分配的文件描述符无一浪费的都已经被使用了。我们可以把这个数值改大些，用 root 权限修改 <code>/etc/sysctl.conf</code> 文件:</p>
<ul>
<li>fs.file-max = 1000000</li>
<li>net.ipv4.ip_conntrack_max = 1000000</li>
<li>net.ipv4.netfilter.ip_conntrack_max = 1000000</li>
</ul>
<h3 id="常识二：端口号范围限制？"><a href="#常识二：端口号范围限制？" class="headerlink" title="常识二：端口号范围限制？"></a>常识二：端口号范围限制？</h3><p>操作系统上端口号1024以下是系统保留的，从1024-65535是用户使用的。每个TCP连接都要占一个端口号, 但可以创建的最大并发连接不只60000个</p>
<h4 id="如何标识一个TCP连接："><a href="#如何标识一个TCP连接：" class="headerlink" title="如何标识一个TCP连接："></a>如何标识一个TCP连接：</h4><p>系统用一个4四元组来唯一标识一个TCP连接：<code>&#123;local ip, local port,remote ip,remote port&#125;</code>。</p>
<blockquote>
<p>《UNIX网络编程：卷一》第四章中对accept的讲解，第二个参数cliaddr代表了客户端的ip地址和端口号。而服务端实际只使用了bind时这一个端口，说明端口号65535并不是并发量的限制。</p>
</blockquote>
<h4 id="server最大tcp连接数："><a href="#server最大tcp连接数：" class="headerlink" title="server最大tcp连接数："></a>server最大tcp连接数：</h4><p>server通常固定在某个本地端口上监听，等待client的连接请求。不考虑地址重用（unix的SO_REUSEADDR选项）的情况下，即使server端有多个ip，本地监听端口也是独占的，因此server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，因此最大tcp连接为<code>客户端ip数×客户端port数</code>，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为<code>2的32次方（ip数）×2的16次方（port数）</code>，也就是server端单机最大tcp连接数约为<code>2的48次方</code>。</p>
<h2 id="I-O-Model"><a href="#I-O-Model" class="headerlink" title="I/O Model"></a>I/O Model</h2><p>最初的服务器都是<strong>基于进程/线程模型</strong>的，一个TCP连接，就需要分配1个进程（或者线程）。而进程又是操作系统最昂贵的资源，一台机器无法创建很多进程。<br>如果是C10K就要创建1万个进程，那么单机而言操作系统是无法承受的（往往出现效率低下甚至完全瘫痪）。<br>如果是采用分布式系统，维持1亿用户在线需要10万台服务器，成本巨大，也只有Facebook、Google、雅虎等巨头才有财力购买如此多的服务器。</p>
<p>传统的同步阻塞I/O模型都是一样的，处理的方式都是requests per second，并发10K和100的区别关键在于CPU。<br>创建的进程线程多了，<strong>数据拷贝频繁（缓存I/O、内核将数据拷贝到用户进程空间、阻塞）， 进程/线程上下文切换消耗大</strong>， 导致操作系统崩溃，这就是C10K问题的本质！</p>
<h3 id="互联网服务端处理网络请求的原理"><a href="#互联网服务端处理网络请求的原理" class="headerlink" title="互联网服务端处理网络请求的原理"></a>互联网服务端处理网络请求的原理</h3><p>典型互联网服务端处理网络请求的典型过程：</p>
<p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/211858pgsyanbk1yffennv.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_1.jpeg">    </p>
<p>由上图可以看到，主要处理步骤包括： </p>
<p> 1）获取请求数据，客户端与服务器建立连接发出请求，服务器接受请求（1-3）；<br> 2）构建响应，当服务器接收完请求，并在用户空间处理客户端的请求，直到构建响应完成（4）；<br> 3）返回数据，服务器将已构建好的响应再通过内核空间的网络 I/O 发还给客户端（5-7）。</p>
<p>设计服务端并发模型时，主要有如下两个关键点： </p>
<p> 1）服务器如何管理连接，获取输入数据；<br> 2）服务器如何处理请求。</p>
<h3 id="“I-O-模型”的基本认识"><a href="#“I-O-模型”的基本认识" class="headerlink" title="“I/O 模型”的基本认识"></a>“I/O 模型”的基本认识</h3><h4 id="阻塞调用与非阻塞调用："><a href="#阻塞调用与非阻塞调用：" class="headerlink" title="阻塞调用与非阻塞调用："></a>阻塞调用与非阻塞调用：</h4><ul>
<li>阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回；</li>
<li>非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。</li>
</ul>
<p>两者的最大区别在于被调用方在收到请求到返回结果之前的这段时间内，调用方是否一直在等待。<strong>阻塞</strong>是指调用方一直在等待而且别的事情什么都不做；<strong>非阻塞</strong>是指调用方先去忙别的事情。</p>
<h4 id="同步处理与异步处理："><a href="#同步处理与异步处理：" class="headerlink" title="同步处理与异步处理："></a>同步处理与异步处理：</h4><p>同步处理是指被调用方得到最终结果之后才返回给调用方；异步处理是指被调用方先返回应答，然后再计算调用结果，计算完最终结果后再通知并返回给调用方。</p>
<p>阻塞、非阻塞和同步、异步的区别（阻塞、非阻塞和同步、异步其实针对的对象是不一样的）：</p>
<ul>
<li>1）阻塞、非阻塞的讨论对象是调用者；</li>
<li>2）同步、异步的讨论对象是被调用者。</li>
</ul>
<h4 id="recvfrom-函数："><a href="#recvfrom-函数：" class="headerlink" title="recvfrom 函数："></a>recvfrom 函数：</h4><p>// FIXME 究竟什么是Socket，操作系统套接字代表的是什么</p>
<p>recvfrom 函数(经 <code>Socket</code> 接收数据)，这里把它视为系统调用。</p>
<p>一个输入操作通常包括两个不同的阶段：</p>
<ul>
<li>1）等待数据准备好；</li>
<li>2）从内核向进程复制数据。</li>
</ul>
<p>对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。</p>
<p>实际应用程序在系统调用完成上面的 2 步操作时，调用方式的阻塞、非阻塞，操作系统在处理应用程序请求时，处理方式的同步、异步处理的不同，可以分为 5 种 I/O 模型（下面的章节将逐个展开介绍）。（参考《UNIX网络编程卷1》）</p>
<h3 id="阻塞式-I-O-blocking-I-O）"><a href="#阻塞式-I-O-blocking-I-O）" class="headerlink" title="阻塞式 I/O(blocking I/O）"></a>阻塞式 I/O(blocking I/O）</h3><p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/212717yp8iwt5z8j1niw8a.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_2.jpeg">    </p>
<p> 在阻塞式 I/O 模型中，应用程序在从调用 recvfrom 开始到它返回有数据报准备好这段时间是阻塞的，recvfrom 返回成功后，应用进程开始处理数据报。</p>
<p><strong>比喻：</strong> 一个人在钓鱼，当没鱼上钩时，就坐在岸边一直等。</p>
<p><strong>优点：</strong> 程序简单，在阻塞等待数据期间进程/线程挂起，基本不会占用 CPU 资源。</p>
<p><strong>缺点：</strong> 每个连接需要独立的进程/线程单独处理，当并发请求量大时为了维护程序，内存、线程切换开销较大，这种模型在实际生产中很少使用。</p>
<h3 id="非阻塞式-I-O-non-blocking-I-O）"><a href="#非阻塞式-I-O-non-blocking-I-O）" class="headerlink" title="非阻塞式 I/O (non-blocking I/O）"></a>非阻塞式 I/O (non-blocking I/O）</h3><p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/212910wn44nrr6zp5siiuo.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_3.jpeg"></p>
<p> 应用程序把一个套接口设置为非阻塞，就是告诉内核，当所请求的 I/O 操作无法完成时，不要将进程睡眠。<br> 而是返回一个错误，应用程序基于 I/O 操作函数将不断的轮询数据是否已经准备好，如果没有准备好，继续轮询，直到数据准备好为止。</p>
<p><strong>比喻：</strong> 边钓鱼边玩手机，隔会再看看有没有鱼上钩，有的话就迅速拉杆。</p>
<p><strong>优点：</strong> 不会阻塞在内核的等待数据过程，每次发起的 I/O 请求可以立即返回，不用阻塞等待，实时性较好。</p>
<p><strong>缺点：</strong> 轮询将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低，所以一般 Web 服务器不使用这种 I/O 模型。</p>
<h3 id="I-O-多路复用-I-O-multiplexing）"><a href="#I-O-多路复用-I-O-multiplexing）" class="headerlink" title="I/O 多路复用(I/O multiplexing）"></a>I/O 多路复用(I/O multiplexing）</h3><p><img src="http://www.52im.net/data/attachment/forum/201809/05/213041mtejdsoeojfjy7dd.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_4.jpeg"></p>
<p> 在 I/O 复用模型中，会用到 Select 或 Poll 函数或 Epoll 函数(Linux 2.6 以后的内核开始支持)，这两个函数也会使进程阻塞，但是和阻塞 I/O 有所不同。</p>
<p> 这两个函数可以同时阻塞多个 I/O 操作，而且可以同时对多个读操作，多个写操作的 I/O 函数进行检测，直到有数据可读或可写时，才真正调用 I/O 操作函数。</p>
<p><strong>比喻：</strong> 放了一堆鱼竿，在岸边一直守着这堆鱼竿，没鱼上钩就玩手机。</p>
<p><strong>优点：</strong> 可以基于一个阻塞对象，同时在多个描述符上等待就绪，而不是使用多个线程(每个文件描述符一个线程)，这样可以大大节省系统资源。</p>
<p><strong>缺点：</strong> 当连接数较少时效率相比多线程+阻塞 I/O 模型效率较低，可能延迟更大，因为单个连接处理需要 2 次系统调用，占用时间会有增加。</p>
<p>众所周之，Nginx这样的高性能互联网反向代理服务器大获成功的关键就是得益于<code>Epoll</code>。</p>
<h3 id="信号驱动式-I-O-（signal-driven-I-O"><a href="#信号驱动式-I-O-（signal-driven-I-O" class="headerlink" title="信号驱动式 I/O （signal-driven I/O)"></a>信号驱动式 I/O （signal-driven I/O)</h3><p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/213143a7n3mnxb38ybgxy3.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_5.jpeg"></p>
<p> 在信号驱动式 I/O 模型中，应用程序使用套接口进行信号驱动 I/O，并安装一个信号处理函数，进程继续运行并不阻塞。<br> 当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中调用 I/O 操作函数处理数据。</p>
<p><strong>比喻：</strong> 鱼竿上系了个铃铛，当铃铛响，就知道鱼上钩，然后可以专心玩手机。</p>
<p><strong>优点：</strong> 线程并没有在等待数据时被阻塞，可以提高资源的利用率。</p>
<p><strong>缺点：</strong> 信号 I/O 在大量 IO 操作时可能会因为信号队列溢出导致没法通知。</p>
<p> 信号驱动 I/O 尽管对于处理 UDP 套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。</p>
<p> 但是，对于 TCP 而言，信号驱动的 I/O 方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源，与前几种方式相比优势尽失。</p>
<h3 id="异步-I-O（即AIO，全称asynchronous-I-O）"><a href="#异步-I-O（即AIO，全称asynchronous-I-O）" class="headerlink" title="异步 I/O（即AIO，全称asynchronous I/O）"></a>异步 I/O（即AIO，全称asynchronous I/O）</h3><p><img src="http://www.52im.net/data/attachment/forum/201809/05/213218wbeovsvt6g7s4zsj.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_6.jpeg"></p>
<p> 由 POSIX 规范定义，应用程序告知内核启动某个操作，并让内核在整个操作（包括将数据从内核拷贝到应用程序的缓冲区）完成后通知应用程序。</p>
<p> 这种模型与信号驱动模型的主要区别在于：信号驱动 I/O 是由内核通知应用程序何时启动一个 I/O 操作，而异步 I/O 模型是由内核通知应用程序 I/O 操作何时完成。</p>
<p><strong>优点：</strong> 异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠。</p>
<p><strong>缺点：</strong> 要实现真正的异步 I/O，操作系统需要做大量的工作。目前 Windows 下通过 IOCP 实现了真正的异步 I/O。</p>
<p> 而在 Linux 系统下，Linux 2.6才引入，目前 AIO 并不完善，因此在 Linux 下实现高并发网络编程时都是以 IO 复用模型模式为主。</p>
<p> 关于AOI的介绍，请见：《Java新一代网络编程模型AIO原理及Linux系统AIO介绍》。</p>
<h3 id="5-种-I-O-模型总结"><a href="#5-种-I-O-模型总结" class="headerlink" title="5 种 I/O 模型总结"></a>5 种 I/O 模型总结</h3><p>  <img src="http://www.52im.net/data/attachment/forum/201809/05/213459mmmhohhgwom24uoj.jpeg" alt="高性能网络编程(五)：一文读懂高性能网络编程中的I/O模型_7.jpeg">    </p>
<p> 从上图中我们可以看出，越往后，阻塞越少，理论上效率也是最优。</p>
<p> 这五种 I/O 模型中，前四种属于同步 I/O，因为其中真正的 I/O 操作(recvfrom)将阻塞进程/线程，只有异步 I/O 模型才与 POSIX 定义的异步 I/O 相匹配。</p>
<h2 id="高性能网络编程中的线程模型"><a href="#高性能网络编程中的线程模型" class="headerlink" title="高性能网络编程中的线程模型"></a>高性能网络编程中的线程模型</h2><h3 id="传统阻塞-I-O-服务模型"><a href="#传统阻塞-I-O-服务模型" class="headerlink" title="传统阻塞 I/O 服务模型"></a>传统阻塞 I/O 服务模型</h3><p><img src="http://www.52im.net/data/attachment/forum/201809/06/195333v2cj2o6y92d2zp5z.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_1.jpeg">    </p>
<p><strong>特点：</strong></p>
<p>1）采用阻塞式 I/O 模型获取输入数据；<br>2）每个连接都需要独立的线程完成数据输入，业务处理，数据返回的完整操作。</p>
<p><strong>存在问题：</strong></p>
<p>1）当并发数较大时，需要创建大量线程来处理连接，系统资源占用较大；<br>2）连接建立后，如果当前线程暂时没有数据可读，则线程就阻塞在 Read 操作上，造成线程资源浪费。</p>
<h3 id="Reactor-模式"><a href="#Reactor-模式" class="headerlink" title="Reactor 模式"></a>Reactor 模式</h3><h4 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h4><p>针对传统阻塞 I/O 服务模型的 2 个缺点，比较常见的有如下解决方案： </p>
<p> 1）基于 I/O 复用模型：多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接。当某条连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理；<br> 2）基于线程池复用线程资源：不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。</p>
<p>I/O 复用结合线程池，这就是 Reactor 模式基本设计思想，如下图：</p>
<p><img src="http://www.52im.net/data/attachment/forum/201809/06/195839s5hi3te5pxueq5ze.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_2.jpeg"></p>
<p>Reactor 模式，是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。 </p>
<p>服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor 模式也叫 Dispatcher 模式。即 I/O 多了复用统一监听事件，收到事件后分发(Dispatch 给某进程)，是编写高性能网络服务器的必备技术之一。</p>
<p>Reactor 模式中有 2 个关键组成：</p>
<p>1）Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人；<br>2）Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。</p>
<p>根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现：</p>
<p>1）单 Reactor 单线程；<br>2）单 Reactor 多线程；<br>3）主从 Reactor 多线程。</p>
<p>下面详细介绍这 3 种实现方式。</p>
<h4 id="单-Reactor-单线程"><a href="#单-Reactor-单线程" class="headerlink" title="单 Reactor 单线程"></a>单 Reactor 单线程</h4><p><img src="http://www.52im.net/data/attachment/forum/201809/06/200048bgll2l41w72174ot.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_3.jpeg">    </p>
<p>其中，Select 是前面 I/O 复用模型介绍的标准网络编程 API，可以实现应用程序通过一个阻塞对象监听多路连接请求，其他方案示意图类似。</p>
<p>方案说明：</p>
<p>1）Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发；<br>2）如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理；<br>3）如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应；<br>4）Handler 会完成 Read→业务处理→Send 的完整业务流程。</p>
<p><strong>优点：</strong></p>
<p>模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成。</p>
<p>缺点：</p>
<p>性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈。</p>
<p> 可靠性问题，线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。</p>
<p><strong>使用场景：</strong></p>
<p>客户端的数量有限，业务处理非常快速，比如 Redis，业务处理的时间复杂度 O(1)。</p>
<h4 id="单-Reactor-多线程"><a href="#单-Reactor-多线程" class="headerlink" title="单 Reactor 多线程"></a>单 Reactor 多线程</h4><p>  <img src="http://www.52im.net/data/attachment/forum/201809/06/200650wun9j9ghkgk7ngna.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_4.jpeg">    </p>
<p>方案说明：</p>
<ul>
<li>1）Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发；</li>
<li>2）如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后续的各种事件；</li>
<li>3）如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应；</li>
<li>4）Handler 只负责响应事件，不做具体业务处理，通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理；</li>
<li>5）Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 Handler 进行处理；</li>
<li>6）Handler 收到响应结果后通过 Send 将响应结果返回给 Client。</li>
</ul>
<p>优点：</p>
<p>可以充分利用多核 CPU 的处理能力。</p>
<p>缺点：</p>
<p>多线程数据共享和访问比较复杂；Reactor 承担所有事件的监听和响应，在单线程中运行，高并发场景下容易成为性能瓶颈。</p>
<h4 id="主从-Reactor-多线程"><a href="#主从-Reactor-多线程" class="headerlink" title="主从 Reactor 多线程"></a>主从 Reactor 多线程</h4><p>  <img src="http://www.52im.net/data/attachment/forum/201809/06/200759gg777fr7v7wzcr7r.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_5.jpeg">    </p>
<p> 针对单 Reactor 多线程模型中，Reactor 在单线程中运行，高并发场景下容易成为性能瓶颈，可以让 Reactor 在多线程中运行。</p>
<p>方案说明：</p>
<ul>
<li>1）Reactor 主线程 MainReactor 对象通过 Select 监控建立连接事件，收到事件后通过 Acceptor 接收，处理建立连接事件；</li>
<li>2）Acceptor 处理建立连接事件后，MainReactor 将连接分配 Reactor 子线程给 SubReactor 进行处理；</li>
<li>3）SubReactor 将连接加入连接队列进行监听，并创建一个 Handler 用于处理各种连接事件；</li>
<li>4）当有新的事件发生时，SubReactor 会调用连接对应的 Handler 进行响应；</li>
<li>5）Handler 通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理；</li>
<li>6）Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 Handler 进行处理；</li>
<li>7）Handler 收到响应结果后通过 Send 将响应结果返回给 Client。</li>
</ul>
<p>优点：</p>
<p>父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。</p>
<p> 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。</p>
<p> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>3 种模式可以用个比喻来理解：</p>
<p>（餐厅常常雇佣接待员负责迎接顾客，当顾客入坐后，侍应生专门为这张桌子服务）</p>
<ul>
<li>1）单 Reactor 单线程，接待员和侍应生是同一个人，全程为顾客服务；</li>
<li>2）单 Reactor 多线程，1 个接待员，多个侍应生，接待员只负责接待；</li>
<li>3）主从 Reactor 多线程，多个接待员，多个侍应生。</li>
</ul>
<p>Reactor 模式具有如下的优点：</p>
<ul>
<li>1）响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的；</li>
<li>2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销；</li>
<li>3）可扩展性，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源；</li>
<li>4）可复用性，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。</li>
</ul>
<h3 id="Proactor-模型"><a href="#Proactor-模型" class="headerlink" title="Proactor 模型"></a>Proactor 模型</h3><p> 在 Reactor 模式中，Reactor 等待某个事件或者可应用或者操作的状态发生（比如文件描述符可读写，或者是 Socket 可读写）。 然后把这个事件传给事先注册的 Handler（事件处理函数或者回调函数），由后者来做实际的读写操作。其中的读写操作都需要应用程序同步操作，所以 Reactor 是非阻塞同步网络模型。</p>
<p> 如果把 I/O 操作改为异步，即交给操作系统来完成就能进一步提升性能，这就是异步网络模型 Proactor。</p>
<p>  <img src="http://www.52im.net/data/attachment/forum/201809/06/201251i0om3mro9wtcxrty.jpeg" alt="高性能网络编程(六)：一文读懂高性能网络编程中的线程模型_1.jpeg">    </p>
<p>Proactor 是和异步 I/O 相关的，详细方案如下：</p>
<p>1）Proactor Initiator 创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 AsyOptProcessor（Asynchronous Operation Processor）注册到内核；<br>2）AsyOptProcessor 处理注册请求，并处理 I/O 操作；<br>3）AsyOptProcessor 完成 I/O 操作后通知 Proactor；<br>4）Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；<br>5）Handler 完成业务处理。</p>
<p>可以看出 Proactor 和 Reactor 的区别：</p>
<p>1）Reactor 是在事件发生时就通知事先注册的事件（读写在应用程序线程中处理完成）；<br>2）Proactor 是在事件发生时基于异步 I/O 完成读写操作（由内核完成），待 I/O 操作完成后才回调应用程序的处理器来进行业务处理。</p>
<p>理论上 Proactor 比 Reactor 效率更高，异步 I/O 更加充分发挥 DMA(Direct Memory Access，直接内存存取)的优势。</p>
<p>但是Proactor有如下缺点：</p>
<p>1）编程复杂性，由于异步操作流程的事件的初始化和事件完成在时间和空间上都是相互分离的，因此开发异步应用程序更加复杂。应用程序还可能因为反向的流控而变得更加难以 Debug；<br>2）内存使用，缓冲区在读或写操作的时间段内必须保持住，可能造成持续的不确定性，并且每个并发操作都要求有独立的缓存，相比 Reactor 模式，在 Socket 已经准备好读或写前，是不要求开辟缓存的；<br>3）操作系统支持，Windows 下通过 IOCP 实现了真正的异步 I/O，而在 Linux 系统下，Linux 2.6 才引入，目前异步 I/O 还不完善。</p>
<p>因此在 Linux 下实现高并发网络编程都是以 Reactor 模型为主。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">222</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">114</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
