<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Guadazi">
<meta property="og:url" content="http://example.com/page/11/index.html">
<meta property="og:site_name" content="Guadazi">
<meta property="og:locale">
<meta property="article:author" content="aaronzhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/11/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Guadazi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guadazi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-config-dynamic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-config-dynamic/" class="post-title-link" itemprop="url">Flink/Storm 动态更新配置实现方案</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-06-09 00:00:00" itemprop="dateCreated datePublished" datetime="2019-06-09T00:00:00+08:00">2019-06-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:28" itemprop="dateModified" datetime="2021-02-09T09:38:28+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>实时计算处理无限数据流，对系统可用性十分敏感，然而业务需求具有必然的更新需求，动态更新实时计算的配置是常见的需求，比如动态增加用户白名单、业务数据在线 debug、新增广告位统计等等。然而，实现并不简单，Apache Strom 和 Apache Storm 具有不同的架构，实现方式也不尽相同。</p>
<p>Apache Strom(这里不包括 Trident)，所有的计算逻辑都是通过实现spout 和 bolt，运行在 task节点上，因此与业务逻辑相关的状态管理、配置管理以及输入输出的控制等均可以定义在 bolt 中，如定时一分钟轮询配置变化、定时 checkpoint 近似数据集等。此外，配置同样可以通过控制流的方式与数据流 uion 到一起，在计算节点检测判断控制流的关键字来实现配置更新的目的。</p>
<p>Apache Flink 的函数式 API 封装要比 Storm 要完善，而灵活性不比 Strom。实现配置动态更新有两种方式，一是在算子中定时轮询拉取配置信息，二是利用广播状态和控制流。</p>
<h1 id="asyncIO"><a href="#asyncIO" class="headerlink" title="asyncIO"></a>asyncIO</h1><h1 id="stateBroadcast"><a href="#stateBroadcast" class="headerlink" title="stateBroadcast"></a>stateBroadcast</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-cep-office/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-cep-office/" class="post-title-link" itemprop="url">【转载】flink cep官方文档</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-06-09 00:00:00" itemprop="dateCreated datePublished" datetime="2019-06-09T00:00:00+08:00">2019-06-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:28" itemprop="dateModified" datetime="2021-02-09T09:38:28+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://github.com/crestofwave1/oneFlink/blob/master/doc/CEP/FlinkCEPOfficeWeb.md">转载自 https://github.com/crestofwave1/oneFlink/blob/master/doc/CEP/FlinkCEPOfficeWeb.md</a></p>
<h2 id="0-本文概述简介"><a href="#0-本文概述简介" class="headerlink" title="0. 本文概述简介"></a>0. 本文概述简介</h2><p>FlinkCEP是在Flink之上实现的复杂事件处理（CEP）库。 它允许你在无界的事件流中检测事件模式，让你有机会掌握数据中重要的事项。</p>
<p>本文描述了Flink CEP中可用的API调用。 首先介绍Pattern API，它允许你指定要在流中检测的模式，然后介绍如何检测匹配事件序列并对其进行操作。 然后，我们将介绍CEP库在处理事件时间延迟时所做的假设。</p>
<h2 id="1-入门"><a href="#1-入门" class="headerlink" title="1.入门"></a>1.入门</h2><p>首先是要在你的pom.xml文件中，引入CEP库。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-cep_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>注意要应用模式匹配的DataStream中的事件必须实现正确的equals（）和hashCode（）方法，因为FlinkCEP使用它们来比较和匹配事件。</p>
<p>第一个demo如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(</span><br><span class="line">        <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> event.getId() == <span class="number">42</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ).next(<span class="string">&quot;middle&quot;</span>).subtype(SubEvent.class).where(</span><br><span class="line">        <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent subEvent)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> subEvent.getVolume() &gt;= <span class="number">10.0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ).followedBy(<span class="string">&quot;end&quot;</span>).where(</span><br><span class="line">         <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> event.getName().equals(<span class="string">&quot;end&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(input, pattern);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Alert&gt; result = patternStream.select(</span><br><span class="line">    <span class="keyword">new</span> PatternSelectFunction&lt;Event, Alert&gt; &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Alert <span class="title">select</span><span class="params">(Map&lt;String, List&lt;Event&gt;&gt; pattern)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> createAlertFrom(pattern);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="2-Pattern-API"><a href="#2-Pattern-API" class="headerlink" title="2.Pattern API"></a>2.Pattern API</h2><p>Pattern API允许你定义要从输入流中提取的复杂模式序列。</p>
<p>每个复杂模式序列都是由多个简单模式组成，即寻找具有相同属性的单个事件的模式。我们可以先定义一些简单的模式，然后组合成复杂的模式序列。 可以将模式序列视为此类模式的结构图，基于用户指定的条件从一个模式转换到下一个模式，例如， event.getName().equals(“start”)。 匹配是一系列输入事件，通过一系列有效的模式转换访问复杂模式图中的所有模式。</p>
<p>注意每个模式必须具有唯一的名称，以便后续可以使用该名称来标识匹配的事件。</p>
<p>注意模式名称不能包含字符“：”。</p>
<p>在本节接下来的部分，我们将首先介绍如何定义单个模式，然后如何将各个模式组合到复杂模式中。</p>
<h3 id="2-1-单个模式"><a href="#2-1-单个模式" class="headerlink" title="2.1 单个模式"></a>2.1 单个模式</h3><p>Pattern可以是单单个，也可以是循环模式。单个模式接受单个事件，而循环模式可以接受多个事件。在模式匹配符号中，模式“a b + c？d”（或“a”，后跟一个或多个“b”，可选地后跟“c”，后跟“d”），a，c ？，和d是单例模式，而b +是循环模式。 默认情况下，模式是单个模式，您可以使用Quantifiers将其转换为循环模式。每个模式可以有一个或多个条件，基于它接受事件。</p>
<h4 id="2-1-1-Quantifiers"><a href="#2-1-1-Quantifiers" class="headerlink" title="2.1.1 Quantifiers"></a>2.1.1 Quantifiers</h4><p>在FlinkCEP中，您可以使用以下方法指定循环模式：pattern.oneOrMore（），用于期望一个或多个事件发生的模式（例如之前提到的b +）;和pattern.times（#ofTimes）， 用于期望给定类型事件的特定出现次数的模式，例如4个;和patterntimes（#fromTimes，＃toTimes），用于期望给定类型事件的最小出现次数和最大出现次数的模式，例如， 2-4。</p>
<p>您可以使用pattern.greedy（）方法使循环模式变得贪婪，但是还不能使组模式变得贪婪。您可以使用pattern.optional（）方法使得所有模式，循环与否，变为可选。</p>
<p>对于名为start的模式，以下是有效的Quantifiers：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// expecting 4 occurrences</span></span><br><span class="line">start.times(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">4</span>).optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2, 3 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2, 3 or 4 occurrences and repeating as many as possible</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2, 3 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2, 3 or 4 occurrences and repeating as many as possible</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).optional().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 1 or more occurrences</span></span><br><span class="line">start.oneOrMore();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 1 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.oneOrMore().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or more occurrences</span></span><br><span class="line">start.oneOrMore().optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.oneOrMore().optional().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2 or more occurrences</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>).greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>).optional().greedy();</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="2-1-2-Conditions-条件"><a href="#2-1-2-Conditions-条件" class="headerlink" title="2.1.2 Conditions-条件"></a>2.1.2 Conditions-条件</h4><p>在每个模式中，从一个模式转到下一个模式，可以指定其他条件。您可以将使用下面这些条件：</p>
<ol>
<li>传入事件的属性，例如其值应大于5，或大于先前接受的事件的平均值。</li>
<li>匹配事件的连续性，例如检测模式a，b，c，序列中间不能有任何非匹配事件。</li>
</ol>
<h4 id="2-1-3-Conditions-on-Properties-关于属性的条件"><a href="#2-1-3-Conditions-on-Properties-关于属性的条件" class="headerlink" title="2.1.3 Conditions on Properties-关于属性的条件"></a>2.1.3 Conditions on Properties-关于属性的条件</h4><p>可以通过pattern.where（），pattern.or（）或pattern.until（）方法指定事件属性的条件。 条件可以是IterativeConditions或SimpleConditions。</p>
<ol>
<li>迭代条件：</li>
</ol>
<p>这是最常见的条件类型。 你可以指定一个条件，该条件基于先前接受的事件的属性或其子集的统计信息来接受后续事件。</p>
<p>下面代码说的是：如果名称以“foo”开头同时如果该模式的先前接受的事件的价格总和加上当前事件的价格不超过该值 5.0，则迭代条件接受名为“middle”的模式的下一个事件，。 迭代条件可以很强大的，尤其是与循环模式相结合，例如， oneOrMore()。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">middle.oneOrMore().where(<span class="keyword">new</span> IterativeCondition&lt;SubEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent value, Context&lt;SubEvent&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!value.getName().startsWith(<span class="string">&quot;foo&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">double</span> sum = value.getPrice();</span><br><span class="line">        <span class="keyword">for</span> (Event event : ctx.getEventsForPattern(<span class="string">&quot;middle&quot;</span>)) &#123;</span><br><span class="line">            sum += event.getPrice();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Double.compare(sum, <span class="number">5.0</span>) &lt; <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>注意对context.getEventsForPattern（…）的调用,将为给定潜在匹配项查找所有先前接受的事件。 此操作的代价可能会变化巨大，因此在使用条件时，请尽量减少其使用。</p>
<ol>
<li>简单条件：</li>
</ol>
<p>这种类型的条件扩展了前面提到的IterativeCondition类，并且仅根据事件本身的属性决定是否接受事件。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start.where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value.getName().startsWith(<span class="string">&quot;foo&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>最后，还可以通过pattern.subtype（subClass）方法将接受事件的类型限制为初始事件类型的子类型。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start.subtype(SubEvent.class).where(<span class="keyword">new</span> SimpleCondition&lt;SubEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<ol>
<li>组合条件：</li>
</ol>
<p>如上所示，可以将子类型条件与其他条件组合使用。 这适用于所有条件。 您可以通过顺序调用where（）来任意组合条件。 最终结果将是各个条件的结果的逻辑AND。 要使用OR组合条件，可以使用or（）方法，如下所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pattern.where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;).or(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// or condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<ol>
<li>停止条件：</li>
</ol>
<p>在循环模式（oneOrMore()和oneOrMore().optional()）的情况下，还可以指定停止条件，例如： 接受值大于5的事件，直到值的总和小于50。</p>
<p>为了更好的理解，可以看看下面的例子：</p>
<p>给定模式：(a+ until b)，b之前，要出现一个或者多个a。</p>
<p>给定输入序列：a1，c，a2，b，a3</p>
<p>输出结果: {a1 a2}{a1}{a2}{a3}</p>
<p>可以看到{a1,a2,a3},{a2,a3}这两个并没有输出，这就是停止条件的作用。</p>
<ol>
<li>连续事件条件</li>
</ol>
<p>FlinkCEP支持事件之间以下形式进行连续：</p>
<ul>
<li>严格连续性：希望所有匹配事件一个接一个地出现，中间没有任何不匹配的事件。</li>
<li>宽松连续性：忽略匹配的事件之间出现的不匹配事件。 不能忽略两个事件之间的匹配事件。</li>
<li>非确定性轻松连续性：进一步放宽连续性，允许忽略某些匹配事件的其他匹配。</li>
</ul>
<p>为了解释上面的内容，我们举个例子。假如有个模式序列”a+ b”，输入序列”a1,c,a2,b”，不同连续条件下有不同的区别：</p>
<ol>
<li>严格连续性：{a2 b} - 由于c的存在导致a1被废弃</li>
<li>宽松连续性：{a1,b}和{a1 a2 b} - c被忽略</li>
<li>非确定性宽松连续性：{a1 b}, {a2 b}, 和 {a1 a2 b}</li>
</ol>
<p>对于循环模式（例如oneOrMore()和times()），默认是宽松的连续性。 如果你想要严格的连续性，你必须使用consecutive()显式指定它， 如果你想要非确定性的松弛连续性，你可以使用allowCombinations()方法。</p>
<p>注意在本节中，我们讨论的是单个循环模式中的连续性，并且需要在该上下文中理解consecutive()和allowCombinations()。 稍后在讲解组合模式时，我们将讨论其他方法，例如next（）和followedBy（），用于指定模式之间的连续条件。</p>
<h4 id="2-1-4-API简介"><a href="#2-1-4-API简介" class="headerlink" title="2.1.4 API简介"></a>2.1.4 API简介</h4><h5 id="1-where-condition"><a href="#1-where-condition" class="headerlink" title="1. where(condition)"></a>1. where(condition)</h5><p>定义当前模式的条件。 为了匹配模式，事件必须满足条件。 多个连续的where()，其条件为AND：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pattern.where(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="2-or-condition"><a href="#2-or-condition" class="headerlink" title="2. or(condition)"></a>2. or(condition)</h5><p>添加与现有条件进行OR运算的新条件。 只有在至少通过其中一个条件时，事件才能匹配该模式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pattern.where(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;).or(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// alternative condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="3-until-condition"><a href="#3-until-condition" class="headerlink" title="3. until(condition)"></a>3. until(condition)</h5><p>指定循环模式的停止条件。 意味着如果匹配给定条件的事件发生，则不再接受该模式中的事件。</p>
<p>仅适用于oneOrMore（）</p>
<p>注意：它允许在基于事件的条件下清除相应模式的状态。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pattern.oneOrMore().until(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// alternative condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="4-subtype-subClass"><a href="#4-subtype-subClass" class="headerlink" title="4. subtype(subClass)"></a>4. subtype(subClass)</h5><p>定义当前模式的子类型条件。 如果事件属于此子类型，则事件只能匹配该模式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.subtype(SubEvent.class);</span><br></pre></td></tr></table></figure>
<h5 id="5-oneOrMore"><a href="#5-oneOrMore" class="headerlink" title="5. oneOrMore()"></a>5. oneOrMore()</h5><p>指定此模式至少发生一次匹配事件。</p>
<p>默认情况下，使用宽松的内部连续性。</p>
<p>注意：建议使用until（）或within（）来启用状态清除</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pattern.oneOrMore().until(<span class="keyword">new</span> IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value, Context ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// alternative condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="6-timesOrMore-times"><a href="#6-timesOrMore-times" class="headerlink" title="6. timesOrMore(#times)"></a>6. timesOrMore(#times)</h5><p>指定此模式至少需要#times次出现匹配事件。</p>
<p>默认情况下，使用宽松的内部连续性（在后续事件之间）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.timesOrMore(<span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<h5 id="7-times-ofTimes"><a href="#7-times-ofTimes" class="headerlink" title="7. times(#ofTimes)"></a>7. times(#ofTimes)</h5><p>指定此模式需要匹配事件的确切出现次数。</p>
<p>默认情况下，使用宽松的内部连续性（在后续事件之间）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.times(<span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<h5 id="8-times-fromTimes-toTimes"><a href="#8-times-fromTimes-toTimes" class="headerlink" title="8. times(#fromTimes, #toTimes)"></a>8. times(#fromTimes, #toTimes)</h5><p>指定此模式期望在匹配事件的#fromTimes次和#toTimes次之间出现。</p>
<p>默认情况下，使用宽松的内部连续性。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.times(<span class="number">2</span>, <span class="number">4</span>);</span><br></pre></td></tr></table></figure>
<h5 id="9-optional"><a href="#9-optional" class="headerlink" title="9. optional()"></a>9. optional()</h5><p>指定此模式是可选的，即有可能根本不会发生。 这适用于所有上述量词。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.oneOrMore().optional();</span><br></pre></td></tr></table></figure>
<h5 id="10-greedy"><a href="#10-greedy" class="headerlink" title="10. greedy()"></a>10. greedy()</h5><p>指定此模式是贪婪的，即它将尽可能多地重复。 这仅适用于quantifiers，目前不支持组模式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.oneOrMore().greedy();</span><br></pre></td></tr></table></figure>
<h5 id="11-consecutive"><a href="#11-consecutive" class="headerlink" title="11. consecutive()"></a>11. consecutive()</h5><p>与oneOrMore（）和times（）一起使用并在匹配事件之间强加严格的连续性，即任何不匹配的元素都会中断匹配。</p>
<p>如果不使用，则使用宽松的连续性（如followBy（））。</p>
<p>例如，这样的模式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;c&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.followedBy(<span class="string">&quot;middle&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;).oneOrMore().consecutive()</span><br><span class="line">.followedBy(<span class="string">&quot;end1&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>针对上面的模式，我们假如输入序列如：C D A1 A2 A3 D A4 B</p>
<p>使用consecutive：{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}</p>
<p>不使用:{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}, {C A1 A2 A3 A4 B}</p>
<h5 id="12-allowCombinations"><a href="#12-allowCombinations" class="headerlink" title="12. allowCombinations()"></a>12. allowCombinations()</h5><p>与oneOrMore（）和times（）一起使用，并在匹配事件之间强加非确定性宽松连续性（如 followedByAny()）。</p>
<p>如果不应用，则使用宽松的连续性（如followBy()）。</p>
<p>例如,这样的模式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;c&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.followedBy(<span class="string">&quot;middle&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;).oneOrMore().allowCombinations()</span><br><span class="line">.followedBy(<span class="string">&quot;end1&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.getName().equals(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>针对上面的模式，我们假如输入序列如：C D A1 A2 A3 D A4 B</p>
<p>使用allowCombinations：{C A1 B}, {C A1 A2 B}, {C A1 A3 B}, {C A1 A4 B}, {C A1 A2 A3 B}, {C A1 A2 A4 B}, {C A1 A3 A4 B}, {C A1 A2 A3 A4 B}</p>
<p>不使用:{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}, {C A1 A2 A3 A4 B}</p>
<h3 id="2-2-组合模式"><a href="#2-2-组合模式" class="headerlink" title="2.2 组合模式"></a>2.2 组合模式</h3><h4 id="2-2-1-简介"><a href="#2-2-1-简介" class="headerlink" title="2.2.1 简介"></a>2.2.1 简介</h4><p>已经了解了单个模式的样子，现在是时候看看如何将它们组合成一个完整的模式序列。</p>
<p>模式序列必须以初始模式开始，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>接下来，您可以通过指定它们之间所需的连续条件，为模式序列添加更多模式。 在上一节中，我们描述了Flink支持的不同邻接模式，即严格，宽松和非确定性宽松，以及如何在循环模式中应用它们。 要在连续模式之间应用它们，可以使用：</p>
<blockquote>
<p>next() 对应 严格, followedBy() 对应 宽松连续性 followedByAny() 对应 非确定性宽松连续性</p>
</blockquote>
<p>亦或</p>
<blockquote>
<p>notNext() 如果不希望一个事件类型紧接着另一个类型出现。 notFollowedBy() 不希望两个事件之间任何地方出现该事件。</p>
</blockquote>
<blockquote>
<p>注意 模式序列不能以notFollowedBy（）结束。</p>
</blockquote>
<blockquote>
<p>注意 NOT模式前面不能有可选模式。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// strict contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; strict = start.next(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxed = start.followedBy(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// non-deterministic relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; nonDetermin = start.followedByAny(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// NOT pattern with strict contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; strictNot = start.notNext(<span class="string">&quot;not&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// NOT pattern with relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxedNot = start.notFollowedBy(<span class="string">&quot;not&quot;</span>).where(...);</span><br></pre></td></tr></table></figure>
<p>宽松连续性指的是仅第一个成功匹配的事件会被匹配到，然而非确定性宽松连续性，相同的开始会有多个匹配结果发出。距离，如果一个模式是”a b”，给定输入序列是”a c b1 b2”。对于不同连续性会有不同输出。</p>
<ol>
<li>a和b之间严格连续性，将会返回{},也即是没有匹配。因为c的出现导致a，抛弃了。</li>
<li>a和b之间宽松连续性，返回的是{a，b1},因为宽松连续性将会抛弃为匹配成功的元素，直至匹配到下一个要匹配的事件。</li>
<li>a和b之间非确定性宽松连续性，返回的是{a,b1},{a,b2}。</li>
</ol>
<p>也可以为模式定义时间约束。 例如，可以通过pattern.within（）方法定义模式应在10秒内发生。 时间模式支持处理和事件时间。 注意模式序列只能有一个时间约束。 如果在不同的单独模式上定义了多个这样的约束，则应用最小的约束。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">next.within(Time.seconds(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>
<p>可以为begin，followBy，followByAny和next定义一个模式序列作为条件。模式序列将被逻辑地视为匹配条件，而且将返回GroupPattern并且 可对GroupPattern使用oneOrMore（），times（#ofTimes），times（＃fromTimes，＃toTimes），optional（），consecutive（）， allowCombinations（）等方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">PatternPatte &lt;Event, ?&gt; start = Pattern.begin(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;start_middle&quot;</span>).where(...)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// strict contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; strict = start.next(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;next_start&quot;</span>).where(...).followedBy(<span class="string">&quot;next_middle&quot;</span>).where(...)</span><br><span class="line">).times(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxed = start.followedBy(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;followedby_start&quot;</span>).where(...).followedBy(<span class="string">&quot;followedby_middle&quot;</span>).where(...)</span><br><span class="line">).oneOrMore();</span><br><span class="line"></span><br><span class="line"><span class="comment">// non-deterministic relaxed contiguity</span></span><br><span class="line">Pattern&lt;Event, ?&gt; nonDetermin = start.followedByAny(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;followedbyany_start&quot;</span>).where(...).followedBy(<span class="string">&quot;followedbyany_middle&quot;</span>).where(...)</span><br><span class="line">).optional();</span><br></pre></td></tr></table></figure>
<h4 id="2-2-2-API"><a href="#2-2-2-API" class="headerlink" title="2.2.2 API"></a>2.2.2 API</h4><ol>
<li>begin(#name)</li>
</ol>
<p>定义一个开始模式</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>begin(#pattern_sequence)</li>
</ol>
<p>定义一个开始模式</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;middle&quot;</span>).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ol>
<li>next(#name)</li>
</ol>
<p>追加一个新的模式。匹配事件必须直接跟着先前的匹配事件（严格连续性）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; next = start.next(<span class="string">&quot;middle&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>next(#pattern_sequence)</li>
</ol>
<p>追加一个新的模式。匹配事件必须直接接着先前的匹配事件（严格连续性）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; next = start.next(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;middle&quot;</span>).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ol>
<li>followedBy(#name)</li>
</ol>
<p>追加加新模式。 匹配事件和先前匹配事件（宽松连续）之间可能发生其他非匹配事件：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedBy = start.followedBy(<span class="string">&quot;middle&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>followedBy(#pattern_sequence)</li>
</ol>
<p>追加新模式。 匹配事件和先前匹配事件（宽松连续）之间可能发生其他非匹配事件：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedBy = start.followedBy(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;middle&quot;</span>).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ol>
<li>followedByAny(#name)</li>
</ol>
<p>添加新模式。 匹配事件和先前匹配事件之间可能发生其他事件，并且将针对每个备选匹配事件（非确定性放松连续性）呈现替代匹配：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedByAny = start.followedByAny(<span class="string">&quot;middle&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>followedByAny(#pattern_sequence)</li>
</ol>
<p>添加新模式。 匹配事件和先前匹配事件之间可能发生其他事件，并且将针对每个备选匹配事件（非确定性放松连续性）呈现替代匹配：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedByAny = start.followedByAny(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;middle&quot;</span>).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ol>
<li>notNext()</li>
</ol>
<p>添加新的否定模式。 匹配（否定）事件必须直接跟着先前的匹配事件（严格连续性）才能丢弃部分匹配：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; notNext = start.notNext(<span class="string">&quot;not&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>notFollowedBy()</li>
</ol>
<p>追加一个新的否定模式匹配。即使在匹配（否定）事件和先前匹配事件（宽松连续性）之间发生其他事件，也将丢弃部分匹配事件序列：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; notFollowedBy = start.notFollowedBy(<span class="string">&quot;not&quot;</span>);</span><br></pre></td></tr></table></figure>
<ol>
<li>within(time)</li>
</ol>
<p>定义事件序列进行模式匹配的最大时间间隔。 如果未完成的事件序列超过此时间，则将其丢弃：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.within(Time.seconds(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>
<h3 id="2-3-匹配后的跳过策略"><a href="#2-3-匹配后的跳过策略" class="headerlink" title="2.3 匹配后的跳过策略"></a>2.3 匹配后的跳过策略</h3><p>对于给定模式，可以将同一事件分配给多个成功匹配。 要控制将分配事件的匹配数，需要指定名为AfterMatchSkipStrategy的跳过策略。 跳过策略有四种类型，如下所示：</p>
<ul>
<li>NO_SKIP：将发出每个可能的匹配。</li>
<li>SKIP_PAST_LAST_EVENT：丢弃包含匹配事件的每个部分匹配。</li>
<li>SKIP_TO_FIRST：丢弃包含PatternName第一个之前匹配事件的每个部分匹配。</li>
<li>SKIP_TO_LAST：丢弃包含PatternName最后一个匹配事件之前的每个部分匹配。</li>
</ul>
<p>请注意，使用SKIP_TO_FIRST和SKIP_TO_LAST跳过策略时，还应指定有效的PatternName。</p>
<p>例如，对于给定模式a b {2}和数据流ab1，ab2，ab3，ab4，ab5，ab6，这四种跳过策略之间的差异如下：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/crestofwave1/oneFlink/blob/master/pic/CEP/%E8%B7%B3%E8%BF%87%E7%AD%96%E7%95%A5.png"><img src="https://github.com/crestofwave1/oneFlink/raw/master/pic/CEP/%E8%B7%B3%E8%BF%87%E7%AD%96%E7%95%A5.png" alt="image"></a></p>
<p>要指定要使用的跳过策略，只需调用以下命令创建AfterMatchSkipStrategy：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/crestofwave1/oneFlink/blob/master/pic/CEP/%E5%88%9B%E5%BB%BA%E8%B7%B3%E8%BF%87%E7%AD%96%E7%95%A5.png"><img src="https://github.com/crestofwave1/oneFlink/raw/master/pic/CEP/%E5%88%9B%E5%BB%BA%E8%B7%B3%E8%BF%87%E7%AD%96%E7%95%A5.png" alt="image"></a></p>
<p>使用方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">AfterMatchSkipStrategy skipStrategy = ...</span><br><span class="line">Pattern.begin(<span class="string">&quot;patternName&quot;</span>, skipStrategy);</span><br></pre></td></tr></table></figure>
<h3 id="2-4-检测模式-Detecting-Patterns"><a href="#2-4-检测模式-Detecting-Patterns" class="headerlink" title="2.4 检测模式-Detecting Patterns"></a>2.4 检测模式-Detecting Patterns</h3><p>指定要查找的模式序列后，就可以将其应用于输入流以检测潜在匹配。 要针对模式序列运行事件流，必须创建PatternStream。 给定输入流 input，模式 pattern 和可选的比较器 comparator，用于在EventTime的情况下对具有相同时间戳的事件进行排序或在同一时刻到达，通过调用以下命令创建PatternStream：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = ...</span><br><span class="line">EventComparator&lt;Event&gt; comparator = ... <span class="comment">// optional</span></span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(input, pattern, comparator);</span><br></pre></td></tr></table></figure>
<p>根据实际情况，创建的流可以是有key，也可以是无key的。</p>
<p>请注意，在无key的流上使用模式，将导致job的并行度为1。</p>
<h3 id="2-5-Selecting-from-Patterns"><a href="#2-5-Selecting-from-Patterns" class="headerlink" title="2.5 Selecting from Patterns"></a>2.5 Selecting from Patterns</h3><p>获得PatternStream后，您可以通过select或flatSelect方法从检测到的事件序列中进行查询。</p>
<p>select（）方法需要PatternSelectFunction的实现。 PatternSelectFunction具有为每个匹配事件序列调用的select方法。 它以Map &lt;String，List &gt;的形式接收匹配，其中key是模式序列中每个模式的名称，值是该模式的所有已接受事件的列表（IN是输入元素的类型）。 给定模式的事件按时间戳排序。 返回每个模式的接受事件列表的原因是当使用循环模式（例如oneToMany（）和times（））时，对于给定模式可以接受多个事件。 选择函数只返回一个结果。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPatternSelectFunction</span>&lt;<span class="title">IN</span>, <span class="title">OUT</span>&gt; <span class="keyword">implements</span> <span class="title">PatternSelectFunction</span>&lt;<span class="title">IN</span>, <span class="title">OUT</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> OUT <span class="title">select</span><span class="params">(Map&lt;String, List&lt;IN&gt;&gt; pattern)</span> </span>&#123;</span><br><span class="line">        IN startEvent = pattern.get(<span class="string">&quot;start&quot;</span>).get(<span class="number">0</span>);</span><br><span class="line">        IN endEvent = pattern.get(<span class="string">&quot;end&quot;</span>).get(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> OUT(startEvent, endEvent);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PatternFlatSelectFunction类似于PatternSelectFunction，唯一的区别是它可以返回任意数量的结果。 为此，select方法有一个额外的Collector参数，用于将输出元素向下游转发。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPatternFlatSelectFunction</span>&lt;<span class="title">IN</span>, <span class="title">OUT</span>&gt; <span class="keyword">implements</span> <span class="title">PatternFlatSelectFunction</span>&lt;<span class="title">IN</span>, <span class="title">OUT</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatSelect</span><span class="params">(Map&lt;String, List&lt;IN&gt;&gt; pattern, Collector&lt;OUT&gt; collector)</span> </span>&#123;</span><br><span class="line">        IN startEvent = pattern.get(<span class="string">&quot;start&quot;</span>).get(<span class="number">0</span>);</span><br><span class="line">        IN endEvent = pattern.get(<span class="string">&quot;end&quot;</span>).get(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; startEvent.getValue(); i++ ) &#123;</span><br><span class="line">            collector.collect(<span class="keyword">new</span> OUT(startEvent, endEvent));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-6-处理超时部分模式"><a href="#2-6-处理超时部分模式" class="headerlink" title="2.6 处理超时部分模式"></a>2.6 处理超时部分模式</h3><p>每当模式具有通过within关键字附加的时间窗口长度时，部分事件序列可能因为超出时间窗口长度而被丢弃。 为了对这些超时的部分匹配作出相应的处理，select和flatSelect API调用允许指定超时处理程序。 为每个超时的部分事件序列调用此超时处理程序。 超时处理程序接收到目前为止由模式匹配的所有事件，以及检测到超时时的时间戳。</p>
<p>为了处理部分模式，select和flatSelect API提供了一个带参数的重载版本</p>
<ul>
<li>PatternTimeoutFunction/ PatternFlatTimeoutFunction。</li>
<li>OutputTag 超时的匹配将会在其中返回。</li>
<li>PatternSelectFunction / PatternFlatSelectFunction。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">PatternStreamPatte &lt;Event&gt; patternStream = CEP.pattern(input, pattern);</span><br><span class="line"></span><br><span class="line">OutputTag&lt;String&gt; outputTag = <span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">&quot;side-output&quot;</span>)&#123;&#125;;</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;ComplexEvent&gt; result = patternStream.select(</span><br><span class="line">    <span class="keyword">new</span> PatternTimeoutFunction&lt;Event, TimeoutEvent&gt;() &#123;...&#125;,</span><br><span class="line">    outputTag,</span><br><span class="line">    <span class="keyword">new</span> PatternSelectFunction&lt;Event, ComplexEvent&gt;() &#123;...&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">DataStream&lt;TimeoutEvent&gt; timeoutResult = result.getSideOutput(outputTag);</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;ComplexEvent&gt; flatResult = patternStream.flatSelect(</span><br><span class="line">    <span class="keyword">new</span> PatternFlatTimeoutFunction&lt;Event, TimeoutEvent&gt;() &#123;...&#125;,</span><br><span class="line">    outputTag,</span><br><span class="line">    <span class="keyword">new</span> PatternFlatSelectFunction&lt;Event, ComplexEvent&gt;() &#123;...&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">DataStream&lt;TimeoutEvent&gt; timeoutFlatResult = flatResult.getSideOutput(outputTag);</span><br></pre></td></tr></table></figure>
<h3 id="2-7-事件事件模式下处理滞后数据"><a href="#2-7-事件事件模式下处理滞后数据" class="headerlink" title="2.7 事件事件模式下处理滞后数据"></a>2.7 事件事件模式下处理滞后数据</h3><p>在CEP中，元素处理的顺序很重要。为了保证在采用事件事件时以正确的顺序处理事件，最初将传入的事件放入缓冲区，其中事件基于它们的时间戳以升序排序， 并且当watermark到达时，处理该缓冲区中时间戳小于watermark时间的所有元素。这意味着watermark之间的事件按事件时间顺序处理。</p>
<p>请注意，在采用事件时间时，CEP library会假设watermark是正确的。</p>
<p>为了保证跨watermark的记录按照事件事件顺序处理，Flink的CEP库假定watermark是正确的，并将时间戳小于上次可见watermark的时间视为滞后事件。滞后事件不会被进一步处理。</p>
<h3 id="2-8-栗子"><a href="#2-8-栗子" class="headerlink" title="2.8 栗子"></a>2.8 栗子</h3><p>以下示例检测事件的带key数据流上的模式start，middle（name =“error”） - &gt; end（name =“critical”）。 事件的key是其id，并且有效模式必须在10秒内发生。 整个处理是用事件时间完成的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = ...</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line"></span><br><span class="line">DataStream&lt;Event&gt; partitionedInput = input.keyBy(<span class="keyword">new</span> KeySelector&lt;Event, Integer&gt;() &#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Integer <span class="title">getKey</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> value.getId();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>)</span><br><span class="line">	.next(<span class="string">&quot;middle&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">			<span class="keyword">return</span> value.getName().equals(<span class="string">&quot;error&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;).followedBy(<span class="string">&quot;end&quot;</span>).where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">			<span class="keyword">return</span> value.getName().equals(<span class="string">&quot;critical&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;).within(Time.seconds(<span class="number">10</span>));</span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(partitionedInput, pattern);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Alert&gt; alerts = patternStream.select(<span class="keyword">new</span> PatternSelectFunction&lt;Event, Alert&gt;() &#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Alert <span class="title">select</span><span class="params">(Map&lt;String, List&lt;Event&gt;&gt; pattern)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> createAlert(pattern);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink-local-demo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink-local-demo/" class="post-title-link" itemprop="url">flink local deploy</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-06-06 00:00:00" itemprop="dateCreated datePublished" datetime="2019-06-06T00:00:00+08:00">2019-06-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:28" itemprop="dateModified" datetime="2021-02-09T09:38:28+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink本地部署"><a href="#Flink本地部署" class="headerlink" title="Flink本地部署"></a>Flink本地部署</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Flink/Flink-cep/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Flink/Flink-cep/" class="post-title-link" itemprop="url">flink cep</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-06-06 00:00:00" itemprop="dateCreated datePublished" datetime="2019-06-06T00:00:00+08:00">2019-06-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:28" itemprop="dateModified" datetime="2021-02-09T09:38:28+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Flink cep</p>
<p>CEP的处理范例引起了人们的极大兴趣，并在各种用例中得到了应用。 最值得注意的是，CEP现在用于诸如股票市场趋势和信用卡欺诈检测等金融应用</p>
<p>模式，从流中查找符合某个pattern的个体事件。<br>可以将一个pattern sequence视为pattern组成的图, 基于用户定义的条件，从一个pattern传递到下一个pattern<br>一个match是事件必须流过复杂pattern图的所有的pattern。</p>
<p><strong>注意</strong></p>
<ul>
<li>每一个pattern必须具有唯一的名称，用于标示符合条件的事件</li>
<li>pattern名称不能包含:</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/failover-recovery/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/failover-recovery/" class="post-title-link" itemprop="url">大规模分布式系统故障恢复和容错架构探究</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-26 00:00:00" itemprop="dateCreated datePublished" datetime="2019-05-26T00:00:00+08:00">2019-05-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:28" itemprop="dateModified" datetime="2021-02-09T09:38:28+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在大规模数据处理的分布式系统中，如何保障数据的高可用、数据的一致性和幂等性(exactly once)是系统的一大难题!<br>使用廉价机器构建集群成为大数据平台的标配，故障恢复和容错（failover recovery）机制成为防止消息丢失和快速恢复服务必不可少的组成部分; 在通用的大数据架构中，也是保障数据高可用、一致性和幂等性的基础。</p>
<p>分布式系统故障恢复需要解决的问题:</p>
<ol>
<li>吞吐量大的场景，当出现了失败时，需要保证失败的数据可以重放，且状态可恢复。</li>
<li>某一个时刻，多个计算节点存在处理速度不一致的问题，一条数据可能经过多个计算节点才能完成计算。如何保存多个计算节点的状态，且保证数据对齐？</li>
<li>如何保证数据经过各个计算节点的顺序性和不重复？</li>
<li>如何回放数据？</li>
</ol>
<p>虽然大规模分布式系统的侧重各不相同，但是failover recovery的机制却如出一辙, 主要有ack模式、异步checkpoint模式、CL模式、补偿模式等，接下来就这四种模式分别总结。</p>
<h1 id="Ack模式"><a href="#Ack模式" class="headerlink" title="Ack模式"></a>Ack模式</h1><p>在分布式系统中，为了确保一条(批)数据被正确处理，且当出现任何故障，保障数据不丢。ack机制是最简单的方式，每一条(批)数据正确处理完后，发送一条确认标示。</p>
<h2 id="TCP-ack"><a href="#TCP-ack" class="headerlink" title="TCP ack"></a>TCP ack</h2><p>在TCP握手时，当收到客户端发起的握手报文时, 返回一个Acknowledgement Number, 标示客户端的请求已经收到，并返回给客户端。<br>而后客户端返回Acknowledgement Number以确保服务端请求正确接受。<br>当网络抖动或者服务器和客户端故障时，报文可能丢失。此时就要依赖于与ack机制相配合的faiover-recovery机制。</p>
<p>如果服务器没有收到客户端的最终ACK确认报文，会一直处于<code>SYN_RECV</code>状态，将客户端IP加入等待列表，<br>并重发<code>SYN+ACK</code>报文。<br>重发一般进行3-5次，大约间隔30秒左右轮询一次等待列表重试所有客户端。<br>另一方面，服务器在自己发出了<code>SYN+ACK</code>报文后，会预分配资源为即将建立的TCP连接储存信息做准备，<br>这个资源在等待重试期间一直保留。更为重要的是，服务器资源有限，可以维护的<code>SYN_RECV</code>状态超过极限后就不再接受新的SYN报文，<br>也就是拒绝新的TCP连接建立。</p>
<p>然而著名的<code>SYNC Flood</code>的DDos攻击正式利用上述的<code>failover-recovery</code>机制。<br>攻击者伪装大量的IP地址给服务器发送SYN报文，由于伪造的IP地址几乎不可能存在，也就几乎没有设备会给服务器返回任何应答了。<br>因此，服务器将会维持一个庞大的等待列表，不停地重试发送SYN+ACK报文，同时占用着大量的资源无法释放。<br>更为关键的是，被攻击服务器的<code>SYN_RECV</code>队列被恶意的数据包占满，不再接受新的SYN请求，合法用户无法完成三次握手建立起TCP连接。<br>也就是说，这个服务器被SYN Flood拒绝服务了。</p>
<p>SYN Flood攻击大量消耗服务器的CPU、内存资源，并占满SYN等待队列。相应的，我们修改内核参数即可有效缓解。主要参数如下：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">net.ipv4.tcp_syncookies</span> = <span class="string">1</span></span><br><span class="line"><span class="meta">net.ipv4.tcp_max_syn_backlog</span> = <span class="string">8192</span></span><br><span class="line"><span class="meta">net.ipv4.tcp_synack_retries</span> = <span class="string">2</span></span><br></pre></td></tr></table></figure>
<p>分别为启用SYN Cookie、设置SYN最大队列长度以及设置SYN+ACK最大重试次数。<br>SYNC Cookie主要是在服务端缓冲基于时间种子的SYN号，只有客户端发送的SYN+ACK与缓冲完全匹配才完成握手，否则直接丢弃。<br><code>tcp_max_syn_backlog</code>则是增加等待队列的长度。</p>
<h2 id="Apache-storm中的ack机制"><a href="#Apache-storm中的ack机制" class="headerlink" title="Apache storm中的ack机制"></a>Apache storm中的ack机制</h2><p>Apache storm是首个真正意义上的流式处理引擎，在spark/Flink出现之前，是实时计算领域的一枝独秀。</p>
<p>storm中是没有checkpoint机制的，但storm以大名鼎鼎的ack算法来保证at least once语义，(在<a target="_blank" rel="noopener" href="http://storm.apache.org/releases/2.0.0-SNAPSHOT/Trident-tutorial.html">Trident</a>出现之前，storm是没有办法保证exactly once语义的)。ack需要spout节点保存每条数据，当所有的计算节点处理完毕，再发送给spout节点，因此与Chandy-Lamport算法相比，每条数据都需要保存和反复发送，而状态和数据回滚需要用户来保证。</p>
<p>实时大数据处理，数据源源不断的流入系统。无法在一个线程中串行的处理并确认一条或一批数据。<br>strom采用的是异步并行处理的模式(这里以JStorm的实现分析),<br>当excutor节点（executor节点是storm的进程，spout和bolt都是executor启动的task线程）收到消息时，首先将消息压入disruptor队列，disruptor的消费者从队列中获取数据，执行转发或者计算。</p>
<p><img src="/images/bigdata/storm/strom-queue.png"></p>
<p>strom引入ack机制来确保数据不丢，但是对系统整体架构也带来了很大的影响，那么问题来了：</p>
<ul>
<li>消息量大，如何保存消息？</li>
<li>消息可能流过多个节点，如何保证每个节点都正确处理？</li>
<li>spout节点重启，如何确保消息不丢失？</li>
<li>消息堆积，如何确保集群的稳定？</li>
</ul>
<p>ack机制是如何巧妙解决这写问题的呢？</p>
<p><img src="https://images2015.cnblogs.com/blog/639357/201612/639357-20161207181349866-1482908747.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A xor A &#x3D; 0.</span><br><span class="line">A xor B … xor B xor A &#x3D; 0，</span><br></pre></td></tr></table></figure>
<p>其中每一个操作数出现且仅出现两次。</p>
<p>strom的ack机制，巧妙的利用了两个相同的值异或为0的原理.</p>
<p>理解下整个大体节奏分为几部分:</p>
<ul>
<li><p>步骤1和2 spout把一条信息同时发送给了bolt1和bolt2，步骤3表示spout emit成功后去 acker bolt里注册本次根消息，ack值设定为本次发送的消息对应的64位id的异或运算值，上图对应的是T1^T2。</p>
</li>
<li><p>步骤4表示bolt1收到T1后，单条tuple被拆成了三条消息T3T4T5发送给bolt3。步骤6 bolt1在ack()方法调用时会向acker bolt提交T1^T3^T4^T5的ack值。</p>
</li>
<li><p>步骤5和7的bolt都没有产生新消息，所以ack()的时候分别向acker bolt提交了T2 和T3^T4^T5的ack值。综上所述，本次spout产生的tuple树对应的ack值经过的运算为 T1^T2^T1^T3^T4^T5^T2^T3^T4^T5按照异或运算的规则，ack值最终正好归零。</p>
</li>
<li><p>步骤8为acker bolt发现根spout最终对应的的ack是0以后认为所有衍生出来的数据都已经处理成功，它会通知对应的spout，spout会调用相应的ack方法。</p>
</li>
</ul>
<p>storm这个机制的实现方式保证了无论一个tuple树有多少个节点，一个根消息对应的追踪ack值所占用的空间大小是固定的，极大地节约了内存空间。</p>
<p>通过ack机制，spout发出的每一条消息，都可以确定是被成功或失败处理。但是，需要备份每条消息，来确认消息是否处理完成，如果消息流过的每个节点都备份数据，总数据量将翻几倍。spout作为消息流入到topology的起点，在这里备份数据既可以节省内存，又可以验证整条链路。此外，Ack机制还常用于<strong>限流</strong>作用： 为了避免spout发送数据太快，而bolt处理太慢，常常设置pending数，当spout有等于或超过pending数的tuple没有收到ack或fail响应时，跳过执行nextTuple， 从而限制spout发送数据。</p>
<p>strom逐条发送逐条处理逐条ack，这也是吞吐量不及spark和flink。</p>
<h1 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>通俗来讲:  就是在分布式系统中，通过状态的checkpoint来确保数据的高可用。</p>
<p>checkpoint俗称检查点，是指定时将数据快照保存到持久化存储介质中，来提供数据的可靠性和与增量文件结合快速恢复数据。</p>
<h2 id="Hadoop-NameNode-的checkpoint"><a href="#Hadoop-NameNode-的checkpoint" class="headerlink" title="Hadoop NameNode 的checkpoint"></a>Hadoop NameNode 的checkpoint</h2><p>NameNode负责管理Hadoop的元数据(workspace信息、blockMap信息、network topology等)信息，是HDFS的心脏。<br>checkpoint机制是NameNode数据故障恢复的方案。</p>
<p><img src="/images/bigdata/hdfs/nameNode_1.x.png" alt="HDFS namenode 1.x"></p>
<p>HDFS 2.x 引入了HA来解决NameNode的单点问题，社区也涌现了多种共享内存方案来保存editlog，而namenode的元数据的数据结构几乎没有变化。</p>
<p><img src="/images/bigdata/hdfs/namenode-workspace-memory.png" alt="name node workspace 内存结构"></p>
<p>workspace信息常驻内存，并定时checkpoint成fsimage文件, 当HDFS-Client发起修改文件目录的请求时，直接修改内存中的数据， 并将修改记录写到editlog文件中。可以将name node的workspace的维护过程简单理解为分布式系统中消息处理的过程，</p>
<h1 id="Chandy-Lamport算法"><a href="#Chandy-Lamport算法" class="headerlink" title="Chandy-Lamport算法"></a>Chandy-Lamport算法</h1><p>在实时流式处理中，简单的使用checkpoint没办法保证exactly once语义，主要是由于在某一个时刻：</p>
<ol>
<li>消息还在处理(没有合并到状态中)，source接收数据的偏移量不能准确的与状态做到数据一致性。</li>
<li>每个子任务处理进度也难以统一。</li>
</ol>
<p>理想情况下，停止接收新数据并排干整个流处理系统，再做checkpoint，才能保证数据一致性和exactly once。停机显然是不可能的！Chandy-Lamport算法使用巧妙的方法，在不停止流处理的前提下拿到每个子任务的状态并checkpoint下来。</p>
<p>著名的一致性算法 Paxos 的作者Leslie Lamport与Chandy合作发表了算法论文: <a target="_blank" rel="noopener" href="https://dl.acm.org/ft_gateway.cfm?id=214456&ftid=20679&dwn=1&CFID=72171565&CFTOKEN=2bfe026b198b5dc8-AEFB79E7-EF87-025C-C01DC78635F21DF8">Distributed snapshots: determining global states of distributed systems</a>, 在该论文中提出了分布式快照算法: <strong>Chandy-Lamport</strong></p>
<blockquote>
<p>A <strong>snapshot algorithm</strong> is used to create a consistent snapshot of the global state of a <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Distributed_system">distributed system</a>. Due to the lack of globally shared memory and a global clock, this isn’t trivially possible.</p>
</blockquote>
<p>Chandy-Lamport算法用于在缺乏全局共享内存和全局时钟的分布式系统中创建一致性的全局分布式快照。而这个算法正是1978年提出的<a target="_blank" rel="noopener" href="http://lamport.azurewebsites.net/pubs/pubs.html?spm=a2c4e.11153940.blogcont688764.10.4f964568O0SyIm#time-clocks"><strong>Time, Clocks and the Ordering of Events in a Distributed System</strong></a>的直接应用。在分布式系统中，为了确保数据在不同计算节点的有序性，引入barrier机制，当相同的barrier到达每一个计算节点时，认为全局节点处理结束。</p>
<p>Chandy-Lamport算法将全局的状态简化为有限个节点以及节点与节点之间的channel组成，也就是有向图。节点是进程，边是channel；分布式系统中，进程运行在不同的物理机器上，一个分布式的系统中的全局状态由进程的状态和channel中的message组成，这些都是分布式快照要保存的内容。</p>
<p>因为是有向图，一个节点的channel包含了input channel和output channel，流经channel的数据源源不断，假设channel是FIFO队列，保证不重复，那么只需要保存每个节点的局部状态和input message的偏移量，合并起来就是全局的分布式快照。</p>
<h2 id="Flink中的Chandy-Lamport算法"><a href="#Flink中的Chandy-Lamport算法" class="headerlink" title="Flink中的Chandy-Lamport算法"></a>Flink中的Chandy-Lamport算法</h2><p>Chandy-Lamport算法在flink中用于实现at least once语义。具体工作流程如下:</p>
<ol>
<li><p>在checkpoint触发时刻，Job Manager会往所有Source的流中放入一个barrier（图中三角形）。barrier包含当前checkpoint的ID<br><img src="https://upload-images.jianshu.io/upload_images/1431048-f1583d01e8fad051.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/521"></p>
</li>
<li><p>当barrier经过一个subtask时，即表示当前这个subtask处于checkpoint触发的“时刻”，他就会立即将barrier法往下游，并执行checkpoint方法将当前的state存入backend storage。图中Source1和Source2就是完成了checkpoint动作。<br><img src="https://upload-images.jianshu.io/upload_images/1431048-29b12d52fb1ccf05.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/523"></p>
</li>
<li><p>如果一个subtask有多个上游节点，这个subtask就需要等待所有上游发来的barrier都接收到，才能表示这个subtask到达了checkpoint触发“时刻”。但所有节点的barrier不一定一起到达，这时候就会面临“是否要对齐barrier”的问题（Barrier Alignment）。如图中的Task1.1，他有2个上游节点，Source1和Source2。假设Source1的barrier先到，这时候Task1.1就有2个选择：</p>
</li>
</ol>
<ul>
<li>是马上把这个barrier发往下游并等待Source2的barrier来了再做checkpoint</li>
<li>还是把Source1这边后续的event全都cache起来，等Source2的barrier来了，在做checkpoint，完了再继续处理Source1和Source2的event，当前Source1这边需要先处理cache里的event。</li>
</ul>
<h1 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h1><p>WAL是一种常见的故障恢复方式，如NameNode的元数据、HBase WAL、kafka消息中间件、SQLite WAL等。</p>
<blockquote>
<p>“In computer science, write-ahead logging (WAL) is a family of techniques for providing atomicity and durability (two of the ACID properties) in database systems.”——维基百科</p>
</blockquote>
<h2 id="HBase中的WAL"><a href="#HBase中的WAL" class="headerlink" title="HBase中的WAL"></a>HBase中的WAL</h2><p>这里介绍一下HBase WAL(write ahead log)机制，Hbase的RegionServer在处理数据插入和删除的过程中用来记录操作内容的一种日志。在每次Put、Delete等一条记录时，首先将其数据写入到RegionServer对应的HLog文件中去。</p>
<p>客户端向RegionServer端提交数据的时候，会先写入WAL日志，只有当WAL日志写入成功的时候，客户端才会被告诉提交数据成功。如果写WAL失败会告知客户端提交失败，这其实就是数据落地的过程。</p>
<p>在一个RegionServer上的所有Region都共享一个HLog，一次数据的提交先写入WAL，写入成功后，再写入menstore之中。当menstore的值达到一定的时候，就会形成一个个StoreFile。<br><img src="https://img-blog.csdn.net/20180419134053354"></p>
<p>WAL记载了每一个RegionServer对应的HLog。RegionServer1或者RegionServer1上某一个regiong挂掉了，都会迁移到其它的机器上处理，重新操作，进行恢复。</p>
<p>当RegionServer意外终止的时候，Master会通过Zookeeper感知到，Master首先会处理遗留下来的HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应的Region目录下，然后再将实效的Region重新分配，领取到这些Regio你的RegionMaster发现有历史的HLog需要处理，因此会Replay HLog的数据到Memstore之中，然后flush数据到StoreFiles，完成数据的恢复。</p>
<p>飞行日志+补偿机制，也是常用的方法，如基于消息的分布式事务是保证最终一致性的方式之一、Quartz中的恢复执行等。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="[参考文献]"></a>[参考文献]</h2><ol>
<li><a target="_blank" rel="noopener" href="https://elf8848.iteye.com/blog/2067774">深入浅出DDoS攻击防御</a></li>
<li><a href="">《Storm源码分析》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9b10313fde10">Flink Checkpoint</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hzmark/p/wal.html">什么是WAL</a></li>
<li><a target="_blank" rel="noopener" href="https://www.sqlite.org/wal.html">Write-Ahead Logging in SQLite</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/docker/yarn-docker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/docker/yarn-docker/" class="post-title-link" itemprop="url">在Docker上搭建Yarn集群和HDFS集群</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-23 00:00:00" itemprop="dateCreated datePublished" datetime="2019-05-23T00:00:00+08:00">2019-05-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:26" itemprop="dateModified" datetime="2021-02-09T09:38:26+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>yarn作为目前最流行的分布式计算资源管理平台，为Hadoop MR、spark、Flink等提供了资源容器</p>
<h2 id="Docker-File"><a href="#Docker-File" class="headerlink" title="Docker File"></a>Docker File</h2><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基础镜像</span></span><br><span class="line"><span class="keyword">FROM</span> hub.c.<span class="number">163</span>.com/public/centos</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum clean all</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y yum-plugin-ovl || <span class="literal">true</span></span></span><br><span class="line"><span class="comment"># 安装基础的工具包</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y vim tar wget curl rsync bzip2 iptables tcpdump less telnet net-tools lsof sysstat cronie python-setuptools</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum clean all</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">22</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /etc/supervisor/conf.d/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> [include] &gt;&gt; /etc/supervisord.conf</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&#x27;files = /etc/supervisor/conf.d/*.conf&#x27;</span> &gt;&gt; /etc/supervisord.conf</span></span><br><span class="line"><span class="comment">#COPY sshd.conf /etc/supervisor/conf.d/sshd.conf</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/usr/bin/supervisord&quot;</span>]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像的作者  </span></span><br><span class="line"><span class="keyword">MAINTAINER</span> averyzhang</span><br><span class="line"><span class="comment"># 安装openssh-server和sudo软件包，并且将sshd的UsePAM参数设置成no  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y openssh-server sudo  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">&#x27;s/UsePAM yes/UsePAM no/g&#x27;</span> /etc/ssh/sshd_config  </span></span><br><span class="line"><span class="comment">#安装openssh-clients</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum  install -y openssh-clients</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加测试用户root，密码abc.123，并且将此用户添加到sudoers里  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;root:abc.123&quot;</span> | chpasswd  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;root   ALL=(ALL)       ALL&quot;</span> &gt;&gt; /etc/sudoers  </span></span><br><span class="line"><span class="comment"># 下面这两句比较特殊，</span></span><br><span class="line"><span class="comment"># 在centos6上必须要有，否则创建出来的容器sshd不能登录  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了避免文件已存在报错，首先删掉私钥文件</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /etc/ssh/ssh_host_rsa_key</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /etc/ssh/ssh_host_dsa_key</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key  </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动sshd服务并且暴露22端口  </span></span><br><span class="line"><span class="comment"># RUN mkdir /var/run/sshd  </span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">22</span>  </span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/usr/sbin/sshd&quot;</span>, <span class="string">&quot;-D&quot;</span>]</span></span><br><span class="line"><span class="comment">###### 以上建立centos-ssh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装java</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel.x86_64</span></span><br><span class="line"><span class="comment">## 添加环境变量</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME /usr/lib/jvm/jre-openjdk/</span><br><span class="line"><span class="keyword">ENV</span> JRE_HOME $&#123;JAVA_HOME&#125;</span><br><span class="line"><span class="keyword">ENV</span> PATH $JAVA_HOME/bin:$PATH</span><br><span class="line"><span class="keyword">ENV</span> CLASSPATH $CLASSPATH:.:$JAVA_HOME/lib</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export JAVA_HOME=/usr/lib/jvm/jre-openjdk/&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export JRE_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span>&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span>&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export CLASSPATH=<span class="variable">$CLASSPATH</span>:.:<span class="variable">$JAVA_HOME</span>/lib&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装scala</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /data/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://downloads.lightbend.com/scala/2.10.7/scala-2.10.7.rpm</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y scala-2.10.7.rpm</span></span><br><span class="line"><span class="keyword">ENV</span> SCALA_HOME /usr/share/java</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export SCALA_HOME=/usr/share/java&quot;</span> &gt;&gt; /etc/profile.d/java.sh </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装Hadoop</span></span><br><span class="line"><span class="comment">## RUN wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> hadoop-2.7.7.tar /data/hadoop</span></span><br><span class="line"><span class="comment"># RUN tar zxvf /data/hadoop-2.7.7.tar -C /data/hadoop</span></span><br><span class="line"><span class="comment"># RUN ln -s /data/hadoop-2.7.7 /data/hadoop</span></span><br><span class="line"><span class="keyword">ENV</span> HADOOP_HOME /data/hadoop</span><br><span class="line"><span class="keyword">ENV</span> HADOOP_CONF_DIR $&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line"><span class="keyword">ENV</span> YARN_HOME $&#123;HADOOP_HOME&#125;</span><br><span class="line"><span class="keyword">ENV</span> YARN_CONF_DIR $&#123;YARN_HOME&#125;/etc/hadoop</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export HADOOP_HOME=/data/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export YARN_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;export YARN_CONF_DIR=<span class="variable">$&#123;YARN_HOME&#125;</span>/etc/hadoop&quot;</span> &gt;&gt; /etc/profile.d/hadoop.sh</span></span><br></pre></td></tr></table></figure>
<h2 id="制作image"><a href="#制作image" class="headerlink" title="制作image"></a>制作image</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t=&quot;avery/centos-yarn&quot; .</span><br></pre></td></tr></table></figure>
<h2 id="创建yarn节点"><a href="#创建yarn节点" class="headerlink" title="创建yarn节点"></a>创建yarn节点</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run --name yarn0 --hostname yarn0 -d -P -p 50070:50070 -p 8088:8088 avery/centos-yarn</span><br><span class="line">docker run --name yarn1 --hostname yarn1 -d -P avery/centos-yarn</span><br><span class="line">docker run --name yarn2 --hostname yarn2 -d -P avery/centos-yarn</span><br><span class="line">docker run --name yarn3 --hostname yarn3 -d -P avery/centos-yarn</span><br></pre></td></tr></table></figure>
<p>查看三个container的ip:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn0</span></span><br><span class="line">172.17.0.2</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn1</span></span><br><span class="line">172.17.0.3</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn2</span></span><br><span class="line">172.17.0.4</span><br><span class="line"><span class="meta">%</span><span class="bash"> docker inspect --format=<span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> yarn3</span></span><br><span class="line">172.17.0.5</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>节点</th>
<th>备注</th>
<th>ip</th>
</tr>
</thead>
<tbody><tr>
<td>yarn0</td>
<td>master</td>
<td>172.17.0.2</td>
</tr>
<tr>
<td>yarn1</td>
<td>slaver</td>
<td>172.17.0.3</td>
</tr>
<tr>
<td>yarn2</td>
<td>slaver</td>
<td>172.17.0.4</td>
</tr>
<tr>
<td>yarn3</td>
<td>slaver</td>
<td>172.17.0.5</td>
</tr>
</tbody></table>
<p>查看端口</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker container ls -a                                        </span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS                                                                     NAMES</span><br><span class="line">e150f9141cbd        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32771-&gt;22/tcp                                                     yarn3</span><br><span class="line">9fe0eb86b3e9        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32770-&gt;22/tcp                                                     yarn2</span><br><span class="line">1d5c0ea3d3b3        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:32769-&gt;22/tcp                                                     yarn1</span><br><span class="line">60a9cb47ff0c        avery/centos-yarn   &quot;/usr/sbin/sshd -D&quot;      2 minutes ago       Up 2 minutes               0.0.0.0:8088-&gt;8088/tcp, 0.0.0.0:50070-&gt;50070/tcp, 0.0.0.0:32768-&gt;22/tcp   yarn0</span><br></pre></td></tr></table></figure>


<h2 id="连接container"><a href="#连接container" class="headerlink" title="连接container"></a>连接container</h2><p>验证ssh连接</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> ssh root@localhost -p 32774</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入密码 abc.123</span></span><br></pre></td></tr></table></figure>
<p>使用exec</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it yarn0 /bin/bash</span><br></pre></td></tr></table></figure>

<h2 id="修改container的主机名"><a href="#修改container的主机名" class="headerlink" title="修改container的主机名"></a>修改container的主机名</h2><p>分别修改三个container的hosts</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hosts </span><br></pre></td></tr></table></figure>
<p>添加下面配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">172.17.0.2      yarn0</span><br><span class="line">172.17.0.3      yarn1</span><br><span class="line">172.17.0.4      yarn2</span><br><span class="line">172.17.0.5      yarn3</span><br></pre></td></tr></table></figure>
<h2 id="ssh-免密"><a href="#ssh-免密" class="headerlink" title="ssh 免密"></a>ssh 免密</h2><p>设置ssh免密码登录<br>在yarn0上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">mkdir .ssh</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn0</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>在yarn1上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>在yarn2上执行下面操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd  ~</span><br><span class="line">cd .ssh</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> (一直按回车即可)</span></span><br><span class="line">ssh-copy-id -i localhost</span><br><span class="line">ssh-copy-id -i yarn0</span><br><span class="line">ssh-copy-id -i yarn1</span><br><span class="line">ssh-copy-id -i yarn2</span><br><span class="line">ssh-copy-id -i yarn3</span><br></pre></td></tr></table></figure>
<p>至此，Docker搭建Hadoop集群的准备工作</p>
<h2 id="Hadoop-安装"><a href="#Hadoop-安装" class="headerlink" title="Hadoop 安装"></a>Hadoop 安装</h2><p>登录yarn0，修改Hadoop配置</p>
<p>配置 Hadoop，cd  ~/hadoop-2.7.2/etc/hadoop进入hadoop配置目录，需要配置有以下7个文件：hadoop-env.sh，yarn-env.sh，slaves，core-site.xml，hdfs-site.xml，maprd-site.xml，yarn-site.xml。</p>
<p>在hadoop-env.sh中配置JAVA_HOME</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The java implementation to use.</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_77</span><br></pre></td></tr></table></figure>
<p>在yarn-env.sh中配置JAVA_HOME</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> some Java parameters</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_77</span><br></pre></td></tr></table></figure>
<p>在slaves中配置slave节点的ip或者host，</p>
<p>yarn1<br>yarn2<br>yarn3</p>
<p>修改core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://yarn0:9000/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang//hadoop-2.7.2/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn0:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang/hadoop-2.7.2/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/fang/hadoop-2.7.2/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改yarn-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8032&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8030&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8035&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8033&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn0:8088&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>将配置好的hadoop-2.7.2文件夹分发给所有slaves节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r hadoop/* root@yarn1:/data/hadoop</span><br><span class="line">scp -r hadoop/* root@yarn2:/data/hadoop</span><br><span class="line">scp -r hadoop/* root@yarn3:/data/hadoop</span><br></pre></td></tr></table></figure>
<h2 id="启动HDFS和yarn"><a href="#启动HDFS和yarn" class="headerlink" title="启动HDFS和yarn"></a>启动HDFS和yarn</h2><p>格式化HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop namenode -format    #格式化namenode</span><br><span class="line">注：若格式化之后重新修改了配置文件，重新格式化之前需要删除tmp，dfs，logs文件夹。</span><br><span class="line">sbin/start-dfs.sh              #启动dfs </span><br><span class="line">sbin/start-yarn.sh              #启动yarn</span><br></pre></td></tr></table></figure>
<p>检查</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@yarn0 hadoop]# jps</span><br><span class="line">709 ResourceManager</span><br><span class="line">984 Jps</span><br><span class="line">346 NameNode</span><br><span class="line">543 SecondaryNameNode</span><br><span class="line">[root@yarn0 hadoop]# ssh yarn1</span><br><span class="line">Last login: Sun Jun  2 23:21:51 2019 from yarn0</span><br><span class="line">[root@yarn1 ~]# jps</span><br><span class="line">305 NodeManager</span><br><span class="line">449 Jps</span><br><span class="line">200 DataNode</span><br><span class="line">[root@yarn1 ~]# ssh yarn2</span><br><span class="line">Last login: Sun Jun  2 23:22:18 2019 from yarn0</span><br><span class="line">[root@yarn2 ~]# jps</span><br><span class="line">193 DataNode</span><br><span class="line">442 Jps</span><br><span class="line">298 NodeManager</span><br><span class="line">[root@yarn2 ~]# ssh yarn3</span><br><span class="line">Last login: Sun Jun  2 23:22:25 2019 from yarn0</span><br><span class="line">[root@yarn3 ~]# jps</span><br><span class="line">178 DataNode</span><br><span class="line">283 NodeManager</span><br><span class="line">427 Jps</span><br></pre></td></tr></table></figure>
<p>yarn web</p>
<p>浏览器打开 <a target="_blank" rel="noopener" href="http://localhost:8088/">http://localhost:8088</a></p>
<p><img src="/images/distributed/docker/docker-yarn-web.png"></p>
<p>搞定收工</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/bigdata/Hadoop/HDFS-NameNode-2.x-HA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/bigdata/Hadoop/HDFS-NameNode-2.x-HA/" class="post-title-link" itemprop="url">Hadoop NameNode 高可用 (High Availability) 实现解析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-23 00:00:00" itemprop="dateCreated datePublished" datetime="2019-05-23T00:00:00+08:00">2019-05-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:28" itemprop="dateModified" datetime="2021-02-09T09:38:28+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="NameNode-高可用整体架构概述"><a href="#NameNode-高可用整体架构概述" class="headerlink" title="NameNode 高可用整体架构概述"></a>NameNode 高可用整体架构概述</h2><p>在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，包括 MapReduce、Hive、Pig 以及 HBase 等也都无法正常工作，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。</p>
<p>所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger(JobTracker 在 2.0 中已经被整合到 YARN ResourceManger 之中) 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。HDFS NameNode 和 YARN ResourceManger 的高可用 (High Availability，HA) 方案基本类似，两者也复用了部分代码，但是由于 HDFS NameNode 对于数据存储和数据一致性的要求比 YARN ResourceManger 高得多，所以 HDFS NameNode 的高可用实现更为复杂一些，本文从内部实现的角度对 HDFS NameNode 的高可用机制进行详细的分析。</p>
<p>HDFS NameNode 的高可用整体架构如图 1 所示 (图片来源于参考文献 [1])：</p>
<p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img001.png" alt="img"></p>
<p>从上图中，我们可以看出 NameNode 的高可用架构主要分为下面几个部分：</p>
<p>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。</p>
<p>主备切换控制器 ZKFailoverController：</p>
<p>ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。<strong>检测NameNode和主从切换  healthMonitor和ActiveStandbyElector</strong></p>
<p>Zookeeper 集群：为主备切换控制器提供主备选举支持。</p>
<p>共享存储系统：</p>
<p>共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。(会不会没有同步完，新的选举就开始了)</p>
<p>DataNode 节点：</p>
<p>除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 <strong>HDFS 的数据块和 DataNode 之间的映射关系</strong>。<strong>DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。</strong> name node包含的元数据信息</p>
<p>下面开始分别介绍 NameNode 的主备切换实现和共享存储系统的实现，在文章的最后会结合笔者的实践介绍一下在 NameNode 的高可用运维中的一些注意事项。</p>
<h2 id="NameNode-的主备切换实现"><a href="#NameNode-的主备切换实现" class="headerlink" title="NameNode 的主备切换实现"></a>NameNode 的主备切换实现</h2><p>NameNode 主备切换主要由 <strong>ZKFailoverController</strong>、<strong>HealthMonitor</strong> 和 <strong>ActiveStandbyElector</strong> 这 3 个组件来协同实现：</p>
<p><strong>HealthMonitor负责监听NameNode的状态，而ActiveStandbyElector负责主备切换</strong></p>
<p>ZKFailoverController 作为 NameNode 机器上一个独立的进程启动 (在 hdfs 启动脚本之中的进程名为 zkfc)，启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 <strong>HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。</strong> 回调方法分别用于几个场景：</p>
<ul>
<li>强制fench NameNode</li>
<li></li>
</ul>
<p>HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调ZKFailoverController 的相应方法进行自动的主备选举。</p>
<p>ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</p>
<p>NameNode 实现主备切换的流程如图 2 所示，有以下几步：</p>
<p><strong>HAServiceProtocol RPC与Hadoop RPC的异同</strong></p>
<ol>
<li>HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。</li>
<li>HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会<strong>回调 ZKFailoverController 注册的相应方法进行处理</strong>。</li>
<li>如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。</li>
<li>ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。</li>
<li>ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。</li>
<li>ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。</li>
</ol>
<h5 id="图-2-NameNode-的主备切换流程"><a href="#图-2-NameNode-的主备切换流程" class="headerlink" title="图 2.NameNode 的主备切换流程"></a>图 2.NameNode 的主备切换流程</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img002.png" alt="img"></p>
<p>下面分别对 HealthMonitor、ActiveStandbyElector 和 ZKFailoverController 的实现细节进行分析：</p>
<h3 id="HealthMonitor-实现分析"><a href="#HealthMonitor-实现分析" class="headerlink" title="HealthMonitor 实现分析"></a>HealthMonitor 实现分析</h3><p>ZKFailoverController 在初始化的时候会创建 HealthMonitor，HealthMonitor 在内部会启动一个线程来循环调用 NameNode 的 HAServiceProtocol RPC 接口的方法来检测 NameNode 的状态，并将状态的变化通过回调的方式来通知 ZKFailoverController。</p>
<p>HealthMonitor 主要检测 NameNode 的两类状态，分别是 HealthMonitor.State 和 HAServiceStatus。HealthMonitor.State 是通过 HAServiceProtocol RPC 接口的 monitorHealth 方法来获取的，反映了 NameNode 节点的健康状况，主要是磁盘存储资源是否充足。HealthMonitor.State 包括下面几种状态：</p>
<ul>
<li>•INITIALIZING：HealthMonitor 在初始化过程中，还没有开始进行健康状况检测；</li>
<li>•SERVICE_HEALTHY：NameNode 状态正常；</li>
<li>•SERVICE_NOT_RESPONDING：调用 NameNode 的 monitorHealth 方法调用无响应或响应超时；</li>
<li>•SERVICE_UNHEALTHY：NameNode 还在运行，但是 monitorHealth 方法返回状态不正常，磁盘存储资源不足；</li>
<li>•HEALTH_MONITOR_FAILED：HealthMonitor 自己在运行过程中发生了异常，不能继续检测 NameNode 的健康状况，会导致 ZKFailoverController 进程退出；</li>
</ul>
<p>HealthMonitor.State 在状态检测之中起主要的作用，在 HealthMonitor.State 发生变化的时候，HealthMonitor 会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。</p>
<p>而 HAServiceStatus 则是通过 HAServiceProtocol RPC 接口的 getServiceStatus 方法来获取的，主要反映的是 NameNode 的 HA 状态，包括：</p>
<ul>
<li>•INITIALIZING：NameNode 在初始化过程中；</li>
<li>•ACTIVE：当前 NameNode 为主 NameNode；</li>
<li>•STANDBY：当前 NameNode 为备 NameNode；</li>
<li>•STOPPING：当前 NameNode 已停止；</li>
</ul>
<p>HAServiceStatus 在状态检测之中只是起辅助的作用，在 HAServiceStatus 发生变化时，HealthMonitor 也会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。</p>
<h3 id="ActiveStandbyElector-实现分析"><a href="#ActiveStandbyElector-实现分析" class="headerlink" title="ActiveStandbyElector 实现分析"></a>ActiveStandbyElector 实现分析</h3><p>Namenode(包括 YARN ResourceManager) 的主备选举是通过 ActiveStandbyElector 来完成的，ActiveStandbyElector 主要是利用了 Zookeeper 的写一致性和临时节点机制，具体的主备选举实现如下：</p>
<p><strong>创建锁节点</strong></p>
<p>如果 HealthMonitor 检测到对应的 NameNode 的状态正常，那么表示这个 NameNode 有资格参加 Zookeeper 的主备选举。如果目前还没有进行过主备选举的话，那么相应的 ActiveStandbyElector 就会发起一次主备选举，尝试在 Zookeeper 上创建一个路径为/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 的临时节点 (${dfs.nameservices} 为 Hadoop 的配置参数 dfs.nameservices 的值，下同)，Zookeeper 的写一致性会保证最终只会有一个 ActiveStandbyElector 创建成功，那么创建成功的 ActiveStandbyElector 对应的 NameNode 就会成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Active 状态。而创建失败的 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Standby 状态。</p>
<p><strong>注册 Watcher 监听</strong></p>
<p>不管创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点是否成功，ActiveStandbyElector 随后都会向 Zookeeper 注册一个 Watcher 来监听这个节点的状态变化事件，ActiveStandbyElector 主要关注这个节点的 NodeDeleted 事件。</p>
<p><strong>自动触发主备选举</strong></p>
<p>如果 Active NameNode 对应的 HealthMonitor 检测到 NameNode 的状态异常时， ZKFailoverController 会主动删除当前在 Zookeeper 上建立的临时节点<code>/hadoop-ha/$&#123;dfs.nameservices&#125;/ActiveStandbyElectorLock</code>， 这样处于 Standby 状态的 NameNode 的 ActiveStandbyElector 注册的监听器就会收到这个节点的 NodeDeleted 事件。收到这个事件之后，会马上再次进入到创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点的流程，如果创建成功，这个本来处于 Standby 状态的 NameNode 就选举为主 NameNode 并随后开始切换为 Active 状态。</p>
<p>当然，如果是 Active 状态的 NameNode 所在的机器整个宕掉的话，那么根据 Zookeeper 的临时节点特性，/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点会自动被删除，从而也会自动进行一次主备切换。</p>
<p><strong>防止脑裂</strong></p>
<p>Zookeeper 在工程实践的过程中经常会发生的一个现象就是 Zookeeper 客户端“假死”，所谓的“假死”是指如果 Zookeeper 客户端机器负载过高或者正在进行 JVM Full GC，那么可能会导致 Zookeeper 客户端到 Zookeeper 服务端的心跳不能正常发出，一旦这个时间持续较长，超过了配置的 Zookeeper Session Timeout 参数的话，Zookeeper 服务端就会认为客户端的 session 已经过期从而将客户端的 Session 关闭。“假死”有可能引起分布式系统常说的双主或脑裂 (brain-split) 现象。具体到本文所述的 NameNode，假设 NameNode1 当前为 Active 状态，NameNode2 当前为 Standby 状态。如果某一时刻 NameNode1 对应的 ZKFailoverController 进程发生了“假死”现象，那么 Zookeeper 服务端会认为 NameNode1 挂掉了，根据前面的主备切换逻辑，NameNode2 会替代 NameNode1 进入 Active 状态。但是此时 NameNode1 可能仍然处于 Active 状态正常运行，即使随后 NameNode1 对应的 ZKFailoverController 因为负载下降或者 Full GC 结束而恢复了正常，感知到自己和 Zookeeper 的 Session 已经关闭，但是由于网络的延迟以及 CPU 线程调度的不确定性，仍然有可能会在接下来的一段时间窗口内 NameNode1 认为自己还是处于 Active 状态。这样 NameNode1 和 NameNode2 都处于 Active 状态，都可以对外提供服务。这种情况对于 NameNode 这类对数据一致性要求非常高的系统来说是灾难性的，数据会发生错乱且无法恢复。Zookeeper 社区对这种问题的解决方法叫做 fencing，中文翻译为隔离，也就是想办法把旧的 Active NameNode 隔离起来，使它不能正常对外提供服务。</p>
<p>ActiveStandbyElector 为了实现 fencing，会在成功创建 Zookeeper 节点 hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 从而成为 Active NameNode 之后，创建另外一个路径为/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 的持久节点，这个节点里面保存了这个 Active NameNode 的地址信息。Active NameNode 的 ActiveStandbyElector 在正常的状态下关闭 Zookeeper Session 的时候 (注意由于/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 是临时节点，也会随之删除)，会一起删除节点/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb。但是如果 ActiveStandbyElector 在异常的状态下 Zookeeper Session 关闭 (比如前述的 Zookeeper 假死)，那么由于/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 是持久节点，会一直保留下来。后面当另一个 NameNode 选主成功之后，会注意到上一个 Active NameNode 遗留下来的这个节点，从而会回调 ZKFailoverController 的方法对旧的 Active NameNode 进行 fencing，具体处理见后文 ZKFailoverController 部分所述。</p>
<h3 id="ZKFailoverController-实现分析"><a href="#ZKFailoverController-实现分析" class="headerlink" title="ZKFailoverController 实现分析"></a>ZKFailoverController 实现分析</h3><p>ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调函数，ZKFailoverController 的处理逻辑主要靠 HealthMonitor 和 ActiveStandbyElector 的回调函数来驱动。</p>
<p><strong>对 HealthMonitor 状态变化的处理</strong></p>
<p>如前所述，HealthMonitor 会检测 NameNode 的两类状态，HealthMonitor.State 在状态检测之中起主要的作用，ZKFailoverController 注册到 HealthMonitor 上的处理 HealthMonitor.State 状态变化的回调函数主要关注 SERVICE_HEALTHY、SERVICE_NOT_RESPONDING 和 SERVICE_UNHEALTHY 这 3 种状态：</p>
<ul>
<li>•如果检测到状态为 SERVICE_HEALTHY，表示当前的 NameNode 有资格参加 Zookeeper 的主备选举，如果目前还没有进行过主备选举的话，ZKFailoverController 会调用 ActiveStandbyElector 的 joinElection 方法发起一次主备选举。</li>
<li>•如果检测到状态为 SERVICE_NOT_RESPONDING 或者是 SERVICE_UNHEALTHY，就表示当前的 NameNode 出现问题了，ZKFailoverController 会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举，这样其它的 NameNode 就有机会成为主 NameNode。</li>
</ul>
<p>而 HAServiceStatus 在状态检测之中仅起辅助的作用，在 HAServiceStatus 发生变化时，ZKFailoverController 注册到 HealthMonitor 上的处理 HAServiceStatus 状态变化的回调函数会判断 NameNode 返回的 HAServiceStatus 和 ZKFailoverController 所期望的是否一致，如果不一致的话，ZKFailoverController 也会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举。</p>
<p><strong>对 ActiveStandbyElector 主备选举状态变化的处理</strong></p>
<p>在 ActiveStandbyElector 的主备选举状态发生变化时，会回调 ZKFailoverController 注册的回调函数来进行相应的处理：</p>
<ul>
<li>•如果 ActiveStandbyElector 选主成功，那么 ActiveStandbyElector 对应的 NameNode 成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeActive 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToActive 方法，将 NameNode 转换为 Active 状态。</li>
<li>•如果 ActiveStandbyElector 选主失败，那么 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeStandby 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，将 NameNode 转换为 Standby 状态。</li>
<li>•如果 ActiveStandbyElector 选主成功之后，发现了上一个 Active NameNode 遗留下来的/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 节点 (见“ActiveStandbyElector 实现分析”一节“防止脑裂”部分所述)，那么 ActiveStandbyElector 会首先回调 ZKFailoverController 注册的 fenceOldActive 方法，尝试对旧的 Active NameNode 进行 fencing，在进行 fencing 的时候，会执行以下的操作：</li>
</ul>
<ol>
<li>1.首先尝试调用这个旧 Active NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，看能不能把它转换为 Standby 状态。</li>
<li>2.如果 transitionToStandby 方法调用失败，那么就执行 Hadoop 配置文件之中预定义的隔离措施，Hadoop 目前主要提供两种隔离措施，通常会选择 sshfence：</li>
</ol>
<ul>
<li>•sshfence：通过 SSH 登录到目标机器上，执行命令 fuser 将对应的进程杀死；</li>
<li>•shellfence：执行一个用户自定义的 shell 脚本来将对应的进程隔离；</li>
</ul>
<p>只有在成功地执行完成 fencing 之后，选主成功的 ActiveStandbyElector 才会回调 ZKFailoverController 的 becomeActive 方法将对应的 NameNode 转换为 Active 状态，开始对外提供服务。</p>
<h2 id="NameNode-的共享存储实现"><a href="#NameNode-的共享存储实现" class="headerlink" title="NameNode 的共享存储实现"></a>NameNode 的共享存储实现</h2><p>过去几年中 Hadoop 社区涌现过很多的 NameNode 共享存储方案，比如 shared NAS+NFS、BookKeeper、BackupNode 和 QJM(Quorum Journal Manager) 等等。目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案合并到 HDFS 的 trunk 之中并且作为默认的共享存储实现，本部分只针对基于 QJM 的共享存储方案的内部实现原理进行分析。为了理解 QJM 的设计和实现，首先要对 NameNode 的元数据存储结构有所了解。</p>
<h3 id="NameNode-的元数据存储概述"><a href="#NameNode-的元数据存储概述" class="headerlink" title="NameNode 的元数据存储概述"></a>NameNode 的元数据存储概述</h3><p>一个典型的 NameNode 的元数据存储目录结构如图 3 所示 (图片来源于参考文献 [4])，这里主要关注其中的 EditLog 文件和 FSImage 文件：</p>
<h5 id="图-3-NameNode-的元数据存储目录结构"><a href="#图-3-NameNode-的元数据存储目录结构" class="headerlink" title="图 3 .NameNode 的元数据存储目录结构"></a>图 3 .NameNode 的元数据存储目录结构</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img003.png" alt="img"></p>
<p>NameNode 在执行 HDFS 客户端提交的创建文件或者移动文件这样的写操作的时候，会首先把这些操作记录在 EditLog 文件之中，然后再更新内存中的文件系统镜像。内存中的文件系统镜像用于 NameNode 向客户端提供读服务，而 EditLog 仅仅只是在数据恢复的时候起作用。记录在 EditLog 之中的每一个操作又称为一个事务，每个事务有一个整数形式的事务 id 作为编号。EditLog 会被切割为很多段，每一段称为一个 Segment。正在写入的 EditLog Segment 处于 in-progress 状态，其文件名形如 edits_inprogress_${start_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，例如上图中的 edits_inprogress_0000000000000000020。而已经写入完成的 EditLog Segment 处于 finalized 状态，其文件名形如 edits_${start_txid}-${end_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，${end_txid} 表示这个 segment 的结束事务 id，例如上图中的 edits_0000000000000000001-0000000000000000019。</p>
<p>NameNode 会定期对内存中的文件系统镜像进行 checkpoint 操作，在磁盘上生成 FSImage 文件，FSImage 文件的文件名形如 fsimage_${end_txid}，其中${end_txid} 表示这个 fsimage 文件的结束事务 id，例如上图中的 fsimage_0000000000000000020。在 NameNode 启动的时候会进行数据恢复，首先把 FSImage 文件加载到内存中形成文件系统镜像，然后再把 EditLog 之中 FsImage 的结束事务 id 之后的 EditLog 回放到这个文件系统镜像上。</p>
<h3 id="基于-QJM-的共享存储系统的总体架构"><a href="#基于-QJM-的共享存储系统的总体架构" class="headerlink" title="基于 QJM 的共享存储系统的总体架构"></a>基于 QJM 的共享存储系统的总体架构</h3><p><strong>基于 QJM 的共享存储系统主要用于保存 EditLog，并不保存 FSImage 文件</strong>。FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法 (参见参考文献 [3])，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉。</p>
<p>基于 QJM 的共享存储系统的内部实现架构图如图 4 所示，主要包含下面几个主要的组件：</p>
<h5 id="图-4-基于-QJM-的共享存储系统的内部实现架构图"><a href="#图-4-基于-QJM-的共享存储系统的内部实现架构图" class="headerlink" title="图 4 . 基于 QJM 的共享存储系统的内部实现架构图"></a>图 4 . 基于 QJM 的共享存储系统的内部实现架构图</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img004.png" alt="img"></p>
<p>FSEditLog：这个类封装了对 EditLog 的所有操作，是 NameNode 对 EditLog 的所有操作的入口。</p>
<p>JournalSet： 这个类封装了对本地磁盘和 JournalNode 集群上的 EditLog 的操作，内部包含了两类 JournalManager，一类为 FileJournalManager，用于实现对本地磁盘上 EditLog 的操作。一类为 QuorumJournalManager，用于实现对 JournalNode 集群上共享目录的 EditLog 的操作。FSEditLog 只会调用 JournalSet 的相关方法，而不会直接使用 FileJournalManager 和 QuorumJournalManager。</p>
<p>FileJournalManager：封装了对本地磁盘上的 EditLog 文件的操作，不仅 NameNode 在向本地磁盘上写入 EditLog 的时候使用 FileJournalManager，JournalNode 在向本地磁盘写入 EditLog 的时候也复用了 FileJournalManager 的代码和逻辑。</p>
<p>QuorumJournalManager：封装了对 JournalNode 集群上的 EditLog 的操作，它会根据 JournalNode 集群的 URI 创建负责与 JournalNode 集群通信的类 AsyncLoggerSet， QuorumJournalManager 通过 AsyncLoggerSet 来实现对 JournalNode 集群上的 EditLog 的写操作，对于读操作，QuorumJournalManager 则是通过 Http 接口从 JournalNode 上的 JournalNodeHttpServer 读取 EditLog 的数据。</p>
<p>AsyncLoggerSet：内部包含了与 JournalNode 集群进行通信的 AsyncLogger 列表，每一个 AsyncLogger 对应于一个 JournalNode 节点，另外 AsyncLoggerSet 也包含了用于等待大多数 JournalNode 返回结果的工具类方法给 QuorumJournalManager 使用。</p>
<p>AsyncLogger：具体的实现类是 IPCLoggerChannel，IPCLoggerChannel 在执行方法调用的时候，会把调用提交到一个单线程的线程池之中，由线程池线程来负责向对应的 JournalNode 的 JournalNodeRpcServer 发送 RPC 请求。</p>
<p>JournalNodeRpcServer：运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求。</p>
<p>JournalNodeHttpServer：运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby 状态的 NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求。</p>
<p>下面对基于 QJM 的共享存储系统的两个关键性问题同步数据和恢复数据进行详细分析。</p>
<h3 id="基于-QJM-的共享存储系统的数据同步机制分析"><a href="#基于-QJM-的共享存储系统的数据同步机制分析" class="headerlink" title="基于 QJM 的共享存储系统的数据同步机制分析"></a>基于 QJM 的共享存储系统的数据同步机制分析</h3><p>Active NameNode 和 StandbyNameNode 使用 JouranlNode 集群来进行数据同步的过程如图 5 所示，Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog：</p>
<h5 id="图-5-基于-QJM-的共享存储的数据同步机制"><a href="#图-5-基于-QJM-的共享存储的数据同步机制" class="headerlink" title="图 5 . 基于 QJM 的共享存储的数据同步机制"></a>图 5 . 基于 QJM 的共享存储的数据同步机制</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img005.png" alt="img"></p>
<p><strong>Active NameNode 提交 EditLog 到 JournalNode 集群</strong></p>
<p>当处于 Active 状态的 NameNode 调用 FSEditLog 类的 logSync 方法来提交 EditLog 的时候，会通过 JournalSet 同时向本地磁盘目录和 JournalNode 集群上的共享存储目录写入 EditLog。写入 JournalNode 集群是通过并行调用每一个 JournalNode 的 QJournalProtocol RPC 接口的 journal 方法实现的，如果对大多数 JournalNode 的 journal 方法调用成功，那么就认为提交 EditLog 成功，否则 NameNode 就会认为这次提交 EditLog 失败。提交 EditLog 失败会导致 Active NameNode 关闭 JournalSet 之后退出进程，留待处于 Standby 状态的 NameNode 接管之后进行数据恢复。</p>
<p>从上面的叙述可以看出，Active NameNode 提交 EditLog 到 JournalNode 集群的过程实际上是同步阻塞的，但是并不需要所有的 JournalNode 都调用成功，只要大多数 JournalNode 调用成功就可以了。如果无法形成大多数，那么就认为提交 EditLog 失败，NameNode 停止服务退出进程。如果对应到分布式系统的 CAP 理论的话，虽然采用了 Paxos 的“大多数”思想对 C(consistency，一致性) 和 A(availability，可用性) 进行了折衷，但还是可以认为 NameNode 选择了 C 而放弃了 A，这也符合 NameNode 对数据一致性的要求。</p>
<p><strong>Standby NameNode 从 JournalNode 集群同步 EditLog</strong></p>
<p>当 NameNode 进入 Standby 状态之后，会启动一个 EditLogTailer 线程。这个线程会定期调用 EditLogTailer 类的 doTailEdits 方法从 JournalNode 集群上同步 EditLog，然后把同步的 EditLog 回放到内存之中的文件系统镜像上 (并不会同时把 EditLog 写入到本地磁盘上)。</p>
<p>这里需要关注的是：从 JournalNode 集群上同步的 EditLog 都是处于 finalized 状态的 EditLog Segment。“NameNode 的元数据存储概述”一节说过 EditLog Segment 实际上有两种状态，处于 in-progress 状态的 Edit Log 当前正在被写入，被认为是处于不稳定的中间态，有可能会在后续的过程之中发生修改，比如被截断。Active NameNode 在完成一个 EditLog Segment 的写入之后，就会向 JournalNode 集群发送 finalizeLogSegment RPC 请求，将完成写入的 EditLog Segment finalized，然后开始下一个新的 EditLog Segment。一旦 finalizeLogSegment 方法在大多数的 JournalNode 上调用成功，表明这个 EditLog Segment 已经在大多数的 JournalNode 上达成一致。一个 EditLog Segment 处于 finalized 状态之后，可以保证它再也不会变化。</p>
<p>从上面描述的过程可以看出，虽然 Active NameNode 向 JournalNode 集群提交 EditLog 是同步的，但 Standby NameNode 采用的是定时从 JournalNode 集群上同步 EditLog 的方式，那么 Standby NameNode 内存中文件系统镜像有很大的可能是落后于 Active NameNode 的，所以 Standby NameNode 在转换为 Active NameNode 的时候需要把落后的 EditLog 补上来。</p>
<h3 id="基于-QJM-的共享存储系统的数据恢复机制分析"><a href="#基于-QJM-的共享存储系统的数据恢复机制分析" class="headerlink" title="基于 QJM 的共享存储系统的数据恢复机制分析"></a>基于 QJM 的共享存储系统的数据恢复机制分析</h3><p>处于 Standby 状态的 NameNode 转换为 Active 状态的时候，有可能上一个 Active NameNode 发生了异常退出，那么 JournalNode 集群中各个 JournalNode 上的 EditLog 就可能会处于不一致的状态，所以首先要做的事情就是让 JournalNode 集群中各个节点上的 EditLog 恢复为一致。另外如前所述，当前处于 Standby 状态的 NameNode 的内存中的文件系统镜像有很大的可能是落后于旧的 Active NameNode 的，所以在 JournalNode 集群中各个节点上的 EditLog 达成一致之后，接下来要做的事情就是从 JournalNode 集群上补齐落后的 EditLog。只有在这两步完成之后，当前新的 Active NameNode 才能安全地对外提供服务。</p>
<p>补齐落后的 EditLog 的过程复用了前面描述的 Standby NameNode 从 JournalNode 集群同步 EditLog 的逻辑和代码，最终调用 EditLogTailer 类的 doTailEdits 方法来完成 EditLog 的补齐。使 JournalNode 集群上的 EditLog 达成一致的过程是一致性算法 Paxos 的典型应用场景，QJM 对这部分的处理可以看做是 Single Instance Paxos(参见参考文献 [3]) 算法的一个实现，在达成一致的过程中，Active NameNode 和 JournalNode 集群之间的交互流程如图 6 所示，具体描述如下：</p>
<h5 id="图-6-Active-NameNode-和-JournalNode-集群的交互流程图"><a href="#图-6-Active-NameNode-和-JournalNode-集群的交互流程图" class="headerlink" title="图 6.Active NameNode 和 JournalNode 集群的交互流程图"></a>图 6.Active NameNode 和 JournalNode 集群的交互流程图</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img006.png" alt="img"></p>
<p><strong>生成一个新的 Epoch</strong></p>
<p>Epoch 是一个单调递增的整数，用来标识每一次 Active NameNode 的生命周期，每发生一次 NameNode 的主备切换，Epoch 就会加 1。这实际上是一种 fencing 机制，为什么需要 fencing 已经在前面“ActiveStandbyElector 实现分析”一节的“防止脑裂”部分进行了说明。产生新 Epoch 的流程与 Zookeeper 的 ZAB(Zookeeper Atomic Broadcast) 协议在进行数据恢复之前产生新 Epoch 的过程完全类似：</p>
<ol>
<li><p>1.</p>
<p>Active NameNode 首先向 JournalNode 集群发送 getJournalState RPC 请求，每个 JournalNode 会返回自己保存的最近的那个 Epoch(代码中叫 lastPromisedEpoch)。</p>
</li>
<li><p>2.</p>
<p>NameNode 收到大多数的 JournalNode 返回的 Epoch 之后，在其中选择最大的一个加 1 作为当前的新 Epoch，然后向各个 JournalNode 发送 newEpoch RPC 请求，把这个新的 Epoch 发给各个 JournalNode。</p>
</li>
<li><p>3.</p>
<p>每一个 JournalNode 在收到新的 Epoch 之后，首先检查这个新的 Epoch 是否比它本地保存的 lastPromisedEpoch 大，如果大的话就把 lastPromisedEpoch 更新为这个新的 Epoch，并且向 NameNode 返回它自己的本地磁盘上最新的一个 EditLogSegment 的起始事务 id，为后面的数据恢复过程做好准备。如果小于或等于的话就向 NameNode 返回错误。</p>
</li>
<li><p>4.</p>
<p>NameNode 收到大多数 JournalNode 对 newEpoch 的成功响应之后，就会认为生成新的 Epoch 成功。</p>
</li>
</ol>
<p>在生成新的 Epoch 之后，每次 NameNode 在向 JournalNode 集群提交 EditLog 的时候，都会把这个 Epoch 作为参数传递过去。每个 JournalNode 会比较传过来的 Epoch 和它自己保存的 lastPromisedEpoch 的大小，如果传过来的 epoch 的值比它自己保存的 lastPromisedEpoch 小的话，那么这次写相关操作会被拒绝。一旦大多数 JournalNode 都拒绝了这次写操作，那么这次写操作就失败了。如果原来的 Active NameNode 恢复正常之后再向 JournalNode 写 EditLog，那么因为它的 Epoch 肯定比新生成的 Epoch 小，并且大多数的 JournalNode 都接受了这个新生成的 Epoch，所以拒绝写入的 JournalNode 数目至少是大多数，这样原来的 Active NameNode 写 EditLog 就肯定会失败，失败之后这个 NameNode 进程会直接退出，这样就实现了对原来的 Active NameNode 的隔离了。</p>
<p><strong>选择需要数据恢复的 EditLog Segment 的 id</strong></p>
<p>需要恢复的 Edit Log 只可能是各个 JournalNode 上的最后一个 Edit Log Segment，如前所述，JournalNode 在处理完 newEpoch RPC 请求之后，会向 NameNode 返回它自己的本地磁盘上最新的一个 EditLog Segment 的起始事务 id，这个起始事务 id 实际上也作为这个 EditLog Segment 的 id。NameNode 会在所有这些 id 之中选择一个最大的 id 作为要进行数据恢复的 EditLog Segment 的 id。</p>
<p><strong>向 JournalNode 集群发送 prepareRecovery RPC 请求</strong></p>
<p>NameNode 接下来向 JournalNode 集群发送 prepareRecovery RPC 请求，请求的参数就是选出的 EditLog Segment 的 id。JournalNode 收到请求后返回本地磁盘上这个 Segment 的起始事务 id、结束事务 id 和状态 (in-progress 或 finalized)。</p>
<p>这一步对应于 Paxos 算法的 Phase 1a 和 Phase 1b(参见参考文献 [3]) 两步。Paxos 算法的 Phase1 是 prepare 阶段，这也与方法名 prepareRecovery 相对应。并且这里以前面产生的新的 Epoch 作为 Paxos 算法中的提案编号 (proposal number)。只要大多数的 JournalNode 的 prepareRecovery RPC 调用成功返回，NameNode 就认为成功。</p>
<p>选择进行同步的基准数据源，向 JournalNode 集群发送 acceptRecovery RPC 请求 NameNode 根据 prepareRecovery 的返回结果，选择一个 JournalNode 上的 EditLog Segment 作为同步的基准数据源。选择基准数据源的原则大致是：在 in-progress 状态和 finalized 状态的 Segment 之间优先选择 finalized 状态的 Segment。如果都是 in-progress 状态的话，那么优先选择 Epoch 比较高的 Segment(也就是优先选择更新的)，如果 Epoch 也一样，那么优先选择包含的事务数更多的 Segment。</p>
<p>在选定了同步的基准数据源之后，NameNode 向 JournalNode 集群发送 acceptRecovery RPC 请求，将选定的基准数据源作为参数。JournalNode 接收到 acceptRecovery RPC 请求之后，从基准数据源 JournalNode 的 JournalNodeHttpServer 上下载 EditLog Segment，将本地的 EditLog Segment 替换为下载的 EditLog Segment。</p>
<p>这一步对应于 Paxos 算法的 Phase 2a 和 Phase 2b(参见参考文献 [3]) 两步。Paxos 算法的 Phase2 是 accept 阶段，这也与方法名 acceptRecovery 相对应。只要大多数 JournalNode 的 acceptRecovery RPC 调用成功返回，NameNode 就认为成功。</p>
<p><strong>向 JournalNode 集群发送 finalizeLogSegment RPC 请求，数据恢复完成</strong></p>
<p>上一步执行完成之后，NameNode 确认大多数 JournalNode 上的 EditLog Segment 已经从基准数据源进行了同步。接下来，NameNode 向 JournalNode 集群发送 finalizeLogSegment RPC 请求，JournalNode 接收到请求之后，将对应的 EditLog Segment 从 in-progress 状态转换为 finalized 状态，实际上就是将文件名从 edits_inprogress_${startTxid} 重命名为 edits_${startTxid}-${endTxid}，见“NameNode 的元数据存储概述”一节的描述。</p>
<p>只要大多数 JournalNode 的 finalizeLogSegment RPC 调用成功返回，NameNode 就认为成功。此时可以保证 JournalNode 集群的大多数节点上的 EditLog 已经处于一致的状态，这样 NameNode 才能安全地从 JournalNode 集群上补齐落后的 EditLog 数据。</p>
<p>需要注意的是，尽管基于 QJM 的共享存储方案看起来理论完备，设计精巧，但是仍然无法保证数据的绝对强一致，下面选取参考文献 [2] 中的一个例子来说明：</p>
<p>假设有 3 个 JournalNode：JN1、JN2 和 JN3，Active NameNode 发送了事务 id 为 151、152 和 153 的 3 个事务到 JournalNode 集群，这 3 个事务成功地写入了 JN2，但是在还没能写入 JN1 和 JN3 之前，Active NameNode 就宕机了。同时，JN3 在整个写入的过程中延迟较大，落后于 JN1 和 JN2。最终成功写入 JN1 的事务 id 为 150，成功写入 JN2 的事务 id 为 153，而写入到 JN3 的事务 id 仅为 125，如图 7 所示 (图片来源于参考文献 [2])。按照前面描述的只有成功地写入了大多数的 JournalNode 才认为写入成功的原则，显然事务 id 为 151、152 和 153 的这 3 个事务只能算作写入失败。在进行数据恢复的过程中，会发生下面两种情况：</p>
<h5 id="图-7-JournalNode-集群写入的事务-id-情况"><a href="#图-7-JournalNode-集群写入的事务-id-情况" class="headerlink" title="图 7.JournalNode 集群写入的事务 id 情况"></a>图 7.JournalNode 集群写入的事务 id 情况</h5><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img007.png" alt="img"></p>
<ul>
<li>•如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段收到了 JN2 的回复，那么肯定会以 JN2 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 153。从恢复的结果来看，实际上可以认为前面宕机的 Active NameNode 对事务 id 为 151、152 和 153 的这 3 个事务的写入成功了。但是如果从 NameNode 自身的角度来看，这显然就发生了数据不一致的情况。</li>
<li>•如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段没有收到 JN2 的回复，那么肯定会以 JN1 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 150。在这种情况下，如果从 NameNode 自身的角度来看的话，数据就是一致的了。</li>
</ul>
<p>事实上不光本文描述的基于 QJM 的共享存储方案无法保证数据的绝对一致，大家通常认为的一致性程度非常高的 Zookeeper 也会发生类似的情况，这也从侧面说明了要实现一个数据绝对一致的分布式存储系统的确非常困难。</p>
<h3 id="NameNode-在进行状态转换时对共享存储的处理"><a href="#NameNode-在进行状态转换时对共享存储的处理" class="headerlink" title="NameNode 在进行状态转换时对共享存储的处理"></a>NameNode 在进行状态转换时对共享存储的处理</h3><p>下面对 NameNode 在进行状态转换的过程中对共享存储的处理进行描述，使得大家对基于 QJM 的共享存储方案有一个完整的了解，同时也作为本部分的总结。</p>
<p><strong>NameNode 初始化启动，进入 Standby 状态</strong></p>
<p>在 NameNode 以 HA 模式启动的时候，NameNode 会认为自己处于 Standby 模式，在 NameNode 的构造函数中会加载 FSImage 文件和 EditLog Segment 文件来恢复自己的内存文件系统镜像。在加载 EditLog Segment 的时候，调用 FSEditLog 类的 initSharedJournalsForRead 方法来创建只包含了在 JournalNode 集群上的共享目录的 JournalSet，也就是说，这个时候只会从 JournalNode 集群之中加载 EditLog，而不会加载本地磁盘上的 EditLog。另外值得注意的是，加载的 EditLog Segment 只是处于 finalized 状态的 EditLog Segment，而处于 in-progress 状态的 Segment 需要后续在切换为 Active 状态的时候，进行一次数据恢复过程，将 in-progress 状态的 Segment 转换为 finalized 状态的 Segment 之后再进行读取。</p>
<p>加载完 FSImage 文件和共享目录上的 EditLog Segment 文件之后，NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式。如前所述，EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog。而 StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点。</p>
<p><strong>NameNode 从 Standby 状态切换为 Active 状态</strong></p>
<p>当 NameNode 从 Standby 状态切换为 Active 状态的时候，首先需要做的就是停止它在 Standby 状态的时候启动的线程和相关的服务，包括上面提到的 EditLogTailer 线程和 StandbyCheckpointer 线程，然后关闭用于读取 JournalNode 集群的共享目录上的 EditLog 的 JournalSet，接下来会调用 FSEditLog 的 initJournalSetForWrite 方法重新打开 JournalSet。不同的是，这个 JournalSet 内部同时包含了本地磁盘目录和 JournalNode 集群上的共享目录。这些工作完成之后，就开始执行“基于 QJM 的共享存储系统的数据恢复机制分析”一节所描述的流程，调用 FSEditLog 类的 recoverUnclosedStreams 方法让 JournalNode 集群中各个节点上的 EditLog 达成一致。然后调用 EditLogTailer 类的 catchupDuringFailover 方法从 JournalNode 集群上补齐落后的 EditLog。最后打开一个新的 EditLog Segment 用于新写入数据，同时启动 Active NameNode 所需要的线程和服务。</p>
<p><strong>NameNode 从 Active 状态切换为 Standby 状态</strong></p>
<p>当 NameNode 从 Active 状态切换为 Standby 状态的时候，首先需要做的就是停止它在 Active 状态的时候启动的线程和服务，然后关闭用于读取本地磁盘目录和 JournalNode 集群上的共享目录的 EditLog 的 JournalSet。接下来会调用 FSEditLog 的 initSharedJournalsForRead 方法重新打开用于读取 JournalNode 集群上的共享目录的 JournalSet。这些工作完成之后，就会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，EditLogTailer 线程会定时从 JournalNode 集群上同步 Edit Log。</p>
<h2 id="NameNode-高可用运维中的注意事项"><a href="#NameNode-高可用运维中的注意事项" class="headerlink" title="NameNode 高可用运维中的注意事项"></a>NameNode 高可用运维中的注意事项</h2><p>本节结合笔者的实践，从初始化部署和日常运维两个方面介绍一些在 NameNode 高可用运维中的注意事项。</p>
<h3 id="初始化部署"><a href="#初始化部署" class="headerlink" title="初始化部署"></a>初始化部署</h3><p>如果在开始部署 Hadoop 集群的时候就启用 NameNode 的高可用的话，那么相对会比较容易。但是如果在采用传统的单 NameNode 的架构运行了一段时间之后，升级为 NameNode 的高可用架构的话，就要特别注意在升级的时候需要按照以下的步骤进行操作：</p>
<ol>
<li>1.对 Zookeeper 进行初始化，创建 Zookeeper 上的/hadoop-ha/${dfs.nameservices} 节点。创建节点是为随后通过 Zookeeper 进行主备选举做好准备，在进行主备选举的时候会在这个节点下面创建子节点 (具体可参照“ActiveStandbyElector 实现分析”一节的叙述)。这一步通过在原有的 NameNode 上执行命令 hdfs zkfc -formatZK 来完成。</li>
<li>2.启动所有的 JournalNode，这通过脚本命令 hadoop-daemon.sh start journalnode 来完成。</li>
<li>3.对 JouranlNode 集群的共享存储目录进行格式化，并且将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件 (具体可参照“NameNode 的元数据存储概述”一节的叙述) 之后的 EditLog 拷贝到 JournalNode 集群上的共享目录之中，这通过在原有的 NameNode 上执行命令 hdfs namenode -initializeSharedEdits 来完成。</li>
<li>4.启动原有的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。</li>
<li>5.对新增的 NameNode 节点进行初始化，将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件拷贝到这个新增的 NameNode 的本地磁盘上，同时需要验证 JournalNode 集群的共享存储目录上已经具有了这个 FSImage 文件之后的 EditLog(已经在第 3 步完成了)。这一步通过在新增的 NameNode 上执行命令 hdfs namenode -bootstrapStandby 来完成。</li>
<li>6.启动新增的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。</li>
<li>7.在这两个 NameNode 上启动 zkfc(ZKFailoverController) 进程，谁通过 Zookeeper 选主成功，谁就是主 NameNode，另一个为备 NameNode。这通过脚本命令 hadoop-daemon.sh start zkfc 完成。</li>
</ol>
<h3 id="日常维护"><a href="#日常维护" class="headerlink" title="日常维护"></a>日常维护</h3><p>笔者在日常的维护之中主要遇到过下面两种问题：</p>
<p>Zookeeper 过于敏感：Hadoop 的配置项中 Zookeeper 的 session timeout 的配置参数 ha.zookeeper.session-timeout.ms 的默认值为 5000，也就是 5s，这个值比较小，会导致 Zookeeper 比较敏感，可以把这个值尽量设置得大一些，避免因为网络抖动等原因引起 NameNode 进行无谓的主备切换。</p>
<p>单台 JouranlNode 故障时会导致主备无法切换：在理论上，如果有 3 台或者更多的 JournalNode，那么挂掉一台 JouranlNode 应该仍然可以进行正常的主备切换。但是笔者在某次 NameNode 重启的时候，正好赶上一台 JournalNode 挂掉宕机了，这个时候虽然某一台 NameNode 通过 Zookeeper 选主成功，但是这台被选为主的 NameNode 无法成功地从 Standby 状态切换为 Active 状态。事后追查原因发现，被选为主的 NameNode 卡在退出 Standby 状态的最后一步，这个时候它需要等待到 JournalNode 的请求全部完成之后才能退出。但是由于有一台 JouranlNode 宕机，到这台 JournalNode 的请求都积压在一起并且在不断地进行重试，同时在 Hadoop 的配置项中重试次数的默认值非常大，所以就会导致被选为主的 NameNode 无法及时退出 Standby 状态。这个问题主要是 Hadoop 内部的 RPC 通信框架的设计缺陷引起的，Hadoop HA 的源代码 IPCLoggerChannel 类中有关于这个问题的 TODO，但是截止到社区发布的 2.7.1 版本这个问题仍然存在。</p>
<h4 id="相关主题"><a href="#相关主题" class="headerlink" title="相关主题"></a>相关主题</h4><ul>
<li>•[<a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HDFS-1623">1]Sanjay Radia, Suresh Srinivas. High Availability for the HDFS Namenode.</a></li>
<li>•[<a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HDFS-3077">2]Todd Lipcon . Quorum-Journal Design.</a></li>
<li>•[<a target="_blank" rel="noopener" href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">3]L Lamport. Paxos Made Simple. ACM SIGACT News,2001</a></li>
<li>•[<a target="_blank" rel="noopener" href="http://shop.oreilly.com/product/0636920033448.do">4]Tom White.Hadoop: The Definitive Guide 4th Edition. O’Reilly Media, Inc., 2015</a></li>
<li>•<a target="_blank" rel="noopener" href="http://www.ibm.com/developerworks/cn/opensource/">developerWorks 开源技术主题</a>：查找丰富的操作信息、工具和项目更新，帮助您掌握开源技术并将其用于 IBM 产品。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/database/MySQL/information_schema/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/database/MySQL/information_schema/" class="post-title-link" itemprop="url">MySQL information_schema数据库</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-25 11:00:00" itemprop="dateCreated datePublished" datetime="2019-03-25T11:00:00+08:00">2019-03-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:26" itemprop="dateModified" datetime="2021-02-09T09:38:26+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DataBase/" itemprop="url" rel="index"><span itemprop="name">DataBase</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>information_schema这这个数据库中保存了MySQL服务器所有数据库的信息。<br>如数据库名，数据库的表，表栏的数据类型与访问权限等。<br>再简单点，这台MySQL服务器上，到底有哪些数据库、各个数据库有哪些表，<br>每张表的字段类型是什么，各个数据库要什么权限才能访问，等等信息都保存在information_schema里面。</p>
<p>选用MySQL版本 5.6.25</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> version();</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="operator">|</span> version()  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5.6</span><span class="number">.25</span><span class="operator">-</span>log <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">use information_schema;</span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Tables_in_information_schema          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> CHARACTER_SETS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLLATIONS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLLATION_CHARACTER_SET_APPLICABILITY <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLUMNS                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> COLUMN_PRIVILEGES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ENGINES                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> EVENTS                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> FILES                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> GLOBAL_STATUS                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> GLOBAL_VARIABLES                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> KEY_COLUMN_USAGE                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OPTIMIZER_TRACE                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PARAMETERS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PARTITIONS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PLUGINS                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PROCESSLIST                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> PROFILING                             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> REFERENTIAL_CONSTRAINTS               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ROUTINES                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SCHEMATA                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SCHEMA_PRIVILEGES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SESSION_STATUS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SESSION_VARIABLES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> STATISTICS                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLES                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLESPACES                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLE_CONSTRAINTS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TABLE_PRIVILEGES                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TRIGGERS                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> USER_PRIVILEGES                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> VIEWS                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_LOCKS                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_TRX                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_DATAFILES                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_LOCK_WAITS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLESTATS                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_METRICS                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_RESET                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_PER_INDEX                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMPMEM_RESET                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_DELETED                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_PAGE_LRU                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FOREIGN                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_COLUMNS                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_INDEXES                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_DEFAULT_STOPWORD            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FIELDS                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMP_PER_INDEX_RESET            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_PAGE                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_CMPMEM                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_INDEX_TABLE                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_BEING_DELETED               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLESPACES                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_INDEX_CACHE                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_FOREIGN_COLS               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_SYS_TABLES                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_BUFFER_POOL_STATS              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INNODB_FT_CONFIG                      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------------+</span></span><br><span class="line"><span class="number">59</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure>
<p>information_schema 数据库中有59张表， 分别存储了如下的信息:<br><a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.6/en/information-schema.html">参考官方文档</a></p>
<table>
<thead>
<tr>
<th>SCHEMATA</th>
<th>提供了当前mysql实例中所有数据库的信息，show databases的结果取之此表。</th>
</tr>
</thead>
<tbody><tr>
<td>TABLES</td>
<td>提供了关于数据库中的表的信息（包括视图），详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息，show tables from schemaname的结果取之此表。</td>
</tr>
<tr>
<td>COLUMNS</td>
<td>提供了表中的列信息，详细表述了某张表的所有列以及每个列的信息，show columns from  schemaname.tablename的结果取之此表。</td>
</tr>
<tr>
<td>STATISTICS</td>
<td>提供了关于表索引的信息，show index from schemaname.tablename的结果取之此表。</td>
</tr>
<tr>
<td>USER_PRIVILEGES（用户权限）</td>
<td>给出了关于全程权限的信息，该信息源自mysql.user授权表，是非标准表。</td>
</tr>
<tr>
<td>SCHEMA_PRIVILEGES（方案权限）</td>
<td>给出了关于方案（数据库）权限的信息，该信息来自mysql.db授权表，是非标准表。</td>
</tr>
<tr>
<td>TABLE_PRIVILEGES（表权限）</td>
<td>给出了关于表权限的信息，该信息源自mysql.tables_priv授权表，是非标准表。</td>
</tr>
<tr>
<td>COLUMN_PRIVILEGES（列权限）</td>
<td>给出了关于列权限的信息，该信息源自mysql.columns_priv授权表，是非标准表。</td>
</tr>
<tr>
<td>CHARACTER_SETS（字符集）</td>
<td>提供了mysql实例可用字符集的信息，SHOW CHARACTER SET结果集取之此表。</td>
</tr>
<tr>
<td>COLLATIONS</td>
<td>提供了关于各字符集的对照信息。</td>
</tr>
<tr>
<td>COLLATION_CHARACTER_SET_APPLICABILITY</td>
<td>指明了可用于校对的字符集，这些列等效于SHOW COLLATION的前两个显示字段。</td>
</tr>
<tr>
<td>TABLE_CONSTRAINTS</td>
<td>描述了存在约束的表，以及表的约束类型。</td>
</tr>
<tr>
<td>KEY_COLUMN_USAGE</td>
<td>描述了具有约束的键列。</td>
</tr>
<tr>
<td>ROUTINES</td>
<td>提供了关于存储子程序（存储程序和函数）的信息，此时，ROUTINES表不包含自定义函数（UDF），名为</td>
</tr>
<tr>
<td>VIEWS</td>
<td>给出了关于数据库中的视图的信息，需要有show views权限，否则无法查看视图信息。</td>
</tr>
<tr>
<td>TRIGGERS</td>
<td>提供了关于触发程序的信息，必须有super权限才能查看该表。</td>
</tr>
</tbody></table>
<p>information_schema的表schemata中的列schema_name记录了所有数据库的名字<br>information_schema的表tables中的列table_schema记录了所有数据库的名字<br>information_schema的表tables中的列table_name记录了所有数据库的表的名字<br>information_schema的表columns中的列table_schema记录了所有数据库的名字<br>information_schema的表columns中的列table_name记录了所有数据库的表的名字<br>information_schema的表columns中的列column_name记录了所有数据库的表的列的名字</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/metric/performance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/metric/performance/" class="post-title-link" itemprop="url">Java性能指标与调优</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-25 08:58:00" itemprop="dateCreated datePublished" datetime="2019-03-25T08:58:00+08:00">2019-03-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:26" itemprop="dateModified" datetime="2021-02-09T09:38:26+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>无论是web服务、集群应用还是单机应用，涉及的性能相关的内容很多:</p>
<p>接下来分别从上层到底层介绍所涉及的点:</p>
<p>webpage–&gt;nginx–&gt;io–&gt;cpu–&gt;memory–&gt;JVM–&gt;Java</p>
<h2 id="webpage"><a href="#webpage" class="headerlink" title="webpage"></a>webpage</h2><h2 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h2><h2 id="io"><a href="#io" class="headerlink" title="io"></a>io</h2><h2 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h2><h2 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h2><h2 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h2><h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/Java/multithread/lockless-disruptor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="aaronzhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guadazi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/Java/multithread/lockless-disruptor/" class="post-title-link" itemprop="url">无锁队列与Disruptor</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-20 00:00:00" itemprop="dateCreated datePublished" datetime="2019-03-20T00:00:00+08:00">2019-03-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-09 09:38:26" itemprop="dateModified" datetime="2021-02-09T09:38:26+08:00">2021-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自<a target="_blank" rel="noopener" href="http://www.importnew.com/19877.html">剖析Disruptor为什么会这么快</a></p>
<p><strong>Disruptor如何解决这些问题。</strong></p>
<p>首先，Disruptor根本就不用锁。</p>
<p>取而代之的是，在需要确保操作是线程安全的（特别是，在<a target="_blank" rel="noopener" href="http://mechanitis.blogspot.com/2011/07/dissecting-disruptor-writing-to-ring.html">多生产者</a>的环境下，更新下一个可用的序列号）地方，我们使用<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Compare-and-swap">CAS</a>（Compare And Swap/Set）操作。这是一个CPU级别的指令，在我的意识中，它的工作方式有点像乐观锁——CPU去更新一个值，但如果想改的值不再是原来的值，操作就失败，因为很明显，有其它操作先改变了这个值。</p>
<p><a target="_blank" rel="noopener" href="http://ifeve.com/wp-content/uploads/2013/01/ConcurrencyCAS.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/ConcurrencyCAS.png" alt="img"></a></p>
<p>注意，这可以是CPU的两个不同的核心，但不会是两个独立的CPU。</p>
<p>CAS操作比锁消耗资源少的多，因为它们不牵涉操作系统，它们直接在CPU上操作。但它们并非没有代价——在上面的试验中，单线程无锁耗时300ms，单线程有锁耗时10000ms，单线程使用CAS耗时5700ms。所以它比使用锁耗时少，但比不需要考虑竞争的单线程耗时多。</p>
<p>回到Disruptor，在我<a target="_blank" rel="noopener" href="http://ifeve.com/disruptor-writing-ringbuffer/">讲生产者</a>时讲过<a target="_blank" rel="noopener" href="https://github.com/LMAX-Exchange/disruptor/blob/version-2.x/code/src/main/com/lmax/disruptor/ClaimStrategy.java">ClaimStrategy</a>。在这些代码中，你可以看见两个策略，一个是SingleThreadedStrategy（单线程策略）另一个是MultiThreadedStrategy（多线程策略）。你可能会有疑问，为什么在只有单个生产者时不用多线程的那个策略？它是否能够处理这种场景？当然可以。但多线程的那个使用了<a target="_blank" rel="noopener" href="http://download.oracle.com/javase/6/docs/api/java/util/concurrent/atomic/AtomicLong.html">AtomicLong</a>（Java提供的CAS操作），而单线程的使用long，没有锁也没有CAS。这意味着单线程版本会非常快，因为它只有一个生产者，不会产生序号上的冲突。</p>
<p>我知道，你可能在想：把一个数字转成AtomicLong不可能是Disruptor速度快的唯一秘密。当然，它不是，否则它不可能称为“为什么这么快（第一部分）”。</p>
<p>但这是非常重要的一点</p>
<p>——在整个复杂的框架中，只有这一个地方出现多线程竞争修改同一个变量值。这就是秘密。还记得所有的访问对象都拥有序号吗？如果只有一个生产者，那么系统中的每一个序列号只会由一个线程写入。这意味着没有竞争、不需要锁、甚至不需要CAS。在ClaimStrategy中，如果存在多个生产者，唯一会被多线程竞争写入的序号就是 ClaimStrategy 对象里的那个。</p>
<p>这也是为什么Entry中的每一个变量都<a target="_blank" rel="noopener" href="http://ifeve.com/dissecting-disruptor-wiring-up/">只能被一个消费者写</a>。它确保了没有写竞争，因此不需要锁或者CAS。</p>
<p><strong>回到为什么队列不能胜任这个工作</strong></p>
<p>因此你可能会有疑问，为什么队列底层用RingBuffer来实现，仍然在性能上无法与 Disruptor 相比。队列和<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Circular_buffer">最简单的ring buffer</a>只有两个指针——一个指向队列的头，一个指向队尾：</p>
<p><a target="_blank" rel="noopener" href="http://ifeve.com/wp-content/uploads/2013/01/QueueMultiple.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueMultiple.png" alt="img"></a></p>
<p>如果有超过一个生产者想要往队列里放东西，尾指针就将成为一个冲突点，因为有多个线程要更新它。如果有多个消费者，那么头指针就会产生竞争，因为元素被消费之后，需要更新指针，所以不仅有读操作还有写操作了。</p>
<p>等等，我听到你喊冤了！因为我们已经知道这些了，所以队列常常是单生产者和单消费者（或者至少在我们的测试里是）。<br>队列的目的就是为生产者和消费者提供一个地方存放要交互的数据，帮助缓冲它们之间传递的消息。这意味着缓冲常常是满的（生产者比消费者快）或者空的（消费者比生产者快）。生产者和消费者能够步调一致的情况非常少见。</p>
<p>所以，这就是事情的真面目。一个空的队列：</p>
<p><a target="_blank" rel="noopener" href="http://ifeve.com/wp-content/uploads/2013/01/QueueEmpty.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueEmpty.png" alt="img"></a></p>
<p>…</p>
<p>一个满的队列：</p>
<p><a target="_blank" rel="noopener" href="http://ifeve.com/wp-content/uploads/2013/01/QueueFull.png"><img src="http://ifeve.com/wp-content/uploads/2013/01/QueueFull.png" alt="img"></a></p>
<p><em>(校对注：这应该是一个双向队列)</em></p>
<p>队列需要保存一个关于大小的变量，以便区分队列是空还是满。否则，它需要根据队列中的元素的内容来判断，这样的话，消费一个节点（Entry）后需要做一次写入来清除标记，或者标记节点已经被消费过了。无论采用何种方式实现，在头、尾和大小变量上总是会有很多竞争，或者如果消费操作移除元素时需要使用一个写操作，那元素本身也包含竞争。</p>
<p>基于以上，这三个变量常常在一个<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/CPU_cache">cache line</a>里面，有可能导致伪分享<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/False_sharing">false sharing</a>。因此，不仅要担心生产者和消费者同时写size变量（或者元素），还要注意由于头指针尾指针在同一位置，当头指针更新时，更新尾指针会导致缓存不命中。这篇文章已经很长了，所以我就不再详述细节了。</p>
<p>这就是我们所说的“分离竞争点问题”或者队列的“合并竞争点问题”。通过将所有的东西都赋予私有的序列号，并且只允许一个消费者写Entry对象中的变量来消除竞争，Disruptor 唯一需要处理访问冲突的地方，是多个生产者写入 Ring Buffer 的场景。</p>
<p><strong>总结</strong></p>
<p>Disruptor相对于传统方式的优点：</p>
<ol>
<li>没有竞争=没有锁=非常快。</li>
<li>所有访问者都记录自己的序号的实现方式，允许多个生产者与多个消费者共享相同的数据结构。</li>
<li>在每个对象中都能跟踪序列号（ring buffer，claim Strategy，生产者和消费者），加上神奇的<a target="_blank" rel="noopener" href="http://code.google.com/p/disruptor/source/browse/trunk/code/src/main/com/lmax/disruptor/RingBuffer.java">cache line padding</a>，就意味着没有为伪共享和非预期的竞争。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">aaronzhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">224</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">114</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aaronzhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
